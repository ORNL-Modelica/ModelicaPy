PROCEEDINGS OF THE

12

INTERNATIONAL

M DELICA

CONFERENCE
May 1517, 2017
Clarion Congress Hotel Prague
Czech Republic
www.modelica.org

The conference is organized by The Czech Society for Cybernetics and Informatics (CSKI) and Politecnico di Milano in cooperation with the Modelica Association.

Proceedings of the 12th International Modelica Conference
Prague, Czech Republic, May 15-17, 2017
Editors:
Doc. MUDr. Ji Kofrnek, CSc. and Prof. Francesco Casella
Published by:
Modelica Association and Linkping University Electronic Press
ISBN:
Series:
ISSN:
eISSN:
DOI:

978-91-7685-575-1
Linkping Electronic Conference Proceedings, No 132
1650-3686
1650-3740
http://dx.doi.org/10.3384/ecp17132

Organized by:
SKI
(Czech Society for Cybernetics and Informatics)
Pod Vodrenskou v 2
182 07 Praha 8 - Libe
Czech Republic

Politecnico di Milano
Dipartimento di Elettronica, Informazione e Bioingegneria
Piazza Leonardo da Vinci, 32
20133 Milano
Italy

in co-operation with:
Modelica Association
c/o PELAB, Linkpings Univ.
SE-581 83 Linkping
Sweden
Conference location:
Clarion Congress Hotel Prague
Freyova 33
190 00 Praha 9 - Vysoany
Czech Republic
Copyright  Modelica Association, 2017
2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

WELCOME
Ji Kofrnek
Conference Chair

Francesco Casella
Program Chair

We would like to welcome you to Prague for
the 12th international Modelica Conference.
The conference was organized by the
Modelica Association in cooperation with
the Czech Society for Informatics and
Cybernetics and Politecnico di Milano.

The International Modelica Conference is
the most important place for the Modelica
and FMI communities to meet, exchange
ideas and advance the state of the art in
object-oriented modelling.

Modelica is not only a unique modeling language, which is widely
used in numerous branches of industry and also in research
and science, but most of all it is an immensely effective tool for
complex simulations in the automotive industry, building energy
management, aerospace and many other fields of engineering.

This year we received 129 paper submissions for the scientific
program. After a thorough peer review process by the
International Program Committee, 83 were accepted for full
oral presentation and 19 for poster presentation, with authors
coming from 18 different countries in Europe, Asia, America, and
Oceania. The scientific program is completed by two distinguished
keynote talks, one from industry and one from academia.

The program of the conference is interesting not only for the
participants, who already use Modelica, but also for those who
would like to be introduced to the possibilities of this new modern
modeling language by our numerous tutorials. The usage of the
language is facilitated by Modelica libraries focused on diverse
fields. Consequently, an important part of the conference is the
traditional Library Award Announcement.

The conference also hosts nine tutorials, the FMI User Meeting,
as well as vendor presentations and a commercial exhibition.
I warmly welcome you to the 12th International Modelica
Conference and I wish you a successful, pleasant, and rewarding
stay in Prague!

We welcome you to Prague, the city of many historic sites, culture
and also the music festival Prague Spring, taking place in Prague
this week.

DOI
10.3384/ecp17132

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

3

4

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

KEYNOTE SPEAKERS
Challenges of Future Robotics

Synchronous Programming and its fit with
Modeling

Presenter:
Bernd Liepert
President of the euRobotics AISB
Chief Innovation Officer at KUKA AG

Presenter:
Grard Berry
Paris, France

Abstract: Robotics will change the world! It will unleash the
same if not an even more disruptive and transformational
power within the next 50 years as mainstream IT-technology
and the Internet have over the last half a century. Nurtured by
technological breakthroughs in industrial automation, robotics
will exhaustively permeate all domains of the human living
realm. Hence, our grandchildren will grow up in a society that
is enriched and enhanced by assistive technologies in every
imaginable way. Robotics and automation will be tailored into
many everyday objects, becoming an integral part of all kinds
of appliances. This Generation R will be without fear of these
technologies perceiving their beneficial nature - they will grow up
as Robotic Natives. This implies, that todays people are already
born to become the first society of Robotic Immigrants. Although
it is not possible to precisely predict the world of tomorrow,
the presented model of the 4 Robotic Revolutions provides a
compelling, holistic approach to describe the future phases
of robotic evolution, characterizing them according to their
technological enablers and underlying interaction paradigms.
Bio: Dr. Bernd Liepert is the Chief Innovation Officer of KUKA AG,
a world leading manufacturer of industrial robots. Dr. Liepert
earned his diploma in mathematics in 1990 from the University
of Augsburg and his honorary doctor degree from University
of Magdeburg in 2011. Since 1990 Dr. Liepert has worked in
changing positions for KUKA. From 1990 to 1996 he worked
as mathematician and developer at KUKA Schweissanlagen +
Roboter GmbH before he took charge as head of development
of the newly founded company KUKA Roboter GmbH until 1997.
From 1998-1999 he was a member of KUKA Roboter GmbH
Board of Management, responsible for development and design.
From 2000-2009 Dr. Liepert was the CEO of KUKA Roboter
GmbH. From 2010 to January 2015 he was the CTO of KUKA AG,
responsible for technology and development of the whole KUKA
group. As Chief Innovation Officer of KUKA AG, Dr. Liepert is
now responsible for expanding innovations at KUKA where he
can apply his vast robotics experience at the interface between
technology and the market. From 2008-2012 Dr. Liepert was
President of EUROP, the European Robotics Technology Platform,
and subsequently President of euRobotics AISBL  the European
Robotics Association. euRobotics was founded in September 2012
and has become the private side of SPARC, the European PublicPrivate Partnership in Robotics in 2013. As president of these
associations Dr. Liepert has been leading the European robotics
community and representing it at high political levels.

DOI
10.3384/ecp17132

Abstract: The family of Synchronous programming languages
was born in the 1980s in three different French labs that gathered
researchers in Computer Science and Control Theory. The three
first languages were Esterel, dedicated to control-dominated
problems in embedded systems, telecom protocols and later
digital circuit design, Lustre, dedicated to continuous control, and
Signal, oriented towards signal processing. They share a common
perfect synchrony principle that expresses that the reaction to
an input should be viewed as conceptually instantaneous. This
simple principle is well-adapted to the targeted applications
and greatly simplifies programming by reconciling parallelism
and determinism. It also leads to well-defined mathematical
semantics that directly ground their formal compiling, simulation
and verification environments. Synchronous programming
rapidly became used in Industry for safety-critical production
systems in avionics (Dassault Aviation, Airbus, etc.), railways, etc.,
as well as in robotics and circuit design. In the 2000s, Esterel
and Lustre have been unified in two new languages industrialized
by Esterel Technologies (now part of Ansys): SCADE 6 for safety
critical software and Esterel v7 for hardware design, both also
incorporating ideas from Harels reactive graphical formalism
Statecharts.
The talk will explain the practical and mathematical concepts
of synchronous programming and stress its advantages over
asynchronous concurrent programming for the considered
applications. It will also explore the links between synchronous
programming and modeling / simulation. In one direction,
synchronous languages are ideal targets to generate embedded
code from executable parts of simulation models. In the other
direction, embedding synchrony into conventional modelers
may be necessary to solve the current tricky issues due to the
coupling of discrete and continuous computations in modelers,
in particular for the currently mishandled case where external
or internal events provoke cascades of discrete reactions. Pouzet
and Bourkess new Zelus language is a step in this direction.
Bio: Former student of the Ecole polytechnique, Member of the
Academy of sciences, of the Academy of technology and the
Academia Europaea, CNRS Gold medal 2014, Grard Berry was a
researcher at the Ecole des mines of Paris and INRIA from 1973
to 2000, Chief Scientist of the company Esterel Technologies from
2001 to 2009, then Research Director at INRIA and President of
the Evaluation Committee of this Institute from 2009 to 2012.
He holds the Chair Algorithms, Machines and Languages at the
Collge de France from 2012, after having held two annual chairs
in 2007-2008 and 2009-2010.
His scientific contribution concerns four main topics: the formal
treatment of programming languages and their relations with
mathematical logic, reactive and real-time programming for
embedded systems, integrated circuit computer-aided design,
and formal verification of programs and circuits. He is the creator
of the Esterel programming language.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

5

6

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Program Committee
Conference Chair
Doc. MUDr. Ji Kofrnek, CSc., Charles University in Prague, Czech Republic
Program Chair
Prof. Francesco Casella, Politecnico di Milano, Italy
Conference Board
Dr. Hilding Elmqvist, Mogram AB, Lund, Sweden
Prof. Peter Fritzson, Linkping University, Sweden
Prof. Martin Otter, DLR, Germany
Dr. Michael Tiller, Xogeny, Michigan, USA
Program Committee
Dr. Johan kesson, Modelon AB, Lund, Sweden
Prof. Bernhard Bachmann, Univ. Applied Sciences Bielefeld, Bielefeld, Germany
Prof. John Baras, University of Maryland, Maryland, USA
Dr. John Batteh, Modelon Inc., Ann Arbor, USA
Dr. Albert Benveniste, INRIA, Rennes, France
Christian Bertsch, Robert Bosch GmbH, Stuttgart, Germany
Volker Beuter, VI-grade GmbH, Marburg, Germany
Torsten Blochwitz, ITI GmbH, Dresden, Germany
Dr. Scott Bortoff, MERL Cambridge, USA
Dr. Timothy Bourke, INRIA, France
Dr. Marco Bonvini, Whisker Labs, USA
Daniel Bouskela, EDF R&D, Paris, France
Prof. David Broman, KTH Royal Institute of Technology, Stockholm, Sweden
Dr. Dan Burns, MERL, Cambridge, USA
Prof. Francesco Casella, Politecnico di Milano, Milano, Italy
Prof. Massimo Ceraolo, University of Pisa, Italy
Prof. Franois E. Cellier, ETH Zrich (retired), Zrich, Switzerland
Dr. Christoph Clau, Fraunhofer IIS EAS (retired), Dresden, Germany
Dr. Johan de Kleer, PARC, Palo Alto, USA
Mike Dempsey, Claytex Services Ltd, UK
Dr. Hilding Elmqvist, Mogram AB, Lund, Sweden
Dr. Olaf Enge-Rosenblatt, Fraunhofer IIS Dresden, Dresden, Germany
Prof. Gianni Ferretti, Politecnico di Milano, Italy
Dr. Rdiger Franke, ABB AG, Mannheim, Germany
Dr. Jens Frenkel, ESI ITI Gmbh, Dresden, Germany
Prof. Peter Fritzson, Linkping University, Sweden
Leo Gall, LTX Simulation GmbH, Munich, Germany
Peter Harman, CAE Tech Limited, UK
Prof. Anton Haumer, OTH Regensburg, Regensburg, Germany
Dr. Dan Henriksson, Dassault Systmes, Lund, Sweden
Dr. Yutaka Hirano, Toyota, Japan
Christoph Hger, TU Berlin, Germany
Prof. Bengt Jacobson, Chalmers Technical Universiy, Gothenburg, Sweden
Prof. Tommi Karhela, VTT / Aalto University, Espoo, Finland
ke Kinnander, Siemens Turbo, Sweden
Jochen Khler, ZF AG, Friedrichshafen, Germay
Dr. Christian Kral, TGM, Vienna, Austria
Dr. Chris Laughman, MERL, Cambridge, USA
Prof. Alberto Leva, Politecnico di Milano, Italy
Kilian Link, Siemens AG, Erlangen, Germany
Prof. Edward Lee, UC Berkeley, USA
Prof. Marco Lovera, Politecnico di Milano, Italy
Kristin Majetta, Fraunhofer IIS, Dresden, Germany
DOI
10.3384/ecp17132

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

7

Dr. Jakob Mauss, QTronic GmbH, Berlin, Germany
Dr. Alexandra Mehlhase, Arizona State Univeristy, USA
Dr. Lars Mikelsons, Bosch-Rexroth GmbH, Lohr am Main, Germany
Ramine Nikoukhah, Altair Engineering, Paris, France
Prof. Henrik Nilsson, University of Nottingham, Nottingham, Great Britain
Prof. Mattias Nyberg, Scania AB, Sdertlje, Sweden
Prof. Akira Ohata, Toyota Motor Corporation, Tokyo, Japan
Dr. Hans Olsson, Dassault Systmes, Lund, Sweden
Prof. Martin Otter, DLR, Oberpfaffenhofen, Germany
Dr. Andreas Pillekeit, dSPACE , Germany
Dr. Adrian Pop, Linkping University, Sweden
Johan Rhodin, 84 Codes, Missouri, USA
Dr. Adrijan Ribaric, Sentient Science, Idaho Falls, USA
Dr. Clemens Schlegel, Schlegel Simulation, Munich, Germany
Prof. Gerhard Schmitz, Technical University Hamburg-Harburg, Germany
Dr. Peter Schneider, Fraunhofer IIS EAS, Dresden, Germany
Prof. Stefan-Alexander Schneider, Kempten University of Applied Sciences, Germany
Dr. Martin Sjlund, Linkping University, Sweden
Prof. Thierry Soriano, Supmeca, France
Dr. Rita Streblow, RWTH Aachen, Aachen, Germany
Dr. Ed Tate, Exa, Livonia, USA
Dr. Wilhelm Tegethoff, TLK-Thermo GmbH, Germany
Bernhard Thiele, Linkping University, Sweden
Dr. Michael Tiller, Xogeny, Michigan, USA
Dr. Jakub Tobolar, DLR Oberpfaffenhofen, Munich, Germany
Dr. Hubertus Tummescheit, Modelon Inc., West Hartford, USA
Prof. Alfonso Urqua, UNED, Madrid, Spain
Prof. Luigi Vanfretti, KTH Royal Institute of Technology, Stockholm, Sweden
Prof. Hans Vangheluwe, McGill University, Canada and University of Antwerp, Belgium
Dr. Subbarao Varigonda, Cummins, Columbus, USA
Dr. Stphane Velut, Lund, Sweden
Dr. Michael Wetter, Lawrence Berkeley National Laboratory, Berkeley, USA
Prof. Dietmar Winkler, University College of Southeast Norway, Norway
Dr. Dirk Zimmer, DLR Oberpfaffenhofen, Germany
Conference Organization Team:
Prof. Francesco Casella, Politecnico di Milano, Italy
Filip Jeek, Czech Technical University in Prague, Czech Republic
Doc. MUDr. Ji Kofrnek, CSc., Charles University in Prague, Czech Republic
Dr. Marek Matejak, Charles University in Prague, Czech Republic
Veronika Skorov, Creative Connections s.r.o., Prague, Czech Republic
Milena Zeithamlov, Action M Agency, Prague, Czech Republic

8

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Contents
Session 1: Keynote 1

17

Session 4A: Automotive I
Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System
Using Modelica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Virtual Occupant Model for Riding Comfort Simulation . . . . . . . . . . . . . . . . . . . . . . . . .
A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of
an Automotive Braking System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Improved Aerodynamic Prediction Through Coupled System and CFD Models . . . . . . . . . . . .

17

Session 4B: Buildings I
Coupled Simulation between CFD and Multizone Models Based on Modelica Buildings Library to
Study Indoor Environment Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Co-Simulation between detailed building energy performance simulation and Modelica HVAC component models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Aspects of FMI in Building Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation .

. 17
. 27
. 35
. 47
55
. 55
. 63
. 73
. 79

Session 4C: Process & Chemical Engineering
Development of a Thermodynamic Engine in OpenModelica . . . . . . . . . . . . . . . . . . . . . . . .
Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting . . . .
Dynamic Simulations of the Post-combustion CO2 Capture System of a Combined Cycle Power Plant
Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate . .
Session 4D: Control Systems I
Framework for dynamic optimization of district heating systems using Optimica Compiler Toolkit .
Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Rapid development of an aircraft cabin temperature regulation concept . . . . . . . . . . . . . . . .
Investigation of the Influence of Controller Approaches on Room Thermal Behaviour A Simulation
Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

89
89
101
111
121

131
. 131
. 141
. 151
. 161

Session 5A: Automotive II
171
Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle . . . 171
Investigating the Effect of a Sonic Restrictor in the Intake of an Engine . . . . . . . . . . . . . . . . . 181
Engine thermal shock testing prediction through coolant and lubricant cycling in Dymola . . . . . . . 189
Session 5B: Buildings II
199
Template based code generation of Modelica building energy simulation models . . . . . . . . . . . . . 199
Modelling and Simulation of Standardised Control Functions from Building Automation . . . . . . . . 209
Modelling of Heat Pumps with Calibrated Parameters Based on Manufacturer Data . . . . . . . . . . 219
Session 5C: Electrical & Power Systems I
Simulation of Large Grids in OpenModelica: reflections and perspectives . . . . . . . . . . . . . . . .
A Modelica-based Tool for Power System Dynamic Simulations . . . . . . . . . . . . . . . . . . . . .
A Modelica VSC-HVDC Average Value Model Implementation and its Software-to-Software Validation
using an EMT Power System Domain Specific Simulator . . . . . . . . . . . . . . . . . . . . . .

227
. 227
. 235
. 241

Session 5D: Control Systems II
249
From system model to optimal control - A tool chain for the efficient solution of optimal control problems249
Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using
FMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
Defining and Solving Hybrid Optimal Control Problems with Higher Index DAEs . . . . . . . . . . . . 265
DOI
10.3384/ecp17132

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

9

Session 6: Poster Session
Large Scale Training through Spoken Tutorials to Promote and use OpenModelica . . . . . . . . . .
EMOTH The EMobility Library of OTH Regensburg . . . . . . . . . . . . . . . . . . . . . . . . . . .
Simulating a Variable-structure Model of an Electric Vehicle for Battery Life Estimation Using Modelica/Dymola and Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Model Reduction Techniques Applied to a Physical Vehicle Model for HiL Testing . . . . . . . . . .
Towards Virtual Validation of ECU Software using FMI . . . . . . . . . . . . . . . . . . . . . . . . .
Parameter Estimation based on FMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Generic FMI-compliant Simulation Tool Coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
FMI and IP protection of models: A survey of use cases and support in the standard . . . . . . . . .
Model-based virtual sensors by means of Modelica and FMI . . . . . . . . . . . . . . . . . . . . . . .
Dymola-JADE Co-Simulation for Agent-Based Control in Office Spaces . . . . . . . . . . . . . . . .
Failure Modes of Tearing and a Novel Robust Approach . . . . . . . . . . . . . . . . . . . . . . . . .
Towards Adjoint and Directional Derivatives in FMI utilizing ADOL-C within OpenModelica . . . .
PDEModelica and Breathing in an Avalanche . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Multirotor Aerial Vehicle modeling in Modelica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Rotating Machinery Library for Diagnosis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Modelling and Simulation of the passive Structure of a 5-Axis-Milling Machine with rigid and flexible
bodies for evaluating the static and dynamic behaviour . . . . . . . . . . . . . . . . . . . . . . .
Modeling and Simulation on Environmental and Thermal Control System of Manned Spacecraft . .
Modeling and simulation of complex ThermoSysPro model with OpenModelica - Dynamic Modeling
of a combined cycle power plant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A Power-Based Model of a Heating Station for District Heating (DH) System Applications . . . . .

275
. 275
. 285
.
.
.
.
.
.
.
.
.
.
.
.
.

291
299
307
313
321
329
337
345
353
363
367
373
381

. 389
. 397
. 407
. 415

Session 7A: Automotive III
425
Model Based Design of a Split Carrier Wheel Suspension for Light-weight Vehicles . . . . . . . . . . . 425
Development of hierarchal commercial vehicle model for target cascading suspension design process . . 433
Model Based Analysis of Shimmy in a Racing Bicycle . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
Session 7B: Thermodynamic Systems
Optimization-friendly thermodynamic properties of water and steam . . . . . . . . . . . . . . . . . .
Modeling of a Thermosiphon to Recharge Phase Change Material Based Thermal Battery for a Portable
Air Conditioning Device . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow
Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

449
. 449
. 459
. 467

Session 7C: Electrical & Power Systems II
477
Improved Model of Photovoltaic Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477
Modelling of a Hydro Power Station in an Island Operation . . . . . . . . . . . . . . . . . . . . . . . . 483
Periodic Steady State Identification of electrical circuits . . . . . . . . . . . . . . . . . . . . . . . . . . 493
Session 7D: Control Systems III
Discrete-time models for control applications with FMI . . . . . . . . . . . . .
Model-based Embedded Control using Rosenbrock Integration Methods . . . .
Integration of complex Modelica-based physics models and discrete-time control
and observations of numerical performance . . . . . . . . . . . . . . . . .

. . . . .
. . . . .
systems:
. . . . .

507
. . . . . . . . 507
. . . . . . . . 517
Approaches
. . . . . . . . 527

Session 8: Keynote 2

533

Session 9A: FMI I
Improving Interoperability of FMI-supporting Tools with Reference FMUs .
The Embedded Simulation via FMI and its Application to the Simulation of
Wear . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Integration Modelica with Digital Mockup Tool using the FMI . . . . . . .

. . . . .
Lifetime
. . . . .
. . . . .

533
. . . . . . . . . . 533
Tests Including
. . . . . . . . . . 541
. . . . . . . . . . 547

Session 9B: Numerical & Symbolic Methods
Solving large-scale Modelica models: new approaches and experimental results using OpenModelica
Transformation of Differential Algebraic Array Equations to Index One Form . . . . . . . . . . . . .
Smart Processing of Function Calls to Achieve Efficient Simulation Code . . . . . . . . . . . . . . . .
10

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

557
. 557
. 565
. 581

DOI
10.3384/ecp17132

Session 9C: Acoustic & Medical Systems
Integrative physiology in Modelica . . . . . . . . . . . . . . . . . . . . . . .
Sound Source Extension Library for Modelica . . . . . . . . . . . . . . . . .
Towards Medical Cyber-Physical Systems: Modelica and FMI based Online
of the Cardiovascular System . . . . . . . . . . . . . . . . . . . . . . .

589
. . . . . . . . . . . . . . . 589
. . . . . . . . . . . . . . . 605
Parameter Identification
. . . . . . . . . . . . . . . 613

Session 9D: Wind & Naval Engineering
623
The DLR RailwayDynamics Library: the Crosswind Stability Problem . . . . . . . . . . . . . . . . . . 623
The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures633
Modelica Based Naval Architecture Library for Small Autonomous Boat Design . . . . . . . . . . . . . 643
Session 10A: FMI II
FMI Go! A simulation runtime environment with a client server architecture over multiple protocols
Building Parallel FMUs (or Matryoshka Co-Simulations) . . . . . . . . . . . . . . . . . . . . . . . . .
Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster . . . . . . .
Development of an open source multi-platform software tool for parameter estimation studies in FMI
models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. 683

Session 10B: Modelica Language & Tools
Innovations for Future Modelica . . . . . . . . . . . . . . . . . . . . . . . .
Hierarchical Semantics of Modelica . . . . . . . . . . . . . . . . . . . . . . .
Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica
modelica.university: A Platform for Interactive Modelica Content . . . . . .

. . . . . . . . . .
. . . . . . . . . .
Drivers Library
. . . . . . . . . .

.
.
.
.

.
.
.
.

735
. 735
. 745
. 755
. 765

. . . .
. . . .
Device
. . . .

Session 10C: Mechanical Systems Modelling
Object-oriented modelling of a flexible beam including geometric nonlinearities
Musculoskeletal Modeling of the Hand and Contact Object in Modelica . . . .
Modelica Spur Gears with Hertzian Contact Forces . . . . . . . . . . . . . . . .
Modeling of Roller Bearings . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.
.

.
.
.
.

Session 10D: HVAC Systems
Cabin Thermal Needs: Modeling and Assumption Analysis . . . . . . . . . . . . .
Simulative Comparison of Mobile Air-Conditioning Concepts for Mechanical and
Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Duty Cycle for Low Energy Operation of a Personal Conditioning Device . . . . .
A Platform for the Agent-based Control of HVAC Systems . . . . . . . . . . . . .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

. . . . . .
Electrical
. . . . . .
. . . . . .
. . . . . .

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

. . . .
Driven
. . . .
. . . .
. . . .

Session 11A: Modelica Tools & GUIs
MoVE A Standalone Modelica Vector Graphics Editor . . . . . . . . . . . . . . . . . . . . . . .
Mo|E A Communication Service Between Modelica Compilers and Text Editors . . . . . . . . .
Traceability Support in OpenModelica Using Open Services for Lifecycle Collaboration (OSLC)
A Simulation Environment for Efficiently Mixing Signal Blocks and Modelica Components . . .

.
.
.
.

.
.
.
.

.
.
.
.

Session 11B: Power Plants & Energy Systems
Component Development for Nuclear Hybrid Energy Systems . . . . . . . . . . . . . . . . . . . . . .
Modeling and simulation of fixed bed regenerators for a multi-tower decoupled advanced solar combined
cycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox
Cycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Applying the Power Plant Library ClaRa for Control Optimisation . . . . . . . . . . . . . . . . . . .
Session 11C: Mechanical Systems, Robotics & VR
Interactive FMU-Based Visualization for an Early Design Experience . . . . . . . . . . . . . . . . . .
Using Modelica for advanced Multi-Body modelling in 3D graphical robotic simulators . . . . . . . .
A New Object-Oriented Approach for Integrating Discrete Element Method into Modelica . . . . . .
Modeling and Simulation of Wheel Driving Systems based on Terramechanics for Planetary Explanation Rover using Modelica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
DOI
10.3384/ecp17132

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

653
. 653
. 663
. 673

693
693
703
713
725

771
. 771
. 783
. 791
. 799
809
. 809
. 815
. 823
. 831
839
. 839
. 847
. 857
. 867
879
. 879
. 887
. 895
. 901
11

Session 11D: Aerospace
909
The Jet Propulsion Library: Modeling and simulation of aircraft engines . . . . . . . . . . . . . . . . . 909
Virtual flight testing of a controller for gust load alleviation using FMI for cosimulation . . . . . . . . 921
The DLR Environment Library for Multi-Disciplinary Aerospace Applications . . . . . . . . . . . . . . 929

12

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Author Index
Abel, Dirk
berg, Marcus
Adib Murad, Mohammed Ahsan
Albertelli, Paolo
Albin, Thivaharan
Altshuller, Dmitry
Andreasson, Johan
Aoyama, Kazuhiro
Asghar, Adeel
Aute, Vikrant
Bachmann, Bernhard
Baharev, Ali
Banakar, Shivakumar
Bardaro, Gianluca
Bardow, Andr
Bartolini, Andrea
Bascetta, Luca
Batteh, John
Bau, Uwe
Baumgartner, Daniel
Baviere, Roland
Bayon, Alicia
Beaude, Francois P.
Bellmann, Tobias
Bender, Daniel
Berenguel, Manuel
Bergianti, Luca
Bertsch, Christian
Beutlich, Thomas
Blochwitz, Torsten
Bonilla, Javier
Bouskela, Daniel
Braun, Willi
Brembeck, Jonathan
Breque, Florent
Briese, Lle Evrim
Bnning, Felix
Bnte, Tilman
Brger, Christoff
Carballo, Jose Antonio
Casella, Francesco
Caujolle, Mathieu
Choi, Hyung Yun
Cimmino, Massimo
Clauss, Christoph
Constantin, Ana
Corniglion, Remi
Corniglion, Rmi
Corves, Burkhard
Croes, Jan
Dad, Cherifa
Dahash, Abdulrahman
Dahl, Markus
Datta, Kaushik
Davoudabadi, Peyman
de La Calle, Alberto
DOI
10.3384/ecp17132

459,
363, 557,

35, 47, 171,

713,

363,

227, 557,
663,
79,

613
449
241
735
613
477
745
643
823
791
581
353
783
887
101
227
887
527
101
425
141
857
235
713
151
683
171
533
895
507
683
407
557
425
771
929
799
425
517
683
887
673
27
219
161
345
673
663
765
337
673
415
755
275
35
857

Dempsey, Mike
Desmet, Wim
Dhumane, Rohit
Dominik, Andreas
Duncan, Brad
Durling, Erik
El Hefni, Baligh
Elci, Mehmet
Elmqvist, Hilding
Emhofer, Johann
vora Gmez, Jos
Fanli, Zhou
Febres, Jess
Ferretti, Gianni
Fischer, Torben
Fleps-Dezasse, Michael
Franke, Rdiger
Fraulob, Sebastian
Fritzsche, Jrg
Fritzson, Peter
Ftterer, Johannes
Galindo, Eduardo
Gallagher, Stephen
Gallarotti, Maura
Galtier, Virginie
Gargoloff, Joaquin
Gauterin, Frank
Gertig, Christoph Udo
Gesenhues, Jonas
Gillot, Romain
Giraud, Loc
Gonzalez Cocho, Mikel
Gottelt, Friedrich
Grber, Manuel
Greenwood, Scott
Greiner, Christopher
Grether, Gustav
Griffin, John
Grimm, Alexander
Gross, Joachim
Gundermann, Julia
Hagemann, Jan
Han, Bing
Han, Manyong
Hrdin, Tomas
Haumer, Anton
Heckmann, Andreas
Hein, Marc
Henningsson, Maria
Henningsson, Toivo
Henriksson, Dan
Heo, Seungjin
Hernndez Cabrera, Jos Juan
Heyberger, Jean-Baptiste
Hirano, Yutaka
Hirao, Akinari

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

181, 299
337
459, 791
809, 815
47
329
407
415
565, 693
605
663
397
847
441, 735
255
425
363, 507
541
249
89, 275, 823
799
189
299
181
663
47
255
101
613
299
141
337
467, 867
249
839
527
623
47
285
101
541
581
381
27
653
285, 389
623
613
329
693
517
433
663
235
17, 425
27
13

Hger, Christoph
Hoppe, Timm
Huchtemann, Kristian
Hsson, Peter
Hyun, Minsu
Ianotto, Michel
Inderfurth, Alexander
Invernizzi, Davide
Ishibashi, Tatsuro
Jain, Rahul
Janczyk, Leonard
Jeek, Filip
Jian, Jin
Jo, Jaehun
Johnson, Lee
Jones, Christopher
Junghanns, Andreas
Justus, Nicola
Kampfmann, Rdiger
Kang, Daeoh
Kaul, Werner
Kawai, Tadao
Kerling, Ines
Kesarkar, Omkar
Ketelhut, Maike
Kirches, Christian
Klckner, Andreas
Ko, Kwangchan
Kckeis, Rupert
Kofrnek, Ji
Kraus, Tom
Kremers, Enrique
Krishnaswamy, Sivasubramani
Kuhn, Martin
Kulhanek, Tomas
Kulshreshtha, Kshitij
Kuric, Muhamed
Lacoursire, Claude
Lanzerath, Franz
Larsson, Per-Ola
Lefeng, Sun
Leimeister, Mareike
Leon, Gladys E.
Letschert, Thomas
Leva, Alberto
Limperich, Dirk
Ling, Jiazhen
Liping, Chen
Lpez Prez, Susana
Lwen, Artur
Magargle, Ryan
Magnani, Gianantonio
Magnsdttir, Arnds
Magnusson, Fredrik
Majetta, Kristin
Mandloi, Padmesh
Marx-Schubach, Thomas
Matejak, Marek
14

703
467, 867
345
477
433
663
199
735
381
89, 275
477
367, 589
397
433
35
477
533
809, 815
313
433
199
381
151
35
613
255
929
433
389
367, 589
255
663
35
493
589
363
373
653
101
131
397
633
235
815
227
783
459, 791
397
847
345
35
441
483
131, 449
79, 161
35
121
589

Matsuda, Shinji
Matsuoka, Hisayoshi
Matteucci, Matteo
Mattsson, Sven Erik
Menager, Nils
Mengist, Alachew
Merabet, Massinissa
Mesonero, Ivn
Meyer, Richard
Mikelsons, Lars
Mochol Montas, Rubn
Msch, Danny
Moudgalya, Kannan
Mucha, Katharina
Mukbil, Awad
Mller, Dirk
Mller, Reiko
Mller, Wolfgang
Najafi, Masoud
Nassif, Fady
Nayak, Priyam
Nemer, Maroun
Nemmaru, Bhargava
Neumaier, Arnold
Nicolai, Andreas
Nielsen, Lasse
Nikoukhah, Ramin
Nonaka, Kenichiro
Nord, Lars Olof
Nytsch-Geusen, Christoph
Ochel, Lennart
Oda, Takatsugu
Ohser, Florian
Ohtomi, Koichi
Oizumi, Kazuya
Olsson, Hans
Osmic, Nedim
Otter, Martin
Paepcke, Anne
Palmkvist, Elias
Park, Jongchan
Peler, Georg Ambrosius
Pfeiffer, Andreas
Picarelli, Alessandro
Pipiorke, Jrg
Pitchaikani, Anand
Pluymers, Bert
Pollok, Alexander
Ponci, Ferdinanda
Pop, Adrian
Pytlak, Radoslaw
Qi, Liu
Radermacher, Reinhard
Rdler, Jrg
Reichl, Christoph
Reinbold, Vincent
Reiner, Matthias
Richter, Christian

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

507,

89,
345,

161,
507,

507,
507, 517, 565,

181, 189,
35,

89, 275,
459,
663,

547
27
887
517
313
823
141
847
79
307
111
313
275
199
533
799
921
321
831
831
275
771
275
353
63
867
831
901
111
199
581
901
895
547
643
517
373
693
63
329
433
209
517
299
73
909
337
151
345
823
265
397
791
199
605
673
929
895

DOI
10.3384/ecp17132

Ritter, Markus
Roca, Lidia
Runvik, Hkan
Salgado, Oscar
Samlaus, Roland
Sammak, Majed
Sangi, Roozbeh
Scaglioni, Bruno
Schichl, Hermann
Schilling, Johannes
Schmitz, Gerhard
Schnabel, Uwe
Schneider, Georg Ferdinand
Schneider, Michael
Schlzel, Christopher
Schwan, Torsten
Schweiger, Gerald
Sekiguchi, Kazuma
Selvan, Nithish
Sevilla, Thomas
Sielemann, Michael
ilar, Jan
Sjlund, Martin
Sohn, Michael
Soler, Rodolfo
Steiger, Simone
Steingrube, Annette
Stellato, Massimo
Stber, Moritz
Suski, Damian
Sutherland, Joshua
Suzuki, Hiromasa
Swaminathan, Shashank
Tahirovic, Adnan
Tarnawski, Tomasz
Tate, Ed
Tuber, Patrick
Tavella, Jean-Philippe
Tegethoff, Wilhelm
Thiele, Bernhard
Thiele, Matthias
Thomas, Philipp
Thorade, Matthis
Tian, Wei
Tidefelt, Henrik
Tiller, Michael
Tillmanns, Dominik
Tobolar, Jakub
Todtermuschke, Karsten
Tomiati, Nicol
Toriya, Hiroshi
Trentelman, Thom
Tugores, Carles Ribas
Tummescheit, Hubertus
Unger, Ren
Valle, Mathieu
Vanfretti, Luigi
Velut, Stphane
DOI
10.3384/ecp17132

131,

441,

809,

367,

663,

921
683
449
337
307
909
799
735
353
101
121
541
209
389
815
73
131
901
909
55
909
589
713
55
189
209
415
171
291
265
643
547
745
373
265
47
581
673
249
713
541
633
199
55
755
725
101
425
541
441
547
643
199
47
73
141
241
131

Vialle, Stephane
von Manstein, Arnim
Walther, Andrea
Walther, Susanne
Wang, Kai
Waurich, Volker
Weber, Jrgen
Wei, Liu
Weiser, Tobias
Wernersson, Karl
Wetter, Michael
Wettergren, Hkan
Widl, Edmund
Windahl, Johan
Winkler, Dietmar
Wischhusen, Stefan
Yoshikawa, Hiroki
Zawadzki, Tomasz
Zimmer, Dirk
Zitzenbacher, Raimund
Zuo, Wangda

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

673
783
363
541
527
713, 879
879, 895
397
765
507
219
755
321
449
483, 725
467
901
265
151
605
55

15

16

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Development of an Integrated Control of Front Steering and
Torque Vectoring Differential Gear System Using Modelica
Yutaka Hirano1
1

Toyota Motor Corporation, Japan, yutaka_hirano@mail.toyota.co.jp

Abstract
To achieve future low carbon mobility society, many
new-type electric vehicles (EVs) are developed
actively in recent period. Those EVs have integrated
power unit which take place of conventional engine,
transmission and differential gear components.
Additionally it is rather easy to integrate torque
vectoring function to those power units using gear sets
to control torque distribution between left wheel and
right wheel. In this paper, model-based development of
an integrated control of the front steering angle and
torque vectoring differential (TVD) gear system is
described. New integrated control logic was developed
using model matching control to let the vehicle yaw
rate and vehicle slip angle follow the desired dynamics.
Simulation results using an extended single track
model of vehicle dynamics are shown to prove the
efficacy of the proposed control. Though, full vehicle
model considering all of vehicle dynamics and drive
train motion using Modelica clarified the problem of
this method in actual cases. Difference between the
extended single track model and full vehicle model was
compared to estimate the reason of the problem.
Keywords:
Model Based Development, Vehicle
Dynamics, Torque Vectoring, Model Matching Control

1

Introduction

To satisfy needs for future low-carbon mobility society,
development of many new EVs is increasingly active
in recent years. Additionally many new proposals
about integrated electric power train which also has
torque vectoring capability are presented (Hhn et al.,
2013). (Burgess, 2009) showed a model-based control
design of TVD using an inverse model for feedforward control. (Efstathios et al. 2015) introduced a
model predictive control of TVD considering nonlinear tire characteristics. On the other hand, authors
have researched a new control of TVD by using
traditional PI feedback control (Hirano et al.,
2013)(Hirano et al., 2014). The author also utilized a
model matching control theory to develop a new
control of TVD (Hirano, 2016a). Additionally the
author expand the control to the integrated control of
TVD and active front steering (AFS) by model
matching control (Hirano, 2016b). The purpose of
DOI
10.3384/ecp1713217

using both TVD and AFS is to control both vehicle
yaw rate and slip angle independently. In the last paper,
the derived control was based on simple LQR (Linear
Quadratic Regulator) and there was no measure to cope
with steady state deviation. In this paper, the LQR
design was modified by augmenting the plant model to
include integral of the state variables. As same as the
last research, an extended single track model of vehicle
dynamics was used to derive and verify the new
control. Finally the developed control was verified by
using the full vehicle model using Modelica. Some
measures about solving problems when applying
Modelica to this kind of problem are also mentioned.

2

Experimental EV
Table 1 Specifications of new experimental EV

750 kg

Conventional
car
1240 kg

869 kgm2

2104 kgm2

2.6 m

2.6 m

0.48 : 0.52

0.62 : 0.38

0.38 m
510-3
16.1

0.55 m
8.810-3
20.4

New EV
Vehicle Mass
Yaw
Moment
Inertia
Wheelbase
Front : Rear Weight
Distribution
Height of CG
Tire RRC
Tire Normalized CP

The proposed experimental EV has specifications as
shown in Table 1. Compared with a conventional
small-class passenger car, the new EV has better
characteristics of lighter vehicle weight, smaller yaw
moment of inertia, lower height of the center of gravity
(CG) and lower rolling resistance coefficients (RRC)
value of tires. Because of these characteristics, this new
EV is expected to have better handling and lower
energy consumption than conventional vehicles. On the
other hand, because of lighter weight and lower value
of tire normalized CP (Cornering Power), this new EV
seems more sensitive against external disturbances
such as crosswind and road irregularity than the
conventional cars. To cope with this problem, direct
yaw moment control (DYC) was applied by using a

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

17

Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System Using
Modelica

new integrated transaxle unit for rear axle which has a
main electric motor and also TVD gear unit with a
control motor. Additionally, to control both yaw rate
and slip angle of the vehicle independently, another
control input of active front steering (AFS) was
introduced.

3

Vehicle Model
df
W

 f f
Xfl

Xfr



Yfl
V
u
vv
V
V

r
Yrl

Yfr
u
v
V



lf

Fx(fr)



M
V
Iz
lf (lr)

: Vehicle slip angle,
: Vehicle yaw rate,
: Vehicle mass,
: Vehicle velocity,
: Vehicle yaw moment of inertia,
: Distance from the CG to front (rear) axle,
(CG: Center of Gravity)
df (dr) : Tread of front (rear) axle,
X** : Longitudinal force of each tire,
Yf (Yr)
: Lateral force of front (rear) tires,
f
: Steering angle of front tire,
F
: Vehicle driving force,
N
: Direct yaw control moment by TVD.
Kf and Kr are the equivalent cornering power of front
and rear tire respectively.
If driving force F and DYC moment N can be
calculated by some control logic, then the target
longitudinal forces of left and right rear wheels to be
realized by TVD power unit become as follows from
Equation (1) and (6).

lr
Xrl

Xrr

N

X rr 

1
N
 F 
2
dr





(7)

X rl 

1
N
 F 
2
dr





(8)

Yrr

dr
W
Figure 1. Extended single track vehicle model

4
Figure 1 shows an extended single track vehicle model
to derive the control logic. Usually the single track
model calculates front and rear tire side forces by
adding both tire forces of right tire and left tire
respectively. But in this paper, the model was extended
to separate the tire longitudinal forces of right tire and
left tire to consider direct yaw moment generated by
the difference of the longitudinal forces of right tire
and left tire. The coordinate system of this model
follows FLU (x: forward, y: leftward, z; upward)
convention. The simplified equations of motion by this
extended single track model become as follows.
dV
M
 F  ( X rr  X rl )
(1)
dt

 d

MV 
    2Y f  2Yr
dt



(2)

d
Iz
 2l f Y f  2lr Yr  N
dt

(3)

where
lf

Y f   K f  f   K f       f
V






Control Design

4.1 Longitudinal Driving Force Control
Let us suppose that the desired value of vehicle speed,
vehicle yaw rate and vehicle slip angle are defined as
Vref ,  ref and  ref respectively.
The desired vehicle driving force F can be
calculated as below by PI feedback control and
Equation (1)..
F M

dVref
dt

 K PF (Vref  V )  K IF  (Vref  V )dt

(9)

Here KPF is a proportional feedback gain and KIF is an
integral feedback gain.

4.2 Model Matching Control of Lateral
Dynamics
For the lateral dynamics, the state space form of the
vehicle dynamics with TVD and AFS control becomes
as follow from Equations (2) and (3).
x  Ax  Bu
(10)
Here,

(4)

l 

Yr   K r  r   K r    r  
V 


(5)

N  d r ( X rr  X rl )

(6)

 
x 
  : State variables

(11)

 
u   f  : Control inputs
N

(12)

Here,
18

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713217

Session 4A: Automotive I

 2( K f  K r )
 
MV
A
 2(l f K f  lr K r )

Iz


2(l f K f  lr K r ) 

MV 2

2
2
2(l f K f  lr K r ) 


I zV


a 
a
  11 12 
a21 a22 

 2K f

B   2lMV
 fKf
 I z

Here, Gs: steering gear ratio. From the Equation (16),
x0 is obtained as follow.
x0   A 1 E s

1



(14)

Please note that the elements of the matrix A of the
Equation (10) are dependent on the vehicle velocity V
as shown in the Equation (13). So the vehicle dynamics
system described by the Equation (10) is a time-variant
system.
It is well known that the response of both yaw rate
and slip angle become to the second order lag function
of the steering input when no control is applied. This
fact results in that the ordinary drivers tend to respond
to steer with time lag against the vehicle motion and
tend to result in vehicle spin when the vehicle motion
becomes unstable such as on the slippery road. On the
other hand, it becomes easier for drivers to stabilize the
vehicle if the response of the vehicle motion will
become to the first order lag function, i.e. there is no
resonance characteristics about the vehicle dynamics.
Thus, the desired dynamics of vehicle yaw rate and
vehicle slip angle are assumed as the first order lag
function of the drivers steering wheel input, as shown
by the Equation (15).
 k



  ref  1  s   0 
 s
xd  

  ref   k G 
 1  s  0 



G

(15)

Here, s is Laplace operator. k and k are gain of
desired slip angle and desired yaw rate from the steady
state gain of each state variables, while G and G are
steady state gain of the slip angle and the yaw rate
respectively from the steering wheel input angle s.
Also  and  are time constant of the desired slip
angle and the desired yaw rate as the first order lag
function.
G and G are calculated as follows. Considering
the case of steady state as x = x0 and without any active
control, the Equation (10) becomes as bellow.
(16)
x0  0  Ax0  E s
where
 2K f 


G MV 
E s
 2l f K f 
 GI 
 s z 

DOI
10.3384/ecp1713217

 4 K f K r lr (l f  lr ) 2l f K f


MI zV 2
Iz



4
K
K
(
l

l
)

f
r f
r

MI zV


(13)


0
b12 
b
  11
1  b21 b22 
I z 

MI zV 2
4 K f K r (l f  lr )  2MV 2 (l f K f  lr K r )
2

Thus, G
equation.


 1

s
 Gs



(18)
and G can be calculated as the following

G  0 
MI zV 2
G   
2
4 K f K r (l f  l r )  2MV 2 (l f K f  l r K r )
 0 
 4 K f K r l r (l f  l r ) 2l f K f


Iz
MI zV 2

 4 K f K r (l f  l r )


MI zV



 1

 Gs



(19)
The model matching control can be derived as
below. The state space form of the desired dynamics
can be written as below from the Equation (15).
(20)
x d  Ad x d  E d  s
Here,
 1
0
 

Ad  
1
 0





k
 

 G 0 

.
Ed   
k
 

  G 0 
 




 and




Assume the error between actual state variables and
desired state variables as e  x  xd . A dynamic state
equation of this error variable can be obtained as below
by subtracting Equation (20) from Equation (10).
e  Ae  Bu  ( A  Ad ) x d  E d  s
(21)
In the previous research (Hirano, 2016b), the
simulation results of full vehicle model showed that
there were some steady state deviation remained after
stabilizing the vehicle motion. Thus, it is suggested
that augmenting the state space equation of the
Equation (21) to include the integral of the state
variables is necessary. By assuming a new state vector
of the error vector as

(17)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

19

Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System Using
Modelica

  
  

elements of feedback gain K as a function of the
vehicle velocity V.

 = (    )

(22)

(    )
[
]
the Equation (21) is augmented as below.

0
0
 = [
1 0 0
0 1 0

0

0]  + [0 0] 
0
0 0
0



(   )

+ [ 0 0 ]   [0 0] 

0 0

(23)

0 0


  +   + 
    

Figure 2. Plot of LQR gain according to vehicle speed

Here,

  [



1 0
0 1

0
0
0
0



0
0] = [ 
2
0
0

Finally the actual control input u is calculated by the
Equations (24) and (26) as below. At first the Equation
(24) is rewritten as below.

2
]
2



Bu  ( A  Ad ) xd  Ed 
[ 1 ]  = [
]
2




  [0 0] = [ ]
2
0 0
(    )
(   )


[
0 0 ]=[   ]

2
0 0

1 is the upper part of size (24) of the gain
Here, 
 and 
2 is the lower part of size (24) of the
matrix 

gain matrix . S is an unknown variable.
From the upper part of the Equation (27) the actual
control input u can be calculated as below.





  [0 0] = [ ]
2
0 0

u  B 1{ K 1e  ( A  Ad ) xd  Ed  s }

where O2 is the zero matrix of order 2 and I2 is the unit
matrix of order 2.
Lets assume a virtual control input of the
augmented state space equation of the error vector as
follow.
    + 

(24)

    
Then the Equation (23) becomes as follow.
  + 4 

(25)
 = 
Here I4 is the unit matrix of order 4. For the linear
system of the Equation (25), we can design a feedback
control

=
 


(26)

by linear control theory. In this paper, the feedback
gain K is calculated by using LQR (Linear Quadratic
Regulator) so that the following criteria function is
minimized.


J   (e T Qe  U T RU )dt
0

Here, Q and R are weight matrixes of order 4. Please
note that K is dependent on vehicle velocity because
the matrix A included in A is velocity dependent as
shown in Equation (13). Figure 2 shows some
20

(27)

(28)

Here, B 1 is the inverse matrix of B. ( B 1 B  I 2 .)
From the Equation (28) it is understood that the control
input consists of a feedback term of the augmented
state error and two feedforward terms of desired state
variables and also of drivers steering input.

5

Simulation Models and Results

5.1 Single Track Vehicle Model
To confirm the validity of above mentioned model
matching control, simulation test based on the single
track vehicle model was performed by using Modelica.
First of all, we should handle time-varying linear state
space system expressed by Equations (10) and (13). It
was easy to describe time-varying state space system as
Equations (10) and (13) by Modelica as mentioned
below.
A new class of time-varying linear state space
system was defined by using Modelica. For this
purpose, the existing class of the linear state space
system of Modelica Standard Library (MSL) was
modified to release the constraint of variability of
variables (i.e. by eliminating parameter qualifier).
The definition of the new class becomes as follow.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713217

Session 4A: Automotive I

block StateSpace_Variable

extends Modelica.Blocks.Interfaces.MIMO(fi
nal nin=size(B, 2), final nout=size(C, 1));
Real A[:, size(A, 1)];
Real B[size(A, 1), :];
Real C[:, size(A, 1)];
Real D[size(C, 1), size(B, 2)]=zeros(siz
e(C, 1), size(B, 2)) ;
output Real x[size(A, 1)](start=x_start)
"State vector";
equation
der(x) = A*x + B*u;
y = C*x + D*u;
end StateSpace_Variable;
model SingleTrackModel

StateSpace_Variable Actual_x(
A=A,
B=B,
C=identity(2));
StateSpace_Variable Desired_xd(
A=Ad,
B=Ed,
C=identity(2));

end SingleTrackModel;

For comparison, the definition of the existing class of
the linear state space system in MSL is as below.
block StateSpace "Linear state space syste
m"

parameter Real A[:, size(A, 1)]=[1, 0; 0
, 1];
parameter Real B[size(A, 1), :]=[1; 1];
parameter Real C[:, size(A, 1)]=[1, 1];
parameter Real D[size(C, 1), size(B, 2)]
=zeros(size(C, 1), size(B, 2)) ;

equation
der(x) = A*x + B*u;
y = C*x + D*u;

end StateSpace;
integratorKi_output
Variable
*K
I
k=1

steering_ratio

delta_f

Desired_xd
Xd_output
Variable
*K

A B
Variable

k=p

(28). The time varying linear state systems of both
plant model and desired dynamics model as mentioned
above are used in this model. Also 1D table elements
are used to define the matrix gains which are
dependent on the vehicle speed. Please note that it was
impossible to write the model by connecting elements
by normal Modelica connection as shown by dashed
lines in Figure 3. There occurred Modelica translator
error by this way. If we connect the dashed lines as
normal Modelica connection, then this model
becomes under-constrained because the variable S in
the Equation (27) is not defined. To solve this problem,
algorithm section to calculate final value of u was
used in this model. (Dashed lines in Figure 3 indicate
that there is additional summation of the signals just
graphically. It is a little shortcoming of Modelica that
all of the equations including algorithm section
cannot be seen directly in the graphical window.)
Figure 4 shows simulation results using the single
track model. Vehicle accelerates from 10km /h to
100km/h between time 1 sec to 10sec. The steering
input angle moves as 1Hz sinusoidal curve. Desired
dynamics was settled as k = 0.3 and k and 
are settled as corresponding value of cut-off frequency
of 1.3 Hz.
The results of vehicle slip angle and yaw rate are
shown not only in the nominal plant but also there
were some perturbation of vehicle mass (M) and tire
cornering power (CP). In the nominal case, the results
of slip angle and yaw rate were exactly matched with
the desired values. It is shown that the model matching
control has rather good robustness against the
perturbation of the parameter M. But it is not so robust
against the change of the plant parameter CP. The
improvement of the robustness of the control should be
a future research.

C D

vecAdd
-1
+
+1

Kp_output
Variable
*K

Active Front Steer Angle
vecAdd3
deMultiplex2
+1
+
+1 + +
+1

Actual_x
delta

A B
Variable

C D

Steering input angle

Deltaf_output
Variable
*K

k11_Table
k13_Table
k12_Table
k14_Table

t_DY C

v2kmh
k=3.6

k21_Table
k23_Table

DYC Torque
k22_Table

Velocity

k24_Table

Figure 3. Modelica model of the controller

Figure 3 shows a diagram of the Modelica model of
the model matching controller as defined by Equation
DOI
10.3384/ecp1713217

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

21

Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System Using
Modelica

5.2 Full vehicle model
The full vehicle model as previous research (Hirano et
al., 2013)(Hirano et al., 2014) was used for full-vehicle
simulation. The model was developed based on
Vehicle Dynamics Library of Modelica (Modelon,
2014) and was built as a full 3-dimentional (3D) multibody-dynamic system (MBS) model. Component
models of control systems such as TVD gearbox,
electric motor and inverter were added with the full
vehicle model.

Figure 5. Structure of full vehicle test model

Figure 5 shows the top level of the model hierarchy
of the full vehicle test model and also the power train
model with the controller.
For the TVD gear train, a driveline structure
referencing the MUTE project of the Technische
Universitt Mnchen (Hhn et al., 2013) was selected
and the TVD model was constructed using Modelica
Power Train Library (DLR, 2013). Figure 6 shows the
configuration of the gear trains. Torque from the main
motor is distributed equally to the left wheel and the
right wheel through the differential gear. The torque
distribution between the left wheel and the right wheel
can be controlled by changing the torque input of the
control motor.

Figure 4. Plot of vehicle velocity and steering input angle

22

Figure 6. Torque vectoring differential (TVD) driveline

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713217

Session 4A: Automotive I

Rdif

5.3 Results of full vehicle simulation

Rdif_rpm

right

w
P4
w
C34

controlMotor
mountB6

w
P3

Torque Vectoring Gear Box

w

support by PowerTrain Library

S4

add1
+1
C34_rpm
+
-1add2
+1
+
-1

P4_rpm

P3_rpm

S4_rpm
w

S3
mountA

S3_rpm

S4_LeftTyre
C4_RightTyre

w
R2
R2_rpm

differential

Part2

Part1

w
C2
C2_rpm
w
S2

S2_rpm
mountB3

w
R1
R1_rpm

Brake
w
C1

C1_rpm
w
S1

left

S1_rpm

w

Figure 7. Modelica model of TVD gear train

Figure 7 shows a diagram of Modelica model of the
torque vectoring gear train. The model is provided with
elements that define the relational expression between
the torque and speed of each gear engagement portion.
3D MBS model of suspension, steering and body
were installed to calculate vehicle dynamics
characteristics. Suspension model was constructed as
an assembled model of each suspension linkage, joints
and force elements such as spring, damper and bushing.
Non-linear tire model based on Magic Formula
model (Pacejka02) was used to calculate combined
lateral force and longitudinal force of each tire.
Steering model considered the characteristics of
viscous friction of steering gear box and steering shaft
as well as steering shaft stiffness.

Figure 8. Comparison between full vehicle model and
single track model

At first, the result of the full vehicle model and the
single track model was compared in a case that no
control was applied. Steering input angle was given as
a sinusoidal sweep signal from 0.1 Hz to 5Hz at
constant vehicle speed V=80[km/h]. Figure 8 shows the
results of vehicle slip angle and yaw rate response. It is
shown that some difference exists between the single

DOI
10.3384/ecp1713217

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

23

Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System Using
Modelica

track model and the full vehicle model especially in the
low frequency response. The reason of this result is
assumed that the approximation when used to derive
the equation of the single track model was too big.
Actually the Equation (2) and (3) about the Figure 1
should be
d
(29)
M u tan 1   u   2Y f cos  f  2Yr
dt
(30)
d
Iz
 2l f Y f cos  f  2lr Yr  N
dt
in precise. Also the non-linearity of the tire
characteristics and effects of many losses and stiffness
of mechanical parts are not considered in the single
track model. This result indicates that we should be
careful when designing controllers based on the single
track model.
Next, a simulation emulating double lane change
maneuver was performed. Though, in this case, a
problem that the vehicle motion of the full vehicle
model became unstable when applying the control law
shown in Eq. (28). The reason was that by the default
gain of the feed forward control parts, the controlled
steering angle exceeded the actual physical limit and
turned more than 6[rad], that is, about 360[deg]. So the
compensation for the feed forward parts was applied so
that the controlled front steering angle will not be so
different from the steering input angle. (Actually the
feed forward parts were gained by 0.1.) After this
modification, the vehicle response became stable in the
actual case using the full vehicle model. Also for the
feedback part, we should be careful to select the value
of weight matrix element when designing LQR
controller. Also the weight for the steering angle
control was lowered than that for the DYC torque
because of the physical limit of the steering angle.
These problems may be solved by modifying the
controller design from LQR to MPC (Model Predictive
Control) which can consider the limitation of the
actuators, but there would be a conflict of calculation
time of the controller in such a case.
Figure 9 shows the results of the full vehicle
simulation imitating the double lane change test by
open-loop driver model. Though there seems necessity
of further gain tuning, the modified model matching
control seems to work to let the actual state variables
trace the desired variables.
Also side wind test was simulated using the full
vehicle model. Figure 10 shows the results. There is a
side wind of 20[m/s] while time = 2 sec to 3.5 sec
when the vehicle is running at 120[km/h] with fixed
steering input angle of 0[rad]. The effect of the
proposed control to stabilize both slip angle and yaw
rate response against the side wind was shown.
For comparison, the result of the previous research
in which design of the model matching control was
done without considering the integral of the error
(Hirano, 2016b) is shown in Figure 11. The new
24

control (Figure 10) showed less steady state deviation
and also better regulation of the state variables against
the external disturbance as the side wind, though it is
not perfect yet.

Figure 9. Full veheicle simulation result for double rane
change test

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713217

Session 4A: Automotive I

Figure 11. Side wind test result by previous control

6

Figure 10. Full vehicle simulation result of side wind test

DOI
10.3384/ecp1713217

Conclusion

A new integrated control of DYC and front steering
angle was proposed using model matching control also
considering the integral of the error. By simulations
using both single track model and full vehicle model
based on Modelica, the effect of the control was
investigated. Also the limitation of control design
based on the single track model was clarified by
comparing the results of the simulation by both single
track model and full vehicle model. Some know-how
about controller design was also obtained from the full
vehicle model simulation considering various
limitations of the actual vehicle. Because of the
limitation of the actual actuators and also neglected
modeling errors, the results of the proposed control
was not satisfactory.
On the other hand, Modelica was always powerful
to express any kind of controllers as well as multiphysics full vehicle model. A new technique to expand
Modelica model to write time-variant models was also
introduced.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

25

Development of an Integrated Control of Front Steering and Torque Vectoring Differential Gear System Using
Modelica

References
M. Burgess, Torque vectoring. Lotus Engineering, 2009.
DLR(German Aerospace Center), Power Train Library Users
Guide (Version 2.1.0), 2013
S. Efstathios, E. Velenis, and S. Longo, Model predictive
torque vectoring control for electric vehicles near the limits
of handling. European .Control Conference (ECC) 2015
IEEE, 2015.
Y. Hirano, S. Inoue and J. Ota, Model-based Development of
Future Small EVs using Modelica, Proceedings of
Modelica Conference 2014, 2014.
Y. Hirano, S. Inoue and J. Ota, Model Based Performance
Development of a Future Small Electric Vehicle by
Modelica, Proceedings of Modelica Conference2015, 2015.
Y. Hirano, Research of Model Matching Control of Torque
Vectoring Differential Gear System, Proceedings of
Japanese Modelica Conference2016, 2016a
Y. Hirano, Model Based Development of an Integrated
Control of Front Steering and Torque Vectoring
Differential Gear System, Proceedings of SICE2016,
2016b
B. Hhn et al., Torque Vectoring Driveline for Electric
Vehicle, Proceedings of the FISITA 2012 World
Automotive Congress, Vol. 191, pp. 585-593, 2013.
Modelon, A.B., Vehicle Dynamics library Users Guide
(Version 1.8), 2014

26

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713217

Virtual Occupant Model for Riding Comfort Simulation
Hyung Yun Choi1

Manyong Han1

Akinari Hirao2

Hisayoshi Matsuoka2

1

Hongik University, Korea, hychoi@hongik.ac.kr, myhan@mail.hongik.ac.kr
2
Nissan Motor Co. Ltd, Japan, a-hirao, hisayoshi_m@mail.nissan.co.jp

Abstract
A digital human body model as a virtual occupant
surrogate for the riding comfort simulation is developed
for both 1D lumped network (Modelica) and 3D mesh
based (Finite Element) solutions. Since the composition
of 1D and 3D versions of the human body model has a
similar multibody system architecture, the kinematic
responses from both solutions are almost equivalent.
The models are therefore complementary, since the
economic 1D models can serve effectively in design
exploration and optimization, while their sophisticated
3D counterparts can serve in final design validation. The
detailed modeling process and validation results against
standard seat vibration excitation test are introduced in
this paper, preparing the models for use in seat design.
Keywords: digital human body model, riding comfort
simulation, 1D lumped network Modelica model, 3D
mesh based Finite Element model, vibration excitation

1

Introduction

A virtual human body model (VHBM) is developed for
quantitative and objective assessments of the riding
comfort design of vehicles. The VHBM has biofidelic
dynamic characteristics of human occupants during the
vehicle ride. The anthropometry of the finite element
human body model is based on a previous study [Kim
2007] and represents a standard North American
50th %tile male from the SizeUSA population survey
2000-03.
There have been many CAE studies to virtually
simulate static and dynamic interactions between the
human occupant and the vehicle seat. Montmayeur et al
[Montmayeur 2004] used a human body model to
predict the sitting pressure distribution and head-to-seat
vertical transmissibility. There was a good correlation
against the experiment but the position of the human
body model was limited to upright erect sitting without
a back support. Choi et al [Choi 2008] used a human
body model to evaluate lumbar support design. They
investigated postural changes of sitting occupants such
as seat back pressure distribution and lordotic curvatures
of the lumbar spine with the different configurations of
lumbar support, and the prominence and height of the
support. Yamada et al [Yamada 2016] used the THUMS
model (Total Human Model for Safety, version 5) to
investigate the influence of muscular strength and seat
reaction force on occupant kinematics in single lane

DOI
10.3384/ecp1713227

change maneuvers. It was found that some skeletal
muscles in the THUMS model were needed to activate,
e.g., 350N by abdominal oblique muscles to resist
against 1.0G lateral vehicle motion. Han et al [Han 2016]
presented an efficient way to model muscle forces of
vehicle occupants as they maintain the postural stability
during the ride. The active joint torque controlled by a
proportional integral derivative (PID) closed loop was
introduced at the elbow joint to simulate voluntary and
reflexive response of the human subjects.
The main focus of the VHBM in this paper is showing
its capability of not sophisticated but quite effective
representations of active skeletal muscle forces by
developing PID-controlled active torques at articulated
joints. It is hypothesized that vehicle occupants brace
their limbs and trunk to maintain the initial upright
(comfortable) sitting posture. Accordingly, the VHBM
model autonomously develops the skeletal muscle
forces, i.e. active torques, at articulated joints against the
external perturbations.
The VHBM was built for two kinds of solution, 1D
lumped network (Modelica) and 3D mesh based (Finite
Element) solutions. The 1D lumped network solution is
very effective for the multi physical system with many
controllers. It is also suitable for the calculation of large
numbers of variants. On the other hand, the 3D mesh
based solution with its fine geometry and material
properties can provide detailed interactions with the
neighboring structure, the vehicle seat in our case.
However the 3D solution requires a great deal of
computing power due to its high level of modeling
complexity. The topological composition of the 1D
version of the human body model is the same as that of
the 3D version since they are both based on a multibody
system with PID controllers. The outcomes of two
different solutions, e.g., dynamic response of human
body model to external loadings, are thus almost
identical. Therefore, the use of the 1D model to calibrate
intrinsic and extrinsic parameters of the human body
model, such as joint properties and weighting factors
(gains) in the PID controllers, is quite beneficial. An
optimization process is normally adopted for
determining those modeling parameters, which becomes
an extremely lengthy task when a 3D model is used. In
case with the Genetic Algorithm at the optimization
process, a number of around several hundred model runs
(15 generations X 50 populations) are often necessary
for the convergent result. However the 3D human body
model is also necessary at the practical application stage

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

27

Virtual Occupant Model for Riding Comfort Simulation

because it produces many informative outcomes at the
riding comfort simulation, e.g., dynamic sitting pressure
distribution.

2.1 Multibody Modeling

articulation, the damping coefficients of the passive
kinematic joint element are adjusted for the different
levels of pre-tensions, which is considered as a major
mechanism of voluntary muscle activation. Meanwhile,
the spring constant of the kinematic joint element
represents the inter-subject variation of the muscular
structure, e.g., male versus female, younger versus older.

The whole human body are segmented into 15 body
regions (see Fig. 1), i.e., head, neck, upper/center/lower
trunks, left and right upper/lower arms, left and right
upper/lower legs, and left and right foot. And they are
articulated by 14 joints as listed in Table 1. The dynamic
properties of the 15 body segments modeled as rigid
bodies: mass, center of gravity, and 2nd mass moment
of inertia of each body region, are calculated by GEBOD
program [Cheng 1996]. The averaged values of 32 body
dimensions measured from 10 test subjects of this study
are used as input parameters at the GEBOD calculation.
Kinematic joint elements are used for the articulation of
the 15 body segments of which the main biomechanical
characteristics are defined by stiffness and damping
coefficients. The kinematic joint element describes the
passive characteristics of the human joint, together with,
the active torques. Assuming that a co-contraction of
agonist and antagonist muscles stiffens the joint

Figure 1. Whole body model segmented by 15 rigid
bodies and 14 articulated joints (in 3D FE model view)\

2

Human Body Modeling

Table 1. Fourteen articulated joints with their anatomical positions
#
1
2
3
4
5, 6
7, 8
9, 10
11, 12
13, 14

Articulated joint
Head-neck
Neck-Upper trunk
Upper-Center trunk
Center-Lower trunk
Upper trunk-arm, R, L
Upper-Lower arm, R, L
Lower trunk-leg, R, L
Upper-Lower leg, R, L
Lower leg-foot, R, L

2.2 Wobbling Masses
The internal organs in the ventral body cavity, such as
lungs, heart, stomach, intestines, liver, spleen, kidneys,
and bladder, are classified by their anatomical locations,
either above or below the diaphragm, i.e., in thoracic
and abdominal/pelvic cavities, respectively. The organs
in a same or adjacent cavity are grouped together as a
single lumped mass in the virtual occupant model, Fig.
2. The wobbling behavior of the internal organs at whole
body vibration is thus characterized by two lumped
masses, one for the thoracic cavity and the other one for
the abdominal and pelvic cavities. Each wobbling mass
was estimated respectively as 5kg and 10kg for the
thoracic and abdominal/pelvic masses.
All sides of the two wobbling masses are tied by
elastic spring elements to the inner surfaces of the
28

DOF
3
3
3
3
3
1
3
1
3

Anatomical position
OC joint
sC7/T1
T12/L1
L5/S1
Right, Left shoulders
Right, Left elbows
Right, Left hip joints
Right, Left Knees
Right, Left ankle

thoracic and abdominal cavities. There are also elastic
spring elements between two wobbling masses
connecting the bottom side of thoracic mass and the top
side of abdominal/pelvic mass. The mechanical
characteristics of spring elements such as stiffness and
damping coefficients were assigned to reproduce the
biofidelic dynamic behavior of the two wobbling masses.

Figure 2. Wobbling masses in the trunk (in 1D
SimulationX model view)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713227

Session 4A: Automotive I

2.3 Active Joint Torque with PID Close
Loop Control
Voluntary and reflexive muscle activation of a vehicle
occupant is modeled by active joint elements at each
anatomical joint position (e.g., shoulder, knee, spine,
etc.). There are two basic elements at each joint, i.e., the
passive kinematic joint element and the torque actuator.
Contrastively to voluntary activation of individual
muscles, i.e., the pre-tension and consequent stiffening
of the articulated joint represented by the passive
kinematic joint element, a vestibular reflexive muscle
activation for the posture stabilization is modeled by the
introduction of active torques with PID closed loop

control. As an example, the modeling of the head-neck
joint (C0-C1) is shown in Fig. 3. The active torque, the
control signal, is a sum of proportional, integral, and
derivative terms between the current and the reference
(initial) joint angles. The gain values at the PID control
determine the rates of torque generation. Faster torque
generation with larger gain values stands for the prerecognition of the upcoming external perturbation. Each
term at PID can be adjusted to calibrate the rate of
muscle recruitment for fine control of the reflexive
response of the human occupant. Authors of this paper
showed a successful application of the proposing active
joint modeling with the elbow reacting to the jerk
loading [Choi 2016, Han 2016].

Figure 3. Block diagram of head-neck joint (C0-C1) with active torque using PID close loop control (in 1D model view)

2.4 Finite element model vs. Modelica model
The composition of 1D lumped network (Modelica)
version and 3D mesh based (Finite Element) version of
the whole body model in Fig. 4 has similar multibody
system architecture. The same segmental dynamic
properties, joint characteristics, and PID control gains,
are assigned to both 1D and 3D models. Consequently,
the outcomes such as dynamic responses from both
models to external loadings are almost identical. So,
utilizing the computational efficiency of 1D Modelica
model and solution instead of 3D FE model, the
calibration process of the intrinsic and extrinsic
modeling parameters become much faster.

Figure 4. 1D lumped network (top) and 3D finite element
(bottom) whole body human models.

The one of lacking feature at the 1D lumped network
solution compared to the 3D mesh based solution is the
pragmatic sliding contact algorithm to handle the
nonlinear boundary conditions. In the context of riding
comfort simulation, the main application of the
occupant model, a dynamic interaction between the
occupant and the vehicle seat, is the most relevant case.
In general, a riding comfort design of the vehicle seat is
responsible for the quality of static support at a sitting
posture and the dynamic isolation against floor level

DOI
10.3384/ecp1713227

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

29

Virtual Occupant Model for Riding Comfort Simulation

vibration. The measurement of the sitting body pressure
distribution and its pattern analysis provide the design
assessment of the static support, while the body regional
transmissibility characterizes the dynamic isolation of
the excitation vibration. There are model libraries
available at SimulationX to handle the sliding contact
between objects, such as polygon-polygon contact. The
polygon-polygon contact library computes the penalty
contact force based on the amount of overlapping depth
between two-dimensional cross sectional outline
polygons of objects. This is a suboptimal choice at 1D
solutions but an appropriate selection of cross section
and contact parameters is always required to reproduce
the same outcome from the sliding contact in 3D mesh
based solutions. Fig. 5 shows a polygon-polygon contact
definition between buttock and seat at the 1D model.

Figure 6. Deformable flesh layer in 3D FE model

The comparison of computation times between three
models, two 3D finite element models with and without
flesh layer and 1D Modelica model is listed in Table 2.
Table 2. Simulation time of a loading case (X direction
excitation, 5Hz, 0.2g relaxed condition for 4sec)
1 core CPU*
time (sec)
108,900 sec
3D FE with flesh
(30.3 hours)
13,880 sec
3D FE w/o flesh
(3.9 hours)
1,851 sec
1D Modelica
(0.5 hours)
* CPU processor: I7-4770K 3.5GHz,
Model

3

8 core CPU
time (sec)
14,770 sec
(4.1 hours)
1,980 sec
(0.6 hours)
NA

Validation of Human Body Model
against Vibration Excitation Test

3.1 Excitation Vibration Test

Figure 5. 2D polygon-polygon contact at 1D lumped
network models.

In addition, the 3D FE whole body model has
deformable flesh layers modeled by a visco-elastic
Ogden rubber material of solid element at those body
regions, i.e., dorsal back, buttock and thigh, which are
normally in touch with vehicle seat. (Fig. 6) This
deformable flesh layer can simulate the precise
distribution of dynamic sitting pressure, which is hardly
obtainable from the 1D lumped network solution.

30

A total of ten male subjects with standard North
American 50th %tile anatomies between 35 and 45 years
old were recruited. The same selection process of test
subjects is adopted from the previous study [Kim 2007].
From the statistical factor analysis of the study, six
primary dimensions listed in Table 3 were chosen to
represent the overall body shape and size of the target
population. Based on the SizeUSA survey (2000-03),
the specific ranges (average/4) in Table 3 for
50th %tile male were assigned as the selection criteria of
test subjects. The mean and standard deviation for the
six primary dimensions of 10 test subjects in this study
are also listed in Table 3.
Table 3. Ranges for selection and mean of primary
dimensions for test subjects
Body dimension

Selection
range

Weight (kg)
Height (m)
Hip Height (m)

81.5 - 89.9
1.759 - 1.799
0.870 - 0.925

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

Mean(SD) of
test subjects
85.9 (2.43)
1.780(0.013)
0.898(0.018)

DOI
10.3384/ecp1713227

Session 4A: Automotive I

Back Waist Length(m)
Bust Girth (m)
Hip Girth (m)

0.476 - 0.548
1.052 - 1.170
1.000 - 1.080

0.527(0.013)
1.067(0.015)
1.034(0.026)

Both standing and sitting postures of all subjects are
scanned in three dimensions, and 32 body dimensions of
each subject are digitally measured for the estimation of
dynamic properties of 15 body segments at the GEBOD
calculation [Cheng 97]. Approval to conduct testing in
this study with human subjects was granted by the Pusan
National University Institutional Review Board (IRB,
PNU IRB/2015_30_HR).
All test subjects hold a driving posture as sitting on
the wood seat engraved with the skin shape of HPM-II
machine (SAE J4002) which is designed to minimize the
slip on the seat during the excitation. The three
translational degree of freedom exciter machine (IMV i220) was used for the test. The typical sitting posture on
the exciter and the wood seat are shown in Fig. 7.
The test subjects were exposed to the discrete sinusoidal
vibrations in uncoupled three translational directions.
Three frequencies, 3Hz, 5Hz, and 10Hz, at two
amplitudes, 0.2g and 0.4g (c.f., 0.1g and 0.2g for 3Hz
excitation), were respectively applied to each of the
three directions, fore/aft(X), lateral(Y), and vertical(Z).
The test subjects were exposed to the excitations in two

frequency and amplitude of the target excitation. The
excitation of each vibration case was applied for 20
seconds with a random order. The data of 16 seconds
record were just used in the analysis by excluding the
first and the last transient 2 seconds.
The frequency analysis of measured body regional
acceleration signals was performed by taking Fast
Fourier Transformation (FFT) with 99% overlap and 2second unit time. The 1st peak head acceleration of 6
representative subset cases are listed in Table 4.
Table 4. 1st peak head acceleration of 6 representative
subset cases.
Head acc. (SD), (m/s2)

Excitation cases*
#1

X_5Hz_0.2g_R

#2

Y_5Hz_0.2g_R

#3

Z _Hz_0.2g_R

#4

Z_5Hz_0.4g_R

#5

Z_10Hz_0.2g_R

#6

X_5Hz_0.2g_T

X

Y

0.985

0.270

(24%) (59%)
0.090

0.254

(73%) (63%)
1.338

0.311

Z
2.100
(48%)
0.153
( 81%)
2.625

(24%) (63%) (53%)
2.335

0.582

6.259

(26%) (58%) (37%)
1.041

0.199

1.384

(32%) (51%) (74%)
0.934

0.379

3.761

(44%) (74%) (39%)

*: excitation direction_frequency_amplitude_muscle condition

3.2 Exciting vibration simulation with virtual
human body model
Using the 3D FE version of the virtual human body
model described in Section 2, the vibration response to
excitation was simulated in the following two steps:
Figure 7. Typical sitting posture of test subject (left)
and wood seat engraved with skin shape of HPM-II
machine (SAE J4002) (right)
conscious muscle conditions of being relaxed and tensed.
In the relaxed muscle condition, the test subjects were
requested to strain against the gravity and the excitation
just enough to sustain the initial sitting posture. In the
tensed muscle condition, the test subjects were instead
asked to fully brace their limbs to maximize the
resistance against the excitation. There were a total of
36 cases in this excitation test, 3 excitation directions X
3 frequencies X 2 amplitudes X 2 muscle condition. The
body segmental accelerations were measured in three
directions at the forehead, chest and two thighs,
specifically on the anterior side of the mid femur. The
vibration was monitored by the accelerometer (Kistler
8310B) placed on the seat buck platform for a feedback
control of the input signal by using NI-PXI8187
controller and Labview software to maintain the
DOI
10.3384/ecp1713227

Step #1: Quasi-static sitting phase by gravity
loading;
Step #2: Dynamic excitation phase by discrete
sinusoidal loadings.
The gravity driven sitting phase at step #1 simulates
the equilibrium state of the virtual human whole body
model in a driving posture. The driver at tensed muscle
condition braces articulated joints at upper and lower
limbs [Choi 2005]. This bracing behavior at the tensed
muscle condition is reproduced by increasing the level
of active joint torques. The change of initial sitting
posture at tensed muscle condition from the relaxed,
especially the slightly more extended elbow joint and
tucked-in chin is noticeably shown in Fig. 8. The effect
of bracing in the sitting posture on pressure distribution
is shown in Fig, 9. The contact area to the seat back at
the tensed posture shifts to the upper dorsal back while
the contact area in buttock to seat cushion remains

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

31

Virtual Occupant Model for Riding Comfort Simulation

similar to the relaxed muscle condition. The simulation
time for relaxed and tensed initial postures are
respectively 1,500 milliseconds and 2,000 millisecond.

Figure 8. Comparison of simulated initial sitting posture
between relaxed (left) and tensed (right) muscle
conditions (3D FE model).

and dependent on external loadings, are calibrated as in
the process shown in Fig. 10. The most important steps
in the calibration process are preliminary and decisive
optimizations. Both intrinsic and extrinsic parameters
are design variables in the preliminary optimization but
only extrinsic parameters in the decisive optimization.
At the decisive optimization process, the intrinsic
parameters adopted from case #4, the best matching case
at the preliminary optimization among 6 loading cases,
are used for all cases since they are supposedly
independent on external loadings, the excitation
direction, frequency, and amplitude. As described in
Section 2.2, the mechanical characteristics of tied
springs for wobbling masses belong to the intrinsic
parameters. The discrete damping values in the
kinematic joint element are separately assigned to
relaxed (cases #1-5 in Table 4) and tensed (case#6)
muscle conditions, which represent the level of bracing
(co-contraction). The three gain terms at PID controllers
for the active joint torque in Section 2.3 fall into the list
of extrinsic parameters.

Figure 9. Comparison of simulated sitting pressure
distribution between relaxed (left) and tensed (right)
muscle conditions (3D FE model).

In Step #2, a discrete sinusoidal excitation loading is
applied for additional 4,000 milliseconds to the
equilibrated sitting virtual driver model. The same 3D
FE model used for Step #1 is also utilized to calculate
6dof kinematic outcomes at the COG point of the lower
trunk, i.e., time profiles of 3 translational and 3
rotational displacements. This vibration response at the
lower trunk body segment is further used as an input
signal of the 1D lumped network model (and the 3D FE
model without deformable flesh layer) for the
calibration process of intrinsic and extrinsic modeling
parameters, which is to be described in detail at Section
3.3. Assuming the negligible effect of intrinsic and
extrinsic parameters on the kinematics of the lower
trunk body segment which is right top of the seat
cushion but more to the upper body and the head, the use
of the 1D model for the calibration process is far more
efficient than the equivalent 3D FE model in terms of
the computation time.

3.3 Calibration of modeling parameters
Two kinds of modeling parameters, intrinsic and
extrinsic variables which are, respectively, independent
32

Figure 10. Calibration process for model parameters.

3.4 Optimization process
The results from two optimizations in the calibration
process in Fig. 10 is listed in Tables 5 and 6. The Genetic
Algorithm (GA) at PAM-OPT (www.esi-group.com) is
adopted to optimize design variables, given by the
intrinsic and extrinsic modeling parameters. The
objective function is defined as the following equation;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713227

Session 4A: Automotive I

2

Obj. function = ((   ) ) +
2

((   ) ) +
2

((   ) ) +
0.1  (max(01  )/1.5)2
Where,
 : 1st peak FFT acceleration in i direction from
simulation.
 : 1st peak FFT acceleration in i direction from test
01  : Rotation angle of C0_C1 (head-neck) joint in
t-direction (yawing).
Each iteration (generation) in the GA optimization
has a number of 30 points (populations). As an
exception, case #2 Y_5Hz_0.2g_R has 90 populations,
three times more than other cases just for the decisive
optimization process. The termination criteria is
satisfying one the following two conditions;
#1 Objective function value becomes less than 0.1
#2 No change in objective function values for last 5
iterations
The objective function values in Table 5 for the
preliminary optimization result is smaller than those
from the decisive optimization result in Table 6 for all 6
loading cases. This becomes obvious that only extrinsic
parameters are optimized as design variables while the
uniform intrinsic parameters are assigned as fixed
modeling variables in the decisive process.
It is also noted that relatively high objective function
values associated with the lateral Y direction excitation

DOI
10.3384/ecp1713227

case (#2 in Table 5 and 6) is mainly due to the small
baseline effect, i.e., the measured head acceleration is
quite smaller than the other excitation directions (see
Table 4).

4. Conclusion
A virtual human body model is developed to predict the
riding comfort design of vehicles. The active response
of the human occupant to maintain the upright sitting
posture is virtually reproduced by using active joint
torques with PID closed loop control. Both 1D lumped
network (Modelica) and 3D mesh based (Finite Element)
solutions are adopted to model the multibody system
architecture of human body. The characteristics of
virtual human body model is verified and validated
against the excitation test with human subjects.

5. Future Study
The virtual human body model will be further validated
against the subject test of angular excitations such as
rolling and pitching which was performed with 6dof
exciter [Choi 2017(2, 3)]. Also a riding comfort index
based on ergonomic criteria is under development.
Assuming the occupant is trying to develop active joint
torques to maintain the upright sitting posture against
external perturbations, the total amount of skeletal
muscle energy together with body regional transfer
function could be a quantitative and objective tool for
the assessment of seat, suspension system, and chassis
designs in the dynamic performance of vehicle.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

33

Virtual Occupant Model for Riding Comfort Simulation

Table 5. Result from the preliminary optimization process in Fig. 10
Excitation cases*
Sim
#1 X_5Hz_0.2g_R

0.101

#2 Y_5Hz_0.2g_R

0.006

#3 Z_5Hz_0.2g_R

0.112

#4 Z_5Hz_0.4g_R

0.225

#5 Z_10Hz_0.2g_R 0.119
#6 X_5Hz_0.2g_T

0.115

Preliminary Optimization 1st Peak Head acceleration (g)
X
Y
Z
Test
Test
Test
% err. Sim
% err. Sim
(SD)
(SD)
(SD)
0.100
0.028
0.214
1%
0.026
-6%
0.259
(24%)
(59%)
(48%)
0.009
0.026
0.016
-29% 0.044
68%
0.008
(73%)
(63%)
(81%)
0.136
0.032
0.268
-18% 0.034
7%
0.272
(24%)
(63%)
(53%)
0.238
0.059
0.638
-5%
0.063
6%
0.564
(26%)
(58%)
(37%)
0.106
0.020
0.141
12%
0.013
-36%
0.212
(32%)
(51%)
(74%)
0.095
0.039
0.383
21%
0.040
3%
0.233
(44%)
(74%)
(39%)

Obj.
Iter. Iter.
func.
No. Term.
% err. Value
21%

0.099 12

#1

-51%

0.896 15

#2

2%

0.059 7

#1

-12%

0.040 11

#1

51%

0.414 25

#2

-39%

0.201 20

#2

*: excitation direction_frequency_amplitude_muscle condition

Table 6. Result from the decisive optimization process in Fig. 10
Excitation cases*
Sim
#1 X_5Hz_0.2g_R

0.199

#2 Y_5Hz_0.2g_R

0.025

#3 Z_5Hz_0.2g_R

0.104

#4 Z_5Hz_0.4g_R

0.225

#5 Z_10Hz_0.2g_R 0.153
#6 X_5Hz_0.2g_T

0.104

Decisive Optimization 1st Peak Head acceleration (g)
X
Y
Z
Test
Test
Test
% err. Sim
% err. Sim
(SD)
(SD)
(SD)
0.100
0.028
0.214
99%
0.033
17%
0.049
(24%)
(59%)
(48%)
0.009
0.026
0.016
177% 0.118
354% 0.037
(73%)
(63%)
(81%)
0.136
0.032
0.268
-24% 0.034
6%
0.258
(24%)
(63%)
(53%)
0.238
0.059
0.638
-5%
0.063
6%
0.564
(26%)
(58%)
(37%)
0.106
0.020
0.141
44%
0.025
25%
0.345
(32%)
(51%)
(74%)
0.095
0.039
0.383
9%
0.039
-1%
0.237
(44%)
(74%)
(39%)

Obj.
Iter. Iter.
func.
No. stop
% err. Value
-77%

1.610 15

#2

130%

17.58 29

#2

-4%

0.126 12

#2

-12%

0.040 7

#1

144%

2.349 18

#2

-38%

0.167 14

#2

*: excitation direction_frequency_amplitude_muscle condition

References
H. Cheng, L. Obergefell and A. Rizer, The development of the
GEBOD program, Biomedical Engineering Conference,
Proceedings of the 1996 Fifteenth Southern, 1996.
H. Y. Choi, S.J. Sah, B. Lee, H.S. Cho, S.J. Kang, M.S. Mun,
I. Lee, J, Lee, Experimental and numerical studies of muscular
activations of bracing occupant. Proc. of Enhanced Safety of
Vehicle, Washington D.C. USA, 2005
H.Y. Choi, K. Kim, C. Kim, S. Sah, S. Kim, S. Hwang, K. Lee,
J. Pyun, N. Montmayeur, I. Lee, Challenge of Lumbar
Support Design Using Human Body Models. SAE Int. J.
Passeng. Cars - Mech. Syst. 1(1), 1078-1084, 2009
H.Y. Choi, M. Han, W. Lee, Active Elbow Joint Model. The
First Japanese Modelica Conference, 2016
H.Y. Choi, M. Han, J. Park, K. Yang, Air ride seat for Heavy
Duty Vehicle. 12th International Modelica Conference,
submitted, 2017
H.Y. Choi, M. Han, A. Hirao, H. Matsuoka, Occupant
kinematics at vibration excitations: Part I Pure rolling and
pitching vibrations. In preparation, 2017

34

H.Y. Choi, M. Han, A. Hirao, H. Matsuoka, Occupant
kinematics at vibration excitations: Part II Real road
vibrations. In preparation, 2017
M. Han, H.Y. Choi, Elbow joint model with active muscle
force, Journal of Mechanical Science and Technology 30/12
5847~5853, 2016
S. Kim, S. Hwang, K. Lee, J. Pyun, H.Y. Choi, K. Kim, S. Sah,
N. Montmayeur, New Anthropometry of Human Body
Models for Riding Comfort Simulation. SAE Technical
Paper 2007-01-2457, 2007
N. Montmayeur, C. Marca, E. Haug, H.Y. Choi, S. Sah,
Experimental and Numerical Analyses of Seating Pressure
Distribution Patterns. SAE Technical Paper 2005-01-2703,
2005
K. Yamada, H. Motojima, Y. Kitagawa, T. Yasuki,
Investigation of relations between occupant kinematics and
supporting by the seat in lane change maneuvers. (In
Japanese) Proceedings of JSAE spring conference, No.3816, pp.941-946, 2016

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713227

A Simulation-Based Digital Twin for Model-Driven Health
Monitoring and Predictive Maintenance of an Automotive Braking
System
Ryan Magargle1 Lee Johnson1 Padmesh Mandloi1 Peyman Davoudabadi1 Omkar Kesarkar1
Sivasubramani Krishnaswamy1 John Batteh2
Anand Pitchaikani2
1

ANSYS Inc., USA, {ryan.magargle,lee.johnson,padmesh.mandloi, mohammad.davoudabadi,
omkar.kesarkar, sivasubramani.krishnaswamy}@ansys.com
2
Modelon Inc., USA, {john.batteh,anand.pitchaikani}@modelon.com

Abstract
This paper describes a model-driven approach to
support heat monitoring and predictive maintenance of
an automotive braking system. This approach includes
the creation of a simulation-based digital twin, or
numerical model, that combines different modeling
formalisms into an integrated model of the braking
system that can be used for monitoring, diagnostics,
and prognostics. The paper provides an overview of
the basic models including Modelica models, reduced
order models for various key components of the system
model, and controls and sensor models. The Modelica
models are implemented in the ANSYS Simplorer
simulation to leverage existing modeling work and
connections with other ANSYS finite element software
to utilize reduced order models. The simulation results
include both baseline results for the system and the
results of injecting failures into the system for
monitoring and predictive maintenance.
Keywords:
digital twin; electronics;
electromagnetics; hydraulics; pneumatics; braking
system; automotive; FEA;

1

Introduction

Beyond the challenges of developing complex
products, companies are increasingly seeking to
monitor and manage the performance of those products
in operation to improve safety, performance, and
customer satisfaction (GE, 2016; Siemens, 2016).
Model-based approaches and physics simulation are
powerful components of creating a digital twin of a
physical asset in operation-- a simulated replica of the
asset that is used to diagnose anomalies in the
performance of the asset and for predicting the state of
health and remaining useful life of that asset. These
insights can subsequently be used with machine
learning algorithms to optimize operational downtime,
trigger pre-emptive maintenance, and mitigate costly
failures (Prytz, 2014). The work shows multi-domain
system simulation modeling that can be used with a
DOI
10.3384/ecp1713235

variety of machine learning analytics engines, such as
PTC Thingworx (PTC, 2016), which are not discussed
in detail here.
The automotive industry produces millions of
vehicles operating in diverse conditions and require
periodic maintenance to replace worn components and
address faulty conditions. Current vehicle health
management practices rely heavily on data science,
which has become quite powerful (Holland, 2010);
however, the role of engineering and physics in these
practices is limited and are included only in the form of
simplified relations, material data, etc. This approach
therefore has limited the applicability of health
management systems to diagnostics and managed
maintenance for a few automotive components and
systems. The need for higher value capabilities like
prognostics for critical components and systems, e.g.
engine, exhaust aftertreatment, and safety, are driving
the evolution of vehicle health management.
Digital twins offer automotive manufacturers an
enhanced ability to diagnose anomalous conditions and
predict remaining useful life of degradable
components, thereby improving owner safety and
satisfaction.
An approach of combining physics-based modeling
techniques (0-D, 1-D, 3-D) at the system level is
applied to create a digital twin for predicting brake pad
wear in a conventional passenger vehicle. Versus
relying solely on physical measurements, a simulationbased approach produces a high-fidelity model that can
be used to predict brake pad wear, given a set of
operating conditions.
Further, the physics-based
models are subjected to failure modes that can produce
abnormal brake pad wear and unsafe conditions, and
simulated to observe the sensor signatures that will
subsequently aid in improving the diagnosis and
mitigation of unsafe or undesirable conditions in the
vehicle.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

35

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System

2

Modeling Overview

This section of the paper provides an overview of the
integrated braking system model and the individual
model components.

2.1 Integrated Model
The integrated braking system model in Simplorer
(ANSYS, 2016) with all subcomponents is shown in
Figure 1. Simplorer offers a system modeling and
integration platform that supports multiple modeling
formalisms, including Modelica based on the
OPTIMICA Compiler (Modelon AB, 2016) from
Modelon, system models using other formalisms like
VHDL-AMS, reduced order models, and controls. The
power converter is on the left, followed by the
electromagnetic solenoid actuator, pneumatic and
hydraulic braking system, and vehicle dynamics
(including the speed sensor), and brake wear model.
The controller is on the top, providing feedback from
the measured speed and slip output to the command
signal input to the power converter.

mm, of the pad surface vs pad normal pressure and
wheel speed.
The following sections will describe all of the major
sub-component models and reduced order modeling
implementation from each of the finite element
numerical models.

2.3 Model Components
This section of the paper details the physical, control
system, and sensor components that comprise the
braking system model.
2.3.1 Electronics

To drive the electromagnetic solenoid actuator, a
DC/DC buck converter, Figure 2, is used to drop the
12V DC supply to a level that will allow a current to
flow as determined by the controller.
AM1.I<=I_set - D

AM1.I>=I_set + D
SW_ON

SET: S1:=1

Current Controller
PWM Control
SW_OFF

I_d

SET: S1:=0

VA

L1
AM1
VP

Buck Converter
IGBT1
A

D1

L=1uH

L2
VN
VB

L=1uH

Figure 2. Electrical circuit representation of buck
converter with setpoint hysteresis controller statediagram.
Figure 1. The full system schematic including electrical,
pneumatic, hydraulic, mechanical and control logic
components.

2.2 Reduced Order Modeling (ROM)
Several reduced order models generated from detailed
3-D simulations are used in this system simulation to
capture component effects that might be difficult to
describe with closed form solutions.
The
electromagnetics models of the ABS valve solenoid
actuator, the magnetic wheel speed sensor, and the
mechanical brake wear are all based on finite element
numerical models to capture the relevant nonlinear
physics.
The basis of all three reduced order models is a
lookup table based on the numerical model outputs
versus specified input variables. The electromagnetic
solenoid actuator uses the lookup table to capture the
dependence of the magnetic flux linkage vs current and
magnetic force versus displacement (Woodson, 1968).
The magnetic wheel speed sensor has a lookup table
that represents the angular displacement of the
magnetic fields on the sensor surface, in degrees,
versus the position of the wheel sensor. The brake pad
wear model lookup table represents the wear rate, in

36

The buck converter has a hysteresis current
controller built-in using the state transition elements
that control the MOSFET switch.
The current
controller opens the switch when the current exceeds
the set point of the ABS controller by a user-defined
threshold, 0.2A in this case, and closes the switch
when the current falls below the set point.
In the system schematic, the converter is placed in a
sub-circuit, as shown in Figure 3. The graph in Figure
3 shows the output of the buck converter alone driving
an inductive 5-ohm load with a 1A set point and 0.2A
threshold without any filtering capacitance.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Session 4A: Automotive I

Current Setpoint
CONST

I_set
VP

VA
VM1

DC

0.1mH

E1

DC

EMF=12

+
V

5ohm
Chopper
VN

12V Battery

Buck_1A23XD9

VB

Buck Converter

Figure 4. 2-D model of electromagnetic solenoid actuator

Figure 3. Power converter subcircuit output current
results for 5 ohm, 0.1 mH load.
2.3.2 Electromagnetics

The DC/DC power converter is used to drive the
electromagnetic solenoid actuator that the ABS
controller uses to bypass brake actuator and vary
braking pressure. To calculate the force generated by
the current flowing through the solenoid coil, including
any nonlinear effects from the steel and airgap
displacement, not amenable to closed form solution, a
2-D axi-symmetric magnetostatic model is created in
Maxwell2D (ANSYS, 2016), as shown in Figure 4.
Maxwell2D uses the finite element method to calculate
the magnetic field (Chari, 1977), as seen in Figure 5,
and uses the virtual work method (Fu, 2004) to
calculate the force on the moving armature. The
winding is shown as a solid object, but it represents
400 turns of copper wire in this model.

DOI
10.3384/ecp1713235

Figure 5. Magnetic flux density and field lines within the
solenoid for a DC current excitation of 1.8 Amps through
400 turns.

The airgap and current are parametrically varied
and the force and inductance are calculated to create a
table of results, as seen in Figure 6.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

37

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System
2.3.3 Brake pad

A detailed 3-D model consisting of brake rotor, hub,
and pads was constructed to predict brake pad wear as
a function of rotor velocity and pressure applied to the
brake pads, shown in Figure 9 as a meshed geometry
simulated using nonlinear structural finite element
analysis (FEA) within ANSYS Mechanical (ANSYS,
2016).

Figure 6. Force vs airgap curves for different current
excitations.

The result of the parametric sweep creates a
multidimensional lookup table of current, flux linkage,
displacement, and force.
Maxwell automatically
creates a circuit element that uses dependent sources
and a lookup table to relate the electrical input energy
and mechanical output energy, where losses can be
lumped and made external to the component, as in
Figure 7 (Woodson, 1968).
ia

ia
+


A

D

pos

a ECE Look-up
Table
Input: ia, pos
Output: a, F

pos
F

F

S

Figure 7. Equivalent circuit of electrical solenoid actuator
using the lookup table results from the finite element
simulation.

Together with the rest of the system circuit, the
electrical actuator is implemented with an icon,
containing all of the complexity of Figure 7. The
circuit model is connected with mechanical elements,
such as the restoration spring and mechanical damping,
as seen in Figure 8.
S_valve
S_TRB1

Magnetic Valve (ECE)

F_valve

+

VA

Current1_N1

S
F

F_mag1
ArmForce_N1
LIMIT_TRB1
SPRING_TRB1

F_TRB1

F
VB

S
Current1_N2

S_Airgap

+

ArmForce_N2

0

0

Figure 9. Meshed 3-D geometry of the rotor discs, rotor
vents, hub, and pad assembly.

Brake pad wear is calculated as part of the FEA
solution using the Archard Wear Model (Archard,
1980), shown in generalized form in Figure 10.

Figure 10. Generalized Archard Wear Model used by
ANSYS Mechanical.

During the FEA simulation, constant pressure is
applied on the outer faces of the two brake pads to
interact with the rotor, spinning at a constant velocity.
Boundary conditions constrain brake pad movement in
the direction normal to the rotor, whereas in more
detailed studies the motion would be determined by the
brake calipers and guide pins. The simulation produces
a wear rate of the brake pads as a function of the
applied pressure and rotor velocity, shown in Figure
11.

0

Figure 8. System model implementation of actuator with
mechanical elements such as spring and mechanical
damping loss connected externally.

38

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Session 4A: Automotive I

a) Assembled braking system
Figure 11. Wear rate on the brake pad for a constant
applied pressure and rotor velocity.

Using distributed computing, the FEA simulation
was performed for a number of combinations of
pressure applied on the brake pads and rotor velocity to
produce a response surface of wear rate at a selected
location on the surface of the brake pad, illustrated in
Figure 12. This response surface model was then
encapsulated as a Functional Mock-up Unit (FMU) and
connected to the speed and force inputs produced by
the vehicle dynamics and ABS subsystems in the
Simplorer system model. The output of this model can
be integrated, using a standard integration block to
measure accumulated wear.

b) Pneumatic brake booster

c) Hydraulic brake actuation

Figure 12. Response surface model of brake pad wear
versus brake pressure and rotor velocity.
2.3.4 Braking System

Leveraging the latest capability in Simplorer for
modeling with Modelica, the braking system is
modeled natively in Modelica as a pneumatic and
hydraulic system using the Pneumatics Library and
Hydraulics Library (Modelon AB, 2016). The model
shown in Figure 13 consists of a pneumatic system for
the brake booster (a) and the hydraulic system (b) for
the brake actuation.

d) Modelica implementation in Simplorer
Figure 13. Pneumatic and hydraulic braking system
model

DOI
10.3384/ecp1713235

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

39

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System

Based on the brake pedal input from the driver, the
models calculate the resulting caliper pressure that is
provided to the vehicle model for use in calculation of
the brake torque. The ABS valve that modulates the
brake pressure based on the electromagnetic force
actuation is shown in Figure 13b.
2.3.5 Vehicle Dynamics

The vehicle is modeled in Modelica with basic
longitudinal dynamics considering a lumped vehicle
mass and a simple single wheel approach. The
Modelica model in Simplorer is shown in Figure 14.
The tire dynamics include the effects of slip via the
Pacejka magic tire formula (Pacejka, 1993). The
vehicle model takes the drive torque and the brake
caliper pressure and calculates the resulting vehicle
response and wheel conditions, including wheel speed
and slip. The wheel speed is passed to the model of the
wheel speed sensor for slip estimation, and the vehicle
speed is provided to the controller.

Figure 15. ABS control as a state diagram which
modulates the activation of the ABS valves.

During a braking event, the control algorithm uses
the measured vehicle speed and calculation of wheel to
determine which braking mode to activate. If vehicle
speed is below a low-speed threshold or if the
calculated wheel slip is less than a minimum value, an
unmodulated braking command is sent to the ABS
actuator. If vehicle speed is above the low-speed
threshold, the controller sends a modulated command
signal to the ABS actuator when wheel slip exceeds the
established threshold.
Using SCADE code generation, the model-based
representation of the controller was transformed into C
code and compiled into an FMU, shown in Figure 16.
The FMU was directly integrated into the braking
system model within ANSYS Simplorer. Simulated
braking tests were applied to the system model to
validate the operation of the control algorithm under
various conditions. Figure 17 shows the modulation of
the ABS during the application of full braking on dry
pavement at a speed of 20 m/s.
controller

Figure 14. Vehicle dynamics model implemented in
Modelica in Simplorer

vehicleVelocity

Iref
vehicle_velocity

ctrl_sig

abs_on_vel
abs_on_vel

slip
ctrl_gain
braking

While the vehicle dynamics considered are fairly
simple, the native Modelica capability in Simplorer
allows for more complex models to be included to
capture higher frequency dynamics. For example,
models from the Vehicle Dynamics Library (Modelon
AB, 2016) can be integrated to capture higher fidelity
chassis dynamics and also more detailed tire dynamics
and tire/ground interactions.
2.3.6 Controls

Shown in Figure 15, control of the ABS valve is
implemented as a state machine in ANSYS SCADE
Suite, a model-based environment for developing
embedded software, often for applications where safety
is critical (ANSYS, 2016).

40

slip

slip_ON
slip_OFF

gain

activate

slip_on_val

slip_off_val

Figure 16. Generated C code for the ABS controller,
encapsulated as a Functional Mock-up Unit.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Session 4A: Automotive I

Figure 17. Simulated results of maximum braking
applied on dry pavement at 20 m/s.
2.3.7 Speed sensor

The sensor for measuring the wheel speed is an
anisotropic magnetoresistive sensor (Lenz, 1990). As
the teeth on a magnetic tone ring pass by the sensor,
the changes in the direction of the magnetic field
relative to the current flow in the sensor cause changes
in the resistance of the modules, as seen in Figure 18
and Figure 19.

Figure 19. Magnetic flux bending as the tone ring teeth
move past the stationary sensor, measuring flux direction
as points, P1 and P2.

Figure 18. Magnetoresistive material, showing a varying
resistance as an external magnetic field angle of incidence
changes vs the direction of current flowing through the
material.

The two sets of resistive sensor modules are at each
point, P1 and P2, as shown in Figure 19. The resistive
Wheatstone bridge shown in Figure 20 has equal
resistors in opposing positions within the bridge.

The variation in resistance follows a squared
sinusoidal dependence on angle from -90deg to 90deg
shown in Figure 18, according to the relation
(McGuire, 1975):

R (t ) = Ro + R cos 2  (t )

(1)

Taking advantage of this variation, the modules are
arranged in Wheatstone bridge configuration so
measurable voltage changes result on their output. The
change in direction of the magnetic field due to the
variable reluctance of the teeth as they pass is
calculated by the Maxwell3D finite element program
(ANSYS, 2016), as seen in Figure 19 using a 2-D view
to visualize the magnetic flux lines. The flux lines can
be seen originating from a permanent magnet and then
linking with the nearest tooth creating an angle relative
to the face of the magnet and sensor.

DOI
10.3384/ecp1713235

Figure 20. Magnetoresistor bridge with matching
resistors placed in opposite positions.

With this arrangement, the output voltage, Vout, can
be seen to change with a change in direction leading to
incremental changes in resistance, dR, as the following:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

41

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System

 R4
R3 
 (2)
Vout = Vout +  Vout  = Vin 

R
R
R
R
+
+
4
1
3 
 2
R1 = R4 = Ro + dR(t )
(3)

R2 = R3 = Ro  dR(t )

The values of  are then passed to an equation
block where the resistance in (1) is calculated for R1,
R2, R3, and R4, as shown in Figure 22.

(4)

where from (1),

dR(t ) = R cos 2  (t ) ,

(5)

 dR(t )   Vin
 = 
Vout = Vin 
 Ro   Ro


dR (t ) = I o R cos 2  (t ) (6)


So it can be seen that the output voltage would be
equal to the current, Io, through the nominal resistance,
Ro, times the change in the resistance. R is the
maximum possible change in resistance, Ro is the
nominal resistance, and (t) is the field angle relative
to the current flow. If there is no change in resistance,
the output voltage is zero, as expected from a balanced
bridge configuration.
To model the resistor bridge in a circuit simulation
using Simplorer (ANSYS, 2016), the equation for the
resistance in Figure 18 and (1) is used. Ro is given as
1200 ohm and R is given as 0.02 ohm.  is measured
for all positions of the sensor in the FEA simulation at
both P1 and P2, which are used for R1, R4 and R2, R3
respectively. The average magnetic fields in the
volumes of P1 and P2 are used according to the
following equation for :

 H y dV 


 = tan 1 
 H dV 
 x 

(7)

Figure 22. Circuit model equations for the value of the
magnetoresistors as the field angles change.

These computed values of resistance are then linked
to a resistor bridge, with the value of each resistance
being fed from each corresponding output of the
equation block, Figure 23 and Figure 24.

Figure 23. Circuit magnetoresistor bridge model,
graphically using resistance values calculated from the
equation block in Figure 22 with wire connections.

Therefore, for any given velocity of the tone ring,
the position can be instantaneously measured and
evaluated against a precomputed table of values of ,
for P1 and P2, for different tone ring positions. This
method excludes any dynamic eddy currents.
In the circuit, this table is represented by a lookup
table model with the angle position as an input and the
corresponding value of  at P1 and P2, Figure 21.

Figure 24. Resistor model properties obtaining resistance
from the equation block.
Figure 21. Circuit model of finite element based lookup
table, with tone ring position as an input and magnetic
field angle measured at P1 and P2.

42

The output of this resistor bridge generates a
voltage on the order of 30V for a wheel rotation of
600rpm, so this measurement voltage is passed onto a

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Session 4A: Automotive I

comparator amplifier which, using a 5V, ground
referenced input, generates a 10V bipolar waveform,
Figure 25.

Figure 27. Circuit representation of speed sensor with
resistor bridge, amplifier, and encoder.

Figure 25. Comparator amplifier electrical circuit and the
output before and after amplification.

As indicated in Figure 27, the vehicle model
rotation wheel speed is taken as an input, integrated to
create an angle for the tone ring which is passed to the
magnetoresistor bridge. The resistor bridge signal is
sent into the amplifier, which is connected to the
encoder, which outputs the estimated wheel speed.
Any faults in the tone ring or other subcircuits will
create estimated wheel speed errors compared to the
actual wheel speed.
The nominal operation of the speed sensor is shown
in Figure 28 using a 600rpm sinusoidal varying input
speed. The waveform varies between 20 rpm and 600
rpm, some stepping can be seen in the encoder output
at low input speeds since the encoder counter also
slows.

This waveform is then used in an encoder that
counts the zero crossings to estimate the speed of
rotation, using state transition blocks, as seen in Figure
26.
(Vin == 0.0)

SET: Speed:=7.5 / (Time - Tprev)
SET: WavePeriod:=Time-Tprev
(Vin == 0.0)
SET: Tprev:=Time

SET: Speed:=0

(time-Tprev0) > 0.05

(Vin == 0.0)

SET: Speed:=0

(time-Tprev) > 0.05

SET: Tprev0:=time

(Vin == 0.0)

Figure 26. Circuit state-diagram containing the zerocrossing logic to count the duration of teeth passing the
sensor to derive the wheel rotation speed.

The state diagram has a transition to catch the signal
zero crossing from positive to negative and a state
transition to catch the zero cross from negative to
positive. The time between them is the transit time of
the tooth, which is used to calculate the instantaneous
rotation speed, since the angular spacing of the teeth is
fixed at 15 deg. If the speed slows down to near zero,
the encoder also slows down in its response, so it has
several timeout loops that estimate the speed as zero if
the time between zero crossings exceeds a user defined
threshold, 50ms in this case.
All of these sensor components are placed into subcircuits, Figure 27.

DOI
10.3384/ecp1713235

Figure 28. Encoder response (bottom) compared to input
600rpm sinusoidal speed input (top).

3

Simulation Results

With all of the component models represented in the
system, several results can be obtained.
The
simulation results of the system are very useful for
analyzing failure data, since in many real measured
datasets this type of data can be difficult to obtain,
especially for corner cases. This failure data is very
useful for training analytics to enable predictive
maintenance and enhanced failure analysis. Simulation
results in this example will be obtained with the
integrated model in Figure 1 for normal ABS operation
and abnormal ABS operation break wear, and sensor
waveform signature for normal and abnormal sensor
operation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

43

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System

3.1 Baseline System Performance
The baseline performance is shown in Figure 29 for a 3
second braking event from 20 m/s to a complete stop
including normal ABS activation.

The brake wear that results in the absence of the
ABS activation can be seen in Figure 32.

Figure 32. Brake wear for abnormal stopping condition
without ABS activation.
Figure 29. Normal vehicle telemetry results for a full
stop from 20 m/s using normal ABS activation.

The amount of brake wear that results, measured in
mm, is shown in Figure 30.

It can be seen that with ABS activation there is a
cumulative brake wear for this single braking event of
6.25x10-10 mm. Without ABS, the brake wear is
1.38x10-10 mm. There is less wear in the absence of
ABS since the wheel spends more time locked to the
brake pads, which also causes the vehicle to spend
more time coming to a complete stop. The cumulative
wear numbers are very low, since only a single braking
event is being investigated.

3.3 Fault Injection: Broken Sensor

Figure 30. Brake wear for normal stopping condition
with ABS activation.

3.2 Fault Injection: Disconnected ABS
Controller

In the second scenario, the speed sensor tone ring is
modeled with missing teeth (Obrochta, 2015), as seen
in Figure 33, and causes the sensor to misread the
wheel speed.
For this simulation, the first second of braking
behavior is investigated for a sensor signature and the
effect on ABS behavior. Figure 34a shows the normal
sensor behavior. Figure 34b shows the effect of
missing one tooth, and Figure 34c shows the effect of
missing two non-adjacent teeth.

In the first fault scenario, the controller fails and is
disconnected from the circuit. In this case, the ABS
activation does not occur. The vehicle telemetry
results in this scenario can be seen in Figure 31 for the
same braking scenario from 20 m/s to a complete stop.

Figure 33. Tone ring mechanical failure with missing
teeth.

Figure 31. Vehicle telemetry results for a full stop from
20 m/s with abnormal ABS failure.

44

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Session 4A: Automotive I

4

a) Vehicle telemetry results for the first second
with no missing teeth.

b) Vehicle telemetry results for the first second
with one missing tooth

c) Vehicle telemetry results for the first second
with two non-adjacent missing teeth on the
tone ring.
Figure 34. Vehicle telemetry results showing the effect of
missing teeth

As teeth go missing from the tone ring, the wheel
speed and slip measurements show intermittent dips.
The dips represent a perceived reduction in speed since
the time between zero crossings increases in the gap,
resulting in an interpreted slowdown in speed. This
perceived reduction in wheel rotation results in
inadvertent ABS activation since it is interpreted as
wheel slip since the vehicle speed does not change with
it. The simulation can be run for any combination of
missing teeth to create signatures leading to more
accurate diagnosis of the ABS sensor and specific tone
ring failure.

DOI
10.3384/ecp1713235

Summary and Future Work

A model-driven simulation approach combining 0-D
and 3-D physics-based models with controls to support
heat monitoring and predictive maintenance for
automotive braking stems was shown.
These
simulation-based digital twins are useful for providing
inputs into analytics systems that support predictive
maintenance for critical sub-systems, especially under
abnormal operating conditions. As an example, the
difference in wear rate was identified for normal
conditions and abnormal conditions where the ABS
controller becomes disconnected, to predict when
maintenance is required on the braking system.
Simulation-based digital twin models are also
useful for obtaining sensor signatures of the fault
conditions needed to train machine learning algorithms
that support advanced system diagnostics. These
models are particularly useful for observing
abnormalities and failures which cannot be observed
easily in physical tests or in sufficient quantities to
reliably train learning algorithms. In this paper, the
unique ABS activation and speed-slip signals were
recorded using simulation for several cases of
mechanical failure of the teeth on the wheel sensor.
In order to realize these simulation-based digital
twins, several methods of system, circuit, and reduced
order modeling were shown using 3-D finite element
analysis and 0-D multi-domain circuit simulation.
Future work will include more detailed physical
models to support more vehicle operating scenarios
and adding fault tree analysis with rigorous and
automated scenario analysis for detailed root-cause and
diagnostics analysis of brake wear. Further work can
also be done to connect the simulation-based digital
twin with real-time data from the vehicle and adding
HMI (Human-Machine Interface) components to depict
vehicle health management parameters (diagnostics,
prognostics) to the driver.

Acknowledgements
The authors gratefully acknowledge Leon Voss and
Michael Sielemann for their work on the original
braking system simulation model.

References
ANSYS, Inc, Canonsburg, PA.
(2016). Maxwell2D.
http://www.ansys.com.
ANSYS, Inc, Canonsburg, PA.
(2016). Maxwell3D.
http://www.ansys.com.
ANSYS, Inc, Canonsburg, PA.
(2016). Mechanical.
http://www.ansys.com
ANSYS, Inc, Canonsburg, PA. (2016). SCADE Suite.
http://www.ansys.com.
ANSYS, Inc, Canonsburg, PA.
(2016). Simplorer.
http://www.ansys.com.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

45

A Simulation-Based Digital Twin for Model-Driven Health Monitoring and Predictive Maintenance of an
Automotive Braking System
GE, Boston, MA. (2016). How a Digital Twin for
physical assets can help achieve no unplanned downtime
[Online]. Available: http://www.geglobalresearch.com/
impact/how-a-digital-twin-for-physical-assets-can-helpachieve-no-unplanned-downtime
J.F. Archard. Wear theory and mechanisms. Wear control
handbook. Peterson MB, Winer WO, editors. New York
ASME, 1980.
Donald C. Augustin, Mark S. Fineberg, Bruce B. Johnson,
Robert N. Linebarger, F. John Sansom, and Jon C. Strauss.
The SCi Continuous System Simulation Language
(CSSL). Simulation, No 9, pp. 281303, 1967.
M. V. K. Chari, Z. J. Csendes. Finite Element Analysis of
the Skin Effect in Current Carrying Conductors. IEEE
Transactions on Magnetics, 13(5): 1125-1127, September
1977.
Iain S. Duff and John K. Reid. An Implementation of
Tarjans Algorithm for the Block Triangularization of a
Matrix. ACM Transactions on Mathematical Software,
4(2):137147, 1978. doi:
W.N Fu, P. Zhou, D. Lin, S. Stanton, Z.J. Cendes. Magnetic
force computation in permanent magnets using a local
energy coordinate derivative method. IEEE Trans. on
Magnetics,
40(2):
683-686,
2004.
doi:
10.1109/TMAG.2004.824774
S. Holland. Integrated Vehicle Health Management in the
Automotive Industry. Health Management, Krzysztof
Smigorski (Ed.). InTech, 2010. doi:10.5772/9889.J.E.
Lenz. A review of magnetic sensors. Proc. of the IEEE,
78(6): 973-989, 1990. doi: 10.1109/5.56910
T. R. McGuire. Anisotropic magnetoresistance in
ferromagnetic 3d alloys. IEEE Trans. Magn., 11(4), 1018
1038, 1975.
Modelon AB, Lund, Sweden. (2016). OPTIMICA Compiler
Toolkit.
http://www.modelon.com/products/optimicacompiler-toolkit/
Modelon AB, Lund, Sweden. (2016). Hydraulics Library.
http://www.modelon.com/products/modelicalibraries/hydraulics-library/
Modelon AB, Lund, Sweden. (2016). Pneumatics Library.
http://www.modelon.com/products/modelicalibraries/pneumatics-library/
Modelon AB, Lund, Sweden. (2016). Vehicle Dynamics
Library.
http://www.modelon.com/products/modelicalibraries/vehicle-dynamics-library/
Eric Obrochta. (2015, Dec. 5). Saturn S series - unwanted
ABS activation at all speeds. [YouTube video]. Available:
https://www.youtube.com/watch?v=oGwyrLxtaNY&t=36
8s. Accessed Dec. 15, 2016.
Pacejka, H.B., and Bakker, E. (1993): The Magic Formula
tyre model. Proceedings of 1st Colloquium on Tyre
Models for Vehicle Analysis, Delft 1991, ed. H.B.
Pacejka, Suppl. Vehicle System Dynamics, 21, 1993.
PTC, Needham, MA. (2016). Thingworx Analytics.
http://www.ptc.com/internet-of-things/analytics.
R. Prytz. Machine Learning Methods for Vehicle Predictive
Maintenance using Off-Board and On-Board Data.
Halmstad University Dissertations, No. 9, 2014.Siemens,
Munich, GmBH (2016). The Digital Twin [Online].

46

Available:
https://www.siemens.com/customermagazine/en/home/
industry/digitalization-in-machinebuilding/the-digital-twin.html
H. H. Woodson and J. R. Melcher. Electromechanical
Dynamics: Part I: Discrete Systems. New York, NY:
John Wiley & Sons, 1968.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713235

Improved Aerodynamic Prediction Through Coupled System and
CFD Models
Ed Tate1

Joaquin Gargoloff 1

Hubertus Tummescheit2

Brad Duncan 1

John Griffin2

John Batteh 2

Exa, USA, {edtate, joaquin, brad}@exa.com
Modelon, USA, {hubertus.tummescheit, john.griffin, john.batteh}@modelon.com
1

2

Abstract
Accurate predictions of aerodynamic forces using
computational fluid dynamics require accurate
geometry. The aerodynamic forces on the vehicle body
affect the vehicle posture or the vehicle position with
respect to the ground. When a vehicle is cruising on the
road, the change in vehicle posture is usually relatively
small with respect to the size of a vehicle. However,
these small changes in geometry can lead to significant
differences in aerodynamic drag and airflow structures.
To address this issue, a coupled simulation approach
was developed to predict vehicle posture in typical
cruise and wind tunnel test conditions. This coupled
approach was tested using Exas PowerFLOW and
Modelons Vehicle Dynamics Library (VDL). In this
approach, the aerodynamic forces on the body are used
to calculate the movement of the body and the
suspension geometry. This modified geometry is then
used to recalculate the operating aerodynamic forces.
The modified geometry shows changes in total force,
the distribution of forces, and the structure of the
airflow over the vehicle. The results provided by
correct geometry under loaded conditions offer better
correlation to test and provide car makers with the
increased accuracy to confidently improve real world
fuel economy.
Keywords:

1

aerodynamics, suspension, co-simulation

Introduction

One of the most important aspects of a vehicle for fuel
economy is the aerodynamic drag. Reducing drag
improves fuel economy in conventional vehicles and
range in electric vehicles. When a new vehicle is
designed, a car maker must decide where to invest
resources in meeting mandated and customer expected
efficiency requirements. Meeting efficiency targets
usually involves improving drag, reducing powertrain
losses, and reducing vehicle mass. Improvements in
each of these areas represent significant investments on
any new program. Accurately predicting the drag is
critical to predicting the performance that a production
vehicle will achieve. If this value is accurately
predicted, an OEM can confidently direct the large

DOI
10.3384/ecp1713247

investments associated with improving fuel economy
and range. If this value is incorrectly predicted, then
late design changes that carry a large risk and expense
are needed to meet the original vehicle targets.
Predicting vehicle efficiency involves many tools that
are used for simulating the different aspects of a
vehicle. The vehicle drag prediction requires 3D CFD
simulation. The efficiency is usually predicted in
system simulations that consider drag, body, and
powertrain behavior.
Two common assumptions are used when
determining drag for fuel economy, range, and vehicle
dynamics simulations. The first is that vehicle
aerodynamic forces are accurately represented by a
load curve that is a function of vehicle speed. The
second is that vehicle geometry is fixed for
characterizing aerodynamic forces. Both assumptions
are valid, but only for limited conditions. In both the
wind tunnel and the real world, these assumptions
reduce the accuracy of the resulting predictions.
In a system simulation, the effect of aerodynamic
forces on a vehicle is usually calculated using the
coefficient of drag. This coefficient is determined from
a CFD simulation, measured in a wind tunnel, or
derived from a coast down test. For fixed geometry in
still air, the drag force,  , is a function of the square
of the vehicle speed, , the air density, , the
coefficient of drag,  , and the frontal area of the
vehicle.
1
(1)
 =     2    
2
The drag force works against the direction of travel
of a vehicle. However, in addition to the drag force, the
airflow over the vehicle also generates lift forces.
These lift forces cause the posture of the vehicle to
change, with a 2 millimeter front ride height increase
and a 3 millimeter rear ride height for our example, as
illustrated in Figure 1. The lift force is calculated
similar to the drag force using a lift coefficient. To
calculate the vehicle posture, lift forces are calculated
over the front and rear axles using an equation similar
to the drag equation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

47

Improved Aerodynamic Prediction Through Coupled System and CFD Models

1
    2  ,  
2
1
=     2  ,  
2

, =
,

(2)
(3)

The lift is determined in this way so that the effect
of different lift forces on the front and rear of the
vehicle are considered. The lift driven changes in
posture mean that the assumption of fixed geometry
doesnt hold. Therefore, for accurate prediction of
forces on a vehicle, this interaction between vehicle
posture and aerodynamic forces should be considered.
CFD accuracy is improved by considering the impact
of aerodynamic forces on vehicle posture.

Figure 1. Lift forces and displacement.

2

Determining Posture Change

Changes in vehicle posture affect the position and
orientation of suspension parts and wheels. These small
changes in geometry affect the airflow over the entire
vehicle. The changes in airflow change the pressure on
the vehicle surfaces. This change in the pressure
distribution and magnitude cause a change in the lift
and drag forces. In some cases, this change in posture
has an easily observable effect on the airflow. For
example, a part of the underbody which was shielded
from high speed airflow might be exposed and act like
an aeronautic air brake. In other cases, the effect may
be subtle, causing changes in the distribution of the
flow over the vehicle body and relative change in the
flow under and over the vehicle. This effect is similar
to how changing an airfoils angle of attack changes its
lift and drag. A key difference is that a vehicles
geometry is much more complex than an airfoil. It has
complex surfaces, heat exchangers, fans, airflow
through the engine bay, rotating tires, and airflow
around the vehicle body.
To accurately determine the effect of these geometry
changes a full 3D flow simulation is required. This
simulation is done using the Lattice-Boltzmann (LB)
solver in PowerFLOW (Exa Corporation, 2017). This
solver offers several advantages over traditional
Navier-Stokes (NS) based solvers. The LB solver is
inherently a transient solver, and the PowerFLOW

48

implementation is able to handle fully detailed
automotive geometry without simplification. This
ability to handle geometry changes without special
consideration simplifies implementation of geometry
movement. This solver is used by OEMs globally for
aerodynamic, thermal, and acoustic simulation. Its
accuracy and robustness are well documented
(Kotopati, 2009; Duncan, 2010; Duncan, 2012).
Modelica was used in this application because it is
capable of describing problems in many engineering
domains. Most importantly, it can elegantly describe
multi-body problems such as suspension simulations.
The features inherent in the language make it easy to
present the model in a form that can be used by
someone who is not an expert in a particular
engineering domain, such as suspension simulation.
Furthermore, since Modelica is able to address
multiple engineering domains, it provides a solution to
describing different functional behavior in the vehicle
using a single language. Vehicle Dynamics Library
(VDL) (Modelon AB, 2016) has been used extensively
in the automotive domain and proven for simulation of
complex vehicle behavior (Andreasson, 2011;
Andreasson, 2016; Griffin, 2012; Klomp, 2016) in
Dymola (Dassault Systemes, 2017). VDL is a
commercial Modelica library with a wide range of full
fidelity, multibody suspension configurations. VDL
can solve for the effect of aerodynamic load, like in a
wind tunnel or the open road, and inertial loads, like on
the track. In conjunction with OPTIMICA Compiler
Toolkit (OCT) (Modelon AB, 2016), Functional
Mockup Units (FMUs) (MODELISAR, 2010) from
VDL can be created to simply the task of interfacing
between multiple solvers.
A model of a proprietary vehicle from Exa known as
the EV12 was implemented using the Vehicle
Dynamics Library (VDL) from Modelon. The EV12
vehicle has a McPherson strut front suspension and a
twist beam rear suspension. As suspension topologies
are available in VDL, modelling the EV12 was simply
a matter of modifying the suspension geometry
parameters to match those of the EV12. The resulting
vehicle model in Dymola is shown in Figure 2.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713247

Session 4A: Automotive I

combiTable1Ds

controller

VDL_whl_frc_z[wheel_number]
.Modelica.Blocks.Types.SimpleController.PID

rideActuator[wheel_number]
f
f

Figure 2. Diagram view of EV12 chassis model
Figure 3. Ride height controller

Two different approaches were used during to the
investigation to quantify the difference in drag forces
and vehicle pressure distribution.
2.1 Change in vehicle posture based on downforce
In the first approach, the goal was to determine the
effect changes in aerodynamic forces had on the static
vehicle posture.
To quantify this effect, the vehicle posture was
controlled by aerodynamic downforce. As changes in
downforce directly relate to changes in tire vertical
forces, tire vertical forces were used to resolve the ride
height. This change was implemented as a controller in
the system model.
The ride height controller, shown in Figure 3, was
implemented by defining the fender height, or vertical
height of the chassis at each vehicle corner, versus tire
vertical force as tabular data and adjusting the force in
the actuator until the desired fender height was
achieved. The tire vertical force is a standard output in
VDL for vehicle simulations. Therefore, accessing the
tire vertical force to use it in the actuator was simply a
matter of pulling this signal off the signal Bus. A PIDcontroller from the Modelica Standard Library was
used to control the force.

Control of the vehicle posture was achieved by
using ride height actuators as shown in Figure 4. VDL
uses both standardized templates and interfaces to
describe vehicle components and sub-components. The
ride height controller described above used a consistent
interface as the standard ride springs. As such changing
from the standard ride spring model to ride height
actuator was simply a matter of changing classes.

Figure 4. Standard ride springs replaced with actuators

Based on this approach, we concluded that even
small changes in aerodynamic downforce affected both
vehicle posture and the position and orientation of the
suspension components.

DOI
10.3384/ecp1713247

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

49

Improved Aerodynamic Prediction Through Coupled System and CFD Models

2.2 Controlled vehicle posture
In the second approach, the vehicle posture was
explicitly controlled.
The vehicle posture was changed using a standard
experiment in VDL in which the wheel hubs are held at
a fixed vertical position and the chassis is pulled down
by two actuators. The attachment points of the
actuators on the vehicle were located at positions
consistent with the sensors that measure the front and
rear ride height in the CFD simulation. The diagram
layer of the heave rig experiment is shown in Figure 5.

the various vehicle postures. The image below was
generated by superimposing all the animation frames.

Figure 7. Superimposed frames of HeaveRig animation

The overall magnitude of the change in suspension
component position and orientation is shown in Figure
8. This plot shows the change in the height of the outer
tierod point vs. front and rear heave changes.

0.35
0.345

Figure 5. Diagram layer of HeaveRig experiment

0.34

The resulting animation of the heave rig experiment
is shown in Figure 6.

0.335
0.33
0.325

0.007
-0.004

The desired results of the heave rig were the time
history of all suspension part positions and orientations
at all front and rear right heights. To generate this data,
a full variable sweep was used in which the front and
rear ride heights were varied from 15 to 15 mm of
travel at 1 mm intervals. This full sweep resulted in
961 different vehicle postures.
As is evidenced in Figure 7, the suspension
components of the vehicle move significantly across

50

0.013

0.009

0.005

0.001

-0.003

-0.007

-0.015

Figure 6. Animation of HeaveRig experiment

-0.011

0.32

-0.015

0.32-0.325

0.325-0.33

0.33-0.335

0.335-0.34

0.34-0.345

0.345-0.35

Figure 8. Variation of outer tierod height with changes in
vehicle posture

The HeaveRig simulation provided a complete time
history of suspension parts position and orientation
during the vehicle posture changes. These results were
exported and reformatted for use in PowerFLOW.

3

Improved Drag Prediction

The most important design point for a vehicles
aerodynamics is the performance under steady speed
conditions on a flat road. This condition is the one

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713247

Session 4A: Automotive I

replicated in most wind tunnels. When operating in this
manner, the vehicles change in posture is caused by
the drag force and the lift forces. When the vehicle
posture changes, many components in the suspension
move. This movement is illustrated in Figure 9. Most
importantly, the vehicle body position changes.

Figure 9. Suspension displacement under aerodynamic
load.

While small changes in posture of a few millimeters
may appear to be inconsequential, these effects are
often a source of error for accurately predicting the
drag of a vehicle. Furthermore, these small changes in
posture lead to appreciable changes the flow structures
on the vehicle. Such an effect is illustrated in Figure
10.
The change in the vehicle posture exposes the front
suspension to more incoming flow, which increases the
static pressure on the surface of the vehicle, increasing
drag. This effect (higher static pressure) is visible in
both the lower A-arm attachment to the body as well as
the front wheel arch pressure, behind the front
suspension. These two areas are marked with white
arrows on each image of Figure 10. Both areas show a
redder shade of static pressure, contributing to about 1
count of aerodynamic drag (a count is 0.001 or a tenth
of a percent).

Figure 10. Differences in surface pressure and underbody
airflow. Original posture [top] vs. realistic posture
[bottom]

Focusing on the rear of the vehicle, Figure 11 shows
the surface pressure for both the baseline vehicle (top)
as well as the realistic posture (bottom). It can be seen
that updating the posture and the suspension yield a
lower surface pressure on the back of the vehicle,
which contributes to 3 count of drag increase.

DOI
10.3384/ecp1713247

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

51

Improved Aerodynamic Prediction Through Coupled System and CFD Models

Case:
Baseline
Posture alone
Posture+Suspension

Cd [counts]
387
390
391

Cd [counts]
+3
+4

Table 1. Difference in vehicle drag due to posture and
suspension change.

This improved accuracy was achieved by first
finding the drag and lift forces on the vehicle using the
at-rest posture. This model included all the vehicle
geometry details such as underhood and suspension
components. After finding the lift forces, they were
applied to the suspension model described in Section
2.1.
The change in posture resulted in changes in the
airflow pressure on the vehicle body. Using the
corrected geometry, these refined forces are a more
accurate representation of the vehicle forces and flows.
The local impact of the changes can be seen in the drag
development show in Figure 12. This graph shows that
the body posture effect of 3 counts is mainly felt at the
back of the vehicle, manifesting in a reduction in the
base pressure. The suspension effects, on the other
hand, have a 1 count of drag impact that is felt mainly
on the front axle suspension and the front wheel arches.

Figure 12. Difference in drag due to posture change.

Figure 11. Differences in surface pressure on the back of
the vehicle. Original posture [top] vs. realistic posture
[bottom]

In this case study, this coupling improved the
accuracy of the drag predictions by 4 counts, about a
1% improvement. Simulating a step in between
(updating the body posture alone without updating the
suspension) enabled us to find that of the 4 total counts
of drag increase, 3 were due to the body posture update
and 1 count was due to updating the suspension
geometry. These effects can be seen in Table 1.

52

This iterative coupling solved for the vehicle lift,
posture change, and then for the improved drag value.
The inputs to the process are the vehicle geometry and
the suspension characteristics. The vehicle geometry
provides the surface data for CFD simulation and the
location of the hard points in the suspension which are
used to setup the system simulation. The suspension
characteristics allow the system model to properly
calculate the changes in geometry due to the lift forces.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713247

Session 4A: Automotive I

4

A Case Study

This process was applied to a proprietary vehicle from
Exa known as the EV12. This vehicle has dimensions
and details similar to a small SUV. To calculate the
posture change, Vehicle Dynamics Library was used to
determine the vehicle geometry changes in response to
these forces. These changes in geometry were used to
modify the vehicle geometry. This modified vehicle
geometry was used to find an updated drag value. For
this case study, the need to iterate on this process was
investigated. It was found that a single iteration was
sufficient to account for posture driven changes in
drag. This quick convergence allows improved drag
prediction at an affordable computational and walltime cost.
The system model was integrated in a rig which
simulates the body motion in response to the drag and
lift forces. This rig is shown in Figure 4. The remaining
part of this solution is the translation of the suspension
movement back to changes in geometry. This
translation is accomplished by using consistent frames
of reference between the system model and the CFD
model. The changes of the frames of reference are
determined in response the aerodynamic forces.

5

Conclusions

A methodology was developed that improves the
correlation of vehicle geometry to real world loading
conditions and thus improves accuracy in replicating
test conditions in CFD. This improvement was
accomplished by coupling a Vehicle Dynamics Library
model of the vehicle with Exas PowerFLOW for 3D
CFD simulation. The vehicle model was coupled with
the CFD simulation via an FMU generated using
OPTIMICA Compiler Toolkit.
In the case study considered, changes in drag of
about 1% were seen due to the changes in vehicle
posture and consequently changes to the suspension
geometry. Improving aerodynamic prediction accuracy
is critical because of the large impact on certification
and real world fuel economy. This case study
examined a single aspect of coupling aerodynamic and
suspension simulations. This coupling is important
enough that it is expected to be part of every vehicle
aerodynamic simulation. Future applications will
consider the impact of real world conditions, tire tread,
and driving cycles to improve designs for efficiency
and comfort.

models for accurate real-time simulation. Japanese
Modelica Conference 2016, Tokyo, Japan, May 23-24,
2016.
Dassault Systemes, Velizy, France (2017) Dymola 2017
FD01. https://www.3ds.com/productsservices/catia/products/dymola/
Duncan BD, Fischer A, and Kandasamy S.: Validation of
lattice-Boltzmann aerodynamics simulation for vehicle lift
prediction. In: ASME 2010 3rd joint USEuropean fluids
engineering summer meeting, 8th international conference
on nanochannels, microchannels, and minichannels,
Montreal, Quebec, Canada, 15 August 2010, ASME
paper FEDSM-ICNMM2010-30891, pp. 27052716. New
York: ASME.
Duncan B, Kandasamy S, Gau H, et al.: Aerodynamic
performance assessment of BMW validation models using
computational fluid dynamics. SAE paper 2012-01-0297,
2012.
Exa Corporation, Burlington, Mass, USA (2017)
PowerFLOW. http://exa.com/en/product/simulationtools/powerflow-cfd-simulation/
Griffin, J., Batteh, J., and Andreasson, J., Modeling Vehicle
Drivability with Modelica and the Vehicle Dynamics
Library, Proceedings of 9th International Modelica
Conference, pp. 599-608, 2012.
Klomp, M., Sundstrm, P., Johnsson, A.: Real-Time
Simulation of Elasto-kinematic Multi-body Vehicle
Models. 13th International Symposium on Advanced
Vehicle Control, Munich, Germany, pp. 255-260, Sep. 1316, 2016.
Kotopati R, Keating A, Kandasamy S, et al.: The latticeBoltzmann-VLES Method for automotive fluid dynamics
simulation, a review. SAE paper 2009-26-057, 2009.
MODELISAR, Functional Mock-up Interface for Model
Exchange, Version 1.0, 2010.
Modelon AB, Lund, Sweden. (2017). OPTIMICA Compiler
Toolkit.
http://www.modelon.com/products/optimicacompiler-toolkit/
Modelon AB, Lund, Sweden. (2017). Vehicle Dynamics
Library.
http://www.modelon.com/products/modelicalibraries/vehicle-dynamics-library/

References
Andreasson, J., The Vehicle Dynamics Library: New
Concepts and New Fields of Application, Proceedings of
8th International Modelica Conference, 2011.
Andreasson, J., Machida, N., Tsushima, M., Griffin, J.,
Sundstrm, P.: Deployment of high-fidelity vehicle

DOI
10.3384/ecp1713247

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

53

54

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Coupled Simulation between CFD and Multizone Models Based on
Modelica Buildings Library to Study Indoor Environment Control
Wei Tian1

Wangda Zuo1,*

Thomas A. Sevilla1

Michael D. Sohn2

1

Department of Civil, Architectural, and Environmental Engineering, University of Miami, USA,
w.tian@umiami.edu w.zuo@miami.edu, t.sevilla@umiami.edu; *Corresponding Author
2
Sustainable Energy Systems Group, Lawrence Berkeley National Laboratory, USA, mdsohn@lbl.gov

such as multizone models, zonal models, and CFD
models (Chen 2009). For the HVAC simulation, there
are some conventional building performance simulation
programs such as EnergyPlus (Crawley et al. 2001),
ESP-r (Strachan et al. 2008), IDA Indoor Climate and
Energy (IDA ICE) (Kropf and Zweifel 2001),
TRYNSYS (Klein et al. 1976), and some advanced
techniques such as Modelica-based modeling (Wetter
2009).
Multizone models are widely used in building energy
performance simulation programs to save computation
time. By asserting that the air is suitably well mixed in
a zone, a multizone model solves the mass balance
equation and energy balance equation in a significantly
faster fashion, compared to the speed of the CFD models
(Chen 2009). However, the underlying well-mixed air
assumptions for multizone models may be invalid if, for
example, the air in the room is stratified. In this case, the
multizone models may calculate incorrect results (Wang
and Chen 2008).
To model a multiple air distribution type zone
building, Wang (Wang 2007) proposed dynamic
coupling between CFD and multizone models. As a
result, the multizone models are adopted for zones with
well-mixed air distribution and CFD model is used for
zones with stratified air distribution. At the
synchronization time, data is exchanged between the
CFD and multizone models. The data exchange is
performed iteratively to ensure a fully-converged
solution. To achieve convergence and stability, Wang
and Chen (2005) recommended transferring pressure
data from multizone models to CFD while
simultaneously giving airflow rates from CFD to
multizone models. While significant, however, their
work only focused on the airflow movement and did not
demonstrate their approach for buildings that included
HVAC systems, and with HVAC controls.
To model the control and distribution of airflow
movement in a building with multiple zones, it is
necessary to integrate the HVAC system modeling,
multizone model, and CFD model. In previous work,
multizone models were implemented in Modelica
(Wetter 2006a). Similar models are also implemented in
the Modelica Buildings library (Wetter et al. 2014)
which can link to the HVAC system model to study the

Abstract
Multizone models are widely used in building airflow
and energy performance simulations because they are
often suitable for the analysis needed, and due to their
fast computation speed. However, the results provided
by the multizone models are sometimes limited due to
the underlying well-mixed assumption of the air in a
zone (e.g., a room). For zones where this assumption is
not suitable, a Computational Fluid Dynamics (CFD)
models may be needed. This paper proposes a coupled
simulation model between the multizone and CFD
model, which in the paper is fast fluid dynamics, a freely
available and publicly released program. The model
allows the simulation of a dynamic interaction between
airflow and Heating, Ventilation and Air-Conditioning
(HVAC) systems for buildings with stratified airflow
distribution in some of the zones. The approach is
implemented using Modelica and its buildings library.
In this presentation, we first discuss the design and
implementation of a data synchronization strategy
between the two models. We then show a possible
validation of the implementation by comparing the
simulated results with experimental data from previous
research. Finally, we perform a case study by linking a
Variable Air Volume (VAV) terminal box to space in
order to evaluate the capability of the coupled
simulation. Finally, further research needs are discussed
at the end of the paper.
Keywords: CFD, Multizone, Coupled Simulation

1 Introduction
On average, Americans spend 90% of their time indoors
(Kats 2003). Therefore, in order to maintain thermal
comfort using HAVC systems, buildings consume about
41% of total energy in the US (Department of Energy
2011). However, the current indoor environment is far
from satisfactory. The estimated loss of productivity
due to the poor indoor environment is up to 160 billion
dollars in the US (Fisk 2000). Thus, it is critical to
improve the indoor environment while decreasing the
energy consumption.
To improve the design of HVAC system and indoor
environment, we can use numerical simulation. On the
airflow simulation, there are various models available,
1

DOI
10.3384/ecp1713255

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

55

Coupled Simulation between CFD and Multizone Models Based on Modelica Buildings Library to Study
Indoor Environment Control

temperature values at two outlets, which are the
averages for time and area, to the multizone modeled
zones, namely, Zone 2 and Zone 3.

control of airflow. Besides the multizone models, there
are several CFD model implementations in Modelica
such as a sub-zonal CFD model (Bonvini et al. 2014)
and VEPZO (Norrefeldt et al. 2012). Moreover, a
externally coupled simulation model between CFD
model for airflow, HVAC, building envelopes and
control was implemented in the Modelica Buildings
library to enable the study of their dynamic interactions
(Zuo et al. 2016). The coupled simulation model was
then validated and used to study a case with stratified
non-isothermal airflows with an idealized constant air
volume system. The results demonstrated that the model
is capable of capturing the dynamics of the system.
Based on the previous efforts, this paper implements
the coupled simulation of CFD and multizone models in
Modelica to study the interaction between airflow
movement and HVAC system. This paper first discusses
the data synchronization strategy used in the
implementation. Then it focuses on the validation by
using a case with well-controlled boundary conditions.
Finally, a more complex case stemmed from research
(Wang 2007) was used to further evaluate the capability
of the coupled simulation.

Figure 2. Sketch of the case on which data exchange was
implemented

Note that in this simplified data synchronization
scheme there is no pressure information exchanged
mutually between two programs. After receiving the
mass flow rate at openings to from the CFD models, the
multizone models can then determine the pressure at
zones and mass flow rates at the openings using the
equation introduced in the next section.

2 Methodologies
A quasi-dynamic data synchronization strategy (Zhai et
al. 2002; Tian and Zuo 2013) is used for the coupled
simulation. As shown in Figure 1, CFD and multizone
models exchange data at a given data synchronization
point and then run on their own till the next point
. The exchange of information is dependent on
different scenarios. Note that CFD models have a
constant time step size and multizone models
programmed in Modelica uses an adaptive time step size.

3 Mathematical Description of

Multizone model and FFD
FFD solves the Navier-Stokes equations:
1



(1)

and
are the velocity component in and
where
directions, respectively, is the kinematic viscosity,
is the fluid density, is the pressure, is the time, and
is the source term, such as the buoyancy force. FFD
splits the Navier-Stokes equation into the following
three equations:
	

(2)


1



(3)
(4)

FFD first solves the advection equation (2) using a semiLagrangian method (Courant et al. 1952). It then solves
the diffusion equation (3) with an implicit scheme.
Finally, it solves the pressure equation (4) together with
the continuity equation

Figure 1. Two-way data synchronization strategy

As shown in Figure 2, we present a simplified
physical representation of the data exchange strategy. In
this scenario, Zone 1 is simulated by CFD as a nonuniform momentum distribution formed by the inlet
directly facing one of the outlets. The mass flow rate and
temperature at the inlet of the CFD zone are already
known. CFD models feed the mass flow rates and

0

(5)

using a projection-correction method (Chorin 1967).
FFD also applies a similar algorithm to solve the
conservation equations of energy and species. The
detailed implementation of sequential FFD model can
2

56

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713255

Session 4B: Buildings I

sign of the mass flow rate. On the right side of the figure,
the mass flow rates and temperature at the outlets from
CFD were given to the prescribed fluid mover through
the first order delay model. The delay model is used to
mimic reality by making the mass flow rate increase
gradually.

be found in (Zuo and Chen 2009; Jin et al. 2012). One
can also refer to the parallelized FFD model by CUDA
and OpenCL in these literature (Zuo and Chen 2010;
Yang 2013; Tian, Sevilla, and Zuo 2017).
Typical
multizone
models,
for
example,
CONTAMW, use the power law to calculate the mass
flow rate
from zone to zone (Dols and Walton
is defined
2002). In Modelica Buildings library, the
as follows (Wetter 2006b):

Sen

qRadGai_flow

Radiative
heat gain
k=0
qConGai_flow

Output of sensor
information at CFD
zone

multiplex3_1

Convective
heat gain
u

qLatGai_flow

yCFD

q

2





Latent
heat gain

(6)

firstOrder

roo

k=0

PT1

MasFloRat
m_flow

ports1

T=1

First order delay
air
air
k=0

radiation
radiation

T

m

surface
surface

Fluid mover with
prescribed mass flow
rate

boundary

where
is the discharge coefficient normally ranging
between 0.6 to 0.75; is the area size of the opening;
is the density of the air; is constant, which is 0.5 for
large openings.  is the pressure difference consisting
of total pressure difference
, pressure
difference due to wind  , and pressure difference due
to density and elevation difference  (Wang and Chen
2007).
Since Modelica is an equation-based, object-oriented
can
modeling language (Fritzson 1998), the sign of
be automatically determined based on the pressure in
two zones. Thus, we can write the mass conservation for
zone as:

TWal
FakRes

m0=1

dp_nominal=10

K

Fluid ports connected
to mixed volume model

T=T_Wall

FakOut

Surface temperature of
CFD zone
Fluid ports to
connect inlet flows

The ambient with
prescribed pressure

ports2

	 	

CFD zone
Resistance
connected to the
ambient

Figure 3. Diagram of Modelica model for coupling

In this paper, we chose Fast Fluid Dynamics (FFD),
as an intermediate model between multizone and CFD
models, due to its fast computation speed. By sacrificing
some accuracy the FFD method is shown to be about 50
times faster than CFD programs if running on the CPU
(Zuo and Chen 2009). By taking advantage of the GPU,
the FFD program can gain another 30 times computation
acceleration, which will be added up to achieve 1500
times faster than CFD program running on CPU (Zuo
and Chen 2010).

(7)

where
is the mass at zone ;
is number of
is the air mass
surrounding neighbours to zone ;
source in the zone . Since the flow in buildings is
typically incompressible, we can assume that
is not
changing with the time. Once the boundary conditions
are applied, the pressure at each zone and mass flow rate
between neighboring zones can be uniquely determined.

5 Case Study
5.1 Isothermal with non-uniform
momentum distribution
We used one of the three experiments conducted by
Wang and Chen (2009) to validate the coupled
simulation model. As shown in Figure 4, space consists
of four zones. Zone 1, which has one inlet and two
outlets, is simulated by FFD, due to the non-uniform
momentum distribution as the inlet is directly facing
opening 1. Other zones were simulated using multizone
models.
Figure 5 shows the Modelica representation of the
validation case. A prescribed fluid mover was connected
to the CFD zone (Zone 1) to provide the inlet boundary
conditions for the FFD program. Other zones were
simulated by the multizone models, namely,
MixingVolume. The openings were simulated by
Orifice, which nonlinearly correlates the mass flow rates
with a pressure difference between zones.

4 Model Implementation
The key obstacle to the implementation is to realize the
extraction of the flow rates and the value of the scalar
variables at the outlets from CFD and to feed them to
the multizone model. To overcome the problem, we put
virtual sensors at the outlets to obtain the necessary
information. For detailed information of the CFD model
in the Modelica Buildings library, please refer to
previous research (Zuo et al. 2014).
Figure 3 shows the detailed implementation. The
CFD zone is modeled using the CFD model in the
Modelica Buildings library. Three real inputs for
radiative heat gain, convective heat gain, and latent heat
gain, are connected to the CFD model. At the lower part
of the figure, there are fluid and heat ports connected to
the CFD model as boundary conditions. Note that the
CFD model will calculate the mass flow rates at all ports
using the mass balance law and the CFD program will
assign the tag of inlet or outlet to the ports based on the
3

DOI
10.3384/ecp1713255

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

57

Coupled Simulation between CFD and Multizone Models Based on Modelica Buildings Library to Study
Indoor Environment Control

outlet

zone 2

zone 4

en
op
g
in
1
en
op
g
in
3

t
le
in

zone 3

en
op

zone 1

g
in
4

op

Y

g
in
en

Z

O

2

X

Figure 6. Validation results of mass flow rate ration at
opening 1 and opening 2
Figure 4. Schematic of a building with two rooms
bouIn

5.2 Multizone airflow with a VAV terminal
box

out

Zone 2

Zone 1

Zone_2

m
Inlet
airflow

Opening 1

In a validation effort, we demonstrate that the coupled
simulation model can study the airflow distribution for
space with a non-uniform momentum distribution. After
adding a VAV terminal box to the validation case, the
case study aimed to investigate the control of room
temperature for Zone 1, as shown in Figure 7. To
increase the efficiency of temperature control, we
increased the length of the inlet (in the X direction) by
0.53 m, in order to insert more air from the terminal box
in the room.
Here we modeled the heat transfer and radiative heat
transfer through and between the envelopes in Zone 1 in
Modelica. The exterior surface temperature for floor and
other walls are 25 and 27 , respectively. The initial
temperature of the space is 30 . The objective is to
sustain 25 temperature for occupant zone of Zone 1,
which is in the lower half part, by adjusting the VAV
terminal box.

Opening 3
V=2.49*2.44*2.44

Zone_1

Zone_4
A=0.08

CFD_Zone

Zone 2

int1_2

A=0.13

int2_4

V=4.93*1.77*2.44

Zone 4
Zone 1

A=0.06

int4_out
Outlet

Zone 3
A=0.08

Ambient

A=0.13
V=2.44*2.44*2.44

int1_3
Opening 2

int3_4
Opening 4
Zone_3

Zone 3

Zone 4

Figure 5. Diagram of Modelica model for a building with
two rooms

The radiative heat gain, the convective heat gain, and
the latent heat gain inside CFD_Zone model are all set
to zero. The inlet mass flow rate is changing at 0.033,
0.053, 0.105, 0.14, and 0.215 m3/s. Since this
experiment is essentially isothermal, we set the inlet
temperature, the temperature at all walls of Zone 1 and
initial temperature at fluid cells as 10 . The data
synchronization time step is set up to 5 s. The simulation
span is 100 s and the Radau solver is used. The residual
is regulated to be below 1E-6.
FFD uses a mesh of 34  12  18. The time step size
for the former two mass flow rates is 0.1 s and for others
is 0.05 s. To simulate the turbulence introduced by the
high-velocity jet, we employed the zero equation model
proposed by Chen and Xu (1998).
Figure 6 shows the mass flow rates ratio at opening 1
and opening 2 in Zone 1. Our simulated results have
good agreement with the experiment when the inlet
mass flow rate is generally larger. Due to the fact that
there is considerable numerical viscosity (can be acted
as turbulence viscosity) in the FFD model as a result of
the solution method, we tuned the coefficients of the
zero equation turbulence model.

VAV Terminal Box

Zone 2

Zone 1

out

Zone_2
Opening 1

Opening 3

V=2.49*2.44*2.44

Zone_1

Zone_4
Zone 2

A=0.08

CFD_Zone

int1_2

int2_4

V=4.93*1.77*2.44

Zone 4
Zone 1

A=0.06

int4_out
Outlet

Zone 3
A=0.08

Ambient

A=0.13

A=0.13
V=2.44*2.44*2.44

int1_3
Opening 2

int3_4
Opening 4
Zone_3

Zone 3

Zone 4

Figure 7. VAV terminal box with validation space

Figure 8 illustrates the detailed model of VAV
terminal box. Since we isolated the room from a VAV
system which serves multiple rooms, we assume that the
pressure difference at terminal box and space outlet as
4

58

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713255

Session 4B: Buildings I

constant. Thus, we set the pressure of the cold air source
as 20 Pa. The temperature of the cold air source is
constant as 16 . The opening of the valve in the cold
air loop is adjustable and reheat coil can be turned on by
opening the valve in the hot water loop. A controller is
implemented to coordinate the opening position of the
valve in cold air and hot water loop.
port_b

Outlet of terminal box

senMasFlo

m_flow

fraMasFlo

Mass flow rate
sensor

Mass flow rate fraction
k=1/m_flow_nominal

dp_nominal=15
m0=m_flow_nominal
vav

ACH

ACH
k=1/2.44/4.93/6.22/1.2*3600

Temperature sensor

TSup

T

Valve

Hot water source
souTer
terHea

Reheat coil
valHea

Hot water sink

con
TRoo

yHea

TSup

yCoo

Valve

sinTer

yDam

Air loop valve position

Terminal Box
Controller
AirSou

Cold air source with
constant pressure

TRoo

Room temperature
Input

Figure 8. VAV terminal box

As shown in Figure 9, we implemented a pressuredependent control logic (Liu et al. 2012). The occupant
zone temperature signal is first sent to adjust the valve
position in the cooling air loop, which is at the lower
part of the figure. If the valve opening decreases to 30%,
which is deemed as the lower limit, then, the reheat coil
will be turned on by feeding the opening position signal
to the valve of the reheat coil. The control of the reheat
coil is shown in the upper part of the figure. To avoid
the short cycling of the reheat coil, we added to the
controller a hysteresis, which has lower bound of 0.3
and higher bound of 0.4.
Reheat control loop
HeaSet

TRoo

conHea

PI controller

Room temperature
set point

product

PI
PI
booleanToReal

k=273.15 + 25

yHea

B

R
Room temperature
input

From Figure 10 to Figure 12, the dynamic response
of the VAV terminal box and indoor environment is
shown. In the beginning, as shown in Figure 10, the
room temperature is initially higher than the set point
(25 ), the opening ratio of the valve in the cold air loop
is decreasing from 1.0 to 0.3 as shown in Figure 11. The
mass flow rate of the supply air as shown in Figure 12
then drops from 0.120 kg/s to 0.044 kg/s. Since the
reheat coil does not turn on, the supply air temperature
remains constant as 16 , as shown in Figure 13.
At around 60 seconds, when the opening ratio of the
valve in the cold air loop reaches 30%, and the room
temperature is lower than the set point (Figure 10), the
reheat coil is turned on. Then, the room temperature is
increased and meets the set point at around 160 seconds.
Since the room temperature is lower than the set point at
this period (60-160 seconds), the opening ratio of the
valve in cold air loop remains a minimum of 30% and
the opening of the valve in reheat coil first climbs up and
then drops, as shown in Figure 11. As a result, the mass
flow rate of the supply air remains constant at 0.044 kg/s
(Figure 12). Consequently, one can see in Figure 13 that
the supply air temperature first increases to a maximum
of 25.4
and then gradually drops to 23.0 , along
with the change of opening of the valve in reheat coil.
From 160 to 225 seconds, the room temperature is
higher than the set point and their difference is
decreasing (Figure 10). As the difference changes, the
opening of the valve in the cold air loop increases from
0.3 to 0.4 kg/s. Though the room temperature is higher
than set point, due to the hysteresis embedded in the
controller, the reheat coil is still on with a small opening
(Figure 11). Thus, the supply air temperature is higher
than 16
and generally decreasing with the valve
opening becoming smaller (Figure 13).
After approximately 225 seconds, the room
temperature is approaching the set point (Figure 10). At
end of the simulation (15 min), the difference between
room temperature and the set point is marginal. Since
the room temperature is higher than set point and the
opening of the valve in cold air loop is larger than 0.4,
the reheat coil is turned off (Figure 11) and supply air
temperature is 16 (Figure 13).

Valve position reheat coil
hysteresis

0.301

30

0.4 Hysteresis to avoid short

cycling of reheat coil valve
zero

Lower limit of the valve
position in air loop

28

max
k=0.3
conCoo

min

min

PI
PI
k=273.15 + 25

PI controller

one

yDam

26

T [ C]

CooSet

max

Valve position in air loop

Room temperature
set point

24
k=1

Cooling control loop

22

Figure 9. Controller in VAV terminal box

Measured T emperature
Set P oint
20

0

100

200

300

400
500
Simulation T ime [s]

600

700

800

900

5

DOI
10.3384/ecp1713255

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

59

Coupled Simulation between CFD and Multizone Models Based on Modelica Buildings Library to Study
Indoor Environment Control

1.0 . However, in the Zone 2, the temperature is 21.7
, which is as expected, because part of the cold supply
air in Zone 1 is directly injected into Zone 2 as opening
1 is facing to the inlet of Zone 2.

Figure 10. Zone 1 temperature control

1.0
Cooling Air V alve
Reheat Coil V alve
0.8

6 Conclusion and Discussion
Opening Ratio

0.6

The results shown in the validation case prove that the
coupled simulation is capable of handling the airflow
simulation in a multi-zone space with non-uniform
momentum distribution. By further adding a VAV
terminal box to the validation case, the coupled
simulation model further demonstrates its application
potential in indoor climate control and its capability to
capture the dynamics of the building system as well as
the indoor environment. In the future, more case studies
need to be performed to holistically assess the coupled
simulation model such as contaminant control and fire
or smoke control. Moreover, the FFD simulation can be
performed in parallel (Tian, Sevilla, and Zuo 2017) or a
reduced order model such as in situ adaptive tabulation
(Li et al. 2016; Tian, Sevilla, Li, et al. 2017) can be
further used to accelerate the computation speed.

0.4

0.2

0.0
0

100

200

300

400
500
Simulation T ime [s]

600

700

800

900

Figure 11. Control outputs from VAV terminal box

0.14
Opening 3
Opening 4

Supply air
Opening 1
Opening 2

0.12

mwater [kg/s]

0.10

0.08

0.06

Acknowledgements

0.04

This research was supported by the National Science
Foundation under Award No. IIS-1633338 and the U.S.
Department of Energy under Contract No. DEEE0007688. This research was also supported in part by
the U.S. Defense Threat Reduction Agency. LBNLs
research was performed under U.S. Department of
Energy Contract No. DE-AC02-05CH11231.

0.02

0.00

0

100

200

300

400
500
Simulation T ime [s]

600

700

800

900

Figure 12. Mass flow rates at different openings
32
Zone 3
Zone 4

Supply air
Zone 1
Zone 2

30
28

References

T [ C]

26
24

Bonvini, M., M. Popovac, and A. Leva. 2014. Sub-Zonal
Computational Fluid Dynamics in an ObjectOriented Modelling Framework. Proceedings of the
Building Simulation.
Chen, Q. 2009. Ventilation Performance Prediction for
Buildings: A Method Overview and Recent
Applications. Building and Environment, 44
(4):848-58.
Chen, Q., and W. Xu. 1998. A Zero-Equation Turbulence
Model for Indoor Airflow Simulation. Energy and
Buildings, 28 (2):137-44.
Chorin, A. J. 1967. A Numerical Method for Solving
Incompressible Viscous Flow Problems. Journal of
Computational Physics, 2 (1):12-26.
Courant, R., E. Isaacson, and M. Rees. 1952. On the Solution
of Nonlinear Hyperbolic Differential Equations by
Finite Differences. Communications on Pure and
Applied Mathematics, 5 (3):243-55.
Crawley, D. B., L. K. Lawrie, F. C. Winkelmann, W. F. Buhl,
Y. J. Huang, C. O. Pedersen, R. K. Strand, et al. 2001.
Energyplus: Creating a New-Generation Building
Energy Simulation Program. Energy and Buildings,
33 (4):319-31.

22
20
18
16
14

0

100

200

300

400
500
Simulation T ime [s]

600

700

800

900

Figure 13. Zone temperature in the space

Note that we presented the mass flow rate of supply
air and at different openings in the space in Figure 12.
We can clearly identify the mass flow rate difference at
Opening 1 and Opening 2, which would be ignored if a
multizone model is used. Due to the mass conservation
law, the mass flow rate at Opening 1 and Opening 3 are
equal, and the same rule applies to Opening 2 and
Opening 4.
Figure 13 shows the temperature of supply air and
other zones. As the room temperature in Zone 1
approaches set point of 25 , the temperature at Zone 3
and Zone 4 gets close to the set point with an error of
6

60

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713255

Session 4B: Buildings I

Department of Energy. 2011. "Building Energy Data Book."
In.
Dols, W. S., and G. N. Walton. 2002. Contamw 2.0 User
Manual: Multizone Airflow and Contaminant
Transport Analysis Software: US Department of
Commerce, Technology Administration, National
Institute of Standards and Technology.
Fisk, W. J. 2000. Health and Productivity Gains from Better
Indoor Environments and Their Relationship with
Building Energy Efficiency. Annual Review of
Energy and the Environment, 25:537-66.
Fritzson, P. 1998. Modelica - a Language for Equation-Based
Physical Modeling and High Performance
Simulation. Applied Parallel Computing, 1541:14960.
Jin, M., W. Zuo, and Q. Chen. 2012. Improvements of Fast
Fluid Dynamics for Simulating Air Flow in
Buildings. Numerical Heat Transfer, Part B:
Fundamentals, 62 (6):419-38.
Kats, G. 2003. Green Building Costs and Financial Benefits:
Massachusetts Technology Collaborative Boston,
MA.
Klein, S. A., J. A. Duffie, and W. A. Beckman. 1976. Trnsysa Transient Simulation Program. Ashrae
Transactions, 82:623.
Kropf, S., and G. Zweifel. 2001. Validation of the Building
Simulation Program Ida-Ice According to Cen
13791 Thermal Performance of Buildings
Calculation of Internal Temperatures of a Room in
Summer without Mechanical CoolingGeneral
Criteria and Validation Procedures. Hochschule
Technik+ Architektur Luzern. HLK Engineering.
Li, D., W. Tian, Z. Wetter, Wangda, and Michael. 2016.
Simulation Using in Situ Adaptive Tabulation and
Fast Fluid Dynamics. IBPSA-USA Journal, 6 (1).
Liu, G., J. Zhang, and A. Dasu. 2012. Review of Literature on
Terminal Box Control, Occupancy Sensing
Technology and Multi-Zone Demand Control
Ventilation (Dcv). US Department of Energy, Tech.
Rep.
Norrefeldt, V., G. Grn, and K. Sedlbauer. 2012. Vepzo
Velocity Propagating Zonal Model for the
Estimation of the Airflow Pattern and Temperature
Distribution in a Confined Space. Building and
Environment, 48:183-94.
Strachan, P., G. Kokogiannakis, and I. Macdonald. 2008.
History and Development of Validation with the
Esp-R Simulation Program. Building and
Environment, 43 (4):601-9.
Tian, W., A. T. Sevilla, D. Li, W. Zuo, and M. Wetter. 2017.
Fast and Self-Learning Indoor Airflow Simulation
Based on in Situ Adaptive Tabulation. Journal of
Building Performance Simulation.
Tian, W., T. A. Sevilla, and W. Zuo. 2017. A Systematic
Evaluation of Accelerating Indoor Airflow
Simulations Using
Cross-Platform Parallel
Computing. Journal of Building Performance
Simulation,
10
(3):243-55.
doi:
10.1080/19401493.2016.1212933.
Tian, W., and W. Zuo. 2013. Literature Review and Research
Needs to Couple Building Energy and Airflow

Simulation. Proceedings of the Proceedings of the
the APEC Conference on Low-carbon Towns and
Physical Energy Storage.
Wang, L. 2007. Coupling of Multizone and CFD Programs
for Building Airflow and Contaminant Transport
Simulations: ProQuest.
Wang, L., and Q. Chen. 2005. On Solution Characteristics of
Coupling of Multizone and CFD Programs in
Building Air Distribution Simulation. Proceedings
of the Proceedings of the 9 th International IBPSA
Conference (Building Simulation 2005), Montreal,
Canada.
Wang, L., and Q. Chen. 2007. Validation of a Coupled
Multizone-CFD Program for Building Airflow and
Contaminant Transport Simulations. HVAC&R
Research, 13 (2):267-81.
Wang, L. L., and Q. Chen. 2008. Evaluation of Some
Assumptions Used in Multizone Airflow Network
Models. Building and Environment, 43 (10):1671-7.
Wang, M., and Q. Chen. 2009. Assessment of Various
Turbulence Models for Transitional Flows in an
Enclosed Environment (Rp-1271). HVAC&R
Research, 15 (6):1099-119.
Wetter, M. 2006a. Multizone Airflow Model in Modelica.
Proc. of the 5-th International Modelica Conference,
2:431-40.
Wetter, M. 2006b. Multizone Airflow Model in Modelica.
Proceedings of the Proc. of the 5-th International
Modelica Conference.
Wetter, M. 2009. Modelica-Based Modeling and Simulation
to Support Research and Development in Building
Energy and Control Systems. Journal of Building
Performance Simulation, 2 (2):143-61.
Wetter, M., W. Zuo, T. S. Nouidui, and X. Pang. 2014.
Modelica Buildings Library. Journal of Building
Performance Simulation, 7 (4):253-70. doi:
10.1080/19401493.2013.765506.
Yang, P. 2013. "Real-Time Building Airflow Simulation
Aided by GPU and FFD." Concordia University.
Zhai, Z., Q. Chen, P. Haves, and J. H. Klems. 2002. On
Approaches to Couple Energy Simulation and
Computational Fluid Dynamics Programs. Building
and Environment, 37 (8):857-64.
Zuo, W., and Q. Chen. 2009. Real-Time or Faster-Than-RealTime Simulation of Airflow in Buildings. Indoor Air,
19 (1):33-44.
Zuo, W., and Q. Chen. 2010. Fast and Informative Flow
Simulations in a Building by Using Fast Fluid
Dynamics Model on Graphics Processing Unit.
Building and Environment, 45 (3):747-57.
Zuo, W., M. Wetter, D. Li, M. Jin, W. Tian, and Q. Chen. 2014.
Coupled Simulation of Indoor Environment, HVAC
and Control System by Using Fast Fluid Dynamics
and Modelica. Proceedings of
the 2014
ASHRAE/IBPSA-USA
Building
Simulation
Conference, Atlanta, GA, Sep. 10-12.
Zuo, W., M. Wetter, W. Tian, D. Li, M. Jin, and Q. Chen. 2016.
Coupling Indoor Airflow, HVAC, Control and
Building Envelope Heat Transfer in the Modelica
Buildings Library. Journal of Building Performance
Simulation, 9 (4):366-81.

7

DOI
10.3384/ecp1713255

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

61

62

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Co-Simulation between detailed building energy performance
simulation and Modelica HVAC component models
Andreas Nicolai1
1 Institut

Anne Paepcke1

for Building Climatology, Faculty of Architecture, TU Dresden, Germany,
andreas.nicolai@tu-dresden.de

or the GreenBuilding library1 . However, modeling the entire building with sufficient physical detail in Modelica
We discuss the application of the FMI Co-Simulation alone is not meaningful for several reasons:
technology to building energy performance simulation,
where detailed physical building models are coupled
 larger building complexes may involve many zones,
to Modelica-based HVAC component and plant models.
constructions, facade elements, thermal storage
First, we describe the generation process of the buildmembers resulting in thousands of differential equaing FMU from our stand-alone building simulation protions,
gram NANDRAD and sketch out internal algorithms for
 Modelica code may become huge and may cause
FMI version 2 capabilities. Then, coupling scenarios
problems with the generic Modelica solvers, even
are described and physical interface conventions are presymbolic analysis may be extremely slow,
sented. Usability is addressed by automatic generation of
building-model specific adapters and wrappers. The build modeling the building in Modelica without suitable
ing FMU and plant FMUs are then simulated together usBIM-style data import or code generation will not
ing different Co-Simulation master algorithms. Finally,
be possible for realistic buildings, it is too timebased on simulation results and performance analysis we
consuming and thus too expensive, and
conclude with recommendations on suitable master algorithm options and specific features of suitable building
 manual connection of many building components
FMUs.
with corresponding equipment and control models
Keywords: FMI, Co-Simulation, Energy, Building Simulamay be extremely time-consuming and error-prone.
tion, HVAC System, Physical Interface, Master Algorithm
For practical purposes, planners and engineers will not
1 Introduction
accept a procedure that involves creation of such complex models with current Modelica user interfaces, alone.
Building energy performance simulation is a technology There are, however, tools under development that asused by planners and building designers in the planning sist with prototyping Modelica-based building and equipprocess. A typical usage scenario includes evaluation of ment models, for example TEASER2 . However, limitadifferent options regarding building envelope construc- tions with respect to the detail of the building model and
tion, HVAC systems and control strategies. Currently, simulation efficiency persist.
available simulation tools, such as EnergyPlus TRNSYS
(Klein et al., 1976; Dols et al., 2014), IDA-ICE (Sahlin 1.1 Benefits of Simulation Coupling within the
et al., 2004) and our own development NANDRAD (NicoBuilding Energy Simulation Context
lai and Paepcke, 2012; Paepcke and Nicolai, 2014) (in
The use of stand-alone simulation tools or Modelica-only
C/C++) are concepted as stand-alone tools. Modeling and
based building modeling may not be a satisfying strategy.
simulation of integrated modern buildings requires flexInstead, a hybrid approach appears meaningful:
ible plant and equipment models, which are often casespecific. Extending the source code of existing building
 using existing building simulation software tailored
simulation models is often only possible by original model
to the building engineering user group, preferedevelopers and also very difficult and time consuming.
ably Building Information Model (BIM) preprocessAlternatively, Modelica as one example for a modeling software packages (DesignBuilder3 , BIM-HVAC
ing language can be used to express such equipment and
1 Green City/ SimulationX  Planungstool,
control systems. There are a number of libraries providhttp://www.ea-energie.de/de/products/ing suitable components for modeling building systems,
green-city-simulationsbibliothek-2-2
for example the Annex60-based libraries AixLib, Build2 TEASER - Tool for Energy Analysis and Simulation for Efficient
ingSystems, Buildings and Idias (Wetter et al., 2013; Wet- Retrofit, https://github.com/RWTH-EBC/TEASER
3 https://www.designbuilder.co.uk
ter, 2009; Nytsch-Geusen et al., 2013; Sahlin et al., 2004)

Abstract

DOI
10.3384/ecp1713263

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

63

Co-Simulation between detailed building energy performance simulation and Modelica HVAC component
models

tool4 , etc.) with database support, graphical representation of the building, and input error control with
automatic generation of input data to building simulation engines (e.g. IDF-files for EnergyPlus, or
nandrad-files for NANDRAD), and

We envision two suitable scenarios of combining a dedicated building energy simulation FMU with one or more
HVAC component FMUs created with Modelica. In the
first scenario, the user will model the equipment system
in Modelica and import a previously generated building
FMU into the modeling environment, connect it to the
Modelica components and run the simulation within the
Environment (Figure 1).
Alternatively, HVAC component or control models may
be designed with Modelica and than exported by the modeling tool into FMUs. These are then combined with
the building FMU and simulated by an alternative CoSimulation master. This approach allows prefabrication
of HVAC component sub-models.

to a class of modern solvers that use dynamic time step
adjustment schemes based on local error estimates, with
the advantage of maintaining required accuracy while improving simulation speed whenever possible (Hindmarsh
et al., 2005). This is an important feature, since different building equipment may be active during different annual seasons and may enforce different time integration
regimes. For example, heating systems are turned off during summer, and if air conditioning is not used, simulation
can speed up since no interaction with actively controlled
equipment occurs. Simulation time steps typically vary
between 1 second and 30 minutes in annual simulations.
The requirement on error control made for FMUs
should also be fulfilled by the Co-Simulation master,
which effectively needs to adjust communication interval
sizes. When separating control and equipment systems
from the buildings thermal response in a Co-Simulation
scenario, the use of larger communication intervals may
cause stability and accuracy problems. Such problems can
be avoided by choosing a sufficiently small time step size.
In realistic simulation cases it is generally not possible to
predict the allowed maximum of the communication step
size. Also, using a fixed tiny communcation step size leads
to inacceptable long simulations and would limit the advantage of performance optimized FMU-internal solvers.
Therefore, a master algorithm which supports error/stability control and dynamic adjustment of communication
step sizes is desirable. This, in return, requires FMI Version 2.0 capabilities of the slaves, in particular the get and
set state functionality (FMI, 2014).
Note, that an error control algorithm within a CoSimulation master will also detect and compensate, by reducing communication step size, potential numerical instabilities, again leading to excessive and inacceptable
simulation times. Phenomena of instability may grow
with increased coupling strength of FMUs interface quantities and often arising from the choice of the model interface.

1.3

2

 use of Modelica and suitable libraries by HVAC
system planners to model building equipment
(heater/chiller/ventilation systems) and required control strategies.
Joining both models in a coupled simulation will combine also the benefits of both modeling approaches. With
the FMI standard a unified methodology and technical description for coupled simulation is available. With respect
to the two described operation modes ModelExchange and
Co-Simulation, we prefer the latter variant that allows individual FMUs to use their own dedicated solver engines.
However, it can be expected that the Co-Simulation approach and gained flexibility implies a simulation overhead and performance penalty. In the remainder of the
article we always refer to Co-Simulation according to the
FMI standard when discussing coupled simulation.

1.2

Envisioned Usage of Co-Simulation

Co-Simulation Requirements

A central requirement for the application of CoSimulation is that obtained results are of a similar accuracy as if the entire model would be calculated standalone. Accuracy shall be defined in this respect such that
the global error, i.e. the difference between numerical solution and true solution is bounded to a defined limit. In
practice, within each integration step the local error is controlled. Every FMU should implement such an error control algorithm to be considered a consistent model.
In the building energy simulation side, this demand restricts the choice of suitable simulation tools, for example, older simulation engines like EnergyPlus and TRNSYS do not implement such an error testing procedure.
Our building simulation models THERAKLES and NANDRAD (Nicolai, 2013; Nicolai and Paepcke, 2012) belong
4 http://www.building-engineering.de

64

Choice of the FMU Interface

The separation of a complex building energy simulation
model into subcomponents is not trivial. A natural choice
for separation of the entire model into FMUs may be to
keep the passive building and its physics regarding interaction with climate and user loads within the building
simulation FMU. All active components such as heating,
cooling, ventilation and associated equipment and control
models will be in one ore more HVAC-FMUs. In this article we use a single FMU with all HVAC equipment and
control models written in Modelica.

2.1

Building Simulation FMU Input/Output
Variables

One option for a flexible interface would be to export all
relevant states like temperatures and solar radiation loads
from the building simulation FMU, and import calculated

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713263

Session 4B: Buildings I

Figure 1. Usage Scenario 1: Building simulation FMU (NANDRAD) imported into Modelica environment (SimulationX)

heating/cooling loads from the HVAC FMUs. This inter- face quantities to Modelica library ports and buses.
face can be considered a very universal interface, since
Different helper components are used depending on the
any kind of heating/cooling loads can be modeled and im- usage scenario:
ported as energy source to each thermal zones energy bal When the building FMU is imported into the Modance. The interface defines for each thermal zone an exelica environment, the FMU is encapsulated into
port of mean air and operative temperature and input of
a Modelica wrapper model, which internally holds
convective and radiative thermal load.
the FMU and connects to the native FMU interface.
The building simulation FMU includes databases for
On the outside it provides port and bus connectors
climatic loads and user behavior and related equipment
matching the corresponding library interfaces, in our
schedules5 . Hence, climatic data and schedules are adcase the GreenBuilding climate, electrical and HVAC
ditionally exported via the FMU interface. This allows
buses (see Figure 2, we use the HVAC, HotWater and
consistent treatment of climatic input data in building and
Electrical port of the GreenBuilding library). This
equipment models. Part of the scheduled user loads are
wrapper is therefore specific to each building6 and to
also hot and cold water demand as well as user-related
the interfaced library.
electric power consumption.

2.2

Convenience Adapters and Wrappers

 When the plant model is to be exported from Modelica into a stand-alone Co-Simulation FMU, the
adapter (Figure 3) is used instead. It provides the
same library-specific connectors as the wrapper, but
does not connect to the building FMU. Instead, it
exports and imports exactly the counterparts of the
building FMU interface variables . When exporting
the Modelica model, only these connectors become
part of the FMU interface. Also, the connector counterparts are identically named to the building FMU
interface quantities, which greatly simplifies automated connection between plant and building FMU
connectors7 . The graphical annotations of zonal con-

The interface definition allows exporting and importing
zonal quantities. Considering typical buildings of more
than hundred conditioned zones, a large number of input/output variables need to be connected to the plant
FMU. Even if the FMI standard would allow usage of vector variables, the manual connection of exported temperatures to the various input ports on the plant side would
not be expedient and may lead to errors that are difficult
to identify and track.
Also, when importing a building simulation FMU into
a Modelica development environment the graphical representation of the inserted FMU with hundreds of ports is
not suitable for practical use. Therefore, we utilize helper
6 The native interface of the FMU changes with the number of thercomponents that assist with mapping native FMU inter- mal zones, or their IDs, and so does the wrapper component.
5 Typically,

such schedules and databases are part of the building
model definition and will be generated/collected within the BIM process

DOI
10.3384/ecp1713263

7 Similarly, when importing a building FMU into a Modelica environment an automated matching of connectors between FMU and wrapper/adapter model would be possible. Unfortunately, none of the currently available modeling environments supports such a procedure.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

65

Co-Simulation between detailed building energy performance simulation and Modelica HVAC component
models

nectors with same quantities but different zone refer- that map FMU input/output variables to existing internal
ences are arranged on top of each other, thus keeping variables. Selecting the usage scenarios and selecting the
the adapter symbol compact.
corresponding zones is part of the FMU preprocessing.
Figure 3 does not show the actual connector names, 3.2 Export procedure
but rather a physical description and associated unit The export procedure involves several steps:
(see (Paepcke et al., 2016) for a complete specification).
 NANDRAD is run as stand-alone simulation to gen2.2.1 Adapter/Wrapper Configurations
erate auxiliary information needed for parametrizaThe use of wrappers/adapters is a compromise between
tion of the HVAC/plant model, for example the heatflexibility of the building model interface and easy-of-use
ing/cooling design day calculation.
within Modelica environments. The current specification
 The NANDRAD solver initialization is used to genof our adapter/wrapper Modelica component is specialerate the variable dependency information, which is
ized of interfacing all building zones with exactly one
stored in the modelDescription.xml file.
HVAC system model in Modelica. For other situations,
the adapter/wrapper models may look different. Yet, the
 The modelDescription.xml is composed (inprinciple approach to provide FMU-independent conneccluded data for ModelExchange and Co-Simulation
tors for the remainder of the Modelica model appears to be
and the FMI v2 functionality).
a promising way to avoid connecting to individual FMU
input/output variables directly.
 All referenced databases are collected. All input
files, the pre-compiled NANDRAD dynamic library
3 Parametrization and Export of
(with implemented FMI functionality), and additional dependent libraries8 are copied. Finally, the
NANDRAD FMUs
FMU archive is created.

3.1

Configuration for FMU Export

When NANDRAD is executed as stand-alone building energy simulation model, for example to compute annual energy demand and comfort criteria, it uses a set of input
files with the building model (BIM) and database elements
(material data, constructions, climatic data, etc.). The input data include definitions of all zones and their heating
and cooling requirements, which enables an ideal heating
and cooling load calculation.
When NANDRAD is used as building simulation FMU
to simulate a realistic heating/cooling system, all conditioned zones need to be connected to the heating cycle
or to the electrical grid of the plant model. All zones
that are part of the interface and import/export variables
are given different usage scenarios, for example, heating
scenario or electrical usage scenario. This information is
then used during export to generate required import/export quantities and also create the internal data structures

 Modelica wrapper and adapter models (.mo files)
are generated individually for the current building
project.
 A report including zone naming, dimensions, unique
IDs and heating/cooling design loads is written to be
used during configuration of the HVAC component
model, and for automatic Modelica model generation
scripts.
During export, compilation of source code is not necessary and the model initialization and the design day calculation are usually very fast, except for large buildings with
several hundred of zones. The auxiliary files are provided
seperately from the generated FMU.
8 Depending on the target platform, different libraries are copied.
Currently, one NANDAD FMU holds only binaries for one platform
Win32, Win64, Linux64, Darwin64 at a time.

Exported climatic data (weather data file content)

GreenBuilding HVAC Port
GreenBuilding HotWater Port
GreenBuilding Electrical Port

Convective thermal load [W] Zone #...
Radiative thermal load [W] Zone #...

Temperature [K]
Relative Humdity [1]
Direct solar radiation [W/m2]
Diffuse solar radiation [W/m2]
Long wave radiation [W/m2]
Air pressure [Pa]
Wind direction [Rad]
 (4 more components)

GreenBuilding HVAC Port
GreenBuilding HotWater Port
GreenBuilding Electrical Port

Electrical power consumption [W]

Domestic water mass flow [kg/s] Zone #...
Domestic water setpoint [K] Zone #...
Domestic water temperatur [K] Zone #...

Figure 2. Modelica wrapper encapsulates NANDRAD FMU
and provides collector ports for climate, HVAC and electrical
quantities

66

Heating setpoint [K] Zone #...
Cooling setpoint [K] Zone #...
Operative temperature [K] Zone #...
Mean air temperature [K] Zone #...

Figure 3. NANDRAD adapter provides Modelica collector
ports as well as input and output variables identically named as
the building FMU ports

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713263

Session 4B: Buildings I

may lead to situations, wherein the last integration step before end of communication interval is much shorter than
previous integration steps10 .
An alternative to limiting the last integration step would
be to allow the integrator to take its natural step size. In
the case of CVODE, the solution at communication interval end could be easily obtained by backward interpo4 NANDRAD FMU Calculation Func- lation. The CVODE integrator could now be re-started
with that interpolated solution in the next communication
tionality
interval. However, such a restart would destroy the his4.1 State-based model evaluation and time in- tory within the multi-step BDF method, effectively forcing
CVODE to restart integration from first order with very
tegration in NANDRAD
small time steps. This approach leads to inacceptable simWhen the building simulation engine NANDRAD was ulation times and cannot be recommended.
developed at the IBK, its design was heavily influenced
by the first version of the FMI for ModelExchange stan- 4.3 Retrieving and restoring the FMU state
dard. The entire physics evaluation is encapsulated within The aforementioned functionality is sufficient for exea state-based model object, whose state changes only by cuting NANDRAD as FMI for Co-Simulation version 1.
modification of the time point or conservative quantites However, as soon as the Co-Simulation master is using
(solution variables). After spatial discretization of all par- an iterative or error controling algorithm, the slaves must
tial differential equations within the building model, a be repeatedly set back in time (see, for example (Clau
large sparse system of coupled ordinary differential equa- et al., 2017)). The master needs to retrieve and restore
tions is assembled. The time integration is then performed each FMUs state.
using our own integration framework, which incorporates
Within NANDRAD the internal state is stored in several
the SUNDIALS:CVODE solver (Hindmarsh et al., 2005). solver components:
Internally, the CVODE integrator is called by the framework for each integration step at a time. It selects/pre State of the integrator (time point, state variables and
dicts a suitable integration time step, performs a modified
Nordsieck history array, counters, control variables)
Newton iteration9 and upon convergence or error test fail State of linear equation system solver, in case of GMure reduces integration step until an acceptable solution is
RES only control variables
found. Note, since integration step sizes are exclusively
determined by the integrator engine, synchronization with
 state of Jacobian, since with modified Newton algocommunication intervals needs to be adressed.
rithm it is only infrequently updated
Figure 4 illustrates the architecture of the stand-alone
NANDRAD solver. The physical model implementa state of preconditioner (part of Jacobian matrix and
tion is encapsulated in a model object which has simiin case of ILU preconditioner also the factorized replar access functions as the ModelExchange specifications
resentation)
require. Therefore, the ModelExchange FMU interface
implementation is only a thin layer around our physi integral model states (integral outputs, state of hyscal model. Our integration framework calls one of the
teresis loops etc.)
supported time integration methods in a step-wise manner. This core loop, which also signals successful steps The data structures are typically very fragmented. The
(stepCompleted()) and tells the model to write in- serialization implementation within NANDRAD creates a
terim outputs (writeOutputs()), is partially replaced continuous memory array and then copies all data memby the Co-Simulation master.
bers into the array, hereby advancing an insertion pointer
4.2 Implementation of the doStep functional- after each copy operation. With the use of C macro definitions, the entire serialization, deserialization and size
ity
computation functionality is only coded once, thus ensurWhen NANDRAD runs as a simulation slave, the time in- ing binary compatibility and improving code maintenance
tegration is now interrupted at the end of communication (Nicolai and Paepcke, 2016).
interval and control is returned to the master. Since inAdditionally, the ability to serialize the entire state of
ternal integration steps may not match interval end, we model and integrator into a continuous memory block enchoose to limit the internal integration step size so that the ables implementation of the fmi2Serialize() and
communication interval is not exceeded. However, this fmi2Deserialize() functions.
Modeling modern complex integrated buildings will
require much more data being commonly used by the
building simulation model and HVAC system model.
Hereby, the procedure of using BIM-data for consistent
parametrization of all model components is desirable and
an ongoing research issue.

9 Within each Newton iteration the large sparse equation system is
solved using a Krylov-subspace method with NANDRAD-specific preconditioner.

DOI
10.3384/ecp1713263

10 Drastic changes in time step sizes typically lead to invalidation of
Jacobian matrix information, with the related overhead of re-composing
and factorizing the Jacobian.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

67

Co-Simulation between detailed building energy performance simulation and Modelica HVAC component
models
Corresponds to FMI ModelInterface
Integrator Implementation

Physical Model Implementation

setTime(t)

solves ODE system of type ydot = f(t,y)

setY(y)

implements physical model equations and the
computation of the system function f(t,y)

ydot()

state of object changes only through calls of
control functions

implicit solver with Newton-Raphson
iteration

writeOutputs(...)

tEnd()

t0()

n()

y0()

yOut(t_out)

t()

step()

init(model)

query functions

stepCompleted(t,y)

control functions

Solver Control System
Implements core integration loop: calls step() function in Integrator, also manages output schedules
To be replaced by Co-Simulation Master

Figure 4. Core components of the NANDRAD stand-alone solver.

4.4

Integration of FMU inputs and outputs in model graph are taken into account. This allows a model
evaluation/update with only small computational effort.
the NANDRAD building model

The physical model of NANDRAD is internally implemented by means of interconnected state-based model objects. We allow a single model object calculation to depend on other model results. For example, room air balance is encapsulated in a single model object that requests
heating and cooling load as input quantities. In turn, the
power of controlled heating and cooling elements reacts
on thermal response of the zone. In complete, NANDRAD
owns several model objects with arbitrary interconnections that form an unstructured graph. Indeed, the states
of all these models must be updated in the correct order
whenever a solver state change is registered. For this purpose we cluster the model graph into nodes with cyclic and
sequential connections first and order it afterwards during
initialization process. As a result, all model objects appear
stacked with respect to their evaluation chronology. This
strategy guarantees all internal states to be current whenever an update is necessary because of changes of solver
states or solver time.
This modeling concept can be easily extended to FMU
inputs and outputs. In detail, we encapsulate all FMU
quantities into an FMU import and an FMU export model
object. The export model transfers all required output
variables from the building model towards the FMI. The
import model caches FMI input quantities, such as heating and cooling loads, and provides them just like calculation results to other internal model objects. This structure enables the model initialization to sort FMU inputs
and outputs to the correct position inside the model object
graph. For evaluation of all models depending on FMU input we store the position of the FMU import model object
within the graph. In the case of update due to FMU input
changes only the corresponding dependent nodes of the
68

To achieve good simulation performance we follow the
concept of lazy evaluation: the call of fmi2SetReal()
does not enforce an update of dependent building model
objects but temporarily fills a data container. Only at the
beginning of each communication step the container values are copied and the model evaluation is triggered. So,
during each communication interval the model results as
well as FMU outputs are consistent to the FMU inputs.

5

Application Cases

The procedure of creating and parametrizing building and
equipment models and exporting FMUs has been tested
with three application cases of different scales: an office
room (1 conditioned zone, 383 ODEs in the building simulation part), a family row-house (2 heated zones, 502
ODEs in the building FMU) and a large appartment complex (178 conditioned zones, 23220 ODEs in the building
FMU).
In this article we will only look at the first case and discuss the observed behavior with respect to the different
Co-Simulation master algorithms employed. Note, it is
generally possible to reduce the number of ODEs, which
mostly result from spatial discretization of envelope/interior constructions, by adjusting the grid-generation parameters. As with most spatial discretization techniques, such
a variation should be complemented by sensitivity studies
which are beyond the scope of the article. In the test case
we selected medium-fine discretization settings, leading to
the reported number of elements.

5.1

Office Room Model Setup

In this model, the office is represented by four enclosing
wall/floor constructions, where internal walls with same
behavior are lumped into one. The only external wall

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713263

Session 4B: Buildings I

faces west and contains a large window. The old construction is made from massive lime sandstone (simplified
as single layer construction) with poor thermal insulation
properties. The HVAC system operates with ideal control
for a heating and cooling demand calculation, dynamic
daily schedules and low setback temperature on weekends.
During the week, schedules distinguish between daytime
and nighttime use (occupied/not-occupied). Corresponding thermal loads are computed by the plant model and
imposed onto the room energy balance. Infiltration is considered with standard settings. Since the heating system
is modeled in an idealistic way. The interaction between
room response and heating system is very strong, leading
to stiffly coupled system.

5.2

Reference Solution and Verification Procedure

Initially, for this problem a Modelica-only solution existed, yet with simplified building representation. The
results of this calculation can be used for plausibility
tests (Figure 5).
A correct reference solution with detailed building
physics can be obtained using the ModelExchangefunctionality of the building FMU and the Modelica-based
equipment model. Generation of a correct reference solution depends on the following assumptions:

 building FMU correctly implements the ModelExchange interface and internal room physics,
 ModelExchange master correctly implements time
integration with error checking,
 Modelica model is correctly solved within the environment.
As Modelica simulation environment and ModelExchange
master we use the SimulationX11 software, which has a
comprehensive quality testing procedure to ensure correctness of Modelica and FMI master implementation. Our
own NANDRAD implementation is tested against standard and customized dynamic test scenarios, and also
compared to the thermal room model THERAKLES12 .
Given these testing procedures, we are confident that
the results of the ModelExchange calculation will be correct and can be used to evaluate the quality of the CoSimulation runs.

Modelica Stand-Alone
ModelExchange

Air Temperature [C]

23

22

21

20

19
0

5

10

15

20

25

30

Real time [d]

Figure 5. Comparison of reference ModelExchange solution
with Modelica-only variant, using SimulationX for both simulations

FMU is used for later Co-Simulation testing. The FMU
was imported into SimulationX (version 3.7), connected
manually to the plant model and simulated with the SimulationX internal solver (CVODE solver, sparse Jacobian).
The fully coupled ModelExchange simulation is a fairly
small problem and was simulated in acceptable time. The
results were then compared to the stand-alone simplified
Modelica variant and showed good agreement (Figure 5).
We also did not expect much difference, since the singlelayer constructions with high thermal conductance will be
reasonably well approximated by the mean thermal resistance approach used by the Modelica model.
For the office room model, we use the ModelExchange
reference solution for the subsequent Co-Simulation tests.
However, for larger buildings (more than one hundred
zones) the procedure of using ModelExchange for simulation fails, because already the symbolic analysis takes
excessive time. For example, in the case of the appartment
complex the symbolic analysis was not yet finished after
three days.

5.3

Co-Simulation Variants

For the Co-Simulation approach, we exported the Modelica plant model from SimulationX into an FMU for
Co-Simulation, version 2, hereby using the CVODE integrator option and numerical Jacobian generation method.
Then, we ran the coupled simulation between the plant
and building simulation FMUs with MASTERSIM13 . We
5.2.1 ModelExchange Reference Simulation
developed this open-source Co-Simulation master impleA first step in generating this reference solution was to ex- mentation specifically for testing and evaluation of buildport the NANDRAD model as FMU for ModelExchange. ing simulation applications.
Since NANDRAD exports a single FMU with both CoSimulation and ModelExchange specification, the same 5.3.1 Non-Iterating Gauss-Jacobi with Fixed StepSize (only FMI v1)
11 https://www.simulationx.de
12 See
http://bauklimatik-dresden.de/therakles.
THERAKLES was used in the test case as plugin alternative to
NANDRAD and gave the same results for this single-zone model
problem.

DOI
10.3384/ecp1713263

The most trivial approach to Co-Simulation is the use
of the Gauss-Jacobi algorithm without iteration and fixed
13 http://mastersim.sourceforge.net

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

69

Co-Simulation between detailed building energy performance simulation and Modelica HVAC component
models

23

Air Temperature [C]

23

Air Temperature [C]

Gauss-Jacobi
Gauss-Seidel
ModelExchange

Gauss-Jacobi 10 min
Gauss-Jacobi 1 min
ModelExchange

22

21

20

19

22

21

20

19
0

5

10

15

20

25

30

0

5

10

15

20

25

30

Real time [d]

Real time [d]

Figure 6. Gauss-Jacobi, non-iterating, fixed communication step sizes (ModelExchange results from SimulationX, CoSimulation results calculated with MASTERSIM)

Figure 7. Comparison of non-iterating Gauss-Jacobi and GaussSeidel calculation for a fixed communication step of 1 minute
(Co-Simulation cases done with MASTERSIM)

time step. This algorithm does not require any FMI v2
features and is thus the most compatible.
For the office room case the simulation was done with
a fixed communication step size of 10 and 1 minutes. For
both variants, stability problems appear. Figure 6 shows
computed room mean air temperatures for the first weeks
of the annual simulation.
The two Co-Simulation variants are plotted vs. the reference solution and clearly show unphysical oscillations,
even at times when heating setpoints are constant. Source
of the problem is the delayed reaction of the plant FMU
on changes in room air temperature. Whenever the room
temperature crosses the setpoint temperature during the
course of the communication interval, the plant loop continues calculating based on outdated information. Specifically, when room temperature increases above setpoint
temperature, the heating system still provides heat to the
room based on previous room air temperature information. During cooling, the heating system remains off for
too long, allowing the room air temperature to drop below
the setpoint temperature. As expected, reducing the communcation step size also reduces magnitude of observed
oscillations.
Using SimulationX as Co-Simulation master with same
time steppings gave nearly identical results compared to
MASTERSIM. Thus, we have confidence in correct behavior of the building and HVAC system FMUs.

Despite the notable improvement, even Gauss-Seidel
does not provide sufficiently accurate results. Lowering
the time step will of course improve results, but at the cost
of reduced simulation performance. In practical applications the user would have to guess the communication interval and refine it in the case of stability/accuracy problems. Recognizing incorrect results may not always be
easy, especially since for realistic application scenarios a
reference solution does not exist. Therefore, it would be
desirable to automatically adjust the time step such that
results are within acceptable tolerances.

5.3.2

Non-Iterating Gauss-Seidel with Fixed StepSize
(only FMI v1)

An attempt at improving the solution was made by using
the Gauss-Seidel algorithm, again with fixed step size and
no iteration. Hereby, the building FMU is been given updated plant FMU results when integrated in the same step.
Figure 7 shows a comparison between a Gauss-Seidel and
Gauss-Jacobi simulation using the same communication
step size.
70

5.3.3 Adaptive Communication Step Size
We implemented the step-doubling technique in
MASTERSIM as adaptive communication step method
(Clau et al., 2017). Clau discusses such an approach within in context of FMI Co-Simulation. The
error tests uses the weighted root mean square norm
of all communicated real variables. When this algorithm is used, all FMUs must have the capability
canGetAndSetFMUstate and formally implement
version 2 of the FMI standard. The algorithm begins
with storing the current FMU states, followed by a full
communication step calculation. The results are cached,
FMUs are set back and two subsequent communication
steps of half length are computed. The result of the single
step and the double-step calculation are used as a measure
for the local truncation error. With this approach, each
step, even if successful, requires 3 FMU evaluations
compared to one FMU evaluation without error test.
Three simulations cases were run: Gauss-Jacobi and
Gauss-Seidel methods, each with only one evaluation (no
iteration), and the last with Gauss-Seidel allowing three iterations. All tests were done with a relative tolerance and
an absolute tolerance of 105 . The latter may be important since thermal loads, the output variables of the plant
FMU, can go down to zero.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713263

Session 4B: Buildings I

Gauss-Jacobi
Gauss-Seidel non-iterating
Gauss-Seidel iterating
ModelExchange

Communication Step Size [s]

Air Temperature [C]

23

10

22

21

20

Gauss-Jacobi
Gauss-Seidel non-iterating
Gauss-Seidel iterating

4

103

10

2

101

100

10

-1

10-2

19
0

5

10

15

20

25

30

0.5

0.55

0.6

0.65

0.7

0.75

0.8

Real time [d]

Real time [d]

Figure 8. Comparison of non-iterating Gauss-Jacobi and GaussSeidel calculation variants with adaptive communcation step
sizes (Co-Simulation cases done with MASTERSIM)

Figure 9. Illustration of step-size variation with adaptive time
step methods within the first day of simulation.

6
When time step sizes fall below 1 s, iteration is disabled. This is a fallback criterion in MASTERSIM in order to avoid useless iterations in case of encountered discontinuities. Changing this value may also change performance of the simulation, but not impact accuracy of
results.
Figure 8 shows the results obtained with variable step
sizes for non-iterating cases. The results are now within
the requested tolerance limit and are, with very few exceptions, nearly identical to the ModelExchange variant.
The simulation time, however, has increased substantially
compared to the incorrect fixed step variants.
Table 1 shows the statistics obtained from the three
cases. For the first two cases iteration is not used, hence
no convergence failures were recorded. Error test failures
occurred about three times more frequent for the GaussJacobi variant, which resulted in a drastic reduction of average time step sizes and similar increase of simulation
time. The step sizes were sometimes reduced drastically
to 107 s. Figure 9 illustrates the strong variations in time
step. For the Gauss-Jacobi simulation, the time step varies
permanently over several orders of magnitude. For all
variants, when the heating system has been turned off at
0.75 d (6:00 pm), the time steps increase again up to the
allowed maximum of 15 minutes. This is important for
increasing overall simulation performance.
Interesting is the comparison between iterating and
non-iterating Gauss-Seidel. Apparently, even with three
iterations often a situation is encountered, that GaussSeidel cannot resolve. In these cases time step sizes were
reduced due to convergence errors, which in turn reduced
the number of error test failures. With this stabilitydominated simulation case, use of the iterating GaussSeidel approach is not meaningful.
DOI
10.3384/ecp1713263

Summary and Conclusion

We presented the tasks necessary to successfully run a
coupled building energy performance simulation using the
FMI standard. We discussed the physical interface between plant and building FMU, the process of generating
the building FMU itself and its internal interface implementation. In realistic cases buildings may have a large
number of conditioned zones, resulting in many input and
output variables. Therefore, we presented an approach for
improving usability by automatically generating Modelica
helper components. Further, we showed one example application for a single zone model and tested different CoSimulation algorithms for accuracy and simulation performance.
In the test case we used an ideal heating system. The
strong coupling between building and plant FMU caused
stability problems for fixed-step solvers. These could be
controlled by use of an adaptive communcation time step,
based on local error estimates. The non-iterating GaussJacobi method performed poorly compared to the noniterating Gauss-Seidel method. Iteration, tested with the
case of Gauss-Seidel, did not improve simulation performance. Without iteration, stability problem were detected
by the error test, with iteration these stability problems often caused conversions failures. In either case communcation step sizes were reduced. However, in all variants the
error test and communcation time step adjustment method
yielded results of acceptable quality.
In our test case, the iterative Gauss-Seidel method
failed frequently due to stability problems. Therefore, using Gauss-Seidel or Gauss-Jacobi iteration is not meaningful for such strongly coupled cases.
The observed behavior and conclusions drawn from the
simulations are of course only an indication of general behavior. In particular, the ideal plant model and control
method in conjunction with a strong thermal response of
the building are definitely an extreme case. Still, success-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

71

Co-Simulation between detailed building energy performance simulation and Modelica HVAC component
models
Table 1. Simulation statistics obtained with adaptive step simulations
Method
ModelExchange
Gauss Jacobi non-iterating
Gauss Seidel non-iterating
Gauss Seidel iterating

Comm.

Steps

1984803
827616
1595677

Error Test Fails

590539
146637
4003

Convergence Fails



809681

Simulation Time
54 min
25 min
10 min
28 min

ful simulation was possible by use of time step adjustment, Alan C. Hindmarsh, Peter N. Brown, Keith E. Grant, Steven L.
Lee, Radu Serban, Dan E. Shumaker, and Carol S. Woodand the method and approach itself is suitable for general
ward. SUNDIALS: Suite of nonlinear and differential/algeapplication.
braic equation solvers. ACM Transactions on Mathematical
To achieve this, the following requirements on FMU
Software, 31(3):363396, 2005.
and master simulator must be fulfilled:

 the solvers within the building and plant FMU must
implement an error test procedure to give consistent
results,
 the FMUs must implement FMI standard version 2
with capability to set and get their states, and

Sanford A. Klein, William A. Beckman, and John A. Duffie.
TRNSYS - A Transient Simulation Program. ASHRAE Transactions, 82(1):623633, 1976.
Andreas Nicolai.
Physikalische Grundlagen des thermischen Raummodells THERAKLES, 2013.
URL
http://nbn-resolving.de/urn:nbn:de:bsz:
14-qucosa-102112.

 the Co-Simulation master must support communica- Andreas Nicolai and Anne Paepcke. Die Gebudesimulationsplattform NANDRAD - Physikalisches Modell, Umsettion time step adjustment based on local error estizungskonzept und Technologien im berblick. In Proceedmates.
ings of the BauSIM 2012, 2012.

It has to be noted, though, that our conclusions are spe- Andreas Nicolai and Anne Paepcke.
Transformation
cific to the idealistic HVAC system used and observations
der Gebudeenergiesimulation NANDRAD mit variablem
may be different when dealing with detailed HVAC sysZeitschrittlser in eine FMU fr Co-Simulation. In Proceedings of the BauSIM 2016, 2016.
tem models for modern integrated buildings.
For practical applications, overall simulation perforChristoph Nytsch-Geusen, Jrg Huber, Manuel Ljubijankic,
mance remains a crucial criterion. Considering the still
and Jrg Rdler. Modelica BuildingSystems  eine Modlong simulation times when applying Co-Simulation, furellbibliothek zur Simulation komplexer energietechnischer
ther work is required with regard to finding suitable physiGebudesysteme. Bauphysik, 35(1):2129, 2013.
cal interfaces, choice of master algorithms and algorithmic
Anne Paepcke and Andreas Nicolai. Anlagenregelung in ODEparameters.
Systemen am Beispiel der thermischen Raum- und Gebudesimulation. In Proceedings of the BauSIM 2014, 2014.

Acknowledgements

We gratefully acknowledge the support and funding re- Anne Paepcke, Torsten Schwan, and Andreas Nicolai.
ceived from the German Federal Ministery for EcoSchnittstellen fr die Co-Simulationskopplung zwischen
Gebude- und Heizungsanlagensimulation. In Proceedings
nomic Affairs and Energy in the research project Enof the BauSIM 2016, 2016.
Tool:CoSim #03ET1215A F-002792.

References
FMI 2.0 Standard, 2014. Functional Mock-up Interface for
Model Exchange and Co-Simulation.
Christoph Clau, Kristin Majetta, and Richard Meyer. Application of Richardson Extrapolation to the Co-Simulation of
FMUs from Building Simulation. In Proceedings of the 12th
international Modelica Conference, 2017.
William.S. Dols, Wang Liangzhu, Steven J. Emmerich, and
Brian J. Polidoro. Development and Application of an Updated Whole-Building Coupled Thermal, Airflow, and Contaminant Transport Simulation Program (TRNSYS/CONTAM). Journal of Building Performance Simulation, 8(5):
326337, 2014.

72

Per Sahlin, Lars Eriksson, Pavel Grozman, Hans Johnsson,
Alexander Shapovalov, and Mika Vuolle. Whole-building
simulation with symbolic DAE equations and general purpose solvers. Building and Environment, 39:949958, 2004.
Michael Wetter. A Modelica-based model library for building
energy and control systems. In Proceedings of the 11th IBPSA
Conference, 2009.
Michael Wetter, Christoph van Treeck, and Jan Hensen. IEA
EBC Annex 60: New generation computational tools for
building and community energy systems. Technical report,
Lawrence Berkeley National Laboratory, 2013.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713263

Aspects of FMI in Building Simulation
Dipl.-Ing. Torsten Schwan1
1

Dipl.-Ing. Ren Unger1

EA Systems Dresden GmbH, Germany, {torsten.schwan,rene.unger}@ea-energie.de
2
ESI ITI GmbH, Germany, Joerg.Pipiorke@esi-group.com

Abstract
Building physics and HVAC system simulation have
become an important usage scenario of the Modelica
modeling language and related simulation tools since
the publication of first adequate libraries (Wetter,
2009). In 2010, the tool independent standard FMI was
published in version 1.0. It enables the exchange of
models between different simulation tools and even
different modeling approaches. Although, automotive
industry mainly initiated the FMI development, it can
extensively benefit building simulation, too.
This paper describes four completely different
applications of FMI in the building simulation
environment which even extend the basic idea of
simple model exchange. This includes the description
of developed models as well as additionally required
software components implementing the FMI standard.
Keywords: Building Simulation, FMI, Model-in-theloop, Controller Test

1

B.A. Jrg Pipiorke2

Introduction

The versatile modeling language Modelica enables
engineers to model and simulate complex multiphysical problems in a wide range of different
domains. Although it has been growing in the
automotive industry during the late 1990s and 2000s
building engineers (mainly HVAC and building
physics specialists) more and more use Modelica for
their purposes as well.
Since the first publications of building physics and
HVAC system related Modelica libraries in 2009, a
wide range of different modeling approaches have been
developed. Most of them are freely available under
open-source license. Some are more commercial and
only partly open-source.
One of the main open-source representatives of
building modeling libraries is the Modelica Buildings
library of LBNL (Wetter, 2009). This constantly
refined library is based on Modelica Fluid library. It
focuses on detailed modeling of heating, ventilation
and air conditioning systems together with detailed
thermal room models. Further open-source library
examples with similar modeling approaches and
objectives are the Modelica Building library of RWTH
Aachen (Lauster, 2012) and the Modelica

DOI
10.3384/ecp1713273

BuildingSystems library of UdK Berlin (NytschGeusen et. al., 2012). Today, these libraries as well as
further similar derivatives are mainly dedicated to the
worldwide growing academic community of building
systems engineers and researchers.
Further commercial but partly open-source libraries
like ESI ITIs Green Building (Unger et. al., 2012) and
its latest derivative Green City (Schwan et. al., 2016)
focus on integrated planning of sustainable and
profitable solutions of buildings and even whole
cities heat, cold and power supply.
Besides the Modelica language and derived libraries
the Modelica Association has been supporting the MA
Project Functional Mockup Interface (FMI) since its
publication in 2010 as well. The FMI 1.0 standard was
developed by 29 partners in the MODELISAR project
between 2008 and 2011. In this ITEA 2 European
project mainly the automotive industry forced the
development of a tool independent model exchange
standard. The FMI 2.0 standard followed these first
developments with its publication in 2014.
The FMI standard in both versions enables
engineers to exchange or co-simulate dynamic models
of different domains. This way, FMI can extend the
field of application of building and energy system
simulation. It can furthermore help to overcome current
and future limits of simulation.
Integrated planning processes more and more use
accurate building physics and HVAC system models
based on any kind of public or in-house library. Their
main task is currently the simulation of different
variants of complex building and energy system
structures. This way, engineers make feasibility studies
and profitableness analyzes of different system
configurations. This application of building systems
related Modelica libraries does not basically require
FMI.
However, there is a wide range of further fields of
application and benefits of Modelica in the building
simulation environment. This paper describes four
sample applications of FMI during integrated planning
processes.
The first example supports the development of a
high-level building control system including weather
forecast and user prediction to optimize ecological
footprint of a sophisticated multivalent HVAC system
in a school and sports complex. This way, FMI

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

73

Aspects of FMI in Building Simulation

Building heat,
cold and power
consumption

Multivalent heating and
cooling system incl.
renewables and storages

Coupling-FMU
Figure 1: Modelica simulation model of the school and sports complex including coupling-FMU to external controller
software (Wicke et. al., 2014)

provides the basics of a software-in-the-loop test stand
of iteratively learning control software.
In the second example FMI provides the
communication between a real-world HVAC system
component (i.e. micro combined heat and power unit)
and a complex model of the virtually connected
building and hydronic heating system. This way, FMI
represents the basic part of modern hardware-in-theloop test stand.
The third example uses FMI to integrate a fastcalculating simulation model in a complex virtual
power plant controller. In this model-in-the-loop
structure the functional mockup unit of the Modelica
model helps to identify optimal operation strategies of
complex diversified power plants.
The last application uses FMI to combine
advantages of different simulation platforms including
individually optimized numerical solvers. This way,
FMI couples highly-optimized hygrothermal multizone building models with easy-to-use Modelica
HVAC system models. In this case, FMI helps to
separate stiff ODE systems with heavily varying time
constants.

74

2

Example 1  Software-in-the-Loop

In a small town in northern Bavaria (Germany) a local
architect wants to transfer the local 1970s school and
sports complex to a future 2040s energetic level.
HVAC engineers therefore planned a sophisticated
multivalent heat, cold and power supply system
including heat pumps, cogeneration units and backup
gas-fired condensing boilers as heat supply. Main heat
and power source are large-scale solar thermal
absorbers and photovoltaic fields. Besides an
integrated waste-water heat recovery system the
integration of three different storage types (stratified
heat storage, cold storage and ice storage) helps to
balance daily and seasonal differences between energy
consumption and production (Wicke et. al., 2014).
However, this quite complex HVAC system
additionally requires smart control algorithms because
of the higher degree of freedom. But such iteratively
learning, optimality-based control software needs
sufficient testing.
The developed controller and optimization software
is based on an existing Python Framework. To provide
the software engineers a suitable software-in-the-loop

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713273

Session 4B: Buildings I

Single-family home with
ground and first floor as
well as roof

Renewables, Storages and
eMobility

Bivalent heating system incl.
space heating and domestic
hot water supply

Coupling-FMU

Figure 2: Modelica model the single-family-home including coupling-FMU to a real-world mCHP (Unger et. al., 2012)

test environment, a Modelica model of the developed
HVAC system including the building complexs heat,
cold and power demand is coupled to this Pythonbased controller software. This software-in-the-loop
test bench uses the pyFMI-framework in the software
and an automatically created coupling-FMU in the
model (c.f. Figure 1) to establish a variable step size
communication via TCP/IP protocol between model
and software. This way, controller software and
simulation model can run on different computer
devices or even at different places.
The generation of the coupling FMU runs
automatically using newly implemented FMU
generator software in java. This software uses an
external csv-file to define the required coupling
interface (inputs and outputs of coupling FMU)
between controller software and test model.
Software-in-the-loop tests of new controller
software require extensive scrutinizing regarding
internal controller timings, especially in combination
with PI or PID controllers. The integrator time
constants have great influence on later robustness.
Building simulation models normally run (much) faster
than real-time to provide sufficient results (at least one
year) within adequate time periods. Those time
constants therefore have to be adapted regarding
communication time steps as well as a constantly
synchronized real-time factor.

3

Example 2  Hardware-in-the-Loop

Existing complex building structures, like the school
and sports complex in Figure 1, require smart solutions

DOI
10.3384/ecp1713273

for energetic renovations. But also smaller buildings,
like simple single-family homes, require holistic
optimization approaches of heat and power supply.
Photovoltaic and cogeneration units this way enable
massive reductions of overall annual power
consumption with manageable investment costs.
Photovoltaic (PV) modules provide renewable
power and small cogeneration modules (so-called
micro combined heat and power units  mCHPs)
utilize synergy effects of heat and power production.
To enable a wide range of different system
configurations as well as an ongoing system
optimization CHP and PV manufactures have to
constantly improve their products. This includes
controller software as well as hardware components.
But reliable developments again require sufficient
testing. Hardware tests of single system components
can use simple test stand configurations (e.g. mCHP 
heat storage, controlled recooling) and generically
calculated heat and power load profiles. But dynamic
tests of hardware and software with evaluated realworld-conditions need further expenses.
This way, Modelica models in combination with
FMI can again help to provide an easy-to-use platform
for hardware-in-the-loop tests. Figure 2 shows a simple
example of a developed single-family home model for
a hardware-in-the-loop test of a small mCHP. This
single-family home model includes heat and power
consumption of a small house (3-thermal zones),
renewable power production and storage by
photovoltaic modules, a battery and a connected
eVehicle charging infrastructure. Heat is supplied by a
2.5 kW mCHp with 1.0 kW power output and a peak-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

75

Aspects of FMI in Building Simulation

District heating grid with
connected buildings
Thermal power plant with
cogeneration

Local utilitys power grid including largescale wind parks and photovoltaic fields

Figure 3: Modelica model of a simple district heating grid with cogeneration plant and superior electric grid connection
(Schwan et. al., 2016)

power gas-fired condensing boiler (Unger et. al.,
2012).
The real-world counterpart of the mCHP is
connected to the model via a specific coupling FMU.
This again automatically created FMU connects realworld measurement sensors (heat and power sensors of
the mCHP) with the model. Measured heat and power
is added as additional heat and power supply to the
building. The mCHP controller gets temperature
measurements of the simulated building (ground and
first floor) and the heat storage to start and stop the
real-world mCHP engine. Furthermore, the mCHP
controller decides to run the simulated peak-power
boiler if reference temperatures are underrun.
The required coupling FMU (c.f. Figure 2) couples
Modelica inputs and outputs in the model with realworld digital and analogue signals of the mCHP
controller. Therefore, the FMU internally converts
model variables into TCP/IP protocol compatible
signals. These signals are interchanged between the
simulation computer unit and the local PLC
(Programmable Logic Controller) of the hardware-inthe-loop test stand. This PLC directly communicates
with the mCHP controller via a system specific
communication bus (e.g. Modbus). Heat supply to
recooler and power supply to test stands grid are
measured with electronic sensors which send back the
measurement data to the model.

76

This configuration represents a simple closed-loop
hardware-in-the-loop test stand based on Modelica
models and FMI. Again timing balance between realworld-time and simulation time is highly important. In
opposite to the software-in-the-loop approach a
hardware-in-the-loop test stand cannot easily be
accelerated. It requires rigid real-time synchronization
between model and device under test. This avoids the
adaption of controller-internal timing constants.
Fortunately, building physics and HVAC system
models mostly are (much) faster-than-real-time. Model
acceleration is not necessary. The model even has to be
stopped after each communication step to synchronize
simulation time and real-world time.

4

Example 3  Model-in-the-Loop

Modelica models as well as the Functional Mockup
Interface standard will be a major part of future
sophisticated test stands (both hardware- and softwarein-the-loop) in the building sector. However, both
provide more potential to improve the current situation
of planners and engineers in this environment.
FMI was developed to provide an independent
model exchange and co-simulation standard. Besides
using FMI as a pseudo data exchange interface,
Modelica models of sophisticated building and HVAC
system structures can also be exported as standalone
FMUs.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713273

Session 4B: Buildings I

Townhouse with
ground and first floor

Monovalent heating system
with geothermal heat pump

Building-FMU Adapter

Building-FMU

Figure 4: Coupling of a Modelica HVAC system model (SimulationX/Green City) with a TU Dresden building-FMU
based on the building physics simulation tool Nandrad (Paepcke et. al., 2016)
The integration of these FMUs in upcoming modelresulting add-on costs. This requires though highlyin-the loop controller architectures (e.g. Virtual Power
accurate prediction of available storage capacities.
Plant Controller  c.f. Schwan et. al., 2016) helps
The integration of accurate but fast calculating
building engineers to design optimality-based
simulation models of those grids in energy trading tool
controllers which can increase overall system
chains and corresponding system controllers (e.g.
efficiency without major extra investment costs.
controller of a cogeneration plant) increases profit
Figure 3 shows such a simple Modelica model based
reliability at the balancing energy exchange. Therefore,
on ESI ITIs Green City library. It represents a highlythese models are exported including a suitable
simplified model of a cold district heating grid with
numerical solver as independent FMUs.
decentral heat pumps, a thermal power plant with
Then, these FMUs are simulated for comparatively
cogeneration and the local utilitys power grid
short time periods (i.e. few days ahead) to identify
including wind parks and photovoltaic fields. This
maximum profit margins regarding different upcoming
system is a role-model of a future part of a virtual
weather conditions as well as expected power and heat
power plant which provides balancing power to the
consumption profiles.
transmission grids via energy exchange (EEX).
In this model-in-the-loop configuration the models
Available heat storage capacities in the district the
must run much-faster-than-real-time to enable the
heating grid provide virtual storage capacities for
evaluation of a great number of different input
renewable power surplus of wind parks or photovoltaic
parameter sets and influencing characteristics.
(i.e. negative balancing power). Furthermore, decentral
Synchronization is not needed because the controller
heat pumps can partly run as renewable energy dump
only uses the accumulated simulation results.
as well by utilizing each buildings thermal capacity. In
times of grid deficits, the district heating grid reduces
5 Example 4  Co-Simulation
the power consumption of the heat pump and the
All three previously shown FMI applications in the
cogeneration plant provides positive balancing energy.
building sector mainly use the standard to provide
These strategies will help to decarbonize overall
sophisticated test scenarios or to optimize controller
energy supply of buildings in the future. However,
functionality. However, FMI is also applicable in this
such concepts require major investments and
environment in its inherent manner, a model exchange
refinancing is not possible with diminishing energy
and co-simulation standard.
profits. But the sale of balancing energy at the energy
Complex building models combine a vast number of
exchange (c.f. EEX) will help to partly compensate
different physical components with highly diversified

DOI
10.3384/ecp1713273

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

77

Aspects of FMI in Building Simulation

time constants. Building physics mainly represent slow
processes. Heating up or cooling down walls or whole
buildings need several hours to several days depending
on thermal inertia and available heating/cooling system
configurations. Power supply of renewables, e.g.
photovoltaic modules or wind power plants, can
fluctuate within several seconds or few minutes
depending on cloudiness and surrounding shadings.
Inverter controllers of photovoltaic, batteries or even
eMobility charging stations can react within a few
seconds regarding available measurements (e.g.
inhabitants individual power consumption in a
dwelling house).
This great variety of time constants can cause very
stiff ODE systems in one Modelica model. But FMI
enables to separate models regarding different time
constants or to combine the strength of different
simulation tools and solvers. Coupled models can cosimulate specialized building physics models with
highly optimized PDE solvers (e.g. heat and moisture
transport through walls) together with fast and accurate
HVAC system models in Modelica and its therefore
optimized ODE solvers.
Figure 4 therefore shows the coupling between
Modelica HVAC system models based on ESI ITIs
Green City library coupled to a townhouse building
physics model in TU Dresdens Nandrad simulation
environment (Paepcke et. al, 2016). This way, a
Modelica simulation environment imports the
Building-FMU created in Nandrad as an additional
model component. The townhouse model consists of
two thermal zones representing ground and first floor.
The HVAC system includes a monovalent heat pump
and a heat storage which provides the heat to the two
hydronic heating circuits.
However, both FMI 1.0 and FMI 2.0 only allow
scalar interface variables (inputs and outputs). But
especially complex building physics models require a
high number of common interface variables (e.g.
indoor temperatures and temperature set points of all
thermal zones or rooms). Therefore, Nandrad
additionally provides a building-FMU adapter which
automatically connects the bus interfaces in the
Modelica model with the vast number of scalar inputs
and outputs of the building-FMU.
On the one hand, this approach provides an interface
between a Modelica HVAC system model and an
imported building physics model. Co-simulation this
way uses basic master algorithms of the available
Modelica simulation environments, like ESI ITIs
SimulationX. On the other hand, the HVAC system
model including the required adapter can be exported
as standalone FMU, too. This way, co-simulation
between two or more FMUs can use more specialized
master algorithms (Clau et. al., 2016) to optimize
simulation speed and accuracy. This can furthermore
improve the tradeoff between increase of simulation

78

speed by usage of several individually optimized
solvers and speed reduction by adding additional
communication time between the FMUs.

6

Conclusion

This paper presents an overview of different fields of
application of Functional Mockup Interface standard in
the building simulation environment. Building and
HVAC system simulations currently become one major
domain of the Modelica language including an
increasing number of available academic and
commercial libraries.
The Modelica community also focuses on coupling
of different models as well as software and hardware
components to utilize synergy effects and to extend
Modelicas fields of application (e.g. BCVTB Nouidui et. al., 2014). Because of its tool independency, its industrial support and its adjustability to
latest network and internet technologies, the FMI
standard and its upcoming updates will help to
integrate Modelica in all design, test and validation
processes in the building sector within the next years.

References
M. Wetter. A Modelica-based model library for building
energy and control systems, 11th International IBPSA
Conference, Glasgow, 2009.
M. Lauster. Modelica Building Library and Building Models.
Symposium on Integrated Planning and Simulation in
Building Physics and Technology. Dresden, 2012.
C. Nytsch-Geusen, J. Huber, M. Ljubijunkic, J. Rdler.
Modelica-BuildingSystems  A Simulation Library of
complex Building Energy Systems. BauSIM, Berlin, 2012.
R. Unger, T. Schwan, B. Mikoleit, B. Bker, C. Kehrer, T.
Rodemann. Green Building  Modelling renewable
building energy systems and electric mobility concepts
using Modelica. 9th International Modelica Conference,
Munich, 2012.
T. Schwan, R. Unger. Holistic District Heating Grid Design
with SimulationX / Green City. ESI SimulationX User
Forum, Dresden, 2016.
M. Wicke, T. Schwan, R. Unger. Model-based design of
control strategies for a sophisticated building energy
system in a school and sports complex. 17th ITI
Symposium, Dresden, 2014.

A. Paepcke, A. Nicolai, T. Schwan. Interfaces of CoSimulation Coupling between Building and Heating
System Simulation. Central European Symposium on
Building Physics, Dresden, 2016.
C. Clau, K. Majetta, R. Meyer. Development of Simulator
Coupling Algorithms using FMI Interface for Building
Simulation Applications. Central European Symposium

on Building Physics, Dresden, 2016.
T. S. Nouidui, M. Wetter. Tool coupling for the design and
operation of building energy and control systems based on
the Functional Mock-up Interface standard. 10th
International Modelica Conference, Lund, 2014.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713273

Application of Richardson Extrapolation to the Co-Simulation of
FMUs from Building Simulation
Christoph Clau, Kristin Majetta, Richard Meyer
Fraunhofer IIS EAS, Zeunerstrae 38, D-01069 Dresden, GERMANY
christoph@clauss-it.com, {kristin.majetta, richard.meyer}@eas.iis.fraunhofer.de

Abstract
The application of the FMI technology gains ground in
building simulation. As far as specialized tools support
the FMI simulator coupling becomes an important
option to simulate complex building models. Cosimulation needs a master algorithm which controls the
communication time steps as well as the signal
exchange between FMUs. Often a constant
communication step size is applied chosen by the user.
The Richardson extrapolation approach allows variable
master step sizes. An extension of this approach is
presented, and the method is applied to both academic
test examples as well as examples of building simulation
which co-simulate FMUs from NANDRAD and
SimulationX. Although variable step size control could
improve the performance this cannot be observed at the
building simulation examples presented. But
Richardson extrapolation turns out to guarantee finding
an appropriate step size at the prize of downgraded
performance.
Keywords: Building Simulation, FMI, Co-Simulation,
Richardson Extrapolation, Variable Time Step Size

1

Introduction

In order to reduce the primary energy production by
both reduction the consumption in buildings and
growing the portion of renewable energy a much higher
knowledge of the dynamic energy and mass fluxes is
essential. Especially the daily and hourly fluctuations of
sun and wind based energy generation require detailed
dynamic considerations by simulation. Since the first
publication of the FMI standard well established
simulation tools have been improved to support FMI
both for model exchange and for co-simulation. This
allows the combination of dedicated tools as well as
their model libraries which contain results of a long
period of investigations. Basing on tool as well as model
combination by co-simulation a big step to generate
detailed simulation results was managed.
Modern buildings typically are divided into the proper
building (walls, roof, windows , thermal, hygric
behavior), HVAC (heating, ventilation, air conditioning
devices), and often a central acting control software
(building energy management systems, BEMS). Within

DOI
10.3384/ecp1713279

the German research project EnTool:CoSim the tools
NANDRAD [Nicolai, 2012] for building simulation,
and the Modelica simulation tool SimulationX [ESI ITI
GmbH] for mainly HVAC and control simulation were
prepared to export FMUs for co-simulation. Since the
FMI standard does not offer dedicated master
algorithms which control the coordinated simulation of
different FMUs, master algorithms have been
investigated and implemented [Bastian. 2011]. So far
master algorithms with a constant step size were
considered mostly. FMUs generated from SimulationX
for HVAC models often have a higher performance than
building FMUs generated by NANDRAD. Furthermore,
different activity ranges can be recognized (less
activity at night, weekend, less heating in summer ).
The required time intervals to be simulated can be very
long (years). Often the user is overstrained to define a
suitable master step size, especially if the co-simulation
method shall leave the research area to be applied in
building practice. These issues as well as the hope for
improved performance suggested the investigation of
variable step size master algorithms, and furthermore
asynchronous algorithms. In this paper results of the
investigation of synchronous variable step size
algorithms are presented. After the introduction of
Richardson extrapolation methods some small academic
test examples are presented, followed by three building
simulations of different complexity which apply
Richardson extrapolation.

2

Algorithms

The task of co-simulation of  Simulators (FMUs) can
be described according to (1) with  , ( = 1. . . ) being
the simulators.  and  are matrices which project the
output values of  into, and the input values of  out of
the vector of coupling values ()[0, ]    . The
argument   is missing if the simulator  lacks input
values. In [Petridis, 2015] this description is derived,
and basic solution methods for cycles are presented
there.


=

   ( )  
=1
 

{  ( )

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(1)

   

79

Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation

The projector  takes the input values of the simulator
 out of the coupling values . The simulator 
calculates its output values which are written into the
coupling value vector  via  . Since all coupling values
 are output values of exactly one simulator, and since
no output value is input of the same simulator the
summarizing is possible. This is described in the first
line of (1). The second line clarifies that simulators
without output values also have to be called.
Due to the FMI-intention the interval [0, ] is divided
into communication intervals [0, ] = [ , +1 ]
with  being the   communication point, and
 = +1   the communication step size.
The communication step size can be chosen
synchronously by calling each simulator with the same
step size, or asynchronously by using individual step
sizes for each simulator. Otherwise, the step size can be
constant, or it can vary. Both properties are independent
from each other. In this paper Richardson extrapolation
is applied as a method of variable but synchronous step
size control.

Figure 1. Richardson extrapolation

According to [Hairer, 1993], [Schierz, 2013] the
Richardson extrapolation algorithm consists of the
following steps (Figure 1):
1) Start at  , and simulate two steps using the step
same size  which results in the coupling
variables  +2 . At the first step 0 is provided by
the user. For following steps  is calculated by
previous steps.
2) Roll back to  and simulate one step using the
doubled step size 2 which results in  +2.
3) Calculate an individual error estimation for each
coupling variable ( = 1. . . ) with  being the
degree of the interpolation polynomial of input
values:
 = (+2  +2 )(1  2+1 )
(2)
4) Calculate a total error estimation according to
1





 + |+2 |

 =  
=1 (

2

)

(3)

5) Calculate the new step size  according to
 =   { ,  { , 





}}

(4)

heuristic values   [1.5,5],  
[0.2,0.5], and   [0.8,0.9] prevent too strong
step size variations.  has to be  =  + 1, if there
The

are no algebraic dependencies between inputs and
outputs, otherwise  =  + 2 is necessary.
6) If   1: Both time steps are accepted, +2 =
 + 2 , +2 =  ,    + 2 , go to 1)
If  > 1: Both time steps are rejected  =
 , go to 1)
Due to the steps 2) and 6) the FMUs must be able to be
set back to a former communication time step.
Otherwise Richardson extrapolation cannot be applied.
This Richardson extrapolation algorithm assumes that
the simulators  solve DAEs, and their output variables
depend on input variables. If output variables do not
depend on input variables, but on any purely time
depending formula or algorithm, then intermediate time
steps do not at all influence the results. Even if
simulators without inputs solve DAEs their output
values are in general not influenced by the master
communication step size. For such components  of the
coupling variables  = 0 follows because of
+2 = +2. If the components  cover the vector of
coupling values totally  becomes zero, and
Richardson extrapolation cannot be applied reasonably.
In such cases the step size of the output values has to be
chosen such that simulators which take the output values
as inputs can reconstruct the output values without
losses. The step size must meet the sampling theorem
[Kotelnikov, 1933]. Therefore, a maximum
communication step size could be calculated if the
fastest frequency component of the output values is
known. Since this is not the case in general, the step size
is controlled similar to classic predictor-corrector
approaches [Hairer, 1993] by simply keeping the
deviation from linear extrapolation small (Figure 2).
The linear extrapolation of the first step is compared
with the values of the second step to generate an error
estimation. This algorithm called Linear extrapolation
algorithm throughout this paper is identical to
Richardson extrapolation except the error estimation
formula (2) of step 3), which is replaced by
 = +2  2+1 + 

(5)

The double sized step to calculate  +2 is no more
necessary there.

with  and  being absolute and relative
error limits which can be chosen individually for
each coupling variable.

80

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713279

Session 4B: Buildings I

Table 1. Equations of the precision test example
Input

Equations

Output

2

1 = 2

1

1

2
= 1 , 2 (0) = 1

   2 = 

2

Figure 2. Linear extrapolation

This way the more communication points are inserted
the more the coupling variable behavior is nonlinear. If
the behavior is linear temporarily or generally then 
also becomes zero. For such cases  gets a small
positive minimum value. It is known that this
extrapolation method on its own gives no reliable step
size control if DAEs are solved. Therefore, it is
combined with the Richardson extrapolation method to
vanishing errors in Richardson extrapolation
reasonably: At first  is calculated according to
Richardson, formula (2) within step 3). If 
vanishes (| | < 1.   12) then  is
replaced by the linear extrapolation error estimation
according to (5). This approach is called Extended
Richardson extrapolation method in this paper.
In summary three methods with variable step size
control are available:
 Richardson extrapolation comprising formula (2)
 Linear extrapolation algorithm comprising formula
(5) instead of formula (2), without the double sized
step. It does not guarantee reliable step size control
in case of DAEs.
 Extended Richardson extrapolation as a
combination of both of them
These algorithms are implemented in the EAS master
tool [Petridis, 2015] which is a proprietary tool for
testing master algorithms.

3

2


The example contains one cycle which is treated by
Newtons method. Since 2 () is differentiated, and all
coupling values depend on 2 (), the pure Richardson
extrapolation algorithm offers correct results. Two cases
of different tolerances are regarded (care for formula (3)
in the algorithm):
 Case 1 (usually default values):  = 1.   6,
and  = 1.   4
 Case 2 (higher precision):  = 1.   8, and
 = 1.   6
The limitation of the Richardson step size variation is
kept far (min 1.e-5 s, max 5 s) to not restrict the step size
choice.

Figure 3. Precision test example results case 1

In case 1 (Figure 3) the accepted step size is growing
which is expected since the solution converges to the
steady state. () is numerically near zero.
If the tolerances demand a higher accuracy (case 2,
Figure 4) () is closer to zero. The step size starts not
significantly smaller than in case 1 but does not increase
as fast as in case 1. That indicates that the smallest
possible accuracy seems to be reached using the step
size 0.1 s.

Simple Test Examples

The following simple academic examples were
developed to test features of the co-simulation
algorithm. They illustrate the implemented Richardson
extrapolation algorithms.

3.1 Precision Test Example
The precision test example presented in [Petridis 2015]
consists of three FMUs according to

Table 1. Each table line describes the equations of one
FMU. The example is designed such that () is zero.

DOI
10.3384/ecp1713279

Figure 4. Precision test example results case 2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

81

Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation

This Richardson extrapolation study advises to choose a
constant step size of about 0.01 s if a constant step size
algorithm should be used. Doing that Figure 5 shows the
reasonable result.

Figure 5. Precision test example using the constant step
size of 0.01 s

Figure 6. Linear system of equations example results
applying Richardson extrapolation

When setting the CPU time necessary in the Richardson
case 1 to be one, the normalized CPU times are listed in
Table 2. Although the step size in Richardson
extrapolation exceeds 0.01 s clearly in the second half
of the time interval, the constant step size simulation is
significantly faster than Richardson extrapolation. The
reason is that Richardson extrapolation simulates the
whole interval more than twice.
Table 2. Normalized CPU time comparison
Richardson
case 1
1

Richardson
case 2
1.14

Constant step
size 0.01 s
0.42

Figure 7. Linear system of equations example results
applying the Linear extrapolation method

3.3 Touching Mass Example

3.2 Linear System of Equations
The linear system of equations with time dependent
system matrix according to Table 3 was already
presented in [Petridis 2015].
Table 3. Linear system of equations

Similar to a bouncing ball the touching mass example
[Klein 2015] switches on a stiff spring as soon as the
mass touches the base. This accelerates the mass into
the opposite direction, and the stiff spring is switched
off when the base is left.

Equations

Out

1 = 1, 2 = ,3 = 1

1 , 3 , 3

2 , 3 , 1

31 + (0.1 + )2 + 0.23 = 1

1

Table 1 shows the equations of this example, separated
into two parts (FMUs). The spring part contains
switching as well as the calculation of the stiff spring
force .

1 , 3 , 2

0.11 + 32 + (0.1 + )3 = 2

2

Table 4. Equations of the touching mass example

1 , 2 , 3

(0.1 + )1 + 0.22 + 43 = 3

3

Input

1 , 2 , 3

1 + 2 +3 = 





In

Applying Richardson extrapolation (Figure 6) the step
size increases since each variable depends on the point
in time only. The step size does not affect the
Richardson error calculation. The values calculated at
each time step are correct indeed, but there are too less
time steps generated. This drawback is overcome
applying the Linear extrapolation time step method
instead of Richardson extrapolation (Figure 7). This
example shows that the combination of both variable
step size methods is necessary. The Extended
Richardson extrapolation method shows the same
results as the Linear extrapolation method.

82

Equations

= (0) = 10



 0.1 =   0.1(0) = 0



={

16  
0

<0
0

Output




All tests reported use Newtons method to calculate
cyclic equations. The constant step size approach needs
a very small step size to handle the reversal process
correctly. Figure 8 shows that the step size of 1.e-5 s
calculates a nearly correct result.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713279

Session 4B: Buildings I

Figure 8. Course of s(t) at different communication step
sizes

Using Richardson extrapolation (max. step size 0.1 s,
min. step size 1.e-15 s, start step size 1.e-3 s, absolute
tolerance ATol 1.e-15, relative tolerance RTol 1.e-8) the
maximum step size is used. Only to calculate the
reversal regions (see Figure 9) the step size decreased
down to about 1.e-7 s (Figure 10).

Figure 9. Reversal region calculated by Richardson
extrapolation

Figure 11. Course of s(t) with spring constant 1.e10,
constant step size 1.e-5 s

4

Application in Building Simulation

Three examples from building simulation are presented
to study the obviousness of Richardson extrapolation at
realistic use cases. The examples of different
complexity consist of two FMUs each. One FMU
describes both the heating facility and heating control
modeled using Modelica and SimulationX [ESI ITI
GmbH]. The other FMU of each example contains the
building physics description as well as weather data
using the NANDRAD tool [Nicolai, 2012] which solves
PDEs. Table 6 shows roughly the structure of all
examples.
Table 6. Macrostructure of the building examples
Input
Room
temperature,
weather

Figure 10. Varying step size using Richardson
extrapolation

Heat flow

To calculate the reversal region correctly a small step
size is necessary, otherwise the result becomes useless.
The usage of the necessary small step size over the
whole interval as a constant step size increases the CPU
time abnormally (Table 5). The varying step size
provided by Richardson extrapolation is the method of
choice. The Linear extrapolation method does not
succeed since the step size does not increase after
deceasing. The reason is still to investigate.

Equations, Tool
DAEs (heating,
heating control),
SimulationX,
Green Building,
Modelica
PDEs (building
physics),
NANDRAD

Output

Heat flow

Room
temperature,
weather

4.1 Single Room
The single room model is based on a small conference
room (up to 20 people, Figure 12).

Table 5. Normalized CPU time comparison for touching
mass example
Step size
0.01 s
1

Step size
1e-4 s
56

Step size
1e-5 s

Richardson

572

1.3

If the spring constant is 1.e10 instead of 1.e6, the
constant step size 1.e-5 s does no more show the correct
result (Figure 11). Richardson extrapolation test
calculates the expected result within a short CPU time
of less than 1s. The step size decreases to 1.8e-9 s.
This example demonstrates the importance of the
Richardson extrapolation method.

DOI
10.3384/ecp1713279

Figure 12. Meeting room on which the model is based

The room has a floor space of 52 m, and a height of 3,3
m, one outer wall (west oriented), at which ambient
conditions are applied. The boundary temperature of the
opposite wall and the ceiling is set to constantly 18 C,
for the other walls to 20 C. The four walls consist of a

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

83

Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation

heavy construction from clinker bricks and plastering,
both ceiling and floor from lightweight concrete.
Furthermore, an intermediate ceiling is included made
of papier mch. The room is equipped with a radiator
heating operating a supply temperature of 70 C. A
valve that can operate continuously between valve
position 0 and 1 regulates its volume flow.
Figure 13 shows the single room model. It consists of a
thermal zone and heating facilities. The green framed
part of Figure 13 contains both the thermal zone and the
weather source, both modeled using NANDRAD, and
therefore placed within the NANDRAD-FMU thermal
zone which solves PDEs. The remaining model part of
Figure 13 contains the heating facilities including the
controller both taken from the GreenBuilding library
[EA Systems Dresden, Unger et alt. 2012]. This model
part is written in Modelica, and exported as FMU
facility using SimulationX 3.7.4

calculate the same result (Figure 14) which does not
differ from the reference solution obtained without
coupling.

Figure 14. Room temperature and convective thermal
heat load

Figure 15. Step size variation in Richardson extrapolation

Figure 16. Step size variation in Linear extrapolation

Figure 13. Single room model

This co-simulation task of both the FMUs thermal
zone and facility has 17 coupling variables according
to Table 7. Since one of the heating power components
is zero, and the ambient variables do not depend on
inputs, there are two true coupling values which form
a cycle.
Table 7. Coupling variables of the single room example
2
2
10
2
1

variables
Heating power
Zone temperature
Ambient values
Temperature set points
Electric power
consumption

th. zone
input
output
output
output
output

facility
output
input
input
input
input

Using the Gauss-Jacobi method for solving the cyclic
equations the three step size methods
 Constant step size 60 s
 Richardson extrapolation
(tstepMax: 3600 s, tstepMin: 1 s, tstepStart: 60 s,
default accuracy ATol: 1e-6, RTol: 1e-4)
 Linear extrapolation
(tstepMax: 3600 s, tstepMin: 1 s, tstepStart: 60 s,
default accuracy ATol: 1e-6, RTol: 1e-4 )

84

According to Figure 15 the accepted step size in
Richardson extrapolation varies considerably. The
constant step size of 60 s is much smaller than most of
the Richardson steps. Therefore, the Richardson method
is even faster than constant step size simulation (Table
8). The Linear extrapolation time step method calculates
smaller step sizes than Richardson extrapolation (Figure
16). In this example, Richardson extrapolation is the
best choice since it is fast, and the user does not have to
define a constant step size.
Table 8. Normalized CPU time comparison single room
Step size 60 s

Richardson

1

0.7

Lin. Extr.

1.6

4.2 Row House
The row house is a building according to Figure 17 with
three floors. The heat to the ground floor and the first
floor is provided by a volume flow controlled heating
system (underfloor heating), the attic is not heated. A
thermal storage buffer (50 m3) which is provided with
warm water by a heat pump supplies the heating system.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713279

Session 4B: Buildings I

The following results are based on Newtons method for
solving the cyclic equations. Figure 19 shows the zone
temperatures, and Figure 20 shows the heat flow into the
heated zones over a time interval of 31 days using
constant step size of 60 s. This step size was chosen
based on experience. The temperatures differ less than
5e-3 K from reference results obtained by closed
simulation via model exchange. The constant step size
cannot be enlarged considerably, since already a
constant step size of 300 s creates clear deviations, see
Figure 21.

Figure 17. Row house sketch

Similar to the single room model the row house is
modeled with different tools. Using NANDRAD the
thermal zones including their interdependencies and
additionally the weather were modeled, and exported as
one FMU thermal zones. The facility model including
heat pump, buffer, and the heating system are modeled
using the GreenBuilding library. This model part is
exported as facility FMU by SimulationX.
Figure 18 shows the graphical model representation of
the row house. The green dashed frame shows the
thermal zones, which form together with the weather
model the thermal zones FMU. All other parts are
within the facility FMU. Table 9 gives an overview on
the 26 coupling variables.

Figure 18. Row house model
Table 9. Coupling variables of the row house example
4
2
2
9
1
2
2
2
2

variables
Heating power
Zone temperature
Zone mean radiant temp.
Ambient values
Ambient values
Heating setpoints
Cooling setpoints
User load
Electric power consumption

DOI
10.3384/ecp1713279

th. zones
input
output
output
output
output
output
output
output
output

facility
output
input
input

Figure 19. Row house room temperatures, constant step
size 60 s

Figure 20. Row house convective thermal heat load,
constant step size 60 s

Figure 21. Row house room temperatures with
deviations, constant step size 300 s

Richardson extrapolation calculates the same results as
shown in Figure 19 and Figure 20, differences are
negligible. Figure 22 shows the step size variation which
was allowed to vary in a wide range from 0.01 s up to
3600 s, the lower limits were not reached.

input

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

85

Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation

supply is modeled using the Green Building library
(Modelica) and SimulationX, and exported as one FMU
2.0 facility.

Figure 22. Row house Richardson accepted step size

According to Figure 22 the constant step size of 60 s is
not a bad choice. This inspires to use a short time
Richardson extrapolation for finding an appropriate
constant step size. Table 10 compares different
simulations. All variable step size methods calculate
wrong results using the default tolerances. If a higher
precision is applied correct results are achieved.
Richardson extrapolation with higher precision is more
twice as slow as well chosen constant step sizes. The
reason is that Richardson extrapolation simulates the
whole interval more than twice. Furthermore, it is to
notice that some wrong simulations take much more
CPU than correct ones at that example.

Figure 23. CAD model of the apartment building

Table 10. Row house comparison of simulation runs
method
step size
deviation**
CPU*
Constant
60 s
0.004 K
21 min
Constant
300 s
0.4 K
20 min
Richardson
3600 s60 s
0.4 K
1 day
Linear extr.
3600 s60 s
0.4 K
24 min
Extended
3600 s60 s
0,4 K
52 min
Richardson
Richardson***
3600 s60 s
0.004
1.1 h
Linear extr. *** 3600 s60 s
0.004
38 min
Extended
3600 s60 s
0.004
1.1 h
Richardson***
*
Desktop-PC, SSD, Intel 2, 1 GHz, 8 GB RAM,
Windows 7 (64 bit), ** max. deviation of the first floor
room temperature from reference values, *** tighter
tolerances (ATol=1e-8, RTol=1e-6)

4.3 Apartment Building
The apartment building has four floors, and three
staircases. Per staircase and per floor there are three flats
so that the building comprises 36 flats, see Figure 23.
The model consists of 168 thermal zones which are
described using NANDRAD like at the row house and
single room model. The thermal zones are exported
altogether with one FMU2.0 zones for co-simulation.
The heat supply of the building consists of a thermal
storage buffer which is recharged by a both a block heat
and power plant and a gas boiler. To keep the huge
model smaller the heat supply model was simplified by
prescribing the temperature of the medium that supplies
the radiators. The 168 heating systems of the thermal
zones comprise the model of a radiator, a controller
model for the volume flow, and a controller model for
the supply temperature each, see Figure 24. The heat
86

Figure 24. Heating system models of 5 thermal zones

The apartment house example has 1186 coupling
variables which are roughly explained in
Table 11.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713279

Session 4B: Buildings I

Table 11. Coupling variables of the apartment building
example
variables
th. zones facility
336 Heating power
input
output
168 Zone temperature
output
input
168 Zone mean radiant temp. output
input
10
Ambient values
output
input
168 Heating setpoints
output
input
168 Cooling setpoints
output
input
168 Electric power
output
input
consumption

Because of the bad performance the model is simulated
over 7 days only. The following considerations are
based on the Gauss-Seidel method with one iteration for
cycle handling. Newtons method is not applicable due
to its extremely bad performance. Figure 25 shows the
mean zone temperatures as well as the thermal load of
some rooms which are result of Richardson
extrapolation with step sizes varying between 0.01 s and
1 hour. This result coincidences with a reference
solution obtained by a co-simulation using SimulationX
3.7.4 for the facility part with included NANDRAD
FMU for the thermal zones. Therefore, the result is
regarded to be correct.

Figure 25. Apartment building: temperatures and heat
load, Richardson extrapolation

Figure 26 shows the accepted step size variation of
Richardson extrapolation. The step size varies between
2 seconds and an hour, however, only some peaks are
below 100s. Therefore, a constant step size simulation
was tested, which shows no visible deviation from the
Richardson extrapolation result at some selected signals.
A gradual increase of the constant step size up to 1 hour
does not change the calculated signals clearly. At 1 hour
step size the differences are about 0.05 K at some
temperatures, and 0.5 W at thermal loads. A more
detailed comparison is necessary. It is an advantage of
Richardson extrapolation that no fixed step size needs to
be defined.

Table 12 shows the performance of the different
simulations. Reasonable constant step size simulations
are about twice as fast as Richardson extrapolation. The
Extended Richardson extrapolation as well as the Linear
extrapolation approach also calculate correct results.
But their performance is worse than Richardson
extrapolation since it uses smaller step sizes (Figure 27).

Figure 27. Apartment building: step size variation during
Extended Richardson extrapolation
Table 12. Apartment building: performance comparison
method
step size
CPU*
Richardson
3600 s  0.01 s 11.4 min
Constant
100 s
7.3 min
Constant
200 s
6.4 min
Constant
400 s
6.0 min
Constant
1000 s
5.4 min
Constant
3600 s
5.4 min
Linear extrapolation
3600 s0.01 s 14.3 min
Extended Richardson 3600 s0.01 s 18.2 min
*
Desktop-PC, SSD, Intel 2, 1 GHz, 8 GB RAM,
Windows 7 (64 bit)

This example demonstrates that Richardson
extrapolation seems to ensure finding the correct
solution. Furthermore, it is useful for finding adequate
step sizes for constant step size simulations. But it is not
an approach to obtain a somewhat high performance.

5

Richardson extrapolation is recognized to be an
important and useful approach for co-simulation. It was
shown that enhancements are necessary for the cases of
outputs that do not depend on inputs which control
DAEs.
There are examples which need a variable step size
approach in co-simulation. The touching mass example
requires the Richardson extrapolation approach.
To apply Richardson extrapolation in building
simulation three differently sized examples are
presented. The results which are by far not yet
representative to building simulation models at all, are:


Figure 26. Apartment building: accepted step size
variation during Richardson extrapolation, limited by
3600 s0.01 s

DOI
10.3384/ecp1713279

Conclusion

The performance of Richardson extrapolation is
worse than the performance of constant step size
method, although Richardson extrapolation partly
uses higher step sizes.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

87

Application of Richardson Extrapolation to the Co-Simulation of FMUs from Building Simulation



Richardson extrapolation with a wide step size
limitation can be applied to find out a trustable
constant step size. This helps the user to define the
step size. This approach should be automated.
Furthermore, the building simulation examples
show that a high number of coupling variables is to
be expected. This frustrated the application of
Newtons method for cycles. Therefore,
modifications of Newtons method should be
investigated.



Acknowledgements

Rene Unger, Torsten Schwan et alt.. Green BuildingModelling Renewable Building Energy Systems and
Electric Mobility Concepts Using Modelica. 9th
International Modelica Conference, Munich, Germany,
2012.
Tom Schierz, Martin Arnold, Christoph Clau. Cosimulation
with communication step size control in an FMI compatible
master algorithm. 9th International Modelica Conference,
Munich, 2012.
Tom Schierz. Modulare Zeitintegration gekoppelter
Differentialgleichungssysteme
in
der
technischen
Simulation. Fortschritt-Berichte, VDI Reihe 20 Nr. 447.
Dsseldorf, VDI Verlag 2013.

This paper is based on the results of the German research
project Entwicklung der Kopplungstechnologie von
Komplexmodellen fr Bauteil-, Raum- und
Gebudesimulation mit Modelica-basierten Anlagen-,
Regelungs- und Nutzermodellen (EnTool:CoSim),
funding reference 03ET1215C.

The authors are much obliged to the contributors of the
research project J. Bastian, T. Blochwitz (ESI ITI
GmbH), A. Nicolai and Anne Paepke (IBK TU
Dresden), Torsten Schwan, and Monika Wicke (EA
Systems Dresden) as well as Kosmas Petridis and
Andreas Klein for support and discussions.

References
Andreas Klein. Private information, 2015.
Andreas Nicolai, Anne Paepke. Die Gebudesimulationsplattform NANDRAD  Physikalisches Modell,
Umsetzungskonzept und Technologien im berblick.
BauSIM 2012, Berlin, 26.-28. September 2012.
EA Systems Dresden: Portfolio. Die neue Generation
intelligenter Energiekonzepte. Company internal document,
via info@ea-energy.de, 2015.
Ernst Hairer, Syvert Paul Norsett, Gerhard Wanner. Solving
Ordinary Differential Equations. Berlin, Springer, 1993.
ESI ITI GmbH: Simulation software SimulationX, website
https://www.simulationx.de/simulationssoftware.html
Jens Bastian, Christoph Clau, Susann Wolf, Peter Schneider.
Master for CoSimulation Using FMI. 8th International
Modelica Conference, Dresden, March 20-22, 2011.
Kosmas Petridis, Christoph Clau. Test of basic co-simulation
algorithms using FMI. 11th International Modelica
Conference, Versailles, 2015.
Vladimir Aleksandrovitch Kotelnikov. On the transmission
capacity of the ether and of cables in electrical
communications. Proc. of the first All-Union Conference on
the technological reconstruction of the communications
sector and low-current engineering, Moscow 1933.

88

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713279

Development of a Thermodynamic Engine in OpenModelica
Rahul Jain1
1 Dept.

Kannan M. Moudgalya1

Peter Fritzson2

Adrian Pop2

of Chemical Engineering, Indian Institute of Technology Bombay, India,
rahjain1@gmail.com,kannan@iitb.ac.in

2 Dept.

Computer and Information Sciences, Linkping University, Sweden,
{peter.fritzson,adrian.pop}@liu.se

Abstract

Unfortunately, OpenModelica does not have a library
of chemical engineering models and a thermodynamic
database. As a result, it is not yet of much use to the
chemical engineering community. If we can add a CAPE
Open thermodynamic database to OpenModelica, it can
immensely increase the utility for chemical engineers.
DWSIM is a state of the art open source steady state
process simulator (Medeiros, 2015). It comes with two
CAPE Open thermodynamic databases, Chemsep (Kooijman and Taylor, 2001) and the native one. In this work,
we describe the different methods to make the DWSIM
chemical engineering library available for OpenModelica.
This paper is organized as following. We explain the
Python-C interfacing approach to call the DWSIMs thermodynamic database from OpenModelica. We then explain how to instead use socket programming to connect
the two simulators. The final part is devoted to the porting
of thermodynamics in native mode on to OpenModelica.
We conclude with a comparison of the three approaches.

OpenModelica, an open source equation oriented modeling environment for steady state and dynamic simulation,
lacks good chemical engineering support. This problem is
addressed by making available in different ways the thermodynamic library Chemsep that comes with DWSIM,
an open source sequential modular steady state simulator.
Only slow speeds could be achieved through a Python-C
API based interface connecting OpenModelica with the
thermodynamic library. A socket programming based interface helps achieve faster speeds. Best results have been
achieved by porting the thermodynamic library and the
calculation routines to OpenModelica, due to two reasons:
(1) thermodynamic equations are solved simultaneously
with mass and energy balances (2) overheads in calling
the external routines of DWSIM are eliminated. Performances of the above mentioned three approaches have
been validated with steady state and dynamic simulations.
Benzene - toluene separation, methanol - ethanol - water distillation, and steam distillation of an n-octane - n2 Importing the Thermodynamic endecane mixture, have been carried out through these simgine of DWSIM in OpenModelica
ulations. This work makes available a powerful simulation
platform to the chemical engineering.
As DWSIM is based on sequential modular solution techKeywords: OpenModelica, DWSIM, Chemsep, thermoniques (Westerberg et al., 1979), it is more suitable to
dynamics, modeling, simulation, chemical engineering,
solve analysis type of problems. One will have to resort
Python-C API, socket programming, media
to iterations to design systems, which may involve finding
the value of some parameters in the output stream or in
Abbreviations
the equipment, or the building block. It is also difficult to
carry out dynamic simulation in DWSIM. DWSIM has a
API Application programming interface
strong thermodynamic engine. DWSIM also has a stancsv
Comma separated values
dalone thermodynamic library (DTL) which can be used
dll
Dynamic link library
externally.
DTL DWSIM thermodynamics library
EOS Equation of state
The weakness of DWSIM is the strong point of OpenVLE Vapor liquid equilibrium
Modelica: it is equation oriented and capable of handling unsteady state equations. Similarly, the weakness
1 Introduction
of OpenModelica is the strength of DWSIM: thermodyModelica (Modelica Association, 2000) is a powerful namic database and routines. As they complement each
modelling language and OpenModelica (Fritzson, 2014) other, there is a good case to integrate OpenModelica with
is its open source implementation. In OpenModelica has DTL.
an excellent interface to build models and to perform sim- 2.1 Python-C API approach to Integrate
ulations. As it implements an equation oriented solution
OpenModelica with DTL
approach, models and solution methods are maintainable
(Piela et al., 1992). Many engineering domains have used DTL consists of a file with an extension .dll (dynamic
OpenModelica.
link library) which is written in VB.NET in windows enDOI
10.3384/ecp1713289

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

89

Development of a Thermodynamic Engine in OpenModelica

Figure 1. Structure of Python-C API approach

Figure 2. Structure of Python-C socket approach

vironment. This file is COM (component object model)
in terms of its operations, inputs, outputs, and underenabled, which means that any programming language
lying types. This API is responsible for converting C
which supports COM can import this library and access
variables to Python and vice versa.
the built-in thermodynamic subroutines. OpenModelica is
 Finally as OpenModelica is compatible with C, the
written in C in Linux environment and it is not straight
inputs are then sent to C functions through Openforward to call programs written in VB.NET.
Modelica external C functions, which in turn calls
We used Python as the glue language to call the COM
the Python functions, which in turn calls DTL rouenabled objects of DWSIM from C routines of OpenModtines.
elica. This was achieved through the package win32com
of Python. This allowed us to access the DTL library
and all the thermodynamic routines available in DWSIM 2.2 Client-Server (sockets) approach to intefrom OpenModelica. Figure 1 describes the flow of the
grate OpenModelica with DTL
approach, which are further described below.
Client-Server or socket approach (Rhodes and Goerzen,
2010) is another approach through which the integration is
 DTL routines are imported to Python first through a possible. Figure 2 describes the data flow of the approach,
package named win32com.client. This package al- which are further explained below.
lows Python to call routines from a dll file registered
in the windows registry. Once the dll file is dis In this approach also, firstly the the DTL routines are
patched through win32com.client, Python has access
called in Python with the help of win32com.client
to all the COM enabled functions of the dll.
package.

 Now Python functions can send input parameters to
DTL routines, get the required thermodynamic properties calculated and receive them. As results of calculations are available, these Python functions can be
considered to behave similar to DTL routines.
 These Python functions are now called by C through
Python-C API. In computer programming, an API
(Application Programming Interface) is a set of routines, protocols, and tools for building software applications. An API expresses a software component
90

 Similar to Python-C approach, functions are written
in Python which calls DTL to calculate various physical properties.
 Now a Python server which consists of all the above
functions is created. This server waits for a C client
to establish connection, receive inputs from it and
send the calculated values back to the client.
 For every calculation (e.g. vapor pressure, equilibrium constant, etc.), a Python server is established.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713289

Session 4C: Process & Chemical Engineering

Table 1. Thermodynamic routines and the procedures to call
them
Thermodynamic Prop.
Vapor Pressure
Enthalpy
Liquid Density
Vapor Density
Pres. Temp. Flash
Pres. Volume. Flash
Pres. Enth. Flash
Liquid Viscosity
Vapor Viscosity
Surface tension

Thermodynamic Func.
VapPres
Ent
LiqDen
VapDen
PTFlash
PVFlash
PHFlash
LiqVis
VapVis
SurfTen

package used was Raoults law. All the pure component and mixture properties were imported from
DTL. To test the capability of the integration methods, the composition of the resulting vapor stream
was specified, and the temperature at which this composition was attained was left unknown. It was observed that the Python-C API approach took 30 seconds to solve the system, whereas the Client-Server
method took less than 1 second to simulate.

Arguments
Comp,T
Comp., T,P
Comp,T
Comp,T
Comp,Z,T,P,Model
Comp,Z,V,P,Model
Comp,Z,H,P,Model
Comp,T
Comp,T
Comp,T

 Dynamic Flash
A dynamic flash was simulated with the feed as
equimolar mixture of benzene and toluene. The thermodynamic package used was again Raoults Law.
It was assumed that the output liquid stream was at
the same composition and temperature, as the holdup
inside the flash separator. Heat supplied to flash separator was kept constant. The set of equations involved were mass balance, energy balance and equilibrium equations. The mass and energy balance
were differential equations. It was observed that the
Python-C API approach took 30 minutes to solve,
whereas the Client-Server approach took 4 minutes
to solve the system.

 Clients are coded in C which establishes connections
with the Python servers and send and receive data
from them.
 Once the connection is established, a Python server
receives the data from C client, contacts DTL, calculates the required property as asked by the C client
and sends it back to the client.

 Finally, these C clients are called by OpenModelica
external C functions giving the required inputs to the
client which in turn contacts the Python servers for
calculations. The C clients receive calculated values
The above two examples and others that we have not refrom Python servers and transfer them to OpenModported
here show that the Client-Server approach is more
elica.
efficient than the Python-C API approach.

2.3

Comparison of the two approaches

In this section, we compare the two approaches presented
above. In both approaches, before any routine in DTL is
called, one has to carry out initialization. This Initialize
routine loads all the compounds and their properties from
the database, which is a time consuming operation. In the
Python-C API approach, this initialization is done every
time a call is made from OpenModelica to DTL. On the
other hand, this has to be done only once in the Client
Server approach. As a result, the latter is far more efficient
than the former.
Whenever an API is used in any program it makes it
slow as there is a lot of conversions involved, such as data
type conversions. As the Python-C API approach is based
on API it is slow.
To verify the speeds of two approaches, we use the
thermodynamic calculations presented next. Table 1 lists
the thermodynamic functions and their arguments that
we have implemented in OpenModelica to receive values
from DTL. These functions can be used directly in any
simulation. When using the socket approach, the Python
server should be up and running during the execution of
the simulation. We now present two case studies that
helped compare the two approaches.

3

Development of a native thermodynamic engine in OpenModelica

A thermodynamic engine consists of the following three
components: Compound database, thermodynamic functions and phase equilibria models. In this section, we describe how we have developed a native thermodynamic engine in OpenModelica.

3.1

Development of Compound Database

A Compound database is a comprehensive database of
physical and chemical properties of all compounds. It
also includes constants for calculating various temperature
or pressure dependent properties like vapor pressure, enthalpy, viscosity, etc.
We first describe the Chemsep (Kooijman and Taylor,
2001) database that we ported to OpenModelica. Chemsep is an open source database, written in xml format. It
has over six hundred compounds with a comprehensive
set of thermodynamic properties of each compound. It
also has an extensive database of binary interaction parameters for thermodynamic packages like NRTL (Renon
and Prausnitz, 1968), Peng Robinson (Peng and Robinson, 1976), UNIQUAC, SRK (Soave, 1972), etc. Most
of the thermodynamic properties are calculated by empir Steady State Flash Separator
ical equations that are functions of temperature or presAn equimolar mixture of Benzene and Toluene was sure. Chemsep database includes the constants which are
flashed in a flash separator. The thermodynamic used in these equations. Therefore, Chemsep database is

DOI
10.3384/ecp1713289

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

91

Development of a Thermodynamic Engine in OpenModelica

Table 2. Independent thermodynamic properties and OpenModelica routines to call them.

Thermodynamic Property
Critical Temperature
Critical Pressure
Critical Volume
Boiling point
Melting point
Molecular weight
Acentric Factor
Triple Point
Solubility parameter
Dipole moment
Heat of formation
Absolute enthalpy

Calling procedure
Compound.Tc
Compound.Pc
Compound.Vc
Compound.Tb
Compound.Tm
Compound.MW
Compound.AF
Compound.TT
Compound.SP
Compound.DP
Compound.HOF
Compound.ABSENT

a comprehensive database that can be used to built a powerful and robust thermodynamic engine.
We now explain how we ported Chemsep to OpenModelica. First, the xml data have to be rewritten in a
form understandable by OpenModelica. Therefore, each
compound (including all its thermodynamic properties) is
replicated as a single class in OpenModelica, as shown
in Figure 3. The properties are given abbreviations (as
shown in Table 2) so that they can be called conveniently.
The conversion from xml to OpenModelica classes is carried out by developing a Python script which automates
this process, thus making it fast and robust.
Now, one can extract any independent property of a
compound by the . (dot) operator, followed by the property relevant abbreviation. For example the critical temperature (Tc) of methane can be accessed by Methane.Tc.
Similarly, all properties of any compound can be accessed
in the same way as shown in table 2.

3.2

Development of Thermodynamic Functions

Thermodynamic properties are generally calculated
through empirical equations that include constants, whose
values are provided by the compound database as explained above, and independent variables, such as temperature, pressure and composition. These properties are
written in the form of functions in OpenModelica. Arguments to these functions are the independent variables
mentioned above, and the coefficients of respective compounds whose properties have to be calculated. These coefficients can be accessed by instantiating the base compound class. The functions then return the calculated
property. For example, the vapor pressure of methane
at 300 K can be calculated by first instantiating the base
Methane class (parameter Methane methane) and then
calling Pvap(methane.VP, 300). Where Pvap is a generic
function to calculate the vapor pressure of any compound
at any given temperature. The whole process is shown
92

Table 3. Dependent thermodynamic properties and OpenModelica functions to call them.
Thermodynamic Property
Liquid density
Vapor pressure
Heat of Vaporization
Liquid heat capacity
Liquid viscosity
Vapor viscosity
Liquid thermal conductivity
Vapor thermal conductivity

Calling procedure
LiqDen(Compound name,temp)
VP(Compound name,temp)
HOV(Compound name,temp)
LiqCp(Compound name,temp)
LiqVis(Compound name,temp)
VapVis(Compound name,temp)
LiqK(Compound name,temp)
VapK(Compound name,temp)

in Figure 4. Similarly, all other thermodynamic properties can be calculated using their respective functions as
shown in Table 3.

3.3

Development of Phase Equilibria models

Phase equilibria models consist of modelling equations for
Vapor Liquid Equilibrium (VLE) models like Peng Robinson, NRTL, UNIQUAC, etc. These models are used to
predict the behavior of various systems.
In a mixture of phases that are in an equilibrium, the
component fugacities are the same in all phases (Smith
et al., 2005), that is :
fiL = fiV

(1)

where fiL and fiV are the liquid and vapor phase fugacities of the ith component respectively. The fugacity of a
component in a mixture depends on temperature, pressure
and composition. In order to relate f iV with temperature,
pressure and molar fraction, we define the fugacity coefficient,
fV
(2)
i = i 
yi P
where i is the fugacity coefficient and P is the pressure
of the system, which can be calculated from PVT data,
commonly obtained from an equation of state (EOS). For
a mixture of ideal gases, i = 1. The fugacity of component i in the liquid phase is related to the composition of
that phase by the activity coefficient i , which by itself is
related to xi and standard-state fugacity fi0 by
i =

fiL
xi fi0

(3)

The standard state fugacity fi0 is the fugacity of the ith
component at the system temperature, i.e. mixture, and in
an arbitrary pressure and composition. Here, the standardstate fugacity of each component is considered to be equal
to pure liquid i at the system temperature and pressure.
An Equation of State is used to calculate equilibria. The
fugacity of the ith component in the liquid phase is calculated by
fL
i = i 
(4)
xi P

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713289

Session 4C: Process & Chemical Engineering

Figure 3. Porting Chemsep database in OpenModelica

Figure 4. Using built in thermodynamic functions (Pvap)

DOI
10.3384/ecp1713289

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

93

Development of a Thermodynamic Engine in OpenModelica

Figure 6. NRTL model as written in OpenModelica 1.11.0

4

VLE curve (Txy) for a binary system through the UNIQUAC model

In this section, we explain the procedure to generate the
VLE curve for a binary system and demonstrate it with
results from an ethanol-water system.
We will first explain the procedure to generate the bubble point curve. Suppose 1 and 2 are the activity coefficients, y1 and y2 are vapor phase compositions, x1 and
x2 are liquid phase compositions, and Pvap1 , Pvap2 are
Figure 5. Porting Chemseps binary interaction parameters in corresponding vapor pressures, of components 1 and 2,
OpenModelica
respectively. Then, the following equations are used to
generate the bubble point curve.
with the fugacity coefficient i calculated by the EOS, just
as it is done for the vapor phase.
We have implemented the following four phase equilibria models: Peng Robinson, SRK, NRTL and UNIQUAC.
Peng Robinson and SRK are the most abundantly used
EOS models, whereas NRTL and UNIQUAC find a wide
variety of applications where activity coefficient models
are required (Medeiros, 2015).
The binary interaction parameters for each of the EOS
and activity coefficient models have been extracted from
Chemsep database where they are stored in a .dat file. The
following procedure is used to port all the binary interaction parameters to OpenModelica.

 First, the dat file is converted to a csv file, which is
easier to process by Python.
 This csv file is then converted to an OpenModelica
function by a Python script which converts the compound and the binary interaction parameters as an array.
Figure 5 demonstrates the above process for NRTL activity coefficient model. This code is automatically generated
by the Python script. Line 6 of this code has been shortened for convenience. The actual code has 400 triplets of
real numbers on the right hand side of line 6.
Figure 6 shows the NRTL model. The model acquires
the required binary interaction parameters from the BIPNRTL function. The model incorporates the equilibrium
relation described in equation 4. This model can now be
directly extended into any model which requires calculation of phase equilibrium. All other phase equilibria models have been modeled similarly.
94

y1 .P = 1 .x1 .Pvap1
y2 .P = 2 .x2 .Pvap2

(5)
(6)

This is known as the modified Raoults law.
Adding the above two equations and equating the vapor
phase mole fractions to one (y1 + y2 = 1), we get
P = 2 .x2 .Pvap2 + 1 .x1 .Pvap1

(7)

Here 1 and 2 are complex nonlinear functions of temperature and liquid compositions and Pvap1 and Pvap2 are
functions of temperature.
The pressure is kept constant at 1 atm. The value of
x1 is varied from 0 to 1 with an interval of 0.1 and for
each value of x1 , the corresponding value of temperature
is calculated by equation 7. This is known as the bubble
point.
Now we explain how the dew point curve is generated.
We once again use the modified Raoults law for this purpose. Manipulating the equations 5 and 6 and putting x1 +
x2 = 1 we get
y2
y1
+
=1
1 .Pvap1 2 .Pvap2

(8)

The pressure is kept constant at 1 atm. The value of
y1 is varied from 0 to 1 with an interval of 0.1 and for
each value of y1 the corresponding value of temperature if
calculated by equation 8.
Figure 7 describes the implementation of the bubble
point model in OpenModelica. The dew point model have
also has been modeled similarly. As shown all the three
parts of the thermodynamic engine, namely, compound

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713289

Session 4C: Process & Chemical Engineering

cution time was 0.58s.

5

Steady State Flash

Now that thermodynamics is available in OpenModelica,
we simulate a steady state flash of a methanol, ethanol,
water system, using NRTL. To check the design efficiency
of the developed thermodynamic engine in OpenModelica, the output composition of the vapor product is specified, while the temperature at which this desired composition of vapor is attained is left unspecified. Thus, it is a
design problem. To carry out this simulation in DWSIM,
Figure 7. Bubble point model as written in OpenModelica we have to use the adjust operation that uses a trial and
1.11.0
error method.
We now explain the problem we propose to solve. The
flow rate and the composition of the feed is specified.
Pressure is kept constant at 1 atm. It is desired to calculate
all other variables for three different values of methanol
mole fraction, x1 . In other words, vapor compositions of
ethanol and water, temperature of all streams and all flow
rates need to be calculated. The schematic of the problem
statement is presented in Figure 9.
The input stream enters at 1 atm and its temperature is
to be determined according to the specified input composition. The simulation is run for three different desired
vapor compositions of methanol. The minimum and max(a) Results from OpenModelica 1.11.0
imum temperatures were taken to be boiling points of pure
methanol and water and the initial guess for temperature
is taken to be average of these two boiling points. The
following equations describe the model.
Mass balance:
zi F = xi L + yiV
F = L +V

(9)
(10)

(b) Results from Aspen Plus 8.1

Equilibrium equation:
Figure 8. Comparison of T-xy curve for ethanol water system
using UNIQUAC VLE model

yi = Ki xi

(11)

Summation Equation:
database, thermodynamic functions and phase equilibria
models, have been incorporated in the model.
Using the above procedure, we have calculated the bubble point curve and the dew point curve for the ethanol(1)water(2) system, and presented them in Figure 8(a). One
can see it to be identical to the figure generated by Aspen
Plus (Aspentech, 2017), presented in Figure 8(b).
Reliable azeotropic data source by American Chemical Society (Gmehling et al., 1995) says that for ethanolwater system, at 1 atm, the azeotropic composition and
temperatures are 0.96 mole fraction ethanol and 351.4 K,
respectively. These values are also in agreement with the
OpenModelica results.
The same simulation when carried out with the imported DWSIMs thermodynamic engine in OpenModelica resulted in an execution time of about 20 minutes,
whereas for the built in thermodynamic engine, the exeDOI
10.3384/ecp1713289

2

 yi = 1

(12)

i=1

Here, F, L, V are the feed, liquid, and vapor flow rates,
respectively, in kmol/hr and zi , xi , yi are the feed, liquid,
and vapor compositions respectively. Ki is the equilibrium
constant. UNIQUAC activity coefficient model is used as
the phase equilibria model.
Figure 10 depicts the example as developed in OpenModelica. The type compound in the fifth line is a general
class used to represent the compound class.
Results of these calculations have been presented in Table 4. One can see that these results are consistent with
the general requirement that higher the mole fraction of
the least volatile component, lower the temperature. All
calculations got completed in OpenModelica in less than
a second.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

95

Development of a Thermodynamic Engine in OpenModelica

Figure 9. Model with problem statement for steady state flash of Methanol-ethanol-water.
Table 4. Results of simulation in OpenModelica using the builtin thermodynamics and in DWSIM
OpenModelica 1.11.0
Desired Vapor Comp.(Methanol) Temperature
0.35
351.21
0.38
350.28
0.425
349.24
DWSIM 3.4
0.35
351.26
0.38
350.211
0.425
349.12

6.1

Figure 10. Flash model as written in OpenModelica 1.11.0

Same calculations are repeated in DWSIM using the adjust function, by trial and error, and the results are reported
in the same Table. One can see the results to be comparable. It took 15 to 20 seconds to do each of these calculations in DWSIM, however.

6

Semi-Batch Steam Distillation of a
Binary Organic Mixture

We now illustrate the ease with which dynamic simulation can be carried out in OpenModelica, using the semibatch steam distillation of a binary mixture. We present
the model first and then an example.
96

Liquid Comp.
0.1985
0.2354
0.274
0.199
0.234
0.279

Model of the process

This illustrative example involves semi-batch steam distillation of a binary mixture (n-octane and n-decane). A
schematic plot of the steam distillation apparatus is shown
in Figure 11. The organic mixture is charged into the still
initially, and then steam is bubbled through continuously
until the desired degree of separation has been reached.
There are two different periods in the operation of the still:
the heating period, until the boiling point temperature of
the organic mixture is reached, and the distillation period.
A brief description of the mathematical models for the two
periods follows (Shacham et al., 2012).
We present the model for the heating period first. A
simple mass balance on the water phase yields
dmw
= Ws
dt

(13)

where Ws is the steam flow rate in kmol/s and mw is the
mass of water in the still in kmol. It is assumed that all
the steam condenses in the distillation vessel and that the
organic phase masses remain constant during the heating
period.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713289

Session 4C: Process & Chemical Engineering

We now present the model for the distillation period.
During the distillation period, there is output of water vapor from the still.
dmw
= Ws V yw
dt

(18)

where V is the outlet vapor flow rate. Material balances
on the two organic compounds yield two additional differential equations
d(mx2 )
d(mx1 )
= V y1
= V y2
dt
dt
Figure 11. Schematic of steam distillation apparatus (Shacham
et al., 2012).

An energy balance on the still provides the equation for
the change of the temperature T in  C
dT
Ws (Hs  Hlw )  Q
=
dt
mw c pLw + m(x1 c pL1 + x2 c pL2 )

(14)

where Hs is the enthalpy of the steam in J/kmol, Hlw is
the enthalpy of liquid water in J/kmol, Q is the rate of
heat transfer to the surroundings in J/sec, c pLw is the molar
specific heat of the water in J/kmol-K, m is the mass of the
organic phase in the still in kmol, x1 and x2 are the mole
fractions, and c pL1 and c pL2 are the molar specific heats of
organic compounds No. 1 and 2, respectively, in J/kmolK. The heat transfer rate to the surroundings is calculated
from the following equation.
Q = UA(T  Ta )

(15)

where UA is the product of the overall heat transfer coefficient U and the contact area A with the surroundings
in J/s-K, Ta is the ambient temperature in K, and T is the
temperature of the liquid in the still in K.
Assuming ideal liquid behavior, Raoults law can be
used to calculate the vapor mole fraction of the components in the organic phase
y1 =

x2 P2
x1 P1
y2 =
P
P

(16)

where P is the total pressure in Pa and P1 and P2 are the vapor pressures of the organic compounds in Pa. The mole
fraction of the water which is immiscible in the organic
phase is given by yW = PW /P. y1 and y2 are the vapor
phase mole fraction of n-octane and n-decane respectively.
The heating period continues until the sum of vapor pressures of the organic compounds and the water is equal to
the total pressure. Thus, the bubble point equation to be
satisfied can be expressed as
f (T ) = 1  (y1 + y2 + yw ) = 0
DOI
10.3384/ecp1713289

(17)

(19)

The organic mass in the still at any time is given by:
m = mx1 + mx2 . The temperature in the still changes in a
manner so that the bubble point equation is satisfied. The
energy balance at a particular temperature yields the momentary vapor flow rate
V=

Ws (HS  HLW )  Q
Hv  [yw hlw + (y1 hL1 + y2 hL2 )]

(20)

where HV is the molar enthalpy of the vapor phase;
hLw , hL1 , and hL2 are the liquid phase molar enthalpies
of water, n-octane and n-decane, respectively. Material
balances on the water and organic phases in the still can
provide the amount and the mole fractions of the various
components in the distillate.

6.2

Example: n-octane, n-decane distillation

Semibatch steam distillation of a mixture containing noctane (compound 1) and n-decane (compound 2) is to
be processed. Initially M = 0.015 kmol of organics with
composition x1 = 0.725 is charged into the still. The initial temperature in the still is T0 = 25  C. Starting at time
t = 0, steam at a temperature Tsteam = 99.2  C is bubbled continuously through the organic phase at the rate of
MS = 3.85e-5 kmol/s. All the steam is assumed to condense during the heating period. The ambient temperature
is TE = 25  C and the heat transfer coefficient between the
still and the surrounding is UA = 1.05 J/s-K. The ambient
pressure is P = 9.839E+04 Pa.
Assumptions: 1) Ideal behavior of all components in
pure state or mixture; 2) complete immiscibility of the water and the organic phases; 3) ideal mixing in the boiler;
and 4) equilibrium between the organic vapor and its liquid at all times. The standard state for enthalpy calculations pure liquids at 0  C and 1 atm. can be used.
We have to Calculate and plot the still temperature (T),
component mole fractions inside the still (x1 , x2 , y1 , and
y2 ), and the component mole fractions in the distillate
(x1dist and x2dist ) using the data and the initial values provided.
We have to determine the lowest n-octane mole fraction
in the feed that can yield a distillate concentration of 90%
of n-octane. Compute the percent recovery of n-octane
in the distillate as function of its concentration in the feed.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

97

Development of a Thermodynamic Engine in OpenModelica

Vary the feed concentration in the range where the requirement for the n-octane concentration in the distillate is attainable.
Plots in Figure 12 shows that the results of OpenModelica are in agreement with that of (Shacham et al., 2012). It
can be observed that the temperature increases during the
heating period and then stays constant during the distillation period when the Bubble point is attained. The liquid
phase compositions is constant during the heating period
as there is no vapor formation.
(a) Temperature profiles generated in OpenModelica 1.11.0

7

Conclusion and Future Work

In this paper, we have implemented and compared three
different ways of making available thermodynamics in
OpenModelica. Each of these approaches has been illustrated with simulations of one or more chemical processes.
We have found the native port to be the most efficient.
We have compared the results of OpenModelica with
those from DWSIM, Aspen Plus, and published literature,
and they match quite well in all calculations.
As now OpenModelica has its own thermodynamic engine, a library of steady state chemical process models
could be modeled. It may also be possible to build a library of dynamic chemical process models in OpenMod(b) Temperature profiles as reported in literature (Shacham et al., 2012)
elica, to carry out general purpose dynamic simulation.
We hope to explore the possibility of enhancing
OMEDITs (Asgharand et al., 2011) features so that the
GUI shall resemble that of established simulators, such as
Aspen Plus or DWSIM, for chemical process simulation.
We propose to check the correctness of thermodynamic
calculations by solving a large number of already solved
flowsheets. Sources for these will include examples from
books, journals, reports and sample problems from other
process simulators. We hope to present these flowsheets
in a way similar to what we have done for DWSIM
(c) Profiles of vapor and liquid compositions, as generated in OpenMod- (DWSIM-Team-FOSSEE-Project, 2017). Usefulness of
elica 1.11.0
such an initiative has been articulated in a similar context
(Braatz, 2014).
A difficult task we face is with respect to thermodynamics in general and the thermodynamic database, in particular. This facility has to be strengthened by adding information on more chemicals and more thermodynamic
calculations. We invite experts in this important area to
contribute and to make OpenModelica a much better open
source process simulator.

Acknowledgements
This work has been supported by Swedish Vinnova governmental agency and the Indian Department of Sci(d) Profiles of vapor and liquid compositions, as reported in the literature ence and Technology governmental agency in the Indo(Shacham et al., 2012)
Swedish RTISIM project, and by the National Mission on
Education through ICT, Ministry of Human Resource DeFigure 12. Comparison of temperature and composition change velopment, through the FOSSEE project. The OpenModduring semi-batch steam distillation
elica development is supported by the Open Source Modelica Consortium.

98

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp1713289

Session 4C: Process & Chemical Engineering

References
Adeel Asgharand, Sonia Tariq, Mohsen Torabzadeh-Tariand,
Peter Fritzson, Adrian Pop, Martin Sjolund, Parham Vasaiely,
and Wladimir Schamai. An open source modelica graphic editor integrated with electronic notebooks and interactive simulation. Proc. of the 8th International Modelica Conference
2011, pp, pages 739747, 2011.
Aspentech. Aspen plus. http://www.aspentech.com/
products/engineering/aspen-plus/, 2017. Last
seen on 1 April 2017.
R. D. Braatz. Scilab textbook companions. IEEE Control Systems Magazine, page 76, June 2014.
DWSIM-Team-FOSSEE-Project. Dwsim flowsheets. http:
//dwsim.fossee.in/flowsheeting-project/
completed-flowsheet, 2017. Last seen on 1 Aprtil
2017.
Peter Fritzson.
Principles of Object Oriented Modeling
and Simulation with Modelica 3.3: A Cyber-Physical Approach. Second edition, 2014. ISBN 9781118989166.
doi:10.1002/9781118989166.
Jrgen Gmehling, Jochen Menke, Jrg Krafczyk, and Kai Fischer. A data bank for azeotropic data - status and applications. Fluid Phase Equilibria, 103(1):5176, 1995. ISSN
03783812. doi:10.1016/0378-3812(94)02569-M.
H.A. Kooijman and R. Taylor. The ChemSep Book. Books on
Demand, Norderstedt, Germany, 2001.
Daniel Medeiros. Dwsim technical document. Technical report,
2015. http://dwsim.inforside.com.br/.
Modelica Association. ModelicaTM - A Unified ObjectOriented Language for Physical Systems Modeling: Language Specification. ReVision, 2000. ISSN 09284869.
doi:10.1016/S0928-4869(97)84257-7.

DOI
10.3384/ecp1713289

Ding-Yu Peng and Donald B. Robinson.
A New TwoConstant Equation of State. Industrial & Engineering
Chemistry Fundamentals, 15(1):5964, 1976. ISSN 01964313. doi:10.1021/i160057a011. URL http://pubs.
acs.org/doi/abs/10.1021/i160057a011.
Peter Piela, Roy McKelvey, and Arthur Westerberg. An introduction to the ascend modeling system: Its language and interactive environment. Journal of Management Information
Systems, 9(3):91121, 1992.
Henri Renon and J. M. Prausnitz.
Local compositions
in thermodynamic excess functions for liquid mixtures.
AIChE Journal, 14(1):135144, 1968. ISSN 15475905.
doi:10.1002/aic.690140124.
Brandon Rhodes and John Goerzen.
Foundations of
Python Network Programming, 2010. ISSN 1098-6596.
URL
http://www.springerlink.com/index/
10.1007/978-1-4302-3004-5{%}5Cnhttp:
//it-ebooks.info/book/1796/.
M. Shacham, M. B. Cutlip, and M. Elly. Semi-Batch Steam
Distillation Of a Binary Organic Mixture: a Demonstration of
Advanced Problem-Solving Techniques and Tools. Chemical
Engineering Education, 46(3):173181, Summer 2012.
J M Smith, H C Van Ness, and M M Abbott.
Introduction to Chemical Engineering Thermodynamics, volume 27. McGraw Hill Education, 2005. ISBN 0072402962.
doi:10.1021/ed027p584.3.
G. Soave. Equilibrium constants from a modified redlich-kwong
equation of state. Chemical Engineering Science, 27(6):
11971203, 1972.
A.W. Westerberg, H.P. Hutchison, R.L. Motard, and P. Winter.
Process Flowsheeting. Cambridge University Press, Cambridge, 1979.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

99

100

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Integrated Process and Molecular Design with Modelica
Using Continuous-Molecular Targeting
Christoph U. Gertig1

Dominik Tillmanns1

Franz Lanzerath1
1

2

Johannes Schilling1

Joachim Gross2

Uwe Bau1

Andr Bardow1

Institute of Technical Thermodynamics, RWTH Aachen University
Schinkelstr. 8, 52062 Aachen, Germany

Institute of Technical Thermodynamics and Thermal Process Engineering, Stuttgart University
Pfaffenwaldring 9, 70569 Stuttgart, Germany
andre.bardow@ltt.rwth-aachen.de

Abstract
The performance of many chemical and energy conversion processes depends on the choice of the molecules
used, e.g. as solvents or working fluids. To capture the
complex relations between the properties of the molecules used and the process conditions, the selection of
suitable molecules should be directly integrated into
process design. Solving the resulting challenging integrated design problem is enabled by the Continous-Molecular Targeting  Computer-Aided Molecular Design
(CoMT-CAMD) approach. Here, the combinatorial
complexity of the molecular decisions is avoided by relaxing molecular parameters in a physically-based thermodynamic model. So far, implementations of CoMTCAMD were based on procedural programming languages. This impedes reusability and the investigation
of process variants as well as the design of complex processes. In order to overcome these shortcomings, we implement the CoMT-CAMD approach based on objectoriented process modeling and thus enable the integrated process and molecular design with Modelica. The
resulting approach is demonstrated for the design of a
process and the working fluid for a geothermal Organic
Rankine Cycle application.
Keywords: GenOpt, optimization, integrated fluid and
process design, computer-aided molecular design, PCSAFT

1

Introduction

In order to achieve high performance, chemical as well
as energy conversion processes have to be tailored to the
specific applications. The key to tailoring a process is
often the choice of suitable molecules. Examples are the
selection of solvents for absorption processes (Adjiman
et al., 2014; Bardow et al., 2010; Burger et al., 2015;
Papadopoulos and Linke, 2009), refrigerants for compression chillers (Roskosch and Atakan, 2015; Sahinidis
et al., 2003) and working fluids for Organic Rankine
DOI
10.3384/ecp17132101

Cycles (Linke et al., 2015; Bao and Zhao, 2013; Lampe
et al., 2015).
Today, design methods usually separate the choice of
suitable molecules and the process design (for a literature review, see e.g. Linke et al., 2015): in a first step,
molecular candidates are pre-selected using criteria
based on heuristics. In a second step, the pre-selected
molecules are used for process optimization.
However, these two-step approaches usually lead to
suboptimal solutions. Heuristic selection criteria cannot
capture the strong and complex relations between the
properties of chosen molecules and the corresponding
optimal process conditions. Therefore, the global optimum might already be excluded from the solution space
when heuristics are applied. Consequently, the design of
molecules should be directly integrated into the process
design (Adjiman et al., 2014; Linke et al., 2015). The
direct formulation of this integrated design problem
leads to a mixed integer nonlinear program (MINLP)
(Gani, 2004) where each molecule considered adds one
degree of freedom. Due to the large number of potential
candidate molecules, the solution of this MINLP is usually prohibitively difficult.
Thus, systematic approaches have been proposed for
the approximate solution of the integrated design problem: Pereira et al. (2008; 2011) solve the integrated design problem based on property predictions with the statistical associating fluid theory for potentials of variable
attractive range (SAFT-VR) with a search space limited
to linear alkanes. For Organic Rankine Cycles, the review by Linke et al. (2015) summarizes the state of the
art. Recently, Burger et al. (2015) have solved the integrated design problem utilizing a hierarchical approach
and short-cut models for the process. Gopinath et al.
(2016) have proposed an approach for the integrated design utilizing physical domain reduction. They employ
tests to remove regions from the molecular and process
domains where constraints, e.g., on phase behavior, are
violated.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

101

Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting

Bardow et al. (2010) proposed a targeting-based design
approach called Continuous-Molecular Targeting 
Computer-Aided Molecular Design (CoMT-CAMD)
for the integrated molecular and process design. Here,
the molecular properties are modeled by the PerturbedChain Statistical Associating Fluid Theory (PC-SAFT)
equation of state (Gross and Sadowski, 2001). In PCSAFT, each fluid is described by a set of physicallybased pure component parameters. In the first step of
CoMT-CAMD, the so-called Continuous-Molecular
Targeting (CoMT), the discrete PC-SAFT pure component parameters are regarded as continuous degrees of
freedom of the design problem and are optimized simultaneously with the process conditions (Lampe et al.,
2014; Stavrou et al., 2014). The resulting design problem can be formulated as a nonlinear program (NLP)
optimization problem. The results of this optimization
are the set of optimal pure component parameters for a
hypothetical target molecule and the corresponding optimal process parameters. In a second step, ComputerAided Molecular Design (CAMD) methods can be used
to design the real molecule which best matches the optimal process performance (Lampe et al., 2015). The
CoMT-CAMD approach has been applied successfully
to the design of solvents for CO2 capture (Stavrou et al.,
2014) and working fluids for Organic Rankine Cycles
(Lampe et al., 2014; 2015). A similar targeting approach
for integrated design was presented by Roskosch and
Atakan (2015). They use a cubic equation of state for
property modeling and relax its parameters in a simultaneous optimization of a compression heat pump process
and working fluid. Subsequently, they select suitable
fluids from databanks utilizing a fitted function for COP
estimation.
So far, integrated process and molecular design with
CoMT-CAMD was based on process models implemented in a procedural programming language. This
hinders the reusability of models and complicates the
design of complex processes as well as the investigation
of process variants. Furthermore, the use of procedural
languages is not convenient in case dynamic processes
have to be investigated.
These shortcomings can be overcome by using a language suited for object-oriented and equation-based
modeling like Modelica (Fritzson, 1998) to model the
process. Thus, in this work, we present the first implementation of the CoMT-CAMD approach based on
Modelica process models. Thereby, we enable the integrated process and molecular design with Modelica. In
order to illustrate the design approach, a case study is
presented for the design of a geothermal Organic Rankine Cycle (ORC) application.
The paper is structured as follows: in Section 2, the
CoMT-CAMD approach is explained. In Section 3, the
implementation of CoMT-CAMD based on Modelica

102

models is described. The case study of the ORC application is presented in Section 4 before conclusions are
drawn in Section 5.

2

The CoMT-CAMD Approach

The Continuous-Molecular Targeting  ComputerAided Molecular Design (CoMT-CAMD) approach was
introduced by Bardow et al. (2010). In CoMT-CAMD,
the fluids are modeled by the Perturbed-Chain Statistical
Associating Fluid Theory (PC-SAFT) equation of state
(EOS). Thus, any fluid can be described by a set of PCSAFT pure component parameters. The CoMT-CAMD
approach comprises two main steps as shown in Figure
1.

Figure 1: The workflow of the CoMT-CAMD approach.

In the first step, the so-called Continuous-Molecular
Targeting (CoMT), the process conditions and the molecules are simultaneously optimized. For this purpose,
the PC-SAFT pure component parameters describing
the properties of the molecules are relaxed and treated
as continuous variables of the optimization problem.
The results of this optimization are the PC-SAFT pure
component parameters of a hypothetical optimal fluid,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132101

Session 4C: Process & Chemical Engineering

the so-called target, and the corresponding optimal process conditions. In the second step, real fluids are identified in the so-called structure-mapping. For this purpose, a second-order Taylor-approximation is computed
around the hypothetical optimum. This Taylor approximation is used to estimate the objective function value
of processes with real fluids. In the structure-mapping,
real fluids can either be selected from databanks of
known fluids (Lampe et al., 2014) or designed using
Computer-Aided Molecular Design (CAMD) algorithms (Lampe et al., 2015). This CAMD algorithm employs Group Contribution (GC) methods to link PCSAFT pure component parameters to molecule structures. This link is used to identify the optimal molecular
structure by solving a mixed-integer quadratic program
(MIQP) optimization problem (for details, see Section
2.3). Due to inaccuracies in the models and the method,
usually, not only one fluid but a ranking of candidates is
desired. Thus, the CAMD algorithm is applied repeatedly using integer cuts (see e.g. Fazlollahi et al., 2012)
to exclude previously found molecules in each new run.
The CoMT-CAMD approach thus yields a list of real
fluids which best match the target. For these fluids, individual process optimizations are performed to determine the optimal process performance.
Details of the CoMT step are explained in Section 2.1
and the PC-SAFT equation of state is described in Section 2.2. The structure-mapping step of CoMT-CAMD
is discussed in more detail in Section 2.3 followed by a
short section on the final process optimizations.

2.1 Continuous-Molecular Targeting
The aim of the CoMT step is the simultaneous optimization of process conditions and fluids to obtain a target
for the subsequent structure-mapping (Bardow et al.,
2010). As mentioned before, the fluids are modeled with
the PC-SAFT equation of state. The PC-SAFT pure
component parameters used to describe the fluids are relaxed and thus treated as continuous variables of the optimization problem. This relaxation transforms the
mixed-integer nonlinear program (MINLP) of the fully
integrated design into a nonlinear program (NLP) given
by problem (1) (Lampe et al., 2015):
max
,

. .
							

,

, 0
, =0
 , =0
$ '

 
min  

min

m
l
max 	   .

max 	 

"

	

"!"-#$%&"
" () 	* "

"
(1)

Here, is the vector with the degrees of freedom of the
process and the vector containing the PC-SAFT pure
component parameters of the molecules.

DOI
10.3384/ecp17132101

The objective function is, for example, a thermodynamic measure like an efficiency. The process model is
and
formulated in terms of inequality constraints
equality constraints . The PC-SAFT equation of state
 is used to compute thermodynamic quantities based
on the pure component parameters and the process conditions. Additionally, bounds are defined on the process
degrees of freedom 012 and 034 and the PC-SAFT
pure component parameters 012 and 034 .
Additional linear inequality constraints ($  ') are
used which set up a convex hull around the PC-SAFT
pure component parameters of real fluids (see Lampe et
al. (2014) for details). This ensures that the CoMT step
results in a hypothetical fluid which is similar to any real
substance. The NLP optimization of the CoMT step results in a hypothetical optimal fluid  and optimal process conditions .
In general, the pure component parameters  of the
optimal hypothetical fluid are not equal to those of any
real fluid. Thus, real substances with favorable performance are identified in a subsequent structure-mapping
(discussed in Section 2.3).

2.2 PC-SAFT Equation of State
The Perturbed-Chain Statistical Associating Fluid Theory (Gross and Sadowski, 2001, 2002; Gross, 2005;
Gross and Vrabec, 2006) is a physically-based equation
of state model for the residual Helmholtz energy. The
underlying molecular picture considers molecules as
chains of hard spheres (segments) which interact with
each other.
Both pure fluids and fluid mixtures are described
based on typically 3 to 7 parameters per each pure component. In this work, we consider only non-polar and
non-associative molecules, so that 3 parameters of PCSAFT are sufficient: the segment number , the segment diameter 6 and the segment dispersion energy
7 8 .
As only the residual part of the Helmholtz energy is
calculated from PC-SAFT, an additional property is required to calculate absolute caloric properties. Here, the
additional property is the ideal gas heat capacity. In the
CoMT step, the molecules are exclusively described by
the PC-SAFT pure component parameters, which
should therefore also be used in order to obtain the ideal
gas heat capacity (Lampe et al., 2014). For this purpose,
Quantitative Structure-Property Relationships (QSPR)
are used with PC-SAFT pure component parameters as
inputs to calculate ideal gas heat capacities :,;< (for details see Stavrou et al., 2014; Lampe et al., 2014; 2015).
Additionally, another QSPR model based on PC-SAFT
pure component parameters is used to calculate molar
masses (Lampe et al., 2015).
By combining the QSPR methods and PC-SAFT, all
thermodynamic equilibrium properties can be calculated
based on 3 PC-SAFT pure component parameters in a
thermodynamically consistent form.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

103

Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting

min B

2.3 Structure-Mapping using ComputerAided Molecular Design

M

As shown in Figure 1, we use Computer-Aided Molecular Design (CAMD) in the structure-mapping step in
order to design real fluids which best match the target
obtained from the CoMT step. For this purpose, a measure for the expected performance of fluids in the process
is needed.
A simple measure is the distance     of a real
fluids pure component parameters from those of the hypothetical optimal fluid in the space of the PC-SAFT parameters. However, this simple measure is not appropriate since it neglects the different sensitivities of the objective function with respect to different PC-SAFT parameters and it depends on scaling. To overcome these
limitations, a performance measure is calculated in the
space of the objective function itself. For this purpose,
we compute the following Taylor-approximation to estimate the performance:
B

=

?@A



+
+

1
2

?@A



	


 L


?@A





.

(2)

Here, ?@A is the objective function of Problem (1)
, rewritten such that it yields the optimal performance solely based on the PC-SAFT pure component
parameters:
?@A

= min

. .	

min

,

,
,
 ,





0
=0
=0

max 	 

(3)

m .

The estimated objective function value B
is used as
assessment criterion in the structure-mapping.
In this work, a CAMD algorithm is employed to design optimal molecules. This CAMD algorithm optimizes the molecular structure with respect to the performance estimate B
(2). In order to evaluate B , the
PC-SAFT pure component parameters have to be known
for each molecule. Lampe et al. (2015) employ a Group
Contribution (GC) method in order to calculate PCSAFT pure component parameters from molecule structures. They use the homosegmented approach from
Sauer et al. (2014) which they call GPC-SAFT. We use
the same method as Lampe et al. (2015) and all nonpolar, non-associating groups they considered.
Following Lampe et al. (2015), the CAMD problem
is formulated as mixed integer quadratic problem
(MIQP) by employing the second-order Taylor approximation (2) as objective function:

104

. .		

C" ( =

%D$# (  0
$  'EFG
(  O

(4)

In this formulation, a fluid is described by a vector (
representing the functional groups constituting the molecular structure. The set of PC-SAFT pure component
parameters are calculated with a GC method as described above (C" ( = . A set of constraints
(%D$# (  0) ensures feasible connectivity of the designed molecules (Struebing, 2011; Struebing et al.,
2011). A convex hull ($  'EFG ) as described in Section 2.1 is also used in the CAMD optimization. In order
to permit the design of novel fluids, the convex hull is
relaxed compared to the one used in the CoMT step, i.e.
'EFG  ' (Lampe et al., 2015). The result of the MIQP is
the optimal molecular structure of a real fluid.
A ranking of fluid candidates can be obtained by repeating the CAMD optimization with integer cuts (see
e.g. Fazlollahi et al., 2012) which exclude previously
found molecular structures from the design space.

2.4 Final Process Optimizations
The result of the structure-mapping step of CoMTCAMD is a ranking of candidate molecules. Since the
objective function used for the structure-mapping is a
second-order Taylor-approximation (2) as described in
Section 2.3, process optimizations are performed with
the identified real molecules in a final step in order to
obtain the respective optimal process conditions and actual objective function values. These objective function
values are also used to refine the ranking of the molecules.

3

CoMT-CAMD with Modelica Models

As explained in Section 1, the integrated process and
fluid design with the CoMT-CAMD approach was
based on process models implemented in a procedural
programming language so far. The contribution of this
work is to enable the utilization of CoMT-CAMD based
on object-oriented process modeling with Modelica.
The utilization of this language facilitates the convenient development, adaption and reusability of models. In
this way, the design of complex processes is enabled.
Furthermore, equation-based modeling with Modelica is
suited for the investigation of dynamic processes. The
implementation of all steps of CoMT-CAMD based on
Modelica is described in the subsequent sections.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132101

Session 4C: Process & Chemical Engineering

3.1 PC-SAFT Modelica-Package
Since the CoMT-CAMD approach is based on fluid
property calculations with PC-SAFT, these calculations
have to be available in Modelica to model the processes.
Examples of such property calculations are the calculation of saturation pressures and temperatures as well as
of caloric properties like specific enthalpies.
For this purpose, a PC-SAFT implementation written
in the procedural language FORTRAN 90 is used for external property calculations. The interface with Modelica is constructed using the Modelica external function
interface (Modelica Association, 2012).
According to Modelica Association (2012), however,
interfaces are only supported with external FORTRAN
77 code. For this reason, FORTRAN 77 subroutines are
implemented as wrappers for all relevant top-level subroutines in the FORTRAN 90 code. The wrapper subroutines are called by Modelica external functions (for
details see Modelica Association (2012)). As the properties are calculated on mole basis in the external code
and calculations on mass basis are desired for the process simulations in Modelica, additional functions for
conversions between mole and mass basis as well as unit
conversions are implemented.
In order to enable the convenient use of the PC-SAFT
property calculations in Modelica, a Modelica package
with the following functions is developed:
 Modelica external functions needed to call
external subroutines.
 Additional functions for conversion between
mole and mass basis as well as unit conversions.
 Top-level functions for each type of property calculation which call the external functions and functions for necessary conversions, perform any additional calculations
required and return the desired thermodynamic properties.
As the focus of this work is embedding Modelica in the
existing CoMT-CAMD framework, the PC-SAFT package is created independent of other libraries. The following types of property calculations are available in the
package:
 Vapor-Liquid Equilibrium (VLE) calculations for pure components with specified saturation pressure or temperature.
 pT-flash calculations for mixtures.
 Bubble point and dew point calculations for
mixtures.
 Property calculations for pure components
and mixtures in subcooled liquid and superheated vapor states.
 Estimation of the critical point.
All these functions can be conveniently used in Modelica process models.

DOI
10.3384/ecp17132101

3.2 CoMT-CAMD Based on Modelica Models and GenOpt
In order to facilitate the integrated optimization of processes and fluids based on object-oriented modeling, the
process and all its equipment models are implemented
in Modelica. For any required property calculation, the
functions in the PC-SAFT package described in Section
3.1 are utilized.
In order to find the hypothetical optimum in the
CoMT step, an objective function is defined. Then, the
Modelica process model is used to search for the point
in the solution space of process conditions and PCSAFT pure component parameters with the maximal objective function value.
One tool suited for this search is the open-source optimization program GenOpt (Generic Optimization Program) (Wetter, 2000; 2016) which provides algorithms
for parametric runs as well as several optimization algorithms and can be coupled with Modelica models (Wetter, 2009).
In this work, parametric runs with GenOpt are used
in the CoMT step to find the hypothetical optimal fluid
and the corresponding optimal process conditions. The
derivatives required for the Taylor-approximation of the
objective function are approximated by finite differences. These are computed with MatLab from the results
of the GenOpt calculations. As the output files of GenOpt are conveniently imported by MatLab, no special
interface is required here.
The CAMD formulation described in Section 2.3 was
implemented in the high-level modeling system GAMS
(General Algebraic Modeling System) (Rosenthal,
2016) which is used to solve the MIQP with integer cuts
to obtain a ranking of real fluids.
For the final process optimizations described in Section 2.4 parametric runs with GenOpt are used to find
optimal process conditions. The workflow of the Modelica-based CoMT-CAMD is shown in Figure 2.

4

Case Study: Design of a Geothermal ORC Application

The proposed molecular and process design with the
CoMT-CAMD approach based on process modeling
with Modelica is applied to a case study of a geothermal
application for an Organic Rankine Cycle. Organic Rankine Cycles (ORCs) are used to transform low temperature heat into electric power (Colonna et al., 2015). The
performance of ORCs depends strongly on the properties of the chosen working fluid. Therefore, the ORC is
a very relevant case study for the integrated fluid and
process design (Linke et al., 2015; Bao and Zhao, 2013).
In the subsequent sections, the ORC process itself as
well as the process model implemented in Modelica and
the specifications of the case study are described. In Section 4.4, the results of the integrated fluid and process
design are presented.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

105

Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting

Figure 2: Workflow of the integrated molecular and process design with CoMT-CAMD including the tools used
in the individual steps.

4.1 Organic Rankine Cycles
Organic Rankine Cycles (ORCs) are energy conversion
processes with a sequence of process steps equivalent to
the classical thermodynamic Rankine cycle (Colonna et
al., 2015). The flowsheet and the temperature-entropy
diagram of a basic ORC process are shown in Figure 3.
In contrast to classical Rankine cycles which use water
as working fluid, organic fluids are utilized in ORCs.
The organic fluid can be tailored to specific applications, in particular the utilization of low temperature
heat and cases with low power output where water becomes unfavorable (Colonna et al., 2015).
In the ORC process, the liquid working fluid (state 1
in Figure 3) is pressurized in a pump (1 2) with power
input !P before the vaporization in an evaporator (2
3) using heat (QRFS3@) from the available heat source with
inlet temperature &TU,12. At the outlet of the evaporator
(State 3 in Figure 3), the working fluid can be in a saturated or superheated vapor state. The vapor is expanded
in a turbine (3 4) to gain the desired power output !V.
Subsequently, the fluid is completely condensed in a
condenser (4 1) by transferring heat (QRW?2X ) to a cooling medium with inlet temperature &YZ,12 in order to
close the cycle.

106

Figure 3: Upper part: Flowsheet of a basic ORC process.
Lower part: T-s diagram for ORC process, heat source and
heat sink.

4.2 Modelica ORC Model
To demonstrate the integrated design of working fluid
and process, the ORC is modeled assuming steady state
conditions. Four equipment models are implemented
and connected to a process model (cf. Figure 3): a pump,
a turbine and two heat exchangers, namely the evaporator and the condenser. These equipment models are connected as shown in Figure 3 via suitable connectors to
assemble an ORC process model. Although the use of
libraries for modeling the ORC would be possible, no
existing libraries are used in this work to keep the equipment models and connectors simple. The most important model equations and assumptions are presented
in the following.
4.2.1 Pump

The pump is adiabatic and modeled based on an isentropic pressure increase and an isentropic efficiency
[1\,] :

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132101

Session 4C: Process & Chemical Engineering

																			

],12


									],?^A


],?^A

=

=

														],?^A =

FS3@ ,


],?^A

(5)

_
d_`,ef
],12 + 	 `,abc
geh,`

Here, ],12 =  and ],?^A =  are the specific en
thalpies at pump inlet and outlet, respectively, and ],?^A
is the specific enthalpy at the pump outlet in case of is
entropic pressure increase. ],12 and ],?^A
are the specific entropies at inlet and outlet conditions for the isentropic case. The pressure level of the evaporation is
termed FS3@.
From the energy balance, the required power input
can be obtained:
!] = R Zi j],?^A  ],12 k

(6)

where R Zi is the working fluid mass flow rate and !]
the required power input.

with a known inlet temperature &TU,12, mass flow R TU
and constant specific heat capacity TU .
The heat transferred is calculated from energy balances of the evaporator:
	QRFS3@ = R TU

TU j&TU,12

 &TU,?^A k	

																							= R Zi jFS3@,?^A  FS3@,12 k

(9)

where &TU,?^A denotes the outlet temperature of the heat
source and FS3@,12 and FS3@,?^A the specific enthalpies
of the working fluid at the evaporator inlet and outlet,
respectively.
The specific enthalpy of the working fluid at the outlet
of the evaporator FS3@,?^A is calculated from the evaporator pressure FS3@ and outlet temperature &l. The
temperature &l is calculated from the saturation temperature of the working fluid and a degree of superheating
&\n .

4.2.2 Turbine

4.2.4 Condenser

The adiabatic turbine is modeled in the same way as the
pump based on an isentropic efficiency [1\,V :

The condenser is modeled based on energy balances
equivalent to those shown for the evaporator. It is assumed that cooling water with known inlet temperature
&YZ,12 and a known constant specific heat capacity YZ
is used as cooling medium. The required mass flow of
the cooling water is calculated from a given temperature
increase of 5 K. The outlet state of the working fluid is
assumed to be a saturated liquid state. Pressure losses in
the condenser are neglected.

			

V,12

=


	V,?^A
=


V,?^A 																																							

j W?2X , V,?^A
k																					

								V,?^A = V,12

(7)


+ 	 [1\,V jV,?^A
 V,12 k					

where W?2X is the pressure level of condensation. The
power output of the turbine can be obtained from an energy balance as:
!V = R Zi jV,?^A  V,12 k

(8)

4.2.3 Evaporator

It is assumed that pressure losses in the evaporator can
be neglected such that preheating and evaporation take
place on the same constant pressure level FS3@. The geothermal heat source is assumed to be hot liquid water

4.3 Specifications of the Case Study and the
Optimization Problem
The specifications of the case study are based on the
subcritical geothermal ORC application presented by
Heberle and Brggemann (2010) and are shown in Table 1. The ORC designed in our work is medium-sized
regarding its power capacity and utilizes low-temperature heat from a geothermal source with a maximum
temperature of 120 C.

Table 1: Specifications of the case study based on Heberle and Brggemann (2010).

Parameter
heat source mass flow
rate
heat source inlet temperature
heat source specific
heat capacity
min. and max. absolute pressure
max. reduced pressure

DOI
10.3384/ecp17132101

Symbol

Value

R TU

66 kg/s

cooling water inlet/outlet temperature

&TU,12

120 C

cooling water heat capacity

TU

4200 J/(kg K)

pinch temperature difference

012/034

1 bar / 50 bar

min. vapor fraction at
turbine outlet

E,034

Parameter

Symbol

Value

&YZ,12/&YZ,?^A

15 C / 20 C

YZ

4200 J/(kg K)

& @12Wn

5K

p A^Eq,012

0.95

0.8

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

107

Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting

Table 2: Optimal process conditions and PC-SAFT parameters of the hypothetical optimal fluid resulting from the CoMT
step as well as the achieved net power output. Values at their bounds are marked with a +.

Parameter

Symbol

condensation pressure
evaporation pressure
degree of superheating+
working fluid mass flow
rate


W?2X

FS3@

&\n

R Zi

Value
7.1 bar
25.7 bar
0 C
70.0 kg/s

The degrees of freedom of the ORC process considered in the optimization are the pressure levels of
evaporation FS3@ and condensation W?2X , the mass
flow rate of the ORC working fluid R rs and the degree
of superheating at the evaporator outlet &\n . The PCSAFT pure component parameters considered for the
working fluid optimization are the segment number ,
segment diameter 6 and segment dispersion energy
7 8 (cf. Section 2.2).
Bounds on the process degrees of freedom are minimal and maximal absolute pressures 012	 and 034 of
1 bar and 50 bar, respectively. Additionally, an upper
bound of the reduced pressure E,034, defined as the absolute pressure divided by the critical pressure W , of
0.8 is used because only subcritical ORCs are considered. In order to avoid damage of the turbine, it is important in practice to avoid the formation of liquid droplets during expansion. Thus, a minimal vapor fraction
p A^Eq,012 of 0.95 at the turbine outlet is used as a further
constraint (see Table 1).
Additional constraints arise to ensure that the temperature differences between the heat source and the working fluid in the evaporator and between the working
fluid and the cooling water in the condenser do not violate the specified pinch temperature difference & @12Wn
of 5 K at any point. As can be seen in the T-s diagram
shown in Figure 3, possible pinch points in the evaporator are at the inlet and outlet and at the point where the
working fluid reaches the saturation temperature. Possible pinch points in the condenser are at the condenser
inlet and, in case the working fluid is superheated at the
inlet, at the point where it first reaches a saturated state.
The net power output !2FA of the ORC is used as objective function for the optimization and can be calculated from the required power input of the pump !] and
the power output of the turbine !V as
,

= !2FA =  !V + !]

(10)

This definition of !2FA leads to a positive objective function
, which is maximized in the optimization.

4.4 Results
To identify an optimal working fluid and the corresponding optimal process conditions for the considered

108

Parameter

Symbol

segment number
segment diameter
segment dispersion energy
net power output

6

Value



3.15



3.45 

7 8


!2FA



164.0 K
1.9 MW

ORC the CoMT-CAMD approach is used (see Figures
1 and 2). First, an optimal hypothetical fluid and corresponding process conditions are obtained as target in the
CoMT step. Subsequently, fluids are designed in the
CAMD step which best match the target.
The results of the CoMT step are shown in Table 2.
The PC-SAFT pure component parameters shown in the
table correspond to a hypothetical optimal fluid. The net
power output !2FA of the target is 1.9 MW. This target
value serves as an upper bound as it represents the highest power output achievable for all hypothetical fluids
represented by PC-SAFT in the considered convex hull
(cf. Section 2.1).
In order to determine a ranking of real fluids which
best match the hypothetical optimum, a ComputerAided Molecular Design (CAMD) algorithm is employed as described in Sections 2.3 and 3.2. Subsequently, the optimal process parameters and corresponding net power output !2FA for the individual fluids are
obtained from process optimizations (cf. Sections 2.4
and 3.2).
The top 10 fluids of the CAMD step are presented in
Table 3 together with the respective net power outputs
resulting from the process optimizations.
As can be seen in Table 3, the top fluids suggested by
the CAMD algorithm are all linear and branched alkanes
and alkenes with a maximum of 6 carbon atoms. We
identify propene as the best working fluid for the ORC
with a net power output !2FA of 1.45 MW. This value is
24 % less than the target value of the hypothetical molecule.
From Table 3, it can be seen that the net power outputs determined in the process optimizations do not perfectly match the ranking from the CAMD step. The objective function used in the CAMD step is a Taylor-approximation of the real objective function of the integrated optimization problem as explained in Section 2.
As the Taylor-approximation does not match the real objective function perfectly, the ranking from the CAMD
step slightly deviates from the final ranking based on
optimized net power outputs. It is therefore recommended to generate a list of candidates and not only one
working fluid. This behavior was also found in earlier
implementations of the CoMT-CAMD approach (cf.
Lampe et al., 2014; 2015) and is thus not specific for the
Modelica-based implementation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132101

Session 4C: Process & Chemical Engineering

Table 3: Top fluids resulting from the CAMD step and corresponding net power output determined using process optimizations. The order is according to the ranking of the
CAMD step. The sorted rank according to the results of the
individual process optimizations is shown in parentheses.

Rank
(Sorted Rank)
1 (2)
2 (6)
3 (1)
4 (9)
5 (3)
6 (4)
7 (7)
8 (5)
9 (10)
10 (8)

Fluid

Net Power Output

Propane
Neopentane
Propene
Propyne
Isobutene
2-Butene
Butane
1-Butene
Neohexane
1-Butyne

1.44 MW
1.31 MW
1.45 MW
1.24 MW
1.38 MW
1.38 MW
1.25 MW
1.33 MW
1.11 MW
1.25 MW

Clearly, the net power output of the target given in Table
2 serves as an upper bound of the objective function.
Therefore, the target is not reached by the designed real
working fluids.
In order to find the target in the CoMT step with GenOpt, about 2105 evaluations of the process model are
required. On the other hand, an individual process optimization for one working fluid requires about 104 evaluations of the process model. Thus, the effort for the integrated molecular and process design with the Modelica-based CoMT-CAMD is similar to the effort for process optimizations for about 30 working fluid candidates. This shows the strength of CoMT-CAMD, where
thousands of different molecules are considered in the
structure-mapping. Additionally, there are further improvements possible compared to the current implementation. As presented in Section 3.2, parametric runs with
GenOpt are used in the CoMT step to find the optimal
hypothetical fluid and the corresponding optimal process conditions. Employing gradient-based optimization
instead of the parametric runs has the potential to further
decrease the computational effort while substantially increasing the accuracy.

5

Conclusion

In this work, we propose the Continuous-Molecular Targeting  Computer-Aided Molecular Design (CoMTCAMD) approach based on object-oriented process
modeling with Modelica. The CoMT-CAMD approach
originally proposed by Bardow et al. (2010) enables the
simultaneous optimization of processes and fluids without any fluid pre-selection by utilizing the physicallybased equation of state PC-SAFT. So far, implementations of the CoMT-CAMD design approach were based
on process modeling utilizing procedural programming
languages. Thus, the reusability of models has been hindered and the investigation of process variants as well
as complex processes has been cumbersome. For this
reason, it is shown in this work how integrated process
DOI
10.3384/ecp17132101

and molecular design with CoMT-CAMD can be based
on object-oriented process modeling with Modelica.
The proposed implementation uses the Modelica external function interface for external property calculations
with PC-SAFT and the optimization tool GenOpt for the
search of optimal hypothetical fluids and process conditions. Additionally, a Computer-Aided Molecular Design algorithm implemented in GAMS is used in order
to design real fluids which best match the hypothetical
optimum. The Modelica-based CoMT-CAMD implementation is demonstrated for the design of a subcritical
geothermal Organic Rankine Cycle (ORC). The results
show that the approach efficiently identifies optimal
ORC processes and working fluids. The CoMT-CAMD
approach implemented in an object-oriented language
for process modeling allows for convenient and efficient
integrated process and fluid design for complex processes. Future work will address the use of deterministic
optimization and the utilization of libraries for the Modelica-based CoMT-CAMD.

Acknowledgements
We thank the Deutsche Forschungsgemeinschaft (DFG)
for funding this work (BA2884/4-1). Furthermore, the
authors thank Heike Schreiber, Matthias Lampe and
Christian Schulze for valuable discussions.

References
Claire S. Adjiman, Amparo Galindo and George Jackson.
Molecules Matter: the Expanding Envelope of Process Design. Computer Aided Chemical Engineering, 34:5564,
2014. doi: 10.1016/B978-0-444-63433-7.50007-9.
Junjiang Bao and Li Zhao. A Review of Working Fluid and
Expander Selections for Organic Rankine Cycle. Renewable and Sustainable Energy Reviews, 24:325342, 2013.
doi: 10.1016/j.rser.2013.03.040.
Andr Bardow, Klaas Steur and Joachim Gross. ContinuousMolecular Targeting for Integrated Solvent and Process Design. Industrial & Engineering Chemistry Research,
49(6):28342840, 2010. doi: 10.1021/ie901281w.
Jakob Burger, Vasileios Papaioannou, Smitha Gopinath,
George Jackson, Amparo Galindo and Claire S. Adjiman. A
Hierarchical Mmethod to Integrated Solvent and Process
Design of Physical CO2 Absorption Using the SAFT- Mie
Approach. AIChE Journal, 61(10):32493269, 2015. doi:
10.1002/aic.14838.
Piero Colonna, Emiliano Casati, Carsten Trapp, Tiemo
Mathijssen, Jaakko Larjola, Teemu Turunen-Saaresti and
Antti Uusitalo. Organic Rankine Cycle Power Systems.
Journal of Engineering for Gas Turbines and Power,
137(10):100801, 2015. doi: 10.1115/1.4029884.
Samira Fazlollahi, Pierre Mandel, Gwenaelle Becker and
Francois Marchal. Methods for Multi-Objective Investment and Operating Optimization of Complex Energy Systems. Energy, 45(1):1222, 2012. doi: 10.1016/j.energy.2012.02.046.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

109

Integrated Process and Molecular Design with Modelica Using Continuous-Molecular Targeting

Peter Fritzson. Modelica  A Language for Equation-Based
Physical Modeling and High Performance Simulation. Applied Parallel Computing, 1541:149-160, 1998. ISSN:
0302-9743.
Rafiqul Gani. Chemical Product Design. Computers & Chemical Engineering, 28(12):24412457, 2004. doi:
10.1016/j.compchemeng.2004.08.010.
Smitha Gopinath, George Jackson, Amparo Galindo and
Claire S. Adjiman. Outer approximation algorithm with
physical domain reduction for computer-aided molecular
and separation process design. AIChE Journal, 62(9):3484
3504, 2016. doi: 10.1002/aic.15411.
Joachim Gross and Gabriele Sadowski. Perturbed-Chain
SAFT. Industrial & Engineering Chemistry Research,
40(4):12441260, 2001. doi: 10.1021/ie0003887.
Joachim Gross and Gabriele Sadowski. Application of the
Perturbed-Chain SAFT Equation of State to Associating
Systems. Industrial & Engineering Chemistry Research,
41(22):55105515, 2002. doi: 10.1021/ie010954d.
Joachim Gross. An Equation-of-State Contribution for Polar
Components. AIChE Journal, 51(9):25562568, 2005. doi:
10.1002/aic.10502.
Joachim Gross and Jadran Vrabec. An Equation-of-State Contribution for Polar Components. AIChE Journal,
52(3):11941204, 2006. doi: 10.1002/aic.10683.
Florian Heberle and Dieter Brggemann. Exergy Based Fluid
Selection for a Geothermal Organic Rankine Cycle for
Combined Heat and Power Generation. Applied Thermal
Engineering,
30(11-12):13261332,
2010.
doi:
10.1016/j.applthermaleng.2010.02.012.
Matthias Lampe, Marina Stavrou, Hanns M. Bcker, J. Gross
and A. Bardow. Simultaneous Optimization of Working
Fluid and Process for Organic Rankine Cycles Using PCSAFT. Industrial & Engineering Chemistry Research,
53(21):88218830, 2014. doi: 10.1021/ie5006542.
Matthias Lampe, Marina Stavrou, Johannes Schilling, Elmar
Sauer, Joachim Gross and Andr Bardow. Computer-Aided
Molecular Design in the Continuous-Molecular Targeting
Framework Using Group-Contribution PC-SAFT. Computers & Chemical Engineering, 81:278287, 2015. doi:
10.1016/j.compchemeng.2015.04.008.
Patrick Linke, Athanasios Papadopoulos and Panos Seferlis.
Systematic Methods for Working Fluid Selection and the
Design, Integration and Control of Organic Rankine CyclesA Review. Energies, 8(6):47554801, 2015. doi:
10.3390/en8064755.
Modelica Association. Modelica - A Unified Object-Oriented
Language for Systems Modeling - Language Specification
Version 3.3. URL= https://www. modelica. org/documents/ModelicaSpec33. Pdf , 2012.
Athanasios I. Papadopoulos and Patrick Linke. Integrated Solvent and Process Selection for Separation and Reactive Separation Systems. Chemical Engineering and Processing:
Process Intensification, 48(5):10471060, 2009. doi:
10.1016/j.cep.2009.02.004.
Frances E. Pereira, Emmanuel Keskes, Amparo Galindo,
George Jackson and Claire S. Adjiman. Integrated Design
of CO2 Capture Processes from Natural Gas. In: Efstratios
Pistikopoulos, Michael Georgiadis and Eustathios S. Kik-

110

kinides. Editors. Process Systems Engineering: Energy Systems Engineering. Weinheim: Wiley-VCH Verlag GmbH
& Co. KG, pp. 231-248, 2008.
Frances E. Pereira, Emmanuel Keskes, Amparo Galindo,
George Jackson and Claire S. Adjiman. Integrated Solvent
and Process Design Using a SAFT-VR Thermodynamic
Description. Computers & Chemical Engineering,
35(3):474491,
2011.
doi:
10.1016/j.compchemeng.2010.06.016.
Richard E. Rosenthal. GAMS  a User's Guide, GAMS Release 24.6.1. URL: http://www.gams.com/help/topic/
gams.doc/userguides/GAMSUsersGuide.pdf. 2016.
Dennis Roskosch and Burak Atakan. Reverse Engineering of
Fluid Selection for Thermodynamic Cycles with Cubic
Equations of State, Using a Compression Heat Pump as Example. Energy, 81:202212, 2015. doi: 10.1016/j.energy.2014.12.025.
Nikolaos V. Sahinidis, Mohit Tawarmalani and Minrui Yu.
Design of Alternative Refrigerants via Global Optimization. AIChE Journal, 49(7):17611775, 2003. doi:
10.1002/aic.690490714.
Elmar Sauer, Marina Stavrou and Joachim Gross. Comparison
between a Homo- and a Heterosegmented Group Contribution Approach Based on the Perturbed-Chain Polar Statistical Associating Fluid Theory Equation of State. Industrial
& Engineering Chemistry Research, 53(38):1485414864,
2014. doi: 10.1021/ie502203w.
Marina Stavrou, Matthias Lampe, Andr Bardow and Joachim
Gross. Continuous Molecular TargetingComputer-Aided
Molecular Design (CoMTCAMD) for Simultaneous Process and Solvent Design for CO2 Capture. Industrial & Engineering Chemistry Research, 53(46):1802918041, 2014.
doi: 10.1021/ie502924h.
Heiko Struebing. Identifying Optimal Solvents for Reactions
Using Quantum Mechanics and Computer-Aided Molecular Design. Ph.D. thesis, Imperial CollegeLondon, London,
2011.
Heiko Struebing, Amparo Galindo and Claire S. Adjiman. Optimal Solvent Design for Reactions Using Computer-Aided
Molecular Design. URL: http://www.minlp.org/library/problem/mod/index.php?lib=MINLP&i=180&pi=137. 2011.
Michael Wetter. Design Optimization with GenOpt. Building
Energy Simulation, (21):1928, 2000.
Michael Wetter. Modelica-Based Modelling and Simulation
to Support Research and Development in Building Energy
and Control Systems. Journal of Building Performance
Simulation,
2(2):143161,
2009.
doi:
10.1080/19401490902818259.
Michael Wetter. GenOpt  Generic Optimization Program 
User Manual  Version 3.1.1. URL: https:// http://simulationresearch.lbl.gov/GO/download/manual-3-1-1.pdf,
2016.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132101

Dynamic Simulations of the Post-combustion CO2 Capture System
of a Combined Cycle Power Plant
Rubn M. Montas

Lars O. Nord

Department of Energy and Process Engineering, NTNU  Norwegian University of Science and Technology,
Trondheim, Norway

Abstract
Dynamic process models of the capture unit of a
600 MW combined cycle power plant with postcombustion CO2 capture were developed in the
Modelica language. The process models were utilized to
understand the transient response of the capture unit
when the plant was initially operated at steady-state
conditions at different power plants loads. Simulations
to characterize the open-loop response of main process
variables of the process to step-change disturbances in
flue gas mass flow rate, solvent circulation mass flow
rate and reboiler duty were performed. It was found that
the plant was slower when operated at lower loads, i.e.,
it required longer total stabilization times for the most
relevant variables of the process. Simulations revealed
that the PCC unit responded significantly faster to an
increase in exhaust gas mass flow rate than to a
reduction in exhaust gas mas flow rate.
Keywords: transient, carbon capture, gas liquid
contactors, operational flexibility, chemical absorption.

1

Introduction

CO2 capture and storage (CCS) comprises a group of
technologies that can significantly reduce the CO2
emissions from thermal power plants and other
industrial sources (IEA, 2016). Post-combustion CO2
capture based on the chemical absorption-desorption
process using amines is a technology that has been
technically proven at commercial scale from coal fired
power plants in projects such as Boundary Dam in
Saskatchewan, Canada, and the Petra Nova project in
Texas, USA.
The introduction of large shares of variable
renewable energy sources such as wind and solar in
power systems is changing the operating patterns of
thermal power generation units, including coal power
plants and natural gas combined cycle plants (IEA,
2011). Power plants traditionally operated as base load
units are operated as load-following units (Montas, et
al., 2016). Therefore, during the last years, interest has
grown in the field of operating flexibility of thermal
power plants with CO2 capture technologies (IEA-GHG,
2012).

DOI
10.3384/ecp17132111

The low amount of existing commercial-scale postcombustion capture plants (PCC) and the scarcity of
published transient performance data of such systems
claims for an interest for the development of dynamic
process models (Bui, et al., 2014). These models allow
studying plant dynamic performance, analyzing various
plant transient events as well as developing and
implementing optimal control strategies for PCC plants
integrated with thermal power plants. Dynamic process
simulation provides process insight and contributes to
the development of the learning curve for flexible
operation of future thermal power plants with CO2
capture.
The purpose of the study is to provide understanding
of the open-loop transient performance of the main
process variables of the PCC unit at different load
operation points of the power plant. A thermal power
plant operated as load-following unit will be operated at
part-load conditions during a significant amount of
hours during its lifetime (Montas, et al., 2016).
Therefore it is of importance to find out differences in
the transient behavior of the process at part-load
operating conditions with respect to those of nameplate
capacity. In this work, a dynamic process model of the
PCC unit of a 600 MW combined cycle power plant with
post-combustion CO2 capture using aqueous
monoethanolamine (MEA) as chemical solvent is
utilized for providing understanding of the open-loop
response of key performance variables to different
disturbances applied to the PCC plant. The process
insight and understanding developed in this work will
be valuable to develop control strategies of the process
when integrated with the thermal power plant.

2

Post-combustion CO2 capture with
chemical absorption

2.1 Chemical absorption process
The process of CO2 capture by chemical absorption is a
two-steps regenerative process; one involves the
absorption of CO2 into a solvent, while the other
involves the desorption or stripping of CO2 from the
solvent and the regeneration of the solvent. The process
conditions change in the absorption and desorption

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

111

Dynamic Simulations of the Post-combustion CO2 Capture System of a Combined Cycle Power Plant

CO2 rich to compression

Depleted flue gas

PT PC

Make up water

LAC A

TT TC

TANK

C.W.

C.W.

FT FC

ABSORBER A

TT TC
LT LC

Fs,a

L/R HX
DESORBER

Depleted flue gas

LT
LAC B
LAC A

C.W.

FT FC
ABSORBER B

REBOILER

C.W.

DCC

Flue gas

Qreb

LC

TT TC
LT LC

Fs,b

Fabs,in

Figure 1. Process configuration of the post combustion CO2 capture unit (PCC) of the natural gas combined cycle power
plant studied in this work. Includes temperature (T), level (L), flow (F) and pressure (P); transmiters (T) and controllers (C).

process, being main changes temperature and pressure,
and also solvent concentrations and pH. For absorption,
low temperature and high partial pressure of CO2 is
desired, while for desorption, high temperature and low
partial pressure of CO2 is desired.
When the process is utilized for flue gas treatment
from a power plant, the exhaust gases are normally
cooled down by means of a direct contact cooler (DCC),
that reduces the flue gas temperature and the water
content. A fan allows overcome the gas pressure drop in
the absorber, which is operated slightly above
atmospheric conditions, and at around 40 C, refer to
Figure 1. In the absorber column, the exhaust gas
flowing upwards meets the chemical solvent flowing
downwards. Packing material allows having a thin film
of liquid with high surface contact area for heat and
mass transfer between the gas and liquid phases, and the
exothermal chemical absorption process. Depleted flue
gas leaves the absorber at the top through a stack,
normally after flowing through a water wash section that
allows keeping the water mass balance of the process
and reduces chemical solvent emissions due to solvent
droplets or solvent vapor carry over. The rich solvent,
i.e., solvent with a lot of bounded CO2, accumulates in
the absorber sump and is then pumped towards the top
of the stripper. An intermediate heat exchanger allows
for heat integration between the absorber and stripper
columns. The rich solvent is heated up by the lean
solvent coming from the stripper bottom towards around
110 C and then enters the stripper at the top of the
column. This heat integration allows reducing reboiler
and cooling duties. A mixing tank allows for
112

accumulation of the solvent at different operating
conditions of the plant.
The desorption process normally occurs at around
100 to 130 C. Steam supplied from the power plant
provides the reboiler duty required to regenerate the
solvent (endothermal desorption process), and to
generate the stripping vapors flowing upwards in the
stripper column, consisting mainly of H2O and CO2. The
regenerated lean solvent is sent to the absorber inlet via
the heat integration exchanger and a lean amine cooler
that controls the temperature of the solvent at the inlet
of the absorber to around 40 C. At the top of the stripper
there is a condenser and a cooler where the solvent and
steam condenses. The condensate is conducted back to
the column via a reflux. The product CO2 rich flow the
top of the stripper is conducted to the compression
section where it will be conditioned for transport and
storage purposes.

2.2 Process configuration
The PCC unit was designed to treat flue gas from a
611 MW combined cycle power plant. The gas turbine
(GT) of the power plant was the heavy duty Mitsubishi
JAC 701, and the steam cycle consisted of a threepressure reheat (3PRH) configuration. The design of the
PCC unit included the process integration with the
power plant through the flue gas line from the HRSG
outlet and a steam extraction from the steam turbines
IP/LP crossover. The steam extraction was utilized to
feed the reboiler duty required to produce the stripping
vapors needed for chemical desorption in the stripper
column. The design point chosen for the post-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132111

Session 4C: Process & Chemical Engineering

combustion unit was 100% GT load under ISO
conditions, which, for the gas turbine, corresponded
to flue gas with a mass flow rate of 887.1 kg/s with
4.33 vol % CO2 (wet). The chemical solvent utilized
was 30%wt aqueous MEA and the target capture rate
was 90%. Further details on design aspects of PCC units
for combined cycle power plants can be found
in (Dutta, et al., 2017).
The resulting process configuration of the PCC unit
consisted of a two absorbers and one stripper layout, as
shown in Figure 1. Each absorber column had
dimensions of 16.3 m in diameter and 23.2 m height,
while the desorber had a 9.7 m diameter with 10 m
height. The process equipment included absorber
columns, desorber column and reboiler, overhead
condenser, internal lean/rich heat exchanger, mixing
tank for water and MEA makeups, direct contact coolers
and circulation pumps. A fan was included in the
process to overcome the pressure drop imposed by the
absorber column.

3

Dynamic process model
development and validation

The Modelica library Gas Liquid Contactors (GLC)
(Modelon AB, 2016), from Modelon AB, was utilized
as a basis to develop the dynamic process model of the
PCC unit. The library contains dynamic process models
of the main equipment for systems level modeling of
the absorber-desorber process with monoethanolamine
(MEA) as chemical solvent. That equipment includes
absorber and desorber columns, sumps, reboiler,
condensers, water wash sections, pumps, valves, mixing
tank, and property media packages.
The chemical absorption-desorption process within
packed segments was modelled considering the twofilm theory approach for heat and mass transfer.
Chemical equilibrium for reactions was assumed, and
mass transfer was modeled considering rate-based
models with enhancement factor (Kvamsdal, et al.,
2009). Detailed description of the dynamic process
models included in the GLC library has been presented
previously in literature (Prl, et al., 2011).
The dynamic process models included in the GLC
library have been previously validated with large-scale
experimental data by (Montas, et al., 2017). The
validation consisted of modeling the whole absorberdesorber system of the demonstration scale chemical
absorption plant at CO2 Technology Centre Mongstad
(TCM DA), in Norway. The amine plant at TCM DA
was configured to treat exhaust gases coming directly
from the exhaust of a natural gas fueled combined heat
and power (CHP) plant placed at Mongstads refinery.
The exhaust gas from two GE 9001E gas turbines
contains about 3.5 %vol CO2, and around 3% of the total
exhaust gas mass flow rate is conducted to the amine
plant for CO2 absorption. The PCC plant at TCM can

DOI
10.3384/ecp17132111

treat up to 60 000 Sm3/hr of exhaust gas and can capture
around 80 ton CO2/day at nameplate capacity when
configured to treat CHP gas. The experimental data
utilized for validation includes steady-state data for a
wide range of operating conditions and multiple
transient events. The plant was operated with 30 wt %
aqueous MEA. The conclusion of the work in
(Montas, et al., 2017) is that the process models can
capture, with sufficient accuracy, the steady-state and
transient phenomena of the process at the demonstration
plant scale. In addition, it gives confidence towards
using the models for simulation and analysis of the
transient performance of the scaled-up process to
commercial scale of 4770 ton/day CO2 captured.
Rules for consistent inventory control (Aske &
Skogestad, 2009) were applied to design the regulatory
control layer of the PCC unit in Figure 1. It included
level controllers for absorbers and stripper sumps,
overhead condenser pressure control, lean solvent
temperature at absorbers inlet, and exhaust gas
temperature at absorber inlet. The controllers were
tuned by means of the SIMC tuning rules.
The supervisory control layer for this process has
three degrees of freedom, consisting of the two solvent
mass flow rates at absorber inlet  s,a and  s,b, and the
reboiler duty reb.

4

Process simulations description

Generally, a combined cycle power plant is brought to
part-load operating conditions by reducing the GT load
and consequently the steam turbines power output will
be reduced. A GT load reduction results in reduced GT
exhaust gas mass flow rate sent to the HRSG of the
combined cycle and to the absorbers of the PCC unit.
The open-loop transient performance of the plant is
studied for three steady-state operating conditions of the
power plant, corresponding to 100%, 80% and 60% GT
load.

4.1 Steady-state operating conditions at
100%, 80% and 60% GT load
In order to obtain the steady-state operating conditions
of the PCC unit at the three operating points, simulations
were run with different flue gas mass flow rates as input
boundary conditions to the dynamic process model,
corresponding to different GT loads, refer to Table 1.
The exhaust gas temperature and composition of the
absorber was considered constant as boundary condition
(input). Note that the exhaust temperature at the inlet of
the absorber is normally controlled by the DCC, and that
it was observed that exhaust gas composition did not
change considerably for the purpose of this study,
considering the part load range analyzed of 100% to
60% GT load, and for the specific GT utilized in this
work. In addition, a decentralized control structure for
the supervisory control layer was included. Several

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

113

Dynamic Simulations of the Post-combustion CO2 Capture System of a Combined Cycle Power Plant

studies, including the one based on self-optimizing
control theory by (Panahi, 2011), suggest that keeping
the capture ratio Cap and a temperature in the stripper
column constant can lead to efficient operation of the
process for varying loads of the absorption-desorption
process. Therefore, the available degrees of freedom for
operation where utilized to control these process
variables. Solvent mass flow rates  s,a and  s,b were
utilized to control the respective CO2 capture rates Capa
and Capb at the top of the absorbers to the design value
of 0.9, while reboiler duty was used as manipulated
variable to control reboiler temperature Treb to the value
119 C. CO2 capture rates are calculated for each
absorber column at the top, by using Equation (1), where
 abs,in is the exhaust flue gas at the inlet of the absorber
column, Xabs,in is the CO2 mass fraction in the exhaust
gas at the absorber inlet,  abs,out is the depleted flue gas
mass flow rate at the absorber stack and Xabs,out is the
CO2 mass fraction in the flue gas at the absorber stack.
The resulting operating conditions of the PCC at
different GT loads are shown in Table 1 and Table 2.
Table 1. Values of PCC unit input variables at different
power plants load operating conditions. Note that both
absorber columns were operated in parallel, so s,a was
equal to s,b.

GT load [%] abs,in [kg/s] s,a [kg/s] reb [MW]
887.1
613.3
205.9
100
765.1
535.2
176.2
80
653.5
464.1
149.6
60
 =

, , , ,
, ,

(1)

Table 2. Values of most relevant process variables of the
PCC unit at different operating conditions of the power
plant. Note that both absorber columns were operated in
parallel, so a was equal to Capb (in the table shown as
Cap). It also resulted in same value of solvent loading at
absorbers inlets (Li,abs).

GT load [%] Li,abs Li,str Cap Prod [kg/s]
0.9
55.2
100 0.280 0.501
0.9
47.6
80 0.280 0.497
0.9
40.7
60 0.279 0.493

4.2 Open-loop step response simulations
The simulations consisted of step-changes of 10% of
main PCC inputs, or disturbances, when the plant was at
steady-state operating conditions at the three GT
operating points. Step-changes were applied to each
process input at a time, keeping the remaining process
inputs constant. The output in main process variables
was recorded and dead times and 10% settling times
were calculated.
114







Dead time  describes how long it takes before a
process variable begins to respond to a change in the
process input. With begins to respond it is meant
that the trajectory of the process variable moves out
of the band defined by the initial steady-state value
of the process variable y0, and a 1% change in the
process variable y, i.e.: -0.01 y + y0< y0< 0.01 y
+ y0, for the first time.
The 10% settling time ts is the time it takes from the
instant in which the process variable begins to
respond to the input change, until it remains within
an error band described by the final steady-state
value of the process variable y, and 10% of the
change in the process variable y, i.e.: -0.1 y + y<
y< 0.1 y + y.
The resulting total stabilization time tsta is the sum
of the dead time and the settling time. In addition,
the relative change RC in the process variable is
calculated as in Equation (2), where y0 is the initial
steady-state value of the process variable.
 (%) = 100 

 


(2)

The main inputs/disturbances applied to the process
in this analysis were:





Flue gas mass flow rate  abs,in. Note that the flow
was split and the absorber columns were operated
in parallel. This means that each absorber column
treated an exhaust gas mass flow rate of  abs,in/2.
Solvent mass flow rates at absorbers inlets  s,a and
 s,b.
Reboiler duty reb.

The responses of the main process variables of
interest in this analysis were:







Solvent lean CO2 loading at absorbers inlet Li,abs.
Solvent rich CO2 loading at stripper inlet Li,str.
CO2 capture rate at absorbers stacks Capa and Capb.
CO2 product mass flow rate Prod, at the outlet of
the overhead condenser of the desorber. This is the
CO2 rich product flow of the PCC unit sent to
conditioning, compression and transport.
Temperature at stripper column bottom Treb.

The difference in solvent loading at inlet and outlet
of the absorber determines the capability of the solvent
to carry CO2. This in turn depends on the absorber size,
operating conditions, regeneration of the solvent and
CO2 partial pressure. Solvent CO2 loading L is defined
as the ratio between moles of CO2 and moles of solvent
(mol/mol) in Equation (3).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132111

Session 4C: Process & Chemical Engineering

1

0.31

CO2 Capture rate

0.3

Flue gas -10%
Solvent flow -10%
Reboiler heat -10%

Lean CO2 loading

Flue gas +10%
Solvent flow +10%
Reboiler heat +10%

0.95

0.9

Flue gas +10%
Solvent flow +10%
Reboiler heat +10%

0.29

Flue gas -10%
Solvent flow -10%
Reboiler heat -10%

0.28

0.27

0.85
0.26
0.8

0.25
0

60

120

180

240

300

360

0

a) Time [min]

120

180

240

300

360

b) Time [min]
0.5

45

Flue gas +10%
Solvent flow +10%
Reboiler heat +10%

44
Flue gas +10%
Solvent flow +10%
Reboiler heat +10%

43
42

Flue gas -10%
Solvent flow -10%
Reboiler heat -10%

Flue gas -10%
Solvent flow -10%
Reboiler heat -10%

0.495

Rich CO2 loading

CO2 Product flow rate [kg/s]

60

41
40
39
38

0.49

0.485
37

36
0.48

35

0

60

120

180

240

300

360

420

480

540

600

660

720

780

0

60 120 180 240 300 360 420 480 540 600 660 720 780 840 900 960

d) Time [min]

c) Time [min]

Figure 2. Transient responses of the relevant process variables to different step-changes in process inputs. These simulations
correspond to the initial steady-state operation of the PCC unit for 60% GT load. Step-changes were applied at t = 0 min.

=

5

  2

(3)

  

Results and discussion

5.1 Response to step changes in flue gas
mass flow rate abs,in
The resulting response times of the PCC units main
process variables to step-changes in flue gas mass flow
rate are shown in Table 3 and Table 4. Figure 2 shows
the transient response of the main process variables for
the different step changes studied in this work. In
addition, Figure 3 shows trends of total stabilization
times tsta for the main variables of the process when
operating the plant at different loads.
It can be observed that CO2 capture rate Cap
stabilized relatively fast, within 1 h, after a disturbance
in flue gas mass flow rate. The CO2 capture rate
decreased for increased flue gas mass flow rate (+10%).
A faster response in Cap was observed when the flue gas
flow rate was increased (+10%) than when it was
decreased (-10%), showing the non-linear performance
of the PCC system. This behavior was consistent at the
different operating points of the PCC plant. The dead
time of this response was negligible, since the flue gas
mass flow rate was included in the calculation and
naturally changes when a step change is applied.

DOI
10.3384/ecp17132111

The CO2 product flow rate Prod required larger
stabilization times than Cap. This shows the differences
in performance of the absorbers and desorber columns
during transient conditions when a disturbance is
applied to the PCC unit. The dead times observed in the
CO2 product mass flow rate can be explained by the
residence time imposed by the solvent hold-ups in the
cold side of the internal heat exchangers piping and rich
solvent piping. These residence times resulted in dead
times in convectively transported variables of the liquid
solvent from absorber outlet to stripper inlet, including
rich solvent loading at the stripper inlet Li,str. Note that
the dead times of Li,str and Prod responses are similar in
Table 3 and Table 4. Stabilization of the Prod was
significantly faster when increasing flue gas mass flow
rate (around 1 h) than when flue gas mass flow rate was
decreased (9 to 11 h). It can also be observed that the
Prod response was slower at lower power plant loads,
refer to Figure 3.
For flue gas flow rate increase (+10%), the relative
change in solvent loadings was small. This is because
the solvent capacity was close to the limit under these
operating conditions. In general, it was found that lean
solvent loading at the inlet of the absorber Li,abs required
larger stabilization times tsta than rich loading at stripper
inlet Li,str. This can be explained by the buffering effect
introduced by the mixing tank placed in the recycle loop
(from stripper sump to absorber liquid inlet). In
addition, larger dead times to this specific disturbance
were found for Li,abs than for Li,str, due to the additional

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

115

Dynamic Simulations of the Post-combustion CO2 Capture System of a Combined Cycle Power Plant

Table 3. Response to +10% step increase in flue gas mass
flow rate abs,in at various GT loads. Dead times , settling
times ts and total stabilization times tsta are shown.

GT load
[%]
Li,abs
Li,str
Cap
Prod
100 Treb
Li,abs
Li,str
Cap
Prod
80 Treb
Li,abs
Li,str
Cap
Prod
60 Treb


[min]
74
26
0
26
0
36
27
0
28
0
68
34
0
34
0

10 %
ts
tsta
RC
[min] [min] [%]
53
127
0.45
11
36
0.45
12
12
-8.79
5
31
0.29
127
127
-0.05
105
141
0.47
12
39
0.50
15
15
-8.74
45
72
0.35
54
54
-0.05
88
156
0.48
13
46
0.54
17
17
-8.70
28
62
0.42
60
60
-0.06

Table 4. Response to -10% step decrease in flue gas mass
flow rate abs,in at various GT loads. Dead times , settling
times ts and total stabilization times tsta are shown.

GT load
[%]
Li,abs
Li,str
Cap
Prod
100 Treb
Li,abs
Li,str
Cap
Prod
80 Treb
Li,abs
Li,str
Cap
Prod
60 Treb

-10 %

ts
tsta
RC
[min] [min] [min] [%]
47
578
626 -2.50
26
538
564 -2.62
0
55
55 8.55
27
556
583 -0.98
3
572
575 0.30
50
639
689 -2.31
29
592
621 -2.53
0
58
58 8.84
30
603
633 -1.90
0
625
625 0.27
129
619
748 -1.99
131
529
661 -2.26
0
39
39 8.88
163
503
666 -1.85
5
667
672 -2.83

residence time introduced by liquid hold-ups in desorber
packed segments and sump, lean amine piping and hot
side piping of the integral heat exchanger, mixing tank
and lean amine cooler. Again, the plant response in

116

solvent CO2 loadings was faster when flue gas mass
flow rate was increased for all power plant loads studied,
refer to Figure 3. It must be mentioned that the relative
change in process variables to step-changes is more
significant the step-down than step-up of the flue gas
flow rate. This can be explained by the fact that the
solvent rich loading at the steady-state operating
conditions is close to the solvent limit CO2 loading
capacity, which is limited by stoichiometry.

5.2 Response to step-changes in solvent mass
flow rate s,a and s,b
The resulting response times of the PCC units main
process variables to step-changes in solvent circulation
mass flow rates are shown in Table 5 and Table 6.
Table 5. Response of the main process variables to 10%
step increase in solvent circulation mass flow rate s,a and
s,b at the inlet of the absorbers, for different GT loads.
Dead times , settling times ts and total stabilization times
tsta are shown.

GT load
[%]
Li,abs
Li,str
Cap
Prod
100 Treb
Li,abs
Li,str
Cap
Prod
80 Treb
Li,abs
Li,str
Cap
Prod
60 Treb

10 %

ts
tsta
RC
[min] [min] [min] [%]
27
50
77
8.04
25 118 143
-0.02
0 131 131
-1.46
21
40
60
-1.48
0
25
25
-1.04
31 113 144
8.19
37 112 149
-0.01
0 137 137
-1.77
25
21
46
-1.78
0
35
35
-1.05
35
67 102
7.85
29 813 842
0.00
0 161 161
-1.47
31
22
52
-1.46
0
39
39
-0.99

Solvent circulation mass flow rate step changes
resulted in inverse responses in CO2 capture rates, refer
to Figure 2. This can be explained by the coupled
operation of the absorbers and desorber columns via the
recycle loop. When increasing the solvent circulation
flow rate (10%), the Cap increases during the first part
of the transient. However, since the reboiler duty is kept
constant, the lean loading at the inlet of the absorber
Li,abs will increase (more solvent being circulated for the
same regeneration energy introduced in the process
reb), resulting in a reduction of Cap, with a delay
imposed by solvent hold-ups (residence time) through
piping and mixing components in the recycle loop.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132111

Session 4C: Process & Chemical Engineering

Observe the large dead time in Li,abs in Figure 2. An
analog explanation could be used for the inverse
response observed when solvent circulation mass flow
rate was reduced. Larger stabilization times were
required when the plant was operated at lower loads, see
Figure 3.
For these disturbances, CO2 product mass flow rate
Prod stabilizes relatively faster (around 1 h) than CO2
capture rate Cap (23 h). Similar stabilization times tsta
were noted when increasing (10%) and when decreasing
(-10%) the solvent circulation mass flow rates  s.
The relative change in stripper inlet rich solvent
loading Li,str was very small, so it can be considered
constant when changing the solvent circulation rate by
10%. It shows that the solvents capacity was working
at the limit. However, lean loading Li,abs relative change
was large. A large dead time was observed in Li,abs (2747 minutes), due to the large amount of solvent
inventory within the plant (residence time), and in the
recycle loop. In addition, a settling time of 1 to 2 hours
was observed, this is likely due to the buffering effect
introduced by the absorber tank and other mixing
components, such as, desorber and absorber sumps.
Table 6. Response of the main process variables to -10%
step decrease in solvent circulation mass flow rate s,a and
s,b at the inlet of the absorbers, for different GT loads.
Dead times , settling times ts and total stabilization times
tsta are shown.

GT load
[%]
Li,abs
Li,str
Cap
Prod
100 Treb
Li,abs
Li,str
Cap
Prod
80 Treb
Li,abs
Li,str
Cap
Prod
60 Treb

-10 %

ts
tsta
RC
[min] [min] [min] [%]
35
53
88 -10.26
29
150
180
0.00
0
118
118
2.05
26
29
55
2.03
0
8
8
1.09
35
74
108 -10.60
0.00
0
125
125
2.11
30
33
64
2.85
0
37
37
1.13
43
71
115
-9.47
37
788
825
0.00
0
166
166
1.38
35
28
63
1.40
0
9
9
0.99

constant at each operating point of the plant. The
resulting response times of the PCC units main process
variables are shown in Table 7 and Table 8.
Table 7. Response of the main process variables to 10%
step increase in reboiler duty reb, for different GT loads.
Dead times , settling times ts and total stabilization times
tsta are shown.

GT load
[%]

100

Li,abs
Li,str
Cap
Prod
Tprod
Li,abs
Li,str
Cap
Prod
80 Treb
Li,abs
Li,str
Cap
Prod
60 Treb

Table 8. Response of the main process variables to -10%
step decrease in reboiler duty reb, for different GT loads.
Dead times , settling times ts and total stabilization times
tsta are shown.

GT load
[%]

100

80

5.3 Response to step-changes in reboiler
duty reb
Simulations in which reboiler duty reb was changed
with step-changes by  10% were performed. Flue gas
conditions and solvent circulation flow rates were kept

DOI
10.3384/ecp17132111

10 %

ts
tsta
RC
[min] [min] [min] [%]
28
384
412 -10.00
172
526
697
-1.80
31
69
100
9.54
0
322
322
9.70
0
335
335
1.09
33
419
451
-9.42
247
531
778
-1.52
35
67
102
9.06
0
332
332
9.67
0
353
353
1.02
37
457
494
-8.91
335
539
874
-1.34
40
87
126
9.24
0
606
606
9.44
0
368
368
0.96

60

Li,abs
Li,str
Cap
Prod
Treb
Li,abs
Li,str
Cap
Prod
Treb
Li,abs
Li,str
Cap
Prod
Treb

-10 %

ts
tsta
[min] [min] [min]
28
56
85
44
694
739
29
52
81
0
24
24
0
11
11
29
66
96
92
685
777
34
65
99
0
27
27
0
13
13
37
72
109
93
403
496
39
75
113
0
33
33
0
12
12

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

RC
[%]
8.448
0.008
-10.81
-10.84
-1.10
8.1519
0.0058
-10.62
-10.63
-1.05
7.88
-0.006
-10.44
-10.44
-1.01

117

Dynamic Simulations of the Post-combustion CO2 Capture System of a Combined Cycle Power Plant

Li,abs

Cap
900
Fgas +10%
Fgas -10%
Fsolvent +10%
Fsolvent -10%
Qreb +10%
Qreb -10%

800
700
600

Total stabilization time tsta [min]

Total stabilization time tsta [min]

900

500
400
300
200
100

800
700
600
500

300
200
100

0

0
60

70

80
a) GT Load [%]

90

100

60

Prod
Total stabilization time tsta [min]

800

700
600
500
400

Fgas +10%
Fgas -10%
Fsolvent +10%
Fsolvent -10%
Qreb +10%
Qreb -10%

300
200
100

70

80
b) GT Load [%]

90

100

Li,str

900

900

Total stabilization time tsta [min]

Fgas +10%
Fgas -10%
Fsolvent +10%
Fsolvent -10%
Qreb +10%
Qreb -10%

400

800
700
600
500

Fgas +10%
Fgas -10%
Fsolvent +10%
Fsolvent -10%
Qreb +10%
Qreb -10%

400
300
200
100
0

0
60

70

80
c) GT Load [%]

90

60

100

70

80
d) GT Load [%]

90

100

Figure 3. Trends in total stabilization times of main process variables of the PCC unit, when disturbed by the different plant
input step changes, at different GT loads. a) CO2 capture rate Cap; b) Solvent CO2 loadings at absorbers inlets Li,abs; c)
Product CO2 mass flow rate Prod; and d) solvent CO2 loading at stripper inlet Li,str.

Increasing the reboiler duty will result in increased
CO2 capture rate Cap due to the lower resulting lean
loading at the inlet of the absorber Li,abs. Reducing
reboiler duty will result in reduced Cap due to the
increase in Li,abs. A relatively large dead time in the Cap
response of 2837 min was found. This dead time was
larger when the plant was operated at lower power plant
loads. This is because at lower power plant loads solvent
circulation rates are smaller (refer to Table 1), resulting
in larger residence time though piping and mixing tank
in the recycle loop.
The relative change in CO2 product mass flow rate
Prod was also large, but with practically no dead time.
This is because the reboiler duty introduced in the
reboiler is physically closer to the overhead of the
stripper. However, the recycle loop and coupled
operation of the absorber and desorber makes the total
stabilization time tsta of the Prod longer than for Cap.
Observe the slow response in Li,str in Figure 3. In
general, longer total stabilization times were found for

118

both Cap and Prod when the plant was operated at lower
loads, refer to Figure 3.
The relative change was also significant for lean
loading at absorber inlet Li,abs with a large dead time, as
previously mentioned. The dead times were even larger
for rich loading at the inlet of the stripper Li,str, and
longer total stabilization times than for Li,abs were
observed.

6

Conclusions

The openloop transient performance of the main
process variables of the plant were studied when the
plant was operated at different power plants load
conditions, and for different disturbances to the PCC
unit. In general, it is found that the plant was slower
when the plant was operated at lower loads, i.e., it
required longer total stabilization times for the main
variables of the process. In general, CO2 capture rate
stabilized relatively faster (13 h) than other process
variables (111 h).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132111

Session 4C: Process & Chemical Engineering

In addition, it was found that the PCC unit responded
significantly faster to the increase in flue gas mass flow
rate than to reductions in flue gas mas flow rate. This
could have significant implications on efficient
operation of the PCC unit when ramping down the
power plants load, due to long stabilization times
require of the process and the resulting inefficient
operation during transient conditions, if a suitable
control structure cannot be implemented.
Process variables respond differently to different
disturbances. For the same process disturbance and
process variable, the response was different when
increasing or decreasing the input. This shows the nonlinear behavior of the process. The recycle loop in the
process from desorber outlet to absorber inlet connects
the operation of the absorbers units and the stripper, and
the resulting dynamic interaction between the
absorption and desorption unit resulted in long
stabilization time of main process variables, up to 11 h.
Current and future work includes the integration of
the PCC unit with a dynamic process model of the power
plant. That will allow the study of dynamic interactions
between the power plant and the PCC unit under
transient events of the power plant, and to analyze
optimal control structures and operation of the
integrated process for efficient flexible operation.

Modelon AB, Post-combustion capture with amine solutions.
Montas, R. M., Fl N. E., Dutta, R., Nord, L. O., Bolland,
O., 2017. Dynamic process model development and validation
with transient plant data collected from an MEA test campaign
at the CO2 Technology Center Mongstad. Energy Procedia.
(accepted for publication).
doi: 10.1016/j.egypro.2017.03.1284
Montas, R. M., Korps, M., Nord, L. O. & Jaehnert, S.,
2016. Identifying operational requirements for flexible CCS
power plant in future energy systems. Energy Procedia,
86(TCCS-8), pp. 22-31.
doi: https://doi.org/10.1016/j.egypro.2016.01.003
Panahi, M., 2011. Ph.D. Thesis: Plantwide control for
economically optimal operation of chemical plants Applications to GTL plants and CO2 capturing processes.
Trondheim: Norwegian University of Science and
Technology. doi: http://hdl.handle.net/11250/248272
Prl, K., Tummerscheit, H., Velut, S. & kesson, J., 2011.
Dynamic model of a post-combustion absorption unit for use
in a non-linear model predictive control scheme.. Energy
Procedia, 4(GHGT-11), pp. 2620-2627.
doi: https://doi.org/10.1016/j.egypro.2011.02.161

References
Aske, E. M. B. & Skogestad, S., 2009. Consistent inventory
control. Industrial engineering chemistry research, Volume
48, pp. 10892-10902.
doi: http://pubs.acs.org/doi/abs/10.1021/ie801603j
Bui, M., Gunawan, I., Verheyen, V., Feron, P.,Meuleman, E.,
Adeloju, S., 2014. Dynamic modeling and optimisation of
flexible operation in post-combustion CO2 capture plants - A
review. Computers and Chemical Engineering, Volume 61,
pp. 245 - 265.
doi: http://dx.doi.org/10.1016/j.compchemeng.2013.11.015
Dutta, R., Nord, L. O. & Bolland, O., 2017. Selection and
design of post-combustion CO2 capture process for 600 MW
natural gas fueled thermal power plant based on operability.
Energy, Volume 121, pp. 643-656.
doi: http://dx.doi.org/10.1016/j.energy.2017.01.053
Fl, N. E., 2015. Doctoral Thesis: Post-combustion
absorption-based CO2 capture: modeling, validation and
analysis of process dynamics. Trondheim (Norway): Doctoral
Theses at NTNU, 2015:244.
doi: http://hdl.handle.net/11250/301562
IEA, 2011. Harnessing Renewable Energies: A guide to the
balancing challenge, 9, rue de la Fdration, 75739 Paris
Cedex 15, France: International Energy Agency.
IEA, 2016. 20 years of carbon capture and storage Accelerating future deployment, Paris, France: IEA.
IEA-GHG, 2012. Operating Flexibility of Power Plants with
CCS.
Kvamsdal, H. M., Jakobsen, J. P. & Hoff, K., 2009. Dynamic
modeling and simulation of a CO2 absorber column for postcombustion CO2 capture. Chemical Engineering Process,
Volume 48, pp. 135-144.
doi: http://dx.doi.org/10.1016/j.cep.2008.03.002

DOI
10.3384/ecp17132111

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

119

120

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Optimizing the start-up process of post-combustion capture plants
by varying the solvent flow rate
Thomas Marx-Schubach1
1 Institute

Gerhard Schmitz1

of Engineering Thermodynamics, Hamburg University of Technology, Germany,
{thomas.marx,schmitz}@tuhh.de

Abstract
This paper presents an optimization of the start-up process
of a post-combustion carbon capture plant (PCC-plant) by
varying the solvent flow rate. In a first optimization run
the start-up time is minimized. In a second optimization
run the overall carbon capture rate during the start-up process is maximized. The results show the great potential
of the optimization, as the start-up time can be reduced
from t = 4650 s in the reference case to t = 2840 s in
the optimized scenario.
Keywords: optimization, start-up, absorption process, carbon capture, process engineering

1

Introduction

To stop global warming, ambitious goals have to be set. At
the United Nations Climate Change Conference in Paris in
2015 a limit for the global temperature increase was set to
1.5 C above pre-industrial levels (United Nations, Framework Convention on Climate Change, 2016). To achieve
this goal the carbon dioxide emissions have to be reduced
significantly. One possibility is the usage of the Carbon
Capture and Storage (CCS) technology, which means that
the carbon dioxide is removed from the flue gas and can be
stored in underground formations. As reported by the International Energy Agency (IEA) it is estimated that CCS
can have a 17 % share on the CO2 reduction in the year
2035 (IEA (International Energy Agency), 2013).
Furthermore, the increasing amount of renewable energies will lead to more fluctuations of net load in the power
grid (Montas et al., 2016). This will impose new challenges and operational requirements on the flexibility of
thermal power plants as start-up and shutdown sequences
and the operation at partial load will become still more
important in the future.
The start-up process of a power plant is a time consuming and complex operation. When a carbon capture plant
is coupled to a power plant the start-up procedure becomes
even more complex. As power plants will start up and
shutdown even more frequently in the future, the minimization of the start-up time is desirable. Hence, there
is a requirement of reducing the start-up time. This can be
achieved by optimizing the start-up time using dynamic
models. As a first step an approach for the optimization
DOI
10.3384/ecp17132121

of a post-combustion carbon capture plant is given in this
paper. At the moment the common start-up procedure of
carbon capture plants is only based on experience.
Many different studies focus on the dynamic simulation of post-combustion carbon capture plants (Bui et al.,
2014). Some studies present the optimization of a capture plant but most of them focus only on the steady state
and full time operation. Since the full time operation of
carbon capture plants might not be economically feasible,
also the optimization of dynamic operation periods will become important in the future (Bui et al., 2014). There are
also studies available dealing with the optimal control of
the process, e.g. (Panahi and Skogestad, 2011), (kesson
et al., 2012), (Lin et al., 2011), (Luu et al., 2015) and
(Mechleri et al., 2017). However, to the authors knowledge the studies do not concentrate on modelling start-up
and shut down procedures of the whole plant. In order to
close this gap, a model which can describe the start-up process is developed and a first approach for an optimization
of the process is presented.

2

Process description

Several processes are available for the post-combustion
capture (PCC) of CO2 from power plant flue gases such as
membrane processes, adsorption and absorption processes.
One possibility is to remove the CO2 in a gas scrubbing
unit using aqueous solutions of different alkylamines as a
solvent, also known as the amine gas treating process. A
process flow diagram of this process is shown in figure 1.
The flue gas first enters a flue gas cooler and is compressed
in a blower. The cooled flue gas enters the absorption unit
at the bottom of the column. The solvent flows countercurrent to the flue gas down to the column sump. 90 %
of the CO2 is chemically absorbed by the solvent. Afterwards the rich solvent is preheated in a heat exchanger
and pumped to the stripper. The solvent is evaporated in
a reboiler using steam from the power plant to provide
the required energy for solvent regeneration. Desorption
takes place in the stripper and the almost pure CO2 (up
to 99.9 %) leaves the plant through a condenser. The regenerated solvent is pumped back to the absorption unit.
Many different solvent additives, primary, secondary and
tertiary amines, can be used. In this case the used solvent
is a 30 wt.-% monoethanolamine (MEA) aqueous solution.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

121

Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate
Treated
Flue Gas

Pure CO2

Washing
Section

Absorber
Flue Gas
Cooler

Condenser
Water

Rich-Lean
Heat
Exchanger

Stripper
Heating
Steam

Blower

Flue Gas

Rich Solvent
Pump

Reboiler
Lean Solvent
Pump

Figure 1. Process flow diagram of a post-combustion capture
plant (Wellner et al., 2016).

The columns are usually filled with structured or random
packings of different types.
The start up process of the plant is described in the following. At the beginning, the columns are in a cold and
empty state. The process is started with the activation of
the solvent pumps. Simultaneously, the other pumps for
the washing sections, flue gas cooler and condenser are
switched on. When the packing units inside the columns
are wetted the heating steam can be supplied in the reboiler and the flue gas compressor can be switched on.
The start up process is completed when the capture rate in
the absorber reaches its nominal value of 90 %. To achieve
this goal, the thermal and chemical equilibrium in the absorption unit has to be reached and the stripper has to attain his operation temperature of approximately 120 C to
ensure a sufficient regeneration of the solvent. The heat up
process of the stripper takes the most time and is therefore
the limiting factor for the start up time. The stripper heats
up in two different ways.
1. The solvent is evaporated in the reboiler and the
vapour enters the stripper at the lower part of the column.
2. The solvent which remains in the stripper sump is
pumped through a counter flow heat exchanger and
heats up the rich solvent that enters the stripper at
the top.
A reduction of the start-up time can be performed by selecting the right solvent flow trajectory, which is not trivial,
since the variation of the solvent flow rate has counteracting effects on the heat up rate. When the solvent flow rate
is increased the temperature in the reboiler is reduced and
it takes more time for the solvent to reach the boiling point.
On the downside, the residence time of the solvent in the
stripper sump decreases leading to a faster increase of the
solvent temperature in the stripper sump. Decreasing the
solvent flow rate leads to the opposite result. Therefore,
the optimal trajectory of the solvent flow rate has to be
122

found numerically using a model of the post combustion
carbon capture plant.

3

Model description

In this section the developed model and the used model
libraries are described briefly. A detailed model for the
dynamic simulation of the described process is developed
within the ThermalSeparation library in Modelica (Dietl,
2012; Joos et al., 2009). The Optimization is performed
with the commercial Optimization Library developed by
DLR (A. Pfeiffer, 2012).

3.1

Model libraries

The ThermalSeparation library is a free Modelica library
intended to describe separation processes such as absorption and rectification processes in Modelica. It can be used
for the dynamic simulation of tray and packed columns
with different levels of detail. More information about the
library can be found in (Dietl, 2012; Joos et al., 2009).
The Optimization library is a commercial library for
many different optimization tasks such as Trajectory Optimization, Realtime Optimization and Model Optimization.
The library is released with Dymola and works only in this
simulation environment. In this article the Trajectory Optimization is used. Further information about the library is
given in (A. Pfeiffer, 2012).

3.2

Start-up model

A model of a post-combustion CO2 capture plant, that can
describe the start-up process, is developed at the Institute
of Engineering Thermodynamics in Modelica using the
ThermalSeparation library and validated with data of a pilot plant.
The pilot plant is located in Heilbronn, Germany and
can handle a nominal flue gas stream of 1500 m3 /h. The
absorber has a height of 40 m and the stripper of 30 m.
Both columns have a diameter of 0.6 m and are filled with
the random packing type VSP-25 (VFF GmbH, 2016).
The most relevant parameters of the nominal operation
point are listed in table 1. More information about the pilot plant can be found in (Rieder and Unterberger, 2013).
The pilot plant is modelled using a first principle approach where the columns are axially divided into stages.
The vapour and liquid mass and energy balances are
solved separately in each stage. For the heat- and mass
transfer across the phase boundary a equilibrium approach
is used. The chemical reaction of carbon dioxide with the
solvent is considered. It is assumed that the reaction takes
place only in the liquid phase. More information about
the model and the underlying assumptions can be found
in (Wellner et al., 2016).
The most important input variables of the pilot plant are
the solvent flow rate Vliq , the molar flue gas flow rate N f g

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132121

Session 4C: Process & Chemical Engineering
Table 1. Main parameters of pilot plant.

1

Value

0.8

Flue gas volume flow rate
CO2 concentration flue gas
Flue gas temp. absorber inlet
Solvent flow rate
Solvent temp. absorber inlet
MEA concentration
Stripper pressure
CO2 product temperature
CO2 target capture rate

1500 m3 /h
12.3 mol-%
40 C
5.3 m3 /h
35 C
30 wt.-%
2 bar
23 C
90 %

0.6

XCO2

Parameter

NCO2 ,Abs,out
NCO2 ,Abs,in

0

0

5000

10000
time in s

15000

20000

Figure 2. Validation start-up strategy - CO2 capture rate

(1)

At t = 0 s the flue gas flow to the absorber is started. The
steam supply in the reboiler starts later at t = 240 s due to
the time delay in the steam generator and the steam cycle
of the power plant. All incoming CO2 is absorbed until
the solution is saturated. Therefore, the CO2 capture rate
is nearly 100 % at the beginning and drops quickly after
approximately 2000 s since the solvent in the absorption
unit is saturated with CO2 and is not regenerated in the
stripper yet. The capture rate in the pilot plant can only be
calculated from this point on because the CO2 concentration at the absorber outlet has not been measured correctly
before. Due to the increasing temperature in the stripper,
the CO2 loading of the solvent in the stripper decreases
DOI
10.3384/ecp17132121

pilot plant
model

0.2

and the capture rate rises slowly to its steady state value.
After t = 2000 s the results of the model show a significant deviation from the measurements of the pilot plant.
One reason is that the columns are modelled based on a
equilibrium approach which means that the heat and material transport equations in each stage are neglected. Another reason is the deviation of the measuring instruments,
since some measured values, e.g. the CO2 -concentration
at the absorber outlet, are far from their nominal values.
However, the agreement of the dynamic behaviour between the model and the pilot plant is very good except
the small overshoot after t = 10 000 s. The start-up process is completed when the plant is capable of keeping a
capture rate of 90 %.
Figure 3 shows the transient behaviour of the stripped
CO2 mass flow rate downstream the condenser for the
same time period. The measured values are also compared
with the simulated ones.
400
mCO2 ,str,out in kg/h

and the heat flow rate to the reboiler Qreb .
While the solvent flow rate and the heat flow rate are
controllable within their limits, the flue gas flow rate depends on the firing output of the power plant. The flue gas
flow rate is only controllable when a part of the flue gas
is bypassed. In an usual start up scenario the solvent flow
rate and the heat flow in the reboiler are set to their steady
state values during the whole start-up process. However,
this results in a very high start-up time. Hence, there is a
high potential for optimization.
Simulation and validation results of the validation startup scenario are shown in the following. At the beginning
of the start-up procedure, the solvent pumps are switched
on until the CO2 concentration in the solvent is homogenized in the whole plant and until the columns are wetted.
This step was not included in the optimization, since the
solvent pumps should be operated at maximum flow rate
to wet the columns as fast as possible. Hence, the focus
of the optimization lies on the second part of the process
when the flue gas flow enters the absorber.
In Figure 2 the carbon capture rate during the second
part of the start-up process in the model and in the pilot
plant is illustrated. The CO2 capture rate is defined in the
following way, where NCO2 ,Abs,out is the molar flow rate
of CO2 after the absorption unit and NCO2 ,Abs,in the molar
flow rate of CO2 before the absorption unit.
XCO2 = 1 

0.4

300
200
100
0

pilot plant
model
0

5000

10000
time in s

15000

20000

Figure 3. Validation start-up strategy - CO2 mass flow downstream the stripper

The simulation data shows a very good agreement with
the measurement data except the overshoot in the simulation data at the end of the start-up process. The overshoot
can be explained by the model assumption that the steam
in the stripper condenses in every stage where the boiling
temperature is not reached yet. In reality the CO2 leaving
the stripper is loaded with steam especially at high temperatures close to the boiling point. This energy loss leads
to a smaller amount of stripped CO2 in the pilot plant at

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

123

Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate
Table 2. General criteria in optimization runs

Variable name

Liquid hold-up
Solvent flow rate

TReb

at any time

0.0002 m3 /s  Vliq  0.002 m3 /s

at any time

Optimization setup

In this section the simplification of the model and the implementation of the optimization run is presented.
The model used for validation is simplified in a first step
in order to reduce the computation time and improve the
robustness of the model. The following simplifications of
the model were made:

 The intermediate cooling unit in the absorber was neglected.
 The flue gas scrubbing units before and after the absorber were removed
Furthermore, the total amount of solvent in the pilot plant is specifically high compared to other postcombustion capture plants (Wellner et al., 2016). Therefore, the total amount of solvent in the pilot plant is reduced by 50 % to get more commonly results. Thermal
stresses were neglected in the reboiler as the start-up process is most of all limited due to the high amount of solvent in the stripper sump. Nevertheless, thermal stresses
should be taken into account in the future to prove this
assumption. An overview of the model used for the optimization is shown in Figure 5. The gas streams are marked
orange, the solvent streams are marked blue. The flue gas
stream entering the absorber and the heat flow rate are implemented using a ramp from the Modelica Standard library as source signal. The solvent flow rate can be set by
using an input connector which is connected to the lean
124

at any time

Vliq,Reb  0.35 m3

the end of the start-up process. It can be seen that the
amount of stripped CO2 in the stripper is nearly the same
in the model an in the pilot plant in the timespan between
approximately t = 2000 s and t = 8000 s. However, the
amount of captured CO2 is much higher in the model in
the same timespan. Therefore, if one assumes a correct
initial amount and loading of the solvent, the overall CO2
mass balance in the pilot plant is not fulfilled, which leads
to the assumption of a certain measuring error. Furthermore, the time limiting component during the start-up process is the stripper. The model can therefore be used for
optimization purposes.
According to the simulation, the start-up time in the validation case is t = 9440 s, which is very high.

4

Type

 125 C

solvent pump. The input connector is used for the optimization. The rich solvent pump is controlled keeping the
filling level of the absorber sump at a setpoint of 2 metres.
As optimization method a Single Shooting Technique
approach is used. The trajectories are approximated with
B-splines of order 3. For the construction of the splines 10
equidistant knots, so called de Boor points, are used in the
optimization runs. They can be used as tuner variables in
the optimization method. Using more knots would lead
to a more accurate solution but the optimization would
take more time. Optimizations with different amounts of
knots were carried out. The result is that 10 knots are a
good compromise between accuracy and simulation time.
An example of the construction of the trajectory using Bsplines is shown in figure 4. The optimization problem is
solved by using the gradient based Sequential Quadratic
Programming (SQP) algorithm. The algorithm is effective
for solving nonlinear optimization problems with linear
constraints. The constraints are essential for the optimization problem. Therefore an algorithm which is capable of
solving optimization problems with constraints has to be
used.
Generally, different optimization algorithms for nonlinear optimization with constraints can be used, such as Random search, interior-point method. A overview of possible
optimization algorithms can be found in (Rao, 2009). In
this paper a gradient based method was used as these algorithms converge faster in general. The SQP algorithm is
sufficient for solving the optimization problem. A disadvantage is that the algorithm can only find local optima.
103

2
Vliq in m3 /s

Reboiler temperature

Constraint

1.5
1
0.5
0

5000

10000
time in s

15000

20000

Figure 4. Example of the construction of B-splines

A general optimization problem with equality and in-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132121

Session 4C: Process & Chemical Engineering

Condenser

Absorber

Desorber

Counter Flow
Heat Exchanger

Reboiler

Desorber
sump

Absorber
sump

Figure 5. Simplified Modelica model of the carbon capture plant in Dymola simulation environment.

equality constraints can be defined in the following way.
minimize f(x)
in subject to
gi  a
hi = b

(2)

As the hold-up in the reboiler may not fall below a specific
value, the inverted hold-up is used as constraint. For the
reboiler temperature and the hold up a Maximum-Block
of the Optimization-Library is used to make sure that the
temperature or liquid hold-up do not exceed their limits
during the whole simulation time as the optimization algorithm only evaluates the last value of the criteria. The
general constraints are summarized in table 2.
The other two input variables, the flue gas flow and the
heat flow rate to the reboiler, are kept constant during the
optimization runs at their steady state values.
The optimization runs are executed on a windows server
R
with two Intel
Xeon E5-2650 v3 CPU and 128 GB memory. To improve the simulation time, the integration of
the model is parallelized by the Optimization-library. The
maximum number of threads is set to 8.

Before the optimization is started, the minimization criteria and the different constraints have to be defined. In the
first optimization the start-up time is minimized. In a second optimization the mean value of the CO2 capture rate
during the start-up process is maximized.
The optimal trajectory of the solvent flow rate has to satisfy many constraints to ensure that the plant is operated
within the permissible operation range. Two of them are
used in both optimization runs. First, the temperature in
the reboiler may not exceed 125 C at any time since the
degradation of the solvent increases significantly at higher
temperatures. Second, the hold-up in the reboiler may not
fall below 0.35 m3 to provide that the heat pipes are cov- 5 Reference start-up scenario
ered with solvent.
The SQP solver can only handle inequality constraints As mentioned in section 3.2 the implementation of the
start-up process is based on experience. The current startin the following form.
up process is performed by setting all manipulated varigi  b
(3) ables to their steady-state values, which results in a high
DOI
10.3384/ecp17132121

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

125

Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate

start-up time. As presented in section 4 the model structure was changed slightly and the total amount of solvent
was reduced. Therefore, the validation scenario shown in
section 3.2 can not be used as a reference for the optimization. The start-up time decreases significantly due to the
reduction of the total amount of solvent. For this reason a
new reference scenario has to be defined by simulating the
reduced model. The carbon capture rate in the reference
scenario is shown in figure 6.
1

Variable name
Capture rate

Type

XCO2  0.9
molCO

Solvent loading

end point

str,sump = 0.184 molMEA2

end point

t

minimize

Start-Up time

103

0.6
1.5

0.2
0

5000

10000
time in s

15000

20000

Vliq in m3 /s

0.4

0

Criteria

The resulting solvent flow rate trajectory of the first optimization run is shown in Figure 7.

0.8
XCO2

Table 3. Additional criteria in optimization run 1

Figure 6. Reference start-up scenario - capture rate

1
0.5
0

500

1000 1500 2000 2500
time in s

Treb in C

All manipulated variables are kept at their steady state
values during the whole start-up process in the reference
Figure 7. Minimized start-up time - solvent flow rate
case. The start-up time in the reference scenario is t =
4650 s, which is reduced in the following optimization sceAs in the reference start-up scenario presented in chapnario.
ter 3.2 the flue gas flow to the absorber starts at t = 0 s. The
steam supply in the reboiler starts also later at t = 240 s
due to the time delay in the steam generator and the steam
6 Minimizing the start-up time
cycle of the power plant. The solvent flow trajectory during the start-up process can be split up into three phases.
In this section the minimization of the start-up time should
At the beginning of the optimal start-up process the solbe achieved by finding the optimal solvent flow trajectory
vent flow rate is at the minimum flow rate of 0.0002 m3 /s.
(optimization 1). For the optimization run additional conThe minimum solvent flow rate leads to a maximum of the
straints and criteria have to be set.
reboiler heat up rate. The reboiler temperature is shown in
First, the end of the start-up process has to be specified
figure 8.
by using constraints. Therefore, it is defined that the carbon capture rate has to be at least 90 % at the end of the
150
optimization. However, this constraint does not guarantee that the plant can keep a stable capture rate of 90 %.
To make sure that the solvent is sufficiently regenerated at
the end of the start-up process, a constraint for the solvent
100
loading in the stripper sump is added. The solvent loading
is defined in equation 4 and is the ratio of the amount of
CO2 and MEA in the solvent.
50
NCO2
(4)
=
0
500 1000 1500 2000 2500
NMEA
time in s
The solvent loading in the stripper sump has to reach the
Figure 8. Minimized start-up time - Reboiler temperature
steady-state value of  = 0.184 molCO2 /molMEA to ensure
a stable carbon capture rate of 90 %. As the library only
handles criteria in the form presented in equation 3 the
When the reboiler reaches its operation temperature
capture rate was also inverted in the model. The additional of approximately 120 C the solvent flow rate rises to
0.000 37 m3 /s. This happens for two reasons. On the one
criteria are shown in table 3.
126

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132121

Session 4C: Process & Chemical Engineering

hand the solvent flow rate has to be increased to prevent
Vliq = 0.000 37 m3 /s). The value has to be found by
that the temperature in the reboiler exceeds the limit of
optimizing a model of the certain plant. If this is not
125 C. On the other hand the increasing solvent flow rate
feasible another possibility is to control the reboiler
leads to a smaller residence time in the stripper sump in
temperature with the solvent flow rate by using a PID
order to achieve a higher heat up rate of the solvent in the
controller.
stripper sump. As soon as the stripper reaches the oper4. When the top of the stripper is heated up to 100 C
ation temperature the solvent flow rate increases continset the solvent flow rate to the optimal steady state
uously to increase the capture rate. At a capture rate of
value (in the pilot plant: Vliq = 0.001 289 m3 /s).
90 % a PID controller is switched on. The controller uses
the capture rate of 90 % as a setpoint and the solvent flow
5. Just as the capture rate reaches 90 % switch on the
rate as the manipulated variable. This results in a small
PID controller to keep a constant capture rate.
oscillation of the solvent flow rate after the controller is
switched on. The start-up process is finished at this point.
When applying the simplified start-up strategy to the
Figure 9 shows the carbon capture rate during and after model, the start-up time increases slightly. However, the
the start-up process.
implementation of the start-up strategy is a lot simpler.
The simplified solvent flow rate derived from the optimiza1
tion case is presented in figure 10.
103

0.6

1.5

0.4
0.2
0

0

5000

10000
time in s

15000

20000

Vliq in m3 /s

XCO2

0.8

1
0.5
0

Figure 9. Minimized start-up time - capture rate

1. Set the solvent flow rate to its steady state or maximum possible value to wet the columns.
2. When the columns are wetted and the steam can be
supplied from the power plant reduce the solvent
flow rate to the lowest possible value.

1000 1500 2000 2500
time in s

Figure 10. Minimized start-up time - solvent flow rate (simplified)

The result for the carbon capture rate is shown in figure 11. The carbon capture rate increases as expected
steeply with increasing solvent flow rate. Between the
steps of the solvent flow rate the capture rate increases
slightly as the CO2 loading in the stripper sump decreases
slowly over time.
1
0.8
XCO2

The capture rate drops quickly to a very small value of
12 % and increases with increasing solvent flow rate and
stripper temperature until a capture rate of 90 % is reached.
The start-up time is significantly reduced from t = 4650 s
to t = 2840 s. As illustrated in figure 9, the plant can keep
the capture rate of 90 % after the start-up process.
The result of the optimization is a specific optimal solvent flow trajectory for the pilot plant. As the trajectory
cannot be applied directly to other plants a more generalized approach for the solvent flow trajectory should be
given. Furthermore, the optimal solvent flow trajectory is
quite complex since many control actions are required.
To solve this problem a simplified approach based on
the optimal solvent flow trajectory is developed. As already mentioned, the solvent flow trajectory can be divided into three phases. Based on this segmentation the
recommendations for an optimal start-up scenario are:

500

0.6
0.4
0.2
0

0

5000

10000
time in s

15000

20000

Figure 11. Minimized start-up time - capture rate (simplified)

3. As soon as the reboiler temperature reaches the operThe start-up time in the simple case increases
ation temperature of 120 C, increase the solvent flow
rate to a certain value (in the case of the pilot plant: marginally from t = 2840 s to t = 2939 s. However, the
DOI
10.3384/ecp17132121

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

127

Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate

Table 4. Additional constraints in optimization run 2

Criteria

Type

Capture rate limit

XCO2  0.95

anytime

Solvent flow rate

Vliq = 0.001 289 m3 /s

end point

Mean capture rate

XCO2

maximize

The CO2 capture rate in the second optimization run
is depicted in figure 13. In comparison with the reference start-up strategy, the capture rate drops quickly to
a lower value at the beginning because of the lower solvent flow rate. However, the lower solvent flow rate leads
to a faster heat-up in the stripper and regeneration of the
solvent. When the solvent flow rate is increased the carbon capture rate increases as well. As a side effect, the
start-up time is also in this scenario reduced significantly
to t = 3520 s.
128

1

0

In a second approach, the main goal is to maximize the
mean value of the capture rate during the start-up process
(optimization 2). This start-up strategy is useful when low
CO2 emissions are more important than a minimal start-up
time.
For this optimization run additional constraints have to
be determined. The maximum CO2 capture rate is limited to XCO2 = 0.95 after t = 1000 s since the carbon capture efficiency is decreasing steeply at very high capture
rates. The reason is the very low CO2 partial pressure in
the gas phase at very high capture rates. The accuracy of
the model decreases in this point of operation. The optimal stationary solvent flow rate is Vliq = 0.001 289 m3 /s
which is defined as the end point of the trajectory. As the
library only handles minimization criteria as presented in
equation 3 the mean value of the negative carbon capture
rate in a time period of t = 20 000 s is chosen. The additional constraints are shown in table 4.
The resulting solvent flow rate trajectory of the second optimization run is shown in Figure 12. The trajectory starts at 0.001 m3 /s and decreases to a minimum
at approximately 0.000 64 m3 /s. Afterwards the solvent
flow rate rises till 0.0016 m3 /s and drops again until the
optimal stationary solvent flow rate of 0.001 289 m3 /s is
reached.

Variable name

1.5

0.5

Maximizing the capture rate

5000

10000
time in s

15000

20000

Figure 12. Maximized amount of captured CO2 - solvent flow
rate

1
0.8
XCO2

7

103
Vliq in m3 /s

implementation of the strategy requires only three control
actions of the solvent flow rate during the whole start-up
process. The simple approach also offers a high reduction
of the start-up time while the constraints are still fulfilled.
The reboiler temperature and the liquid hold-up in the reboiler do not exceed their limits at any time.

0.6
0.4
0.2
0

0

5000

10000
time in s

15000

20000

Figure 13. Maximized amount of captured CO2 - capture rate

In table 5 a comparison of the mean capture rate in the
different start-up scenarios over the same time period of
t = 20 000 s is shown. The minimization of the start-up
time is labelled as Optimization 1, the maximization of
the mean capture rate is labelled as Optimization 2. The
reference strategy is presented in section 5.
Table 5. Mean value of capture rate in different start-up scenarios

Reference

Optimization 1

Optimization 2

0.836

0.805

0.856

As expected the highest mean capture rate is achieved
in the second optimization run, but the enhancement of the
mean capture rate in comparison with the reference startup strategy is quite small. However, the second optimization run leads to a very good compromise between a relatively fast start-up process and a high amount of captured
carbon dioxide during the start-up process as the mean capture rate is comparatively small in the first optimization
run. In the future, also a multicriteria optimization with
the combination of both optimization criteria is conceivable.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132121

Session 4C: Process & Chemical Engineering

8

Performance

The optimization model consists of 29833 equations. As
the optimization algorithm can only find local optima one
can not guarantee that the best solution has been found.
Therefore, the optimization is repeated several times and
different start values for the solvent flow rate are used.
The result is that the solutions actually are different but
they vary only slightly when different start values are
used. Sometimes the algorithm does not converge. This
is mostly due to the fact that the optimization algorithm
cannot evaluate a new solution since the integration of the
model fails in some cases. One optimization run takes approximately an average of 18 hours.

9

Conclusion and Outlook

The results of this paper show that there is a high optimization potential for the start-up process of a post-combustion
capture plant. The start-up time can be significantly reduced by varying the solvent flow rate only.
The results of the model optimization should be applied
to the real operation of a carbon capture plant for validation purposes in the future. Unfortunately, the pilot plant
used for the validation of the model is no longer in operation.
The optimization does not take thermal stresses in the
reboiler into account. Additionally, the reboiler should be
discretized in space in order to calculate local temperatures in the reboiler. Both options should be added to the
model in the future.
This work focusses on the start-up process at full load.
Future work could concentrate on the start-up process at
partial load. Furthermore, future optimization should include the variation of other parameters of the plant that
influence the start-up process as for example the total
amount of solvent. It could be also performed with the
used Optimization Library.
The technical design of the pilot plant was not changed
during the optimization. Future work should also include
the improvement of the technical design. A possible option would be for example the implementation of the lean
vapour compression (Fernandez et al., 2012).
The SQP solver used in the optimization does not guarantee that the global optimum is found. The optimization
should be also performed by using a genetic algorithm to
confirm the results of this paper in the future.

Nomenclature


solvent loading (molCO2 /molMEA )

m

mass flow rate (kg/s)

N

molar flow rate (mol/s)

Q

heat flow rate (W)

DOI
10.3384/ecp17132121

V

volume flow rate(m3 /s)

N

amount of substances(mol)

T

temperature (C)

t

time s

X

CO2 capture rate (-)

Abbreviations
CO2

carbon dioxide

CCS

carbon capture and storage

MEA

monoethanolamine

PCC

post-combustion carbon capture

Subscripts
abs

absorber

fg

flue gas

in

incoming stream

liq

liquid

out

outgoing stream

reb

reboiler

str

stripper

sump

column sump

References
A. Pfeiffer. Optimization Library for Interactive Multi-Criteria
Optimization. In Proceedings of the 9th International Modelica Conference, pages 669680. Modelica Association, 2012.
doi:10.3384/ecp12076669.
A. Bui, I. Gunawan, V. Verheyen, P. Feron, E. Meuleman, and
S. Adeloju. Dynamic modelling and optimisation of flexible operation in post-combustion co2 capture plants-a review.
Computers and Chemical Engineering, 61:245265, 2014.
Karin Dietl. Equation-Based Object-Oriented Modelling of
Dynamic Absorption and Recification Processes. PhD thesis, Hamburg University of Technology, Hamburg, Germany,
2012.
Eva Sanchez Fernandez, Egbertus J. Bergsma, and Thijs
J.H. Vlugt Ferran de Miguel Mercader. Optimization of lean
vapour compression (lvc) as an option for post-combustion
co2 capture: Net present value maximisation. International
Journal of Greenhouse Gas Control, 11:114  121, 2012.
IEA (International Energy Agency). World energy outlook special report: Redrawing the energy-climate map. Technical
report, OECD/IEA, France, 2013.
Andreas Joos, Karin Dietl, and Gerhard Schmitz. Thermal Separation: An Approach for a Modelica Library for Absorption,
Adsorption and Rectification. In Proceedings of the 7th International Modelica Conference, pages 804813. Modelica
Association, 2009.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

129

Optimizing the start-up process of post-combustion capture plants by varying the solvent flow rate

Yu-Jeng Lin, David Shan-Hill Wong, Shi-Shang Jang, and JenqJang Ou. Control strategies for flexible operation of power
plant with CO2 capture plant. AIChE J, 58:26972704, 2011.
doi:10.1002/aic.12789.
Minh Tri Luu, Norhuda Abdul Manaf, and Ali Abbas. Dynamic modelling and control strategies for flexible operation
of aminre-based post-combustion CO2 capture systems. International Journal of Greenhouse Gas Control, 39:377389,
2015. doi:10.1016/j.ijggc.2015.05.007.
Evgenia Mechleri, Adekola Lawal, Alfredo Ramos, John Davison, and Niall Mac Dowell. Process control strategies for flexible operation of post-combustion CO2 capture plants. International Journal of Greenhouse Gas Control, 57:1425, 2017.
doi:10.1016/j.ijggc.2016.12.017.
Rubn M. Montas, Magnus Korps, Lars O. Nord, and Stefan Jaehnert. Identifying operational requirements for flexible
CCS power plant in future energy systems. Energy Procedia,
86:22  31, 2016.
Mehdi Panahi and Sigurd Skogestad. Economically efficient operation of CO2 capturing process. Part II. Design of control
layer. Chemical Engineering and Processing, 52:112124,
2011. doi:10.1016/j.cep.2011.11.004.
Johan kesson, Carl D. Laird., Geoffry Lavedan., Katrin Prl,
Hubertus Tummescheit, Stephane Velut, and Yu Zhu. Nonlinear Model Predictive Control of a CO2 Post-Combustion
Absorption Unit. Chem. Eng. Technol., 35:445454, 2012.
doi:10.1002/ceat.201100480.
Singiresu S. Rao. Engineering Optimization: Theory and Practice. Wiley-VCH, 2009. doi:10.1002/9780470549124.
Alexander Rieder and Sven Unterberger.
EnBWs postcombustion capture pilot plant at Heilbronn - Results of the
first years testing programme. Energy Procedia, pages 1553
1571, 2013.
United Nations, Framework Convention on Climate Change. Report of the Conference of the Parties on its twenty-first session, held in Paris from 30 November to 13 December 2015,
2016.
VFF GmbH. Manufacturer of random packings for pilot
plant, 2016. URL http://http://www.vff.de/en/
products/random-packings.
Kai Wellner, Thomas Marx-Schubach, and Gerhard Schmitz.
On the dynamic behaviour of coal fired power plants
with post-combustion CO2 capture. Industrial & Engineering Chemistry Research, 55(46):1203812045, 2016.
doi:10.1021/acs.iecr.6b02752.

130

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132121

Framework for dynamic optimization of district heating systems
using Optimica Compiler Toolkit
Gerald Schweiger1

Hkan Runvik2

1 AEE

Fredrik Magnusson3,2

Per-Ola Larsson2

Stphane Velut2

INTEC, 8200 Gleisdorf, Austria, gerald.schweiger@aee.at
AB, SE-223 70 Lund, Sweden, {per-ola.larsson,

2 Modelon

hakan.runvik,fredrik.magnusson,stephane.velut}@modelon.com
University, SE-221 00 Lund, Sweden, fredrik.magnusson@control.lth.se

3 Lund

Abstract
Recent studies show that district heating infrastructures
should play an important role in future sustainable energy
systems. Tools for dynamic optimization are required to
increase the efficiency of existing systems and design new
ones. This paper presents a novel framework to represent,
simplify, simulate and optimize district heating systems.
The framework is implemented in Python and is based on
Optimica Compiler Toolkit as well as Modelons Thermal
Power Library. The high-level description of optimization problems using Optimica allows flexible optimization
formulations including constraints on physically relevant
variables such as supply temperature, flow rate and pressures. The benefit of new algorithms for symbolic elimination in Optimica Compiler Toolkit is also investigated.
The framework is applied on a test case, which is based on
a planned city district located in Graz, Austria. The results
demonstrate the generality of the representation as well as
the accuracy of the simplification for dynamic optimization of temperature supply and pressure control. Keywords: district heating, dynamic optimization, symbolic
elimination

models and sophisticated control design would be supportive. Limitations of standard methods rely often on
simplified models, static relationships and single-domain
approaches. Therefore standard approaches are restricted
and thus unsuitable for investigating many issues. The
presented framework is based on the previous work of
some authors (Velut et al., 2014; Runvik et al., 2015;
Schweiger et al., 2017a).
The main contributions of this paper are (i) a demonstration of the capabilities of Modelons Thermal Power
Library that in version 1.14 will have out-of-the box models for dynamic thermo-hydraulic optimization of district heating systems, (ii) a demonstration of a framework for creating and manipulating district heating networks in Python as well as translating networks into executable Code for simulation and optimization and (iii) an
investigation of the impact of the new algorithm for symbolic elimination available in JModelica.org and Optimica
Compiler Toolkit (OCT).

2

Tools and languages

Three environments were used within the framework:
(i)The unified network representation and the aggregation
1 Introduction
algorithms are implemented in Python; (ii) Dymola is used
A major challenge for future energy systems is the design to simulate the complex models and (iii) JModelica.org
of systems that integrate large shares of fluctuating and OCT were used to solve the dynamic optimization
renewable inputs while improving the overall system problem.
efficiency. There are a number of options for increasing
energy system flexibility, including the combination 2.1 OCT and JModelica.org overview
of different energy domains, increasing supply and 2.1.1 JModelica.org
demand flexibility or the integration of energy storage
technologies. Previous research has shown that district JModelica.org (kesson et al., 2010) is an open-source
heating infrastructure has the potential to play a key platform developed for simulation, optimization and analrole in sustainable energy systems (Lund et al., 2014; ysis of complex dynamical systems. It utilizes the open
Schweiger et al., 2017b). The new generation of district Modelica and FMI (Functional Mock-up Interface) stanheating systems (called 4th generation district heating) dards and has a Python-based user interface. It is develplays an integral part of smart energy systems. Among oped in collaboration between Modelon and several acaothers these systems will be characterized by intermittent demic institutions, such as the Department of Automatic
operations and highly fluctuating supply temperatures. Control and the group of Numerical Analysis at the Centre
As reported by (Allegrini et al., 2015), there is much to for Mathematical Sciences at Lund University.
be done to explore the full benefit of innovative district
Of special interest in this project is the dynamic openergy systems. They argue that a shift to fully dynamic timization capabilities of this tool. An extension of the
DOI
10.3384/ecp17132131

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

131

Framework for dynamic optimization of district heating systems using Optimica Compiler Toolkit

Modelica language called Optimica (kesson, 2008) is
used for this purpose. The model dynamics of the optimization models are described using Modelica. To add
the extra information necessary to describe the optimization formulation Optimica is used. This means that constraints, objective function and optimization time horizon
all can be collected in one easily understandable model.
More details of how optimization problems are solved in
the JModelica.org toolchain are presented in the following
sections.
2.1.2

Optimica Compiler Toolkit

Optimica Compiler Toolkit (OCT) is based on JModelica.org technology, but has several additional features
(Modelon, 2016). One of these is the support for encrypted libraries, which is of special interest in relation to
this project. This makes it possible to combine the usage
of commercial libraries, here Modelons Thermal Power
Library, with the optimization framework. This lowers
the difficulty for users to solve their own optimization
problems, when predefined components and media models from the library can be used.

3

District Heating Network Models

A district heating network model for short-term production planning must capture the following: (i) transport delays depending on mass flows, (ii) pressure losses and (iii)
heat losses.

3.1

General model properties

The presented framework is based on the physics-based
modeling language Modelica and a high-level, large-scale
dynamic optimization method available in OCT.
High-fidelity models of district heating networks often
have high computation cost and some model properties
like events or non-differentiability make them even unusable in dynamic optimization. Hence, there is a need
to design simpler models, in particular regarding size and
differentiability, that can be used for online optimization.
There is also a need to design accurate models that can
be used for dynamic simulation to validate the optimal inputs computed based on the simpler model. Models of
both types will be available in Modelons Thermal Power
Library 1.14.
Pipes are the central components in district heating systems. The pipe model for simulation is implemented based
on a plug-flow approach as the solution of the following
one dimensional energy balance:
T
1
T
q(T (x)) = 0
+ v(t)
+
t
 x Sc p

q = 0 (Modelica Association, 2014). The operator keeps
track of the spatial distribution via suitable sampling, interpolation and shifting of the stored distribution and it
also supports flow reversal. Assuming positive flow and a
heat loss q that depends linearly on Tboundary  T (x), the
difference between the surrounding temperature and the
fluid temperature, the temperature at the pipe outlet is
 Tp

T (x = L,t) = Tboundary + (T (x = 0,t  )  Tboundary )e

where L is the pipe length,  the time-varying transport delay and Tp a temperature decay constant. From
the previous equation, it can be seen that the pipe
model with heat loss can be implemented using two
spatialDistribution operators, one to keep track
of the temperature distribution inside the pipe and therefore T (x = 0,t  ), and one to calculate the time-varying
delay  that is needed to compute the impact of the heat
 
loss given by e Tp .
The spatialDistribution operator can however
not be used in the optimization framework because of insufficient differentiability of the involved equations. The
pipe model for optimization (see Figure 1) contains a combination of a fixed time delay and a discretized dynamic
volume. The goal is to compute the main characteristics of
the pipe without having to use a model with a large number of segments which would increase model complexity.
The fixed delay is dependent on the range of the mass flow
for each pipe and corresponds to the minimal time delay.
The dynamic volume must capture the flow-dependence
of the varying transport delay. The number of segments
within the dynamic volume depends on the geometry of
the pipe.

Figure 1. Pipe model for optimization consisting (from left to
right) of a dynamic volume model (fluidTransport), a model that
captures the fixed delay (fluidDelay), a model that calculates the
heat losses (fluidHeatLoss) and a model that calculates the pressure drop (friction).

where v is the fluid velocity, S the cross-section area,  the
fluid density, c p the specific heat capacity of the fluid and
q the heat loss to the surroundings of the pipe. The Modelica built-in operator spatialDistribution provides 3.2 Case study
a robust method to approximate the solution of such par- The case study represents a district heating network in a
tial differential equations when there is no heat loss, i.e. planned city district in Graz/Austria that consists of one
132

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132131

Session 4D: Control Systems I

production unit, 16 consumers and a total length of about
4200 m, see Figure 2. We assume a perfect load prediction
over the entire optimization horizon. Work has also been
done on non-perfect load prediction (Rantzer, 2015), but
was omitted here to focus on other parts of the framework.

supply water temperatures and pressure differences for all
customers were introduced based on real network limits to
satisfy the customers demand. The minimization of supply water temperature and pressure difference for the production unit mimics the situation in a real plant where low
temperatures and differential pressures are desirable in order to reduce heating and pumping costs. The weights are
chosen such that a low temperature is given a higher priority than pressure minimization, as this is the relatively
larger cost in reality. The optimization constraints are inequality constraints defined using the min and max variable attributes.

4

Framework

4.1

Overview

A schematic view of the framework is presented in Figure
3 and each step is explained below.

 Step 1: The network is created using a unified network representation that includes data of the network, demand and boundary conditions.

Figure 2. The scheme of the district heating system. The production unit is seen on the right side; the black/blue circles represent the 16 consumers.

Optimica files that extend the optimization models are
used to describe the optimization problems. The dynamic
optimization problem used for all optimization cases has
the general form
Z tf

min.
t0

2
(Tprod +  d pprod +  Q2prod +  dpprod )dt,

s.t. model dynamics,
mProd (t)  mUProd

t  [t0 ,t f ],

L
TCustomer
 TCustomer (t) t  [t0 ,t f ],
L
d pCustomer
 d pCustomer (t) t  [t0 ,t f ],

 Step 2: The unified network representation is
translated into executable Modelica code, including
graphics annotations (can be read by any Modelcia
authoring tool). A dynamic simulation with fixed
nominal control signals is performed, to get a nominal operation conditions where the aggregation will
be done (Loewen, 2001).
 Step 3: The original network is aggregated to a size
suitable for optimization. The aggregation depth is
flexible and certain consumers can be excluded from
the aggregation.
 Step 4: The aggregated network is simulated to get
initial trajectories for the dynamic optimization.
 Step 5: The dynamic optimization problem is solved.
 Step 6: The optimal trajectories are applied to the
original network.

where Tprod is the supply temperature, d pprod the differential pressure at the production unit, Qprod the load and
,  ,  as well as  are weights. The load derivative Qprod
and the pressure derivative dpprod are the degrees of freedom in the optimization formulation. These are squared in
the cost function to penalize fast control signal changes.
mU Prod is the upper limit of the mass flow at the production unit and it was set to 65 kg/sec; it is representL
ing the pump limitations. TCustomer
is the lower limit of Figure 3. Schematic view of the framework showing the difthe supply temperature for all customers and it was set to ferent steps for network creation, simulation and optimization.
60 deg.C. The lower limit of the differential pressure for
L
all customers (d pCustomer
) was set to 0.5 bar. Minimum
DOI
10.3384/ecp17132131

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

133

Framework for dynamic optimization of district heating systems using Optimica Compiler Toolkit

4.2
4.2.1

Modeling

2001; Larsen et al., 2004).

District heating network representation

The core of the framework is a unified network representation implemented in Python. In general, the representation is applicable for all kinds of network-based energy
systems including district heating systems, gas systems
and power systems. Typically such systems consist of
edges and nodes. Edges could be transmission or distribution lines, gas pipes or pipes within a district heating
system. Nodes could represent consumers and producers in any energy domain, storage or hybrid technologies.
Such a unified network representation is required for two
reasons. Firstly, an automatically generated simulation or
optimization network model based on a unified network
representation reduces the effort for modeling as well as
the liability for errors. Secondly, several steps require detailed information of the network topology and other steps
change the topology of the network. The unified network
representation consists of three central modules: network
representation, aggregation of the network and translation
into executable simulation/optimization code. The first
two modules are independent of the actual simulation and
optimization language. The library is implemented in the
Python module networkX (Hagberg et al., 2008) that is
suitable for the creation and manipulation of complex networks. The network representation is in this paper combined with models from Modelons Thermal Power Library suitable for dynamic simulation and optimization of
district heating systems.
4.2.2

Aggregation method

Dynamic thermo-hydraulic optimization of large-scale
district heating systems is very complex and numerically
challenging. Several concepts approach the problem
by simplifying (some) models (Olsthoorn et al., 2016;
Orehounig et al., 2015), others by simplifying the network
topology using aggregation methods (Larsen et al., 2004;
Grosswindhager et al., 2012). Two methods have been
developed in Denmark and Germany (Larsen et al.,
2004); they are called the Danish and the German
method. The idea behind the aggregation is (i) to change
the tree structure of a network into a line structure and
(ii) to remove short branches. The German method can
handle network topologies with loops as well; this was
the reason why we implemented the German method in
our framework. Both methods were originally defined
for steady state operation. The methods have different
starting points: The German method conserves volume,
mass flow and temperatures in all nodes. Thus, heat
losses from the original and the aggregated networks are
not exactly the same. The Danish method conserves heat
losses. Thus, the node temperatures of the original and the
aggregated networks are not exactly the same. Previous
works on aggregation methods show that networks can
be aggregated up to a very high level even in dynamic
operations without losing significant accuracy (Loewen,
134

4.2.3 Generation of Modelica models for simulation
and optimization
The network representations are translated into Modelica
models using Python functions. Based on the information in the network, corresponding Modelica code is generated, complete with annotations to enable visual inspection of the resulting model. In Figure 4, a generated network for the Graz network is visualized in the diagram
view in Dymola. This method allows for the creation of
complete models for simulation or optimization with components, connect statements and parameter values defined
by the network model. Apart from the actual network, the
generated Modelica models intended for optimization also
contain input and output connectors, to handle the control
signals and delay modeling in the optimization setup.
The components of the Modelica models which are
used for optimization in this project come from Modelons
Thermal Power Library 1.14.
Both the complete district heating network described in
Section 3.2 and aggregated versions of this are translated
into Modelica models. The complete models are used for
simulation, while the aggregated models are used for optimization and for creating initial trajectories for optimization. Different aggregation levels are evaluated in optimization, as explained in Section 5.1.

4.3

Optimization

The OCT toolchain that is used to solve the dynamic
optimization problems starts by transferring the generated Modelica and Optimica code to CasADi Interface
(Lennerns, 2013), which has a flattened and symbolic
representation of the model and optimization problem
based on CasADi (Andersson, 2013). This representation is then propagated to the dynamic optimization algorithm implemented in JModelica.org (Magnusson and
kesson, 2015). This algorithm implements direct collocation (Biegler, 2010) to transcribe the problem into a
nonlinear program (NLP), which is then solved by IPOPT
(Wchter and Biegler, 2006). CasADi is used to compute
first- and second-order sparse derivatives using algorithmic differentiation (Griewank and Walther, 2008).
The dynamic optimization framework has recently been
extended to treat delay differential-algebraic equations
where the delay is fixed a priori, which is needed for the
pipe models discussed in Section 3.1. Methods based on
direct, local collocation are well-suited for handling such
models (Betts et al., 2016).
4.3.1 Symbolic elimination
Before the model is transferred to CasADi Interface,
the OCT compiler performs alias elimination, variability
propagation and index reduction. The flattened, fully implicit differential-algebraic equation (DAE) is then transferred to CasADi Interface and later exposed to the direct

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132131

Session 4D: Control Systems I

Figure 4. Modelica model of Graz network generated in Python from network description. The customers are represented by the
orange red house icons, the pipe models are red and blue and the production unit is the gray model located furthest to the left.

collocation.
This approach leads to very large and sparse NLPs because of the multitude of algebraic variables in the network model. There has been recent work carried out
(Magnusson and kesson, 2016) to address this problem in general by applying a block-lower triangular (BLT)
transformation of the DAE to identify algebraic variables
that only depend affinely on the corresponding block variables. This allows symbolic elimination of such variables
by forward substitution. Further variables can be eliminated by applying tearing (Meijer, 2011; Baharev et al.,
2016) to handle nonlinear dependencies. The majority of
algebraic variables are thus eliminated prior to discretization by direct collocation, drastically reducing the size of
the NLP. However, although the number of variables and
equations are reduced, the resulting NLP Jacobian and
Hessian tend to become more dense as a result, potentially
crippling the performance of the sparse numerical linear
algebra. A novel heuristic, similar to local minimum fillin (Duff et al., 1986), is used to identify algebraic variables
that should not be eliminated in order to preserve the sparsity of the NLP, typically leading to faster solution times.
In Modelica tools it is common to eliminate all algebraic variables by embedding Newton iterations in the
right-hand side of an explicit ordinary differential equation, which is the foundation of FMI. In the spirit of simultaneous discretization, this approach is not used in OCT
to avoid the long evaluation times that may result from
solving implicit equations in each iteration and also the
increased problem density resulting from elimination.
As demonstrated in (Magnusson and kesson, 2016),
and as we will also see is the case in this work, the symbolic elimination not only reduces the solution time, but
also improves convergence robustness, that is, probability of successfully solving an optimization problem in a
timely manner.

tups. The goal is to understand the impact of the aggregation level on the production plans and of the symbolic
elimination on the convergence and robustness of the optimization problem.

5.1

Optimization setups

The optimization problem was solved for three different
aggregation levels resulting in two, five and seven customers. Very little difference in the optimal trajectories
could be observed (data not shown). This indicates that
aggregating the network to just two customers is sufficient
to describe the current network with good accuracy.
The convergence of the optimization algorithm was also
analyzed in detail for each aggregation level, to investigate the scalability of the current approach. All optimization cases were run on a laptop with 8 GB RAM and four
2.6 GHz CPUs, with convergence results and optimization model statistics displayed in Tables 1 and 2. The results show that the main benefit of the elimination occurs
for larger network models, when both the time per iteration and the number of iterations is significantly reduced,
resulting in a much better overall performance. The total time for running the entire script is reduced by more
than a factor 2 and the optimization convergence is also
significantly more robust, as indicated by the number of
iterations and by manual inspection of the output from
IPOPT. For fewer customers, the comparison between the
two methods give less clear results. The overall time for
running the script is approximately the same, as is the robustness of the convergence. The reason for the similar
performance is that the time gained by eliminating variables is lost from the extra time needed to perform the
elimination.

5.2

Optimal trajectories

The optimized trajectories are studied for the aggregated
system with five customers. The network aggregation is
displayed in Figure 5, and the trajectories are displayed in
5 Results
Figure 6. It is clear from the temperature plot that the heat
The production planning formulation described in Section loss and transport delay are correctly captured in the op3.2 was solved for different optimization and model se- timization model: the customer at the network periphery
DOI
10.3384/ecp17132131

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

135

Framework for dynamic optimization of district heating systems using Optimica Compiler Toolkit

Table 1. Optimization model statistics.

Nbr of customers
Nbr of states
Nbr of algebraics
Nbr of algebraics a.e
Nbr of variables in NLP
Nbr of variables a.e

2
12
136
17
61354
18395

5
22
298
45
130412
39079

7
30
413
66
150159
45712

Table 2. Optimization convergence results.

Nbr of customers
2
Without symbolic elimination
Nbr of iterations
29
IPOPT CPU time [s]
13
NLP function eval time [s]
24
IPOPT total time [s]
103
Script total time [s]
120
With symbolic elimination
Nbr of customers
2
Nbr of iterations
31
IPOPT CPU time [s]
7
NLP function eval time [s]
25
IPOPT total time [s]
75
Script total time [s]
121

5

7

42
163
60
422
448

88
1103
161
1516
1548

5
43
31
68
240
431

7
44
60
71
314
685
Figure 5. Complete and aggregated network models.

received a slightly colder water and with some delay. It
is also visible that the optimization minimizes pump cost,
i.e. discharge pressure at the producer, while respecting
the differential pressure constraint across the customers
valve: the customer O, furthest away from the producer
has its dp constraint active most of the time. During high
load, the distribution pump of the producer is at its maximum capacity and the mass rate saturates. As a consequence the supply temperature is increased to fulfill the
heat demand of all customers. The temperature increase is
done in advance to compensate for the mass flow dependent delays in the network.
Another interesting phenomenon can be seen when customer O, far away from the producer is operating at maximum valve opening, at about t=2.5h and 9.5h. Figure 7
displays this phenomenon around the first load peak. It
shows that the increase in the supply temperature at the
producer propagates with the flow in the network and results in valve closing at the customers close to the producer, in the figure illustrated with customer I1, which is
closest to the producer. This shifts the mass flow rate from
the close customers to customer O that gets its higher load
fullfilled. The increase in the producers supply temperature propagates quicker than the speed of the hot water.

5.3

Verification in simulation

The previous section demonstrates that the optimization
method is able to generate optimal trajectories for temperature and pressure that fulfill the operational constraints
from the customers and the distribution network. The net136

work model used for optimization differs however from
the original one as it has been simplified by the aggregation method described in Section 4.2.2. The idea is
now to validate the optimization results and the aggregation method by applying the optimal trajectories on the
complex model with 16 customers. As the pressure profile would not be applied in reality, the supply pressure at
the production unit is instead manipulated by a controller
that maintains a minimum pressure difference over all customers. Only the supply temperature trajectory is applied
to the complex network model. The results are shown in
Figure 8. The supply temperature at the customer furthest
away from the plant is very similar when the optimization
and simulation results are compared. The mass flowrate
computed by the differential controller is also very similar to the optimized trajectory. Some differences in the
differential pressure can be seen as the optimization does
not always operate at the minimum value but sometimes
at a higher level to minimize the overall cost. The results
indicate in general that the aggregation to two customers
is good enough for this 16 customers network model.

6

Discussion

This paper presents new features of Modelons Thermal
Power Library 1.14 in the field of dynamic optimization
of district heating systems as well as the impact of the
new algorithm for symbolic elimination available in Optimica Compiler Toolkit. The new features together with

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132131

5800
5600
5400
5200
5000
4800
4600
44000

70

Total load

Mass flow [kg/s]

Load [kW]

Session 4D: Control Systems I

2

4

6
Time [hours]

8

10

66
64
62
60

12

Mass Flow Producer

68

2.0

T_supply Producer
T_supply Customer O
Temperature constraint

2

4

6
Time [hours]

8

10

12

Production unit and Customer O feed water temperature and
temperature constraint

62
60
58
Mass Flow Producer
Mass Flow constraint
10
12

56
4

6
Time [hours]

8

4

6
Time [hours]

8

10

Mass flow [kg/s]

Differential pressure [bar]

T_supply Customer I1
T_supply Customer O

2.0

2.5

3.0
Time [hours]

3.5

4.0

Mass Flow Customer O

19
18
17
16
2.0

2.5

3.0
Time [hours]

3.5

4.0

Customer O mass flow
Differential pressure Customer O
Differential pressure constraint

2

70
68
66
64
62
60
58
56

15

Production unit mass flow and mass flow constraint
0.80
0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.400

4.0

Supply temperatures for closest and furthest Customer

Mass flow [kg/s]

Mass flow [kg/s]

64

2

3.5

20

66

540

3.0
Time [hours]

Total supply mass flow
Temperature [deg C]

Temperature [deg C]

Total customer load
66
65
64
63
62
61
60
590

2.5

5.4
5.2
5.0
4.8
4.6
4.4
4.2
4.0

Mass Flow Customer I1

2.0

12

Customer O differential pressure and differential pressure constraint

2.5

3.0
Time [hours]

3.5

4.0

Customer I1 mass flow
Figure 7. Heat to customer O based on mass flow change for
remaining customers.

Figure 6. Optimal trajectories for an aggregated network model
with five customers.

a unified representation of network-based energy systems
make it possible to analyze, simulate and optimize small
and larger district heating or cooling systems. It is also
possible to include physical constraints based on operational limitations into the optimization formulation.
Based on the results it can be concluded that the aggregation method achieves accurate results at an aggregation
depth of about 90 %. Furthermore it can be concluded
that the main benefit of the elimination occurs for larger
models where the computation time could be reduced by
more than a factor 2. Enabling the elimination yields an
overall computation time for seven remaining customers
of about 11 minutes and a solution time of about 5 minutes. In the context of model predictive control the solution time is sufficiently low for a real-time application and
it could be further reduced by initializing the optimization
with the results of the latest iteration. In an offline optiDOI
10.3384/ecp17132131

mizatino context, the overall computation time could also
be reduced by using the optimization results for lower aggregation levels as initial guesses for the optimization of
more complex networks. The next stage of our research
will include scale-up studies and the integration of the unit
commitment problem in the overall framework.

7

Acknowledgements

Fredrik Magnusson acknowledges support from the
LCCC Linnaeus Center and eLLIIT Excellence Center at Lund University. Gerald Schweiger acknowledges the Austrian Federal Ministry of Science, Research
and Economics for funding the project FlexEnergySys
(848346)". Modelon AB acknowledges support from PiiA
 Processindustriell IT och Automation.

References
Johan kesson. Optimicaan extension of Modelica supporting dynamic optimization. In Proceedings of the 6th Interna-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

137

Framework for dynamic optimization of district heating systems using Optimica Compiler Toolkit

66

Temperature [deg C]

Lorenz T. Biegler. Nonlinear Programming: Concepts, Algorithms, and Applications to Chemical Processes. MOSSIAM, Philadelphia, PA, 2010.

Limiting Customer Optimization
Limiting Customer Simulation

65
64
63
62
61
60
59
58

0

2

4

6

Time [hours]

8

10

12

Andreas Griewank and Andrea Walther. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. SIAM, Philadelphia, PA, 2nd edition, 2008.

Supply temperature for limiting customer

Mass flow [kg/s]

70

65

60

55

50

Producer Optimization
Producer Simulation
0

2

4

6

Time [hours]

8

10

12

Differential pressure [bar]

Limiting Customer Optimization
Limiting Customer Simulation

0.75
0.70

Stefan Grosswindhager, Andreas Voigt, Martin Kozek, and
A Varying-coefficient Models. Predictive Control of District
Heating Network using Fuzzy DMC. In International Conference on Modelling, Identification and Control, 2012.
Aric A. Hagberg, Daniel A. Schult, and Pieter J. Swart. Exploring network structure, dynamics, and function using NetworkX. Proceedings of the 7th Python in Science Conference
(SciPy 2008), (SciPy):1115, 2008.

Total mass flow through the production unit
0.80

Iain S. Duff, Albert. Erisman, and John K. Reid. Direct Methods for Sparse Matrices. Clarendon Press, Oxford, United
Kingdom, 1986.

0.65
0.60
0.55
0.50
0.45
0.40

0

2

4

6

Time [hours]

8

10

12

Differential pressure for limiting customer
Figure 8. Comparison between optmization results for two customers and simulation results for the complete network with optimal inputs.

tional Modelica Conference, pages 5766, 2008.
Johan kesson, Karl-Erik rzn, Magnus Gfvert, Tove
Bergdahl, and Hubertus Tummescheit. Modeling and optimization with Optimica and JModelica.orglanguages and
tools for solving large-scale dynamic optimization problems.
Computers & Chemical Engineering, 34:17371749, 2010.
Jonas Allegrini, Kristina Orehounig, Georgios Mavromatidis,
Florian Ruesch, Viktor Dorer, and Ralph Evins. A review of
modelling approaches and tools for the simulation of districtscale energy systems. Renewable and Sustainable Energy Reviews, 52:13911404, 2015. URL http://dx.doi.org/
10.1016/j.rser.2015.07.123.
Joel Andersson. A General-Purpose Software Framework for
Dynamic Optimization. Ph.D. thesis, Arenberg Doctoral
School, KU Leuven, Belgium, 2013.
Ali Baharev, Hermann Schichl, and Arnold Neumaier. Decomposition methods for solving sparse nonlinear systems
of equations. Submitted for publication. Available online: http://reliablecomputing.eu/baharev_
tearing_survey.pdf, 2016.
John T. Betts, Stephen L. Campbell, and Karmethia C. Thompson. Solving optimal control problems with control delays
using direct transcription. Applied Numerical Mathematics,
108:185203, 2016.

138

Helge V Larsen, Benny Bhm, and Michael Wigbels. A comparison of aggregated models for simulation and operational
optimisation of district heating networks. Energy Conversion
and Management, 45:11191139, 2004.
Bjrn Lennerns. A CasADi based toolchain for JModelica.org.
M.Sc. thesis, Department of Automatic Control, Lund University, Sweden, 2013.
Achim Loewen. Entwicklung eines Verfahrens zur Aggregation
komplexer Fernwrmenetze. Ph.D. thesis, Fraunhofer UMSICHT, Germany, 2001.
Henrik Lund, Sven Werner, Robin Wiltshire, Svend Svendsen, Jan Eric Thorsen, Frede Hvelplund, and Brian Vad
Mathiesen.
4th Generation District Heating (4GDH):
Integrating smart thermal grids into future sustainable energy systems.
Energy, 68:111, 2014.
URL
http://www.sciencedirect.com/science/
article/pii/S0360544214002369.
Fredrik Magnusson and Johan kesson. Dynamic optimization
in JModelica.org. Processes, 3(2):471496, 2015.
Fredrik Magnusson and Johan kesson. Symbolic elimination
in dynamic optimization based on block-triangular ordering.
Optimization Methods and Software, 2016. Accepted for publication.
Patrik Meijer. Tearing differential algebraic equations. M.Sc.
thesis, Centre for Mathematical Sciences, Lund University,
Sweden, 2011.
R - A Unified ObjectModelica Association.
Modelica
Oriented Language for Systems Modeling Language
Specification Version 3.3 Revision 1.
2014.
URL
https://www.modelica.org/documents/
ModelicaSpec33Revision1.pdf.

Modelon.
OPTIMICA Compiler Toolkit,
2016.
URL
http://www.modelon.com/products/
optimica-compiler-toolkit/.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132131

Session 4D: Control Systems I

Dave Olsthoorn, Fariborz Haghighat, and Parham A Mirzaei. Integration of storage and renewable energy into district heating
systems : A review of modelling and optimization. Solar Energy, 136:4964, 2016. URL http://dx.doi.org/10.
1016/j.solener.2016.06.054.
Kristina Orehounig, Ralph Evins, and Viktor Dorer. Integration of decentralized energy systems in neighbourhoods using the energy hub approach. Applied Energy, 154:277
289, 2015. URL http://dx.doi.org/10.1016/j.
apenergy.2015.04.114.
Jonatan Rantzer. Robust production planning for district heating
networks. M.Sc. thesis, Centre for Mathematical Sciences,
Lund University, Sweden, 2015.
Hkan Runvik, Per-Ola Larsson, Stphane Velut, Jonas Funquist, Markus Bohlin, Andreas Nilsson, and Sara Modarrez
Razavi. Production Planning for Distributed District Heating
Networks with JModelica.org. In 11th International Modelica Conference, pages 217223, 2015.
Gerald Schweiger, Per-Ola Larsson, Fredrik Magnusson,
Patrick Lauenburg, and Stphane Velut. District heating and
cooling systems  framework for modelica-based simulation
and dynamic optimization. Energy, 2017a. ISSN 0360-5442.
doi:https://doi.org/10.1016/j.energy.2017.05.115.
URL
http://www.sciencedirect.com/science/
article/pii/S0360544217308691.
Gerald Schweiger, Jonatan Rantzer, Karin Ericsson, and Patrick
Lauenburg. The potential of power-to-heat in swedish
district heating systems. Energy, 2017b. ISSN 0360-5442.
doi:http://dx.doi.org/10.1016/j.energy.2017.02.075.
URL
http://www.sciencedirect.com/science/
article/pii/S0360544217302499.
Stphane Velut, Per-Ola Larsson, Johan Windahl, Linn Saarinen,
and Katarina Boman. Short-term production planning for district heating networks with JModelica.org. In Proceedings of
the 10th International Modelica Conference, pages 959968,
2014.
Andreas Wchter and Lorenz T. Biegler. On the implementation
of a primal-dual interior point filter line search algorithm for
large-scale nonlinear programming. Mathematical Programming, 106:2557, 2006.

DOI
10.3384/ecp17132131

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

139

140

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Optimal Control of District Heating Systems using Dynamic
Simulation and Mixed Integer Linear Programming
Loc Giraud

Massinissa Merabet

Roland Baviere

Mathieu Valle

Univ. Grenoble Alpes, INES, F-73375 Le Bourget du Lac, France
CEA, LITEN, 17, Rue des Martyrs, F-38054 Grenoble, France, roland.baviere@cea.fr

Abstract
This paper presents the development of a new advanced
control method suitable for variable temperature District
Heating Systems (DHS). The proposed controller
determines optimal planning for the on/off status and
power of the heat generators as well as for the supply
temperature and differential pressure at the production
plant level. Compared to existing methods, the original
features of the developed solution are to fully exploit the
thermal storage capacity of the network and to
determine the best compromise between pumping costs
and heat losses. A numerical case study based on a
representative DHS is used to evaluate the method over
a heating season (5 months). Results show that our
method reduces production costs up to 8.3 % when
compared to a more classical controller. Moreover, the
observed computing time is compatible with the
requirements of the receding time horizon principle,
ensuring that the method is tractable on real DHS.
Keywords:
District Heating, Model Predictive
Control, Dynamic Simulation, Mixed Integer Linear
Programming

1

Introduction

Nowadays, many research works devoted to District
Heating Systems (DHS) are performed on low and very
low temperature systems, mainly because of their
energy performance and their ability to use renewable
energy sources. However, High Temperature District
Heating Systems (HTDHS) represent an important share
of the existent systems in Europe. For instance, systems
with temperature over 110 C account for more than 50
% of the heat delivered by French DHS (SNCU, 2013).
The energy load of HTDHS is generally supplied by
numerous generators and fuels. On the other hand, their
distribution network usually bears large variations in
temperature and differential pressure. Thus, HTDHS are
affected by non-constant production costs yet they
natively comprise important thermal storage capacities,
i.e. network storage, if an adequate supply temperature
control is used. Additionally, HTDHS are subject to
complex dynamic behaviors originating both from the
variability of the demand and the significant
temperature transportation delay. Finally, heat can be
DOI
10.3384/ecp17132141

delivered to the consumers using various combinations
of temperature and mass flow rate. Lowering network
temperature would limit the thermal losses; however,
the mass flow rate shall increase in order to maintain the
same heat flow, and this will cause pumping work to
rise. Contrary to what is generally considered, in many
practical situations, particularly recurrent in HTDHS,
the optimal balance between pumping work and heat
losses may be obtained with high supply temperature
and low differential pressure.
As pointed in (Lund, 2014), the intelligent control for
optimal operation is a future challenge for the
improvement of DHS. Due to its complexity and high
parameters combinatorics, the determination of optimal
production and distribution plans in DHS is difficult, if
not impossible, when solely based on empirical laws
and/or expert judgement. In this context, decision
support/making tools relying on a Model Predictive
Control (MPC) scheme are very useful. Despite
significant progress, there is still an important room
for improvement in this domain.
This paper focuses on the optimal control of
pressurized water DHS. For this application, we have
developed and tested an algorithm that optimizes, given
a load prediction, the use of production means as well as
supply temperature and differential pressure. Compared
to existing methods, the original features of the
developed solution are, firstly, to fully exploit the
thermal storage capacity of the network. Secondly, our
controller is suitable for determining the best possible
combination between electrical costs for pumping and
heat production costs compensating distribution losses.
Though generic, the proposed control method is
particularly adapted to existing HTDHS.
Our controller is based on a MPC scheme. At each
time step, a dynamic non-linear model of the
distribution network is simulated over a finite timehorizon. In the present work, this model is built using
the equation-based object-oriented language Modelica
along with the simulation platform Dymola and an inhouse component model library named DistrictHeating
(Giraud b), 2015). The simulation results are then used
to formulate a linearized model of the distribution
network. Combined with other linear constraints
representing the technical limitations of the different

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

141

Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming

pieces of equipment and with a linear cost function, the
model forms a Mixed Integer Linear Program (MILP).
In a last step, this program is solved yielding the optimal
trajectories for the various control variables of the
problem.
In section 2, we present a literature review on
advanced control for DHS. Section 3 firstly describes
the algorithmic aspects of the proposed controller,
secondly presents the non-linear network model used for
dynamic simulation and finally details the formulation
of the linear optimization problem. A case study
consisting of a virtual yet representative HTDHS is then
described in section 4. In section 5, the simulation
results obtained for various controllers over a heating
season are presented and discussed. Section 6 includes
the conclusions and perspectives of our study.

2

Existing DHS Control Methods

The approach currently used to determine the control
variables of DHS (e.g. supply temperature, differential
pressure, load distribution between different heat
production units ) often relies on heuristic methods,
i.e. a formalization of common sense, simple logic or
expert judgement. As an example, we can recall here the
determination of supply temperature using a single or
even multi-variable heating curve. Though simple to
implement and robust with respect to production or
demand uncertainties, the efficiency of such control
methods is always limited when applied to a system
comprising several sources, variable energy purchase
prices and energy storage capacity. This is partly due to
the fact that anticipative control strategies are difficult if
not impossible to formulate in this framework. Another
difficulty is that production goals may be multiple and
conflicting (e.g. power and heat generation in combined
heat-and-power units).
To overcome the aforementioned difficulties, an
MPC scheme is an interesting alternative. The MPC
approach consists of a load prediction module and an
optimization procedure used to determine the best
possible path for control variables, i.e. the one
minimizing an objective function while meeting
different technical and operational constraints.
Depending on the formulation of the quantitative
objective to minimize, operating costs and/or CO2
content of the delivered heat may be significantly
improved.
However, building an MPC scheme to control a DHS
is a complex task. This explains why most previous
works done on this subject only consider some parts of
the problem. On the one hand, numerous studies deal
with production optimization only, i.e. they address the
unit commitment and load dispatch problems. In
(Eriksonn, 1994), the author determines the heat power
planning for each production unit considering starting
costs, minimal load of each generator and bounds for
heat power ramp rates. This approach is mostly used in
142

studies interested in combined heat and power plants
since electricity must be produced when it is the most
profitable. On the other hand, several works only
consider the supply temperature determination.
Important features here are to reduce heat losses and to
use the network capacity for heat storage. For instance,
the supply temperature is optimized in (Nielsen, 2005)
using the Finite Impulse Response method to linearize a
dynamic distribution network model and then to solve
the linear optimization problem. Few works study both
the load dispatch problem and the supply temperature
determination. The integer variables, representing for
instance the heat generators statuses, are then not taken
into account in these cases in order to reduce the
combinatory.
Load Prediction

Starting guess

Dynamic
network model

Optimizer

,

Convergence
?

No

Yes
Optimized control variables

Figure 1: Proposed optimal control
algorithm for DHS.

More recently, both the supply temperature and heat
power planning have been determined in order to
minimize the production costs yet without considering
the time delays in the network (Fang, 2015). Another
possible approach, quite popular in the Modelica
community, consists in modeling, formulating and
solving a dynamic optimization problem using the
JModelica.org tools (Akesson, 2011). Following this
method, (Runvik, 2015) also solve a short-term
production planning problem for a DHS using a twosteps optimization procedure including production and
distribution variables. However, due to prohibitive
computational costs, the network representation only
includes three customers.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132141

Session 4D: Control Systems I

In conclusion of this review, no method has been
identified in the literature that adequately optimizes the
production and the distribution considering network
storage for DHS. In the following, we present such a
method and study its benefits on a representative
HTDH.

3

Optimal Control of DHS

In this section, we describe the optimal control method
we designed. The objective is to determine the optimal
trajectory for the control variables over a defined
anticipation horizon. Taking into account the relatively
slow dynamics of a DHS requires anticipation, i.e. using
load predictions and optimizing of control variables so
that the system produces the desired effects in the future.
Additionally, periodically revising the optimization is
mandatory in order to cope with load prediction
uncertainties.
To address these challenges, we combine a dynamic
nonlinear model of the DHS with linear optimization
methods, similarly to other works like those of
(Benonysson, 1991) and (Sandou, 2006). For each
anticipation horizon, our system encompasses both
production and distribution optimization and controls
heat powers, generators statuses, supply temperature
and differential pressure. To guarantee the applicability
of the control trajectories, the optimization is
constrained by the technical limits of the DHSs pieces
of equipment.
This section first gives a general description of the
algorithm, then details the dynamic nonlinear model,
which we illustrate more specifically in the case study.
It ends with a description of the linear optimization
problems formulation.

algorithm is illustrated in Figure 2 in a situation where
the receding horizon Pr is chosen equal to 1.

3.2 The dynamic distribution network model
The proposed algorithm requires the simulation of a
dynamic model representing the distribution network.
Figure 3 depicts the mesh-free layout of the
distribution network considered in the case study. Since
we study our control strategy on a mid-scale DHS, our
dynamic network model is based on a detailed physical
representation of the system by gathering component
models that we previously developed and validated. The
components models are taken from an in-house
Modelica library named DistrictHeating and presented
in (Giraud b), 2015). The heat generators are represented
considering equivalent heat and momentum sources.
Moreover, the model enables the control of supply
temperature and differential pressure at the production
plant level. The distribution pipe model that we use is
based on the method of characteristics, also called node
method in the specific DHS related literature see
(Benonysson, 1991). This model accounts for heat
propagation delays, heat losses, tube thermal inertia and
pressure
losses.
Concerning
the
substation
representation, we use an explicit model comprising a

3.1 General Description
Figure 1 depicts the proposed algorithm. The dynamic
nonlinear network model is first simulated using initial
guesses for the distribution control variables, namely the
supply temperature and differential pressure at
production plants. We then extract relevant input data
for the optimization problem and we formulate a linear
relaxation of the optimization problem using the MILP
formalism. The optimizer finally computes a new set of
control variables. Iterations between the dynamic
network model and the MILP optimizer are conducted
until convergence is reached, using a criteria defined by
a threshold on the supply temperature increment.
We then periodically revise the optimization using
the receding time horizon. At time , the optimization
procedure is performed for the predictive horizon t+Nt
yet only the first output values for time slot [:  + ]
are applied to the system. At time t+Pr, the calculation
is repeated for the optimization horizon t+Pr+Nt. This

DOI
10.3384/ecp17132141

Figure 2: Receding horizon principle

heat exchanger, a regulation valve and an ideal
controller (see (Giraud a), 2015) for details).

3.3 Formulation of the Linear Optimization
Problem
The linear optimization problem is an approximation, or
relaxation, of the complete, strongly nonlinear problem
that would take into account all the physical and
technical constraints of the system. However,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

143

Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming

formulating the linear problem using appropriate
assumptions yields usable results in a limited
computating time. This section details the formulation
of the linear problem we adopted, which includes the
MILP variables, the cost function to minimize, the
technical limits of the DHS, the critical curve describing
consumers constraints and a linearized model of the
distribution network.
3.3.1 MILP variables
The optimization variables of the problem are identified
by an asterisk and typed in bold to better readability. All
of them are time discretized and considered constant
over one time step.
Continuous variables
() : Represents the heat power produced by each
generator g at the time t.
() : Represents the supply temperature in the
network at the time t.
 () : Represents the total mass flow rate at the
production plant at the time t.
(t) : Represents the differential pressure at the
production plant at the time t.

(t) : Represents the pump work at the time t.
Binary variables
() : Represents the on/off status of each
generator, i.e. it is equal to one when generator  is on
and to zero otherwise.
() : Identifies the timing of each generator startup, i.e. it is equal to one only when
switches from 0
to 1 and to zero otherwise.
3.3.2 The cost function

The function to be minimized, presented in expression
(1), reflects the integral of operational costs over a finite
time-horizon. The first term in equation (1) represents
the fuel consumption and it is thus proportional to the

 parameters standing for fuel prices. The second term
accounts for specific costs linked to generator start-up
and they are therefore proportional to fixed monetary
/
amounts denoted 
. The last term accounts for
electricity consumption due to pumps operation. It is
therefore proportional to a time variable electricity
purchase price hereafter denoted   (). Pumping and
heat generation efficiencies are accounted for
respectively using the 
and  constant parameters.

 ( (
.. +







()   +  /


()) +

  ()



()

(1)

 )

To guarantee the applicability of its outcomes, the
minimization calculation must be performed in the
presence of linear constraints on the optimization
variables. Inequality constraints will be presented first.
In a second step we present the equality constraints
accounting for the mass, energy and momentum balance
equations governing the relations between the operating
variables.
3.3.3 Inequality constraints

Several continuous variable are considered with lower
and upper bounds representing physical limitations of
DHS components as presented in inequalities (2), (3)
and (4). Each parameter noted with a  or 
superscript is a known and fixed parameter of the
problem.



() 
() 




(2)
(3)

Figure 3: Layout of the distribution network case study in Modelica/Dymola.

144

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132141

Session 4D: Control Systems I



 ()





expression (8) relating  , the primary mass flow rate
, the primary inlet and outlet temperatures (
and
) and the fluid specific heat capacity .

(4)

To limit thermal fatigue, we bound supply
temperature and heat power variations with expressions



Figure 4: Consumer critical temperature as a function of the differential pressure and heat demand (left) 
Cut-plane for a fixed heat demand (right).

of the following type, written for a sample variable  :




  ()

 (

1)  



(5)

Inequalities (6) are used to confine between 
and   when generator  is started. Otherwise,
is set to 0.
()  

() 



()   

(6)

Finally, inequalities (7) are considered to define the
timing of each generator start-up, i.e. variable .
()

(

1) 

() 

()

() =

 ()
  (

()

(8)

())

On the other hand,
cannot exceed the value
reached when the primary control valve is fully open.
 (),
Such maximal value, denoted
can be
calculated assuming a quadratic dependency between
the local differential pressure of the network, namely
, and the mass flow rate. This is shown in equation
(9) used for valve modeling. In this equation,
and
are nominal values of the primary mass flow rate
and the differential pressure.

(7)

 ()



=

()

(9)

3.3.4 Critical conditions to supply heat demand

Supplying the requested heat demand to a DHS
customer is only possible when the local network
temperature exceeds a threshold called the critical
(). The present
temperature and hereafter denoted
section firstly discusses how to derive the formula used
() and secondly presents the linear
to evaluate
inequality constraints necessary in the MILP problem to
guarantee that heat demand is fulfilled.
We consider in this study that the substations are of
the indirectly connected type and that they are composed
of one counter-flow heat-exchanger, free of any by-pass,
and a primary control valve used to regulate the building
heating system temperature at a requested level. For
such system, as long as the consumer heat demand  is
fulfilled, a static energy balance applied on the primary
side of the heat exchanger yields the mathematical

DOI
10.3384/ecp17132141

The critical temperature is obtained by assuming that

the demand is fulfilled while
equals
. Thus,
combining equations (8) and (9) leads to expression (10)
for the critical temperature:
() =

 ()

() +
 



()

(10)

At this stage, it is worth mentioning that an additional
heat-exchanger model is requested to evaluate formula
(10) since the primary outlet temperature, namely
(), has not been determined yet. In our study, the
Logarithmic Mean Temperature Difference method is
used for this purpose.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

145

Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming

As a consequence, heat demand of consumer  will
only be satisfied if local network conditions in terms of
temperature and differential pressure are above critical
values shown in Figure 4, i.e. if inequality (11) is
verified:
() 

() =

 ()

() +
 



()

())

=1  

(12)

In expression (12), the   functions are a set of 
linear functions approximating the critical temperature
calculated from the right hand-side of expression (11).
Bearing in mind that the algorithm aims at producing
optimal planning for the supply temperature and the
differential pressure, we then consider linear relations
between the variables at the consumers sides and those
at the production plant level where the control variables
are applied. The heat propagation equation (13), detailed
in (Benonysson, 1991), is used to express the consumers
inlet temperature
as a function of the supply
Normalized heat demand (-)



(11)

This last expression is adapted to our problem using
piecewise linear approximations compatible with the
MILP formalism:
()    (

temperature
. It considers a propagation time delay
and heat losses using the 
thermal time
constant and the
parameter
representing
the

ambient temperature surrounding the distribution pipes.
+(


())

(



)

(13)

 ( )


 

At this point, one can note that temperature
propagation delay
introduces nonlinearities into the
optimization problem. Thus, propagation delays
are
not handled directly in the MILP problem but are
provided by the dynamic model presented in section 3.2.
For the differential pressure losses, a linearized
relation, well verified on the Grenoble DHS, is
considered as shown in expression (14):
() =

()

 

 ()

(14)

Expression (12) is then re-written using (13) and (14)
to introduce the
,  and
optimization
variables. This yields the linear inequality constraints
(15) that are used in our MILP problem to guarantee that
consumer satisfaction is not sacrificed.

0.6
0.5

0.4
0.3
0.2
0.1
0.0
04/11/13

04/12/13

03/01/14
Time (day)

02/02/14

04/03/14

Externatl temperature ( C)

-10
-5
0
5
10
15
20

Figure 5: Evolutions over the heating season of the normalized heat demand (top) and external temperature
(bottom).

146

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132141

Session 4D: Control Systems I



+(

())

(

 





)

 ( )
 

()

(

 ())





(15)

=1 

3.3.5 The linearized distribution network model

The relations between the optimization variables
accounting for distribution network mass, momentum
and energy conservation laws are considered thanks to a
set of linearized equality constraints that are presented
in this section.
First, the pumping work 
appearing in the cost
function (1) is expressed linearly using a first order
Taylor expansion limited to differential pressure and
mass flow rate variations. The fluid density  are
therefore assumed constant, which leads to expression
(16):

=

()
() 

() +

 ()




() 


()

(16)

()

(),
() and 
In this last expression,
are provided by the dynamic simulation model
described in section 3.2.
Second, a linearized version of the network energy
balance is obtained. This point is crucial if one wants to
benefit from the possibility to store heat directly in the
distribution network. By following the derivation
presented in (Giraud, 2016), the subsequent expression
can be obtained:


/

() =   ()  [1 +  ()]

(17)





()

In expression (17),  () is a modulation term that
depends on past and present values of supply
temperature.
3.3.6 Summary

Our MILP DHS production and distribution optimizer is
composed of a linear cost function (see equation (1))
subject to linear equality (see equations (16) and (17))
and inequality (see equations (2)-(7), (15)) constraints
representing the physical conservation laws and the
technical limitations of the DHS.

4

The case study

The operation of our advanced controller has been
evaluated by simulation means relying on a

DOI
10.3384/ecp17132141

representative case-study. This section explains how the
case-study has been designed and it details the models
composing it.
The CCIAG company and our research group are
currently involved in a joint research program devoted
to the development of advanced decision
support/making tools for operational management of
DHS. CCIAG operates the second largest DHS in
France in the city of Grenoble. This system yearly
delivers 900 GWh of heat using 225 km of distribution
pipes and liquid pressurized water as heat carrier fluid.
This system is actually managed using variable supply
temperatures and differential pressures respectively
ranging from 110 C to 180 C and 5 to 15 bars. These
features are similar to systems in other French and
European cities (e.g. Metz, Chambry, Vienna,
Warsaw). Therefore, we have built the case-study
used in the present paper upon the Grenoble HTDH
system. However, in order to limit the modelling work
during the first stages of our research project we
considered only a portion of the Grenoble distribution
network.
On the production side, we have considered 15 heat
production units as it is representative of the installed
capacity in Grenoble. All the 15 heat production units
form a unique production plant represented in the
dynamic model by equivalent heat and momentum
sources. The sample network serves 26 heat consumers
modelled using load profiles taken from an historical
database (15 min sampling period) provided by CCIAG.
The substation models are parametrized using the
dimensioning rules applied on the Grenoble DHS.
To increase the relevance of the model, the main
parameters used to model the production units in the
MILP model have been proposed by CCIAG, our
industrial partner in the project. For confidentiality
purposes, the fuel prices denoted  , the cost of a
generator start up denoted 
and the daily
electricity price profile used for pump operation,
denoted   are not reported here.

4.1 Simulation settings
The simulation period covers the full 2013/2014 French
heating season, i.e. from November 2013 to mid-April
2014. The heat demand normalized by the installed heat
power capacity (designed for an external temperature of
-11 C) and the external temperature over that period are
shown in Figure 5. Outside this period, low cost heat
from the waste incineration unit is produced in excess of
demand thereby limiting the usefulness of advanced
control strategy. Moreover, the heating season
represents over 80 % of annual production costs.
The simulations were conducted with an elementary
time step of 15 minutes. The optimization time-horizon
is set to 24 hours and the receding horizon is fixed at 6
hours. For control in real conditions, affected by many
sources of uncertainty (e.g. load prediction errors ),

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

147

Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming

the receding horizon would be chosen equal to the 15
min elementary time step to increase robustness and
stability. A complementary study on this topic is
currently under investigation.
A 1 K threshold on the supply temperature increment
is used to decide that convergence between the dynamic
model and the MILP problem is reached. We set the
relative MIP gap tolerance to 0.03. That instructs
CPLEX to stop as soon as it has found a feasible integer
solution proved to be within three percent of optimal.
This tolerance is less than the error due to the
uncertainties of the predictions. There is no relaxation in
our resolution method since no approximation scheme
is used, so we always find a solution within 3% from the
optimal which is a global minima. It could be interesting
to compute a relaxation of the MIP and compare the
exact and the approximate resolutions, but the good
performance of our model in terms of computational
time makes the exact resolution compatible with the online application of our controller on a real DHS.

4.2 Implementation

CPLEX can easily and quickly solve numerous
problems with high combinatory owing to
parallelization and application of the branch and bound
method to reduce the search space (Brah, 1991). As a
result, the computational time is generally lower than
with other MILP solvers.

5

Results and Discussion

The simulation results obtained over the heating season
are presented and discussed in this section. The
numerical performance of the controller are also
described. The current limitations of the proposed
controller are finally presented at the end of this section.
For evaluation purposes, we compared the
performance of our advanced controller to a more
classical controller based on expert laws. This controller
is still a popular method used in many existing systems
owing to its simplicity and robustness. The standard
controller is based on the piling method for the
production planning. On the distribution side, the supply
temperature is determined using a static heating curve
while the differential pressure is maximized. To limit a
chattering effect on the on/off status of heat production
units, a hysteresis time-dependence is considered in the
determination of generators starts and stops.

Figure 7: Architecture of the PEGASE
optimal control framework

The overall algorithm is programmed using an in-house
optimal control framework named PEGASE. PEGASE
is based on the FBSF platform developed by the L3S
company (L3S, 2016). FBSF enables multi-models
simulation based on the FMI 2.0 co-simulation standard.
Figure 6 illustrates the architecture of the PEGASE
optimal control framework. The lower layer is the FBSF
simulation platform, which provides the basic services
for running multi-model simulations. The middle layer
is the optimal control layer, which performs the optimal
control algorithm presented in the previous sections.
The upper layer contains the dynamic simulation models
used by the optimal control layer, as well as other
prediction models and generic OPC connectivity
services.
For the application described in this paper, we use
only one dynamic simulation model, which consists of
the Modelica model of the distribution network. This
model is converted into a 2.0 co-simulation FMU by
DYMOLA 2017. For other applications, several
dynamic simulation models can be used together, either
in the form of FMU or with FBSF-specific C++ code.
Within the optimal control layer, we express the
MILP optimization problem using an in-house C++
code and solve it relying on CPLEX (IBM, 2009).
148

Figure 6: Normalized production costs over the
2013/2014 heating season for a standard (1) and an
optimal controller (2).

As displayed in Figure 7, results point that our
method significantly reduces production costs both with
and without the consideration of uncertainties. The
production costs decrease is explained in the following
section.
Table 1. Computational time and iterations for a 24 hours
predictive horizon.

Computational time
Mean
Max
37.8 s
273.7 s

Number of iterations
Mean
Max
3
29

On the production side, the optimal controller often
keeps several peak generators at minimal load to
anticipate future peak demands and avoid start-up costs
when the produced heat is low (particularly during
nights). As a consequence, the number of generator

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132141

Session 4D: Control Systems I

Figure 8: Snapshot of a dynamic simulation of the Grenoble DHS within the PEGASE
simulation framework.

startups over the season is significantly reduced between
the expert law control and the optimal controller.
On the distribution side, due to the optimization of
and
, results are very specific for the optimal
controller. On the one hand, the supply temperature is
often minimized and the differential pressure is
maximized. As a result, the heat losses are reduced and
the pumping work is increased for a global energy
consumption reduction. This is due to the low pumping
costs compared to the heat production costs encountered
in this case study. On the other hand, our optimal
controller is able to use the storage capacity of the
network to anticipate future peak demands thereby
increasing the use of base generators and avoiding the
use of additional and expensive heat generators. To
benefit from the network storage capacity, our control
strategy increases the supply temperature prior to a peak
demand. Accordingly, differential pressure is decreased
without impacting the supplied heat demand. As a
consequence of using the network storage capacity, the
number of generators startups is further decreased.
Table 1 presents the mean and maximal values of
computational costs and iterations for a 24 hour
predictive horizon. Using a 15 min time step, the
optimization problem contains 5430 variables including
2460 binary variables and 5530 constraints. The mean
and maximal computational time are respectively less
than 40 s and about 4 minutes. These figures are

DOI
10.3384/ecp17132141

compatible with the on-line application of our controller
on a real DHS.
The controller, as described in the present paper, is
currently restricted to DHS comprising one single
heating plant feeding a non-meshed network.
Application of the method to a multiple supply points
DHS and a meshed network is the subject of ongoing
work. Another point worth mentioning is that the
number of constraints of the MILP problem grows
linearly with respect to the number of consumers (see
inequality (15)). Thus, the application of the proposed
method to large-scale DHS impose to consider a set of
critical consumers in the network. As suggested in
(Nielsen, 2005), such consumers may be selected so that
if the (see inequality (15)) requirements for them
are satisfied then the requirements for all consumers are
satisfied. It has been verified that the current CPLEX
MILP solver could handle problems comprising a set of
several hundreds of critical consumers. This testing can
be considered positive with respect to the scalability of
the proposed controller.

6

Conclusions

In this paper, we present a new control method for DHS
management which simultaneously optimizes the
production and the distribution variables. For each
anticipation horizon, an optimized planning for the
status and power of each generator as well as for the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

149

Optimal Control of District Heating Systems using Dynamic Simulation and Mixed Integer Linear
Programming

supply temperature and the differential pressure is
proposed. Based on the heat demand prediction of each
consumer or group of consumers, our controller
determines autonomously the combination of supply
temperature and differential pressure necessary to
supply the heat demand. The method is based on an
algorithm minimizing the production costs and
respecting a family of constraints representing the
conservation laws and the physical limitations of the
generators and the distribution network. We consider
the nonlinearities of the distribution network thanks to
an iterative method between the dynamic network
simulation and the optimizer. Once implemented on a
DHS, this generic control strategy will autonomously
select the best compromise among the control variables
to minimize the production costs.
We also compared the proposed method to a more
classical controller based on expert law. The
comparison is based on the simulation over a heating
season of a virtual DHS representative of the Grenoble
case. Results show that our global optimization method
improves the seasonal production costs by more than 8
% compared to empirical methods. The proposed
controller decreases the production costs by taking
advantage of the network storage capacity. The use of
expensive peak heat generators is then minimized
whereas base heat generators operation is maximized.
The distribution network dynamic model used in the
present study was built by gathering components taken
from the Modelica DistrictHeating modelling library.
However, due to efficiency issues well described in
(Casella, 2015), such modelling approach is currently
not suitable for the representation of large-scale DHS
comprising thousands of consumers and encompassing
several hundreds of kilometers of distribution pipes. For
such systems, we developed a dedicated C++ simulation
code, not detailed in the present paper, and applied it to
the Grenoble DHS (see Figure 8). This last development
paved the way to the application and testing of our
optimal controller on the 400 MWth Grenoble DHS
during the 2016-2017 heating season.

Acknowledgements
The authors sincerely wish to thank Elise Le Goff,
Nicolas Giraud and Philippe Clolot from CCIAG, our
industrial partner in the project, for the many stimulating
exchanges and for providing real-life data from the
Grenoble network. We would also like to acknowledge
the financial support of CCIAG for the joint research
program and of ADEME for the PhD of Loc Giraud.

References
Akesson, J., Faber R., Laird C.D., Prolb K. Tummescheit H.,
Velut S., Zhu Y., Models of a post-combustion absorption
unit for simulation, optimization and non-linear model
predictive control schemes, Proc. 8th Modelica
Conference, Dresden, Germany, March 20-22, 2011

150

Brah S. A. and Hunsucker J. L., Branch and bound algorithm
for the flow shop with multiple processors, Eur. J. Oper.
Res., no. 51, pp. 8889, 1991.
Casella F., Simulation of Large-Scale Models in Modelica:
State of the Art and Future Perspectives, Proc. 11th
International Modelica Conf., Sept 21-23 2015, Versailles,
France
Donald C. Augustin, Mark S. Fineberg, Bruce B. Johnson,
Robert N. Linebarger, F. John Sansom, and Jon C. Strauss.
The SCi Continuous System Simulation Language (CSSL).
Simulation, No 9, pp. 281303, 1967.
Benonysson A., Bhm B., and Ravn H.F., Operational
optimization in a district heating, Energy Convers.
Manag., vol. 36, no. 5, pp. 297314, 1995
Eriksson H., Short Term Operation of District Heating
Systems: An Application of Mathematical Programming
Doctoral thesis, Chalmers University of Technology, 1994.
Fang T. and Lahdelma R., Genetic optimization of multiplant heat production in district heating networks, Appl.
Energy, vol. 159, pp. 610619, Dec. 2015.
Giraud L., Bavire R., Paulus C., Valle M., and Robin J.-F.,
Dynamic Modelling, Experimental Validation and
Simulation of a Virtual District Heating Network, Proc.
28th Int. Conf. on Efficiency, Cost, Optimization,
Simulation and Environmental Impact of Energy Systems
(ECOS), Pau, France, 2015.
Giraud L., Bavire R., Valle M., Paulus C. Presentation,
Validation and Application
of the DistrictHeating
Modelica library, Proc. 11th International Modelica Conf.,
Sept
21-23
2015,
Versailles,
France
doi
10.3384/ecp1511879
Giraud L., Modlisation Dynamique et Gestion Avance de
Rseaux de Chaleur, Doctoral Thesis, Universit Grenoble
Alpes, 2016.
IBM, Users Manual for CPLEX - IBM ILOG CPLEX v12.1.
International Busines Machines Corporation, 2009.
Lund H., Werner S., Wiltshire R., Svendsen S., Thorsen J. E.,
Hvelplund F., and Mathiesen B.V., 4th Generation District
Heating (4GDH), Energy, vol. 68, pp. 111, Apr. 2014.
Nielsen T. S. and Madsen H., Control of Supply Temperature
in District Heating Systems with Multiple Supply Points,
presented at the 18th Int. Conf. on Efficiency, cost,
Optimization, Simulation, and Environmental Impact of
Energy Systems (ECOS), Trondheim, Norway, 2005, vol.
2, pp. 10711079.
Runvik H., Larsson P.-O., Velut S., Funquist J., Bohlin M.,
Nilsson A., Modarrez Razavi S., Production Planning for
Dusributed District Heating Networks with JModelica.org,
Proc. 11th International Modelica Conf., Sept 21-23 2015,
Versailles, France doi 10.3384/ecp15118217
Sandou G., Modlisation, Optimisation et commande de
parcs de production multi-nergies complexes, Doctoral
thesis, Universit Paris XI Orsay, Paris, France, 2006.
SNCU, Enqute nationale sur les rseaux de chaleur et de
froid - Restitution des statistiques portant sur lanne 2011,
2013
https://www.l-3s.fr/, accessed in december 2016

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132141

Rapid development of an
aircraft cabin temperature regulation concept
Alexander Pollok1,2
1 Institute

Daniel Bender1

Ines Kerling1

Dirk Zimmer1

of System Dynamics and Control, DLR German Aerospace Center, Wessling, Germany,

{alexander.pollok,daniel.bender,ines.kerling,dirk.zimmer}@dlr.de
2 Dipartimento

di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy

Abstract
The air in aircraft cabins is controlled for pressure, temperature and humidity. The number of temperature zones
is generally kept low, for reasons of necessary ducting
space. We devise a new ducting concept, which enables
a large number of temperature zones. Controllability of
the system is however predicted to be a potential obstacle.
For a quick resolution of this question, a Modelica model
is created. Model creation is focused on a short development time as well as usefulness for controller synthesis. A
workflow is presented that enables a quick iteration time
between controller synthesis in Matlab and controller testing in a Modelica environment. Finally, the impact of this
new concept on the energy consumption of the air generation unit is discussed.
Keywords: Modelica, energy, exergy, control, modelling

1

Introduction

In modern passenger aircraft, temperature control is realized using a small number of temperature zones. For
instance, the Airbus A320 features two fixed-size temperature control zones for the cabin, plus one additional zone
for the flight deck. A typical cabin temperature regulation system is illustrated in Figure 1. Fresh air is delivered
by the air conditioning packs and ducted into the mixing
chamber (M). There it is mixed with filtered and recirculated air from the cabin underfloor volume. It is split up
into two mass flows. For each mass flow, very hot (around
200 Celcius) trim air is added to increase the temperature
to the desired value. The air is then ducted into the cabin
volume. Displaced air is ducted into the underfloor, where
some of it is recirculated, the remaining air is vented overboard.
Airlines like to customize their aircrafts with variations
in travel classes, seat configurations, and availability of
onboard entertainment systems. Generally, the demarcations of travel classes do not conform to the borders of
cabin temperature zones. Imagine an expensive and therefore sparsely populated first class, followed by the business class, densely packed with business people producing
hot air. This can lead to discrepancies with regard to the
heat load per cabin length, which cannot be compensated
by the control system, if they belong to the same temperaDOI
10.3384/ecp17132151

cabin
cargo compartment

recirc.

M
Pack 1

Pack 2

trim air

Figure 1. Conventional cabin temperature regulation system

ture zone.
Some ideas have been proposed to remedy this problem. In (Jacobs and De Gids, 2006) a concept is presented,
where each passenger receives his own air outlet and individual temperature zone. However, the resulting size of
the necessary ducting system within the crowded installation space of a modern aircraft is not considered. Similar
concepts are mentioned in (Gao and Niu, 2008) or (Zhang
et al., 2012), but the focus of the work is not on the control
or feasibility side, but on air contamination reduction.
We propose an alternative cabin temperature regulation
concept, which is illustrated in Figure 2. This concept is
based around two main ducts, each one spanning the complete cabin length. One of them ducts air at a relatively
cold temperature, the other one at a relatively hot temperature. At each cabin temperature zone, the air from both
pipes is locally mixed using a small actuator, then ducted
into the cabin.
This concept realises a variable number of temperature
control zones. For a large number of zones, the amount of
necessary ducting space and weight is lower than that of
a conventional architecture, as a simple spreadsheet calculation for a typical single aisle aircraft shows, see Figure 3. Main reason for this is that only 2 pipes of cabin
length L have to be fitted, instead of N pipes of average
length L/2. System weight and volume even goes down

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

151

Rapid development of an aircraft cabin temperature regulation concept

approach is needed for an early design evaluation. The
corresponding modeling environment must thus be able to
cabin
cover all relevant aspects of the proposed concept. Beside
the physical processes belonging to the pneumatic and
thermal domain, this also contains the control design and
of the temperature regulation system. Modelica is a wellcargo compartment
established choice for the physical modelling (Sielemann,
2012; Schlabe and Zimmer, 2012) but provides also sufficient to represent and evaluate the control models (Baur
et al., 2009; Bonvini and Leva, 2012). The control design
can then be achived in interaction with Matlab.
recirc.
The goal of this paper is to show how Modelica can be
used for accelerated feasibility studies using the example
of a new cabin temperature regulation concept. It is strucPack 1
Pack 2
tured as follows: Section 2 presents the design requirements for a suitable model as well as the taken approach.
Figure 2. Proposed cabin temperature regulation concept
Section 3 shows the controllability of the temperature regulation concept, based on the developed model. Section 4
for a larger number of temperature zones, as less distri- treats energy considerations of the proposed architecture.
bution ductwork between control valves and riser ducts is Interesting points that came up during the development of
needed.
the project are discussed in Section 5. Section 6 concludes
the paper.

H

ducting volume [m3 ]

34

32

conventional
proposed

2

28
26

Development time The time needed to plan, develop,
and test the model shall be short.

24

170
165
160
155
150
145
140
135
130
1252

Modelling

A good simulation model is the basis for all subsequent
development steps. The following requirements hold in
the context of this work (from most to least important):

30

222

ducting weight [kg]

C

4

6
8
10 12 14
number of temperature zones

16

conventional
proposed

Unity If possible, all requirements shall be met in a unified model. Having several versions of a model often
results in a significant increase in development time
as well as project complexity.
Linearity Small perturbations around the design point
shall result in linear model behavior. Model inputs
that are connected to saturating actuators shall be
scaled symetrically around zero.

16

Accuracy The simulation model shall include all major
physical effects. Deviations from reality should be
small enough to be irrelevant for the subsequent development steps.

Figure 3. comparison of total ducting weight and ducting volume for conventional and proposed concept

Robustness The model should predict accurate transient
responses for boundary conditions that are far from
the design conditions.

4

6
8
10 12 14
number of temperature zones

This is bought at the expense of a potentially much Simulation Speed Simulation of the model shall be fast.
more involved control system. Pneumatic and thermal
Numerical Stiffness shall be avoided if possible.
interactions between temperature zones may be strong
enough to prohibit the use of decentralized control. Also, Size Total size of the model shall be small. This includes
the energy offtake of such a concept compared to a conseveral metrics like the number of variables, number
ventional architecture is unclear.
of states and lines of code. A small model decreases
Given the high cost of testing facilities, a model-based
development time and increases comprehensibility.
152

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132151

Session 4D: Control Systems I

These requirements partially contradict each other.
Some balancing can be done using multi-objective optimization like shown in (Pollok and Bender, 2014), but ultimately, some arbitrariness remains. We decided to keep
the model as simple as possible, with the exception of two
physical effects that posed challenges for the control design: the first effect is the thermal interaction of air between the different cabin zones. The second effect is the
pneumatic interaction of air in the asymetric ducting system. The complete model structure is shown in Figure 4
and presented in the following.

sis and concept validation, this effect has to be modelled.
This was done using vectorized flow elements together
with customized connect-statements in a short amount of
code and development time. The implementation is shown
in Figure 5. Not shown are the parameters for the individual air resistance components. These are also dependent on the discretization parameter, since for example the
length per pipe is not constant.

Figure 5. ducting subsystem model

Figure 4. Top level view of temperature regulation model

Six subsystems were created for air conditioning packs,
mixing chambers, ducting system, cabin, heat sources and
recirculation system. These subsystems were in turn composed from simple components like flow resistances or
volume elements. The model structure was limited to
those three layers of system, subsystem and components.
Inheritance was avoided, based on the results as described
in (Pollok and Klckner, 2016). The Modelica Standard
Library (Modelica-Association, 2008) was used as much
as possible to save additional modelling time.
All subsystems included an integer parameter n, denoting the number of discretized volume elements in the
cabin. In this way, the scalability of the concept can be
tested later without additional modelling effort.
Of those subsystems, ducting and cabin are especially
interesting from a modelling perspective:

2.2

Cabin

The flow configuration inside the aircraft cabin is complex
and can only accurately be determined by experiments or
CFD-calculations. However, for the evaluation of the presented concept, a low-order approximation suffices. The
cabin is divided lengthwise into n volume elements. These
elements are directly connected to enforce pressure equalization. Fluid volume elements can directly be connected
in Modelica, at the cost of nonlinear systems of equations.
This cost is however preferable to the alternative, where
the very small flow resistances between cabin volumes
leads to a very stiff simulation model. If no equalization
mass flows occur, there is still some amount of thermal
equalization caused by diffusion. This is modelled using
thermal resistance elements, coupled between the volume
elements. They were parameterized according to empirical experience.
2.1 Ducting
Again, the subsystem was realized using a combinaAs illustrated in Figure 2, air is ducted from the mixing
tion of vectorized elements and customized connect statechambers into the cabin via a network of ducts. This
ments. The implementation is shown in Figure 6.
network is asymetrical and interactive with regard to the
cabin temperature zones. If a large amount of cold air
3 Control
is needed for the center temperature zones, the effective
hydraulic resistance from the cold mixing chamber to the A sufficient way to demonstrate controllability of a system
outer temperature zones increases. For controller synthe- is to find a stabilizing controller. For a demonstration of
DOI
10.3384/ecp17132151

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

153

Rapid development of an aircraft cabin temperature regulation concept

Figure 6. cabin subsystem model

was simulated for 1000s to come close to the steady state
solution. Keep in mind that all model inputs are set to zero
at linearization. Therefore, the valid range for all model
inputs has to include zero and some buffer in both directions. This can be a problem for instance when a model
input is connected to a valve opening with a valid range of
0 to 1. In this work, we scaled all such inputs to a valid
range of -1 to +1. All other in- and outputs were scaled
according to typical orders of magnitude. The linearized
system was exported as a .mat-file using the writeMatrixcommand.
Computation of the LQG controller was done in Matlab, based on the script as described in (Skogestad and
Postlethwaite, 2007, p. 348). This formulation adds integrators to the plant outputs, ensuring zero steady state
error for the controlled system. The model was reduced
from 32 to 23 states, based on the results of the Hankel singular value decomposition as presented in Figure 8. Also,
the 1-dof1 variant was used, since setpoint changes are not
a major concern in climate control systems.

robust performance, the response of the controlled system
with regard to noise and nonlinearities can be shown.
We used linear quadratic Gaussian (LQG) control to
find an optimal controller for the problem. The method is
simple and often satisfactory in the development of multivariate, or MIMO-controllers for linear time-invariant
(LTI)-systems. LQG controllers consist of a linear
quadratic estimator (LQE, also known as Kalman filter) to
estimate non-measured states, and a linear quadratic regulator (LQR), essentially an optimal state regulator. The
regulator uses the estimated states to compute a control
signal, the estimator uses the measured states as well as
the control signal to estimate the states. This is illustrated
in Figure 7. Both components can be designed independently, this will not compromise stability of the controlled
system, but it can affect stability margins (for reference,
see the very interesting abstract of Doyle (1972)), so robustness properties have to be verified after controller synthesis.
Figure 8. Hankel singular value decomposition of temperature
control system
target

controller
(LQR)

estimated
plant states

control
signal

measurephysical system ments

(plant)

estimator
(LQE)

Figure 7. Structure of an LQG regulator

A Matlab-script was developed to automatically generate Modelica-code of the controller. This script is shown
in Listings 1 and 2. In this way, a candidate controller can
be tested in a Modelica environment in a few seconds.
Listing 2. Matlab code for the generation of Modelica controller
code
function [ ] = fun_changeMatrixFormat( M )
% Changes the Matrix to a format like
% it is needed for an Matlab- Input
% f.e. M = 1 0

For LQG-synthesis, a linearized model is necessary. We
used the linear systems library as presented in (Baur et al.,
2009) as implemented in Dymola 2016 to linearize the
1 In a 1-dof (one degree of freedom controller, setpoint changes and
model around the steady state. The model was instanti- disturbances
are handled equally. In a 2-dof controller, setpoint changes
ated with a pack temperature spread of 20Kelvins and 10 can be handled far more aggressively, as the setpoint is not part of the
cabin temperature zones. Before linearization, the model feedback-loop and therefore has no impact on system stability.
154

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132151

Session 4D: Control Systems I

Listing 1. Matlab code for the generation of Modelica controller code
function [] = fun_dymola( sys )
%input: statespace object sys, representing combined estimator and controller
sys_x = size(sys.a,1);
% = m_A, n_A, m_B, n_C
sys_y = size(sys.d,1);
% = m_C, m_D
sys_u = size(sys.d,2);
% = n_B, n_D
% declarations
fprintf('\n\nmodel Controller "1-DOF LQG controller"\n\n');
fprintf('// import \n');
fprintf('import Modelica.Blocks; \n\n');
fprintf('// parameters \n'); %A,B,C,D...
fprintf('parameter Real A_controller[%.0f, %.0f] = ', sys_x,
fun_changeMatrixFormat( sys.a );
fprintf('; \n');
fprintf('parameter Real B_controller[%.0f, %.0f] = ', sys_x,
fun_changeMatrixFormat( sys.b );
fprintf('; \n');
fprintf('parameter Real C_controller[%.0f, %.0f] = ', sys_y,
fun_changeMatrixFormat( sys.c );
fprintf('; \n');
fprintf('parameter Real D_controller[%.0f, %.0f] = ', sys_y,
fun_changeMatrixFormat( sys.d );
fprintf('; \n');

%Name ""

sys_x);

sys_u);

sys_x);

sys_u);

% variables
fprintf('// variables \n');
% blocks
fprintf('Blocks.Continuous.StateSpace statespace_controller');
fprintf('(A = A_controller, B = B_controller, C = C_controller, D = D_controller) \n');
fprintf('annotation (Placement(transformation(extent={{36,-2},\n{56,18}})));\n');
fprintf('Blocks.Math.Feedback sum_controller [%0.i] \n', sys_u);
fprintf('annotation (Placement(transformation(extent={{-36,-2},\n{-16,18}})));\n')
% inputs/outputs
fprintf('Blocks.Interfaces.RealInput command[%0.f] "command signal" \n',sys_u);
fprintf('annotation (Placement(transformation(extent={{-120,40},{-80,80}})));\n');
fprintf('Blocks.Interfaces.RealInput feedbacksignal[%0.f] "sensor/feedback signal" \n',sys_u);
fprintf('annotation (Placement(transformation(extent={{-120,-78},{-80,-38}})));\n');
fprintf('Blocks.Interfaces.RealOutput outputsignal[%0.f] "driver/output signal" \n', sys_y);
fprintf('annotation (Placement(transformation(extent={{100,-10},{120,10}})));\n\n');
% equations
fprintf('// equations \n');
fprintf('equation \n');
% connecting the blocks and in/outputs
fprintf('for i in 1:%.0i loop\n', sys_y);
fprintf('connect(statespace_controller.y[i], outputsignal[i]) \n');
fprintf('annotation (Line(\npoints={{57,8},{110,8}},\ncolor={0,0,127}));\n');
fprintf('end for; \n\n');
fprintf('for i in 1:%.0i loop\n', sys_u);
fprintf('connect(statespace_controller.u[i], sum_controller[i].y) \n');
fprintf('annotation (Line(\npoints={{34,8},{-17,8}},\ncolor={0,0,127}));\n');
fprintf('connect(command[i], sum_controller[i].u1) \n');
fprintf('annotation (Line(\npoints={{-100,52},{-64,52},{-64,8},{-34,8}},\ncolor={0,0,127}));\n'
);
fprintf('connect(feedbacksignal[i], sum_controller[i].u2) \n');
fprintf('annotation (Line(\npoints={{-100,-58},{-26,-58},{-26,0}},\ncolor={0,0,127}));\n');
fprintf('end for; \n\n');
% creating symbol for the block
fprintf('annotation (...)');
fprintf('end Controller; \n'); % Name;

DOI
10.3384/ecp17132151

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

155

Rapid development of an aircraft cabin temperature regulation concept

%
0 1 to [1, 0; 0, 1]
% for as much information as possible
format long;
mnbigness = size(M);
countm = 1;
countn = 1;
fprintf('[');
while (countm <= mnbigness(1))
while(countn <= mnbigness(2))
if (countn < mnbigness(2))
fprintf('%f, ', M(countm, countn
));
else
if (countm < mnbigness(1))
fprintf('%f; ', M(countm,
countn));
else
fprintf('%f', M(countm,
countn));
end
end
countn = countn+1;
end
countn = 1;
countm = countm+1;
end
fprintf(']');
end

On the first try, equal disturbance and measurement
noise was assumed, and a unity matrix was used for the
input weight matrix R. The state weight matrix Q was calculated so that the projected plant output as well as the
artificial integrator vector were also weighted with a unity
matrix, using the Matlab code shown in Listing 3.
Listing 3. Matlab code for projection of the plant outputs to the
state vector
R=weight_input*eye(n_u);
Q=blkdiag(weight_output.*transpose(C)*
eye(n_y)*C,weight_integrator*eye(n_y));

Since the actual system contains hard nonlinearities
such as actuator saturation, compliance to those limits
has to be tested using simulations of the controlled system. These simulations showed that the resulting controller outputs were exceeding the actuator limits. The
variable weight-output was increased to 10.000, resulting
in improved behavior2 . Note that no actual optimization
with regard to some performance criterion took place. The
response of the controlled system to target temperature
steps (from 20 to 21 Celcius) on each temperature zone is
shown in Figure 9. Overshoot3 is generally low, but temperatures are still somewhat affected by temperature steps
on neighboring zones. Rise time is at 68 to 102 seconds
(M4 : 85s, SD: 11.3s).
Robustness with regard to sensor noise was validated
using the Noise library as presented by Klckner et al.
2 Using LQR/LQG, it is quite typical that small changes in controller
behavior necessitate large changes in the weighting matrices.
3 Overshoot describes the peak of the response to a step input, rise
time describes the time it takes the output to increase from 0.1 to 0.9.
4 M denotes the mean value, SD denotes the standard deviation.

156

(2014). The qualitative behavior of the system remains
unchanged. An illustration of the overall workflow can be
seen in Figure 10.

4

Efficiency

The concept presented within this work requires a cold (C)
and a hot (H) air reservoir (see Figure 2). Each of these
reservoirs is supplied by a separate air conditioning pack.
Conventional architectures duct the cooled air from the air
packs to a common mixer unit (see Figure 1. The packs
therefore condition the fresh bleed air to the same pressure and temperature. The proposed concept now claims
an asymmetrical air conditioning in terms of temperature.
The air pack would then run in different conditions compared to conventional in-service air packs. About 2-3% of
the whole energy consumption of a conventional civil aircraft applies to the ECS (Bender, 2016). Thus an energy
analysis of the deviating pack operation is necessary.

4.1

System Description

The key part of the ECS is the air generation unit (also
called the pack). The pack conditions the air flow in terms
of temperature, pressure and humidity. Usually there are
two packs installed in an aircraft. Conventional systems
use engine bleed air as the power source. The bleed air is
drawn off from the compressor stages upstream the combustion chamber. Provided at high temperature (around
220 C) and high pressure (around 2.5bar), the air must be
conditioned before it is distributed into the cabin. First the
air flow is lead to the air pack where it is cooled down and
dehumidified. It passes several heat exchangers, a compressor, a turbine and valves before the flow has reached
the right condition to be lead to the mixing unit. The ram
air enters the pack from the ambient and passes a water
injector, two heat exchangers and a fan. All of them are
installed in the ram air channel. The ram air is used as a
heat sink.
Figure 11 illustrates the Modelica diagram layer
schematic of the air generation unit that is used for the
energy analysis in this work. It includes a conventional
three-wheel bootstrap-cycle, driven by bleed-air. Three
different flows are considered: The bleed air arises from
the compressor stage at the engine, passing at first the
pneumatic distribution device before it enters the ozone
converter. Inside the primary heat exchanger (PHX) the
hot air is cooled down against the ram air flow. Before entering the compressor stage (CMP), a part of the air flow
is separated and bypassed through the temperature control valve (TCV). Downstream the compressor stage the
heated and compressed air is cooled down a second time
inside the main heat exchanger (MHX) against the cold
ram air flow. Here the most intense heat exchange takes
place due to large temperature differences. The air flow
now enters the hot side of the reheater and is cooled down
again before its temperature is further decreased inside the
condenser in order to dehumidify the air flow and prevent
downstream conditions from reaching the saturation point.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132151

Session 4D: Control Systems I

Figure 9. Response of controlled system to target temperature steps

Modelica
environment

Computation
environment

Create
System Model
Linearize
Model
Export as
.mat-File

Controller
Synthesis

Controller
Validation

Modelica Code
Generation

Figure 10. Workflow for controller synthesis

Figure 11. Diagram layer of air pack system model with three
wheel bootstrap cycle

This configuration of the three wheel bootstrap cycle uses
the concept of high pressure water separation. In case of
condensation, the free water is separated in the water extractor and carried to the injector located at the beginning
of the ram air channel. The dehumidified air flow now
passes the reheater a second time, this time at the cold

side where it is reheated against its upstream air flow. Inside the turbine the air is expanded to a sufficient pressure level. Concurrently the temperature decreases significantly below ambient conditions. At this point the air
reaches its coldest condition. Meeting the separated air
from the temperature control valve, the flow gains a higher

DOI
10.3384/ecp17132151

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

157

Rapid development of an aircraft cabin temperature regulation concept

temperature und finally is heated up inside the condenser
again before it leaves the air pack to the mixing unit.
The second flow occurring is the ram air flow. It functions as a heat sink and enters the aircraft through inlets
outside the aircrafts fuselage. The amount of air flow can
be controlled by flaps installed at the inlet and outlet of
the ram air channel. Water from the water extractor is now
injected into the ram air flow where it evaporates and subsequently the temperature of the ram air flow is decreased.
The cool air passes successively the main heat exchanger
and primary heat exchanger before it leaves the ram air
channel to the ambient. In ground operation the ram air
flow is driven by the ram air fan that is mounted on the
same shaft as the compressor and turbine. The components shown in Figure 11 are taken from an ECS library
(Sielemann et al., 2007).
Figure 12. Drag caused by Ram air vs. average temperature and

4.2

temperature anomaly

Energy analysis

The proposed cabin temperature regulation concept is
based on asymmetrical pack discharge temperatures for
each pack. Therefore the energy analysis was performed
for a wider range of discharge temperatures. Two identical
air packs were assumed so that simulations were carried
out using the air pack Modelica model shown in Figure 11
for a range of discharge temperatures varying from -30 C
to 20 C. The mass flow and the discharge pressure were
kept constant. Two control laws are implemented in the
model. One that keeps the discharge temperature at the
defined value by regulating the bypass mass flow through
the TCV and another law that limits the compressor outlet
temperature by regulating the ram air mass flow.
The three wheel bootstrap cycle is a self-containing air
generation unit, i.e. it does not need any additional power
source to run the turbo components. This is realized by the
turbine that is driven by pneumatic power of the bleed air.
It is assumed that the bleed air is constantly provided by
the engine, independent of the operation of the air pack.
However, the ram air flow changes due to different operating points and causes different amounts of aerodynamic
drag. It is therefore directly linked to the pack discharge
temperature. For the energy analysis, the variation of occurring drag caused by the ram air is calculated for each
operating point. The drag of both air packs is summed
up and displayed with the average temperature of both
packs and their anomaly in temperature. Temp average
denotes the average discharge temperature of both packs,
Temp anomaly denotes the deviation of both packs from
the common average. For example, if one pack discharges
air at 10 C while the other discharges air at 20 C, temp
average is 15 C, and temp anomaly is  5 C.
Figure 12 shows the result of the simulations for the
different discharge temperatures. The model was simulated for a cruise flight phase at 39.000 feet altitude. The
horizontal axis shows the average temperature that can be
achieved of the two packs. All possible combinations for a
temperature range from -20 C to 30 C were considered.
For each combination, the temperature anomaly to the av158

erage temperature was determined and presented by the
vertical axe. The graphic shows a triangular shape what is
related to the fact that e.g. an average temperature of -10
C could be achieved by a maximum range of 0 C and
-20 C what leads to an anomaly of 10 K. The coloring
represents the total drag of both packs and the black lines
represent lines of constant drag. Due to confidential reasons, the values are normalized to an average drag value.
The results show that the drag for the border regions of
high and low average temperature remains constant with
increasing anomaly. However, for the medium temperature range, the lines of equal drag tip to the left with increasing anomaly. That means, the combined drag of both
packs is slightly higher for packs operating with large temperature differences.

5

Discussion

The resulting concept with its workflow depicted in Figure 10 proved to be effective for the analysis and optimization of a nonlinear MIMO control problem with a complex
plant model. Yet, the concept of this paper for the temperature regulation of aircraft cabin represents only one item
of a more general problem set. In this case, the control
design was an integral part needed to evaluate the overall
system design in an early phase. A rapid LQG controller
provided a sufficient solution. Interfaces to and from Matlab eased the control design whereas Modelica served as
main modeling and evaluation environment.
The long-term goal of this work however goes beyond
this use case. Since many sub-systems are already highly
optimized, further system optimization requires a higher
level of sub-system integration and also more centralized
control approach. This represents a higher level of integration and it often implies a low availability of corresponding test examples or rigs. Principal questions of controllability, performance of controllers and of the system as a
whole need to be evaluated at an early design phase.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132151

Session 4D: Control Systems I

To this end, it is necessary to bring together the different software platforms that engineers use for control design (such as Matlab) and the modeling environments for
system dynamics (such as Modelica). This is not the first
paper addressing this problem. Typical attempts use the
S-function standard to import the plant model to Matlab.
Alternative approaches use the FMI-Standard to export the
controller from Matlab to a Modelica environment. The
presented work shows that code generation is also a feasible technique to achieve the desired result. It has the
advantage that the final result is pure Modelica and does
not require any further tools or interfaces.
Having the final result in pure Modelica is more suited
when many variations of the plant model shall be created
in order to test for various kinds of robustness. These
changes may go beyond normal parameter changes since a
variety of failure scenarios have to be modelled and simulated. In this application, typical faults are the malfunction
of one pack and the malfunction of one or more valves in
the ducting. Also the controller might be tested against
Modelica models of higher fidelity. For all this work, having the controller in Modelica with all the internal controller signals openly available is the most convenient approach.
The aforementioned robustness tests still have to be performed to a large extent. These will hopefully not only further validate the temperature regulation concept but also
the foreseen work-flow.

6

Conclusion

John Doyle. Guaranteed margins for lqg regulators. 1972.
Hilding Elmqvist, Toivo Henningsson, and Martin Otter. Systems modeling and programming in a unified environment
based on julia. In International Symposium on Leveraging
Applications of Formal Methods, pages 198217. Springer,
2016.
NP Gao and JL Niu. Personalized ventilation for commercial
aircraft cabins. Journal of aircraft, 45(2):508512, 2008.
P Jacobs and WF De Gids. Individual and collective climate
control in aircraft cabins. International journal of vehicle design, 42(1-2):5766, 2006.
Andreas Klckner, Franciscus LJ van der Linden, and Dirk Zimmer. Noise generation for continuous system simulation. In
Proceedings of the 10th International Modelica ConferenceLund, Sweden-Mar 10-12, 2014, number 96, pages 837846.
Linkping University Electronic Press, 2014.
Modelica-Association. The Modelica Standard Library. Online,
URL: http://www.modelica.org/libraries/Modelica, 2008.
Alexander Pollok and Daniel Bender. Using multi-objective
optimization to balance system-level model complexity. In
Proceedings of the 6th International Workshop on EquationBased Object-Oriented Modeling Languages and Tools,
pages 6978. ACM, 2014.
Alexander Pollok and Andreas Klckner. The use of ockhams
razor in object-oriented modeling. In Proceedings of the 7th
International Workshop on Equation-Based Object-Oriented
Modeling Languages and Tools, pages 3138. ACM, 2016.

Modelica can be used to quickly generate models for val- Daniel Schlabe and Dirk Zimmer. Model-based energy management functions for aircraft electrical systems. Technical
idation studies of new concepts. However, the design of
report, SAE Technical Paper, 2012.
controllers based on this models makes additional tools
necessary. Integrated modelling and computation environ- Michael Sielemann. Device-Oriented Modeling and Simulation
ments such as Modia (Elmqvist et al., 2016) could be a
in Aircraft Energy Systems Design. PhD thesis, Hamburg
remedy.
University of Technology, 2012.

Acknowledgements
We thank Trey and Matt for inspiration.

References
Marcus Baur, Martin Otter, and Bernhard Thiele. Modelica
libraries for linear control systems. In Proceedings of 7th
International Modelica Conference, Como, Italy, September,
pages 2022, 2009.
Daniel Bender. Exergy-based analysis of aircraft environmental control systems - integration into model- based design
and potential for aircraft system evaluation. In ECOS 2016
- 29th International Conference on Efficiency, Cost, Optimisation, Simulation and Environmental Impact of Energy Systems, 2016.

Michael Sielemann, T Giese, B hler, and Martin Otter. A flexible toolkit for the design of environmental control system
architectures. In Proceedings of the First CEAS European
Air and Space Conference, 2007.
Sigurd Skogestad and Ian Postlethwaite. Multivariable feedback
control: analysis and design, volume 2. Wiley New York,
2007.
Tengfei Tim Zhang, Penghui Li, and Shugang Wang. A personal air distribution system with air terminals embedded in
chair armrests on commercial airplanes. Building and Environment, 47:8999, 2012.

Marco Bonvini and Alberto Leva. A modelica library for industrial control systems. In Proceedings of the 9th International MODELICA Conference; September 3-5; 2012; Munich; Germany, number 076, pages 477484. Linkping University Electronic Press, 2012.

DOI
10.3384/ecp17132151

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

159

160

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Investigation of the Influence of Controller Types on Room
Thermal Behaviour  A Simulation Study
Kristin Majetta1, Christoph Clau1, Christoph Nytsch-Geusen2
1

Fraunhofer IIS EAS, Zeunerstrae 38, D-01069 Dresden, GERMANY
kristin.majetta@eas.iis.fraunhofer.de
christoph@clauss-it.com
2
Fachgebiet fr Versorgungsplanung und Versorgungstechnik, Berlin University of the Arts, Hardenbergstr. 33,
D-10623 Berlin, GERMANY
nytsch@udk-berlin.de

Abstract
To control the indoor temperature of rooms two kinds of
approaches are common. The first one is to use standard
PI-controllers with a set of default parameters, which
often leads to insufficient performance, waste of energy
and unacceptable comfort violations [Rahmati, 2003].
The other approach is to use specifically developed and
adapted controllers [Seidel et al., 2015], which have the
drawback in a time-consuming and expensive
development. Therefore, this paper investigates on
finding rules and guidelines to find a suitable controller
for a given room without the need of expensive
controller adaption via simulation. To provide those
rules a simulation study will be performed. This paper
presents the first preparatory steps of this investigation,
which includes the choice and development of four
different room models equipped with different heating
systems, which are an electrical radiator, a floor heating
system, and a water supplied radiator. The authors
present five types of controller models of different
controller types to control the operative temperature of
a room. Simulations of well-defined scenarios analyze
the eligibility of the controller models regarding net
energy consumption and comfort for the considered
room models. First optimization results to improve the
quality of the controllers are shown and further steps are
explained.
Keywords: Building Simulation, Room Controller,
Room Thermal Behavior, Optimization

1

Introduction

The German government plans the reduction of the
primary energy consumption by 20% by the year 2020
compared to 2008 and, even more ambitious, by 50% by
2050. Many actions are taken to achieve this goal. One
is the foundation and support of research projects to
develop energy saving technologies. In the buildings
sector one of these technologies are advanced control
strategies to regulate e.g. indoor climate, energy
consumption or the choice of an energy source out of
different energy supplies. Normally, those controller
strategies are developed and adapted to a specific room
for which they work efficiently. Often those controllers
can only be sufficiently adapted to other buildings under
DOI
10.3384/ecp17132161

application of relatively large simulation effort which
includes the model development and parameterization
of the considered room, the comparison of the room
behavior with measurements and the parameterization
as well as an optimization of the controller model.
Therefore, the adaption to other rooms or buildings is
expensive and often the energy reduction is in no
relation to the effort of adjusting the controller. This is
why nowadays often basic controllers with default
parameters are used which is not sufficient to achieve
the control goals regarding room temperature and net
energy consumption. During the last years research in
the field of indoor room temperature controllers, several
example control algorithms have been developed. In
[Lauenburg, 2014] for example, the control of a radiator
heating system is optimized. A similar approach is
presented in [Carlon, 2014] where the energetic
performance of a low-energy house in analyzed and two
possible control strategies of the biomass boiler heating
systems are investigated. Very high research effort
during the last years was done in the field of model
predictive control methods where the future behavior of
the room is predicted by simulating and optimizing a
room model to calculate the in the future needed set
points to ensure comfort and energy optimality.
Deputizing for the abundance of research activities and
literature in this field the following references are
named: [Afram, 2014; Parisio, 2013; Oldewurtel, 2010;
Ma, 2009]. A drawback of this method is that the needed
prediction model must be developed which is normally
done from measurements, and that this model needs to
be updated after each optimization run. Rules would be
helpful that support the choice of indoor room
temperature controllers including a suitable set of
parameters that fit best for the considered room.
Therefore, a methodology is needed which provides
those rules and guidelines for typical use cases of
temperature controllers with regard to given rooms and
their installed HVAC technology. This paper presents
first steps of this investigation, which is the
development of four different, representative room
models as well as five controller models of important
controller types. By means of simulations of defined
scenarios suitable for each type of room (e.g. office
room, class room), the eligibility of the controller

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

1

161

Investigation of the Influence of Controller Approaches on Room Thermal Behaviour A Simulation Study

models is investigated regarding the net energy
consumption and the adherence by temperature comfort
boundaries. First optimization results to improve the
quality of the controllers are shown and further
necessary steps are explained.

2
2.1

Modeling
Building models

To investigate the influence of different controller
models on room behavior, four room models were built,
that differ in size, building materials, heating system and
usage. The chosen rooms are an office room, a class
room a meeting room and a summerhouse (also called
room since it consists of a single thermal zone). All
models are equipped with different heating systems
(electrical radiator, radiator flown through by water,
floor heating) so that the typically range of room heating
supply techniques is covered. That way it is assured that
the methodology, which will be developed for choosing
a suitable controller, is universally applicable and can
easily be transferred to other problems.
The models of the four example rooms are built from
model components of the Modelica BuildingSystems
library, which is developed by the University of Arts
(UdK), Berlin [Nytsch-Geusen, 2013]. This library can
describe the behavior of complex building systems
which consist of thermal and hygrothermal models of
single buildings or districts in combination with the
corresponding energetic supply techniques. The
technical building services can contain thermal,
hydraulic or electrical models for solar heat,
photovoltaic, and HVAC systems. The room models
developed for the purpose of this investigation are based
on the Building1Zone1DBox-template that describes a
single thermal zone with six opaque boundaries that can
contain windows. The template is equipped with
connectors compatible to the ambient model of the
BuildingSystems library, with thermal ports to supply
the building zone with heat and with a connector for the
air change rate. The air temperature TAir of the zone is
supplied by the model via an output connector. Figure 1
shows the graphical representation of the
Building1Zone1DBox template connected to the
ambient model.

Figure 1: Template Building1Zone1D connected to
ambient model

162

The ambient model provides the outside air temperature,
the relative humidity of the ambient air, the wind speed
and the solar radiation. The influence of the solar
radiation on the operative room temperature depends
mainly on the orientation of the windows, which are
modelled within the Building1Zone1DBox template.
To assure the comparability of results, all room models
receive the same ambient conditions from the TMY
(typical meteorological year) [Deutscher Wetterdienst,
2014] of Chemnitz, a city in the east of Germany with
approximately 250.000 inhabitants. For the sake of
simplicity internal loads are not part of this study.
Summerhouse
The model of the summerhouse has a floor space of 30
m, a height of 3.5 m and, deviating from Figure 2, it is
modeled with six boundaries, which represent four
walls, the ceiling and the floor.

Figure 2: 3D representation of the summerhouse model

The summerhouse is modeled as a free-standing room,
which means that the adjacent conditions of the
boundaries (except for the floor) of the thermal zone are
the ambient conditions. The adjacent boundaries are
modeled as heavy construction from plastering,
Styrofoam and bricks from concrete. The summerhouse
model is equipped with a model of a 2kW electrical
heating system. The actuating mechanism of the heating
system is discrete which means it can either be switched
on or off completely. Therefore, the control signal
provided by the heating controller must also be discrete.
Single office room
The model of the office room is suitable for one person.
It has a floor space of 15 m and a height of 2.7 m. It is
enclosed by six boundaries of which the west oriented
boundary adjacent conditions are the ambient
conditions. The other boundaries border on neighbour
rooms and have constant adjacent temperatures of 20
C. The west oriented boundary is modeled as heavy
construction. The other materials are wood for the
ceiling two boundaries (walls) that border on neighbour
rooms and concrete for the wall that separated the office
room from the floor. Figure 3 shows a picture of the
office room that was used as a basis to develop the room
model.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

2

DOI
10.3384/ecp17132161

Session 4D: Control Systems I

Figure 3. Picture of the office room on which the model
is based

The office room model is equipped with a floor heating
system that works with a supply temperature of 35 C.
The model of the heating system calculates a heating
power  using (1). In (1)  is the temperature of the
floor surface,  is the room temperature and  is the
floor area (Recknagel, 2012).  is calculated from the
supply temperature which is given to the heating system
as input signal.
 = 8.92  (   )1.1  
(1)
The heating power  is given to the room as input
signal. The heating model has an input connector for its
control signal. The required control signal must be
Boolean. In case of control signal = true the heating
system provides a heating signal of a certain amount of
heat to the room model. If control signal = false the
amount of heat provided by the heating system is zero.
Meeting room
The model of the meeting room is based on a small
conference room at Fraunhofer IIS/EAS. It is designed
for meetings and workshops for about 20 people (Figure
4).

from clinker bricks and plastering. The ceiling and the
floor are modeled from lightweight concrete. Also an
interior ceiling is included which is made of papiermch. The room model is equipped with a water
heating systems (Figure 5) that gives radiation and
convective heat via a radiator to the room model. The
model of the water heating system, which is taken from
the BuildingSystems library, is modelled as fluidic
system. It contains a pump, pipes, a valve to regulate the
volume flow, a radiator, an expansion vessel as well as
a boiler. To regulate the volume flow of the water
running through the radiator model, the valve model is
controlled by its actuator position according to the valve
characteristic, which specifies the volume flow rate
depending on the valve position. Accordingly, the
control signal calculated by a controller has to take
values between 0 and 1.

Figure 5. Water heating system

Classroom
The classroom model is based on data of the plus-energy
primary school in Hohen Neuendorf near Berlin which
was built as part of the research program
Energieoptimiertes Bauen (EnOB) founded by the
German Federal Ministry of Economic Affairs and
Energy [Sick, 2015]. Figure 6 shows a picture of one
classroom of the school, that was the basis for the
classroom model.
The model has a floor space of 94 m and a height of
4 m. It contains one outer wall thats boundary
conditions are the ambient conditions.

Figure 4. Picture of the meeting room on which the
model is based

The room model has a floor space of 52 m and a
height of 3.3 m. it has one outer wall, the west oriented
wall, at which ambient conditions are applied. The
boundary temperature of the opposite wall and the
ceiling is constant 18 C, and for the other walls, it is 20
C. The four walls are modeled as heavy construction

DOI
10.3384/ecp17132161

Figure 6. Picture of the classroom on which the model is
based

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

3

163

Investigation of the Influence of Controller Approaches on Room Thermal Behaviour A Simulation Study

It is modeled as lightweight construction from wood,
mineral wool and plasterboard. The inner walls are also
lightweight and modeled from the materials wood and
mineral wool. The floor consists of concrete, cement,
bitumen, ethafoam and linoleum. The ceiling is modeled
from concrete, cement and linoleum. The boundary
temperatures of the inner walls are constant at 17 C.
The water based heating system is the same as described
for the meeting room model.

of the office room model under constant ambient and
neighbour room temperatures.

2.2 Controller models
On the way of developing the methodology for choosing
a suitable controller for a given room, the
conformability of different controller models to the four
introduced room models is investigated. Therefore, five
common control strategies were chosen and modeled in
Modelica. Partly they were developed in research
projects at Fraunhofer IIS/EAS, partly they are taken
from the Modelica Standard Library. The choice of the
controller models can easily be extended. For example,
the application of a model predictive controller is
planned.
Two-Point Controller
The model of the two-point controller compares the
actual room temperature with a required set point
temperature. It provides a heating signal of 1 if the room
temperature is below the set point temperature, which
means the heating system should be turned on. The
controller provides a heating signal of 0 if the room
temperature is above the set point temperature. A
hysteresis parameter prevents the controller from
switching on and off permanently. This parameter
influences the span between the given temperature set
point and the actual temperature for turning the heating
system on or off. Therefore, the height of the hysteresis
influences the user comfort and the effective heating
energy.
Forward-looking Switching (FS)
The aim of this controller is to determine the right
moment to turn the heating system of a room model on
and off to reach a desired target temperature at a specific
point in time [Majetta, 2015]. Under the assumption of
a given ambient temperature  (), a given supply
temperature of a water heated heating system,
respectively heating power in case of an electrical
heating system  (), given temperatures of the
adjacent rooms  () and a given start value of the room
temperature  ( = 0), the idea of this controller is to
approximate the room temperature  () by the
response of a first order system () to a step change as
first approximation. This is easily possible because the
heating and cooling characteristics of single rooms are
known neglecting disturbances and providing it with
constant power. Figure 7 shows exemplarily the heating

164

Figure 7. Heating up process of office room model

() is characterized by its steady-state value , its start
value  and its slope of the temperature change ( =
0) at time  = 0 and can be described by (2).




() =   (  ) 
(2)
The variables  and  depend on  (),  ( = 0),
 () and  (). Internal loads are not considered. For
simplicity reasons the temperatures of the neighbour
rooms are chosen to be identical. The variables  and 
are identified using results from particular simulations
with defined constant values of  (),  ( = 0),  (),
and  (). In the following, the identification process of
 is shown exemplarily. To identify the dependency of
the steady-state value  from  (),  () and  (), the
linear approach
 =   1 +   2 +   3

(3)

was chosen. To identify the unknowns (1 , 2 , 3) in
(3), n simulations under defined conditions were
undertaken and the linear system
 = 

(4)

with
,1
=[ 
,

,1

,

1
,1
 ] and  = [  ]

,

is solved applying the least squares method [Isermann,
1991]. To do so, a solution   shall be calculated that
minimizes the quadratic error  = |   |2.   is
calculated by solving the normal equation    =
 . Using (2) for each value of  ,  ,   ,  can
be calculated. A similar approach is applied for
identifying the parameter . The parameter  does not
have to be identified since it is the start value of the room
temperature, which simply can be taken from the
simulation. Knowing ,  and ( = 0), (2) is
parameterized during the whole simulation of the room
model and calculates the points in time for turning on or
off the heating system online by transforming (1) to


, () =   ln (  )
(4)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

4

DOI
10.3384/ecp17132161

Session 4D: Control Systems I

where  is the desired target temperature in the room.
Since the heating and cooling process of the room model
cannot be described exactly by an exponential function,
two parameters were introduced to the controller model
to optimize the point in time for turning the heating
system on and off.
Combination of Two-point controller and Forwardlooking Switching  Combi-Controller
Both of the introduced controllers have properties that
might be considered as drawbacks. The two-point
controller responds to a change of the set point not
before the change happened, i.e. in case of a desired
temperature that is warmer than the actual set point, the
heating system starts to warm up the room at that
moment the desired room temperature should be already
reached. That means that it probably, especially in the
case of a slow working heating system will be too cold
in the room for some time. Once the desired target
temperature is reached, the two-point controller works
well within the tolerance given by the hysteresis.
The forward-looking switching has the ability to turn
the heating system on and off at the right moment in
order to achieve a desired target temperature in the
future. However, once it is turned on, no mechanism is
available to prevent the room from overheating. In the
upper part of Figure 8 the room temperature is shown
that results from controlling the room temperature with
the two-point controller (red continuous line marked
with dots) and the forward-looking switching controller
(blue dashed line). The desired target temperature is
pictured as the green continuous line. The temperature
related heating signal is pictured in the lower part of
Figure 8.

Since both of the mentioned controllers have their
described properties which might be drawbacks in some
cases, the two controller approaches are combined and
considered as the third type of room temperature
controller within this study called combi-controller.
Statechart controller
Related to defined conditions (e.g. desired
temperatures) certain states occur naturally (e.g. actual
temperature too high or low). Those are identified as
system states that require certain actions (e.g. heating)
and represented as finite state machines (statechart). The
statechart controller [Clau, 2014] presented here
controls the required target temperatures due to the
occupancy of the room and it calculates the set points
for the heating system to achieve those target
temperatures. To realize those control actions two
statecharts were developed that work together. Figure 9
shows one of those statecharts. It calculates the target
temperatures dependent on the occupancy situation in
the room

Figure 9. Occupancy statechart to calculate target
temperature

Figure 8. Room temperature and heating signal for twopoint controller and forward-looking switching

DOI
10.3384/ecp17132161

The occupancy statechart contains the four states
Room_Unoccupied, PrepToOcc (preparation state for
oncoming
occupancy),
Room_Occupied
and
PrepToUnOcc (preparation state for oncoming leaving).
Within those states different parameters are calculated,
e.g. minimal (TempMin) and maximal (TempMax)
temperatures and set points for heating and cooling for
each state.
Values of control variables that have to be determined
and decision to be taken, which are normally
represented by transitions are calculated by a
parameterized function approach which combines the
available sensor values by a physically motivated
equation. For example, the length of the preparation
time (PrepTimeOcc) the room is pre-heated in order to
reach the target temperature when persons enter or leave
the room. With Tr  room temperature, Tout  ambient
temperature and Tmin/Tmax  admissible minimal/

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

5

165

Investigation of the Influence of Controller Approaches on Room Thermal Behaviour A Simulation Study

maximal room temperature the following heuristic and
parameterized function approach to calculate the
preparation time PrepTimeOcc is used
 = 0
+ 1 ((, )

2

+
(, ))
+ 2 ((, )
+

(5)

2

(, ))

3.1 Scenario Working Period for the office
room
This scenario was developed for the single office room.
It comprises three working weeks from February 28 to
March 21 including weekends. The daily working time
from Monday to Friday is from 8.00 am to 5.00 pm.
During this time, the desired target temperature is 22 C.
During absence of people the target temperature is 18
C (Figure 10).

with
     < 
(, ) = {
0 

(6)

     > 
(, ) = {
0 

(7)

Equation (5) was chosen so, that the preparation time
increases if the room temperature or the ambient
temperature are outside the interval [Tmin, Tmax]. Other
parameterized function approaches calculate the set
point for the heating system respectively in the occupied
or unoccupied state of the room. The parameters
0 , 1 , 2 in (5) and other parameters of the statechart
controller are determined by optimization.
The statechart controller is implemented in Modelica
using if-then-else constructions.
P-controller
The fifth controller used in this study is a well-known pcontroller with limited output. It is taken from the
Modelica
Standard
Library
(Modelica.Blocks.Continuous.LimPID).

3

Simulation Study

The aim of the work presented in this paper is to analyze
the suitability of different control strategies to ensure a
desired room temperature with possibly less net energy
consumption. Therefore, each room model is simulated
with each controller model. To ensure the comparability
of the results, for each combination of room model and
controller model simulation scenarios were defined.
Those guarantee the same simulation conditions e.g.
ambient and boundary conditions of the room or the
number of people entering the room at specified
moments in time. The scenarios represent the usage of
the rooms during heating periods (mid seasons, winter)
since heating is the only action that can be done actively
in the rooms (no cooling facilities are regarded).
In the following, one scenario is chosen to demonstrate
the functioning of the controllers and further steps like
their evaluation and optimization are discussed.

166

Figure 10. Target temperature of scenario "working
period" for the office room

The aim of the controller models is to keep the office
room temperature as close as possible to the set point
while minimizing net energy consumption. To measure
that the deviation between target and room temperature
is calculated during occupancy and distinguished
between too warm for times when the room temperature
is more than 1 K higher than the target temperature and
too cold if the room temperature is more than 1 K below
the target temperature. To calculate the total times (too
warm total and too cold total) too warm and too cold are
integrated over the simulation time period. Looking at
the example of the room temperature controlled by the
two-point controller (Figure 11), the signal tooCold
shows that at the beginning of every working day, it is
too cold. Especially on Mondays, it is too cold nearly
half of the day since the room temperature decreased a
lot on the weekends before. The energy consumption is
159.6 kWh, the total time where it was too cold is 16.8
h and the total time where it was too warm in the room
is 0.1 h.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

6

DOI
10.3384/ecp17132161

Session 4D: Control Systems I

Figure 11. Room temperature and signals tooWarm and
tooCold achieved by two-point controller

In comparison to the two-point controller, the statechart
controller meets the required target temperature better
however more net energy consumption is required. The
reason for that is that before the new week begins, the
room is being preheated in order to meet the high target
temperature on Monday morning. Figure 12 shows the
operative room temperature caused by the statechart
controller as well as the signals tooWarm and tooCold.
The energy consumption is 168.3 kWh and the total time
where it has been too cold is 7.4 h. It is never too warm
in the room.

Figure 12. Room temperature and signals tooWarm and
tooCold achieved by statechart controller

Table 1 shows the net energy consumption and the
aggregated times when it was too warm or too cold in
the room coursed by the five introduced controllers. It
can be seen that the combi controller containing the
forward-looking switching controller and the two-point
controller, needs the most net energy, however it meets
the required target temperature best whereas the pcontroller needs least energy at the price of the strongest
comfort violation with regard to the times when it is too
cold in the room. Figure 13 shows the room
temperatures caused by the five different controllers as
well as the desired target temperature
Table 1. Comparison of controllers regarding net energy
consumption and violation of comfort boundaries

Controller
two-point
FS
combi
statechart
p

DOI
10.3384/ecp17132161

Energy
in kWh
161.1
163.9
175.5
168.3
137.31

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

tooWarm
(total) in h
2.1
0.9
0
0
0

tooCold
(total) in h
8.3
0
0
7.4
32.4

7

167

Investigation of the Influence of Controller Approaches on Room Thermal Behaviour A Simulation Study

Figure 13. Room temperatures caused by the five
controllers

The so far investigated eight simulation scenarios for
each combination of the four room models and the five
controller models show, that all of the controller models
work different and fit better to one or another room
models. Therefore, it is promising to take the type of the
room and its HVAC equipment into consideration when
choosing a suitable room temperature controller.

3.2 Further Steps
Up to now, the introduced controller models are
parameterized from experience of the modeler. To
achieve less energy consumption by sticking to the
temperature comfort conditions, optimization of the
controller parameters is considered. Optimization will
be done by using the generic optimization program
GenOpt [Wetter 2000]. GenOpt can be used with
simulation programs that support textual based
input/output functionality like EnergyPlus [EnergyPlus
2016], TRNSYS [TRNSYS, 2016] or Dymola [Dymola,
2016]. For the optimization, a cost function is needed
that characterizes if a controller model is good. This
evaluation will be done by rating the net energy
consumption and the violation of the comfort
specifications regarding the room temperature. Equation
(8) shows the considered cost function in principle.
 =  + 1   (8)
+ 2  
In (8) energy denotes the net energy for heating the
room, tooWarmTotal and tooColdTotal are the total
times the room has been to warm or to cold respectively.
The two penalty terms are weighting factors.
The principal optimization procedure was so far
tested for the scenario working period for the office
room controlled by the two-point controller using
Dymola. The two-point controller has one free
parameter, the hysteresis parameter that can be tuned in
order to optimize the cost function. This parameter was
allowed to vary within the boundaries of 0.1 and 5. The
minimal cost function value was reached at a hysteresis
parameter of 1.04. To verify this result, a parameter
variation using the mos-script functionality in Dymola
was operated which showed the same result. The net
energy consumption decreased from 161.1 kWh for the
168

default hysteresis parameter value of 2 to 159.5 kWh for
the optimized hysteresis parameter value.
After optimizing the controller parameters for all
scenarios, sensitivity analyses of the optimized
parameters regarding different locations (including
different weather) of the rooms, different HVAC
systems and other, still to be defined parameters, will be
performed. Aim of this analysis is to figure out how
robust the controller parameters are.
The subsequent step will be to find and establish
criteria to assess the quality of the controller and hence
to deduce rules for choosing a specific controller to a
given room and decide if the controller needs special
parameter adaption or if the default parameter will be
sufficient.

4

Conclusion

The work presented in this paper are the first steps of a
broad investigation with the aim to develop a
methodology to provide rules and guidelines for
choosing a suitable room temperature controller with
regard to the given room and its installed HVAC
technology. To achieve this goal a simulation study is
performed. The instrument of simulation instead of
measured data is used in this study for several reasons.
First, one is considerably faster than real-time. Second,
the investigations can be done under specified
conditions and third, several scenarios can be elaborated
and easily compared to each other. This paper presents
the first steps of this investigation which is the
development of four different representative room
models with different heating systems like floor heating,
electrical heating and radiator heating as well as five
controller models of important controller types. Within
the simulation of defined scenarios suitable for the type
of the room (e.g. office room, classroom), the eligibility
of the controller models is investigated. In addition, an
outlook to further steps is given which will be the
optimization of controller parameters including the
definition of a cost function, a sensitivity analysis to
study the robustness of the optimized controller
parameters and the definition of criteria to evaluate the
quality of the controller.

Acknowledgements
This paper is based on the results of the research project
Entwurfsverfahren
fr
ganzheitliche
Energiemanagementsysteme
in
Gebuden
(ENERMAT), funding reference 03ET1084A.

The authors are much obliged to the contributors of the
research project Torsten Blochwitz, Eva Fordran,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

8

DOI
10.3384/ecp17132161

Session 4D: Control Systems I

Matthias Franke, Jeanette Floss, Jrgen Haufe, Jrg
Hohlfeld, Edgar Liebold, Richard Meyer, Paul Pinther,
Stephan Seidel and Jens Wurm.

References
Abdolreza Rahmati, Farzan Rashidi, Mehran Rashidi: A hybrid
fuzzy logic and PID controller for control of nonlinear HVAC
systems. Proceedings of IEEE International Conference on
Systems, Man and Cybernetics, pp. 2249-2254, 2003.

Abdul Afram, Farrokh Janabi-Sharifi. Theory and application
of HVAC control systems  A review of model predictive
control (MPC). Building and Environment 72, pp. 343-355,
2014. http://dx.doi.org/10.1016/j.buildenv.2013.11.016
Alessandra Parisio, Marco Molinari, Damiano Varagnolo, et al.:
A Scenario-based Predictive Control Approach to Building
HVAC Management Systems. IEEE International Conference
on Automation Science and Engineering (CASE), pp. 428-435,
2013.

Patrick Lauenburg, Janusz Wollerstrand. Adaptive control of
radiator systems for a lowest possible district heating return
temperature. Energy and Building 72, pp. 132-140. 2014.
http://dx.doi.org/10.1016/j.enbuild.2013.12.011
Stephan Seidel, Christoph Clau. Eva Fordran, et al.: Design
and Optimization of Building Energy Management
Systems. Proceedings of 18th ITI Symposium. pp. 329-337,
November 9-11, Dresden, 2015.
Rolf Isermann. Identifikation dynamischer Systeme 1,
Springer-Verlag, 2. Auflage, pp. 189-195, 1991.
TRNSYS website: http://www.trnsys.com/
Yudong Ma, Francesco Borrelli, Brandon Hencey, et al.: Model
predictive control of thermal energy storage in building cooling
systems. Proceedings of the 48th IEEE conference on decision
and control, pp. 392-397, Shanghai, China, 2009.
Hermann Recknagel, Eberhard Sprenger, Ernst-Rudolf
Schramek.:
Taschenbuch
fr
Heizung+Klimatechnik
Oldenbourg Industrieverlag GmbH; p.804, 2011/2012.

Christoph Clau, Eva Fordran, Matthias Franke, et al.
Entwicklung und Optimierung von Gebude-ManagementSystemen. Fifth German-Austrian IBPSA Conference,
pp.166-173, Aachen, 2014.
Christoph Nytsch-Geusen, Jrg Huber, Manuel Ljubijankic,
Jrg Rdler. Modelica BuildingSystems  eine
Modellbibliothek
zur
Simulation
komplexer
energietechnischer Gebudesysteme. Bauphysik 35, Heft1,
Ernst & Sohn Verlage fr Architektur und technische
Wissenschaften GmbH & Co. KG, 2013
Deutscher Wetterdienst. Testreferenzjahre von Deutschland
fr
mittlere,
extreme
und
zuknftige
Witterungsverhltnisse. Handbuch, 2014. Website:
www.dwd.de
Dymola
Website:
http://www.3ds.com/productsservices/catia/products/dymola
Elisa Carlon, Markus Schwarz, Christoph Schmidl, et al. Low
Energy Houses Heated By Biomass Boilers: Optimization
Of The Heating System Control Strategy By Means Of
Dynamic Simulation. 3rd International High Performance
Buildings Conference, pp.3303/1  3303/8, 2014.
EnergyPlus Website: https://energyplus.net/
Frauke Oldewurtel, Alessandra Parisio, Colin N. Jones et al.:
Energy efficient building climate control using stochastic
model predictive control and weather predictions. Proceedings
of American control conference, 2010

Friedrich Sick, Sebastian Dietz, Gustav Hillmann, Margarethe
Korolkow, Susanne Rexroth. Monitoring PlusenergieGrundschule Hohen Neuendorf und IEA Task 41 (Solar
Energy and Architecture). Schlussbericht, Berlin, 2015,
Website:
http://www.enob.info/fileadmin/media/Publikationen/EnB
au/Projektberichte/27_Projektbericht_EnBau_0327430M_
-_Monitoring_Schule_Hohen-Neuendorf.pdf
Kristin Majetta, Christoph Clau, Jrgen Haufe, et al. Design
and Optimization of an Energy Manager for an Office
Building. ASIM/GI-Section Workshop  Simulation of
Technical Systems & Methods in Modeling and Simulation,
pp. 289-296, 2015.
Michael Wetter. Design optimization with GenOpt. Building
Energy Simulation User News 21, p. 200, 2000.

DOI
10.3384/ecp17132161

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

9

169

170

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Powertrain and Thermal System Simulation Models of a High
Performance Electric Road Vehicle
Massimo Stellato1

Luca Bergianti2

John Batteh3

1

Dallara Engineering, Italy m.stellato@dallara.it
Dallara Engineering, Italy l.bergianti@dallara.it
3
Modelon Inc., Ann Arbor, Michigan USA john.batteh@modelon.com
2

Abstract
Performance and range optimization of electric
vehicles are challenging targets in the design of
contemporary automobiles. This paper illustrates that
the thermal system and the development of the related
control logic are key factors in achieving these targets.
Both subjects benefit from the support of modeling and
simulation. The paper describes our approach applied
to a real case study.
The activity is the result of a cooperation between
Dallara, responsible for the case study, and Modelon,
developers of the libraries used to build the simulation
model.

The thermal system architecture, the components
and all the car data in this analysis reflect the real case.

3

Model Description

Figure 1 shows the top level of the Systems Model,
comprising of the following sub-models using the
libraries noted:
 Driver
 Powertrain (Vehicle Dynamics Library)
 Brakes (Vehicle Dynamics Library)
 Thermal System (Liquid Cooling, Vapor Cycle and
Heat Exchanger Libraries)

Keywords: electric vehicle, thermal system, control
logic, powertrain, battery, cooling, range, derating.

1

Introduction

The goal is to evaluate the potential of the simulation
models to define the thermal system architecture of an
electric vehicle. This approach should allow the
maximum degree of freedom for the control logic to be
optimized later in the project, in order to optimize both
vehicle range and performance.
Thanks to new technologies in the automotive field
in general and for electric vehicles, a multi-physics
approach to analyze the interactions between complex
subsystems becomes necessary to evaluate the vehicle
performance (Bouvy et al, 2012). This need has led to
the construction of a multi-physics model developed in
the Modelica environment with components taken from
four different application libraries: Vehicle
Dynamics, Liquid Cooling, Vapor Cycle and
Heat Exchanger (Modelon, 2016). The models are
developed using Dymola (Dassault Systmes, 2016).

2

Figure 1. Systems model top view

The aim of the Systems Model is to match the
reference speed profile (input) while considering the
thermal limits of battery and powertrain together with
the longitudinal vehicle performance (speed and
acceleration) in order to calculate the range.
Figure 2 shows the main input and output of the model.

Case Study Description

The activity reported in this paper supports the design
of the thermal system of a real case high performance
Sedan class electric vehicle which features three
inboard motors (one at the front and two at the rear).

DOI
10.3384/ecp17132171

Figure 2. Model input and output

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

171

Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle

Its also possible to develop different driving cycles
to represent typical real driving styles in order to
evaluate their effect on the range.
The Systems Model can be interfaced with the
multi-body vehicle model for vehicle dynamics
analysis (Figure 3).
This approach allows both the refined analysis of the
vehicle performance and the study of the cooling
system at the same time.

Figure 5. Powertrain sub-model

Figure 3. Full vehicle multibody model

The battery model has both electric and thermal
features with variable internal resistance and open
circuit voltage as function of state of charge and cell
temperature. The cell heat capacity is modeled with a
lumped thermal element storing heat. The physical
interaction between the cell and the coolant is modeled
with a lumped thermal element transporting heat
(Figure 6).

3.1 Driver Model
The driver model, (see Figure 4), tries to match the
speed profile (input) by varying the accelerator and
brake pedal positions, which are respectively
connected to the powertrain and brake models. If the
coolant temperatures reach the limits, the control logic
applies a progressive power derating as needed.

Figure 6. Battery sub-model

The model provides interfaces to the thermal
system at the cell bottom, cell top or cell surface, as
shown in Figure 7.
Figure 4. Driver sub-model

3.2 Powertrain Model
The powertrain model, illustrated in Figure 5, is
composed by the following elements:
 Battery
 3x Motors
 Driveline
Figure 7. Cell temperature in the case of the thermal
system linked to cell surface vs cell bottom

This approach looks at the irreversible heat
generation due to the ohmic thermal loss caused by the
batterys internal resistance, in the real case theres
172

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132171

Session 5A: Automotive II

also the effect of the reversible heat due to the
chemical reactions in the battery electrodes (Schmitke
et al, 2015).
A finite volume and finite element method would
not represent a preferable alternative for system
simulations as they slow down the simulation (Krger
et al, 2012) and still does not consider the effect of the
reversible heat due to chemical reactions.
The battery energy consumption is used to predict
the range via the state of charge calculated by
integrating the generated current over time.
The motors are characterized in terms of both
peak and continuous power curves, which depend on
the available voltage at the inverter inlet. This voltage
depends on the generated current, open circuit voltage
and internal resistance of the battery. The motor and
inverter efficiencies vary with torque and rpm. The
model includes both winding and stator core
temperatures. The winding is not interfaced with the
thermal system. The equation describing the
relationships between winding temperature and peak
power is provided by the motor supplier. When the
winding temperature reaches the limit value, the motor
available power switches gradually from peak to
continuous (Figure 8). The stator core is interfaced
with the thermal system through coolant ducts (Figure
9); when the coolant temperature at the stator outlet
reaches its limit, the control logic applies the power
derating, as described later in the paper.
The stator core modeling consists of a thermal
capacitance and a thermal conductance between stator
and coolant which reflect the real geometry and
material property.

The energy recovery under braking is also
considered: the motors assist the mechanical brakes by
providing a torque of up to 10% that available in
normal driving conditions; the energy recovery under
braking affects both range and heat rejection.
An ABS / traction control model is included to
avoid front and rear wheel spin during acceleration and
braking.

3.3 Thermal System Model
The thermal system is the most innovative block of the
systems model; its aim is to cool the battery and the
powertrain as needed.
All the thermal components considered in the model
are calibrated to match the behavior of the actual
components. For example the radiator characteristic
(Figure 10) has been provided by the supplier and
validated by Dallara with experimental tests in the
cooling rig (Figure 11).

Figure 10. Coolant radiator characteristic: Heat
dissipation normalized and air pressure drops

Figure 8. Winding temperature as function of peak and
continuous power in a typical electric motor for
automotive applications

Figure 11. Radiator testing at the Dallara cooling rig

Figure 9. Stator of the electric motor

DOI
10.3384/ecp17132171

The thermal system is composed of multiple coolant
radiators, complete with fans, and one chiller (plate
heat exchanger).
The chiller utilizes the air conditioning refrigeration
power to assist the radiators in cooling batteries and
powertrain. The compressors electrical power,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

173

Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle

required to activate the chiller, affects the range
calculation as well.
Through one or more 4-way valves, different
architectures can be studied and allow the
reconfiguration of the thermal system into multiple
loops in order to cool both the battery and the
powertrain as a single system or as separate systems
(see Figure 12).
The modularity of the thermal system model allows
the analysis of different architectures to select the best
solution subject to the vehicle design constraints.

Figure 14 shows the thermal system components:
chiller, radiator, battery, inverter and motor.

Figure 14. Thermal system components

The coolant flow rate has been calculated by
considering the pump characteristic, the coolant
pressure drops for each component and pipes
geometry (Figure 15). The heat exchange between
pipes and the environment is also considered.

Figure 12. Thermal system sub-model

The model allows the performance of weight
sensitivity analysis on the range; the effect of the
weight in the configurations under investigation can be
considered in the choice of the thermal system
architecture.
The radiator cooling efficiency is a function of the
air flow across radiator, which varies with vehicle
speed and fan performance.
The air flow across the radiator is calculated by
considering the maximum available between the effect
of the vehicle speed and the performance of the fan
(Figure 13). At low vehicle speeds, the airflow due to
the fan is dominant; at higher vehicle speeds the air
flow is essentially a function of the vehicle speed
alone. In the real world these two effects interact and
provide an even higher air flow rate.

Figure 15. Pipes modeling in the thermal system, both
distributed and concentrated pressure drops are
considered for each pipe

The 4-way valve model, shown in Figure 16, has
been developed with the Liquid Cooling Library
starting from the model of the 3-way valve.

Figure 13. Fan performance curve vs radiator + duct air
pressure drops

174

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132171

Session 5A: Automotive II

Figure 16. 4-way valve sub-model

3.4 Control Logic Model
The control logic analyzes the battery and powertrain
coolant temperatures and continuously switches to the
most efficient cooling loop configuration among those
available through the thermal system model.
If the coolant temperatures reach the limits, then
the control logic applies power derating.

4

While the specifics of the variable system
configuration are confidential, the general architecture,
which shows how the coolant flow path is arranged in
each configuration, is reported in Figure 17. The grey
blocks represent radiators, chiller, battery and
powertrain.
An outline of the three configurations is given below:
 Config 0  All components in series to cool
battery and powertrain in a single system (Figure
17a). This configuration is suitable for low heat
rejection requirements of
both battery and
powertrain with moderate ambient temperature;
 Config 1  Components in separate loops (Figure
17b) to independently cool battery and powertrain.
This first two-loops configuration caters for
high battery heat rejection and medium powertrain
heat rejection requirements with medium and high
ambient temperatures;
 Config 2  Components in separate loops (Figure
17c) to cool independently the battery and
powertrain. This second two-loops configuration
caters for medium battery heat rejection and high
powertrain heat rejection requirements with
medium and high ambient temperatures.

Approach

The main purpose of designing the thermal system of
an electric vehicle is to optimize the vehicle range and
minimize power derating.
The chiller reduces the battery power which then
makes it necessary to minimize its use to optimize the
range. Moreover, as the chiller power demand to cool
the battery increases, less power is available for the air
conditioning of the vehicle interior, with negative
implications on passenger comfort (Krger et al,
2012).
The battery and powertrain cooling requirements
vary throughout the simulation, as they depend on both
the instantaneous power required to match the
reference speed profile (Krger et al, 2012), and
battery and powertrain efficiency; in some conditions
the powertrain requires more cooling than the battery
while the opposite holds true in other conditions.
For this reason, a variable thermal system
architecture is more efficient than a fixed layout in
both the case of low heat rejection values to minimize
the chiller use and with high heat rejection values to
minimize the power derating. This variable architecture
is configurable during vehicle operation in order to
favor battery cooling over powertrain cooling or vice
versa, depending on the instantaneous cooling
requirements.
Following this approach, a variable thermal system
layout has been designed to switch between three
different configurations.
DOI
10.3384/ecp17132171

Figure 17a. Thermal system configuration 0

Figure 17b. Thermal system configuration 1

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

175

Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle

5

Figure 17c. Thermal system configuration 2

By monitoring the battery and powertrain coolant
temperatures, the best configuration among the three
choices is continuously selected by the control logic
that switches from one configuration to another
through two 4-way valves.
When either the battery or the powertrain coolant
temperature approaches the limit values, a gradual
power derating is applied.
The amount of coolant in the system plays an
important role as it affects the thermal inertia and
therefore the time before reaching the maximum
temperature values. More coolant in the system,
allows running in unstable conditions (i.e. extreme
acceleration) for longer periods of time, before the
control logic starts to degrade power.
This effect is shown in Figure 18, where the
temperatures (considering coolant quantities of 8l and
24l in the system) are calculated for the same heat
rejection profile.

Results

The results reported in Figures 20-22 show the
comparison between the variable thermal system
architecture defined by this activity and three different
fixed architectures (config 0, 1, 2 of Figure 17) with
the same radiators and chiller of the variable thermal
system. The driving cycle considered (Dimensioning
Cycle) is confidential; it was developed to represent an
aggressive use of the vehicle in terms of cooling
requirements, Figure 19 summarizes the main input
and output. A maximum available cooling power of 3
kW is considered for the chiller. The vehicle range is
calculated with and without considering the power
consumption due to the thermal components (fans,
pumps and compressor). The impact of the thermal
considerations of the system results in a roughly 8%
decrease in vehicle range.

Figure 19. Dimensioning Cycle, input and output,
variable thermal system architecture

The vehicle speed profile achievable with the
variable thermal system architecture matches the
Dimensioning Cycle speed profile (input) much better
than the one provided by a fixed architecture, which
needs more power derating (Figure 20-21). The
performance gain of the variable thermal system
architecture could be increased by optimizing the
control logic.

Figure 18. Coolant temperature sensitivity with coolant
volume.
Figure 20. Dimensioning Cycle, Tout motor coolant,
variable vs fixed thermal system architecture

176

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132171

Session 5A: Automotive II

The thermal system configuration, managed by the
control logic, changes during the simulation to best
cope with the cycle requirements (Figure 24).

Figure 24. Dimensioning Cycle, thermal system
configuration, variable thermal system architecture
Figure 21. Dimensioning Cycle, Tout battery coolant,
variable vs fixed thermal system architecture

Figure 22 shows the battery cells temperature
profile, achieved with the variable thermal system
architecture in comparison with the profiles achieved
with the fixed architectures.

The total mechanical power (front motor + rear
motors) required to perform the Dimensioning Cycle is
reported in Figure 25.

Figure 25. Dimensioning Cycle, total power (front +
rear_1 + rear_2) @ outlet powertrain, variable thermal
system architecture
Figure 22. Dimensioning Cycle, T battery cell, variable
vs fixed thermal system architecture

Figure 23 shows that the battery cell temperature is
higher than the coolant temperature because of the
thermal conductance of the cell.

Figure 23. Dimensioning Cycle, T battery cell vs T out
battery coolant, variable thermal system architecture

DOI
10.3384/ecp17132171

Figure 26 shows that for low acceleration levels, the
cooling demand from the powertrain is greater than the
cooling demand from the battery; at high acceleration
levels the opposite is true.

Figure 26. Dimensioning Cycle, powertrain heat rejection
(front + rear_1 + rear_2) vs battery pack heat rejection,
variable thermal system architecture

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

177

Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle

Further analyses were performed on the
homologation cycles US06 and NEDC where power
derating is not required. All the simulations are
performed considering the same SOC start (0.95) and
SOC end (0.15).
The homologation cycles are generally of low
thermal demand, consequently the chiller is typically
not necessary and a variable thermal system not
required. In the real world, or considering more
aggressive cycles, the advantages (energy saved)
related to the introduction of a variable system
architecture (with Chiller) could represent a noticeable
increase of the range (up to 15 km), to further
minimize the power derating as reported for the
dimensioning cycle.
Figure 27 summarizes the main input and output
for the US06 Cycle.

Figure 30 reports the battery outlet coolant
temperature and the battery cell temperature in the
US06 cycle, the chiller is turned off.

Figure 30. US06 Cycle, T battery cell vs T out battery
coolant, variable thermal system architecture

Figure 31 summarizes the main input and output
for the NEDC Cycle.

Figure 27. US06 Cycle, input and output, variable
thermal system architecture

Figure 28 shows that the vehicle speed matches
the US06 speed profile (input) without derating.

Figure 28. US06 Cycle, reference speed profile (input) vs
vehicle speed, variable thermal system architecture

Figure 29 reports the motor outlet coolant
temperature in the US06 cycle.

Figure 29. US06 Cycle, Tout motor coolant, variable
thermal system architecture

178

Figure 31. NEDC Cycle, input and output, variable
thermal system architecture

Figure 32 shows that the vehicle speed matches the
NEDC speed profile (input) without derating.

Figure 32. NEDC Cycle, reference speed profile (input)
vs vehicle speed, variable thermal system architecture

Figure 33 reports the motor outlet coolant
temperature in the NEDC cycle.

Figure 33. NEDC Cycle, Tout motor coolant, variable
thermal system architecture

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132171

Session 5A: Automotive II

Figure 34 reports the battery outlet coolant
temperature and the battery cell temperature in the
NEDC cycle, the chiller is turned off.

Figure 34. NEDC Cycle, T battery cell vs T out battery
coolant, variable thermal system architecture

A weight sensitivity analysis has been performed
on the NEDC cycle; an increase of 10 kg reduces the
range by 2 km.
The homologation cycles were also helpful for a
first validation of the systems model, because the car
manufacturers tipically declare the vehicles range on
these cycles. A systems model with the architecture
and available data of a benchmark vehicle has been
developed, achieving range results on US06 and NEDC
cycles aligned with those declared by the benchmark
vehicle constructor.
The last analysis reported (Figure 35) concerns the
total electric power needed to cool the battery during
the fast charge, considering a battery power supplies of
100 kW, 110 kW and 150 kW; these are representative
of the typical and maximum values used in the real
case for the fast charge of the electric vehicles.
In all three cases analyzed the pumps and fans are
kept at max rpm, the chiller power is the power in
surplus at the radiator needed to keep the coolant
battery temperature below its limit.

Figure 35. Fast charge analysis, the total electric power
required to cool the battery is reported in red color

6

Conclusions and Further
Developments

The activity described in this paper was useful to
evaluate the potential of the simulation model and to
define the thermal system layout for a real case study.

DOI
10.3384/ecp17132171

The performance gains of a variable thermal system
architecture with respect to a fixed architecture have
been detailed.
The model continues to support and evolve with the
case study and can be fully validated in the future with
real vehicle tests, as well as being used as a starting
point for future electric vehicle projects.
Ongoing work with this model to further support
the case study includes the following:
 Powertrain and thermal system control logic
optimization.
 Analysis of the battery heating required in low
ambient temperature conditions, which constitutes
another critical point in the design of Electric
Vehicles (Bouvy et al, 2012).
 Analysis, supported by experimental test, of the
fans and vehicle speed interaction for the air flow
rate across the radiators.
 Battery model with electrochemical features
development, which describes the battery physics
in detail (Schmitke et al, 2015).
 Interface with the vehicle multi-body model for
real time applications at Dallara Dynamic Driving
Simulator.
 Air conditioning system development with effects
on passenger human comfort.
 Active grill shutter model development (Batteh et
al, 2014).

References
J. Batteh, S. Chandrasekar and J. Gohl. Integrated Vehicle
Thermal Management in Modelica: Overview and
Applications. Proceedings of 10th International Modelica
Conference, pp. 409-418, 2014
C. Bouvy , P. Jeck, J. Gissing, T. Lichius, L. Ecksterin.
Holistic Vehicle Simulation using Modelica  An
Application on Thermal Management and Operation
Strategy for Electrified Vehicles. Proceedings of 9th
International Modelica Conference, pp. 263-270, 2012.
C. Bouvy, P. Jeck, S. Ginsberg, P. Jeck, B. Hartmann, S.
Baltzer and L. Eckstein. Holistic Battery Pack Design.
Aachen, pp. 367-380, 2012.
I. Krger, A. Mehlhase and G. Schmitz. Energy
Consumption of Battery Cooling In Hybrid Electric
Vehicles. Proceedings of 14th International Refrigeration
and Air Conditioning Conference, 2012.
I. Krger , A. Mehlhase and G. Schmitz. Variable Structure
Modeling for Vehicle Refrigeration Applications.
Proceedings of 9th International Modelica Conference,
pp. 927-934, 2012.
C. Schmitke and T. Son Dao. Developing Mathematical
Models of Batteries in Modelica for Energy Storage
Applications. Proceedings of 11th International Modelica
Conference, pp. 469-477, 2015.
Dassault
Systmes.
Dymola
2017.,
2016.
www.Dymola.com

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

179

Powertrain and Thermal System Simulation Models of a High Performance Electric Road Vehicle

Modelon. Heat Exchanger Library. Version 1.4.1, 2016.
www.modelon.com/products/modelicalibraries/heatexchanger-library/
Modelon. Liquid Cooling Library. Version 1.5, 2016.
www.modelon.com/products/modelicalibraries/liquidcooling-library/
Modelon. Vapor Cycle Library. Version 1.3, 2016.
www.modelon.com/products/modelica-libraries/vaporcycle-library/
Modelon. Vehicle Dynamics Library. Version 2.3, 2016.
www.modelon.com/products/modelica-libraries/vehicledynamics-library/

180

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132171

Investigating the Effect of a Sonic Restrictor in the Intake of an
Engine
Maura Gallarotti

Alessandro Picarelli

Mike Dempsey

Claytex Services Ltd., Edmund House, Rugby Road, Leamington Spa, CV32 6EL, UK
{maura.gallarotti, alessandro.picarelli, mike.dempsey} @claytex.com

Abstract
The air induction system is one of the engine
subsystems that most influences fuel efficiency and
power generation, especially in restricted race
engine applications.
In this paper, the quasi-1D model of a sonic restrictor
is presented, together with its integration in an engine
model, in order to investigate the behaviour of the
engine power and torque when the choked condition is
reached.
The study shows how power and torque curves are
affected when a sonic restrictor is installed within the
intake system and outlines the need of detailed
simulations in a restricted engine development process,
to avoid steep engine power reductions at high speeds.
Keywords: sonic restrictor, choked flow, engine,
MVEM, intake manifold.

1

Introduction

The development of high-fidelity predictive models of
vehicle engines is one of the main objectives of
powertrain simulation engineers. Dymola is a
convenient software for vehicle and engine modelling,
since the underlying Modelica language is suited to
complex multi-domain systems.
However, as Dymola is mainly limited to 0D-1D
thermofluid systems, engineers can face some
intricacies in modelling the more complex flows
happening in engines. To get better results, CFD
simulations can be performed, but often at the cost of
losing the integration with the mechanical part of the
model and losing any real-time simulation capability.
This paper shows that although Dymola is not a
CFD code, it can handle the inherent non-linearities of
the nozzle flow that arise in the transition from the
subcritical to the choked state.
A sonic restrictor is a converging-diverging nozzle
installed in the intake system in order to limit the
maximum power output of the engine by limiting the
mass flow of air flowing into the cylinders.
In situations where the engine would require a
higher mass flow than the one allowed by the nozzle,

DOI
10.3384/ecp17132181

the constraint of sonic flow velocity at the throat limits
the mass flow and a shock takes place in the divergent
section of the nozzle, thus introducing strong pressure
losses that ultimately limit the engine power.
Sonic restrictors are being used in several
motorsport championships in order to equalize the
maximum power of the engines. Among the racing
series that make use of air restrictors are the Formula 3,
the Formula SAE, the FIA GT1 World Championship,
Le Mans Series and several others. Sometimes sonic
restrictors are also used in road applications for derating purposes, mainly in motorbike engines.
In restricted engines, a reliable model of the air
induction system is of paramount importance, as the
flow in the sonic restrictor has direct effects on power
generation and fuel efficiency.
The challenge when modelling a converging
diverging nozzle lies in the asymmetric behaviour of
the flow before and after the shock, with equations for
the subsonic flow being very different from the ones
used for supersonic conditions.
If not implemented in an efficient way, such a
physical problem could trigger in Dymola several
events and non-linear iterations, making the model
computationally expensive.

2

The sonic restrictor model

The sonic restrictor is modelled in Dymola as a
component where steady momentum, continuity and
energy balances are performed. It uses the fluid
connectors from Modelica.Fluid (Casella, F. et al.,
2006) which make it fully compatible with the
Modelica Standard Library.
As in pipes, the pressures at inlet and outlet
determine the mass flow rate, the flow goes from the
higher to the lower pressure and a greater pressure
difference gives a higher mass flow.
For a pressure drop weaker than the critical one, the
flow accelerates in the converging section and
decelerates in the diverging one isentropically.
If the pressure at the throat equals the critical one,
the nozzle becomes choked and the sonic condition is
reached (see Equation 1, where
is the critical

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

181

Investigating the Effect of a Sonic Restrictor in the Intake of an Engine

pressure and
the inlet pressure). Being the speed of
sound the speed of propagation of small disturbances,
the Mach at throat cannot be higher than 1, as the flow
upstream the throat does not receive any information
about what is happening downstream.

with huge associated viscous losses that reduce the
total pressure.
The Mach numbers upstream (u) and downstream
(d) of the shock are related by Equation 4 (Anderson J.,
2002)

(4)

Figure 1. Sonic restrictor.

(1)

This equation states that the further along the nozzle
the shock occurs, the stronger it will be: as the Mach
upstream increases above 1, the normal shock becomes
stronger and
becomes progressively less than 1,
decreasing the total pressure of the flow leaving the
sonic restrictor and entering the cylinders.
From a practical point of view, this means that the
section in which the shock will occur will influence the
total pressure of the flow entering in the cylinders.
The total pressures upstream and downstream the
shock are linked by Equation 5 (Anderson J., 2002):

If the pressure at the throat is further reduced, the
mass flow at the throat is limited to the critical value,
the flow becomes supersonic in the diverging section
and a shock occurs. The critical mass flow rate can be
found using Equation 2, where
is the total pressure
and
the total temperature.

(5)

(2)
For air, with =1.4, the critical pressure ratio (given
by Equation 1) is 0.528, meaning that in a nozzle, the
sonic condition is reached when the pressure at the
throat is lower or equal to 0.528 times the pressure at
inlet.
In all the other air ducts of the engine, the Mach is
much lower than 1 and the continuity equation for a
subsonic flow states that a decrease in area causes an
increase in velocity. However, if the flow becomes
supersonic, the flow behaviour changes and Equation 3
tells us that an increase in velocity is associated with an
increase in area. In fact, the flow accelerates in the
diverging section of a choked nozzle.

Figure 2. Discontinuity in the Mach number at the nozzle
outlet going from a subsonic (red curve) to a supersonic
(green curve) flow.

(3)
In a choked nozzle, the flow accelerates isentropically
from the inlet and its static pressure decreases
maintaining a constant total pressure, until a shock
occurs in the diverging section.
A shock is a discontinuity in the flow field across
which the flow abruptly slows down from a supersonic
to a subsonic speed while increasing the static pressure

182

Figure 2 shows the Mach at the outlet of the sonic
restrictor both when the sonic condition is not reached
(red curve) and in case of shock (green curve). For a
given inlet pressure, if the throat pressure is higher
than the critical value, the flow remains isentropic,
while if the throat pressure decreases further, the sonic
condition is reached and the outlet Mach decreases
drastically.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132181

Session 5A: Automotive II

(8)

Figure 3. Discontinuity in the mass flow going from a
subsonic (red curve) to a supersonic (green curve) flow.

Figure 3 shows the mass flow through the sonic
restrictor for a subsonic flow (red curve) and for a
supersonic flow (green curve).
The transition from the subsonic to the supersonic
condition has been implemented in Dymola avoiding
the use of if statements, as conditional expressions can
trigger events. The mass flow rate through the sonic
restrictor has been defined as the minimum value
between the critical mass flow rate and the value from
the isentropic solution using the operator min.
In case the sonic condition is not reached, the mass
flow rate can be calculated using Equation 6:

In this way, the solution will follow the continuous line
of figures 2 and 3, discarding the dotted parts without
using
computationally
expensive
conditional
expressions.
As far as the energy balance is concerned, the total
temperature has been assumed to be constant between
inlet and outlet.

3

The engine model

The sonic restrictor was integrated in an engine model
developed using the Engines library (Picarelli, A. et al.,
2009; Roberts, N. et al., 2013). A 0.6 L motorcyclederived four-cylinder naturally aspirated spark ignition
engine was used.
A MVEM (Mean Value Engine Model) was used in
place of a more detailed CAREM (Crank Angle
Resolved Engine Model) in order to be able to focus on
the effects of the sonic restrictor on the average air
mass flow rate rather than on an oscillating value.

(6)

For the chocked condition, the mass flow rate can be
calculated using Equation 2.
In the same way, the Mach at the outlet of the
sonic restrictor has been defined as the minimum value
between the one reached in case of shock and the one
in case of an isentropic solution, avoiding the use of
conditional expressions.
The Mach at the outlet in case the sonic condition
is not reached can be calculated using the definition of
total pressure (Equation 7), assuming that
.

2

3

4

5
1

(7)

When the shock occurs, the Mach at the outlet can be
calculated using Equation 8, that can be derived from
Equations 2 and 6:

DOI
10.3384/ecp17132181

Figure 4. Engine test model: 1-Engine, 2-Engine Control
Unit, 3-Rig Controller, 4-Engine coolant system, 5-Dyno.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

183

Investigating the Effect of a Sonic Restrictor in the Intake of an Engine

Figure 4 shows the test rig, where the engine is
connected to a dyno (5) and controlled by the ECU (2).
The engine is run on a dynamometer and controlled to
ramp up from around 5000 rpm to 11000 rpm with
wide open throttle in order to generate the full load
curve. To achieve this, the rig controller (3) specifies
the throttle opening.
1

2

case, in the same way as for the sonic restrictor,
the air flow rate at a given throttle position will be
independent of manifold pressure and engine
speed.
Having tested the engine at WOT (wide open
throttle), there is no risk that the flow could
become choked in the throttle, influencing the flow
in the sonic restrictor.
The intake manifold (3), containing the sonic
restrictor and the plenum volume.

The sonic restrictor was placed after the throttle and
before the plenum, as shown in Figure 7.
4

3

5
6
1

2

Figure 7. Intake manifold model: 1-Sonic restrictor, 2Plenum.
Figure 5. Engine model: 1-Intake, 2-Exhaust, 3-Camshaft
4-Timing belt, 5-Cylinder block, 6-Crankshaft.

Figure 5 shows the engine model, with the intake
system (1), the exhaust system (2), the camshaft (3),
the timing belt (4), the cylinder block (5) and the
crankshaft (6).
Having used a MVEM in place of a CAREM, the
camshaft and the timing belt models are empty, but
they can be replaced with detailed models in case a
CAREM engine is used.

To compute the cycle-averaged torque, the Mean Value
combustion model uses IMEP maps where the output
is a function of engine speed and plenum pressure,
with corrections for air fuel ratio, spark timing and cam
timing. Its clear that, by influencing the plenum
pressure, the sonic restrictor can yield a different
engine torque characteristic.
The mass flow rate through the engine is calculated
using Equation 9, as a function of intake air
temperature, engine speed and plenum pressure
(Hendricks et al., 1996).
(9)

1

3

2

h
Figure 6. Intake model: 1-Air filter, 2-Throttle, 3-Intake
v
manifold with sonic restrictor.
v

Where n is the engine speed [rpm],
the
volumetric displacement of each cylinder [m3],
the
intake manifold pressure, R the specific air gas
constant [J/Kg/K] and T the fluid temperature [K].
The coefficients and are function of speed and
are provided in tabular format using experimental data.

The intake system is shown in Figure 6 and consists of:
The air filter (1) modelled with a pressure loss
characteristic curve
- The throttle (2), modelled with an orifice also
capable of modelling the choked condition. If the
throttle is almost closed, the pressure ratio across it
can be higher than the critical value (0.528) and
the choked condition can be reached. Also in this
184

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132181

Session 5A: Automotive II

First of all, Figure 9 shows that in two of the 3
analysed cases the sonic condition was reached, while
for the largest throat area (1.25 At) the flow remained
always subsonic.
For a throat diameter of 20 mm (0.75 At), the
choked condition was reached at 8760 rpm, while for a
throat area 25 % larger the choked flow was reached at
9450 rpm (a speed around 8% higher).

1

2

3

Figure 8. Cylinder block: 1- Piston head, 2-Combustion
block, 3-Piston mechanism.

4

Results

The sonic restrictor model was integrated on a 0.6 L
four-cylinder naturally aspirated spark ignition engine
in order to analyse engine power and torque in case of
choked flow.
Three different sonic restrictor throat areas were
tested, with a throat diameter ranging from 20 mm to
25 mm, increasing the throat area in each test by 25%.
The results are shown in the following plots where
At represents the case with a throat diameter of 22.4
mm, 0.75 At the case with a throat area 25% smaller
(throat diameter: 20 mm) and 1.25 At with a throat area
25% larger (throat diameter: 25 mm).
The inlet area has always been assumed to be the same
as the outlet one.
In all the three cases, the engine was run at WOT
from 5500 to 10500 rpm.

Figure 10. Total pressure at the inlet and the outlet of the
sonic restrictor.

In the case of the largest throat area 1.25 At, the
flow through the nozzle was isentropic and the total
pressure across the sonic restrictor remained constant
as shown in Figure 10, where the total pressures at the
inlet and outlet of the sonic restrictor are plotted.

Figure 9. Boolean on the choked condition, true means
that the restrictor is choked.
Figure 11. Mach at the sonic restrictor throat.

DOI
10.3384/ecp17132181

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

185

Investigating the Effect of a Sonic Restrictor in the Intake of an Engine

The Mach at throat reached 0.8 at 10500 rpm, the
engine torque, the engine power and the engine air
mass flow rate followed the same trends as in a nonrestricted engine.
The engine torque reached its maximum at around
9000 rpm, the engine power reached its maximum at
around 10000. At 10500 rpm the engine torque was
already decreasing relatively steeply, while the engine
power had just started to decline.
The mass flow rate increased following the engine
speed ramp, as shown in Figure 14.

shock to keep a constant mass flow, and the stronger
shock corresponds to increased total pressure losses, as
shown in the total pressure chart in Figure 10.
After the sonic speed was reached at throat, the mass
flow rate was limited to the choked value and at 10500
rpm the mass flow rate was 13% lower than in the nonchoked case.

Figure 14. Normalised engine air mass flow rate.

Figure 12. Normalised engine torque.

Figure 15. Volumetric efficiency.

Figure 13. Normalised engine power.

For a throat area At, the sonic condition was reached
at 9450 rpm, as shown in Figure 9.
Seemingly surprisingly, both the engine torque and
the engine power decreased substantially at higher
speeds (by around 18% with respect to the non-choked
condition at 10500 rpm). This happens because of the
sonic restrictor losses associated to the shock. As the
static pressure required by the engine downstream the
sonic restrictor decreases, the nozzle needs a stronger
186

By reducing the throat area a further 25%, the
simulations showed that the shock was reached at a
lower engine speed (8760 rpm).
An important result to outline is that the shock was
stronger in case of a smaller throat area, as shown by
the greater total pressure drop in Figure 10 (from 1 bar
to 0.73 bar at 10500 rpm).
At 10500 rpm both the engine torque and the engine
power were around 40% lower than in the case without
shock.
For the same speed, the engine air mass flow rate
was around 30% less than in the case without shock.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132181

Session 5A: Automotive II

The drop in efficiency and power for the smallest
throat area is clear also from Figure 15, where the
volumetric efficiency is plotted.
The case with the smallest throat area shows clearly
that the engine should not operate at speeds much
higher than the one at which the sonic condition is
reached. This suggests that the rev limiter should be set
not far from the engine speed at which the air flow
through the sonic restrictor becomes choked.
Furthermore, for a given displacement, engines with
a higher torque at lower rotational speeds are likely to
produce a higher power before the sonic restrictor
becomes choked, thus bringing an advantage over ones
optimised for higher regimes.

5

Casella F., Otter M., Proelss K., Richter C., Tummescheit H.,
The Modelica Fluid and Media library for modeling of
incompressible and compressible thermo-fluid pipe
networks, Proceedings of the 5th Int. Modelica Conference,
Vienna, 2006.
Anderson J., Modern Compressible Flow: With Historical
Perspective (Aeronautical & Aerospace Engineering),
McGraw-Hill Education; 3rd edition, 1 Aug. 2002.
Hendricks, E., Chevalier, A., Jensen, M., Sorenson, S. et al.,
Modelling of the Intake Manifold Filling Dynamics, SAE
Technical Paper 960037, 1996, doi:10.4271/960037.
Picarelli, A., Dempsey M., Investigating the multibody
dynamics of the complete powertrain system, Proceedings
7th Modelica Conference, Como, Italy, 2009. doi:
10.3384/ecp09430085

Conclusions

In this paper a sonic restrictor was integrated in an
engine model to analyse the effect of choked flow
through a nozzle on the engine mass flow rate, engine
torque and engine power. Three cases with decreasing
throat areas were analysed to assess the effect of the
throat diameter on the shock intensity.
The full load curve showed that a considerable torque
and power drop was reached after the choked
condition, highlighting the need of limiting the
maximum engine speed around the one at which the
nozzle starts to be choked.
The study shows how Dymola can be used to
analytically solve the fluid mechanics in engines. Of
course, a quasi-1D code cannot solve phenomena such
as flow separation and boundary layer development,
but it can solve the shock and the compressible
chocked flow, making it a good starting point for
testing and development of restricted engines.

DOI
10.3384/ecp17132181

References

Roberts, N., Dempsey M., Picarelli A., Detailed Powertrain
Dynamics Modelling in Dymola  Modelica, IFAC
Proceedings Volumes, 2013, doi: 10.3182/20130904-4-JP2042.00111

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

187

188

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Engine thermal shock testing prediction through coolant and
lubricant cycling in Dymola
Eduardo Galindo1

Rodolfo Soler1

Alessandro Picarelli2

Victor Avila2

1

AVL IBERICA SA - VALLADOLID, Spain, {Eduardo.Galindo, Rodolfo.Soler}@avl.com
2
Claytex Services Ltd.  Leamington Spa, UK, {alessandro.picarelli}@claytex.com

Abstract
In this work, an acausal multi-domain physical system
model is used to study the interaction between an
internal combustion engine operation and a range of
cooling and lubrication system thermal cycling
scenarios. Although the model can be used for
modelling a wide range of scenarios, this paper
concentrates on the application of engine thermal shock
test dynamics prediction through coolant and lubricant
cycling. An internal combustion engine is loadcontrolled on a dynamometer. Coolant and lubricant
temperature transients are imposed on the engine
system. Using freely available and commercial
Modelica Libraries within the Dymola environment, the
systems integration of the coolant rigs, lubricant rigs and
engine is achieved. The rigs and the controllers are
validated against test data to create predictive models of
such systems for test virtualisation. This allows the user
to develop and define control strategies for the tests
from desktop, prior to engaging in laboratory tests.
Keywords: Engine testing, thermal-shock, control
system development

1

Introduction

Engines need to work under a variety of temperature
conditions. Some engine failure modes are caused by
temperature cycling which in turn causes thermal
expansion and contraction of the components. This
phenomenon can induce mechanical stresses which in
extreme cases can lead to component failure.
This paper builds on (Picarelli et al, 2014) and seeks to
validate engine coolant and lubricant conditioning rigs
for virtualisation of test scenarios in order to predict the
system behaviour and to tune the control systems prior
to the real testing taking place.
In addition to previous tests, where only the engine
coolant was conditioned, in this paper we present
thermal shock testing where the dynamics of the
lubrication system are also included.

DOI
10.3384/ecp17132189

2

Thermal shock testing

Many manufacturers carry out thermal shock tests to
understand and prevent component failure, as well as to
accelerate durability testing of engines and engine
components, including cylinder-head gaskets.
Thermo-mechanical fatigue is the term used to describe
the type of fatigue in which temperature is varied
throughout a cycle. The maximum tensile strain occurs
at the same time as the maximum temperature.
Maximum compressive strain occurs at the minimum
temperature. The main factor causing thermosmechanical failure is a large number of temperature
cycles. As in fatigue testing, it is possible to accelerate
thermal cycling failure modes by increasing the
frequency or amplitude of the thermal cycles.
These thermal tests are used to simulate critical
conditions inside the engine by circulating a coolant
flow with very large temperature gradients occurring
over short periods of time (e.g. 30C to 120 C). This
cycle is repeated a several times.
The main task performed in this study is simulation of
repeated hot/cold thermal cycles. The engine is cycled
between rated power and idle speed. The coolant and
lubricant are also cycled between hot and cold
temperatures by means of external conditioning units.

Figure 1. Example of an engine thermal shock cycle.
Engine speed shown in red and coolant outlet temperature
from engine shown in blue (C).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

189

Engine thermal shock testing prediction through coolant and lubricant cycling in Dymola

The temperature gradient in the warm up and cooling
down cycles is critical to generating the mechanical
stresses applied to the engine due to the thermal shock.
These kinds of tests allow manufacturers to reproduce
the whole life of an engine in about 500 hours for a light
duty passenger car and 2000 hours for a heavy-duty
vehicle. Manufacturers expend great efforts in obtaining
a good correlation between specific tests and the actual
lifetime of an engine. Once the correlation is completed,
the test must be performed as accurately as possible to
preserve this correlation.

a maximum speed of 5600 rpm, yielding a maximum
power of 76.2kW.
The physical model is tested in two relatively different
scenarios, which are as follows:
1. Thermal-shock test with low temperature gradients
for heating and high temperature gradients for cooling,
running between 110C and -30C. This test also
includes the cooling of the engines oil down to -20C.
In advance well refer to this test cycle as
Thermalshock 1:

Figure 3. Temperature path for the engine coolant (black)
and oil (red) for Thermalshock 1.
Figure 2. Cracks in the valve seat produced by thermal
stress.

3

The need for a simulation model

An accurate and representative simulation model allows
us to reduce engineering time for the prediction of new
tests and design of new systems giving us the ability to
predict the behaviour of a given system before
manufacturing it.
This simulation ability also allows us to change the test
or equipment parameters and foresee their impact on the
results. This way, we can have a better view on how the
system will behave, so that any specific issue or change
can be adapted quickly and easily.
Furthermore, the simulation model has already
predicted some unexpected and unwanted behaviours
such as pressure spikes, giving the opportunity to make
the necessary corrections early enough, thus avoiding
additional engineering efforts and potential system
failures.

4

Figure 4. Throttle position of the engine for the
Thermalshock 1 (solid line) and engine speed (dashed
line).

2.
Hot and cold test, with low temperature
gradients for both cooling and heating, but with high
frequency heat transients produced by quick variation
on the engine throttle position. Hereon we will refer to
this test cycle as Thermalshock 2.

Case Study

The thermal shock rig system in this study was intended
to test engines from 60 kW to 120 kW, with an engine
mass of 90kg to 120 kg. This power was limited by a
maximum torque of 130-250Nm and a maximum speed
of 6700rpm.
The actual engine used in the real test was a 4-cylinder
gasoline engine with a maximum torque of 130 Nm and
190

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132189

Session 5A: Automotive II

Figure 5. Temperature profile for the engine coolant and
oil for the Thermalshock 2.

Figure 7. Complete systems simplified P&ID (Piping and
Instrumentation Diagram).

4.2

Figure 6. Throttle position of the engine for the
Thermalshock 2 (solid line) and engine speed (dashed
line).

These two tests are important in order to check the
durability of their internal combustion engines, specially
focused on the endurance of the head gaskets which are
particularly affected by the thermal stress.

4.1

Thermal Shock Equipment Concept

The equipment consists of several fluid conditioning
devices all connected to each other and/or the engine
(Figure 7). Given that the thermalshock test itself has
two well differentiated parts (hot part and cold part),
there are two cool-ant conditioning devices and a further
device that switches the connection of the engine
between them.
Since the oil has to be conditioned too, the engine is
connected to a heat exchanger on the gallery
connections (the engines oil pump is responsible for the
flow), and to an oil cooling device on the sump.

DOI
10.3384/ecp17132189

Thermal Shock Testing Equipment

Coolant conditioning unit:
Composed of a pump and a 3-way valve that directs the
coolant through a heat exchanger (for cooling) or a
heating resistance (for heating).
Switch over valves:
A device composed of several 2 way pneumatic valves
that allows the engine to be connected either to the
coolant conditioning unit (Consyscool) or to the
thermalshock chiller. This way the valves connect the
engine to the coolant conditioning unit during the hot
phase, and to the chiller during the cold phase.
Thermalshock chiller:
Composed of a water chiller specially designed and built
for engine thermalshock testing. A pump flows the
coolant from the inertia tank to the engine and to the oil
cold heat exchanger.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

191

Engine thermal shock testing prediction through coolant and lubricant cycling in Dymola

5
5.1

Model Development
Engine Model

The engine type used on the rig is a 1.8l turbo-petrol
inline 4-cylinder engine.
The engine model in these tests is a thermal
representation of the real engine which includes heat
rejection from combustion to the coolant, lubricant and
the engines thermal mass.

Figure 8. Thermalshock chiller picture showing the large
water tank on the left and the controllers and valves on the
right hand side.

The design of this chiller is specially customized for
engine testing, with special features like a on-standby
design that allows the system to be ready for a
thermalshock at any time (Figure 8).

Figure 9. Thermalshock chiller controller screen.

The controller of the chiller is custom-designed for the
engine testing process, with several programming
parameters, interface with the testing facilities and
remote control for operation and diagnosis (Figure 9).
High temperature oil conditioner (see Figure 12):
Consisting of a plate heat exchanger which is connected
to a conditioning unit (similar to the engine coolant
conditioning unit). The oil is cooled by means of a coldwater heat exchanger.
Low temperature oil conditioner (see Figure 12):
Consisting of an oil pump (variable speed), and a heat
exchanger cooled by the same chiller used for cooling
the engine coolant.

192

The engine heat release to coolant and lubricant has
been defined as a fraction of the crank power and varies
depending on engine speed and load. The fraction value
is determined from steady state tests by calculating the
power required for the coolant and lubricant temperature
changes between the inlets and outlets of the engine
circuits. The fluid paths within the engine are
represented by a single pipe having average diameter of
the passageways and the measured total engine pathway
volume and surface area. The pipe dimensions are
adjusted to achieve the required flow velocities through
the engine.
The engine thermal mass used in this study is a lumped
thermal mass and is not split by subsystem. More
detailed models are available within the Claytex
Engines library for studies which require higher level of
engine thermal mass discretisation. The engines library
was used in a previous study (Dempsey et al, 2009;
Dempsey et al, 2012; Dempsey et al, 2013; Picarelli et
al, 2014).
The coolant pump of the engine is replaced by electric
coolant pumps within the rig which can be controlled to
deliver specific flows or flow profiles. The lubricant
pumped by the engine lubricant pump itself when the
engine is running. An electric lubricant pump within the
rig is used when the engine is switched off.
The heat transfer from the engine to the coolant is
calculated by means of a Nusselt Number correlation,
calculated specifically for this engine. The Nusselt
Number (Nu) correlation is then used within the pipe
model which represents the coolant path within the
engine. Due to the fact that the thermal mass of the
engine is of lumped type, the volume model used to
represent the mass of coolant within the engine has one
thermal node. The same Nu correlation can be
implemented with multiple node fluid pipes derived
from the Modelica.Fluid library should a more detailed
thermal discretisation be required and will be the subject
of further work when engine CAD data becomes
available. This will also increase the predictive
capabilities of the model. The exact same Nusselt

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132189

Session 5A: Automotive II

Number heat transfer approach is used for the heat
exchangers in the rig model described in section 5.2.

5.2

Rig Model

The thermal shock rig must be able to supply
preconditioned coolant to two different flow
conditioning units and by means of a switch valves
device controls the engine fluid temperatures. The rig
described in this paper uses a 2000 litre coolant tank
kept at temperature with fixed set-points and an external
source which supplies water permanently. The water
tank is kept at constant ambient temperature and the
coolant tank is kept at low temperature, around -30 C
(Figure 10. Complete thermal shock rig with water tank
(1), coolant tank (2), Mean Value engine model (3)).
The tanks are required to also smooth out and absorb
any temperature fluctuations in the rig, in addition to
these two tanks, there are also some small expansion
tanks included throughout the rig to absorb any possible
pressure, temperature and volume fluctuations.

4

6

Figure 11. Switch over valve model used in the rig to lead
the coolant from the different heat exchangers through the
engine.

Both lubricant conditioning units (see Error!
Reference source not found.) are included in the same
model (Figure 12. Oil conditioning unit DiagramFigure
12).

3
3

1a
2

5
1b
Figure 10. Complete thermal shock rig with water tank (1),
coolant tank (2), Mean Value engine model (3), coolant
conditioning (4), lubricant conditioning (5) and hot/cold
switchover valve (6).

At particular points in the cycle, the switchover valves
(Figure 11) model and the internal valves of the
conditioning units before described, are controlled to
channel either hot or cold coolant through the engine.
These changes in coolant and lubricant temperatures
yield the required thermal shock for the engine to
experience and operate through.

DOI
10.3384/ecp17132189

1

Figure 12. Oil conditioning unit Diagram: High
temperature conditioner (1), plate heat exchanger (1a), cold
water heat exchanger (1b), low temperature conditioner (2)
and electric pump (3).

The rigs are modelled using the Modelica.Fluid and
Modelica.Media libraries (Casella et al, 2006) with
some customized components from the Claytex library
which incorporates advanced functionality within the
components both for visualization and enhanced model
efficiency. The fluids used match that of the rig in terms
of properties and are a mixture of 50% Ethylene Glycol
and water with linear compressibility for the coolant

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

193

Engine thermal shock testing prediction through coolant and lubricant cycling in Dymola

side and Oil with constant compressibility for the
lubricant side.
The controller for the tank cooler is of on/off type and
starts to cool with 40.4 kW of power when the tank fluid
temperature has deviated from the set point by +1 C.

Figure 14. StateGraph controller for the internal coolant
conditioning unit 3-way valve.

Figure 13. PID controllers for controlling the coolant and
lubricant conditioning units and chiller tank to maintain the
corresponding fluid temperatures close to the set points.

To control the 3-way valves, within the fluid
conditioning devices, a Modelica.StateGraph model was
used which is shown below (Figure 14). The valves are
operated to route the coolant and the lubricant through
the heat exchangers or bypassing them to restore desired
temperature targets at particular points in the cycle.
The same type of StateGraph model controls the throttle
pedal position which is cycled from 0-100% in a similar
phase to the engine speed (Figure 15).

Figure 15. Resulting accelerator pedal position (top) and
engine speed (bottom) for the thermal shock test.

194

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132189

Session 5A: Automotive II

Results

6
6.1

Initial Results from Dymola

Before the actual rig commissioning tests were
undertaken, the Modelica system model was already
finished, and showing the following expected results:
Thermalshock 2:

Figure 17. Dymola initial Thermalshock 1 stability
estimated as 0.5 C with only low frequency oscillations
on the hot phase an asymptotic cooling up to -30C on the
cold phase.

6.2

Experimental Results

After the commissioning of the actual real life system,
the following data was gathered:
Thermalshock 2 experimental results:

Figure 16. Dymola initial Thermalshock 2 stability
estimated as 0.6C with only low frequency and
amplitude oscillations.

Thermalshock 1:

Figure 18. Real Thermalshock 2 results, with higher
frequency oscillations and a maximum amplitude of 3C.

At first sight it was seen that the expected accuracies
and oscillation frequencies were underestimated.

6.3

Model Adjusting

Since the same system model was used for both tests,
the model validation strategy was as follows:
For the thermalshock 2 tests, the real PID control
parameters used for the test were recorded. Then, these
PID parameters were introduced to the Dymola model.
Next, the following parameters where adjusted in order

DOI
10.3384/ecp17132189

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

195

Engine thermal shock testing prediction through coolant and lubricant cycling in Dymola

to have similar paths on the engine outlet coolant
temperature:



Engine thermal mass and heat transfer
coefficient
3-way valve actuation speed

The following parameters/model properties did not
require adjustment:












Validation

After checking the model was running accurately
simulations on the Hot-Cold tests, all the tuned
parameters where frozen, thus obtaining a validated
mathematical model.
This model was then used for the Thermalshock 1 test,
with the following results:

Fluid properties
Pipe/ducting geometries
Bend losses
Heat exchanger pressure drops
Heat exchanger performance and thermal
coefficients
Pump flow characteristics
Pump loss characteristics
Valve losses
Engine combustion heat release
Engine combustion heat release
Engine inertia

The 3 tuned parameters had different effects on the
modelled outlet temperature of the system, and
modifying them one by one the following results were
achieved:

Figure 19. Adjusted Dymola model, running a
Thermalshock 2 test, with higher frequency variations and
maximum amplitudes of 1.75C on the coolant outlet
temperature.

Although the maximum amplitudes measured in the
experiment and model results differed (larger in the
experiment results: 3C vs. 1.75C, the average
temperature and remaining oscillations we of similar
value: 1C vs. 0.8C.
196

6.4

Figure 20. Validated Dymola model, running a
Thermalshock 1 test, with higher frequency variations and
amplitudes of 2.7C on the coolant outlet temperature on
the hot phase, and asymptotic cooling on the cold part.

Where the Thermalshock 1 experimental results were:

Figure 21. Real Thermalshock 1 results, high frequency
oscillations and amplitude of 2.5C.

After model validation and calibration using the hotcold results, the results for the thermalshock tests were
much more realistic, proving that the model can be used
for any test made using the same system, regardless of
the test conditions.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132189

Session 5A: Automotive II

Figure 22. Comparison of the thermalshock 1 real results
(black) and the validated Dymola model (blue).
Further investigation is required to confirm the reason for
which the higher temperature oscillations in the model are
half those measured in the experimental results. Further
tuning of the valves pressure drops, hence flow speeds in
this operation mode might improve the discrepancy.

6.5

Lubricant Dynamics Validation

Despite the rig model being prepared to also simulate
lubricant
conditioning
and
heating
(

Figure 23), technical issues in the real rig suggested the
lubricant measurement data could have been
compromised, hence preventing detailed validation of
lubricant conditioning (Figure 24).

Figure 23. Example of the non-validated results for the
lubricant temperature (blue line), running Thermalshock 1
test. Throttle position is also displayed (red line).

DOI
10.3384/ecp17132189

Figure 24. Comparison of the Thermalshock 1 real results
(Orange) and the non-validated Dymola model (blue)

This validation will be the objective of a further
investigation in the future.

7

Conclusions

After adjusting the Modelica model parameters, the
simulation results were much more realistic. Even
though the systems hysteresis/entropy is still a
parameter that cannot be simulated and produces nonperiodic oscillations, the more significant results such as
temperature accuracies, heating and cooling times are
correctly simulated and can predict an actual behaviour
of a system under different test scenarios with an
accuracy of 0.5C.
The information about the engines thermal mass and
global heat transfer coefficient will be useful for future
projects with similar engines. Even with different
engines, these parameters are now a starting point for
estimating these values otherwise impossible to know.

References
Casella. F. et al. (2006) The Modelica Fluid and Media
library for modeling of incompressible and compressible
thermo-fluid pipe networks Modelica Conference, 2006
Dempsey M., and Picarelli A. (2009). Investigating the
multibody dynamics of the complete powertrain system.
Como, Italy: Proceedings 7th Modelica Conference.
Dempsey M., Picarelli A, Fish G. (2012). Using Modelica
models for driver-in-the-loop simulators. Munich,
Germany: Proceedings 9th Modelica Conference.
Dempsey M., Roberts N., Picarelli A. (2013) Detailed
Powertrain Dynamics Modelling in Dymola  Modelica.
IFAC-AAC conference Tokyo, Japan.
Picarelli A., Galindo E., Diaz G. (2014) Thermal shock
testing for Engines in Dymola. Lund, Sweden. 10th
Modelica Conference, 2014

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

197

198

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Template based code generation of
Modelica building energy simulation models
Christoph Nytsch-Geusen1 Alexander Inderfurth1 Werner Kaul1
Katharina Mucha1 Jrg Rdler1 Matthis Thorade1 Carles Ribas Tugores1
Institut fr Architektur und Stdtebau, Berlin University of the Arts, Germany, nytsch@udk-berlin.de

1

Abstract
This contribution describes an approach for a template
based code generation for different detailed Modelica
models for building energy simulation (BES).
The information from several data sources, which
describe the building geometry, the building
construction, the building location and the building
itself, is used to fill a building data model. This
intermediate data structure is still independent of a
certain building simulation tool.
A new developed tool for template based code
generation (CoTeTo) uses the building data model and
combines it with a set of different code generators,
which are able to generate Modelica building models
with a different level of detail: Strong simplified loworder building models for district energy simulation
with a large population of buildings, more advanced
multi-zone building models for building energy
simulation and 3D space resolved room models for a
detailed indoor climate analysis.
Three case studies for the mentioned building model
types demonstrate the code generation approach.
Keywords: building energy simulation, adapted model
level of detail, Modelica code generation

1

Introduction

Template based code generation

2

A general approach for code generation of BES models
has to consider the heterogeneous data formats (data
sources) in the building industry sector and should be
able to generate models with a different level of detail,
which fits to the question of the simulation analysis.
Data sources

The generation of machine-readable code usually
combines static and dynamic data sources. The static
part describes the keywords and syntactical
requirements of a computer language and builds a static
framework while the dynamic part injects real values
and structures from the runtime environment of the
code-generating application or from an external data
source. In the simplest case the application uses some
(potentially nested) print()-like statements. This
approach has some limitations because even the smallest
change in the output format requires access to the source
code of the application, programming skills and
potentially large compile cycles.
With the rise of dynamic web-sites a more flexible
technology was widely used and much improved: the
template engines. Such an engine is a program library

DOI
10.3384/ecp17132199

linked into an application, but the process of the code
generation is controlled by external text files. These
template files embed simple control structures and
placeholders in normal text and can be easily edited. The
concept is similar to the serial letter function in word
processing applications.
The idea of code generation for Modelica BES
libraries was first applied within the EnEff BIM project.
In this project the structured data of an IFC files were
used for the automatic generation of Modelica system
models, consisting of a HVAC sub-model and a strong
simplified building model (for more details see Thorade
et al., 2015).
This contribution is focused on code generation for
Modelica building energy models with different levels
of detail. Important information for the code generation
are the building geometries, the building topologies, the
building constructions, the building locations and the
behavior of the building occupants.

Data mapper

IFC

Type A

CityGML

Type B

JSON

Type C

Building data model

Template based
code generator

Geometry

Generator 3 D

Topology

CoTeTo

Construction

Generator 1 D

Type D

Building use

Room model

Building model

Ambient data

MySQL
Database

Generated models

Generator 0 D
District model

Figure 1. Template based code generation of BES models
with a different level of detail

A set of data mappers transform the input data into a
common building data model. Dependent on the present
information within this data model one or more template
based code generators can produce Modelica BES

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

199

Template based code generation of Modelica building energy simulation models

models for room simulation, building simulation or
district simulation (compare with Figure 1).

2.1 Data sources
In the building industry sector, there are different data
sources and data formats available, which can satisfy the
needs of the building energy simulation domain. On the
scale of single buildings, the IFC-Format in the version
IFC2x3 (IFC2x3, 2017) can be used and in near future
also the version IFC4 (IFC4, 2017). This format
represents the digital building model in a well-structured
form (the entire building, several spaces, walls,
windows etc.) in combination with a precise description
of the building geometry. Most of the architecture CAD
programs can export the IFC data format. It fits perfect
to the structure of a multi-zone-building model (building
model, thermal zones, building components) and the
precise
geometrical
data
also
allows
the
parameterization of spatial resolved room models.
On the scale of city districts the CityGML format
(CityGML, 2017) and the GeoJSON format (GeoJSON,
2017) can deliver the necessary building parameter for
district energy models. Normally, GIS programs are
able to export one or both of these data formats with
simplified building geometries, which fits to the reduced
parameter sets of the low-order building models on the
district model scale. In this case, the challenge consists
in the data acquisition of huge populations of buildings
and not for a single building (Kaul et al., 2014).
In special cases, building parameter sets are also
available in data base formats, e.g. MySQL (Inderfurth
et al., 2017).

building topology (substructure of a building in thermal
zones), the used construction types (multi-layer
definitions), the definition of the building ambient data
(location, weather data) and the type of building use
(e.g. air change rates, set temperatures for heating and
cooling etc.). The building data model itself is
independent of the type of the data sources (but it has
functions for setting building parameters from data
sources) and also on the type of the code generator
(different code generators use the same function to get
building parameters from the building data model).

2.4 CoTeTo
To automate some of the required steps for the
generation and parametrization of Modelica code a
software tool (Code Templating Tool) was developed in
the context of the EnEff-BIM project (Thorade et al,
2015). CoTeTo (CoTeTo, 2017) comes with an open
source license and can be download from GitHub
(https://github.com/UdK-VPT/CoTeTo). It includes
pluggable input, filter and output components that cover
the process of data acquisition, preprocessing and output
using a template system. CoTeTo is implemented in
Python and can be used standalone or as a library
imported in Python applications. A command line
interface is provided for interactive usage or inclusion
in shell scripts. A GUI based on PyQt4 (PyQt4, 2017)
can be started as an application (see Figure 2Figure 1) or
included in PyQ4-based applications as a widget.

2.2 Data mapper
A data mapper is a specialized software module, which
is able to map a certain data source file format to the
format independent building data model (see paragraph
2.3). Two different data mappers were realized based on
Python up to now: the first data mapper can be used for
1-dim. multi-zone-building simulation and 3-dim. room
simulation and uses the IFC format as the data input.
The Python bindings of the IfcOpenShell-library
(IfcOpenShell, 2017) are used to read the IFC-files and
Python bindings of the OpenCascade-library
(pythonOCC, 2017) are used to transform in a second
step the geometrical and the topology data in a manner,
that they can be stored in the building data model. The
second data mapper was implemented for district energy
simulation and can read the GeoJSON-format. A third
data mapper for information input from SQL data bases
is under development.

2.3 Building data model
The building data model holds all the information,
which is necessary for the Modelica code generation.
This includes the data for the building geometry (full
geometrical description or simplified geometry), the
200

Figure 2. CoTeTo GUI for template based code generation

CoTeTo uses the Mako template engine (Mako,
2017) for the code generation step, but an experimental
interface to the Jinja2 engine (Jinja2, 2017) is
implemented as well.

2.5 Generators
CoTeTo documents (called generators) can be easily
edited and shared without deep programming
knowledge. A generator is stored in a folder structure or
a zip file containing plain text files. The idea of a
generator is to include all parts necessary to generate the
code for a defined target (like a certain Modelica
buildings library) form a defined source (like a special
file format or database structure).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132199

Session 5B: Buildings II

A generator depends on a so-called input API, which
is defined in a Python module. Some standard input
APIs are included in CoTeTo (CSV, JSON, XML, ),
but generators can define own input modules. Between
the data input and the output templates filter functions
can be called to preprocess the data structure. These
Python functions are defined in the generator.
The CoTeTo framework handles this conversion
process completely data-agnostic, the structure and
format of the data objects is defined by the input APIs,
generators and filter functions only.

2.6 Adaption to the BuildingSystems library
Based on the CoTeTo framework three code generators
for
the
Modelica
BuildingSystems
library
(http://www.modelica-buildingsystems.de) were implemented. This library is being developed for the dynamic
simulation of the energetic behavior of single rooms,
multi-zone buildings or entire city districts (NytschGeusen et al., 2016). The simulation models of the
library describe the dynamic energy balance of the
building envelope under consideration of the building
geometry, the thermal properties of the building
construction, the ambient climate and the user behavior.
As the Modelica library IDEAS, AIX Lib and Buildings,
the BuildingSystems library uses as a core the same
Annex 60 Library, which was developed as a common
project from the authors of the four mentioned libraries
in the Annex 60 project (Wetter et al., 2015).
The predefined components of the BuildingSystems
library such as air volumes models, building
construction models, wall and window models, zone
models, low-order building models or ambient models
(compare Figure 3, Figure 6 and Figure 10) are the base
for the generated Modelica code. These model classes
include the physical description (energy and mass
balances, empirical equations etc.) and are instantiated
and parameterized by the code generator using the
information, which is stored in the building data model.
The following code shows as an example the Mako
code, which generates the Modelica records for the
definition of all multi-layered opaque constructions of a
building model:
% for con in constructions:
record ${con.name}
extends OpaqueThermalConstruction(
nLayers=${con.nLayers},
thickness={
% for value in con.thickness:
${value}${',' if not loop.last else ''}
% endfor
},
material={
% for value in con.material:
${value}()${',' if not loop.last else ''}
% endfor
});
end ${con.name};
% endfor

DOI
10.3384/ecp17132199

Based on the stored information in the building data
model the code generator generates for example the
code for three different building constructions:
record ConstructionFacade
extends OpaqueThermalConstruction(
nLayers=4,
thickness={0.015,0.2,0.15,0.02},
material={
HighGradePlaster(),
Concrete(),
ExpandedPolystyrene(),
HighGradePlaster()});
end ConstructionFacade;
record ConstructionInnerWall
extends OpaqueThermalConstruction(
nLayers=3,
thickness={0.015,0.12,0.015},
material={
HighGradePlaster(),
Kalksandstein1800(),
HighGradePlaster()});
end ConstructionInnerWall;
record ConstructionBottom
extends OpaqueThermalConstruction(
nLayers=3,
thickness={0.02,0.06,0.2},
material={
Wood(),
WoodFibreInsulation(),
Concrete()});
end ConstructionBottom;

3

Case studies

The case studies shall demonstrate the general
approach for template based Modelica code generation
for building energy simulation. The examples address
three different scales of building simulation: District
modelling, multi-zone modelling and single room
modelling.

3.1 City district
The first case study considers a city district in BerlinKreuzberg, which was designated by the Berlin city
government as a redevelopment area (SenStadtWohn,
2016). In this context an analysis about the present
energy efficiency of the building stock within this areal
will be of interest. Because the whole district includes
144 buildings, the challenge for a district energy model,
which could describe the present energy demand,
consists in the data gathering of a huge parameter set
(geometries, U-values etc.) for all buildings.
Data source: In the former research project Open
eQuarter, a new layer-oriented geographic information
system (GIS) based method was developed to obtain
building sharp parameter data sets (Kaul et al., 2014).
For this purpose, different city maps with information
such as the building outlines, the number of stories, the
building age in combination with a data base with Uvalues of the building elements were used, dependent on
the building age (Loga et al., 2015). The open source
GIS tool QGIS (QGOS, 2017) in combination with the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

201

Template based code generation of Modelica building energy simulation models

Open eQuarter plugin is able to export a GeoJSON file,
which includes all the necessary building parameters
(location, simplified building geometries, U-values)
gained and calculated by the mentioned data sources.
This GeoJSON file serves as the data input for the
building data model in Figure 1.
Data mapper: In a first step the building data model
takes the information through a data mapper from a
GeoJSON file, which contains beside the mentioned
building parameters also the building outlines for each
building as polygon points. A python filter function
calculates the centroids of these polygons to obtain the
local placements of the building models within the
district model. After this intermediate step all needed
building data are stored in the building data model and
can be used afterwards by the Modelica code generator.
Components:
Two
components
of
the
BuidingSystems library are used for the code generation
(see Figure 3). First, an ambient model, which describes
the climate boundary condition of the city district, in
particular the outside air temperature and the solar
radiation on the building surfaces. Second, a low order
building model (described in Nytsch-Geusen and Kaul,
2015), which is able to calculate the dynamic heating
and cooling demand for an individual building with a
small set of input parameters.

Building1Zone0DDistrict building2(
UValFac = 1.83,
UValRoo = 1.23,
UValGro = 1.2,
UValWin = fill(3.1,4),
fWin = 0.294,
length = 48.020794,
width = 7.903955,
heightSto = 3.0,
nSto = 4)
annotation(Placement(transformation(
extent={{29.574,1.040},{19.574,11.040}})));
...
Ambient ambient(
nSurfaces = 720,
weatherDataFile = WeatherDataFile_Berlin());
equation
connect(ambient.toSurfacePorts[1:5],
building1.toAmbientSurfacesPorts[1:5]);
connect(ambient.toAirPorts[1:5],
building1.toAmbientAirPorts[1:5]);
connect(ambient.TAirRef, building1.TAirAmb);
connect(ambient.xAir, building1.xAirAmb);
connect(building1.airchange[1],airchange.y);
connect(building1.T_setHeating[1],TSetHeating.y
);
connect(building1.T_setCooling[1],TSetCooling.y
);
...
connect(ambient.toSurfacePorts[6:10],
building2.toAmbientSurfacesPorts[6:10]);
connect(ambient.toAirPorts[6:10],
building2.toAmbientAirPorts[6:10]);
...
end DistrictModel;

Figure 3. Components for district modelling.

Code generator: During the code generation the
building centroids are used for component related
annotations, which defines the graphical appearance of
the individual building models on a realistic position.
This is possible, because the positions of each individual
building were gained from geo-referenced maps
(compare with Figure 4). The excerpt of the generated
code shows the instantiation and parameterization of the
first two building models of the district, the ambient
models and the connections between the ambient model
and the two building models:
model DistrictModel
extends Modelica.Icons.Example;
Building1Zone0DDistrict building1(
UValFac = 0.371,
UValRoo = 0.269,
UValGro = 0.4,
UValWin = fill(1.575,4),
fWin = 0.21,
length = 8.127566,
width = 5.318865,
heightSto = 3.0,
nSto = 4)
annotation(Placement(transformation(
extent={{0.0,0.0},{10.0,10.0}})));

202

Figure 4. Generated Modelica district model with 144
low-order building models (the City map is taken from
OpenStreetMap, https://www.openstreetmap.org)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132199

Session 5B: Buildings II

3.2 Multi-zone building
The second case study demonstrates the code
generation of a multi-zone building model (a storey of
an office building) with thirteen thermals zones. It
includes eight single office rooms, each of them with the
same floor space, oriented to the North. Second, it has
a bullpen with a large south oriented window and a
smaller west oriented window. Beside the bullpen a
conference room is attached, which has also a south
oriented window. Further the story includes two sanitary
rooms without windows and a corridor, which divides
the north oriented by the south oriented rooms as a
thermal buffer zone.
Data source: The building was constructed in
Archicad 19 (see Figure 5) and afterwards exported as
an IFC2x3 file. This model includes a precise
description of the building geometry, topology and also
the information about the layered construction of the
building (used materials and the thicknesses of each
layer).

First for the generation of the Modelica code of the
thermal multi-zone building model (see Figure 7) and
second for a corresponding C# script, which is able to
visualize the simulation results within a 3-dimensional
building model (see Figure 8), based on Unity 5
(Nytsch-Geusen et al., 2017).

Figure 7. Generated Modelica multi-zone building model
with 13 thermal zones.

The excerpt of the generated code shows the
instantiation of the individual opaque and transparent
building elements, thermal zones and their connections
to a multi-zone building model (model Building). In
the next step this container class is instantiated and
connected on a higher level together with the ambient
model to the Modelica system model (model
MultiZoneBuilding):
model MultiZoneBuilding
extends Modelica.Icons.Example;

Figure 5. Building model, constructed in Archicad 19.

Data mapper: The data mapper reads the IFC file
and analyses the building geometry and modifies if
necessary the topology. For example, the south faade
of the building is constructed in the CAD tool as one
continuous element, but it has to be divided into two
individual thermal wall models, because these models
will have different thermal boundary conditions in a
multi-zone building model. After this analysis the
building data is stored in the building data model.
Components:
Different
models
of
the
BuildingSystems library (opaque and transparent
building element models, zone models, building
template models etc. and again an ambient model) are
used as the base for the code generation (see Figure 6).

Figure 6. Components for multi-zone modelling.

Code generator: In this case study the stored
information in the building data model is used twice:
DOI
10.3384/ecp17132199

record ConstructionFacade
extends OpaqueThermalConstruction(
nLayers=4,
thickness={0.015,0.2,0.15,0.02},
...
model Building
extends BuildingTemplate(
nZones = 13,
surfacesToAmbient(nSurfaces = 43),
nSurfacesSolid = 13, ...);
// building zones
ZoneTemplateAirvolumeMixed office1(
V=36.0,height=3.0,
nConstructions1=8,...);
...
ZoneTemplateAirvolumeMixed bullpen(
V=450.0,height=3.0,
nConstructions1=11,...);
// constructions elements
WallThermal1DNodes wall11(
redeclare ConstructionFacade
constructionData,
angleDegAzi = 180.0,angleDegTil = 90.0,
nInnSur = 1, AInnSur = {window2.A},
height = 3.0,width = 3.0);
...
Window window2(
angleDegAzi = 180.0,angleDegTil = 90.0,
height = 1.5,width = 2.5, UVal = ...);

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

203

Template based code generation of Modelica building energy simulation models

equation
// construction elements <-> zones
connect(wall11.toSurfacePort_1,
office2.toConstructionPorts1[1]);
connect(window2.toSurfacePort_1,
office2.toConstructionPorts1[5]);
...
// construction elements <-> ambient
connect(window2.toSurfacePort_2,
surfacesToAmbient.toConstructionPorts[5]);
connect(wall11.toSurfacePort_2,
surfacesToAmbient.toConstructionPorts[6]);
...
// construction elements <-> ground
connect(bottom1.toSurfacePort_2,
surfacesToSolids.toConstructionPorts[1]);
...
end Building;
Building building(
show_TSur = true,nSurfaces = 182,nZones = 13);
Ambient ambient(
nSurfaces = building.nSurfacesAmbient,
weatherDataFile = WeatherDataFile_Berlin());
equation
connect(ambient.toSurfacePorts,
building.toAmbientSurfacesPorts);
connect(ambient.toAirPorts,
building.toAmbientAirPorts);
connect(ambient.TAirRef, building.TAirAmb);
connect(ambient.xAir, building.xAirAmb);
...
end MultiZoneBuilding;

sur[0].GetComponent<Renderer>().material=
new Material(Shader.Find("Transparent/Diffuse"));
sur[0].GetComponent<Renderer>().material.
color = new Color(1, 0, 0, 0.3F);
sur[0].transform.rotation =
Quaternion.Euler(90.0F,90.0F,0.0F);
sur[0].transform.position =
new Vector3(0.0F,1.5F,-2.0F);
sur[0].GetComponent<Collider>().enabled = false;
dy = sur[0].transform.TransformDirection(dirY);
sur[1] = GameObject.CreatePrimitive(
PrimitiveType.Cube);
sur[1].name = "wall1_sur2";
...
}
void Update(){
time += 0.01F;
float[] T_Surface = new float[]{
// C# code for reading the simulation results
// from the Modelica simulation
...
}
for (int i = 0; i < nSurfaces; i++){
rgb = RGBMapper (T_Surface[i],10.0F,30.0F);
sur[i].GetComponent<Renderer>().
material.color=
new Color(rgb[0],rgb[1],rgb[2],0.3F);}
}
}

3.3 Single room
The third case study for template based code
generation was taken from the DFG Forschergruppe
1736 UCaHS (UCaHS, 2017). Within this project, the
indoor climate of a patient room in a Berlin hospital (see
Figure 9) was analyzed in detailed regarding the heat
stress risk during hot summer weeks.

Figure 8. Generated multi-zone Unity building model for
visualization of simulation results.

Figure 8 shows the visualization of the simulated surface
temperatures of the multi-zone building model. The
following code is an excerpt of the automatically
generated C# script, which instantiates in Unity 5 this
3D visualization model:
using UnityEngine;
using System.Collections;
public class Surfaces : MonoBehaviour{
public GameObject[] surfaces;
private int nSur = 182;
private Vector3 dirY = new Vector3(0,1,0);
private Vector3 dy = new Vector3(0,0,0);
private float[] rgb = new float[3];
private float time = 0.0F;
void Start(){
sur = new GameObject[nSur];
sur[0] = GameObject.CreatePrimitive(
PrimitiveType.Cube);
sur[0].name = "wall1_sur1";
sur[0].transform.localScale =
new Vector3(4.0F,0.01F,3.0F);

204

Figure 9. Floorplan and 3D model of the patient room.

For this purpose, a discretized room model in
Modelica, a so called zonal model, which is based on
a finite-volume-method and a simplified implementation of the Navier-Stokes equations was
developed by Mucha (2017). A typical configuration of
this room model includes between 300 to 500 air volume
models, which are interconnected to each other by
coupling models, which consider the friction between
the air layers and the momentum transport. Caused by
the high number of air volume elements and their
necessary interconnections a manually failure free
configuration of a room model, especially for non-boxshaped rooms would be nearly impossible.
Data source: At the moment the geometrical
description of the 3-dim. room geometry inclusive its
space discretization and also the physical parameter of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132199

Session 5B: Buildings II

the building construction are stored in a structuresd
JSON file.
DataMapper: The data mapper reads the building
parameter from the JSON file and stores it in the
building data model.
Components: Figure 10 shows the components of
the BuildungSystems library, which are used for the
configuration of the space-discretized room model: an
air volume model (energy and mass balance), a flow
element model (friction calculation within the air), a
heat conduction model (heat conduction within the air)
and an interface model for the boundary condition of the
room model (surface, wall and window models).

interconnections of the components to the 3dimensional air flow model:
model Room
...
FlowConnectionY floConY5710;
ZoneHeatConductionY heaConY5710;
AirElementThermal airEle6710(
posX= vecX[10], posY= vecY[6], posZ= vecZ[7],
T_start = T_inside,
scalF = {scalX[10],scalY[6],scalZ[7]},
enabled = false, BCwall_west = false,
BCwall_east = true, BCwall_floor = false,
BCwall_roof = false, BCwall_south = false,
BCwall_north = true);
...
FlowConnectionY floConY6710;
ZoneHeatConductionY heaConY6710;

Figure 10. Components for room modelling.

Code generator: The code generator takes the
information from the building data model and generates
the Modelica code for the space discretized room model.
This case study clearly demonstrates the advantage of
the template based code generation approach. More than
500 air volume models have to be connected in three
room coordinates with flow element models. In
addition, different special cases have to be considered
during the code generation process, for example the
presence of furniture or the changing boundary
condition models at the borders of the air space (e.g. a
connection of a border air volume model with an
adjacent wall or opening model).

AirElementThermal airEle7710(
posX= vecX[10], posY= vecY[7], posZ= vecZ[7],
T_start = T_inside,
scalF = {scalX[10],scalY[7],scalZ[7]},
enabled = false,BCwall_west = false,
BCwall_east = true, BCwall_floor = false,
BCwall_roof = true, BCwall_south = false,
BCwall_north = true);
...
equation
...
connect(floConX679.Port2, airEle6710.PortX1);
connect(airEle679.PortHeatIntern,
heaConX679.Port1);
connect(heaConX679.Port2,
airEle6710.PortHeatIntern);
connect(airEle679.PortY2, heaConY679.Port1);
connect(floConY679.Port2, airEle779.PortY1);
connect(airEle679.PortHeatIntern,
heaConY679.Port1);
connect(heaConY679.Port2,
airEle779.PortHeatIntern);
connect(airEle779.PortX2, airEle779.Port1);
...
end Room;

3.4 Analysis and discussion
The three case studies are compared to each other with
the help of benchmark values, e.g. the line of codes, the
number of components or the number of connections
within the generated system model (see Table 1).
Figure 11. Generated discretized Modelica room model
with 532 air volume models.

Figure 11 shows a variation of a generated room model
of the patient room: one with a large cooling ceiling and
one with a small cooling ceiling, which covers only the
area of one of the patient beds. The correspondent
adaptions in the building data model, before the code
generation is repeated for the varied model are relative
simple in comparison to manually changes in the
generated code of the originally model.
The excerpt of the generated code exemplary shows the
instantiation of two of the air volume elements, the flow
and the heat conduction elements and the

DOI
10.3384/ecp17132199

Table 1. Comparison of the three case studies.

District
Lines of code
Number of
components
Number of
connections
Number of
equations
Continuous
time states
Time-varying
variables

Building

Room

2,904

1,544

15,985

150

173

3713

1,008

544

10,982

435,765

40,434

132,712

1,872

305

2,481

34,285

3,139

30,194

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

205

Template based code generation of Modelica building energy simulation models

It can be stated, that building energy simulation analysis
in Modelica usually leads to large system models.
System models with 3,000 up to 16,000 lines of
Modelica code cannot be manually configured failure
free. The number of the components reaches from 150
to 3,713 and the number of connections from 544 to
10,982.
The generated models of Table 1 can be compiled and
simulated without any problems by Dymola 2017 FD01.
A test width a generated district model with more than
500 buildings illustrated the present limitations of the
Modelica simulation tools: Dymola 2017 FD01 was not
able to compile this large model, neither with a 64 bit
compiler.
In the case of the district model, information from the
GIS system can be used to generate a Modelica model
which is able to display the real location of the
individual buildings in the city map.
In the case of the multi-zone building model the input
data can be used to generate consistent program code for
two different purposes (Modelica and Unity code).
In the case of the room model, the code generator
enables configuration of 3 dimensional models, which
cannot be really modeled within a 2-dimensional
graphical editor of a Modelica simulation tool.

4

Summary and Outlook

The described new approach for a template based code
generation for Modelica building models was
successfully applied to three different case studies on
different room scales: district simulation, multi-zone
building simulation and room simulation. A building
data model, which stores the information in a structured
and compact manner in combination with a template
based code generator (CoTeTo), can avoid failures of
manually written large Modelica system models.
In the next development step, the described Modelica
code generators will be extended for special modelling
cases. For this purposes, Mako code for conditional code
generation will be introduced, which allows variations
of generated components and connections within the
Modelica system model.
The import of complex building or district data based
on IFC or CityGML can be potentially incomplete or
error prone. For this purpose, a graphical viewer incl. a
consistency check shall be developed in future to obtain
a more reliable base for the following code generation
process.
Modelica simulator developers should improve their
tools regarding the compiler technologies and also their
numerical efficiency and flexibility. Especially large
city district models, which can be easily generated from
the GIS data with the described method, can address a
lot of computer memory and potentially need a huge
amount of numerical resources. In this context, the
application of parallel computing technologies could
improve the situation.
206

Acknowledgements

The research described in this paper is conducted within
research project EnEff BIM: Planung, Auslegung und
Betriebsoptimierung von energieeffizienten Neu- und
Bestandsbauten durch Modellierung und Simulation auf
Basis von Bauwerkinformationsmodellen funded by
the Federal Ministry for Economic Affairs and Energy
in Germany (reference: 03ET1177D).

References
CityGML. Exchange and storage of virtual 3D city models http://www.citygml.org (last access on 2017 Jan 20).
CoTeTo - Code Templating Tool - https://github.com/UdKVPT/CoTeTo (last access on 2017 Jan 20).
Alexander Inderfurth, Arda Karasu, Christoph NytschGeusen,
Claus
Steffan. Architectural-Geometrical
Simplification for Multi-Zone Building Models for Urban
Refurbishment Projects. Accepted for Building Simulation
2017, 15th International Conference of IBPSA. San
Francisco, August 2017.
GeoJSON. A format for encoding a variety of geographic data
structures - http://geojson.org (last access on 2017 Jan 20).
PyQt4. Python bindings for the Qt application framework https://riverbankcomputing.com/software/pyqt (last access
on 2017 Jan 20)
Werner Kaul, Christoph Nytsch-Geusen, Phillip Wehage, and
Michael Frber. Teilautomatisierte Akquise energetischer
Gebudedaten fr die Quartiersanalayse und - simulation
durch den Einsatz von Geo-Informations-Systemen (GIS).
BAUSIM 2014 IBPSA Germany. Conference Proceedings.
Aachen, September 2014.
Tobias Loga, Britta Stein, Nikolaus Diefenbach, and Rolf
Born. Deutsche Wohngebaudetypologie. Beispielhafte
Manahmen zur Verbesserung der Energieeffizienz von
typischen Wohngebauden, Institut Wohnen und Umwelt,
Darmstadt / Germany, ISBN: 978-3-941140-47-9, 2015.
IFC2x3.
IFC2x
Edition
3
specification
http://www.buildingsmart-tech.org/ifc/IFC2x3/TC1/html
(last access on 2017 Jan 20)
IFC4. IFC4 specification http://www.buildingsmarttech.org/ifc/IFC4/final/html/ (last access on 2017 Jan 20)
IfcOpenShell. The open source IFC toolkit and geometry
engine - http://ifcopenshell.org/python.html (last access on
2017 Jan 20)
Mako.
Mako
templates
for
python
http://www.makotemplates.org (last access on 2017 Jan 20)
Jinja2. Jinja2 (the python template engine) http://jinja.pocoo.org (last access on 2017 Jan 20)
Christoph Nytsch-Geusen, and Werner Kaul. Generation of
dynamic energetic district models from statistical
relationships. 14th IBPSA Building Simulation Conference,
Hyderabad, Conference Proceedings, December 2015.
Christoph Nytsch-Geusen, Christoph Banhardt, Alexander
Inderfurth., Katharina Mucha, Jens Mckel, Jrg Rdler,
Matthis Thorade, and Carles R. Tugores. BuildingSystems
 Eine modular hierarchische Modell-Bibliothek zur
energetischen Gebude- und Anlagensimulation. BAUSIM

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132199

Session 5B: Buildings II

2016 IBPSA Germany, Conference Proceedings. Dresden,
September 2016.
Christoph Nytsch-Geusen, Thaeba Ayubi, Jens Mckel, Jrg
Rdler, Matthis Thorade. BuildingSystems_VR  A new
approach for immersive and interactive building energy
simulation. Accepted for Building Simulation 2017, 15th
International Conference of IBPSA. San Francisco, August
2017.
Katharina Mucha. Ein Simulationsansatz zur Bewertung von
Hitzestressrisiken in Innenrumen. Weiterentwicklung
eines zonalen Modells in Modelica. Dissertation, Fakultt
Gestaltung, Universitt der Knste Berlin, 2017.
pythonOCC. pythonOCC  3D CAD for python http://www.pythonocc.org (last access on 2017 Jan 20).
QGIS.
Ein
freies
Open-Source-GeographischesInformationssystem - http://www.qgis.org/de/site (last
access on 2017 Jan 20).
Senatsverwaltung fr Stadtentwicklung und Wohnen:
Sanierungsgebiet
Friedrichshain-Kreuzberg

Rathausblockhttp://www.stadtentwicklung.berlin.de/staedt
ebau/foerderprogramme/stadterneuerung/de/rathausblock/i
ndex.shtml (last access on 2016 Dec 29).
Matthis Thorade, Jrg Rdler, Peter Remmen, Tobias Maile,
Reinhard Wimmer, Jun Cao, Moritz Lauster, Christoph
Nytsch-Geusen, Dirk Mller, and Christoph van Treeck. An
open toolchain for generating Modelica code from Building
Information Models. 11th International Modelica
Conference, p.383391, Versailles, September 2015.
UCaHS. DFG Research Unit 1736 UCaHS - Urban Climate
and Heat Stress in mid-latitude cities in view of climate
change http://www.ucahs.org (last access on 2017 Jan 20).
Wetter Michael, Fuchs Marcus, Grozman Pavel, Helsen
Lieve, Jorissen Filip, Lauster Moritz, Mller Dirk, NytschGeusen Christoph, Picard Damien, Sahlin Per, and Thorade
Matthis. IEA EBC Annex 60 Modelica Library - An
international collaboration to develop a free open-source
model library for buildings and community energy systems.
14th IBPSA Building Simulation Conference, Hyderabad,
Conference Proceedings, December 2015.

DOI
10.3384/ecp17132199

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

207

208

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Modelling and Simulation of Standardised Control Functions from
Building Automation
Georg Ferdinand Schneider1
1 Group

Georg Ambrosius Peler1

Simone Steiger1

Technical Building Systems, Fraunhofer Institute for Building Physics IBP, Nrnberg, Germany,

georg.schneider@ibp.fraunhofer.de, georg.pessler@ibp.fraunhofer.de,
simone.steiger@ibp.fraunhofer.de

Abstract
Despite the accepted fact that control logic deployed in
future and existing buildings through building automation
systems constitutes a key factor for increasing their energy efficiency, the support for modelling and simulation
of these in current state-of-the-art simulation tools and libraries is rather limited. In particular a gap exists for modelling and simulation of standardised control functions. In
this work we present an approach for modelling standardised control logic using Modelica. We evaluated the interoperability of the modelling approach by simulating a test
case of an automation solution controlling the sunshade of
a room and by reimplementing a state-based control for an
air handling unit reusing models from two Annex60 compliant libraries.
Keywords: Building Automation, Control Function,
VDI 3813, VDI 3814, ISO 16484

1

Introduction

The three pillars which influence the energy demand in
buildings are a sophisticated faade, energy efficient technical equipment and the actual operation by means of control through a Building Automation System (BAS). The
use of BAS is stipulated by relevant standards, e.g. EN
15232:2013. However, benefits in terms of reduced energy demand from the faade and/or technical equipment
can easily be spoilt by operating a building using a poorly
designed, misconfigured or malfunctioning BAS.
The operation of a building is a complex control task involving multiple sensors, actuators and control algorithms
spanning different scales in terms of time and space; the
sum of input and outputs can easily reach ten thousand.
Hence, the design, (continuous-) commissioning and operation of such a complex system is a challenging, timeand cost-intensive task.
A possible solution for managing this complexity during BAS design and operation is the use of a Model-Based
Design (MBD) methods, where all components of a building are modelled and simulated to design and test the control logic of a BAS prior to its deployment in a building. Also, comparison of the simulation model and the
real-world implementation provides a helpful insight in
detecting anomalies during operation (VenkatasubramaDOI
10.3384/ecp17132209

nian et al., 2003). The model and adjacent simulation
infrastructure can further be used for Model-in-the-loop
and Software-in-the-Loop (SIL) evaluation, e.g. for automotive applications (Chrisofakis et al., 2011) and later
in Hardware-in-the-loop simulation, e.g. for circulating
pump control (Schneider et al., 2015).
Models to describe the behaviour of control logic and
algorithms are part of the Modelica Standard Library
(MSL) since its very beginnings. A research effort from
the International Energy Agencys Energy Buildings and
Communities Programme (IEA EBC) develops as one outcome a core library for Building Performance Simulation
(BPS) using Modelica. A set of four libraries, all suitable for MBD within the buildings domain, Buildings
(Wetter et al., 2014), AixLib (Constantin et al., 2014)
BuildingSystems (Nytsch-Geusen et al., 2013) and
IDEAS (Baetens et al., 2012) now share one common core
library Annex60 (Wetter et al., 2015). A special library
NCLib for the simulation of automation systems is presented by Liu (2013), however its focus is on modelling
automation system devices rather than the control logic
involved. A library specifically designed to model and
simulate control functions from industrial automation in
Modelica without specific control functions for standardised room or building automation is presented by Bonvini
and Leva (2012).
Several national and international standards exist to
support the design process of BAS, e.g. VDI 3813-2:2011;
VDI 3814-6:2009; ISO 16484:2011 by providing a set of
commonly utilised control functions which can be reused
to compose an automation solution for room and building
automation. The number of defined control functionalities
and the detail of the descriptions varies between standards.
Having these pieces of control logic readily available in a
simulation environment to compose by drag-and-drop a
control strategy for a room or a piece of equipment in a
building can result in significant benefits in terms of time
required for the design and quality of the resulting control logic. Automation engineers may design and test their
control solution prior to the deployment in a real building
by coupling its simulation to models of rooms, buildings
and equipment. Also in later stages of the life-cycle the
outcome of the simulation model can be compared with
actual monitoring data for fault detection purposes.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

209

Modelling and Simulation of Standardised Control Functions from Building Automation

However, to the best of our knowledge, no library exists for the modelling and simulation of standardised control functions (see comparison in Table 1). The contribution aspect of this work resides in presenting Modelicabased modelling approach for standardised control functions from BAS.
We present a model library BuildingControlLib
which provides a basis to implement standardised control
functions in a streamlined manner. For the implementation of block oriented control functions from standards we
recommend representing the structure by class diagrams
and the actual control behaviour for state-based control
logic using activity diagrams, as defined by the Unified
Modeling Language (UML) (Object Management Group,
2015). The design of the models and library is such that
the compatibility to the MSL as well as libraries from Annex60 effort is ensured. The graphical visualisation included in the models is designed such that representations
composed to the standards and control solutions may be
compiled in a ease-to-use manner from interested BAS
practitioners.
As a beginning we include models of control functions
compliant to the standards VDI 3813-2:2011 and VDI
3814-6:2009. Due to partly ambiguous textual descriptions for control behaviour in standards the models compliant to VDI 3813-2:2011 are designed such that standardised interfaces and actual control functionality are
separated. This offers the benefit that the actual functionality can be easily exchanged with own code or implementations, possibly using the Functional Mockup Interface
(FMI) standard (Blochwitz et al., 2012). To support users
when composing own control solutions by drag and dropping control functions from the library we include the notion of connector semantics (Dibowski et al., 2010) to help
users composing only semantically correct automation solutions; for example it is not possible to connect an indoor
air temperature output and an outdoor air temperature input. To represent state-based control we include models
to simulate state-based control descriptions in BAS as defined in VDI 3814-6:2009
In the remainder of this work we describe the underlying design principles when modelling standardised control functions in section 2. We then demonstrate the usability of the approach by simulating two test cases where
the automation models are coupled to physical room and
equipment models from Annex60 compliant libraries in
section 3.

2

Implementation

structure with a users guide, ready-to-simulate examples,
components, interfaces and types.

Figure 1. Overall structure of model library.

At the top level we include the mandatory packages for documentation and examples and three packages
VDI3813, VDI3814 and Nonstandardized. The
number of packages mentioned is not meant to be exhaustive. Instead the implementation undertaken so far may
serve as a blue print for implementing control functions
from further standards, e.g. ISO 16484:2011.
The first package contains models for the simulation
of room automation functions from VDI 3813-2:2011;
the second contains models for the simulation of state
graphs as defined in VDI 3814-6:2009; and the third package gathers models for common non-standardised control
functions. In some cases, e.g. a schedule, we reuse functionality already implemented for non-standardised applications.
Auxiliary models used in example models are kept in
the Utilities package.

2.1

Room Automation According to VDI 3813

The models are included in a library termed
BuildingControlLib.
Its overall structure is Beside the general best practices for Modelica libraries,
depicted in Figure 1 from a screenshot in Dymola 2015 e.g. package structure, the following requirements have
FD01 (Dymola, 2015) which we use for implementation. been defined to enable seamless use of the library:
The design of the overall structure follows the best
1. Modular design such that control functionality is enpractices and conventions documented in the MSL,
capsulated and may be exchanged as needed;
e.g. naming convention of models and classes, package
210

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132209

Session 5B: Buildings II

Table 1. Overview of the reviewed open-source libraries. X - criteria fulfilled and - not fulfilled. (1) - Annex60 (Wetter et al.,
2015), (2) - Buildings (Wetter et al., 2014), (3) - AixLib (Constantin et al., 2014), (4) - BuildingSystems (Nytsch-Geusen
et al., 2013), (5) - IDEAS (Baetens et al., 2012), (6) NCLib (Liu, 2013), (7) - IndustrialAutomationSystems (Bonvini
and Leva, 2012) and (8) - this work.

Criteria
Models for
... control
... room automation
... building automation (BA)
... standardised BA
Semantic connectors
Based on Annex60
Active development

(1)

(2)

(3)

(4)

(5)

(6)

(7)

(8)

X
(X)
(X)
obsolete
X

X
(X)
(X)
X
X

X
(X)
(X)
X
X

X
(X)
(X)
X
X

X
(X)
(X)
X
X

-

X
X

X
X
X
X
X
X

2. Automated compatibility checking of control functions as proposed by Dibowski et al. (2010);

 ActuatorFunctions - which receive a setpoint
to generate a physical control command for a motor;

3. Graphical representation as defined within the standard.

 OperatorAndDisplayFunctions - which exchange status information to occupants and give
them the ability to send manual commands;

The first requirement results from prevalent heterogeneity in actual implementations of control behaviour in standards. Existing standards do provide textual descriptions
on how the actual behaviour should be, however this descriptions leave room for interpretation. Thus functionalities might comply to standards but have minor differences.
To ensure the seamless exchange of functionality, possibly from non-Modelica implementations, we separate the
definition of interfaces (function) from its functionality as
described in detail in the next sections.
The second requirement is motivated by an approach
reported by Dibowski et al. (2010). The methodology described allows to automatically derive interoperable automation solutions for room automation. The approach
relies on the formal specification of input and output variables of control functions, by annotating exchange variables with information on e.g. its unit, quantity, etc. The
approach is exemplified for control functions for room automation (Dibowski, 2013). As Modelica provides mechanisms for consistency checking on exchange variables the
requirement should be fulfilled by implementation to support library users when implementing own solutions.
Finally to allow easy composition of control solutions
also by interested practitioners the visual appearance of
the modelled control functions should align with the definitions in the standards. Thus allowing the easy reuse and
composition of automation solutions.
Structure of VDI3813 Package
The top-level structure of VDI3813 package is illustrated in Figure 1. It follows the taxonomy established
within the standard which classifies available control functions into:

 ApplicationFunctions - which provide the
actual automation functionality by processing sensor
or operator functions and transmit new setpoints and
commands to actuators;
 Macrofunctions - which provide an interface
to compose reusable macro-functions from low-level
control functions.

The standard also defines supervisory control functions
such as data storage and external messaging which we
found to be out of scope for dynamic simulation of control behaviour and coupling to models of physical processes. The category Common I/O functions with two control functions for interfacing the automation system to external applications is not explicitly modelled.
To ensure computationally efficiency we implement the
control functions as Modelica block as suggested by Liu
(2013). Whenever possible we reuse models from MSL.
Encapsulating Functionality
The actual functionality in the standard is defined using textual descriptions. This leaves a wide range for interpreting and implementing this descriptions; hence, implementations of control functions vary between different
manufacturers of devices for room automation.
To represent and model this heterogeneity as defined in
the first requirement (see section 2.1) the following design principle is applied within this library. We introduce
a block Function as a base class for defining the interface to other functions. Each Function has a associated block Functionality (see Figure 2) which
serves as a template to implement the respective intended
 SensorFunctions - which convert physical sig- functionality. This allows for easy maintainability and
nals into automation signals;
quick exchange of functionality within the library, e.g.

DOI
10.3384/ecp17132209

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

211

Modelling and Simulation of Standardised Control Functions from Building Automation

a manufacturer would like to place his own functionality within the model, potentially using the FMI standard
(Blochwitz et al., 2012). By leaving the respective block
Function unaltered its interoperability with other function blocks is ensured and changes are only applied within
Functionality.

!"#$%&'#()&%*+,"%'-(%&$./01-()2'#%1')3"#$%&'#()&%*

45,2.

$/0$?@A10B0#$0
!")*+'(

C0($%&D(%0@B&E#()

;5:,=

!"#$%&'(
6578.

&))"-&#(#$0@%/10B/')C@A(BB0C

4,9565,2.

!"#$%&'(
!")*+'(
.5;<.4.;

block
PartialFunction

block
PartialFunctionality

$'-A(10@1''-@@%0-A01(%"10@%'@$'-!'1%@-'C0@B0%A'&#%B

.5977:
1''-@%0-A@E10(%01@%/(#@$'')&#E@B0%A%
4,95;5277>

block
Function

block
Functionality

!")*+'(

($%&D(%0@$'')&#E@A'B&%&'#

!"#$%&'(
1''-@%0-A@)0BB@%/(#@/0(%&#E@B0%A%
4,95;56<,.
!")*+'(
($%&D(%0@/0(%&#E@A'B&%&'#

connector
Input

connector
PhysicalInput

connector
Output

connector
PhysicalOutput

Provide
graphical
layout
connector
PartialInput

connector
PartialPhysicalInput

connector
PartialOutput

Implement
semantic data
types

connector
PartialPhysicalOutput

Figure 2. Class diagram in UML describing the modelling principle of encapsulating functionality.

To ensure uniform and complaint graphical layout of
the control functions it is once defined in the partial block
PartialFunction using Modelica annotations.
To implement a control function a block is created
which inherits from PartialFunction. Parameters
and connectors must be added. In the corresponding functionality block the actual control logic is implemented in
what ever way is preferred, e.g. reusing models from other
libraries.
For all implemented control functions we provide a
default functionality which may be adapted to the users
needs or exchanged if required. However, regarding the
mentioned space for interpretation arising from textual descriptions in the standard these are not meant to be normative. To ensure understandability we provide UML activity diagrams for describing the respective functionality
as implemented and include it into the documentation of
each model. As an example we present the UML activity
diagram of AutomaticThermalControl in Figure 3.
212

!"#$%&'(

Figure 3.
UML activity diagram of a functionality
AutomaticThermalControl as described in VDI 38132:2011.

Semantic Connectors
To solve the task of automating the design process of
room automation systems recently the semantically unambiguous specification of function profiles for room automation is introduced (Dibowski et al., 2010; Dibowski,
2013). This approach allows for the automated generation
of room automation profiles, i.e. a set of control functions from a standard, automatically from initially defined
requirements. The approach requires to formally specify
automation devices including their functional profiles, i.e.
the control functions implemented on a devices. Moreover to automatically bind variables of different control
functions detailed semantics of the input and output variables are specified. The approach has been successfully
demonstrate by modelling functions and devices complying to the VDI 3813-2:2011 standard.
To support library users in the design of a room automation solution using the library we integrate the notion of
semantics in the design of connector classes. We define
for every variable type in the standard a separate connector class. We specify the unit, quantity, basic type (Real,
Boolean, Integer, ...) and direction of information
flow (input/output) in the connector definition and a
corresponding type definition using the known Modelica
language elements for this. As emphasised by Dibowski
et al. (2010); Dibowski (2013) these specifications are not
enough to differentiate among input and output variables.
As Modelica does not provide additional ways to specify
variable semantics we introduce a naming convention for
exchange variables specified in the connector classes. The
naming convention has two parts: (1) Each variable starts
with one of the strings value, status, command and setpoint, a classification recommended by Dibowski (2013);

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132209

Session 5B: Buildings II

(2) in the second part we added additional strings specifying additional semantics e.g. to differentiate between an
indoor and an outdoor air temperature.
For example for the exchange variable describing
the outdoor illuminance abbreviated in the standard as
H_OUT we specify a connector ValueIlluminanceOutdoor:

off
switchON
0

or
>1
20

or1

stateGraphRoot

root

cooling

Listing 1. Source code of connector ValueIlluminance
OutdoorInput.

1

connector ValueIlluminanceOutdoorInput
extends Partial.PartialInput;
input
BuildingControlLib.[ ... ].
ValueIlluminanceOutdoor
valueIlluminanceOutdoor; // Specified
variable name
end ValueIlluminanceOutdoorInput;

switchOFF
switchON1

30

heating

10
booleanStep

freezeProtect
switchON2

2

The semantic correctness when composing automation
solutions from drag and dropping control function blocks
in e.g. a macro is ensured by the ability of a Modelica
simulation environment to check connector compatibility
in terms of unit, quantity, basic type, input/output and the
name of the variable. Hence, a user can only connect
different control functions if input and output connectors
match. To ensure compatibility with models which implement connectors using the MSL interfaces, converter models are provided in the Sources and Sensors packages.

booleanStep1

30

3

and
&

40

0

10

and1
0

Figure 4. Ready to simulate model of a state graph from package VDI3814.

tations of the connect statements it is possible to derive a
graphical layout which is very similar to the one used in
the standard.
Additionally we reused blocks from MSL to model log2.2 State Graph According to VDI 3814
ical conjunction and logical disjunction as required in the
Control logic for the control of Heating Ventilation and standard.
Air-Conditioning (HVAC) often follows a state-centric behaviour. Multiple descriptions exist for modelling this be- 3 Results from Test Cases
haviour originally described by Harel (1987). The stan- To evaluate the performance of the implemented control
dard VDI 3814-6:2009 defines the concept of a State library and to examine its interoperability to existing ModGraph to provide a graphical representation of state- elica libraries in the domain, we present results from two
centric control behaviour in BAS.
test cases implemented for demonstration purposes. In the
In the package VDI3814 we provide models to com- first test case we implement an automation solution of a
pose by drag-and-drop a State Graph. The graphical sunshade in a room using control function models from
layout of the models fits the definitions in the standard the package VDI3813 where we reuse a room model in(see Figure 4). For implementing we use models from cluded in the AixLib-library (Constantin et al., 2014). In
Modelica.StateGraph package from MSL.
the second example we re-implement the state-based conAn example of the modelling capabilities of the pack- trol of an Air Handling Unit from Buildings-library
age is displayed in Figure 4 where the control of a generic (Wetter et al., 2014) using the models provided in the
air handling unit is modelled with control states off, cool- VDI3814 package.
ing, heating or frost protection. A specific characteristic
of VDI 3814 State Graphs is that the explicit concept of 3.1 Room automation according to VDI 3813
a transition does not exist. A new state is active when a Most room automation control functions focus on mainBoolean expression is evaluated as true. However transi- taining acceptable indoor comfort conditions for occution conditions are included into a state. This definition is pants while minimising the energy demand required to
modelled by including an array of transitions and a state provide these comfort conditions to the occupant.
In Figure 5 the scheme of an automation solution for
into one model. This allows to display the designed state
graphs as defined in the standard while reusing the models a room with a sunshade is illustrated. It is composed of
from Modelica.StateGraph package. Also in the control functions from VDI 3813-2:2011 which are modstandard it is possible to put return objects symbolised by elled within the library presented in this work. As outa circle around a number of the targeted state. This can lined above, the standard distinguishes between: sensor
also be modelled and when removing the graphical anno- functions; actuator functions; operator and display funcDOI
10.3384/ecp17132209

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

213

Modelling and Simulation of Standardised Control Functions from Building Automation

tions and application functions. Disconnected inputs in
the simulation of this test case have been fixed to reasonable constants for keeping results easy to understand.
The overall functionality intended to be realised here
automatically limits or increases the amount of solar
heat gains of a room either by deploying or elevating a sunshade, respectively. It is implemented as a
macro function (VDI 3813-2:2011) using the application functions OccupancyEvaluation, PriorityControl, AutomaticThermalControl and SetpointCalculation. The connection to the physical
inputs required by these functions is realised using the
control functions PresenceDetection (Check with a
sensor if room is occupied), WindowMonitoring (Sensor function to check if window is open), BrightnessMeasurementOutdoor (Determine outdoor brightness), AirTemperatureMeasurementRoom (Determine room air temperature) and AirTemperatureMeasurementOutdoor (Determine outdoor air temperature). A user may adjust the current temperature setpoint via the AdjustTemperatureSetpoint function. The outcome of the automation solution affects the
actual (real or virtual) sunshade by using the function
sunshadeActuator.
AutomaticThermalControl is only active if the
room is unoccupied and the outdoor illuminance levels are
higher than a threshold. Then, dependent on the comparison of current setpoint of the room and the measured room
temperature, the sunshade is either deployed or elevated.
Between the control output of AutomaticThermalControl and its actual deployment via the ActuateSunshade control function finally, i.e. PriorityControl checks if no higher prioritised signal is
found or the window is open. If the signal of AutomaticThermalControl is of current highest priority,
it is then forwarded to the SunshadeActuator control
function and deployed on the actual sunshade.
We implemented the described room automation solution using models from the previously described library. We couple it to a model which captures the physical behaviour of a room which we adapted from the
model ASHRAE140.Case900FF from Constantin et al.
(2014). The boundary conditions (weather, internal gains,
etc.) remained unchanged. We adapted the ventilation
schedule to 30 min once every day and introduced a constant heat flow rate of 500 W to heat the room in order
to limit the outcome of these disturbances to the sunshade
control on the automation solution. Also we modified the
model of the south facing wall to contain a window with
a sunshade which may be deployed from outside via a
Boolean connector. We calculate the value of the outdoor
illuminance assuming a constant factor of 2.49 between
the value of irradation on a horizontal surface provided by
the model radOnTiltedSurf_Perez[5].
We simulated the coupled room and automation model
for the first day in the weather file. We chose boundary
conditions such that no presence is detected and no au214

tomatic or manual set point changes are applied. Hence
the automatic control is active only when illuminance
levels are sufficient. Results of the simulation are presented in Figure 6. Presented therein are the input signals affecting the AutomaticThermalControl control function, i.e. in the upper third the outdoor illuminance H which is compared within the control function
with a threshold PH . If the illuminance is too low, no
control action happens. In the mid part the Boolean expressions indicating if AutomaticThermalControl
is operating in heating yhea or cooling mode ycoo and a signal telling the sunshade to be deployed or not are plotted
(usun ). In the lowest subplot in Figure 6 the outdoor Toa
and indoor air temperature Tra are given and their respective heating (Thea,s ) and cooling (Tcoo,s ) set point. Also the
air exchange rate AER is given, representing the ventilation scheme applied.
Given the described boundary conditions the control
functionality allows to keep the room temperature within
the bounds set by the heating and cooling set points, Thea,s
and Tcoo,s respectively. Before ventilating (time < 43200 s)
the sunshade is deployed several times when the control
switches to cooling mode, triggered by the actual room
temperature reaching the upper temperature set point at
24 degrees Celsius. The sharp decline during ventilation
results in a period where the heating mode is active and
the sunshade is elevated.
When the temperature recovers after ventilation with
outdoor air the cooling mode is active until the automatic
control enters the inactive mode when illuminance levels
fall below the threshold specified (PH ).

3.2

Control of an Air Handling Unit via
VDI 3814 compliant State Graph

To evaluate the models implemented in the package VDI3814 we re-implement the model ModeSelector from the Buildings-library (Wetter
et al., 2014). The model is used in the example
VAVReheat.ClosedLoop to control a model of an
Air Handling Unit which supplies conditioned air to a
thermal zone. It encompasses six states representing the
behaviour of the system (initial, unoccupied off, morning
pre-cooling, morning warm-up, unoccupied night set back
and occupied).
We simulate VAVReheat.ClosedLoop with the
provided model and with the same control logic implemented using models from VDI3814-package. We use a
Dymola 2015 FD01, 64bit with the following simulation
settings:

 start time: 0 s, end time: 172800 s;
 solver: Esdirk23a - order 3 stiff;
 interval length: 600 s; Tolerance: 1e-6.
We compare the results of the two simulations by calculating the R squared value and the Mean Absolute Percentage Error (MAPE) between the respective results. The

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132209

Session 5B: Buildings II

PresenceDetection

OccupancyEvaluation

P
P_AUTO

P_ACT

P_AUTO

M

P_MAN

WindowMonitoring
SunshadeActuator

PriorityControl

B
B_WINDOW

S_SET

B_WINDOW

S_SET

S_STA

S_PROT

Lx

BrightnessMeasurementOutdoor

S_MAINT

H

S_MAN
H_OUT

C

AirTemperatureMeasurementRoom
T
T_ROOM

Legend

S_AUTO

SensorFunction
ActuatorFunction

AutomaticThermalControl
S_MAN

P_ACT

ApplicationFunction

 Fraunhofer IBP

H_OUT

BMS

OperatorDisplayFunction

T_ROOM

AdjustTemperatureSetpoint
5C
INPUT

OUTPUT

T_STA

T_SETPT

T_SETPTS

SetpointCalculation
C

AirTemperatureMeasurementOutdoor

T_BMS

T_SETPTS

T_SETPT

T
T_OUT

T_OUT

Figure 5. Scheme of the control functions utilised in the simulated room automation test case.

results are summarised in Table 2. The results show a
high agreement of the two simulations reflecting the similar behaviour. Some discrepancies can be observed on
the compared simulated data which can be explained from
errors resulting from interpolating these values. An error
of 0.192% for the control mode exists as a negligible deviation between the control mode signals of both simulation was identified; this originates from the waiting times
which at some point in the state graph network need to be
introduced. For the VDI3814 case with integrating transitions and states in one model, a fixed delay is introduced to
avoid the termination of the simulation when initialising.
Table 2.
Results from comparing the simulation of
VAVReheat.ClosedLoop with the original model from
Buildings library (Wetter et al., 2014) and this work. MAPE
- Mean Absolute Percentage Error.

Variable
TOut
controlMode
occupied
TRooMin
TRooAve
TRooSetCoo
TRooSetHea

4

R2

MAPE in %

.999
.970
1.00
0.999
0.999
0.997
0.997

6.816e-6
0.192
0.000
6.475e-4
6.157e-4
20.24e-4
19.48e-4

Discussion

From the results presented in this work the Modelica modelling language is found to be suitable for the proposed
DOI
10.3384/ecp17132209

modelling and simulation of standardised control functions.
However, some limitations have been identified when
implementing the notion of semantic connectors. We
found the ability of the Modelica language to support
checking of the consistency of connector variables according to units, quantity and the name of the variable to be
a helpful feature. However, when attempting to include
detailed semantics of connector variables the only possibility is to introduce a naming convention for the exchange variables which is cumbersome to maintain and
prone to errors. It may be of interest to extend the Modelica language in future releases in this direction to evaluate the types of a connector variable (not only the basic
type, e.g. Real, Boolean, Integer, etc.) allowing to
define a taxonomy of types instead of a naming convention. An approach known from the simulation of cyberphysical systems embedded in the Ptolemy II framework
offers a possibility to include consistency checking (Leung et al., 2009) of units based on ontology. The concept
of expandable connector is not found to be suitable in this context as a variable name might occur several times in one automation solution but must not be connected to each of its occurrences.
Standards are evaluated and revised on a regular basis,
thus a regular revision and maintenance of the library is
required. We are confident that the presented underlying
design principles of the modelling approach remain relevant and applicable to future and upcoming versions of
standards.
Most standards provide textual descriptions of the functionality of a control function which often is ambiguous

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

215

1200
1000
800
600
400
200
0

deployed
not deployed
active
inactive
active
inactive
25
20
15
10
5
0
5
0

Time in s
Exchange rate in 1/h

Temperature in degC

Boolean in -

Illuminance in lux

Modelling and Simulation of Standardised Control Functions from Building Automation

12
14400

H
PH

28800

yhea
ycoo

43200

usun
Tra

57600

Toa
Tcoo,s

72000

0
86400

Thea,s
AER

Figure 6. Simulation results of room automation example for one day. H - outdoor illuminance, PH - threshold for illuminance,
yhea - heating mode, ycoo - cooling mode, usun - sunshade control signal, Thea,s - temperature set point heating, Tcoo,s - temperature
setpoint cooling, Tra - room air temperature, Toa - outdoor air temperature, AER - air exchange rate.

216

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132209

Session 5B: Buildings II

and is prone for different interpretation. When implementing the models we use established documentation
measures, namely UML class and activity diagrams to
document our implementation. Having well-documented,
commonly-agreed on simulation models of the control
functions available as a reference implementation may
help the wide-spread and further adoption of BAS in the
buildings domain.
When modelling buildings, technical equipment and
components and control logic of BAS the resulting hybrid system involves continuous and discrete event dynamics (Fritzson, 2014). In particular modelled discrete
behaviour in control logic, e.g. a transition from one state
to another if the condition tRoom > 22C is evaluated to
true, triggers events involving state variables which need
to be handled by the numerical solver. A large number of
these events leads to a significant slow down of simulation
speed when simulating the mentioned systems.
The Modelica modelling language provides built-in
functionalities to efficiently handle events and should be
applied when ever possible. Discrete behaviour with respect to time, e.g. sampling, can be efficiently handled
using discrete variables or clocks introduced in Modelica
3.3 language specification (Otter et al., 2012).
The generation of state events can be prevented
from using noEvent(expression) in case it is
known that the respective expression is continuous
and smooth(p,expression) if not known.
The use of clocked variables and expressions seems to
be a promising path for efficient implementation of control behaviour in Modelica. In particular the ability to
transfer clocked control systems from its Modelica implementation to clocked control hardware is a huge benefit. However, its effect on computational efficiency when
simulating needs to be investigated as in the buildings domain distinguishing models with discrete and continuous
dynamics is sometimes difficult; For example the discrete
behaviour of a user opening a window when some temperature threshold is crossed may be modelled within the
buildings model, thus discrete and continuous models are
mixed.

5

Conclusion

to room models from AixLib-library (Constantin et al.,
2014) and a state graph to control an air handling unit
model from Buildings-library (Wetter et al., 2014).
The models presented, along with the models existing
for building elements and equipment, allow to investigate
the interaction and influences of an automation solution on
the buildings behaviour in an integrated manner. Through
the respective feedback from user models and also the interaction of user and automation solution as it is implemented in a real BAS is possible.
The total number of models and standards described included here is still limited. In future we plan to include
more standardised, e.g. from ISO 16484:2011, and nonstandardised control functions, e.g. for HVAC control.
We introduce the notion of a semantic connector which
allows the library user to only connect control functions
which are supposed to be connected, following the idea
presented by Dibowski et al. (2010). The approach relies
on a naming convention, despite the ability of consistency
checking of Modelica modelling language for quantities
and units. Future research may expand on this allowing
to define variable semantics more freely as previously discussed and implemented by Leung et al. (2009).
In future we intend to investigate the potential benefits
of using clocked variables in the definition of BAS control
behaviour and standardised control functions for efficient
simulation of the resulting hybrid systems.
Our intention is to stream line this effort with developments connected to the Annex60 effort and stipulate collaboration and reuse by open-sourcing the described models. For this purpose we intend to integrate the models
within an open library. Through doing this we hope that
this effort acts as a catalyst for implementing and providing control logic from BAS for building control in a comprehensive, well-documented and efficiently implemented
way.

Acknowledgements
This research was performed as part of the Energie Campus Nrnberg and supported by funding through the Aufbruch Bayern (Bavaria on the move) initiative of the state
of Bavaria.

In this work we present a modelling approach to model References
and simulate standardised control functions from building automation in Modelica. We exemplify this by mod- R. Baetens, R. De Coninck, J. Van Roy, B. Verbruggen,
J. Driesen, L. Helsen, and D. Saelens. Assessing electrielling block like control functions from VDI 3813-2:2011
cal bottlenecks at feeder level for residential net zero-energy
and state-centric control from VDI 3814-6:2009. In parbuildings by integrated system simulation. Applied Energy,
ticular this includes models for sensor, actuator, operator96:7483, 2012.
and display, application control functions and a template
to model macro functions from VDI 3813-2:2011 and set
of models to compose state graphs as specified in VDI T. Blochwitz, M. Otter, J. Akesson, M. Arnold, C. Clau,
H. Elmqvist, M. Friedrich, A. Junghanns, J. Mau,
3814-6:2009 built on top of StateGraph package from
D. Neumerkel, H. Olsson, and A. Viel. Functional mockup
Modelica Standard Library.
interface 2.0: The standard for tool independent exchange of
The usability of the models is demonstrated in two exsimulation models. In Proceedings of the International Modample applications linking a room automation solution
elica Conference, pages 173184, Munich, Germany, 2012.
DOI
10.3384/ecp17132209

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

217

Modelling and Simulation of Standardised Control Functions from Building Automation

M. Bonvini and A. Leva. A modelica library for industrial control systems. In Proceedings of the International Modelica
Conference, pages 477484, Munich, Germany, 2012.
E. Chrisofakis, A. Junghanns, C. Kehrer, and A. Rink.
Simulation-based development of automotive control software with Modelica. In Proceedings of the International
Modelica Conference, pages 17, Dresden, Germany, 2011.
A. Constantin, R. Streblow, and D. Mller. The Modelica
HouseModels Library: Presentation and Evaluation of a
Room Model with the ASHRAE Standard 140. In Proceedings of the International Modelica Conference, pages 293
299, Lund, Sweden, 2014.
H. Dibowski. Semantischer Gertebeschreibungsansatz fr
einen automatisierten Entwurf von Raumautomationssystemen. PhD thesis, Department of Computer Science, TU Dresden, Dresden, Germany, 2013.
H. Dibowski, J. Ploennigs, and K. Kabitzsch. Automated Design of Building Automation Systems. IEEE Transactions on
Industrial Electronics, 57(11):36063613, 2010.
Dymola,
2015.
URL http://www.3ds.com/
products-services/catia/products/dymola.
Dassault Systemes AB, Lund, Sweden, [Accessed: 31-122016].

G. F. Schneider, J. Oppermann, A. Constantin, R. Streblow,
and D. Mller. Hardware-in-the-Loop-Simulation of a Building Energy and Control System to Investigate Circulating
Pump Control Using Modelica. In Proceedings of the International Modelica Conference, pages 225233, Versailles,
France, 2015.
VDI 3813-2:2011. Building automation and control systems
(BACS) Room control functions (RA functions), 2011.
VDI 3814-6:2009. Building automation and control systems
(BACS) Graphical description of logic control tasks, 2009.
V. Venkatasubramanian, R. Rengaswamy, K. Yin, and S. N.
Kavuri. A review of process fault detection and diagnosis:
Part I: Quantitative model-based methods . Computers &
Chemical Engineering, 27(3):293  311, 2003.
M. Wetter, W. Zuo, T. S. Nouidui, and X. Pang. Modelica Buildings Library. Journal of Building Performance Simulation, 7
(4):253270, 2014.
M. Wetter, M. Fuchs, P. Grozman, L. Helsen, F. Jorissen, M. Lauster, D. Mller, C. Nytsch-Geusen, D. Picard,
P. Sahlin, and M. Thorade. IEA EBC Annex 60 Modelica
Library - An International Collaboration to Develop a Free
Open-Source Model Library for Buildings and Community
Energy Systems. In BuiSim 2015, Hyderabad, India, 2015.

EN 15232:2013. Energy performance of buildings - Impact of
Building Automation, Controls and Building Management,
2013.
P. Fritzson. Principles of object-oriented modeling and simulation with Modelica 3.3: A cyber-physical approach. John
Wiley & Sons, 2014.
D. Harel. Statecharts: A visual formalism for complex systems.
Science of Computer Programming, 8(3):231274, 1987.
ISO 16484:2011.
(BACS), 2011.

Building automation and control systems

J. M.-K. Leung, T. Mandl, E. A. Lee, B. Osyk, C. Shelton, S. Tripakis, and B. Lickly. Scalable semantic annotation using
lattice-based ontologies. In Proceedings of MDELS, pages
393407, Denver, USA, 2009.
L. Liu. Object-oriented Modeling and Efficient Simulation
of C3-Systems. PhD thesis, University of Saarland, Saarbrcken, Germany, 2013.
C. Nytsch-Geusen, J. Huber, M. Ljubijankic, and J. Rdler.
Modelica BuildingSystems- eine Modellbibliothek zur Simulation komplexer energietechnischer Gebudesysteme. Bauphysik, 35(1):2129, 2013.
Object Management Group. OMG Unified Modeling Language,
2015.
M. Otter, B. Thiele, and H. Elmquvist. A Library for Synchronous Control Systems in Modelica. In Proceedings of
International Modelica Conference, 2012.

218

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132209

Modelling of Heat Pumps with Calibrated Parameters Based on
Manufacturer Data
Massimo Cimmino1

Michael Wetter2

1

Department of Mechanical Engineering, Polytechnique Montreal, Montreal QC, Canada,
massimo.cimmino@polymtl.ca
2
Lawrence Berkeley National Laboratory, Energy Technologies Area, Building Technology and Urban Systems Division,
Simulation Research Group, Berkeley CA, USA, mwetter@lbl.gov

Abstract
A Modelica model for the simulation of heat pumps is
presented. The model uses a simplified vapor
compression cycle with only five refrigerant states.
Parameters to the model are evaluated using an
optimization procedure to minimize the differences
between the model predicted heating capacities and
power input and those provided in the manufacturer
technical data. The optimization process is done from a
Python implementation of the heat pump model.
The model is first tested by verifying that calibration
from performance data generated by the heat pump
model results in the same parameters as the ones used in
the generation of the performance data. In the presented
example, calibrated parameters were found close to the
original parameters used to generate the data, except for
the evaporator heat transfer coefficient for which the
model was found not to be very sensitive. In a second
example, the model is calibrated against manufacturer
data. The heating capacities and power input calculated
from the calibrated model are within 2.7% and 4.7% of
the manufacturer data, respectively. Finally, the
computational performance of the model is tested in a
system simulation of a hydronic heating system. The
simulation using the presented heat pump model was
executed in 48 seconds, compared to 17 seconds for the
same system using a simple boiler model.
Keywords:
Heat Pump, Vapor Compression Cycle,
Model Calibration

1

Introduction

Heat pump systems offer great potential for the
reduction of energy use for heating, cooling and heat
recovery, and are attractive heat delivery systems in
applications involving low temperature thermal
networks (Lund et al., 2014). To optimize the design and
evaluate the energy performance of such systems,
efficient simulation tools are required to model the
annual behavior of the system components.
Heat pump models can be divided into two major
categories: empirical models and refrigerant cycle
models. Empirical models are obtained by mapping the
DOI
10.3384/ecp17132219

heat pump performance in terms of capacity, power
input and coefficient of performance to the operating
conditions, i.e. the water mass flow rates and
temperatures on the load and source side of the heat
pump. The performance map can then be interpolated
during numerical simulations, or used to produce an
equation-fit of the heat pump performance. On the other
hand, refrigerant cycle models are obtained from first
principles, with varying degree of details in the
definition of each heat pump component.
Empirical models have been shown to provide good
approximations of the heat pump performance as
shown, for instance, by Swider (2003), Lee and Lu
(2010) and Carbonnell et al. (2012). However,
researchers have pointed out that these models might not
be suitable for extrapolation of the heat pump
performance outside of the operating conditions used to
formulate the model (Jin, 2002; Scarpa et al., 2012).
Unfortunately, such extrapolation is often required as
manufacturers generally provide performance data for a
narrow operating range. Models based on first principles
offer better potential to accurately predict the heat pump
performance over a wider range of operating conditions.
Refrigerant cycle models are often more demanding
in terms of computational time when compared to
empirical models, and may require parameters not
provided by manufacturers. Simplified vapor
compression cycles may be used to reduce the
computational time (Domanski and McLinden, 1992;
Jin, 2002; Lemort and Bertagnolio, 2010; Scarpa et al.,
2012). These simplified cycles divide the vapor
compression cycle into a limited number of steps and
refrigerant states, thereby reducing the number of 
usually computationally expensive  refrigerant
thermodynamic properties to evaluate. Parameters to
these models may then be obtained through calibration,
using an optimization procedure to minimize the model
predicted heat pump performance and the performance
data from the manufacturer.
A calibrated water to water heat pump model with a
scroll compressor is presented in this paper, based on the
work of Jin (2002). The model relies on a simplified
vapor compression cycle with 5 refrigerant states, where

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

219

Modelling of Heat Pumps with Calibrated Parameters Based on Manufacturer Data

only 3 of the states need to have refrigerant
thermodynamic properties evaluated. The model is
implemented into the Modelica Buildings library
(Wetter et al., 2014). An external implementation of the
heat pump model into Python is used to obtain the
calibrated model parameters based on tabulated
manufacturer data. The computational efficiency of the
Modelica model is tested in the simulation of a hydronic
heating system.

2

Heat Pump Model

A heat pump model has been built from components
from  and components added to  the Buildings
library (Wetter et al., 2014). The model presented in this
paper is for a water to water heat pump with a scroll
compressor using refrigerant R410A and is shown in
Figure 1. The heat pump model incorporates two new
component
models,
Buildings.Fluid.
HeatExchangers.EvaporatorCondenser for the
evaporator and condenser and Buildings.Fluid.
HeatPumps.Compressors.ScrollCompressor for
the scroll compressor, as well as a refrigerant package
for the thermodynamic properties of R410A
Buildings.Media.Refrigerants.R410A.
The heat pump model is based on the work of Jin
(2002), and has been extended to allow for single- and
variable-speed compressors and dynamic heat storage
on the water side. The model relies on a simplified vapor
compression cycle, which removes the need to explicitly
model the expansion device. The model is meant to use
parameters for the sub-components, obtained from
calibration of the model to manufacturer data.
The vapor compression cycle and the refrigerant,
evaporator, condenser and compressor models and their
implementation in Modelica are presented in this
section.

2.1 Simplified Vapor Compression Cycle
A simplified vapor compression heat pump cycle, as
proposed by Jin (2002), is presented in Figure 2. The
simplified cycle serves two purposes: (1) to reduce the
number of parameters in the heat pump model and
thereby facilitate the calibration process, and (2) to
reduce the number of evaluations of thermodynamic
properties of the refrigerant and thereby reduce
computing time.
The simplified vapor compression cycle relies on the
following assumptions:
1. The refrigerant leaves the condenser in the
saturated liquid state, i.e. there is no subcooling of
the refrigerant.
2. The refrigerant leaves the evaporator in the
superheated vapor state, with a constant degree of
superheating  . The enthalpy increase from
superheating has been magnified in Figure 2 and is
usually small compared to the latent heat of
evaporation.
3. The theoretical compressor work is the result of
isentropic compression at the built-in volume ratio
followed by isochoric compression or expansion to
the condensing pressure.
4. Sensible heat transfer to the refrigerant is neglected
in the evaporator.
5. The expansion process is isenthalpic.
From this set of assumptions, only a limited number of
refrigerant thermodynamic properties need to be
evaluated to solve the complete vapor compression
cycle: the temperatures, pressures and specific
enthalpies of the saturated vapor and saturated liquid
refrigerant (i.e. points A and B), and the specific volume
and isentropic exponent of the superheated vapor
refrigerant (i.e. point C).

Figure 2. Simplified vapor compression cycle.

2.2 Refrigerant Properties
Figure 1. Model of a water to water heat pump with a
scroll compressor.

220

The necessary routines for the evaluation of the
thermodynamic properties of refrigerant R410A were
implemented in a media package. Except for the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132219

Session 5B: Buildings II

enthalpy of saturated refrigerant vapor, coefficients for
the equations presented in this section were obtained
from commercial supplier data (du Pont, 2004).
Coefficients for the enthalpy of saturated refrigerant
vapor were produced from tabulated properties in the
supplier data.
The implemented refrigerant routines and their
associated inputs are presented in Table 1. Specific
enthalpies and pressures of the saturated liquid and
saturated vapor refrigerant are calculated from degree 5
polynomial correlations. Thermodynamic properties of
the superheated refrigerant vapor are calculated using
the 11-term Martin-Hou equation of state (Martin and
Hou, 1955). Note that temperatures in all equations
related to thermodynamic properties are in Kelvin.
Table 1. Refrigerant routines.

Output

2

Input(s)

Specific enthalpy (Saturated liquid), 



Pressure (Saturated liquid), 



Specific enthalpy (Saturated vapor), 



Pressure (Saturated vapor), 



Isentropic exponent (Vapor), 
Specific isobaric heat capacity (Vapor),

Specific isochoric heat capacity (Vapor),

Specific volume (Vapor), 

, 
, 
, 
, 

The specific enthalpy and pressure of saturated liquid
and saturated vapor refrigerant are calculated from
degree 5 polynomial correlations of the following form:
6

 =   1

(1)

=1
6

ln( ) =   1

During the development of the heat pump model, it
was found that the numerical solver needs to solve Eq. 3
for . In many cases, the numerical solver could not
converge since it could not choose a proper guess value
for . A refrigerant routine was then implemented to
evaluate the specific volume based on pressure and

temperature by successive evaluation of  and  ,
starting from a guess value  =  + 0 . This
leads to an efficient implementation of the inverse of
Eq. 3, as the guess value  is relatively close to the
final value.
The isentropic exponent is calculated from the
derivatives and integrals of the equation of state (de
Monte, 2002):
 =  
(4)

(2)

=1

where  is the critical pressure (= 4926.1 kPa for
1
R410A),  = (1   ) 3  0,  is the critical
temperature (= 72.13C for R410A),  = (1 
 )  0, and  and 0 are correlation coefficients
that differ for Eqs. 1 and 2 and for saturated liquid and
saturated vapor.
The specific volume of the superheated vapor
refrigerant is evaluated from the Martin-Hou equation
of state:
4  +   +  exp (  )





(3)
=
+
+1
(  0 )
  0



 =    ( | )  |
 ,
 ,

(5)



2
|
 
2
    ,

 = ,     

(6)

The derivatives and integrals in Eqs. 5 and 6 are
calculated directly by implementations of the
corresponding derivatives and integrals of the equation
of state in Eq. 3. The specific isobaric heat capacity of
ideal gas, , , is evaluated from a degree 3 polynomial
correlation based on temperature, in the form:
4

, =    1

(7)

=1

where  are correlation coefficients.

2.3 Compressor
The compressor model solves the complete vapor
compression cycle presented in Section 2.1. The model
interfaces with the evaporator and condenser models
through HeatPorts. The temperature and heat transfer
rates at the ports correspond to the refrigerant
temperature and heat transfer rates in the evaporator and
condenser.
The scroll compressor model proposed by Jin (2002)
was implemented and extended to consider variablespeed compressors. As outlined in Section 2.1, the
theoretical compressor work is the result of isentropic
compression at the built-in volume ratio followed by
isochoric compression or expansion to the condensing
pressure. The volume ratio between discharge and
suction of the scroll compressor is fixed and the
compressor work must be adjusted if the pressure ratio
does not match the pressure ratio obtained from
isentropic compression at the fixed volume ratio. The
theoretical compressor work is then:

=1

where  is the gas constant (= 0.11455 kJ/(kgC) for
R410A), and  ,  ,  and  are coefficients to the
equation of state.
DOI
10.3384/ecp17132219

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

221

Modelling of Heat Pumps with Calibrated Parameters Based on Manufacturer Data

 =


  1 
  (
1
  

(8)
1
1 
+   1)

where  is the theoretical compressor work,  and
 are the evaporating and condensing pressure,  is
the normalized speed of the compressor, with  = 1 the
value at the nominal speed,  is the nominal
refrigerant volume flow rate,  is the built-in volume
ratio between discharge and suction of the compressor

and  =  is the built-in pressure ratio.
The theoretical compressor work is adjusted for the
electro-mechanical efficiency of the compressor to
obtain the power input into the compressor. A constant
electro-mechanical efficiency is assumed:

(9)
 =
+ 

where  is the power input into the compressor,  is the
electro-mechanical efficiency of the compressor and
 is the constant part of the compressor power
losses.
Since sensible heat transfer is neglected in the
evaporator and expansion is considered isenthalpic, the
evaporator heat transfer rate is obtained from the
enthalpy difference between the enthalpy of saturated
vapor at the evaporating pressure (point A in Figure 2)
and the enthalpy of saturated liquid at the condensing
pressure (point B in Figure 2):

(10)
 =  (
  ) (   )

where  is the evaporator heat transfer rate,  is
the specific volume at the suction of the compressor

(point C in Figure 2) and  =   is the leakage

refrigerant is included in the compressor model and not
in the evaporator model. Only the effects of
superheating on the suction specific volume and
isentropic exponent are considered. The superheating
enthalpy increase is neglected.

2.4 Evaporator and Condenser
The evaporator and condenser model is shown in
Figure 3. It extends from the already implemented
TwoPortHeatMassExchanger of the Buildings
library. It interfaces with the compressor model through
a HeatPort. The refrigerant in both the evaporator and
condenser is assumed to exchange heat with the fluid
stream at a constant temperature. The effective heat
transfer coefficient  between the refrigerant and
the fluid is calculated by the    method:
 =  ,
(12)
 = 1  exp()

(13)

where  is the number of transfer units,  is the heat
exchanger effectiveness,  is the heat transfer
coefficient of the evaporator or condenser,  is the
fluid mass flow rate and , is the fluid specific isobaric
heat capacity.



mass flow rate in the compressor, with  being the
leakage coefficient.
The condenser heat transfer rate is then evaluated
from an energy balance:
 = ( +  )
(11)
where  is the condenser heat transfer rate.
The specific enthalpies  and  are evaluated from
the implemented refrigerant routines presented in
Table 1 for the saturated liquid at  =  the
condensing temperature and the saturated vapor at  =
 the evaporating temperature. The specific volume
at suction is evaluated for  =  and  =  +
 , where  is the temperature of the superheated
vapor at the compressor suction. The evaporating and
condensing pressure used in Eq. 8 are evaluated from
the refrigerant routines for the pressure of saturated
vapor evaluated at  =  and  =  . The
isentropic exponent used in Eq. 8 is evaluated at  =
 and  =  +  . Superheating of the

222

Figure 3. Model used for both the evaporator and
condenser of the heat pump.

The effective heat transfer coefficient is then
evaluated based on the outlet fluid temperature, since
the HeatPort of the MixingVolume returns the outlet
fluid temperature. The heat transfer rate is given by:
{ ,  } =  ({ ,  }
(14)
 ,,{,} )
 = ,  (1  )

(15)

where ,,{,} is the outlet fluid temperature in
the evaporator or condenser.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132219

Session 5B: Buildings II

3

Model Calibration

The parameters required by the heat pump subcomponent models are typically not provided by the heat
pump manufacturers. These parameters therefore need
to be determined by calibrating the model to the
manufacturer data. There are 8 parameters that need to
be evaluated: the nominal refrigerant flow rate  ,
the volume ratio  , the leakage coefficient , the degree
of superheating  , the electro-mechanical
efficiency , the constant part of the power losses 
and the heat transfer coefficients  and  of
the evaporator and condenser.
Manufacturers usually provide technical data in the
form of tabulated values of heat pump capacities and
power input at different operating conditions in terms of
inlet water temperatures and mass flow rates into the
evaporator and condenser. Jin (2002) proposed the use
of optimization methods to identify the set of parameters
that minimize the sum of normalized square errors of the
heat pump capacities and power inputs. The cost
function to minimize is:
 =  [(

()
()
  ,



()
,
2

()
 ()  
+(
) ]
()


2

)
(16)



An optimization routine was set-up in Python using the
SciPy (Jones et al., 2001) package. Analogous models
for the refrigerant properties, the compressor, the
evaporator and the condenser were implemented in
Python. The set of parameters that minimizes the cost
function are evaluated from the Python model using a
sequential least square programming method. Once the
parameters are evaluated, the Python implementation of
the heat pump model is verified against the Modelica
model.
The time required to calibrate the model increases
with the number of manufacturer data points that are
used. Jin (2002) showed that using the combinations of
maximum and minimum entering water temperature and
mass flow rates on the evaporator and condenser sides,
for a total of 16 data points, decreases the calibration
time significantly with minimal effect on the accuracy
of the calibrated model. The Python optimization
routine thus only uses a subset of 16 data points from
the manufacturer data, and compares the model with the
complete manufacturer data set once the calibration is
complete.
Not all combinations of parameters yield a valid heat
pump model. For example, certain sets of parameters
may result in refrigerant temperatures in the condenser
to be greater than the critical temperature. In these cases,
it is not possible for the model to evaluate the capacity
and power input of the heat pump, since property
DOI
10.3384/ecp17132219

routines for saturated refrigerant (Eqs. 1 and 2) are only
valid for temperatures below the critical temperature.
It is then important to choose proper guess values for
the parameters when calibrating the model. Guess
values of the electro-mechanical efficiency and the
degree of superheating are simply chosen to be  = 0.95
and  = 4C. The rest of the parameters are
evaluated from the nominal values of the heat pump
capacity , , power input  and
corresponding
entering
water
temperatures
,,, and ,,, , assuming a 5C
temperature difference between the inlet fluid
temperatures and the refrigerant temperatures and a 1%
leakage mass flow rate. The guess values of the
parameters are evaluated following this sequence:
1. Evaluate the refrigerant temperatures:
 = ,,,  5C
(17)
 = ,,, + 5C

(18)

2. Evaluate the evaporator heat transfer rate at
nominal conditions:
, =   ,
(19)
3. Evaluate the evaporating pressure  and
condensing pressure  at the corresponding
refrigerant temperature from the refrigerant
routines.
4. With the suction temperature  =  + 
and evaporating pressure  , evaluate the specific
volume and isentropic exponent from the
refrigerant routines.
5. Evaluate the volume ratio:
(20)
 = (  )1
6. Evaluate the nominal refrigerant volume flow rate:


= (  +  )
(21)
 ,
(22)
 = 
(   )
 = 0.01
(23)
7. Evaluate the leakage coefficient:
 =  (  )

(24)

8. With the theoretical power evaluated from Eq. 8
and the previously evaluated parameters, evaluate
the constant part of the power losses:
 = max(0,     )
(24)
9. Evaluate the condenser and evaporator heat transfer
coefficients:
{ , } = , 5C
(25)
This sequence has been implemented in Python and is
used to choose starting values for the parameters. It was
found to produce valid parameters in all cases
considered.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

223

Modelling of Heat Pumps with Calibrated Parameters Based on Manufacturer Data

4

Examples

4.1 Calibration from Model Produced Data
The calibration method for the heat pump model is first
verified using data produced by the model. Heat pump
capacities and power input were calculated using the
Python model for water mass flow rates of 0.6, 0.9 and
1.2 kg/s at both the evaporator and condenser, inlet
water temperatures of 0, 5, 10, 15, 20 and 25C at the
evaporator and inlet water temperatures of 15, 25, 35
and 45C at the condenser, for a total of 216 data points.
The calibration is done using only the 16 points
corresponding to the combinations of minimum and
maximum values of the inlet water temperatures and
flow rates. The set of parameters used to evaluate the
heat pump capacities and power input, the guess values
for each parameter and the set of parameters resulting
from the calibration are shown in Table 2. A comparison
of the heat pump capacities and input power at all
216 points for the model values and calibrated values is
shown in Figure 4.

power input for mass flow rates of 0.47, 0.71 and
0.94 kg/s at both the evaporator and condenser, inlet
water temperatures of -1.2, 4.5, 10.1, 15.6, 21.2 and
26.7C at the evaporator and inlet water temperatures of
15.6, 26.7, 37.8 and 48.9C at the condenser, for a total
of 216 data points. Once again, the calibration is done
using only the 16 points corresponding to the
combinations of minimum and maximum values of the
inlet water temperatures and flow rates. The guess
values for each parameter and the set of parameters
resulting from the calibration are shown in Table 3. A
comparison of the heat pump capacities and input power
at all 216 points for the model values and calibrated
values is shown on Figure 5.

Table 2. Heat pump parameters for calibration using
model produced data.

Original
value
2.365

Guess
value
1.668

Calibrate
d value
2.362

0.00288

0.00193

0.00287

0.0041

0.00049

0.0041

 (C)

6.84

4.00

6.49

 (-)
 (W)

0.924

0.950

0.922

396.1

2206

398.7

 (W/C)

7007.7

5044.9

7014.5

 (W/C)

29991

5044.9

49136

Parameter
 (-)

(m3/s)
 (kg/s)

The calibration process yielded parameters within 0.7%
of the model value, except for the degree of superheating
(5.1%) and the heat transfer coefficient of the evaporator
(64%). The model appears not be very sensitive to the
heat transfer coefficient of the evaporator. For instance,
the sum of normalized square errors (Eq. 16) is
8.9410-6 using the calibrated values and 1.34410-5
when replacing only the heat transfer rate of the
evaporator with the model value. The computing time
for the calibration of the model was 80.5 sec.

4.2 Calibration from Manufacturer Data
The calibration method is also verified against
commercial heat pump data. Technical data for a
commercial water to water heat pump with 19.3 kW
nominal capacity and 4.5 nominal coefficient of
performance was used to calibrate the heat pump model.
The technical data includes values of the capacity and
224

Figure 4. Comparison of model produced and calibrated
model heat pump capacities and power input.

Overall, the calibrated model is in good agreement with
the manufacturer data. The sum of the normalized
square errors is 0.00507 and the maximum differences
between calculated heat pump capacities and power
input from the model and the manufacturer data are

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132219

Session 5B: Buildings II

2.7% and 4.7%, respectively. Similar results have been
obtained for different technical data from different
manufacturers. The computing time for the calibration
of the model was 72.3 sec. A database of sets of
parameters, provided via Records, for various heat
pumps from different manufacturers will be included
with the heat pump model.

radiators when required. The radiators are turned on
when the room temperature falls below the temperature
set points of 21C during the day and 16C at night. The
heat pump is turned on if the supply water temperature
from the radiators falls below the current set point and
turned off when the temperature at the bottom of the
storage tank rises above 55C. Cooling is provided by
outside air if the room temperatures rise above 22C.
Table 3. Heat pump parameters for calibration using
manufacturer data.

Parameter

Guess value

 (-)

(m3/s)
 (kg/s)

1.436

Calibrated
value
1.975

0.001484

0.001984

0.0004947

0.002566

 (C)

4.0

5.703

 (-)
 (W)

0.95

0.8192

2134

856.9

 (W/C)

6633.2

2840.4

 (W/C)

6633.2

21523

The nominal heating power of the boiler in the original
system is 2.2 kW. Therefore, the parameters to the heat
pump model were the same as those presented in
Table 3, with parameters  , ,  ,  and
 scaled by a factor 0.125 to obtain approximately
the same heating capacity.
The simulation time for the simulation model using
the heat pump is compared to the simulation time for the
model using the boiler. Both simulations are done using
the Radau solver, a tolerance of 110-6 and a simulation
stop time of 1 week. The simulation time using the heat
pump model was 48 seconds while the simulation time
using the boiler was 17 seconds.

5
Figure 5. Comparison of manufacturer and calibrated
model heat pump capacities and power input.

4.3 Hydronic Heating System
The heat pump model is integrated into a simulation
model of a hydronic heating system. The system model
is equivalent to the Buildings.Examples.
HydronicHeating.TwoRoomsWithStorage system
model from the Buildings library, with the boiler
replaced by a water to water heat pump with a constant
source temperature of 8C.
The hydronic heating system consists of two rooms
equipped with radiators. Hot water is produced by the
heat pump, stored into a storage tank and fed to the

DOI
10.3384/ecp17132219

Conclusions

A model for a water to water heat pump with a scroll
compressor is presented. To keep the computational
time small and to reduce the number of evaluations of
refrigerant thermodynamic properties, the model is
based on a simplified vapor compression cycle with
only five refrigerant states. Components for the
compressor, the evaporator and condenser, as well as
routines for the evaluation of thermodynamic properties
of refrigerant R410A were implemented in Modelica.
Parameters to the model are evaluated from
manufacturer data by solving the optimization problem
that minimizes the differences between the model
predicted heat pump capacities and power input and
those found in the manufacturer technical data.
The heat pump model was also implemented in
Python to facilitate the calibration process. While it

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

225

Modelling of Heat Pumps with Calibrated Parameters Based on Manufacturer Data

would be possible to call the Modelica model during the
optimization, a Python implementation was judged
more convenient in terms of ease of use. However, it
duplicates the implementation of the heat pump model,
which would make it difficult to apply the same
methodology to more complex systems. Support for the
preprocessing of parameters using Modelica models
within the Modelica framework would facilitate the use
of calibrated Modelica models.
The calibrated model presented in this paper has been
shown to generate heat pump capacities and power input
very close to the manufacturer data, and to be able to be
integrated into simulation models with minimal impact
on the simulation time. Future work will be devoted to
the extension of the methodology to more complex
cycles, such as multi-stage cycles, and to the modeling
of chillers.

Lund, H., Werner, S., Wiltshire, R., Svendsen, S., Thorsen, J.
E., Hvelplund, F., and Mathiesen, B. V. (2014). 4th
Generation District Heating (4GDH): Integrating smart
thermal
grids
into
future
sustainable
energy
systems. Energy, 68: 1-11.
Martin, J. J., and Hou, Y. C. (1955). Development of an
equation of state for gases. AIChE Journal, 1(2): 142-151.
Scarpa, M., Emmi, G., and De Carli, M. (2012). Validation of
a numerical model aimed at the estimation of performance
of vapor compression based heat pumps. Energy and
Buildings, 47: 411-420.
Swider, D. J. (2003). A comparison of empirically based
steady-state models for vapor-compression liquid
chillers. Applied Thermal Engineering, 23(5): 539-556.
Wetter, M., Zuo, W., Nouidui, T. S., and Pang, X. (2014).
Modelica Buildings library. Journal of Building
Performance Simulation, 7(4): 253-270.

Acknowledgements
This research was supported by the Assistant Secretary
for Energy Efficiency and Renewable Energy, Office of
Building Technologies of the U.S. Department of
Energy, under Contract No. DE-AC02-05CH11231.

References
Carbonell, S. D., Cadafalch, R. J., Prlisch, P., and Consul, S.
R. (2012). Numerical analysis of heat pumps models:
comparative study between equation-fit and refrigerant
cycle based models. in Proc. Int. Conf. on Solar Heating,
Cooling and Buildings, EuroSun 2012 (Rijeka, HR).
De Monte, F. (2002). Calculation of thermodynamic
properties of R407C and R410A by the MartinHou
equation of state  part I: theoretical development.
International Journal of Refrigeration, 25(3): 306-313.
Domanski, P. A., and McLinden, M. O. (1992). A simplified
cycle simulation model for the performance rating of
refrigerants and refrigerant mixtures. International Journal
of Refrigeration, 15(2): 81-88.
E. I. du Pont de Nemours and Company (2004).
Thermodynamic properties of du Pont Suva 410A
refrigerant.
URL
https://www.chemours.com/Refrigerants/en_US/assets/do
wnloads/h64423_Suva410A_thermo_prop_si.pdf.
Jin, H. (2002). Parameter estimation based models of water
source heat pumps. Ph.D. Thesis. Oklahoma State
University, Stillwater, OK, USA.
Jones, E., Oliphant, T., and Peterson, P. (2001). Open source
scientific tools for Python. URL http://www. scipy. org, 73,
86.
Lee, T. S., and Lu, W. C. (2010). An evaluation of
empirically-based models for predicting energy
performance of vapor-compression water chillers. Applied
Energy, 87(11): 3486-3493.
Lemort, V., and Bertagnolio, S. (2010). A Generalized
Simulation Model of Chillers and Heat Pumps to be
Calibrated on Published Manufacturer's Data. In
Proceedings of the International Symposium on
Refrigeration Technology 2010, Zhuhai, China.

226

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132219

Simulation of Large Grids in OpenModelica:
reflections and perspectives
Francesco Casella1
1 Dipartimento

Alberto Leva1

Andrea Bartolini2

di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Italy,
{francesco.casella,alberto.leva}@polimi.it
s.r.l., Italy, andrea.bartolini@dynamica-it.com

2 Dynamica

Abstract

overall discussion on this topic. Preliminary results were
presented in (Casella et al., 2016), which was mainly addressed to the power system community. This paper incorporates the results of additional work carried out since
then, and presents the current state of the research from
the perspective of the Modelica community.

This paper belongs to a long-term research activity on
modelling and simulation of large-size power grids in
Modelica, using the OpenModelica Compiler. We describe the present state of the research, its evolution over
the last year, the conclusions we could reach in this period in comparison with the initial hypotheses, and some 2 Previous research
results. Finally, we outline the future of the presented acIn this section we summarise the research context and
tivity.
Keywords: Grid Modelling and Simulation, Large-Scale the results from which we started, referring the interested
reader to (Casella et al., 2016) for further details.
Systems, Efficient Simulation.
National grids in Europe are rapidly evolving (ENTSOE,
2015, 2014). The penetration of intermittent sources
1 Introduction
like wind and solar enhances the need for continent-level
The modelling and simulation of large power grids is an integration for countries to help one another. Transemerging domain of interest for the Modelica language, mission networks are moving from the traditional strucas the encountered problems basically consist of large net- ture dominated by large synchronous generators and AC
worked systems with decentralized control, where multi- links, toward an increasing share of HVDC links and of
ple producers and consumers cooperate to the goals of sta- medium- and small-scale generators interfaced to the grid
ble network behaviour, satisfaction of all the load requests, via AC/DC/AC links. As a consequence, the manageand system optimality.
ment of transmission grids by national Transmission SysAlthough control strategies for such large-scale systems tem Operators (TSOs) increasingly requires knowledge of
are usually designed as hierarchical systems, abstracting the dynamic behaviour of the the system outside the counlow-level behaviours within higher levels, it is sometimes try boundaries.
necessary to simulate the entire system. This can be the
Traditionally, well-established domain-specific tools
case when a full verification of the designed strategy, in- are used such as PowerFactory, PSS/E, and Eurostag.
cluding the interactions among its parts, is in orderand These tools come with extensive component libraries, but
this is an issue shared by any large-scale system.
the exact formulation of the said models is difficult to acIn the case of electric grids, there is another problem cess, since they are written in low-level languages like
to address. For management reasons at the nation- or FORTRAN. With commercial tools, the models source
continent-wide scale, it is required to periodically assem- code might even be unavailable to the end user. This hinble a model of the entire system and use it to run numerous ders the required interoperability, as models of the same
simulations, to verify that the stress expected in the next object in different tools may behave differently. Indeed,
time period can be sustained without incurring in stability full interoperability would ideally require all European
problems, to test critical manoeuvres when required, and TSOs to use the same simulation tool.
possibly to take decisions in a view to optimise the operModelica has been already used for the modelling
ation. This particular use of simulation makes a fast code of electrical power systems, including detailed machine
generation vital.
models (Franke and Wiesmann, 2014; Kral and Haumer,
Over the last two years, we have been working on 2005), and more recently it has been considered also to
this subject, with the goal of providing an entirely model electro-mechanical transients in high-voltage genModelica-based solution using the open-source Open- eration and transmission system. In this context, an acModelica Compiler (OMC) for code generation. The tivity worth mentioning is the iTesla European FP7 reproblem at hand is one very interesting case of an emerg- search project (Vanfretti et al., 2013, 2014; Zhang et al.,
ing class of large-scale models, see (Casella, 2015) for an 2015), although the results of the project refer to small- or
DOI
10.3384/ecp17132227

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

227

Simulation of Large Grids in OpenModelica: reflections and perspectives

medium-sized power systems, with at most a few dozens
generators and transmission lines.
At the beginning of this activity, we formulated the
following research question: "Are Modelica and Modelica tools adequate to support the simulation of electromechanical models of national- and continental-size
power grids?". From that moment till now, we have been
building a prototype model library, using which many test
cases have been created and analysed to answer the research question stated above. The library contains representative models for the main components used in the addressed systems, i.e., generators, governors, transformers,
transmission lines, and loads. Note that the goal of this
library is not the accurate modelling of any real system,
but rather to build realistic models of large-scale power
systems in order to test the ability of Modelica tools to
handle them. The simulation code is generated with the
open-source OpenModelica Compiler (OMC).
The results obtained so far are encouraging, but at the
same time the activity has revealed several shortcomings
of the OpenModelica environment, in particular referring
to the efficiency of both the code generation and the simulation phase. A development activity was therefore carried out  and is still ongoing  within the OpenModelica
Consortium to address the evidenced problems, and verify
the effects of the introduced improvements with respect to
some representative benchmark cases. The result of the
activities just sketched is presented in the following.

3

Current research activity

For the purpose of this study, a prototype library has been
built, providing models of synchronous generators, transformers, transmission lines with breakers and over-current
protections, electrical loads, and governors. All the highlevel modelling features of Modelica, like the support for
complex numbers, were extensively used.

systems are feasible, but are far more computationally demanding, and outside the scope of our study.
It is also assumed that the network frequency stays
close enough to its reference value, so that the impedances
can be computed with that value, ans considered constant.
There are some similarities between the design of this library and that of the Modelica.Electrical.QuasiStationary
library.
However, the specific modelling framework which is
required for large power grid studies, i.e., three-phase
balanced systems represented by one equivalent phase
only, is not directly available there.

Figure 2. Model of a transmission line (excerpt).

Figure 2 shows an excerpt of transmission line model,
including breakers for current protection. The two algorithms compute the state of the breaker on the one side of
the line (the other is omitted for brevity), while the equations describe admittances, currents and voltages.

Figure 1. Connector definition.

Figure 1 shows the types for complex current and voltage, used to define the electrical connector. It is assumed
that the three-phase voltages and currents are always balanced and described by phasors referred to a common reference frame rotating with a reference speed/frequency,
usually that of a strong generator in the network.
Under these assumptions, a three-phase voltage and
current system can be described by just one voltage and
onecurrent phasor, provided the appropriate factors of 3
or 3 are taken into account when computing the actual
power flows. Most large-scales grid studies are made under this assumption; extensions to unbalanced three-phase
228

Figure 3. Model of a transformer (excerpt).

The equations for the transformer model are
analogoussee Figure 3, where again just an excerpt is
reported for brevity.
The model of a synchronous generation unit is built
hierarchically, by connecting those of synchronous machine, governor, and exciter controller, see Figure 4. The
synchronous generator is described by the simplest possible 4-state model, taking the mechanical power input
Pm_req from the governor, and the normalised excitation
voltage vf from the voltage controller.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132227

Session 5C: Electrical & Power Systems I

Figure 4. Generator model.

by the equation V = ZI, where Z is a constant complex
impedance. PQ models can be easily obtained by writing
equations that prescribe the real and imaginary parts of
the complex power flow through the Pin connector of the
load. However, doing so makes the (large) implicit system
of equations describing the network nonlinear.
Since reliable sparse nonlinear solvers were not available in the Modelica tool used for this study at the beginning of the work, a linearized PQ model was also implemented, in which the relationships between complex
voltage, current and power were linearized around the
nominal operating point, which is supplied by an external power flow computation. Later on, as full nonlinear
sparse solvers became available both for initialization and
simulation, the regular PQ load models were used.
In order to simulate network protection strategies, it
is necessary to be able to simulate the dynamic formation of more than one electrical islands from an single
synchronous network, due to the opening of strategically
placed circuit breakers. The newly formed islands need
separate frequency references and may drift apart from
each other. In this case, three factors shall be considered:
1. topological factor, i.e., detecting the formation of
sub-islands in the network, starting from the actual
status of circuit breakers,
2. functional factor, i.e., assessing the ability of each
island to survive in terms of voltage and frequency
regulation,

Figure 5. Synchronous generator equations (excerpt).

This model is interfaced to the rest of the system
through a Pin connector (see Figure 1). The core equations are shown in the excerpt of Figure 5.

Figure 6. Excitation system model, according to IEEE Std
421.5-2005.

The governor and exciter models (see for example Figure 6) are simple block diagrams, in accordance to the
IEEE standards. A graphical representation is here preferred to a text-based one, as it is immediately familiar to
any practitioner in the field.
Coming to loads, both linear and nonlinear models
are provided. The basic linear load model is described
DOI
10.3384/ecp17132227

3. modelling factor, i.e., finding a model structure
which allows the models to properly work after the
islanding event in each of the possible functional
condition, avoiding singularities or other numerical
problems that would cause the simulation to abort.
Up to the authors understanding, this is a major departure from the modelling assumption and the structure of
all the existing Modelica libraries for multi-phase power
system modelling, which assume a fixed connection topology throughout the simulation, and exploit this property to
use the over-constrained connector features originally introduced in Modelica 3.0, propagating the phase reference
through the connectors. Unfortunately, this feature cannot be used for the grid models considered in this paper,
unless it is extended to handle dynamically changing connection graphs; this in turn would require a change of the
Modelica language, and major changes to how this feature
is handled in the Modelica tool.
In this study a prototype framework to manage this aspect was implemented using Modelica 3.3. In fact, for
the purposes of the testing activities carried out so far,
the topological analysis was not handled with a generalpurpose algorithm (that could be implemented as an external C function), but rather hard-coded in simple Modelica
functions that returned the results of the analysis, which
were known a-priori for those tests.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

229

Simulation of Large Grids in OpenModelica: reflections and perspectives

In a nutshell, the prototype framework is based on a specifically towards the efficient solution of electrical cirNetwork Supervisor model, which is unique for the entire cuit equations. This restricted the choice of system models to those in which the very large strong component of
grid model. The supervisor:
the causalized system equations is linear. This sub-set
 receives the status of the network breakers via in- of equations comprises the transformer and transmission
put/output connections and monitors their changes; lines components (which are linear) and the load models,
which can then be either constant impedances or PQ load
 performs the topological analysis and detects the for- models linearized around the nominal operating point.
mation of islands in the grid each time the breaker
The only viable integration strategy given this limistatus changes;
tation was then to causalize the system of differentialalgebraic equations, bringing it into state-space form, and
 sends to each load via input/output connections the then integrating it with an explicit ODE solver. At each
new activation status (active/not active) and to each time step, the calculation of the derivatives requires the
generator the new frequency reference (or reference solution of the very large strong component of the system,
generator), when the breaker opening actually leads which is performed by the KLU sparse solver.
to island formation.
Steady-state initialization was also feasible by prescribing the currents at the boundaries of the synchronous
Generators and loads change their active equations (us- generators to the values obtained by the external powering conditional equations) and frequency reference, ac- flow computations, which allows to split the initialization
cording to the information received from the Network Su- problem into one very large linear system (transformers
pervisor, in order to avoid singularities that may prevent + transmission lines + loads) and many small nonlinear
the simulation from continuing. For example, all PQ load problems (each individual synchronous generator). The
models are turned into open circuits when they find them- availability of an external power-flow computation is also
selves in a not active island i.e., an island without gen- essential to set proper initial guess values on the nonlinear
erators, because otherwise the system of equations of the problems.
sub-island would have no solution, aborting the simulaThe models were simulated for 20 seconds, which is
tion.
the typical length of transients for stability studies, using Heuns algorithm (2nd order Runge-Kutta) and a fixed
Network
Nodes
Gens
Lines
Trafos
Equations
time step of 20 ms. The transmission lines currents are
GRID_C
751
74
369
583
56386
GRID_E
1817
267
1458
1202
157022
monitored on both sides, but no breaker ever tripped.
GRID_D
8376
2317
1946
2489
579470
Code generation and simulations reported here were
GRID_G
8113
407
6833
2824
593886
carried out on an Intel Xeon CPU E5-2650 server with
20 virtual cores at 2.30GHz, 72 GB of RAM installed,
running Linux Ubuntu 16.04 LTR 64 bit and using OMC
Table 1. Features of the exemplary grids.
1.11.0-dev-59. Each simulation was carried out as a single
thread, which is reasonable as multi-core systems can be
Coming to the test cases, four exemplary grids of difexploited by running several simulation scenarios in parferent sizes were considered, named in the following
allel. The parts of the code generation process that can run
GRID_{C,E,D,G}. Table 1 summarizes the main feaindependently are instead parallelised in OMC, as well as
tures of the models, which describe the Irish power systhe compilation of the C code.
tem, the 400 kV Italian power system, the 400 kV paneuropean transmission system, and the detailed 400-220Network
Flattening C gen.
Compilation
Simulation
150-132 kV transmission system, respectively. The modGRID_C
24
24
13
12
els were supplied by CESI in the context of the study reGRID_E
73
67
35
44
GRID_D
334
315
123
111
ported in (Casella et al., 2016). Note that the number of
GRID_G
318
303
144
186
nodes, reported for convenience, is not always a reliable
complexity indicator, because a node can have a very variable number of attached entities, each in turn of different
Table 2. Performance results (times in seconds).
complexity; for this reason, we also report the number of
equations. The results obtained by simulating these modPerformance results are summarised in Tab. 2. Notice
els are summarised and discussed in the next section.
for clarity that the third column includes both the time for
structural analysis and optimisation, and that for C code
4 Simulation results
generation. The fourth column is the time used by the C
During the first round of activity, that took place between compiler and by the linker, while the fifth shows the total
November 2015 and July 2016, the only fully reliable simulation time. The simulation time is almost twice as
large-scale sparse solver made available by the OpenMod- fast as real time for the smallest grid, and about 10 times
elica tool was the KLU linear solver, which is geared slower for the largest one.
230

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132227

Session 5C: Electrical & Power Systems I

The time spent for flattening, structural analysis, Ccode generation and compilation currently dominates, taking up to about 13 minutes for the largest case. This is already a feasible situation for off-line applications, in particular if one generates the simulation code once and then
runs many simulations with it, by only changing the parameters in the initialization files, which can include for
example the tripping times for circuit breakers, the load
values, and so forth. However, such a code generation and
compilation time is still definitely too long for real-time
applications, with the typical turnover time of TSO operations, which is around 15 minutes. The peak recorded
memory allocation was about 20 GB of RAM, which does
not pose any problem on reasonably sized systems.
As to event handling, the event detection logic currently
implemented in OMC uses a simple bisection algorithm
to determine the exact point in time when thresholds are
crossed. If a great precision is not necessary, only a few iterations would be required, whose cost will be comparable
to that of carrying out a two-stage time integration step.
Otherwise, it could be possible to implement a more sophisticated event detection, for example using a Newtonbased algorithm.
Later on, as the sparse nonlinear solver Kinsol and the
sparse DAE solver IDA became available in the OpenModelica tool, it was possible to use the full nonlinear
PQ load models, as well as to employ a variable step size
sparse implicit DAE solver, which turns out to be more
efficient than explicit solvers as the underlying system is
somewhat stiff. Note that in this case the system is not
causalized and brought to state-space form; after alias reduction (and possibly index reduction, which however is
not required for these specific models), the resulting DAEs
are passed directly to the solver.
An example is shown in Figures 7 and 8, where three
solvers are compared:

 Runge-Kutta/KLU on the grid model with linearized
PQ loads,
 IDA/Kinsol/KLU on the grid model with linearized
PQ loads,
 IDA/Kinsol/KLU on the grid model with nonlinear
PQ loads.
The simulated transient is a 30% step reduction of the
active power of one of the PQ loads (node N_152) in
the smaller GRID_C model. The transients obtained with
KLU and IDA/Kinsol on the linear network model match
within the relative tolerance of the variable-step integrator,
i.e., 106 .
Figures 7 and 8 show the frequency transient in node
N_152 (load) and node N_144 (generator). The frequency
peak at node N_152 is about 50.1 Hz. The blue and green
(overlapped) traces refer to the PQ linearised model, integrated using the KLU and the IDA solvers respectively,
DOI
10.3384/ecp17132227

Figure 7. KLU and IDA/Kinsol test  frequency transient at
load N_152.

while the red one refers to the PQ non-linear model, integrated using the IDA solver. It is apparent how the linearized model is perfectly adequate to solve this kind of
transients, although it could end up being badly off in
other more severe transients.
Performance results obtained with the IDA solver are
reported in Table 3, using the same hardware of earlier experiments and OMC 1.12.0-dev-731. The simulation time
shown is net of the time for set-up, initialisation and writing results to mass storage. Comparing these results with
those of Table 2, it is apparent how this solution strategy is
much more efficient, despite the additional computational
complexity brought in by the nonlinear load models.
The advantage of using the variable step-size DAE
solver are even more evident if longer simulation intervals are taken, as is for example the case when addressing
voltage stability studies. The ability of the implicit DAE
solver to take steps with a length of many seconds when
the system is close to steady-state, allow to massively outperform the explicit ODE solver, whose step length is unconditionally limited to a few tens of milliseconds owing
to numerical stability problems.
The times for code generation and compilation are not
reported here, as these phases have not yet been optimized
for this kind of solver, so that the results are not indicative
of the performance that could be achieved once all current
performance bottlenecks have been resolved.
Finally, the Network Supervisor prototype was tested
on the same GRID_C model, using PQ linearized
load models, and changing some over-current protection
thresholds in such a way to result in the opening of four
lines after 1 s from the simulation start. These lines opening generate three sub-islands.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

231

Simulation of Large Grids in OpenModelica: reflections and perspectives

Figure 8. KLU and IDA/Kinsol test  frequency transient at
generator N_144.

Figure 9. Network generator frequencies.

Table 3. Simulation performance with the IDA sparse DAE
solver

One can see a small power oscillation (lower than 20 kW),
taking place symmetrically between the two machines.

Network

Rel. tol.

No. of steps

Sim. time [s]

GRID_C
GRID_C
GRID_E
GRID_E
GRID_G
GRID_G

104
106
104
106
104
106

39
146
140
364
221
615

0.96
3.18
8.80
15.22
59.95
123.19

 Sub-island 1, which contains only three generators,
two of these in frequency regulation. The generators will be shut down, bringing their power output
to zero rapidly.
 Sub-island 2, a small sub-island with six generators.
All generators are kept in regulation and a new reference generator will be assigned (N_517).
 Sub-island 3, a big sub-island, which contains the
rest of the network. All generators are kept in regulation and the reference generator does not change.
Figure 9 shows the new frequency rearrangement after the protection opening. Starting from the top, the
first trace refers to the sub-island 2, which reaches a new
steady-state with a frequency deviation of about 0.9 Hz;
the second trace refers to the sub-island 1, which is shut
down, and shows a transient with a frequency peak deviation of about 1.2 Hz; the last trace refers to the sub-island
3, which is the most stable due to its large dimension.
Figure 10 shows the shut-down transient in the subisland 1 for the two generators in frequency regulation.
232

5

Conclusions and future work

At the beginning of the activity to which this paper belongs, the research question was whether or not is it feasible to use the Modelica language and Modelica simulation tools to handle nation- and continental-wide electromechanical power system models. Over the last year, we
reached an affirmative conclusion, though there is clearly
work to be done to speed up the code generation phase,
which is still too long for many application contexts.
More in detail, we could prove the feasibility of using 100% Modelica models for the simulation of transients in systems of national and continental size, albeit
currently with very simple generator and controller models. The only exception is topological analysis, which will
arguably be better handled by external C code, possibly
re-using legacy code that performs the same task.
The simulation times we observed, particularly when
using the variable step-size sparse DAE solver IDA, are
acceptable, and are certainly amenable to further improvements as the implementation of that solver in OpenModelica is streamlined and optimized. On the other hand,
there is still much work to do in order to reduce the time
for code generation by at least one order of magnitude.
Development activities are under way on the OpenModelica compiler to achieve this goal, most notably a new,
much faster front-end, as well as code generation algorithms that are optimized for the sparse DAE solver. We
also evidenced the need for further improvements as for
the model initialisation and the event handling.
It is worth noticing that we could carry out all the re-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132227

Session 5C: Electrical & Power Systems I

ENTSO-E. ENTSO-E policy paper: Future TSO coordination
for Europe. Technical report, ENTSO-E, 2014.
ENTSO-E. ENTSO-E work programme 2015 through 2016.
Technical report, ENTSO-E, 2015.
R. Franke and H. Wiesmann. Flexible modeling of electrical
power systems  the Modelica PowerSystem library. In Proc.
of the 10th International Modelica Conference, pages 515
522, Lund, Sweden, 2014.
C. Kral and A. Haumer. Modelica libraries for DC machines,
three phase and polyphase machines. In Proc. 4th International Modelica Conference, pages 549558, Hamburg, Germany, 2005.
L. Vanfretti, M. LI, T. Bogodorova, and P. Panciatici. Unambiguous power system modeling and simulation using Modelica tools. In 2013 IEEE Power & Energy Society General
Meeting, 2013.

Figure 10. Active power of generators in sub-island 1.

search activity entirely within the OpenModelica framework, particularly after several improvements were made
to the compiler front-end, back-end, and simulation runtime.
Given the positive outcome of this first one and a half
year of ground-breaking work, the authors believe that
some more specific investment in the development of the
OpenModelica tool for this type of applications could lead
to much better performance than what is reported in this
paper. Even if the performance of domain-specific tools
may not be fully reached, the added value brought in terms
of flexibility and openness by the use of the Modelica
object-oriented modelling framework, as well as by the
use of open-source tools like OpenModelica, makes this
research activity worth to be further pursued.

6

L. Vanfretti, T. Bogodorova, and M. Baudette. A Modelica
power system component library for model validation and parameter identification. In Proc. 10th International Modelica
Conference, pages 11951203, Lund, Sweden, 2014.
M. Zhang, M. Baudette, J. Lavenius, S. Lvlund, and L. Vanfretti. Modelica implementation and software-to-software
validation of power system component models commonly
used by nordic TSOs for dynamic simulations. In Proc. 56th
SIMS Conference on Simulation and Modelling, pages 105
112, Lund, Sweden, 2015.

Acknowledgements

The authors gratefully acknowledge the financial support
of CESI S.p.A. and RTE for supporting this research work.
They also want to thank the entire development team of
OpenModelica for their support and hard work, which
made these developments possible.

References
F. Casella. Simulation of large-scale models in Modelica: state
of the art and future perspectives. In Proc. 11th International
Modelica Conference, pages 459468, Versailles, France,
2015.
F. Casella, A. Bartolini, S. Pasquini, and L. Bonuglia. Objectoriented modelling and simulation of large-scale electrical
power systems using Modelica: a first feasibility study. In
Proc. 42nd Annual Conference of the IEEE Industrial Electronics Society, pages 62986304, Florence, Italy, 2016.

DOI
10.3384/ecp17132227

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

233

234

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

A Tool to ease Modelica-based Dynamic Power System Simulations
Raul Viruez1

Silvia Machado1 Luis Mara Zamarreo1 Gladys Len1
Sbastien Petitrenaud2 Jean-Baptiste Heyberger2
1 Aplicaciones

Franois Beaude2

en Informtica Avanzada S.L., Sant Cugat del Valls, Spain.

{viruezr,machados,zamarrenolm,leonge}@aia.es
2 Rseau

de Transport dlectricit , Paris, France.

{francois.beaude,sebastien.petitrenaud,jean-baptiste.heyberger}@rte-france.com

Abstract
Developments made during the EU FP7-funded project
iTesla towards automatic ways of transforming power systems from proprietary format to Modelica, served as a
proof of concept for the adoption of Modelica as a common and standardized language for power system modelling and simulation. This work is a continuation of
the progress made during the iTesla project. This paper
presents a tool developed with the main purpose of providing users with an easy way to generate power system networks in Modelica and perform time-domain simulations.
The tool is validated by generating Modelica systems for
IEEE cases and comparing simulation outputs with a reference commercial tool (Eurostag).
Keywords: Modelica, open source software, power system
modelling, power system dynamics, CIM.

1

Introduction

The work presented here is a continuation of the developments made during the iTesla1 project towards the automatic transformation of power system networks for performing phasor time-domain simulations using Modelica.
The specification for the automatic transformation was
presented in (Vanfretti et al., 2016) and this work presents
its full implementation in a user-friendly and open source
tool.
One of the most challenging objectives of the iTesla
project was to conduct accurate pan-European security assessments taking into account system dynamics in addition to static analysis. This task requires the execution
of time-domain simulations considering a large number
of contingencies. But one of the main obstacles for running such simulations is that each European TSO relies
on its own (proprietary) data format in order to describe
dynamic models.
To address this issue, iTesla partners agreed to use
Modelica2 as the standard language for power system dynamic modelling. The use of Modelica as a common language for power system dynamic simulations began with
1 iTesla:

Innovative Tools for Electrical System Security within
Large Areas. http://www.itesla-project.eu/
2 Modelica
R
and the Modelica Association.
https://
modelica.org/

DOI
10.3384/ecp17132235

a previous European project named PEGASE3 , where
simple systems were studied. During the iTesla project
several software modules were developed to automatically
transform power system models from different proprietary
formats, used by TSOs, to Modelica. Also, a Modelica
library containing electrical and logical models was implemented (Bogodorova et al., 2013) and validated against
domain-specific simulation tools (PSS/E and Eurostag).
This library called iPSL (iTesla Power System Library),
is open source and can be found at the project repository4 .
The developments made during the iTesla project allowed the successful conversion of several European
power systems ranging from a dozen to hundreds of buses,
and a similar number of generator machines, from PSS/E
or Eurostag format to Modelica. Time-domain simulations, including contingencies, were performed on the
automatically converted systems, thus achieving one of
the main objectives of the project. The iTesla project
served as a proof of concept for the usage of Modelica as a
standard language for power system modelling, but many
manual tasks were still required for each study conducted.
At the end of the project, the authors of the present
work decided to further expand the iTesla software developments exploiting some of the current results, the expertise gained in Modelica, and the team working strength, for
the development of a simulation tool based on Modelica.
This user-friendly tool, from now on referred to as Power
Systems on Modelica (PSM) tool, automatically generates
and simulates power systems in Modelica. The tool is intended to be fully compatible with the iPSL library (iPSL
has been enlarged and improved for this purpose), but the
user will not be limited to the library models, since any
Modelica model may also be freely added.
One of the main goals pursued with the development
of such a tool, which will be released open source, is
to enable users to easily convert CIM5 electrical networks to Modelica, in order to ease the transition to an
open equation-based language for power system modelling. This paper presents the automatic model generation
3 PEGASE: Pan European Grid Advanced Simulation and State Estimation. http://www.fp7-pegase.com/
4 iPSL repository. https://github.com/itesla/ipsl
5 ENTSO-E Common Information Model (CIM) for grid model exchange. https://www.entsoe.eu

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

235

A Modelica-based Tool for Power System Dynamic Simulations

developed for the tool and shows some preliminary results.
The paper is organized as follows. Section 2 presents
the PSM tool and how the automatic model generation is
achieved. In section 3 specific cases are used to validate
the tool. And finally, section 4 presents the conclusions
and future work.

2

PSM tool

The PSM tool6 is intended to generate power system networks in Modelica (*.mo files) from CIM files containing
static system models and state variables from a given snapshot, plus dynamic data given in XML files. A power flow
computation is run over the network to obtain the steadystate of the system. A Dynamic Data Repository (DDR) is
used for defining which dynamic models, either from iPSL
library or user-defined, should be used to map network
equipment, and which parameters must be used to instantiate those dynamic models. The users also have the possibility to perform time-domain simulations using a Modelica
solver engine (either OpenModelica or Dymola).
The tool has been designed to ensure modularity, allowing users to either run processes individually or as a
full workflow. The software is built as a modular Java
application. Modules can be used directly from the command line or from a simple JavaFX user interface. Various
power flow engines and Modelica simulation engines can
be used, and further user-defined interfaces may be added
later on.
The general architecture of the tool is shown in Figure 1. The different modules involved in the conversion
process are: 1) CIM importer, 2) Power flow computation,
3) Modelica file generation, 4) Dynamic simulation definition, and 5) Time-domain simulation.
The tool first converts CIM data files into the iTesla
Internal Data Model7 (IIDM), on which a power flow is
computed. Then another module generates the Modelica
file connecting to the Dynamic Data repository to retrieve
dynamic data. The user has the possibility of introduce
events to be studied in the dynamic simulation, and finally run time-domain simulations with a Modelica engine
(currently OpenModelica or Dymola) selecting the desired
simulation parameters.
The individual modules are described below.

2.1

CIM importer

The main goal of this module is to import a network system model file in CIM format and convert it to IIDM. The
module only supports CIM-compliant files (at the time this
work was prepared: ENTSO-E CIM Profile 1). The user
6 PSM

tool will be released open source in a specific repository starting June 2017. The exact link will be published in the iPSL repository
https://github.com/itesla/ipsl.
7 The IIDM allows to import, export and edit power system models
in the iTesla platform. Specifications on IIDM format can be found
at the GitHub repository for iTesla Power System Tools. https://
github.com/itesla/ipst

236

is free to manually write/update CIM files, as long as the
generated file is CIM-compliant8 .

2.2

Power flow computation

This module is in charge of computing the power flow over
the IIDM network obtained in the previous step. The tool
has been designed to work with two different alternatives
for power flow computation:

 HELMTM -Flow power flow engine9 .
 HADES power flow engine 10 .
The tool is intended to allow easy switching between
these two engines. The values obtained from the power
flow computation are re-injected into the IIDM network
before moving on to the next module, i.e. the Modelica
file generation. The user also has the possibility of deactivating the power flow computation and generating the
Modelica file using input values from CIM.

2.3

Modelica file generation

This module is responsible for the generation of the
Modelica (.mo) file. The tool enables the user to specify
dynamic models (relying on the iPSL library and/or userdefined libraries) and parameters for each static item in the
given network setup, as well as to provide default parameters for each dynamic model. Default dynamic models can
also be defined for each static object type.
As depicted in the general architecture of the tool (Figure 1), this module connects to the DDR populated with
the system dynamic data and all necessary models.
The DDR is based on a set of XML files that store:

 Which mappings from static network elements to dynamic models to use in the dynamic system model
building (and its connections).
 The definitions required for building full model initialization simulations of complex dynamic models.
 The parameter sets used for dynamic model instantiations. Global declarations and system wide equations.
Full model initializations (see the blue box at the bottom
of the Modelica file generation module in Figure 1) refer
to the derivation of relevant and coherent initial values for
all model variables based on power flow outputs and external parameters. This is done by performing very shorttime simulations of the specific models using either OpenModelica or Dymola. This initialization is performed
8 Although CIM format can be used for dynamic models exchange,

it
is currently hardly used for this purpose in the power system community.
Therefore the DDR option was considered more appropriate for PSM.
9 For more information on HELMTM -Flow, see http://
elequant.com/. This product is based on the Holomorphic Embedding Load Flow Method(Trias, 2012).
10 RTE official power flow engine.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132235

Session 5C: Electrical & Power Systems I

Figure 1. General Architecture of the PSM tool

only for component models requiring explicit initialization, which is the case of some generator machines and
may be the case for specific control models. The main advantage of using full model initialization instead of initial
equation inside Modelica models (the common initialization strategy in Modelica) is that the use of external (local)
initializations can significantly increase simulation speed
since it reduces the size of the initial system to be solved
(especially for large systems) and it is designed to be very
scalable. The use of initial equation may cause boundary
problems and increase the number of equations, resulting
in a decreased performance. See (Vanfretti et al., 2016)
for more details on initializations schemes.

2.4

Dynamic simulation definition

This module is intended to define the simulation scenario.
The user can define events to be triggered at specific times
during the simulation. This module also allows defining
load variations, capacitor changes, etc. As a result, one
or several Modelica files are generated in addition to the
Modelica base case generated in the previous step.

2.5

Time-domain simulation

This module is in charge of running time-domain simulations on the Modelica files generated with the tool, allowing the user to chose between two Modelica simulations
engines: OpenModelica or Dymola. PSM fully relies on
these engines to run simulations, and thus one of them
must be previously installed before the user starts running
the PSM tool.
OpenModelica is an open source Modelica environDOI
10.3384/ecp17132235

ment, freely downloadable11 . Instead, Dymola is a commercial environment12 . The user may also directly open
the generated Modelica file in any preferred Modelica environment for edition and simulation.
In PSM, the user has access to the definition of standard simulation setup (simulation interval, output interval,
integration method, integration tolerance, fixed integrator
step, etc.) given by the available simulation solver: OpenModelica or Dymola. The Time-domain simulation module will generate output files in the standard Modelica
output format (MATLAB binary format *.mat), which is
provided by both supported simulation engines, as well as
in *.csv format. This will allow the user to import simulation results into the preferred Modelica environment or
other software for plotting and analysis of results.

2.6

User interface

The tool also includes a basic graphical user interface with
functionalities allowing the user to select which processes
to run, on which data sets, and displaying progress and
logs, without having to manually run command line actions.

3

Tools validation

Different power system networks are being used to test
and validate PSM. Some of these systems were already
used for testing developments made during the iTesla project and the results are presented in (Vanfretti et al., 2016)
and (Len et al., 2015). In this work, validation was
11 OpenModelica.
12 Dymola

https://openmodelica.org/
by Dassault Systmes. http://www.3ds.com

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

237

A Modelica-based Tool for Power System Dynamic Simulations

also performed using IEEE13 cases (IEEE14, IEEE30,
IEEE57, and IEEE118), which have not yet been used before.
All IEEE cases have been generated in Modelica format
using PSM, and for this all necessary dynamic models
from Eurostag were included in iPSL and DDR files were
generated with the corresponding dynamic data. Eurostag
equivalent models were created in Modelica using the exact same equations used by this proprietary software. This
section presents the results obtained with the IEEE57 and
IEEE118 cases.
The results obtained with the different generated
Modelica systems are compared against the exact same
networks built in Eurostag, taking this software as a reference. Validations are done both graphically and numerically. The numerical assessment is carried out using
the Root Mean Square Error (RMSE) as done in previous works (Vanfretti et al., 2016). The assessment metric
chosen to accept the results as valid is that the absolute
RMSE is  1003 for all compared values (voltage magnitudes in p.u. and angles in radians in all buses).

3.1

Figure 2. Simulation of the IEEE57 case with a bus fault of 0.2
seconds occurring at t=1 s. The blue dashed line corresponds
to Dymola simulation results and the red solid line to Eurostag
results.

IEEE57 case

The IEEE57 test case is composed of 57 buses, 7 generators, 63 lines, 17 transformers, 42 loads, and 3 compensation banks. The generators are modelled in Modelica
as synchronous machines defined by external parameters. This Eurostags model, together with the machine
described using internal parameters, were developed and
included in iPSL during the iTesla project. The control
systems present in this IEEE case are a voltage controller
ExcSEXS, an stabilizer PSSI3E2B, and a governor GovSteam014 . These models were developed in Modelica and
Eurostag specifically for PSM, and have been included in
iPSL15 . Two types of events were introduced to validate
the results of time-domain simulation performed with the
Modelica model, using Dymola, against Eurostag.
Figure 2 shows the voltage magnitude at a given specific bus when a bus fault event is introduced (at this
bus) at time t=1 seconds, lasting 0.2 seconds. As can be
seen in the figure, the curves obtained with the Modelica
system generated with PSM and simulated using Dymola
(blue dashed line), and the Eurostag system (red solid line)
match very well. The numerical assessment test was carried out obtaining a RMSE for all voltage magnitudes and
angles bellow the defined threshold (1003 ).
Figure 3 shows the response of the IEEE57 test case
to a line fault lasting 0.1 seconds occurring at time t=1
seconds, where again, the results obtained with Modelica
system using Dymola (blue dashed line) and Eurostag (red
solid line) are very similar. The RMSE obtained is below

Figure 3. General Simulation of the IEEE57 case with an open
line of 0.1 seconds occurring at t=1 s. The blue dashed line
corresponds to Dymola simulation results and the red solid line
to Eurostag results.

the threshold.
All simulations in Dymola were performed using the
DASSL integration method with a tolerance of 1006 .
Typical times for running the type of simulations shown
for the IEEE57 case are 300 seconds to simulate 4 actual
seconds. These simulations were run in a machine with
13 Power Systems Test Case Archive from the University of WashR Xeon
R CPU E5the following characteristics: Intel
ington.
https://www2.ee.washington.edu/research/ 2690 2.60 GHz (2 processors), 48 GB of installed memory
pstca/
(RAM) and 64-bit Operating System. Eurostag simulation
14 Control systems were built following standard IEC 61970-302.
15 All these Modelica models can be found at the iPSL repository.
for the same system takes only a few seconds to complete.
https://github.com/itesla/ipsl

238

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132235

Session 5C: Electrical & Power Systems I

Figure 4. General Simulation of the IEEE118 case with a bus
fault of 0.2 seconds occurring at t=1 s. The blue dashed line
corresponds to Dymola simulation results and the red solid line
to Eurostag results.

3.2

IEEE118 case

to open simulation tools to improve cooperation and exchange for performing dynamic power system simulations.
Modelica allows enhanced transparency and results in
power system modelling and simulation, with all the necessary ingredients to become a standard language for
power system modelling. However, there is a clear need
for easier ways to transform power systems networks
into the Modelica language. The proposed tool is designed to provide such possibility and bridge the gap
between Modelica and power system simulations, in order to ease widespread adoption among the power system
community.
For the development of this tool, the authors have proposed a simple architecture that, given the correct inputs,
allows the user to generate a Modelica file and simulate it
using a Modelica solver engine. The tool has been validated with a variety of power system networks, comparing
simulation results with a reference commercial software
(Eurostag). In particular, results obtained with two IEEE
cases are presented here, showing very accurate results.
Nevertheless, further work on Modelica simulation engines is needed in order to achieve scalability. The networks studied are below or around a hundred nodes, but
simulation time increases excessively with systems size
and rapidly becomes unmanageable above 100 nodes.
PSM will be released as open source in a specific
repository starting June 2017. The exact link will be
published in the iPSL repository: https://github.
com/itesla/ipsl.

The IEEE118 case was also used to test PSM. This system
is composed of 118 buses, 177 lines, 9 transformers, 54
generators, 91 loads, and 14 compensation banks. The
dynamic models are the same as those used in the IEEE57
with CMCONST governor added.
Figure 4 shows the comparison between the Modelica
generated file and Eurostag for the voltage magnitude at References
a specific bus, when a bus fault is introduced at time t=1
T. Bogodorova, M. Sabate, G. Len, L. Vanfretti, M. Halat, J-B.
sec, lasting 0.2 seconds.
Heyberger, and P. Panciatici. A Modelica power system libDue to the size of the IEEE118 network, the number
rary for phasor time-domain simulation. Smart Grid Technoof equations in Modelica (14,000 equations) increases
logies Europe (ISGT EUROPE), 2013 4th IEEE/PES, pages
considerably compared to the IEEE57 case (2,000 equa15, 2013. doi:10.1109/ISGTEurope.2013.6695422.
tions), and this greatly increases the simulation time in any
Modelica engine. For the IEEE118 results shown, it takes G. Len, M. Halat, M. Sabate, J-B. Heyberger, F.J. Gomez, and
L. Vanfretti. Aspects of power system modeling, initialization
Dymola approximately 6 hours to run 2.5 actual seconds
and simulation using the Modelica language. IEEE PES In(on the same machine used for the IEEE57 case). This
novative Smart Grid Technologies Europe, pages 16, 2015.
is clearly a limitation for achieving scalability to real netdoi:10.1109/PTC.2015.7232504.
works, which are of the order 10,000 nodes. Further
work is needed in this direction16 .
A. Trias. The Holomorphic Embedding Load Flow method.

4

Conclusions and future work

Power and Energy Society General Meeting, 2012 IEEE,
pages 18, 2012. doi:10.1109/PESGM.2012.6344759.

This paper presents the implementation of a user-friendly L. Vanfretti, A. Adib Murad, F. Gmez, G. Len, S. Machado,
and open source tool that allows users to automaticJ-B. Heyberger, and S. Petitrenaud.
Towards Automated Power System Model Transformation for Multially generate and simulate power system networks in
TSO Phasor Time Domain Simulations using Modelica.
Modelica. This work is the result of years of developPES Innovative Smart Grid Technologies Conference
ment made during the iTesla project and the extension of
Europe (ISGT-Europe), 2016 IEEE, pages 17, 2016.
those developments in a post-iTesla collaboration work.
doi:10.1109/ISGTEurope.2016.7856341.
This collaboration motivated by the authors commitment
16 OpenModelica developers are working on the integration of the
Sundials IDA solver in order to significantly improve simulation times
for large DAE systems. For more information see https://www.
openmodelica.org/.

DOI
10.3384/ecp17132235

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

239

240

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

A Modelica VSC-HVDC Average Value Model Implementation and
its Software-to-Software Validation using an EMT
Power System Domain Specific Simulator
Mohammed Ahsan Adib Murad1
1 School

Luigi Vanfretti2

of Electrical Engineering, University College Dublin, Ireland, mohammed.murad@ucdconnect.ie
of Electrical Engineering, KTH Royal Institute of Technology, Sweden, luigiv@kth.se

2 School

Abstract
This paper reports the implementation of a three-phase
VSC-HVDC model using the Modelica language. The
model is suitable for power system simulation where the
power electronic circuitry can be represented using equivalent voltage and current sources to model the high frequency switching process. Differently from the authors
previous work, this model is built using as much components as possible from the MSL (Modelica Standard Library) to represent the three-phase electrical circuit, while
implementing the de facto control system models used
within typical power system simulation tools. To show
the applicability of Modelica for modeling a VSC-HVDC,
a software-to-software validation is performed using the
EMTP-RV power system simulator.
Keywords: VSC, HVDC, power systems, software-tosoftware validation, power electronics, electro-magnetic
transients, DC grids, power systems

1
1.1

Introduction
Motivation

High Voltage Direct Current (HVDC) transmission systems have received renewed attention in the last decade
due to their applications for long distance power transmission, particularly to enable interconnections between
distant wind farms and the main electrical grid (Bahrman,
2006). There are two main converter technologies used
in HVDCs: Line-Commutated Converter (LCC) and Voltage Source Converter (VSC), which are used for different applications in power systems (Abildgaard and Molinas, 2012). VSC-based HVDC systems provide certain
advantages w.r.t. those based on LCC, including (Reed
et al., 2003; Flourentzou et al., 2009), including independent control of active and reactive power,energy supply to
weak and passive grids, etc.
An overview of different VSC topologies are reported
in (Andersen et al., 2002) and include conventional twolevel, multi-level diode-clamped, floating capacitor multilevel converters, etc.
Recently, the Modular Multilevel Converter (MMC) technology has been adopted because of its advantages compared to other multilevel converter topologies for HVDC
DOI
10.3384/ecp17132241

applications. With the adoption of MMC-based VSC technologies, modeling and simulation is becoming of crucial
importance for different network studies; where modeling
and simulation tools are needed in all facets related to their
utilization: from design, through implementation, and in
their operation.

1.2

Related Works

Power system electro-mechanical dynamic modeling and
simulation is used for the analysis of dynamic behavior of large power networks, and the use of Modelica is
now becoming attractive because of several advantages
offered by the Modelica language as compared to existing power system simulation tools (Vanfretti et al., 2016;
Casella et al., 2016). Another modeling and simulation
approach that is important for power system analysis is
the Electro-Magnetic Transient (EMT) methodology, and
previous work has shown the advantages and limitations
of the use of Modelica (Bachmann and Wiesmann, 2000)
in adopting the EMT approach.
EMT analysis tools, such as EMTP-RV (see http://
emtp-software.com/), are typically used for the analysis of VSC-HVDC systems (Peralta et al., 2012), which
allow to analyze their performance for different levels of
modeling granularity of the power electronics of these systems (including average value models). To the knowledge
of the authors, there only exists two previous implementations of VSC-HVDC models using the Modelica language
in the literature (Majumder et al., 2013; Olenmark et al.,
2015), however, these have not been implemented-in nor
validated-against EMT (Electro-Magnetic Transient)-type
power system simulation tools (e.g. EMTP-RV), and more
importantly, they are not publicly available.

1.3

Paper Contributions

This paper reports the implementation of a three-phase
VSC-HVDC average value model, and a power system
test model that is compared against EMTP-RV. The aim
is to show the potential use and challenges of applying
the Modelica language for EMT-type analysis of VSCHVDC networks when detailed switching circuits do not
need to be represented (e.g. system-level control design
purposes).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

241

A Modelica VSC-HVDC Average Value Model Implementation and its Software-to-Software Validation using
an EMT Power System Domain Specific Simulator

The remainder of this paper is organized as follows. Section 2 gives a brief description of the VSC-HVDC model.
In Section 3, the model implementation in Modelica is explained, while in Section 4, software-to-software validation results are summarized. Finally, in Section 5, conclusions are drawn and future work is outlined.

2

VSC-HVDC Model

where, vu j and vl j are upper and lower arm voltages. Using
(1) and (2) the MMC is represented as a classical VSC.
The controlled voltage source in the AC side is determined
by:
Vdc
(3)
2
where, vre f j are the reference voltages generated from the
inner controller of the high level control system (i.e. they
are dimensionless quantities in per unit). Based on the
principle of power balance, the DC side model equations
are derived assuming no energy is stored inside the MMC
converter, as follows
vconv j = vre f j

In EMTP-RV two types of VSC-based MMC station models are available, which are based on the results by (Peralta et al., 2012): Monopole, and Bipole configuration
with ground return. The MMC stations are represented
using four kinds of models: (a) Full detailed model, (b)
Vdc Idc =  vconv j i j
Detailed equivalent model, (c) Switching function of arm
j=a,b,c
model, and (d) Average-value model (AVM). The threephase configuration of the MMC topology assumed by where the DC side current is given by,
these models is shown in Figure 1.
1
Idc =
 vre f j i j .
Idc
2 j=a,b,c
iua

iub

Vua

SM1ub

SM1uc

SM2ua

SM2ub

SM2uc

SMNua

SMNub

SMNuc

Larm

Larm

Using these principles, the AVM model implementation
in EMTP-RV allows to build up an entire VSC-HVDC
model. Figures 2 and 3 show the schematic of the implementation of the two basic components as available in
EMTP-RV for this purpose.
Vdc

Larm
ic

ib

ia

Larm
SM1la

SM1lb

SM2la

SM2lb

AC

Larm

SM1lc

SM2lc

SMNla

ilb

SMNlb

ilc

Larm

Larm

Vla

ila

(5)

iuc

SM1ua

Larm
vc
vb
va

(4)

SMNlc

VDC
Varef

AC Side
Phase A

Vac

VDC
Vbref

AC Side
Phase B

Larm

Vac

VDC
Vcref

AC Side
Phase C

Vac

Figure 1. MMC topology.

In this work the AVM model with an high level control system is implemented. The full description of the
model is documented in (Peralta et al., 2012). In this Section, the most relevant components of the model available
in EMTP-RV are reviewed, as they are replicated in the
Modelica implementation, in Section 3.

2.1

Average-Value Model (AVM)

Figure 2. AC side of AVM model.

Req_DC
Varef
Vcref

In an AVM, the power electronic switches (IGBTs) and
diodes are not modeled in detail, instead the MMC behavior is represented using controlled voltage and current
sources. Thus, an ideal behavior of the internal variables
of the MMC is assumed. For each phase j = a, b, c; the
voltage of the converter is derived from Figure 1, from
where,

Leq_DC

DC_Side

P

Vbref
Ia

IDC

C1

Ib
Ic

N

Figure 3. DC side of AVM Model.

In Figure 2 the AC side voltage for each phase is calculated using (3) and Larm is the arm inductance. In FigLarm di j
ure 3 the DC side current IDC is calculated using (5)
vconv j =
 v j.
(1)
and equivalent inductance, total conduction loss and the
2 dt
equivalent capacitor are given by, Leq_DC = (2/3)Larm ,
Assuming the total number of sub-modules in each R
eq_DC = (2/3)NRON and C1 = 6C/N; where N is the
phase is constant,
number of sub-modules per arm, C is calculated using
the energy conservation principle, and RON represents the
vu j + vl j = Vdc
(2) conduction loss of each IGBT.
242

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132241

Session 5C: Electrical & Power Systems I

2.2

Control System

next. In addition to the VSC model, an equivalent genThe VSC type MMC topology uses an upper level con- erator model and a two winding transformer three-phase
trol system, which includes an outer and inner control. models were also implemented for software validation
The structure of the overall upper level control system purposes.
is shown in Figure 4. The upper level control system 3.1 AVM Model in Modelica
serves two main purposes: (i) to regulate system variables, i.e. the active and/or reactive power or voltages The AVM model was implemented using component mod(labeled outer control in Figure 4), and (ii) to generate els from the MSL (Modelica Standard Library). The conreference voltages (vd_re f and vq_re f ), which are used nector models used in the AC side are the three-phase
plug, and in DC side is the single phase positive and negaas input to the AVM.
tive pin. The AVM model in Modelica is shown in Figure
2.2.1 Upper Level Control
5.
The VSC-MMC model uses the classical vector control
strategy. The inputs to the upper level control are three- 3.2 Upper Level Control in Modelica
phase per unit (p.u.) variables, using the matrix in (8), Next, all the blocks of the upper level control system
these variables are converted to direct-and-quadrature-axis shown in Figure 4 were implemented in Modelica. As
components rotating at synchronous speed ( d
dt ). The all the controllers in the upper level control system use the
phase angle  is calculated using a Phase-Locked Loop same PI controller implementation, first a PI controller us(PLL). The blocks for Clarke transformation, P/Q/VAC ing components from the MSL was implemented. Next
calculations and d-q transformation are used to compute the Modelica implementation was compared to the one
the variables required for the outer and inner controllers. implemented in EMTP-RV. After validating this compoThe d-q transformed voltage and currents are calculated nent against EMTP-RV, the same PI controller was used
using the transformation matrix, T , as follows:
in the remaining P, Q, VDC, VAC, inner control and PLL
(6) blocks.
(7) 3.3 PLL in Modelica

idq = Tiabc
vdq = T vabc_grid
where

The phase locked loop (PLL) implemented in Modelica is
shown in Figure 6. The main function of the PLL loop is to
synchronize with the phase angle and frequency of the AC
3
1
1
1
grid voltage. The implementation of the PLL used simi2
2
2
lar components in Modelica, as those available in the speThe AC grid voltage, active and reactive power are calcucific power system tools documentation/description (i.e.
lated from the d-q reference,
EMTP-RV). Given the fact that the reference documentaP = vd id + vq iq
(9) tion has a copyright, so the detail description is not given
Q = vd iq + vq id
(10) here.
q
vgrid = v2d + v2q
(11) 4 Software-to-Software Validation


2 cos(t)
T = sin(t)

cos(t  2
3 )
sin(t  2
3 )



cos(t + 2
3 )

sin(t + 2
3 ) . (8)

The signals are converted to per unit (p.u.) quantities before entering to the upper level control system. The outer
and inner control block is used to control active power, reactive power, DC and AC voltage. All these controllers are
realized using proportional and integral (PI) control loop.
The input to these PI controller loops are the difference
between the reference (set by the user) and the controlled
variable. The references to the outer control loop are usually fixed set points, that in practice are varied by a remote
dispatcher. In this model the references to the outer control loop are fixed and can be varied by the user. The final
block (d-q to abc) is used to convert the d-q reference to
three-phase voltage references.

4.1

Sub-system Model Validation

The AVM and each block of the upper level control system were implemented as individual models within one
package, then all the blocks were assembled to realize
complete the implementation of the VSC model.
Next, software-to-software validation was carried out
against the EMTP-RV model. For example, consider the
PLL block shown in Figure 6, it has two inputs and two
outputs. After the implementation of the entire PLL block
in Modelica, this model was validated by simulating it using the same input signals in both Modelica and EMTPRV. The results of the PLL block simulations are shown in
Figures 7 and 8.
3 VSC Model Implementation in The same procedure is followed for the three-phase equivalent generator and three-phase two winding transformer
Modelica
models shown in Figure 9. After implementing needed
All the components included in the VSC model available components, a test power system model described next is
in EMTP-RV are implemented in Modelica and described used to validate the VSC-HVDC model.
DOI
10.3384/ecp17132241

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

243

A Modelica VSC-HVDC Average Value Model Implementation and its Software-to-Software Validation using
an EMT Power System Domain Specific Simulator

Q
P
VDC

VDC_meas

Outer Control
P/Q/VAC
Calculations

VDC

Clarke TR
Vac_prim

Iac_prim

P

V_alpha_Y
V_beta_Y
I_alpha_Y
I_beta_Y

Q

Id_ref

Id_ref

Q

Iq_ref

Iq_ref

Vd_ref

vd
vq
id
iq

Vq_ref

VAC Grid

VAC Grid

Vac_secon

Iq

Iac_secon

I_alpha_D

dq
Transformation

I_beta_D

Inner Control

P

Linearization &
dq to abc

Vd_ref

vd

Vq_ref

V_alpha_Y

Vabc_ref

vq

V_beta_Y
I_alpha_D

id

I_beta_D

iq

V_alpha

PLL

theta

V_beta

Figure 4. Block diagram of the control system of the VSC-HVDC.

Figure 5. AVM Model in Modelica.

4.2

Power System Test model

The VSC-HVDC test power system model implemented
in Modelica and EMTP-RV is shown in Figure 10. A DC
cable model is yet to be implemented in Modelica, and
thus, resistive line model (R = 1.022) is used instead.
Converter 1 (VSC1) controls the active power and Con244

Figure 6. PLL in Modelica.

verter 2 (VSC2) controls the DC voltage, while 1000 MW
active power is transferred from VSC1 to VSC2. The user
can select which controller should be active in each VSC.
The model parameters used (i.e. transformer resistance
and reactance, MMC arm inductance, etc), are exactly
the same in both software tools, and are summarized in

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132241

Session 5C: Electrical & Power Systems I

2
50.1
1.5
50.05

50

F [Hz]

Input a

1

0.5

49.95

49.9
0
49.85
-0.5
49.8

49.75

-1
0.35

0.4

0.45

0.5

0.35

0.55

0.4

0.45

0.5

Time(s)

0.55

0.6

0.65

0.7

0.75

0.8

Time(s)

6

0.8
0.6

5

0.4
4

Theta [rad]

Input b

0.2
0
-0.2

3

2
-0.4
-0.6

1

-0.8
0
-1
0.36

0.38

0.4

0.42

0.44

0.46

0.48

0.5

0.52

Time(s)

Figure 7. Inputs to the PLL block. (Red traces: EMTP-RV and
blue traces: Modelica)

0.4

0.42

0.44

0.46

0.48

0.5

0.52

0.54

0.56

0.58

0.6

Time(s)

Figure 8. Outputs of the PLL block. (Red traces: EMTP-RV
and blue traces: Modelica)

the Appendix. In EMTP-RV the integral and proportional
gains of each PI controller (in upper level control system)
are automatically calculated by specifying the desired settling time (with 5% error). The computation method used
by EMTP-RV is proprietary, and thus, for the sake of consistency, the values computed by this tool are used in the
Modelica model.

4.3

Steady State

EMTP-RV initializes the model variables using a threephase power flow solver, which is not available outside of
this tool. To validate the sub-system models (i.e. equivalent generator, controllers, PLL, etc.), no initialization values were provided to the Modelica models (starting values
of the voltage and currents were set = 0). At the beginning
of the simulation, the Modelica and EMTP-RV results do
not match, however, after the Modelica trajectories reach
in their steady-state, the simulation results show an adequate match. To illustrate, consider the test system shown
in Figure 9, where an equivalent generator and three-phase
two winding transformer are included. No initialization
values for the inductor currents (i.e. the states) were proDOI
10.3384/ecp17132241

Figure 9. Test system of the equivalent generator and the two
winding transformer.

vided.
The simulation was carried out using the solver Dassl
with interval length equal to 1e-5. The same interval
length is used in EMTP-RV, however note that EMTP-RV
uses a Trapezoidal solver.
The simulation results shown in Figure 11 show that at

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

245

A Modelica VSC-HVDC Average Value Model Implementation and its Software-to-Software Validation using
an EMT Power System Domain Specific Simulator

400/320 KV

VSC 1

VSC 2

R

320/400 KV

0.5
S=100 MVA
VDC=640 KV

VAC = 400 KV
F = 50 Hz

S=100 MVA
VDC=640 KV

Vref (p.u.)

VAC = 400 KV
F = 50 Hz

Figure 10. VSC-HVDC Test system.

0

-0.5

1000

0.745

0.75

0.755

0.76

0.765

0.77

Time(s)
500

Figure 13. Vabc_re f of VSC1 i.e. output of upper level control
(Red: EMTP-RV, other: Modelica).

Is (A)

0

3000

-500

2500
2000

IDC (A)

-1000

0

0.005

0.01

0.015

0.02

0.025

0.03

0.035

0.04

0.045

0.05

1500
1000
500

Time(s)

0

Figure 11. Secondary current of the transformer before the
steady-state is reached (Red: EMTP-RV, other: Modelica).

-500
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Time(s)

Figure 14. DC current of VSC1 (Red: EMTP-RV, Blue: Modelica).

800

Is (A)

600
400

4.4

200

Software-to-Software validation of the VSC-HVDC
model (see Figure 10) is carried out in two steps. First,
simulations are carried out without applying any perturbations to the model in order to check whether the steadystate trajectories match or not. In addition, no initial values were provided to the controllers integrators in the
Modelica model. As a result, the simulation is allowed
to reach the steady state value before disturbances are
applied and comparisons are made. Figures 13 and 14
show the simulation results for Vabc_re f and IDC of VSC1,
showing the close match between the two different implementations.
Next, a step change in the active power reference form 1
to 0.5 (1000 MW to 500 MW) at 0.8 second is applied.
The step change and response of the controller are shown
in Figure 15, while other trajectories are shown in Figures
16-19. It is noted that a close match is achieved between
both implementations.

0
-200
-400
-600
-800
0.705

0.71

0.715

0.72

0.725

0.73

0.735

0.74

Time(s)

Figure 12. Secondary current of the transformer when the
steady-state is reached .

the beginning of the simulation the traces do not match
for the two different implementations. The traces in red
are from EMTP-RV, while other traces in different colors
are from the Modelica tool used. The simulation output of
the Modelica model matches the EMTP-RV results after
the steady-state is reached (shown in Figure 12).
Observe that when a larger test system model is to be
simulated (see Section 4.2), there are more states that
need to be initialized. The authors found that some of the
Modelica-tools (OpenModelica and Dymola), the solvers
are not able to solve the initialization problem and/or to
execute the simulation successfully. For the test system
shown in Figure 10 the Rkfix4 solver with interval length
1e-5 and tolerance of 0.01 were used.
246

5

Software-to-Software Validation

Conclusion

This paper showed the potential use of the Modelica language to model EMT-type models of VSC-HVDC systems
when the high-frequency switching process can be represented using equivalent voltage and current sources. Differently from the authors previous work (Vanfretti et al.,
2017), this model is built using as much components as
possible from the MSL to represent the three-phase elec-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132241

Session 5C: Electrical & Power Systems I

1600
1

1400

P

IDC (A)

P [p.u.]

0.9
0.8
0.7

Pref 

0.6
0.5

1200
1000
800

0.7

0.75

0.8

0.85

0.9

0.95

1

1.05

Time(s)

0.8

Figure 15. Active power response of VSC1 (Red: EMTP-RV,
Blue: Modelica).

0.9

1

1.1

1.2

1.3

1.4

Time(s)

Figure 19. DC current on the VSC1 side (Red: EMTP-RV, Blue:
Modelica).

2000

I_phsA [A]

The Modelica implementation was compared to the
EMTP-RV software, a de facto power system model0
ing and simulation tool used for VSC-HVDC analyses,
yielding surprisingly similar results (even identical when
-1000
a desired disturbance is applied after the steady-state is
-2000
reached). The major benefit of the work reported herein
is that the control system implemented can now be ex0.7
0.75
0.8
0.85
0.9
0.95
1
changed with different tools that support the FMI stanTime(s)
dard, including Simulink and EMTP-RV, which makes it
Figure 16. Primary current (Phase A) of VSC1 (Red: EMTP- possible to keep and maintain a single version of the conRV, Blue: Modelica).
trol system model implemented (i.e. the one in Modelica).
The results from this work show that there is great potential for the use of Modelica for EMT-type modeling and
1
simulation of electrical power systems, and particularly
of power electronic components. However, further work
0.8
must be carried out with respect to the provision of adequate starting guess values for the initialization problem,
0.6
and more importantly, to efficiently simulate switching
processes without substantially affecting simulation time.
0.4
The Modelica files of the model presented
in
this paper are available under the GPLv3
0.6
0.8
1
1.2
1.4
1.6
Time(s)
license in the following GitHub repository:
https://github.com/SmarTS-Lab/2017_
Figure 17. Current reference of upper level control of VSC1
ModelicaConf_VSC-HVDC_AVM_Model
(Red: EMTP-RV, Blue: Modelica).
Idref

1000

6
1.02

VDC (p.u.)

1.01
1
0.99
0.98
0.97
0.6

0.8

1

1.2

1.4

Time(s)

Figure 18. DC voltage on the VSC1 side (Red: EMTP-RV,
Blue: Modelica).

Acknowledgment

This work was supported in part by the FP7 iTesla project,
the ITEA3 openCPS project, and the STandUP Collaboration Initiative.
Mohammed Ahsan Adib Murad is supported by Science Foundation Ireland under Grant No. SFI/15/IA/3074.
The authors would like to thank Professor Federico Milano for supporting the first author during the preparation
of this paper.

7

Appendix

The two node test power system model parameter data are
provided in the Tables 1 and 2.

trical circuit, while implementing the de facto control sys- References
tem models used within typical power system simulation E. N. Abildgaard and M. Molinas. Modelling and contools.
trol of the Modular Multilevel Converter (MMC). EnDOI
10.3384/ecp17132241

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

247

A Modelica VSC-HVDC Average Value Model Implementation and its Software-to-Software Validation using
an EMT Power System Domain Specific Simulator
Table 1. Equivalent generator data.

Parameter

Value

Line to line RMS voltage (KV)
Generator short circuit capacity (MVA)
R/L ratio (p.u.)
Fequency (Hz)

400
10000
10
50

Table 2. VSC and two winding transformer data.

Parameter

Value

Rated power (MVA)
Transformer primary voltage [r.m.s. LL]
(KV)
Transformer secondary voltage [r.m.s.
LL] (KV)
Fequency (Hz)
Transformer resistance (p.u.)
Transformer reactance (p.u.)
MMC arm inductance (p.u.)
Capacitor energy in each sub-module
(KJ/MVA)
Number of sub-module per arm, N
Conduction loss of each IGBT (p.u.)

1000
400

A. Olenmark, J. Sloth, A. Johnsson, C. Wilhelmsson, and
J. Svensson. Control development and modeling for flexible DC grids in Modelica. In 2015 The 11th International
Modelica Conference, September 2015.
J. Peralta, H. Saad, S. Dennetiere, J. Mahseredjian, and
S. Nguefeu. Detailed and averaged models for a 401level MMC-HVDC system. IEEE Transactions on Power
Delivery, 27(3):15011508, July 2012. ISSN 0885-8977.
doi:10.1109/TPWRD.2012.2188911.
G. Reed, R. Pape, and M. Takeda. Advantages of voltage sourced converter (VSC) based design concepts for
FACTS and HVDC-link applications.
In 2003 IEEE
Power Engineering Society General Meeting (IEEE Cat.
No.03CH37491), volume 3, page 1821 Vol. 3, July 2003.
doi:10.1109/PES.2003.1267437.

320
50
0.001
0.18
0.15
40
400
.001

L. Vanfretti, T. Rabuzin, M. Baudette, and M. Murad.
itesla power systems library (iPSL): A Modelica library for phasor time-domain simulations.
SoftwareX, 5:84  88, 2016.
ISSN 2352-7110.
doi:http://dx.doi.org/10.1016/j.softx.2016.05.001.
L. Vanfretti, M.A.A. Murad, and F.J.Gmez. Calibrating a
VSC-HVDC model for dynamic simulations using RaPId and
EMTP simulation data. In 2017 IEEE Power Energy Society
General Meeting, pages 15, July 2017.

ergy Procedia, 20:227  236, 2012. ISSN 1876-6102.
doi:http://dx.doi.org/10.1016/j.egypro.2012.03.023.
B. R. Andersen, L. Xu, P. J. Horton, and P. Cartwright.
Topologies for VSC transmission.
Power Engineering
Journal, 16(3):142150, June 2002. ISSN 0950-3366.
doi:10.1049/pe:20020307.
B. Bachmann and H. Wiesmann. Advanced modeling of electromagnetic transients in power systems. In Modelica Workshop
2000, Oct 2000.
M. P. Bahrman. Overview of HVDC transmission. In 2006
IEEE PES Power Systems Conference and Exposition, pages
1823, Oct 2006. doi:10.1109/PSCE.2006.296221.
F. Casella, A. Bartolini, S. Pasquini, and L. Bonuglia. Objectoriented modelling and simulation of large-scale electrical
power systems using Modelica: A first feasibility study. In
IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society, pages 62986304, Oct 2016.
doi:10.1109/IECON.2016.7793558.
N. Flourentzou, V. G. Agelidis, and G. D. Demetriades. VSC based HVDC power transmission systems:
An overview.
IEEE Transactions on Power Electronics, 24(3):592602, March 2009.
ISSN 0885-8993.
doi:10.1109/TPEL.2008.2008441.
R. Majumder, B. Berggren, and M. Larsson.
Development and comparison of DC grid model in Powerfactory
and Dymola for controller design. In 2013 IEEE Power
Energy Society General Meeting, pages 15, July 2013.
doi:10.1109/PESMG.2013.6672328.

248

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132241

From system model to optimal control A tool chain for the efficient solution of optimal control problems
Manuel Grber1
1

Jrg Fritzsche2

Wilhelm Tegethoff3

TLK Energy GmbH, Germany, manuel.graeber@tlk-energy.de
2
Volkswagen AG, Germany
3
Institut fr Thermodynamik, TU Braunschweig, Germany

Abstract
Based on a specific application example - the thermal
management system of an internal combustion engine a toolchain is presented for formulating and solving of
nonlinear optimal control problems. Starting from
graphical modeling of the thermal management system
with the Modelica library TIL, the model is exported to
the standardized model exchange format Functional
Mock-up Interface (FMI). Furthermore, it is imported to
the optimal control software package MUSCOD-II.
Python is used as scripting language for the problem
formulation, the numerical solution and the processing
of results. By using FMI as an interface, models from
any simulation and modeling tools can be used if there
is an FMI model export and the models fulfill certain
mathematical requirements (smoothness).
Keywords:
Optimal control, Functional mock-up
interface, thermal management, cooling system

this is the aerospace industry, in which OCPs have been
solved for optimal trajectory planning for decades. The
largest (in our opinion) obstacle to a widespread
industrial use of optimal control is the necessary time
and knowledge-intensive effort. Successful work with
existing software requires a high degree of expert
knowledge. According to our experience, the by far
largest time effort in optimization projects cannot be
seen in performing the actual optimization calculations,
but rather in the modeling of the system under
consideration. On the one hand, derivative-based
optimization algorithms require a certain numerical
model quality (differentiability) that go beyond the
requirements of pure simulation algorithms. On the
other hand, it is important to depict the correct positive
and negative effects, the superposition of which
determines the optimum. The modeling process is
almost always iterative. Reliable results can only be
produced by repeatedly interpreting optimization results
and changing modelling details.

1 Introduction
When developing control concepts or superior operating
strategies, frequently the question arises, what is the
theoretically best possible control of a system.
Questions of this kind can be mathematically expressed
as Optimal Control Problems (OCP) describe. What is
special about this class of optimization problems is the
dynamics of the controlled system. Contrary to static
optimization problems, not a finite number of
parameters are free for optimization, but trajectories of
system inputs. Therefore, an OCP is an infinitedimensional optimization problem, which usually
cannot be solved directly. However, different
mathematical methods exist to determine approximated
numerical solution. Detailed introductions in the theory
of optimal control can be found in (Bryson and Ho 1979)
and (Betts 2001). The Direct Multiple Shooting Method
according to (H. G. Bock and Plitt 1984) used in this
article is explained in Section 3.

Based on the described experiences and observations,
we suggest a tool chain in this article to use optimal
control efficiently. The thermal management system of
a combustion engine serves as a continuous example.
Starting with the modeling of the controlled system in
Section 2, the model is exported as FMU (Blochwitz et
al. 2012) and imported into to the specialized
optimization package MUSCOD-II (H. G. Bock and
Plitt 1984; Diehl 2001; Leineweber et al. 2003). For the
problem formulation, the numerical solution and the
processing of results Python is used as scripting
language.
Other Modelica-related optimal control projects are
described in (kesson et al. 2010), direct collocation
(Imsland et al. 2010), single shooting, and (Franke
2002), multiple shooting.

2
Although these and other specialized OCP algorithms
have existed for a long time, they have not yet made it
into the broad industrial application. An exception to

DOI
10.3384/ecp17132249

Modelling of the controlled system

The most important part in the successful work with
optimal control is the dynamic model of the system
under consideration. Mathematically, the system model

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

249

From system model to optimal control - A tool chain for the efficient solution of optimal control problems

is described as a system of ordinary differential
equations:
d
(1)
= (, , , )
d
Here x denotes the vector differential states, u the vector
of inputs, p the vector of parameters and t is time. It is
also possible system models with additional algebraic
implicit equations. Since this is not supported by the
current FMI 2.0 standard and due to better readability,
we limit ourselves to explicit ordinary differential
equations (ODE) of the form shown above.
Equation systems of this type are the mathematical basis
of various industrially used system simulators such as
Simulink or Dymola. In order to be able to exchange
models between different simulators, the open standard
Functional Mock-up Interface (FMI) was developed.
We use FMI to link system models to optimization
algorithms. Thus, it is possible to develop the system
model of an optimum control problem in the modeling
tool of choice. The only requirement is the availability
of FMI exports.
Models that are suitable for simulation need not yet be
suitable for the use of derivative-based optimizers.
Discontinuities in the model equations can lead to poor
or even failing convergence behavior. In practice,
however, the theoretical mathematical requirements for
models must not be completely satisfied. Even if the
continuous differentiability of all model equations is not
fulfilled, for example by the linear interpolation of
characteristic fields, reasonable results can be achieved
with derivation-based optimizers.
Thermal systems such as the thermal management
system considered here, can be graphically modelled
with the Modelica library TIL (Schulze 2013; Grber et
al. 2010; Richter 2008). Large parts of TIL are directly
suitable for use in optimizers. This includes circuits with
compressible liquids and ideal gas mixtures. Two-phase
fluid circuits modeled with TIL are not yet suitable for
optimization. However, current research deals with this
topic.
Figure 1 shows the thermal management system as a
TIL model. The coolant (blue) is pumped through the
engine block by an electrically driven pump. There,
waste heat from the combustion engine is added as timedependent heat flow. The upper circuit through the
heating heat exchanger is constantly flowed through.
The lower circuit for heat dissipation to the environment
can be connected via an electrical valve as required.

250

Figure 1. Sketch of the thermal management system.
Screenshot of Modelica / TIL system models.

The manipulated variables of this system are:
 Water pump speed
 Cooling fan speed
 Opening degree of the valve
Both heat-exchangers are modelled according to the
finite volume method with 5 discrete volumes. The
system model has 36 differential states in total.
The primary control task is temperature control of the
engine, which is achieved by demanding a setpoint of
90C for the fluid temperature at the engine block outlet.
Three manipulated variables and only one control
variable leave two degrees of freedom. An open
question is how to deal with these degrees of freedom.
An obvious idea is to introduce the additional demand
for the lowest possible energy consumption. Thus, the
cost function to be minimized follows as:
f

 =  pump + fan + (  set )2 d

(2)

0

The electrical power consumption of pump and fan as
well as a squared penalty term for setpoint deviations are
integrated over a given period of time. The two control
objectives can be weighted with the factor c. High
values result in higher energy consumption but
temperatures closer to the setpoint.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132249

Session 5D: Control Systems II

The input trajectories within the period under
consideration are free for optimization. However, upper
and lower bounds for all manipulated variables are taken
into account:
(3)
lb  ()  ub    [0, f ]
In addition, the given initial state of the system model
enters as equality constraint:
(4)
(0) = 0
The complete optimal control problem follows as:
min ((), (), )
(),()

s.t.

d
() = ((), (), , )    [0, f ]
d
lb  ()  ub
   [0, f ]
(0) = 0

(5)

3 Numerical solution of optimal

control problems
This section is based on (Grber 2013) and attempts to
explain the basic mathematical ideas behind the used
numerical methods. For a deeper and more
mathematical representation, references to further
literature are given in several places.
Optimal control problems of the above-described form
are not directly solvable by numerical methods.
Considering the continuous trajectories sought as a set
of infinitely many individual points, it becomes clear
that an OCP is an infinite-dimensional optimization
problem. Deriving analytical solutions is only possible
for very simple subclasses. For most real problems, only
an approximate numerical solution is possible.
Within the last decades, various methods have been
developed to numerically solve optimal control
problems. These can be divided into two large groups:
indirect and direct methods. Indirect methods are based
on Pontryagin's Maximum Principle. With the help of
this necessary optimum condition, the OCP is
analytically transformed into a boundary value problem
with the original differential equations and additional
adjoint equations. This boundary value problem can
then be solved with various numerical methods. A
frequently mentioned disadvantage of these methods is
the difficult consideration of restrictions. Since it is
necessary in many technical applications to limit state
variables and controls to certain areas, this disadvantage
is not insignificant.

used. By discretizing the trajectories, the infinitedimensional OCP is approximated with a finitedimensional Nonlinear Program (NLP). This NLP can
then be solved with common numerical methods such as
Sequential Quadratic Programming (SQP) or Interior
Point Method (IP). Within direct methods, a distinction
is made between sequential and simultaneous methods.
In direct sequential procedures, the control trajectories
are described by piecewise defined functions  mostly
polynomials. In the simplest case, the polynomials are
of the order of zero, and the controls are piecewise
constant functions over time. The coefficients of these
polynomials are the free optimization variables. Using
an ODE or DAE solver, the cost function can now be
evaluated for given control trajectories and initial
values. Coupled to an optimization algorithm, the OCP
can be iteratively solved by repeatedly solving an initial
value problem with different control trajectories. It has
been shown, that particularly for ill-conditioned
problems convergence and stability properties of such
methods are not very good (Hans Georg Bock 1987;
Albersmeyer and Diehl 2010).
Direct simultaneous methods go one step further and
discretize not only the control but also the state
trajectories. In the case of direct collocation, the
trajectories of all state variables and controls are again
described by piecewise defined functions. The
continuous ODE is converted into a system of difference
equations using a suitable scheme. This equation system
is included as an equality constraint in the optimization
problem. Leading to a very large but finite-dimensional
NLP, which can be solved with conventional methods.
In order to reduce the computation time, the special
structure of the equation systems can be exploited.
(Biegler 2007) provides an overview of current
simultaneous methods.

Figure 2. Multiple Shooting Method. Control trajectories
(red) are discretized with piecewise constant functions and
state trajectories (black) are discretized by solving
independent initial value problems.

Recent work deals almost exclusively with direct
methods. The term comes from the fact that not a
transformed problem, but directly the original OCP is
DOI
10.3384/ecp17132249

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

251

From system model to optimal control - A tool chain for the efficient solution of optimal control problems

The direct multiple shooting method used in this work
is usually seen as simultaneous method, but could also
be interpreted as a mixed form between the sequential
and simultaneous methods. Control trajectories are
discretized analogously to the methods described so far.
The state trajectories are also divided into individual
sections. However, the path within these sections is not
described by polynomials. Rather, initial values for the
states are introduced at the nodes of the multiple
shooting grid. At node i, these additional variables are
designated as  . Based on these initial values and the
original ODE, the trajectories of the states are
determined by solving several independent initial value
problems. For an arbitrary choice of the initial values,
the resultant total trajectories of the states have jumps,
see Figure 2. Therefore, closing conditions are included
in the OCP as additional equality constraints. The value
of a state variable at the end of a section must be equal
to the initial value of the next section.

4

Optimal Control of a Thermal
Management System

This section describes optimization results for the
thermal management system described in section 2.
The system model is graphically generated and
parameterized in Dymola using the library TIL. With the
Dymola FMI export functionality, the model is exported
as FMU for Model Exchange 2.0. Control inputs must
be declared as top level inputs in Modelica and
variables, which are used in the cost function, as top
level outputs.
The coupling of the FMU to the optimizer MUSCODII, and the complete configuration of the calculations is
done in the Python language. The Python code used her
is shown in Figure 3.

If an identical discretization grid with n intervals is
chosen for controls and states and the controls are
parameterized piecewise constant with the values  , the
following NLP results from OCP (5):


min   ( ,  , )

0 ,,
0 ,,1 =0

s.t.

+1 =  (+1 ;  ,  ,  , )

lb    ub
0 = 0

(6)

  {0,  ,   1}
  {0,  , }

It should be noted that the solution of an initial value
problem is behind the evaluation of the cost functions
 ( ,  , ) and the determination of the states at the
end of an interval  (+1 ;  ,  ,  , ). In the solution of
this NLP with derivative-based methods, it is of great
importance to determine the derivatives of these
functions with respect to the free optimization variables
accurately and efficiently. This is a non-trivial task
when using variable step size integrators. An extensive
discussion of this topic can be found in (Bauer 1999)
and (Albersmeyer 2010).
To illustrate the multiple shooting method, the
discretization for a simple example is shown in Figure
2. On each shooting interval i, an independent initial
value problem is solved with the initial value  and the
constant control  . The figure shows the result of an
optimization iteration, that has not yet converged. The
violation of the matching conditions for the state
variables is clearly visible.

252

Figure 3. Python code for the numerical solution of the
optimal control problem.

The scenario considered is a 10-minute drive up a
mountain pass after a cold start at 20C. This means that
relatively much engine waste heat is introduced into the
cooling circuit, which in turn has to be dissipated to the
ambient air. Due to the comparatively low uphill speed
the cooling fan has to be used more extensively. The

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132249

Session 5D: Control Systems II

optimum control trajectories are calculated as piecewise
constant curves with an interval length of 10s. A
simulation of the thermal management system with a
simple control concept is used as a basis for comparison
For this purpose, the pump, such as a mechanical water
pump, is operated at a rotational speed coupled to the
motor speed. The valve is controlled by a P-controller
and a setpoint of 85C for the coolant temperature.
While the fan controls the same temperature with a PI
controller to the desired setpoint of 90C.
Figure 4 shows the optimum and simulated (with PI
controllers) controls. Obvious differences are:
 Maximum pump speed in the first minute of the
optimal solution
 The fan becomes active in the optimal solution
earlier.
The first difference is only to be explained by the fact
that the electrical power of the pump is used to heat the
coolant. At the beginning all temperatures are at 20C.
In order to reach the setpoint of 90C as quickly as
possible, it is worth (in the sense of the cost function) to
use the electrical power of the pump to heat up the
system.

compared to optimal control, especially between
minutes 4 and 5. Within this time span, the PI controller
reacts to the overshooting temperature. This has the
consequence that the cumulative energy consumption
increases sharply. Whereas the more uniform optimal
control of the fan speed leads to total energy
consumption reduced by 19%. The individual numerical
values are listed in Table 1.

Figure 5. Results from optimization and simulation. The
primary control objective of keeping the coolant
temperature at 90  C is achieved in both cases. The
optimum control achieves the setpoint value somewhat
earlier, without overshooting.

Figure 4. Controls from optimization and simulation. The
optimum control uses the fan earlier and completely opens
the valve later.

The second difference can be explained by looking at
figure 5. While the PI control of the temperature does
not become active until the setpoint is exceeded, the
optimum control reacts earlier. With increased fan speed
and valve opening, cooling is started before 90C is
reached. An exact approach of the setpoint can thus be
achieved, without overshooting. In addition, it is
avoided that the fan is operated with maximum speed
and disproportionately high energy demand.
This second positive aspect is clearly visible in figure 6.
The cumulative electrical energy consumption of both
variants is shown, divided into fan and pump energy.
The fan energy clearly dominates in both cases. In the
case of PI control, the fan runs at a much higher speed

DOI
10.3384/ecp17132249

Figure 6. Cumulative electrical energy consumption from
optimization and simulation. The optimum control
achieves a 19% reduction in energy consumption.

For the described cold-start high-load scenario, the
optimum control shows a significant reduction in energy
consumption while at the same time better compliance
with the setpoint for the coolant temperature. With the
presented tool chain, such investigations can also be
carried out for other systems and scenarios. Such
optimal control results can be used for various purposes:
 as reference for control concepts
 finding heuristic (almost optimal) control laws
 for online optimization (NMPC)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

253

From system model to optimal control - A tool chain for the efficient solution of optimal control problems

Table 1. Total consumed electrical energy for both
variants.

Pump
PI control
Optimal
control
Difference

Fan

Total

0.18 MJ

0.98 MJ

1.16 MJ

0.20 MJ

0.74 MJ

0.94 MJ

+12%

-25%

-19%

5 Summary
With the presented tool chain Modelica/TIL  FMI 
MUSCOD-II thermal system can be modeled
conveniently and optimal control trajectories can be
calculated rapidly. For the example application, thermal
management of an internal combustion engine,
electrical energy savings of 19% (fan and pump)
compared to PI control are achieved. By comparing the
optimization and simulation results, the causes for
energy savings can be explained.
Optimization calculations of this type can serve as a
reference for control concepts to be developed. The
interpretation of the optimal trajectories can also be used
in finding heuristic (almost perfect) control laws. In
principle, optimum control calculations are also suitable
for online use in vehicles or other technical systems.
Which is known as nonlinear model predictive control
(NMPC). For prototypical NMPC applications on a
Windows laptop, the presented tool chain can be used
directly. However, it is not yet suitable for implementation on embedded control units.

References
kesson, Johan, Karl-Erik rzn, Magnus Gfvert, Tove
Bergdahl, and Hubertus Tummescheit. 2010.
Modeling and Optimization with Optimica and
JModelica.org--Languages and Tools for Solving
Large-Scale Dynamic Optimization Problems.
Computers & Chemical Engineering 34 (11): 1737
49. doi:10.1016/j.compchemeng.2009.11.011.
Albersmeyer, Jan. 2010. Adjoint Based Algorithms and
Numerical Methods for Sensitivity Generation and
Optimization of Large Scale Dynamic Systems.
Ruprecht-Karls-Universitt Heidelberg.
Albersmeyer, Jan, and Moritz Diehl. 2010. The Lifted
Newton Method and Its Application in
Optimization. SIAM Journal on Optimization 20
(3): 165584.
http://epubs.siam.org/doi/abs/10.1137/080724885.
Bauer, Irene. 1999. Numerische Verfahren Zur Lsung
von Anfangswertaufgaben Und Zur Generierung
von Ersten Und Zweiten Ableitungen Mit
Anwendungen Bei Optimierungsaufgaben in

254

Chemie Und Verfahrenstechnik. Universitt
Heidelberg. doi:10.1159/000328458.
Betts, John T. 2001. Practical Methods for Optimal
Control Using Nonlinear Programming. Society for
Industrial and Applied Mathematics.
Biegler, L. 2007. An Overview of Simultaneous
Strategies for Dynamic Optimization. Chemical
Engineering and Processing: Process
Intensification 46 (11): 104353.
Blochwitz, T., M. Otter, J. Akesson, M. Arnold, C. Clau,
H. Elmqvist, M. Friedrich, et al. 2012. Functional
Mockup Interface 2.0: The Standard for Tool
Independent Exchange of Simulation Models. In
9th International Modelica Conference.
Bock, H. G., and K. J. Plitt. 1984. A Multiple Shooting
Algorithm for Direct Solution of Optimal Control
Problems. In Proc. of the 9th IFAC World
Congress Budapest, 24347. Pergamon Press.
Bock, Hans Georg. 1987. Randwertproblemmethoden Zur
Parameteridentifizierung in Systemen Nichtlinearer
Differentialgleichungen. Universitt Bonn.
Bryson, Arthur E., and Yu-Chi Ho. 1979. Applied
Optimal Control: Optimization, Estimation, and
Control. John Wiley & Sons Inc.
Diehl, Moritz. 2001. Real-Time Optimization for Large
Scale Nonlinear Processes. Universitt Heidelberg.
Franke, Rdiger. 2002. Formulation of Dynamic
Optimization Problems Using Modelica and Their
Efficient Solution. In 2nd International Modelica
Conference, 31523. Oberpfaffenhofen.
Grber, Manuel. 2013. Energieoptimale Regelung von
Klteprozessen. TU Braunschweig.
Grber, Manuel, Kai Kosowski, Christoph Richter, and
Wilhelm Tegethoff. 2010. Modelling of Heat
Pumps with an Object-Oriented Model Library for
Thermodynamic Systems. Mathematical and
Computer Modelling of Dynamical Systems 16 (3):
195209. doi:10.1080/13873954.2010.506799.
Imsland, L., P. Kittilsen, and T. S. Schei. 2010. ModelBased Optimizing Control and Estimation Using
Modelica Models. Modeling, Identification and
Control 31 (3): 10721. doi:10.4173/mic.2010.3.3.
Leineweber, D B, I Bauer, A A S Schfer, H G Bock, and
J P Schlder. 2003. An Efficient Multiple Shooting
Based Reduced SQP Strategy for Large-Scale
Dynamic Process Optimization (Parts I and II).
Computers and Chemical Engineering 27: 15774.
Richter, Christoph. 2008. Proposal of New ObjectOriented Equation-Based Model Libraries for
Thermodynamic Systems. Technische Universitt
Braunschweig.
Schulze, C. 2013. A Contribution to Numerically
Efficient Modelling of Thermodynamic Systems.
Technische Universitt Braunschweig.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132249

Nonlinear Model Predictive Control of a Thermal Management
System for Electrified Vehicles using FMI
Torben Fischer1
1 Fraunhofer

Christian Kirches2

torben.scher@ict.fraunhofer.de

Center for Scientific Computing (IWR), Heidelberg University, Germany,

{tom.kraus,christian.kirches}@iwr.uni-heidelberg.de

of Vehicle System Technology, Karlsruhe Institute of Technology (KIT), Germany, frank.gauterin@kit.edu

Abstract
Energy-efficient thermal management systems for Emobility help to decrease energy consumption and increase range. Due to transient external conditions and the
increasing system complexity, optimization-based control
approaches are required in order to harness the full potential of such systems. In (Fischer et al., 11th Int. Modelica Conf, 2015), we have presented a model-based development cycle for a thermal management system in Emobility to this end. In this article, we build upon this
work to describe the use of this model within a nonlinear model predictive control (NMPC) approach. The main
benefits of using an advanced optimization-based control system in this application are a) the ability to control the battery temperature and the cabin temperature simultaneously, b) the increased energy efficiency achieved
by exploiting the predictive character of the optimizationbased control approach, c) the possibility to include operational limits as constraints in the optimization problems
and d) the fast reaction to disturbances or model parameter
changes. We evaluate the merit of the proposed advanced
control system by way of a comparison to conventional
PID controller.
Keywords: thermal management system, nonlinear model
predictive control, Functional Mock-up Interface

1

Frank Gauterin3

Institute for Chemical Technology (ICT), Project Group New Drive Systems, Germany,

2 Interdisciplinary
3 Institute

Tom Kraus2

Introduction

E-mobility is widely considered to be a key concept to
achieve ambitious goals set forth in contemporary climate
and environmental protection plans. Due to higher costs
and lower ranges compared to combustion engine driven
vehicles, a breakthrough in the mass market has yet to take
place. In this article we propose an optimization-based
control for energy-efficient operation of a thermal management system. In (Fischer et al., 2015) we observed a
decrease of the energy consumption of up to 30%, depending on ambient conditions. To improve the system further,
a nonlinear model predictive control (NMPC) approach is
proposed with the aim to harness the full potential of the
multiple-input multiple-output system (MIMO).
This article constitutes a follow-up of (Fischer et al.,
DOI
10.3384/ecp17132255

2015), where the concept of the thermal management system is presented, including simulation results. The remainder of this article is structured as follows: 1 introduces the subject and describes the related state-of-the-art.
2 recalls the process model of the thermal management
system. A short discussion of the NMPC approach resides in 3 covering the formulation as a mathematical optimization problem, the multiple-shooting discretization,
a real-time solution algorithm and the employed software
interface. In 4 process model modifications are described
which were necessary in order to employ derivative-based
optimization techniques. 5 contains an offline case
study to compare different approaches of jacobian matrix
generation on the basis of the Karush-Kuhn-Tucker (KKT)
violation and an online case study to compare NMPC to
conventional PI control. Finally, we provide conclusions
and an outlook on future topics in 6.

1.1

State of the Art

NMPC is widely used in, e.g., process control and chemical engineering, often with rather slow sampling rates. In
the past years, the automotive industry has also shown an
increased interest in model predictive control. Applications like adaptive cruise control (Kirches, 2011; Kirches
et al., 2013), lateral dynamic stabilization, etc., can be typically controlled by a MPC-controller. Further examples
may be found in, e.g., (del Re et al., 2010). In the area
of heating, ventilation, and air conditioning (HVAC), conventional control methods like PID-controllers and bangbang-controllers are still state-of-the-art, mostly due to
simplicity of design and implementation. There are, as
well, investigations on advanced control systems. For example, (Esen et al., 2014) and (Karnik et al., 2016) use
MPC-controllers in the application field of thermal management systems, and (Afram and Janabi-Sharifi, 2014)
gives an general overview for HVAC systems. To reduce
the computational effort, these approaches however often do not rely on first-principles models, but rather on
data models or linearized state-space representations. The
first publication of an NMPC-controller based on firstprinciple models using Modelica is (Franke, 2002). In
(Grber et al., 2012), a functional mock-up unit (FMU)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

255

Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using FMI

of a first-principle Modelica model was used for the first
time within an fully nonlinear MPC setting. This example is closely related to the present article, as it treats a
compression-vapor cycle.

2

Thermal Management System

In this section, we review the layout of a thermal management system as introduced in (Fischer et al., 2015).
The thermal management system of a vehicle has multiple
tasks. Primarily, for passenger comfort heating or cooling of the passenger cabin is required. Moreover, there
are a number of legal requirements to be met including
windshield defrosting and defogging. Finally, powertrain
components have to be kept within their thermal operational range. In the particular case of an electrified vehicle,
increasing demands due to thermally even more sensitive
components and significant less amount of waste heat lead
to a development of new thermal management systems.

coolant and air are also realized using a finite volume
method. The refrigerant accumulator, the coolant reservoirs, and the passenger cabin are modeled using lumped
volumes. The fluid data is taken from the TILMedia library, which provides bi-cubic spline interpolants for the
used refrigerant. The coolant is modeled as pure water and
the ambient air as dry air.

2.2

Controlled Variables

The controlled variables in the system shown in Fig. 1
are the cabin temperature Tcabin , the superheating temperature of the heat pump Tsh and also the battery temperature
Tbattery . The desired cabin temperature Tcabin is assumed to
be at 22C according to passenger preference. To ensure
a safe and efficient operating mode, the superheating temperature of the heat pump Tsh is desirable to be at 5 K.
The admissible thermal operating interval of the battery is
from 20C to 40C. A temperature above this range can
lead to increased aging effects and eventually to degrada2.1 Concept and Model
tion and a thermal runaway. The operating temperatures
The main feature of the system, depicted in Fig. 1, is a re- of the electric motor and the power electronics are usually
versible heat pump, called thermal module (1), which pro- observed but not tracked to a preset value.
vides heating and cooling power to keep the components
within a thermal operating range. Waste heat emitted by 2.3 Manipulated Variables
electric components (2) is used to increase the temperature One manipulated variable in the system is the rate of
level of the heat source, thereby contributing to a higher change ucompr of the compressor frequency of the heat
efficiency of the system. By way of a flexible intercon- pump, which in a PID framework would be controlled
nection, independent thermal conditioning of the cabin (3) according to the cabin temperature setpoint. The second
and the battery (4) may be achieved. By using waste heat input is the rate of change uvalve of the expansion valve
from an optional energy converter like a fuel cell or an in- which in a PID logic would be assigned to the superheatternal combustion engine (5) in a hybrid electric vehicle, ing temperature setpoint. As the system contains two therthe thermal module can be switched off.
mally conditioned components, the output heat rate is split
up by a 3/2-way-valve ((6) in Fig. 1) in the coolant by dividing the mass flow. The valve is a linear control valve
and accepts continuous values between 0 (path to battery
closed) and 1 (path to battery open).

2.4

Figure 1. Scheme of the thermal management system

The heat exchangers in the refrigerant cycle are modeled in distinct ways. The condenser is modeled using
a moving boundary approach while the evaporator is realized using a finite volume method. Details can be found in
4.2. The heat exchangers modeling the heat flow between
256

Control Approach

In (Fischer et al., 2015), we have described a first control
approach, namely a decoupling of the MIMO-system into
multiple SISO-systems, which can then be controlled individually and by separate PID controllers. This approach
turned out to be problematic, as the battery temperature
and thus the cabin comfort was affected by a starting thermal conditioning of the battery. The influences of the PID
controllers on each other also led to inefficient overshooting behavior and oscillations. As the main control goal is
energy-efficiency in order to allow for maximum electric
range of the vehicle, we propose an NMPC approach to
control the system.
In a first step, a reduced model of the thermal management system without battery and attached vehicle model
is used to compare the control schemes in the computational studies in 5. This is appropriate since it is still convenient to control this reduced system by PI-controllers
which serves as good reference for the NMPC-controller.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132255

Session 5D: Control Systems II

3

Nonlinear Model Predictive Control

In this section, we briefly review Nonlinear Model Predictive Control (NMPC) as an optimization-based scheme for
advanced closed-loop feedback control of dynamic processes.

3.1

s.t.

past

future
prediction horizon

NMPC Problem Formulation

A suitable mathematical model description, capable to
predict the future behavior of the dynamic process under
consideration, must be available for the realization of any
NMPC controller. For the system at hand, a nonlinear
differential-algebraic system of equations (DAE) is suitable. The objective function to be minimized is typically
assumed to be of tracking type, i.e. set-points are provided for the controlled variables. In addition, NMPC
permits to include nonlinear constraints on process quantities. The optimization problem to be solved in order to
find optimal controls may then be formulated as a DAEconstrained optimal control problem and reads
Z T
2


2

min 
`(x(), z(), u(), p)d 
 + ||e(x(T ), p)||2,W
x,z,u

NMPC a true closed-loop control scheme. Fig. 2 visualizes this control concept.

0

2,Q

x() = f (x(), z(), u(), p)   [0, T ]
0 = g(x(), z(), u(), p)   [0, T ]
x(0) = x0 (t)
  [0, T ]
0  c(x(), z(), u(), p)
  [0, T ]
0 5 ri (x(i ), z(i ), p)
{i }  [0, T ]

(1a)
(1b)
(1c)
(1d)
(1e)

Herein, an objective function of least-squares type on the
prediction horizon [0, T ] is composed of an integral term `
with weight matrix Q and an end-point term e with weight
matrix W , and tracks set-points provided for certain controlled variables. The problem is constrained by the DAE
model equations (1a, 1b), by inequality path constraints on
dynamic states and controls (1d), and by point constraints
on a grid {i }  [0, T ] that may cover, for example, boundary or periodicity conditions.
By way of constraint (1c), the current process state x0 (t)
at physical time t is embedded into the dynamic optimization problem, and must hence be available as a measurement or be provided by an observer. If the process
model is sufficiently accurate and the formulation of the
optimization problem is suitable, its solution yields optimal process inputs u () on   [0, T ] where  = 0 coincides with the physical time t at which the observation was
taken.
In practice, however, model predictions must be assumed inaccurate because of inevitable measurement or
actuation errors as well as due to systematic model errors.
Naturally, this effect becomes more apparent over longer
time horizons T . For this reason, u , computed from the
initial state x0 (t), is applied to the process for a short
time only. The natural choice for the length of this short
time interval is the systems sampling time.
The optimization procedure is continuously repeated,
each time a new measurement is available. This makes
DOI
10.3384/ecp17132255

past controls

x0 (t) feedback control to be optimized

future controls to be optimized

0 = 0

1

2

N1
N = T

Figure 2. The Nonlinear Model Predictive Control paradigm
for a piecewise constant control subject to optimization on the
prediction horizon.

3.2

Direct Multiple Shooting

In order to computationally solve problem (1) efficiently,
a parameterization of the control u and a discretization
of the states x and z in time is necessary in a direct approach to optimal control. With the direct multiple shooting method (Bock and Plitt, 1984), we employ a simultanous approach.
To this end, the control u is parameterized by piecewise
constant control parameters q on a discretization grid 0 =
0 < 1 < . . . < N1 < N = T ,
u() := qi  Rnu ,   (i , i+1 ), 0  i  N  1.
On each control interval [i , i+1 ], a separate DAE initialvalue problem (IVP)
x() = f (x(), z(), qi , p),   [i , i+1 ]
0 = g(x(), z(), qi , p)  i ()g(si , zi , qi , p)
x(i ) = si , z(i ) = zi

(2a)
(2b)
(2c)

is solved, given the initial value si  Rnx .
The DAE condition is relaxed using a function i ()
that is monotonically strictly decreasing on [i , i+1 ] and
that satisfies  (i ) = 1 and  (i+1 ) = 0. This relieves us
of having to find consistent initial values zi  Rnz for solving the IVP. Consistency in the optimal solution will be
ensured by requiring
0 = g(si , zi , qi , p), 0  i  N.
Continuity of the IVP solutions thusly obtained is enforced by additional matching conditions,
0 = x(i+1 ; i , si , zi , qi , p)  si+1 , 0  i  N  1,
wherein x(i+1 ; i , si , zi , qi , p) denotes the solution of the
i-th IVP on [i , i+1 ] and for initial values si and zi . Finally,
path and point constraints (1d,1e) are enforced in the time
grid points i only. The integral least-squares objective
function is evaluated along the solution of (2).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

257

Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using FMI

The nonlinear programming problem (NLP) resulting  ,  denote the most recent Lagrange multipliers of the
equality and inequality constraints of (QP), respectively.
from this discretization and parameterization reads
In the offline case, the embedding of x0 (t) is replaced by
N1
a
fixed initial value.
2
2
min  :=
||L (s , z , q )|| + ||e(s , z )||
(3a)
s,z,q



i

i

i

i

2,Q

N

N

2,W

i=0

s.t. 0 = x(i+1 ; i , si , zi , qi )  si+1 , 0  i  N  1
0 = g(si , zi , qi )
0iN
0 = s0  x0 (t)
0 5 ri (si , zi , qi )
0  i  N.

(3b)
(3c)
(3d)
(3e)

Herein, Li is an appropriate quadrature rule for `
on [i , i+1 ], ri summarizes the path and point constraints (1d,1e) in i , qN := qN1 , and the dependencies
on p have been omitted. For future reference, we denote
by c() the set of equality constraints (3b, 3c, 3d) and d()
refers to (3e).
This highly structured nonlinear programming problem is solved by a tailored sequential quadratic programming (SQP) method as described in (Bock and Plitt, 1984;
Leineweber et al., 2003). For NMPC, a single iteration k
of this method may be divided into three distinct phases
according to the real-time iteration scheme first proposed
in (Diehl, 2001), as follows:

3.3

Software Interfaces

A state of the art software package that implements the numerical algorithm just presented is MUSCOD, see (Bock
and Plitt, 1984; Leineweber et al., 2003). The DAE initial value problems (2) are solved by DAESOL, cf. (Bauer
et al., 1999; Albersmeyer, 2010).
The developed Modelica model has to be interfaced
with the DAE solver of MUSCOD. To this end, the Functional Mockup Interface (FMI) (Blochwitz et al., 2011)
is one convenient way to do this. Advantages are easy
handling, simulation speed (as the model is provided as
a dynamic link library), and the small effort required to
export existing Modelica models as Functional Mockup
Units (FMU). The interfacing between MUSCOD and the
FMU is carried out in C++, which has already been described in detail in (Grber et al., 2012).
Due to limitations in the current version 2.0 of the FMI
standard, only an ODE interface can be exposed to MUSCOD. Hence, in place of the DAE IVPs (2), the ODE IVPs

1. Prepare:
In the k-th SQP iterate w(k) =
(k)
(k)
(k)
x() = f (x(), g1 (x(), qi , p), qi , p),   [i , i+1 ],
(s , z , q ), compute the gradient b(k) of the
objective and the Jacobian J (k) of the least-squares
x(i ) = si
objective residuals of (3), evaluate the (in-)equality
constraint residuals c(k) , d (k) , and compute lineariza- are solved and the local inversion of the algebraic contions C(k) , D(k) of the (in-)equality constraints.
straint g for the unknown z(t) is internally taken care of
2. Feedback: Obtain a state measurement or estimate by the FMU by way of an iterative nonlinear root-finding
method. This situation is unfortunate from the point of
x0 (t). Solve the quadratic programming problem
view of an all-at-once method for dynamic optimization,
T (k) T (k)
(k) T
1
as these inner iterations could be carried out much cheaper
J )w + b
w
min 2 w (J
w
as part of the solution procedure for the nonlinear pros.t. 0 = C(k) w + c(k)
(QP) gramming problem (3). Moreover, the possibility of different outcomes of adaptive choices during finite differ0  D(k) w + d (k)
ence approximation of Jacobians of f may introduce un(k)
(k)
to find w = (s, z, q) and return u0 + u0 as necessary approximation errors here. Nonetheless, we
have not observed numerical instabilities that could be
the new feedback control.
traced back to this issue.
3. Transition: Determine a step length  (k)  (0, 1] by
way of a globalization approach, and let w(k+1)  Offline Optimization. Offline optimization is a dynamic optimization for a given initial point, time horiw(k) +  (k) w, k  k + 1.
zon and number of intervals which does not incorporate
For online optimal control (NMPC), the three phases are any feedback from the real-world plant. The output data
continuously repeated as fast as CPU resources permit comprises the state vector and the optimal control vector
and state estimates become available. For offline opti- at each interval, which can be provided in the simulation
mal control, the three phases constitute one iteration of an within a time table in a further step. A stable and robust ofSQP method for nonlinear programming, cf. (Nocedal and fline optimization is essential for the online optimization.
Wright, 2006). These are carried out until the termination Fig. 3 shows the scheme of the offline optimization.
criterion
For the online optimization an integration of the realworld
plant model is needed. The optimized manipulated
||L (w(k) )|| +  i |ci (w(k) )| +   j [d j (w(k) )] ,
variables, provided by MUSCOD, have to be applied oni
j
line to the real-world plant model. This requires that an
referred to as the KKT violation, falls below a preset up-to-date measurement of the real-world plant state is
threshold. Herein, L denotes the Lagrangian of (3) and available, since it serves as the initial state for predictions
258

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132255

Session 5D: Control Systems II

Figure 3. Scheme of the offline optimization

in the control model. Fig. 4 shows the scheme of the online optimization. Basically, there are two paths we follow
to interface the model:
Online Optimization with Simulation in Dymola. A
Python script is the central control script, which starts the
simulation in Dymola, sets the optimal manipulated variable and gets the updated measurement data via the Direct
Data Exchange (DDE) Interface. It is challenging though
to filter the needed variables, as there is no function in Dymola to get the state vector of a model. The DDE Server
of Dymola has to be executed before and the simulation
speed must be reduced to real-time.

regularity assumptions for (1). In particular, `, e, f , g, c,
and ri in (1) need to be twice continuously differentiable
w.r.t. all arguments. Furthermore, the algebraic constraint
function g needs to be invertible w.r.t. the algebraic state
z(t), i.e., the Jacobian  g(x, z, q, p)/ z  Rnz nz has full
rank for all applicable values of its arguments.
A first requirement hence is to adapt the existing model
to a model that conforms to the requirements set forth.
The model must not contain any discontinuities; conditional statements, min(), max(), abs()-functions and limiters have to be avoided; the use of the actualStream()operator is no longer possible. Occurrences must be replaced by continuous and twice differentiable statements.
Fig. 5 shows a discontinous function, typically used in hybrid simulations, which in this case is replaced by the logistic function with k = 10 and x0 = 3,
f (x) = (1 + ek(xx0 ) )1 .

1
0.5

Online Optimization with Simulation in MUSCOD.
In this approach no simulation environment is needed anymore. A Python script starts the optimization, and starts a
sequential simulation after each optimization interval. At
the end of each simulation part, the states can be extracted
out of the FMU and passed to MUSCOD as new initial
point. This leads to a very fast result since the simulation
is a lot faster than real time. Furthermore, an ideal NMPC
can be simulated, where no time is needed to calculate the
optimal manipulated variables.

Figure 4. Scheme of the online optimization.

4

Model Adaptations for Optimization

In this section, we report on lessons learned while developing and carrying out adaptation procedures necessary in
order to make the existing thermodynamical model fit for
optimization based control using gradient-based methods.

4.1

Continuous Differentiable Model

This choice of numerical optimization algorithm and initial value problem solver implies certain smoothness and
DOI
10.3384/ecp17132255

0
1

2

3

4

5

Figure 5. Discontinuous transitions have to be replaced by numerical smooth functions.

4.2

Phase Change in Condenser

The rise of the density when crossing the boiling point
curve of the refrigerant in the condenser is discontinuous
and leads to problems in the optimizing process. As stated
in section 2.1, the heat exchangers are modeled by a finitevolume-method. This means, that the flow path is discretized into N cells. Each cell consists of mass flow and
energy conservation. Depending on the operating point or
in transient conditions, the crossing of the boiling point
curve can occur in different cells, and also within a cell.
The discontinuous rise of the density affects the state variable enthalpy, which eventually leads to problems for the
optimizer finding a proper gradient.
To solve this problem, the modeling approach of
a moving boundary heat exchanger, cf. (Jensen and
Tummescheit, 2002) is used. In this case, the flow path
is not discretized into N cells, but always into three cells
according to the fluid phases: subcooled, two-phase and
superheated. Thus, the rise of the density within a cell can
be avoided, as one cell is always considered as a homogeneous phase.
However, using a moving boundary heat exchanger
leads to another major problem. The model is only valid, if
the condenser still contains the three zones superheating,
two-phase and subcooled. It is therefore essential to keep
the heat pump in an operating state, where all three zones
exist. This is achieved by introducing soft constraints punishing operating points of the heat pump which should be
avoided. The limits are defined as follows: the length of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

259

Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using FMI

the subcooled condenser cell lsc should be greater than 5%
of the total length, and the superheating temperature Tsh
should be greater than 4 K. In case of violating these soft
constraints, a high weighted penalty is added to the objective variable, indicating the optimizer to avoid this state.
There are some approaches to model a switching moving boundary model, cf. (Bonilla et al., 2015). Since the
switching algorithm always relies on boolean logic, it cannot be used with a gradient-based SQP algorithm.

4.3

FMU Status Report

The status of the FMU is returned by each function after
calling to indicate the success of the function call. In the
case of fmi2SetContinuousStates the status can
be fmi2Discard, indicating that it is recommended to
discard the last solution and to evaluate the model equations again with a smaller time step. This information has
to be directed to the ODE solver. Ignoring this information can obviously lead to much higher computation time
or even to non-convergence.

5

Computational Results

The final objective function including the two soft constraints reads as follows:

 1
`(x(t), z(t), u(t), p) = wi 2 i (i (t)  i )

i=1,...,6

(4)

wherein  T = (Tcabin , Tsh , ucompr , uvalve , Tsh , lsc ) and
with weights
wT =

 104 10 105
105
104 104 T
, ,
,
,
,
7
292 5 72.5 4.5  10
8 0.1

chosen such that denominators normalize quantities to 1
and numerators indicate relative weights. The set-point is
 T = (295.15, 5, 0, 0, 4, 0.05)T .
The functions i are i (x) = Id (identity) for i = 1, . . . , 4
and i (x) = x  H(x) (Heaviside integral) for i = 5, 6. To
guarantee smoothness assumptions, the Heaviside integral
function x  H(x) is exponentially smoothed in computational practice. The end-point term is

 1

In this section, we report on computational findings for the
e(x(T ), z(T ), p) = wi 2 (i (t)  i )
i=1,...,2
adapted thermodynamical model both for offline optimal
control and in the NMPC context. The results presented
T
T
in this section focus on the thermal management system for  = (Tcabin , Tsh ) , identical set point, and weights
without battery and attached vehicle model.
 106 50 T
T
w
=
,
.
5.1 Problem Setup
292 5
The manipulated variables ucompr and uvalve of the reduced
model are the rates of change of the compressor frequency 5.2 Performance Comparison of Different Jacobian Methods
and the area of the expansion valve. The controlled variables are the cabin temperature Tcabin and the superheating The performance of the online optimizing controller critivalue of the heat pump Tsh . All results are generated with cally depends on the choice of the method to generate Jathe same basic system model, counting a total number of cobians. Fundamentally, derivatives can be computed by
43 differential states, and with a time horizon of h = 20 s automatic differentiation (AD) or numerically by a finite
discretized by N = 20 shooting intervals.
difference scheme (ND). The FMUs generated by Dymola
The sole difference between the model used in the offline use numerical Jacobians by default. By setting the flag Adand the NMPC study is the incorporation of the ambient vanced.GenerateAnalyticJacobian, Dymola can be contemperature as an additional pseudodynamic state in the figured to generate analytic Jacobians and include them
NMPC controllers model (Tamb = 0) while in the offline in the FMU. For this to be effective, it is necessary that
controllers model the temperature is merely a constant. every function used in the Modelica model also declares
An incorporation of this easily measureable quantity ob- a corresponding derivative function. For the given sysviously is the more suited choice since it yields better pre- tem, this required the use of a tailored version of the fluid
dictions. However, since required derivative functions for database TILMedia supplying derivative functions for a
the ambient temperature were not available this was omit- wide range of materialdependent functions. MUSCOD
ted in the offline study for sake of comparability (see also can be configured to use Jacobians, which are provided
5.2).
from outside, e.g. the FMU (numerical or analytical), or
The objective function, defined in Eq. (4), penalizes the to approximate Jacobian matrices numerically by its builtdifferences between controlled variables and their set- in finite difference scheme.
points, as well as input changes. Moreover, a soft con- This sections numerical study compares these three genstraint formulation is chosen to avoid that the superheating eration methods for Jacobians on the basis of respective
temperature Tsh drops below the lower operational bound offline optimization runs. In the scenario, an instantaneous
of Tsh,LB = 4 and that lsc drops below lsc,LB = 0.05:
step change of the ambient temperature of 5 K is applied to
a stationary system state (compare also the online study
max(0, Tsh,LB  Tsh ) = 0.5  (Tsh,LB  Tsh + |Tsh,LB  Tsh |)
at t = 600 s). To investigate effects on precision the intemax(0, lsc,LB  lsc ) = 0.5  (lsc,LB  lsc + |lsc,LB  lsc |)
gration tolerance was set to 109 .
260

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132255

Session 5D: Control Systems II

0

Jacobians generated by ND (MUSCOD)
Jacobians generated by AD (FMU)
Jacobians generated by ND (FMU)

KKT violation

10

5

10

10

10

5

10

15

20

25

Iteration number

Figure 6. After 25 SQP iterations, the remaining KKT violation during offline optimization is smallest (best) when using AD
Jacobians. ND Jacobians provided by MUSCOD are runner-up. ND Jacobians provided by the Modelica FMU perform worst.

objective function (ND)
infeasibility (ND)
objective function (AD)
infeasibility (AD)

0

Rel. distance
to last iterate

10

5

10

10

10

5

10

15

20

25

Iteration number

Time per iteration in [s]

Figure 7. A self-convergence plot of objective function values and infeasibility measures reveals convergence after 10 SQP iterations regardless of the choice of method for generating Jacobians.
30
Jacobians generated by ND (MUSCOD)
Jacobians generated by AD (FMU)
Jacobians generated by ND (FMU)

20
10
0

5

10

15

20

25

Iteration number

Figure 8. AD Jacobians from the Modelica FMU are computationally more expensive than MUSCOD ND Jacobians. Measured
time refers to an integration tolerance of 109 .

Fig. 6 assesses the impact of the Jacobian generation
method on the convergence behavior of MUSCOD in
terms of the remaining KKT violation. As expected, AD
yields a solution with the highest precision. Fig. 7 shows
a self-convergence plot for the objective function value
and the infeasibility measure, i.e., we show for iterations
k = 0, . . . , N  1 the fractions

5.3

Comparison of PI Control and NMPC

In this section two tuned PI-controllers are compared to
the developed NMPC controller. The parameters for the
PI-controller were determined using a step response of the
system and were manually tuned to a normal and more aggressive behavior. The scenario used for this purpose consists of a transient heat-up, starting from a steady state, at
(k)
(N)
(0)
(N)
an ambient temperature of 5C and of a following abrupt
|m  m |/(m  m )
ambient temperature change of +5C, which is applied at
t = 600 s after reaching steady state again, see Fig. 9.
of objective function (m = 0) and infeasibility (m = 1):
The resulting controlled variables are shown in Fig. 10
(k)
(cabin temperature) and in Fig. 12 (superheating value).
0 = (s(k) , q(k) )
The corresponding manipulated variables are plotted in
(k)
(k) (k)
(k) (k) 
Fig. 11 (compressor frequency) and in Fig. 13 (expansion
1 = i [ci (s , q )] +  j [d j (s , q )]
valve area). In contrast to 5.2 the integration tolerance is
As can be seen, after six SQP iterations convergence has now set to 105 . Based on experience this is a sufficient
essentially been achieved regardless of the chosen method. value for this application.
As Fig. 8 reveals the MUSCOD internal finite difference
scheme is, to our surprise, faster than both of the FMU Transient Heat-Up of Passenger Cabin We observe,
Jacobian generation methods. Thus, all following numer- that the NMPC curve rises and settles significantly faster
ical results on NMPC were obtained using this Jacobian than both PI-controllers and without any temperature
generation scheme.
overshoot indicating a very efficient control system (cf.
DOI
10.3384/ecp17132255

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

261

Ambient
temperature
in [C]

Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using FMI

10

5
0

100

200

300

400

500

600

700

800

900

1000

Time in [s]

Temperature in [C]

Figure 9. Ambient temperature step of +5K.
25
20
NMPC
PI (normal)
PI (aggressive)

15
10
5
0

100

200

300

400

500
Time in [s]

600

700

800

900

1000

Compressor frequency
in [Hz]

Figure 10. Passenger cabin temperature during scenario (transient heat-up and temperature step) with different controllers.
150
NMPC
PI (normal)
PI (aggressive)

100
50
0
0

100

200

300

400

500

600

700

800

900

1000

Time in [s]

Superheating in [K]

Figure 11. Frequency of the compressor during scenario (transient heat-up and temperature step) with different controllers.
20
NMPC
PI (normal)
PI (aggressive)

15
10
5
0
0

100

200

300

400

500

600

700

800

900

1000

Time in [s]

Figure 12. Superheating value during scenario (transient heat-up and temperature step) with different controllers.
6

Expansions valve
area in [m]

1

x 10

NMPC
PI (normal)
PI (aggressive)
0.5

0
0

100

200

300

400

500

600

700

800

900

1000

Time in [s]

Figure 13. Expansion valve area during scenario (transient heat-up and temperature step) with different controllers.

Fig. 10). The compressor frequency and expansion valve
reach their upper bounds faster and, subsequently, stabilize the system to a steady-state far more rapidly with
NMPC (cf. Fig. 11 and Fig. 13). The predictive character
of NMPC taking into account the systems thermal inertia
can be identified on the basis of the compressor frequency
already being decreased at a temperature well below 20C.
Fig. 12 depicts the effect of the rather weak tracking
weighting for the superheating temperature in the NMPC
262

objective function and the corresponding soft-constraint to
ensure a lower operational bound of 4 K (cf. 5.1). Superheating value fluctuations are acceptable unlike violations
of the operational limits, which are prevented here by the
NMPC approach. On the basis of Tab. 1, showing criteria
for controller performance as overshoot, settling time and
rising time, we can eventually state, that NMPC combines
the fastest and most efficient way to heat up the cabin temperature to its set value.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132255

NMPC

PI (norm.)

PI (aggr.)

78.2
95
0.4

162.7
194.6
1.25

80.4
173.1
10.50

Rising time [s]
Settling time [s]
Overshoot [%]

Table 1. The NMPC controllers characteristics during transient
heat-up significantly outperform PI control.

Time per
time step in [s]

Session 5D: Control Systems II

4
3
2
1
0
0

200

400

600

Time step #

800

1000

Figure 14. CPU time in seconds per NMPC iteration, consumed
by all three phases and including FMU evaluation calls during
the preparation phase. Measured time refers to an integration
tolerance of 105 .
Time per
time step in [ms]

Reaction to Disturbances At t = 600 s the controllers
can be compared when dealing with a disturbance, here,
an ambient temperature step of +5C. On the basis of
2
Fig. 10, we conclude that the NMPC shows the best be1.5
havior, with a very small amplitude and a very short time
1
interval before the steady state is reached again. This is
not due to the predictive character of NMPC, as the tem0.5
perature change is not known in advance. The NMPC
0
0
200
400
600
800
1000
controller gets the information about a temperature change
Time step #
along with the measured state vector at t = 600 s. Again,
the weak weighting of the superheating value can be ob- Figure 15. CPU Time in milliseconds per NMPC iteration consumed by the feedback phase only.
served in Fig. 12, as the superheating value is affected by
the disturbance in the case of the NMPC-controller.
CPU Time The computations were performed on a
workstation using a single core of an Intel Xeon CPU
at 3.5 GHz. To guarantee real-time feasibility for future
application in a vehicle, it is necessary that the duration
of feedback and prepare phase is shorter than the chosen
sampling time (1 s here). If this can be ensured, the
feedback phase duration is the time delay between the
measurement of the system state and the availability of
new values for the manipulated variables. Naturally,
a short duration is essential to make sure the applied
feedback relies on up-to-date system state information.
Fig. 14 shows a graph of the CPU time consumed by
both phases. The realtime feasibility limit is indicated by
a dotted red line and mostly not exceeded in the scenario.
However, three CPU time peaks within the transient heatup phase and the abrupt temperature change phase still violate the limit. The peak at the beginning is due to a cold
start of the NMPC controller. Since we start stationarily
this peak could be avoided by the execution of sufficiently
many SQP iterations before a respective warm-start of the
NMPC controller. An investigation of the remaining peaking behavior must yet be carried out, i.e. whether it originates from the particular model implementation or is a
general property of the system. In future work, the latter
could be adressed algorithmically by introducing adaptive
relinearization into the NMPC schemes using, e.g., multilevel schemes (Bock et al., 2005; Kirches et al., 2012) or
mixed-level schemes (Frasch et al., 2012). Fig. 15 shows
a graph of the CPU time consumed by the feedback phase
only. It is in the order of 0.5  2 milliseconds, which is a
near instantaneous response on the measured system state
relative to the system dynamics time scale. The feedback
phase CPU time rises only very mildly during transient
phases, and remains satisfyingly low throughout.
DOI
10.3384/ecp17132255

6

Conclusion & Outlook

The article discusses the development of an NMPC setup
for a thermal management system of electrified vehicles.
Compared to conventional PI control, several advantages
concerning the transient heat-up and in reaction to disturbances were noted. The NMPC reaches the set-point
value and settles considerably faster, nearly without any
overshoot. This indicates an overall high degree of energy
efficiency. Also, NMPC reacted faster on external disturbances that were not known in advance. A further benefit
is the safe operating mode, as each state variable of the
system can be constrained and constraints remained satisfied throughout all experiments. In the context of the heat
pump application, the superheating value could be kept
at a safe distance from the dew line in every operating
point. The only observed drawback was the comparably
high development effort that was necessary for developing
the model and deploying NMPC for the system at hand.
The Functional Mockup Interface turned out be a convenient way to export a previously developed Modelica
model and to use it within the optimizer. To use the
developed Modelica simulation model also for optimal
control, though, several adaptations concerning smoothness assumptions were necessary. Although the optimizer could not be given access to the whole differentialalgebraic equation (DAE) system due to intrinsic limits of
the current version 2.0 of the FMI standard, the derivativebased optimization was found to work satisfactorily for
the model at hand. A direct implementation of the DAE
system in MUSCOD still promises a significant future increase in performance and numerical stability. Finally, we
expected a higher impact of using analytic Jacobians provided to the optimizer by the FMU. Without insight into
the auto-generated source code from which the FMU was

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

263

Nonlinear Model Predictive Control of a Thermal Management System for Electrified Vehicles using FMI

compiled, we could not rigorously answer the question of H.G. Bock and K.J. Plitt. A Multiple Shooting algorithm for
direct solution of optimal control problems. In Proceedings
why the analytic Jacobian provided by the FMU is about
of the 9th IFAC World Congress, pages 242247, Budapest,
twice as slow as the comparably simple one-sided finite
1984. Pergamon Press.
difference approximation method we used in conjunction
H.G. Bock, M. Diehl, P. Khl, E. Kostina, J.P. Schlder, and
with MUSCOD.
Outlook. This article focused on controlling the cabin
temperature through the use of NMPC. In a further step,
the temperatures of cabin and battery will be tracked in
parallel and the temperature of the electric components
of the powertrain will be restricted to a realistic thermal
range. The evaluation of the complete system can then be
carried out on the basis of driving cycles.
Right now the NMPC controller still receives the entire
measured state vector from the simulation. This is not realistic after deploying the controller to the final hardware
application, as only a subset of the system state can be
measured in reality. Thus, an observer will be employed
to estimate the states that are not physically measurable.
In a second step, the hardware application will be targeted, where the whole developed thermal management
system in an electric vehicle is controlled by the NMPC.
The optimization must prove real-time feasibility to guarantee a solution within the defined time interval under all
circumstances. The direct implementation of the DAE
system in MUSCOD might prove to be essential to this
end.
Acknowledgements.

The authors acknowledge support by
DFG Graduate School 220 and the Institutional Strategy of Heidelberg University funded by the German Excellence Initiative, and by the German Federal Ministry of Education and Research program Mathematics for Innovations in Industry and
Service 20132016, grant no 05M2013-GOSSIP. This publication was also written in the framework of the Profilregion Mobilittssysteme Karlsruhe, which is funded by the Ministry of
Science, Research and the Arts and the Ministry of Economic
Affairs, Labour and Housing in Baden-Wrttemberg and as a national High Performance Center by the Fraunhofer-Gesellschaft.
The authors are grateful to the TILMedia team at TLK-Thermo
GmbH in Braunschweig for kindly providing access to a specialized version that supplies derivatives.

References
A. Afram and F. Janabi-Sharifi. Theory and applications of
HVAC control systems: A review of model predictive control (MPC). Building and Environment, 72:343355, 2014.
J. Albersmeyer. Adjoint based algorithms and numerical methods for sensitivity generation and optimization of large scale
dynamic systems. PhD thesis, Heidelberg University, 2010.
I. Bauer, H.G. Bock, and J.P. Schlder. DAESOL  a BDF-code
for the numerical solution of differential algebraic equations.
Internal report, IWR, SFB 359, Heidelberg University, 1999.
T. Blochwitz, M. Otter, M. Arnold, C. Bausch, C. Clauss,
H. Elmqvist, A. Junghanns, J. Mauss, M. Monteiro, T. Neidhold1, D. Neumerkel, H. Olsson, J.-V. Peetz, and S. Wolf.
The functional mockup interface for tool independent exchange of simulation models. 8th Int. Modelica Conf., 2011.

264

L. Wirsching. Numerical Methods for Efficient and Fast Nonlinear Model Predictive Control. In R. Findeisen, F. Allgwer,
and L. T. Biegler, editors, Assessment and future directions of
Nonlinear Model Predictive Control, volume 358 of LNCIS,
pages 163179. Springer, 2005.
J. Bonilla, S. Dormido, and F. E. Cellier. Switching moving
boundary models for two-phase flow evaporators and condensers. Communications in Nonlinear Science and Numerical Simulation, 20:743768, 2015.
L. del Re, F. Allgwer, L. Glielmo, C. Guardiola, and I. Kolmanovsky. Automotive Model Predictive Control. Springer,
2010.
M. Diehl. Real-Time Optimization for Large Scale Nonlinear
Processes. PhD thesis, Universitt Heidelberg, 2001.
H. Esen, T. Tashiro, D. Bernardini, and A. Bemporad. Cabin
heat thermal management in hybrid vehicles using model predictive control. 22nd Med. Conf. Contr. Autom. (MED), 2014.
T. Fischer, F. Gtz, L. Berg, H.-P. Kollmeier, and F. Gauterin.
Model-based development of a holistic thermal management
system for an electric car with a high temperature fuel cell
range extender. 11th Int. Modelica Conference, 2015.
R. Franke. Formulation of dynamic optimization problems using modelica and their efficient solution. 2nd International
Modelica Conference, pages 315323, 2002.
J.V. Frasch, L. Wirsching, S. Sager, and H.G. Bock. MixedLevel Iteration Schemes for Nonlinear Model Predictive Control. In Proc. IFAC Conf. on NMPC, 2012.
M. Grber, C. Kirches, D. Scharff, and W. Tegethoff. Using
functional mock-up units for nonlinear model predictive control. 9th International Modelica Conference, 2012.
J.M. Jensen and H. Tummescheit. Moving boundary models for
dynamic simulations of two-phase flows. 2nd International
Modelica Conference, pages 235244, 2002.
A.Y. Karnik, A. Fuxman, P. Bonkoski, M. Jankovic, and
J. Pekar. Vehicle powertrain thermal management system using model predictive control. SAE International, 2016.
C. Kirches. Fast Numerical Methods for Mixed-Integer Nonlinear Model-Predictive Control. In H.G. Bock, W. Hackbusch,
M. Luskin, and R. Rannacher, editors, Advances in Numerical Mathematics. Springer Vieweg, Wiesbaden, July 2011.
C. Kirches, L. Wirsching, H.G. Bock, and J.P. Schlder. Efficient Direct Multiple Shooting for Nonlinear Model Predictive Control on Long Horizons. J. Proc. Contr., 22(3):540
550, 2012.
C. Kirches, H.G. Bock, J.P. Schlder, and S. Sager. Mixedinteger NMPC for predictive cruise control of heavy-duty
trucks. In European Control Conference, pages 41184123,
Zurich, Switzerland, July 17-19 2013.
D.B. Leineweber, I. Bauer, A.A.S. Schfer, H.G. Bock, and J.P.
Schlder. An Efficient Multiple Shooting Based Reduced
SQP Strategy for Large-Scale Dynamic Process Optimization
(Parts I and II). Comp. Chem. Eng., 27:157174, 2003.
J. Nocedal and S.J. Wright. Numerical Optimization. Springer
Verlag, Berlin Heidelberg New York, second edition, 2006.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132255

Defining and Solving Hybrid Optimal Control Problems with
Higher Index DAEs
Radosaw Pytlak1
1 Faculty

Damian Suski2

Tomasz Tarnawski3

Tomasz Zawadzki4

of Mathematics and Information Science, Warsaw University of Technology, Poland,
r.pytlak@mini.pw.edu.pl

2 Institute

of Automatic Control and Robotics, Warsaw University of Technology, Poland,
{d.suski,t.zawadzki}@mchtr.pw.edu.pl

3 Department

of Quantitative Methods and Information Technology, Kozminski University, Poland,
ttarnawski@kozminski.edu.pl

4 Research

and Academic Computer Network (NASK), Poland,
tomasz.zawadzki@nask.pl

Abstract
The paper deals with optimal control problems defined
for hybrid systems described by higher index DAEs. We
present a prototype solution that supports the whole process from defining such problem to solving it and presenting results. Problems definition is done with Dynamic Optimization Modeling Language (DOML) which
is based directly on Modelica. The proposed numerical
procedure for solving the problems of interest has the following features: 1) it is based on the appropriately defined
adjoint equations formulated for the discretized equations
being the result of the numerical integration of system
equations by an implicit RungeKutta method; 2) initialization for higher index DAEs is performed with the help
of Pantelides algorithm; 3) it does not require the system to be transformed to ODEs (through differentiation of
some algebraic equations).
The paper presents numerical examples related to hybrid systems described by index three DAEs, showing the
validity of the proposed approach. All software components needed to carry out the computations, i.e. the code
editor, compiler, numerical libraries and GUI for presenting results are prepared as parts of a combined platform:
Interactive Dynamic Optimization Server (IDOS).
Keywords: hybrid systems, optimal control problems,
higher index DAEs

1

Introduction

The DOML language (introduced in (Pytlak et al.,
2014)) was devised an as extension of Modelica towards
defining optimal control problems for systems described
with Modelica language  quite analogically to Optimica
(proposed earlier, in (kesson, 2007), see also (kesson,
2008)). In fact, the DOML compiler environment is heavily based on the open source Modelica (and Optimica)
compiler environment JModelica.org (see e.g. (kesson
et al., 2009)). During the efforts of adapting Optimica for the purpose of deploying it within IDOS environment a conclusion was reached to redesign some
of its optimization-related constructs, as its original design brought in some troublesome limitations (details can
be found e.g. in (Pytlak et al., 2013) and (Tarnawski
and Pytlak, 2014)). To avoid confusion with Optimica,
we then chose to refer to the language as DOML. Although the framework is (eventually) intended to be fully
compatible with Modelica, the current development efforts are focused strictly on building prototype, proof-ofconcept implementations of advanced optimization algorithms. Therefore, ensuring DOMLs wide and flawless
compatibility with Modelica syntax (and MSL models in
particular) has to wait for its turn (still, being based on
JModelica.org environment, DOML is in the position to
enjoy a fair deal of compatibility inherited in the package). Up to this point several different optimization algorithms and solver libraries have already been implemented
(see Table 1 in (Pytlak et al., 2014)): e.g. solvers for optimal control problems with ODEs based on apriori discretization of system equations (HQP package), solvers
that use adjoint equations and do not require apriori discretization of equations, solvers based on multiple shooting methods, solvers for control problems with integer valued controls which use BONMIN package, solvers that
use integration procedures from SUNDIALS package and
IPOPT as the optimization engine.

The paper presents recent development of solver functionality implemented within DOML (Dynamic Optimization
Modeling Language) environment and deployed as part
of the IDOS (Interactive Dynamic Optimization Server,
described in (Pytlak et al., 2014), see also (Pytlak et al.,
2013)) infrastructure. It uses a numerical procedure based
on control vector parameterization and RADAU5 together
with event (discrete state transition) handling and is capaThe new algorithm implementation presented here is
ble of solving optimal control problems for hybrid, high- designed to solve optimal control problems defined by hyindex DAEs.
brid systems, i.e. systems with mixed discrete-continuous
DOI
10.3384/ecp17132265

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

265

Defining and Solving Hybrid Optimal Control Problems with Higher Index DAEs

dynamics (van der Schaft and Schumacher, 2000), whose
dynamics are described with high-index DAEs. It must be
noted, that even separately each of these categories poses
nontrivial difficulties for optimization and even for simulation alone. In particular:

 new keywords, minimize and maximize were introduced making it possible to have meaningfully
named optimized parameters with the direction of
optimization chosen by the user. It also became possible to specify multicriteria optimization problems.

 higher index DAE systems need the procedure for
the automatic consistent initialization, the integration
procedure for higher index DAEs and the optimization solver equipped with the procedure for evaluating gradients of functionals defining optimization
problems

 annotation(solver) was used to allow the user to
specify the algorithm to be used to solve the given
problem, along with its runtime settings. A preliminary procedure of choosing the most appropriate
solver, based on elements detected in the problemss
definition, was also implemented.

 hybrid systems require the procedure for the accurate location of discrete transition times, the integration procedure with an automatic handling of discrete
dynamics an the optimization solver equipped with
the procedure for evaluating gradients of optimization problem functionals, which is dedicated for a
hybrid system dynamics.
The authors are not aware of any implementations (other
then the one introduced in (Pytlak, 2011)) of a dynamic
optimization algorithm capable of reliably solving highindex DAE problems without an application of the index reduction procedure. Similarly, the authors are not
aware of an established and widely-used implementation
of a dynamic optimization algorithm applicable to hybrid
systems. In particular, the optimization algorithms implemented in environments featuring Optimica (JModelica.org, OpenModelica) cover the problems described by
ODEs (or DAEs with the help of the index reduction) but
not hybrid systems.
The paper is organized as follows. In section 2 we outline the features of DOML and in particular the language
constructs used to express the problems of interest. They
are then used in section 3 to define two simple exemplary
problems used to test and illustrate capabilities of the implemented solver. Trajectories obtained by solving these
problems are also presented. The following two sections
are devoted to formal description and analysis of the algorithm. First, in section 4, a formal definition of hybrid
optimal control problem is laid out (and used to formally
re-define the example problems). Then, based on that, section 5 discusses the most important mathematical and implementational details of the proposed optimization procedure. The paper is wrapped up with short concluding
remarks.

2

Hybrid optimal control problem
definition in DOML

The provisions of DOML that differentiate it against Optimica were already described in earlier works (e.g.: (Pytlak et al., 2014), (Tarnawski and Pytlak, 2014) or (Pytlak
et al., 2013)). To avoid excessive repetition, here they are
only listed very briefly:
266

 a mechanism for labeling equations and constraints
was introduced, by means of which the adjoint variables (for equations) and Lagrange multipliers (for
constraints) could be referred to. Implementation of
some solvers required that functionality.
 decision variables InitialGuess attribute was redefined with continuous variability, so that it became
possible for initial guess to be defined as a signal
changing over time. This was developed particularly
with chaining of solvers in mind: an approximate
solver could be run first, then the solution obtained
could be used to warm-start another solver  a more
exact one, yet also more fussy with respect to the
starting point.
For the most part, these earlier provisions were well
geared for formally defining the optimal control problems
of interest. In the case of hybrid systems, however, we
found it necessary to devise specific syntactic constructs
to fully express the systems dynamics. The resulting
canonical form description of a hybrid system is structured around:

 singular enumeration type variable whose values
range over possible discrete states of the system;
 compound if elseif statement containing equations defining the dynamics specific for each state;
 embedded when clauses specifying transition
guardsconditions for exiting the current state and
the new state reached with the transition;
 optional reinit operator used to define any potential discontinuous behavior upon a changeofstate
event.
In result, the description of a hybrid system may take the
form along the lines drawn on Listing 1. Please note, that
the presented code is meant as a mere example and does
not necessarily reflect sensible dynamics of any actual system.
In a general case the state-transition conditions (guards)
between a pair of states do not have to be the same for both
directions. One good example, when this is certainly not
the case, is hysteresis (in the example shown: between

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132265

Session 5D: Control Systems II

Listing 1. Example of DOML code defining a hybrid system
optimization Hybrid_ex(startTime = 0.0,
finalTime = 1.0)
minimize Real objective = x3(finalTime);
... // decls of vars (x) and inputs (u)
type Q = enumeration(A, B, C);
discrete Q q(start = Q.A); // the state
equation
... // equations common to all states
if q == Q.A then
der(x1) = -x1 + x2 + 2*u;
when x1 < -1 then
//transition A->B
q = Q.B;
end when;
elseif q == Q.B then
der(x1) = -2*x1 +x2 + u;
when x1 > 1 then
//transition B->A
q = Q.A;
end when;
else // q == Q.C
der(x1) = -x2 + u;
when x2 < 0 then
//bounce-back C->C
q = Q.C;
reinit(x3, -x3);
elsewhen x2 > 10 then //transition C->A
q = Q.A;
end when;
end if;
end Hybrid_ex;

section, after introducing the necessary formalism, we restate them in a mathematically formal way.
Example 1. It is an optimal control problem of a nonstandard pendulum described by DAEs with index three
(van der Schaft and Schumacher, 2000), in Cartesian coordinates x1 and x2 . On the vertical axis there is a fixed pin
interfering with pendulums string and effectively halving
its length when x1  0. For x1  0 the pendulum swings
with its original length. There is no jump in differential
state variables during state transition. The control variable
u represents force applied horizontally to the pendulums
end (constrained above by 0.3, in either direction). The
objective of the control is to cause the system to reach
such final state in which the pendulums position x1 (t f ) is
as close as possible to the neutral point, while its velocity
component v2 (t f ) is equal to 0.06. The DOML definition
of the problem is presented in Listing 2.
After 10 iterations optimality conditions were satisfied
with accuracy 106 while equality constraint v2 (t f ) = 0.06
with accuracy 107 . The obtained optimal trajectories are
given in Figure 2 while the optimal control in Figure 1 
as it turns out, it exhibits a relatively complex switching
structure.

0.3

0.2

0.1
controls

states A and B). In addition, with the proposed construct,
it is possible to define transition from a state onto itself
(in the example: happens in C) which is applicable for
instance in the case of a ball bouncing off a wall, back
into the realm of the same dynamics, but with its velocity
(abruptly) altered (hence the reinit placed in the example).

u

0

0.1

0.2

3

Examples

Below, we present the results of applying the presented
algorithm to solving two optimal control problems based
on hybrid systems. They have been previously discussed
in (Pytlak and Suski, 2017), but here we show results for
different versions of these problems. Please note, that
the purpose of these examples is purely illustrative within
the discussion of capabilities of the implemented solver
and they do not necessarily represent sensible problems of
real engineering importance or application. Also, as noted
earlier, the algorithms implementation is at the stage of
proof-of-concept and has only been tested on cases with
limited complexity, where the whole problem is defined
in one stand-alone input file. Defining optimization problems through models constructed with MSL components
was not tested (however, the compiler is build on top of
the JModelica.org compiler, which itself provides a substantial MSL support).
Below, we define the exemplary optimal control problems solely be means of DOML code. In the following
DOI
10.3384/ecp17132265

0.3
0

0.5

1

1.5
time

2

2.5

3

Figure 1. The pendulum exampleoptimal control.

Example 2. The second example is the popular bouncing ball problem discussed in several papers e.g. (van der
Schaft and Schumacher, 2000). The ball bounces off the
fixed surface level at x1 = 0 with the opposite velocity (assuming no energy loss, i.e. the coefficient of restitution
is 1). The system has only one discrete state. The control variable u is a force applied vertically to the ball (with
the constraint that it cannot exceed the value of 2.5, either
upwards or downwards). The objective is to end up (at
t f = 1) with the ball being at the height of 0.5 and having
minimum velocity (in terms of its absolute value). The
DOML script of the problem is presented in Listing 3.
Applying the SQP code resulted, after 23 iterations, in
an approximate optimal solution given in Figure 3. The

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

267

Defining and Solving Hybrid Optimal Control Problems with Higher Index DAEs

package Pendulum
optimization Pendulum_opt(startTime = 0,
finalTime = 3.0)
minimize Real obj = x1(finalTime)^2;
type states =
enumeration(short, normal);
discrete states State;
parameter Real p = 0.5;
... // decls of vars (x1, x2, ... L)
input Real u1(min=-0.3, max=0.3,
initialGuess=0.0);
initial equation
if x1 >= 0.0 then
State = states.normal;
else
State = states.short;
end if;
equation
der(x1)
der(x2)
der(v1)
der(v2)

=
=
=
=

v1;
v2;
w1;
w2;

package Bouncing
optimization Bouncing_opt (startTime =
0.0, finalTime = 1.0)
minimize Real obj = x2(finalTime)^2;
type states = enumeration(normal);
discrete states State;
parameter Real c = 5.0;
Real x1(start = 1.0);
Real x2(start = 0.0);
input Real u(min=-2.5,max=2.5,
initialGuess=0.001);
initial equation
State = states.normal;

if State == states.normal then
0 = w1+x1*L-u1;
0 = w2+1.0+x2*L;
0 = x1*x1+x2*x2-1.0;
when x1 < 0.0 then
State = states.short;
end when;
else
0 = w1+x1*L/p-u1;
0 = w2+1.0+(x2+1.0-p)*L/p;
0 = x1*x1+(x2+1.0-p)*(x2+1.0-p)-p*p;
when x1 > 0.0 then
State = states.normal;
end when;

equation
der(x1) = x2;
der(x2) = -c + u;
if State == states.normal then
when x1 < 0.0 then
State = states.normal;
reinit(x2, -pre(x2));
end when;
else
State = states.normal;
end if;
constraint
c1: x1(finalTime) = 0.5;
end Bouncing_opt;
end Bouncing;

end if;
constraint
c1: v2(finalTime) = 0.06;

Listing 3. The DOML file of the bouncing ball problem.

end Pendulum_opt;
end Pendulum;

Listing 2. The DOML file of the pendulum problem.

268

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132265

Session 5D: Control Systems II

1

3
x1
x2
2

0.5

trajectories

trajectories

1
0

0.5

0

1

1

1.5
0

2

x1
x2
v1
v2
0.5

1

1.5
time

2

2.5

3
0

3

Figure 2. The pendulum exampleoptimal trajectories.

0.1

0.2

0.3

0.4

0.5
time

0.6

0.7

0.8

0.9

1

Figure 4. The bouncing ball exampleoptimal trajectories.

where
2.5

 Q is a finite set of discrete states. Its elements are
denoted by q.

u

2
1.5

 U is a set of admissible controls. The elements of
U are measurable functions u : I  U, where I can
be any closed interval of R and U is a fixed subset of
Rm .

1

controls

0.5
0
0.5

 I is a function which assigns to every discrete state
q a set

	
I (q) = x  Rn : q (x)  0 , q : Rn  Rnq (2)

1
1.5
2
2.5
0

0.2

0.4

0.6

0.8

1

such that as long as a hybrid systems is in a discrete state q the continuous state trajectory x stays
in I (q). We therefore say that I (q) is an invariant
set for a discrete state q.

time

Figure 3. The bouncing ball exampleoptimal control.

optimality conditions and equality constraint x1 (t f ) = 0.5
were satisfied with accuracy 106 . Some of the final trajectories are illustrated in Figure 4. At final time the ball is
at the required height, and has a relatively small velocity,
|x2 (t f )|  0.3.

4

Formal discussion of hybrid systems

Hybrid systems are systems with mixed discretecontinuous dynamics (van der Schaft and Schumacher,
2000). In this work we use the formal definition of a hybrid system based on the one given in (Suski and Pytlak,
2016), which is similar to many other definitions given in
the literature e.g. (Lygeros et al., 1999), (van der Schaft
and Schumacher, 2000), (Shaikh, 2004). We restrict our
analysis to systems with autonomous transitions.
A hybrid system H is a tuple
H = (Q, U , I , F , T , G , J )
DOI
10.3384/ecp17132265

(1)

 F is a function which assigns to every discrete state
q a function Fq : Rn  I (q) U  Rn such that in a
discrete state q the continuous state evolves according to a differential-algebraic equation
Fq (x, x, u) = 0.

(3)

 T is a subset of Q  Q, which collects all pairs of
discrete states (q, q0 ) such that the transition from a
state q to a state q0 is possible.
 G assigns to each pair (q, q0 )  T a subset of I (q)
boundary such that when a continuous state trajectory is about to leave I (q) through its boundary
 I (q) at a point xt  G (q, q0 )   I (q) a discrete
state changes from q to q0 . We call such an event a
transition and G plays a role of a transition guard.
 J assigns to each pair (q, q0 )  T a function qq0 :
G (q, q0 )  I (q0 ) such that when a discrete state

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

269

Defining and Solving Hybrid Optimal Control Problems with Higher Index DAEs

changes from q to q0 at a transition time instant tt with
then a continuous state undergoes a jump according

	
U = u  L11 [0,t f ] |  0.3  u(t)  0.3 a.e. on [0,t f ]
to
x(tt+ ) = qq0 (x(tt )).
(4)
and t f = 3.0. The parameter p satisfies p = 1 for x1 
Having the definition of hybrid systems we can for- 0 and p = 0.5 for x1  0. The hybrid system has
mally state the optimal control problem with hybrid sys- therefore two discrete states q1 and q2 with invariant
sets: I (q1 ) = {(x1 , x2 , v1 , v2 , w1 , w2 , L)  R 7 : x1  0},
tem as:
I (q2 ) = {(x1 , x2 , v1 , v2 , w1 , w2 , L)  R 7 : x1  0}.
min  (x(t f ))
(5)
In turn, the optimal control problem given as the second
u
example (bouncing ball) can be formally defined as: The
optimal control problem transcribed formally is as follows
subject to the constraints:


h1i (x(t f )) = 0, i  E
(6)
(20)
min x2 (t f )2
h2j (x(t f ))  0, j  I
u(t)   a.e. t  T.

uU

(7)
(8) subject to the constraints

where the continuous dynamics of a hybrid systems is described by a system of higher index differentialalgebraic
and
equations (DAEs)
Fq (x, x, u,t) = 0 a.e. t  T = [0,t f ]

(9)

x1 (t f )  0.5 = 0

(21)

x1 = x2
x2 = 5 + u

(22)
(23)

which depends on the actual discrete state q.
We assume that u(t)  R m , x(t)  R n , I, E are finite with
sets of indices and  is a convex bounded subset of R m .

	
U = u  L11 [0,t f ] |  2.5  u(t)  2.5 a.e. on [0,t f ] .
A more general problem with parameters as decision variables, with an unspecified time horizon and with the state
constraints could also be considered but for the simplicity and t f = 1.0. The jump function is given by

 

of presentation we analyze the problem stated above.
x1 (tt+ )
x1 (tt )
We also assume that a solution to system (9) exists and
J (x(tt )) =
=
. (24)
x2 (tt+ )
x2 (tt )
is unique for any u  U where
U = {u  L1m [T ] | u(t)   a.e. on T } ,

(10)

The system has only one discrete state q with invariant
set defined by I (q) = {x  R 2 : x1  0}.

and any consistent initial condition x(0).
5 Numerical procedure
Example Problems restated
Having defined the above one can transcribe the earlier The utilized numerical procedure for solving hybrid optiexamples in a mathematically formal way. The hybrid op- mal control problems include the mechanisms for
timal control problem from the first example (pendulum)
 numerical integration of system equations (3) bemay be stated as follows:
tween transitions


min x1 (t f )2
(11)
uU
 proper handling of transitionsprecise location of
transition times and application of state jumps
subject to the constraints
v2 (t f )  0.06 = 0

(12)

v1
v2
w1
w2
w1 + x1 L/p  u
w2 + 1 + (x2 + 1  p)L/p
x12 + (x2 + 1  p)2  p2

(13)
(14)
(15)
(16)
(17)
(18)
(19)

and
x1
x2
v1
v2
0
0
0
270

=
=
=
=
=
=
=

 the calculation of adjoint variables for the evaluations of gradients of functionals defining the problem.
The numerical procedure for solving optimal control
problems described by higher index DAEs was introduced
in (Pytlak, 2011). For the completeness of a presentation the essential ingredients of the procedure are also discussed here.
Suppose that we want to integrate numerically the set
of differentialalgebraic equations
F(x, x, u) = 0

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(25)
DOI
10.3384/ecp17132265

Session 5D: Control Systems II

by an implicit RungeKutta method. If we denote by x(k) for k = 0, . . . , N  1. The adjoint variables p are the means
the value of x calculated at the kth integration step (at a for the gradient evaluation according to the formula
time tk ), then the next value x(k + 1) is evaluated by solv0
ing the set of nonlinear equations
Fu(k)
(u) = u (k)T p(k + 1).
(37)
s

F(xi (k + 1), x(k) + h(k)  ai j x j (k + 1), u(k)) = 0, (26)
j=1

Using (32)(33), the adjoint equations (36) and the formula (37) can be expressed without the knowledge of :

s

x(k + 1)  x(k)  h(k)  bi xi (k + 1) = 0, (27)
i=1

where coefficients ai j , bi depend on a RungeKutta
method.
In order to define state equations of the discrete time
system (26)(27) we introduce the state vector X(k):


x1 (k)
 .. 


X(k) =  .  ,
(28)
 xs (k) 
x(k)
then equations (26)(27) become
F(X(k + 1), X(k), u(k)) = 0.

(29)

System (29) is fully implicit and, under some nonsingularity assumption, can be expressed as explicit. If the Jacobian of F with respect to X(k + 1), denoted by FX + , exists
and is nonsingular for all k = 0, . . . , N  1, then from the
Implicit Function Theorem there exists unique function 
such that
X(k + 1) = (X(k), u(k))

(30)

F((X(k), u(k)), X(k), u(k)) = 0

(31)

and

for k = 0, . . . , N  1.
Under differentiability assumptions imposed on F the
function  is differentiable with respect to X(k) and u(k)
and we have

1
X (k) =  FX + (k)
FX (k)
(32)

1
u (k) =  FX + (k)
Fu (k).
(33)
where FX + (k), FX (k), Fu (k) are evaluated at a point
(X(k + 1), X(k), u(k)) and X (k), u (k) are evaluated at
(X(k), u(k)).
If we consider the function
F 0 (u) =  (X u (N))

(34)

then its gradient can be calculated by referring to adjoint
equations for the functional (34) and the system (30).
The adjoint equations for the functional (34) and the
system (30) are considered, for example, in (Pytlak,
1999):
p(N) = X (X u (N))T
p(k) = X (k)T p(k + 1),
DOI
10.3384/ecp17132265

(35)
(36)


T
p(k) = FX (k)T FX + (k)
p(k + 1) (38)

T
0
T
Fu(k) (u) = Fu (k) FX + (k)
p(k + 1). (39)
Eventually we have the viable formula for the gradient
of F 0 (u) provided that matrices FX + (k) are nonsingular.
For special (but widely used) forms of higher index
DAEs the matrices FX + (k) are nonsingular provided that
h(k) are sufficiently small. For example in (Hairer et al.,
1989) it is shown that the statement holds for DAEs in the
Hessenberg form up to an index three and the RADAU
IIA integration scheme. Therefore, for many higher index
DAEs we have a valid technique for computing gradients
of F 0 (u) (and other functions involved in an optimal control problem).
For the numerical integration, our software utilizes
the RADAU5 code, which implements the RADAU IIA
scheme with number of stages s = 3. The coefficients
of a method and its good numerical properties are described in (Hairer et al., 1989). The numerical integration of DAEs will succeed if initial states are consistent.
The initialization problem is solved in two steps. In the
first step, the system of equations, required for the consistent initialization, is formed. This step is carried out with
the help of Pantelides graph based procedure (Pantelides,
1988) together with symbolic differentiation implemented
within JModelica.org compiler. In the second step the system of equations is solved with the help of IPOPT solver
(Wachter and Biegler, 2006). The consistent initialization
procedure is called at the initial time and at points at which
control functions exhibit jumps.
RADAU5 code requires the preliminary analysis of
higher index DAEs: the user has to identify variables
which have socalled index 1, index 2 and index 3 property. These indices can be established during the consistent initialization processin our approach that information is passed from the procedure which implements the
Pantelides algorithm into the integration procedure. As
a result the user of our package does not have to specify
indices of equations variables in the DOML script.
In hybrid systems, one needs a procedure, which locates
the transition times. To complete this task, our procedure
uses subroutines drchek.f and droots.f (Hiebert
and Shampine, 1980). The subroutine drchek.f does
the preliminary check on the presence of a transition point.
Next, the subroutine droots.f is called to locate the
root with the specified accuracy. The root finding problem is solved with the help of the interpolation procedure
which uses Hermite polynomials.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

271

Defining and Solving Hybrid Optimal Control Problems with Higher Index DAEs

Between transitions, the adjoint equations are solved
with the help of a formula (36), the same as for nonhybrid
systems. However, the situation at a transition time is different. Let us denote the system equations before transition as
(40)
X(k + 1) =  1 (X(k), u(k), h(k))
and the system equations after transition as
X(k + 1) =  2 (X(k), u(k), h(k)).

(41)

In the above equations the dependence of system equations on h(k) is explicitly stated. The reason for that is the
following. The step sizes nearby a transition step kt are
not taken freely, but they are taken to satisfy the transition
condition
(X  (kt )) = 0
(42)
where X  (kt ) denotes the state vector before jump. The
value of a state after jump is determined by the equation
X + (kt ) = (X  (kt )).

(43)

Now to calculate the adjoint variables at a transition the
following linear system of equations needs to be solved
for variables p(kt ) and 
T
p(kt ) +  (X (kt ))T = (X (kt ))T X2 (kt ) p(kt + 1) (44)
p(kt )T h1 (kt  1) = p(kt + 1)T h2 (kt ). (45)

6

Conclusions

The paper presents the most recent advancement in the
DOML-IDOS environment, where a number of optimization algorithms can be used to solve optimal control problems specified in a language directly derived from Modelica (and Optimica). The latest numerical procedure, described here, implements an advanced algorithm for solving hybrid optimal control problems with higher index
DAEs. The procedure is based on the RADAU5 program
which is the implementation of an implicit RungeKutta
method. The procedure uses variable stepsizes in order to
locate precisely switching points. The procedure is based
on the adjoint equations associated with the discretized
equations being the result of system equations integration
and does not require the transformation of higher index
DAEs to ODEs by performing differentiations of some
system equations.
So far, the development focus was placed strictly on
implementing proof-of-concept, prototype solutions based
on most recent dynamic optimization algorithms while ensuring wide Modelica compatibility, environment robustness, more graceful error handling, etc. have been put on
hold. The authors are well aware of the need to devote
more attention to those lagging issues and indeed intend
to do so.

References

The partial derivative h (k) is calculated with the formula
J. kesson. Tools and Languages for Optimization of Large1

h (k) =  FX + (k)
Fh (k)
(46)
Scale Systems. PhD thesis, Department of Automatic Control,
Lund University, Lund, Sweden, 2007.

analogical to formulas (32)-(33). The formulae (44)(45)
are derived in (Pytlak and Suski, 2017).
J. kesson. Optimicaan extension of Modelica supporting dyTo solve the optimal control problem, we replace connamic optimization. In Proceedings of the 6th Modelica Control functions by their piecewise constant approximations
ference, Bielefeld, Germany, March 2008. Modelica Associand follow the optimization procedure outlined below.
ation.
Optimization Procedure
1. Choose initial control u0 and set the iterations number: k = 0.

J. kesson, M. Gfvert, and H. Tummescheit. JModelicaan
open source platform for optimization of Modelica models.
In Proceedings of MATHMOD 2009 - 6th Vienna International Conference on Mathematical Modelling, Vienna, Austria, February 2009. TU Wien.

2. For the control uk , integrate system equations by calling consistent initialization procedure when necessary. Calculate the cost function and evaluate all con- E. M. Gertz and S. J. Wright. Object-oriented software for
straint functions. Evaluate the adjoint equations for
quadratic programming. ACM Transactions on Mathematieach function defining the optimal control problem
cal Software, (29):5881, 2003.
and on that basis calculate the gradients of all functions involved in optimal control problem.
E. Hairer, Ch. Lubich, and M. Roche. The numerical solution

of differential-algebraic equations by RungeKutta methods.

3. Perform the optimization step. If optimality condiLecture Notes in Mathematics, 1409:56225, 1989.
tions are satisfied with the assumed accuracy then
STOP. Otherwise evaluate uk+1 , increase k by one K. L. Hiebert and L. F. Shampine. Implicitly defined output
and go to Step 2).
points for solutions of ode-s. Technical report, United States
Department of Energy, Sandia Laboratories, 1980.

In our code the main optimization loop is handled by
the SQP code described in (Pytlak, 1999). The optimiza- J. Lygeros, K. H. Johansson, S. Sastry, and M. Egerstedt. On the
tion procedure requires solving QP subproblems at each
existence of executions of hybrid automata. In Proceedings of
iteration. The interior point method described in (Gertz
the 38th IEEE CDC, pages 22492254, Phoenix, AZ; USA,
and Wright, 2003) is used for that purpose.
December 1999. IEEE.
272

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132265

Session 5D: Control Systems II

C. C. Pantelides. The consistent initialization of differentialalgebraic systems. SIAM Journal on Scientific and Statistical
Computing, 9(2):213231, 1988. doi:10.1137/0909014.
R. Pytlak. Numerical Methods for Optimal Control Problems
with State Constraints. Lecture Notes in Mathematics 1707.
Springer Berlin Heidelberg, 1999. ISBN 9783540662143.
R. Pytlak. Numerical procedure for optimal control of higher
index DAEs.
Discrete Contin. Dyn. Syst., 29(2):647
670, 2011. ISSN 1078-0947; 0133-0189; 1553-5231/e.
doi:10.3934/dcds.2011.29.647.
R. Pytlak and D. Suski.
On solving hybrid optimal control problems with higher index DAEs.
Optimization
Methods
and
Software,
2017.
doi:http://dx.doi.org/10.1080/10556788.2017.1288730.
R. Pytlak, J. Baszczyk, A. Karbowski, K. Krawczyk, and
T. Tarnawski. Solvers chaining in the IDOS server for dynamic optimization. In Proceedings of 52nd IEEE CDC,
pages 71197124, Florence; Italy, 2013. IEEE. ISBN 9781-4673-5714-2. URL http://dblp.uni-trier.de/
db/conf/cdc/cdc2013.html#PytlakBKKT13.
R. Pytlak, T. Tarnawski, B. Fajdek, and M. Stachura.
Interactive Dynamic Optimization Server  connecting
one modelling language with many solvers.
Optimization Methods and Software, 29(5):11181138, 2014.
doi:10.1080/10556788.2013.799159.
M. S. Shaikh. Optimal Control of Hybrid Systems: Theory and
Algorithms. PhD thesis, McGill University, Montreal, Que.,
Canada, 2004. URL http://digitool.library.
mcgill.ca/R/?func=dbin-jump-full&
object_id=85095&local_base=GEN01-MCG02.
AAINR06340.
D. Suski and R. Pytlak. The weak maximum principle for hybrid
systems. In Proceedings of the of the 24th IEEE MED, pages
338343, Athens; Greece, 2016. IEEE.
T. Tarnawski and R. Pytlak. DOML - a compiler environment
for dynamic optimization supporting multiple solvers. In
Proceedings of the 10th International Modelica Conference,
pages 10951104, Lund; Sweden, 2014. Linkping University Electronic Press.
A. J. van der Schaft and J. M. Schumacher. An Introduction to
Hybrid Dynamical Systems. Lecture Notes in Control and Information Sciences. Springer, 2000. ISBN 9781852332334.
A. Wachter and L. T. Biegler. On the implementation of an interior point line search flter algorithm for large scale nonlinear programming. Mathematical Programming, (106):2557,
2006.

DOI
10.3384/ecp17132265

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

273

274

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Large Scale Training through Spoken Tutorials to Promote and use
OpenModelica
Kannan M. Moudgalya1
1 Dept.

Bhargava Nemmaru1 Kaushik Datta1
Peter Fritzson2 Adrian Pop2

Priyam Nayak1

Rahul Jain1

of Chemical Engineering, Indian Institute of Technology Bombay, India,

kannan@iitb.ac.in,{bnemmaru,kaushikdatta18,nayak.priyam22,rahjain1}@gmail.com
2 Dept.

Computer and Information Sciences, Linkping University, Sweden,
{peter.fritzson,adrian.pop}@liu.se

Abstract
The step-by-step self-teaching approach through audiovideo tutorials, known as Spoken Tutorials, has been very
successful. About 3.4 million students in India have taken
at least one course during the past 6-year period, of which
1.6 million students have attended the rapidly expanding
course programme during 2016. This programme has now
been expanded by a newly developed course in Modeling and Simulation with Modelica using the OpenModelica open source tool, primarily via the OMEdit graphical
user interface. The spoken tutorial programme is exclusively based on free and open source software. This paper
gives an introduction to the spoken tutorial approach and
presents the recently developed spoken tutorial series for
Modelica using OpenModelica. Feedback of participants
shows that this series is an effective tool for self-learning
of OpenModelica. The paper also presents a new web
version that generalises the interactive DrModelica course
material, OMWebbook: it enables students to learn Modelica, do text-based modeling exercises, and run simulations without needing to install a Modelica tool. OMWebbook is also planned to be covered in a future update to
the spoken tutorial course on Modelica.
Keywords: Spoken Tutorial, tutorial, Modelica, OpenModelica, teaching, self learning, modelling, simulation

1

Introduction

Modelling and simulation is the most cost effective way
for a developing country like India to become a developed
one. For example, the warning issued by the Indian Space
Research Organisation (ISRO) saved 10,000 lives recently
(Laxman, 2016). It is well known that satellites help locate
arable land, help predict locations in seas with fish population, etc. Indias advances in the satellite technology are
rooted in modelling and simulation. ISROs interplanetary
missions are said to be most cost and time effective, one
of the reasons being the extensive use of simulation (EconomicTimes, 2013). Improving the modelling and simulation ethos amongst the academics can help derive such
benefits in other sectors also.
Free and open source software (FOSS) is equally imDOI
10.3384/ecp17132275

portant to a developing country like India. Use of proprietary software results in an outgo of $ 1 billion every
year, in education and police sectors alone (De, 2009).
This precious foreign exchange can be more usefully spent
in priority sectors like poverty alleviation and infrastructure development. Because of this, the Indian government has made the use of open source software mandatory, whenever it is of comparable capability to commercial software for the tasks at hand (Govt. of India, 2015).
As OpenModelica implements the complete Modelica language (Modelica-Association, 2012) and is an open source
implementation, we have selected it to promote the modelling and simulation culture in India. The award winning Spoken Tutorial method is selected for this promotion (Google, 2015; QS&Wharton, 2015).
This paper is organised as follows. We begin with a
brief explanation of the Spoken Tutorial methodology in
sections 2 and 3. We list the Spoken Tutorials created on
OpenModelica in section 4. We then explain in section
5 how to use these tutorials for effective learning without
experts. In section 6, we explain the cloud environment
OMWebbook In the final section, we conclude the paper
with a discussion on future work.

2

Spoken Tutorials

A Spoken Tutorial is a ten minute long audio-video tutorial, created using the Screencast technology. It is well
known that the optimal time for a video tutorial is about 9
minutes (Guo, 2013).
Here we use the tutorial concept in a slightly different
way from a conventional 2-3 hour lecture-based tutorial.
Spoken Tutorial is a smaller modular piece of active learning: A typical student following such an audio-video tutorial is expected to pause/replay the video and reproduce
every command. To enable this, all the files used in the
video are also seamlessly made available to the learner. As
the software covered is open source, the student can download it, and practise the tutorial side-by-side. There are
also exercises to perform. A beginner could easily spend
half an hour to practise a 10 minute Spoken Tutorial, while
an advanced learner may complete it in less time.
Spoken Tutorials are created to explain general IT con-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

275

Large Scale Training through Spoken Tutorials to Promote and use OpenModelica

cepts. Although only a small amount of information may
be covered in ten minutes, one can cover advanced topics
as well through a series of tutorials. The following factors
distinguish this methodology:

2. As it was difficult to find free slots, we mapped Spoken Tutorials to lab courses and encouraged learning during lab hours. As they do not have access to
good teachers, most students in India find this a valuable resource that helps them understand the subject,
score well in exams and get jobs.

1. Spoken Tutorials are created for self learning. We
write the script before making the video. The script
has to be certified as understandable by a beginner,
before it is taken up for recording.

3. We convinced university authorities, curriculum
boards and syllabus committees to use Spoken Tutorials officially in their lab courses. More than 100
universities, each of which has about 50 to 500 affiliating colleges, have accepted the Spoken Tutorial methodologies, and have sent circulars recommending the use. At present, there are about 20,000
semester long lab courses that officially use Spoken
Tutorials.

2. Spoken Tutorials are released through Creative Commons Attribution Share Alike (CC-BY-SA) license
from our website (Spoken-Tutorial-Project, 2017b).
3. Spoken Tutorials are created on open source software
only. As a result, anyone who wants to learn using
Spoken Tutorial, can download and practise with the
corresponding software.

4. We now insist that we work only with colleges that
agree to train ALL their students through Spoken Tutorials. This and the previous point have helped us
train a really large number of students in the first full
year of implementation, which is 2016, see Figure 1.
We have trained a total of 2.8 million people in the
past five years, reaching 1.6 million in 2016 alone.
200,000 people have already enrolled for our training during the first 20 days of this calendar year.

4. We make available all the code, data files, etc., that
are required in a tutorial, see Figure 6. This allows
the learner to reproduce all the commands shown in
the tutorial. This also allows a learner to start learning from any tutorial, obviating the need to go in a
particular sequence.
5. We use the side-by-side method of learning through
Spoken Tutorials. A schematic of the arrangement
is given in Figure 7. This arrangement reduces the
cognitive overload of learners (Moudgalya, 2014).

5. We provide online tests and certificates to college
students who pass them. These are offered free of
cost, thanks to the funding from our government.

6. We dub the spoken part of Spoken Tutorials into all
22 official languages of India. For this, we time the
script, which needs to be done only once. The fact
that the video is in English helps from the employment perspective of our students. We have dubbed
some of our tutorials also into some languages of
the Middle East, South East Asia, Latin America and
Africa. As our tutorials are available under the CCBY-SA license, these are available to everyone.

6. Our website (Spoken-Tutorial-Project, 2017b) also
receives a large number of visitors. In Figure 2, we
present the statistics of visitors to our web page. It
should be noted that most of our learners using the
offline learning material, created using the facility
described in Figure 4, which has increased the number of learners 50 times, as reported in Figure 2.

7. The web statistics are good from the view of other
7. We have about 800 tutorials made into English, covparameters as well. For example, the average
ering about 40 topics, such as, C, C++, Java, Python,
time one spends on our web page (Spoken-TutorialPHP, Perl, Ruby, Scilab, LATEX, LibreOffice and
Project, 2017b) is about 10 minutes and the bounce
DWSIM. We have about 5,600 dubbed tutorials. This
rate is about 30%, as can be seen from Figure 3.
is the largest collection of IT training material in Indian languages.
We can use the procedure presented in this section to teach
and thereby promoting OpenModelica and the Modelica
3 Large Scale Training with Spoken language.

Tutorials

4

OpenModelica Spoken Tutorials

We now briefly explain the way we have used Spoken TuWe created ten Spoken Tutorials on OpenModelica, as
torials to promote IT literacy:
shown in Table 1. In this Table, we have listed the title
1. We initially offered 2 hour free training to college of these tutorials and their learning objectives. The averstudents and faculty, to be done outside college age time of these tutorials is about 13 minutes, with the
hours. As Spoken Tutorials are created for self learn- minimum of 8 minutes and a maximum of 15 minutes.
ing, presence of an expert is not necessary. Any inter- Although these are the first set of tutorials we created on
ested person could organise a training session, using OpenModelica, we have numbered them from 4, because
the resources at the college.
of reasons to be explained next.
276

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132275

Session 6: Poster Session
Number of students/teachers trained in their colleges/schools
1,600,000
1,400,000
1,200,000

Table 1. Summary of Spoken Tutorials on OpenModelica

No.
4

Name
Developing
an
equation based
model

5

Control
flow
and
event
handling
Functions
and types

1,000,000
800,000
600,000
400,000
200,000
0
2,011

2,012

2,013

2,014

2,015

2,016

Figure 1. Growth of students/teachers trained. Our insistence
that every student should be trained on at least one topic, and
mapping to course content, have resulted in a large growth in
2016. The total number trained until now is about 3 million.

6

7

Arrays in
Modelica

8

Array functions and
operations

9

Modelica
Packages

10

Annotations
in Modelica

11

Icon
and
diagram
views

12

Component
oriented
modelling

13

Block
component
modelling

Figure 2. Growth of visits to ST website (Spoken-TutorialProject, 2017b). This can be obtained by visiting (StatCounter)
and choosing Yearly data

In a recently held workshop (FOSSEE-Team, 2017), all
the participants were asked to self-learn OpenModelica
using Spoken Tutorials. We received the following feedback from the participants about the use of Spoken Tutorials:

 ... the detailed step-by-step descriptions made it easy
to learn the basics of OpenModelica.
 Is is good for beginners. I suggest you to showcase
more application use cases for the advanced use.
 ... very good , we have learned much from spoken
tutorial.
 Spoken Tutorials are easy to Understand.

Learning Objectives
Create a new Modelica class, variables, parameters and equations.
Assign initial, minimum and maximum values. Simulate model and
see results.
Explain if-else statements, time
and state events, when statement,
and reinit function.
Define functions, data types, input
and output variables, assignment
statements, and the algorithm section. Evaluate a polynomial.
Define vectors, vector indexing,
array variables, for and while
loops, and nested for loop.
Explain OMShell, array construction function and perform arithmetic operations on vectors and
matrices.
Create a package of classes, reference classes in a package, import
statement, and using Modelica library.
Specify an annotation and define
a record. Explain through experiment, model and documentation
annotations.
Specify icon and diagram views
of a class, insert a polygon and
an ellipse in icon/diagram view.
Introduce coordinate system, grid
and components. Explain origin
and extent concepts, and line and
fill styles.
Instantiate classes. Define component orientation, acausal connectors, resistors, sources and the
ground. Connecting classes and
pins.
Define blocks and connect them.
Use MISO blocks and Modelica
libraries. Define RealInput and
RealOutput connectors. Instantiate sum and product functions.

 ... up to some extent this tutorial make learning easier but we should make some more basic tutorial on
OpenModelica.

Figure 3. Analysis of visitor statistics of Spoken Tutorial, given
by SimilarWeb (Team)

DOI
10.3384/ecp17132275

 In my opinion side by side tutorials are the best way
to start learning a new software. In order to master
anything it will take a lot of practice of course but

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

277

Large Scale Training through Spoken Tutorials to Promote and use OpenModelica

Table 2. Summary of New Spoken Tutorials on OpenModelica

No.
1

Name
Introduction
to OMEdit

2

Examples
through
OMEdit

3

OM Connectors

Learning Objectives
Introduction to OM, OMEdit,
opening a class from libraries
browser, simulating it and seeing the results in plots. Explain
through a heat transfer example in
thermal library.
Expose learners to models from
electrical and mechanics libraries,
using rectifier and double pendulum classes. Simulate and see the
results in plots.
Train how to compose existing objects to create a new circuit. Concept of connectors introduced. Explain through resistor,
capacitor, inductor, voltage source
and ground.

having the basics right makes practice a lot easier.

 Tutorials are excellent. If you could include tutorials on popular extensions available on Modelica,
it would be a great help. For example, the device
drivers library.

5

Method to Use OpenModelica Spoken Tutorials

We now explain how to use OpenModelica Spoken Tutorials. One should remember that our method should be such
that any volunteer can conduct these workshops. As volunteers may not know answers to questions the learners
may have, we insist on only reproducing what is shown
in Spoken Tutorials: the learner does not know anything,
so why not first do the things suggested in the tutorial?
The pros and cons of this approach are summarised in
(Moudgalya, 2011). We also offer a timed forum that
will help the learner to go through the answers of previous questions and to ask new questions (Spoken-TutorialProject, 2017a).
The first thing to do is to create an offline version using
the create the cdcontent utility, as shown in Figure 4. Of course, this has to be done only by the organiser
of the workshop. This will create a zip file, which has to
be unzipped and copied on to every computer thereafter.
We now summarise the recommended way to use Spoken
Tutorials to conduct an OpenModelica self-learning workshop:
1. Open the file index.html using Firefox or
Chrome. Internet Explorer may not work correctly.
One gets the page as shown in Figure 5. From the url
inside the red box in this figure, one can see that the
learning content comes from the file system.

Tutorials in Table 1 were created as per the pedagogy
2. Listen to the side by side spoken tutorial that
we use in classes: teach the underlying language first. But
appears on this page. This tutorial explains how the
this is not necessarily the best way when it is offered for
learner has to use this method. After that, one has
self learning. Students who depend on commercial simto Select Foss Category and then Select
ulators are used to the plug and play method of learning,
Language and then Submit - these options are enwhich is possible in OpenModelica if one uses the preclosed in a green box in Figure 5.
defined models that come with the distribution. This will
3. The learner has to learn all the tutorials in the resultalso reduce the fear of first time users.
ing play list one by one. From the play list, one can
To address the above issue, we created two more tutoriselect any tutorial. If one scrolls down, one can see
als. The first one explains how heat transfer modelling can
if any code file comes with that tutorial. In Figure 6,
be done. The second tutorial is concerned with examples
one can see where the code files are available.
from Electrical Engineering and Mechanical Engineering.
These two tutorials are created for the absolute beginners,
4. Figure 7 shows how to open the Spoken Tutorial and
who would like to learn how to use the already available
the OpenModelica software side by side. Using the
models.
side-by-side method (Moudgalya, 2014), the learner
We created one more tutorial to explain how to connect
has to reproduce every command described in the tupredefined models. Such a facility is generally available
torial. The learner has to do the assignments also.
in commercial simulators. Introduction to this capability
As a result, the learner ends up spending a lot more
right at the beginning increases the value of the simulator
time, even though the tutorial itself may only be of
in the opinion of the learner. In this tutorial, we show how
ten minute duration.
to connect the preexisting blocks to build a new model.
We now ask new learners to practise these tutorials, before
5. Using the method explained above, one has to learn
starting with the ones in the previous section.
learn all Spoken Tutorials in the play list.
These new tutorials are listed in Table 2. Although created later, they are numbered from 1, as we recommend The above given explanation is for the offline user. The
these to be practised first, before proceeding to the ones same procedure will work for online use of Spoken Tutolisted in Table 1.
rials.
278

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132275

Session 6: Poster Session

In the six month time since we created Spoken Tutorials under discussion, we have trained more than 5,000
people on OpenModelica. As this is achieved through the
self learning of already created Spoken Tutorials, there is
a potential to train many more.

needed. Figure 10 shows a small part of a chemical engineering course book in OMNotebook and OMWebbook
with some formulae that have been typeset using this approach.
We propose to develop Spoken Tutorials on DrModelica, OMNotebook and OMWebbook in the near future.
6 Cloud Environment OMWebbook This will help beginners to quickly learn how to use these
to Ease Learning of OpenModelica powerful tools and hence will further ease the learning of
OpenModelica. Given that modelling and simulation are
DrModelica (Lengquist-Sandelin et al., 2003) is an in- advanced topics for most students in India, we need all the
teractive electronic document for learning Modelica text- tools to make them accessible.
based modeling and simulation using the OpenModelica
tool OMNotebook. It is structured like a book, with chap- 7 Conclusions and Future Work
ters, sections, model examples, exercises, formulae, and
In this work, we have outlined a procedure to improve
figures (Asghar et al., 2011). The recent versions of Drthe modelling and simulation ethos in India and elsewhere
Modelica contain most of the model examples in (Fritzthrough Spoken Tutorial enabled self-learning of Openson 2014) in an editable and executable form, including
Modelica. Based on the user feedback, we are in the
plots of simulated models. DrModelica is intended for
process of increasing the offering of Spoken Tutorials on
self-learning and includes exercises with solutions, where
other OpenModelica topics. Through this effort, the powthe solutions are temporarily hidden while the student is
erful modelling paradigm of Modelica is expected to reach
working on a problem. Thus, it is extremely useful to
many people in India.
everyone, and especially to the beginning learners of the
In the companion paper presented by our group in this
Modelica language and the OpenModelica tool.
conference (Jain et al., 2017), we have explained how the
Recently we have developed a web-based verfeatures of OpenModelica have been extended to make it
sion of OMNotebook, called OMWebbook (http:
useful to chemical engineers. We seek such contributors
//omwebbook.openmodelica.org/) which enables
in other domains too. We hope to promote the use of the
editing models, running simulations, and doing plots in a
Modelica language and the OpenModelica tool with speweb-page (Figure 8). The appearance is very similar to
cific focus on different domains of application.
the OMNotebook. Thus, the students need not install any
We also seek collaborators who would want to make
Modelica tool on their computer. They do not even need a
available this important technology in their countries.
computer, the exercises can be done using a phone or pad.
OMWebbook communicates with a server that performs Acknowledgements
the actual simulation and plots. Naturally, those who do
not have bandwidth to access the Internet can use OM- This work has been supported by Swedish Vinnova governmental agency and the Indian DST governmental
Notebook.
OMNotebook, and also OMWebbook, have recently agency in the Indo-Swedish RTISIM project, and by the
been enhanced with support for typesetting Mathemati- National Mission on Education through ICT, Ministry of
cal formulae using LATEX commands (Asghar et al., 2011). Human Resource Development, through the Spoken TutoThese commands are associated with a formulae cell (Fig- rial project. The OpenModelica development is supported
ure 9) but can be hidden (Figure 10) when editing is not by the Open Source Modelica Consortium.

DOI
10.3384/ecp17132275

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

279

Large Scale Training through Spoken Tutorials to Promote and use OpenModelica

Figure 4. Creating a zip file of all tutorials for offline use, using the cdcontent facility

Figure 5. Unzipped content, opened in Firefox or Chrome. Internet Explorer may not work correctly. The URL inside the red box
points to a file. One has to first listen to the side-by-side method tutorial. After that, one selects the FOSS, then the language, such
as English, and then Submit. This will give a play list. One can then open any of the tutorials and practise side by side, as shown
in 7

280

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132275

Session 6: Poster Session

Figure 6. In the selected tutorial, one has to scroll down to locate the code files. Its location is indicated by the red oval in the
above figure. Code files help the learner reproduce every command.

Figure 7. Side-by-side method. On the left hand side, we have the spoken tutorial, developing an equation based model. On the
right hand side, OMEdit is displayed. The code file that came with the tutorial is opened in OMEdit.

DOI
10.3384/ecp17132275

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

281

Large Scale Training through Spoken Tutorials to Promote and use OpenModelica

Figure 8. Example using OMWebbook on the simple HelloWorld model in DrModelica

282

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132275

Session 6: Poster Session

Figure 9. Type-setting mathematical formulae in OMNotebook using LATEX commands

Figure 10. Example of finished typesetting of mathematical formulae in OMNotebook and OMWebbook

DOI
10.3384/ecp17132275

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

283

Large Scale Training through Spoken Tutorials to Promote and use OpenModelica

References
A. Asghar, S. Tariq, M. Torabzadeh-Tari, P. Fritzson, A. Pop,
M. Sjlund, P. Vasaiely, and W. Schamai. An Open Source
Modelica Graphic Editor Integrated with Electronic Notebooks and Interactive Simulation . In Proc. of the 8th International Modelica Conference 2011, pages 739747, Linkping
university, Sweden, 2011.
R. De.
Economic impact of free and open source
software - a study in india.
Technical Report
http://www.iimb.ernet.in/~rahulde/
RD_FOSSRep2009.pdf, IIM Bangalore, 2009.
EconomicTimes. Why isros mars mission is the cheapest.
http://economictimes.indiatimes.com/
slideshows/science-technology/whyisros-mars-mission-is-the-cheapest/
harness-software-work-fast/slideshow/
24982272.cms, 31 Oct. 2013.
FOSSEE-Team.
Openmodelica workshop.
fossee.in/workshop/om/, 4-5 Jan. 2017.

http://

Google.
Google mooc focused research awards.
https://research.googleblog.com/2015/
03/announcing-google-mooc-focusedresearch.html, March 2015. Last seen on 22 Jan.
2017.
Govt. of India.
Policy on adoption of open source
software for govt. of india.
Gazette Notification,
http://www.indianemployees.com/
gazette-notifications/details/policyon-adoption-of-open-source-software-forgovt-of-india/, 2015. English notification is given
after that in Hindi. Last seen on 22 Jan. 2017.
P. Guo.
Optimal Video Length for Student Engagement. See https://www.edx.org/blog/optimalvideo-length-student-engagement, 2013. Last
seen on 3 April 2017.

http://timesofindia.indiatimes.com/india/
cyclone-vardah-isro-satellites-saved10000-lives-in-tamil-nadu/articleshow/
55992320.cms, 17 December 2016. Last seen on 3 April
2017.
EL. Lengquist-Sandelin, S. Monemar, P. Fritzson, and P. Bunus.
DrModelica - An Interactive Tutoring Environment for Modelica. In Proceedings of the 3rd International Modelica Conference, Linkping, Sweden, 3-4 Nov. 2003.
Modelica-Association. Modelica: A unified object-oriented language for physical systems modeling, language specification
version 3.3. http://www.modelica.org/, May 2012.
K. M. Moudgalya. LATEX Training through Spoken Tutorials.
TUGboat, 32(3):251257, 2011.
K. M. Moudgalya. Pedagogical and Organisational Issues in
the Campaign for IT Literacy Through Spoken Tutorials. In
R. Huang, Kinshuk, and N.-S. Chen, editors, The new development of technology enhanced learning, chapter 13, pages
223244. Springer-Verlag, Berlin Heidelberg, 2014.
QS&Wharton.
Reimagine education 2015:
Spoken Tutorial is Placed First in the Nurturing Employability Award Category.
http:
//application.reimagine-education.com/
the-winners-individual/2015/132/
2193b0ae3841f24da1464d4b6b70ee0f/Indian+
Institute+of+Technology+Bombay%22,
Dec.
2015.
Spoken-Tutorial-Project.
Online forum.
See http://
forums.spoken-tutorial.org/, 2017a. Last seen on
3 April 2017.
Spoken-Tutorial-Project. Official web page. See http://
spoken-tutorial.org/, 2017b. Last seen on 3 April
2017.

R. Jain, K. M. Moudgalya, P. Fritzson, and A. Pop. Development
of a Thermodynamic Engine in OpenModelica. In 12th Int.
Modelica Conf., Prague, 2017. Modleica Association.

StatCounter. Summary log. http://statcounter.com/
p5528933/summary/?account_id=
2904483&login_id=5&code=
9f03e451b379437c7356d2529c726a7a&guest_login=
1. Last seen on 12 Dec. 2016.

S. Laxman.
Cyclone Vardah: ISRO satellites saved
10,000 lives in Tamil Nadu.
Times of India,

Similar Web Team. Get insights for any website or app. https:
//www.similarweb.com/. Last seen on 12 Dec. 2016.

284

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132275

EMOTH
The E-Mobility Library of OTH Regensburg
Alexander Grimm, B.Eng.1
1

Prof. Anton Haumer2

OTH Regensburg, Germany, alexander.grimm@st.oth-regensburg.de
2
OTH Regensburg, Germany, anton.haumer@oth-regensburg.de

Keywords:
e-mobility, electric vehicle, modular
vehicle model, energy consumption, real driving cycle,
driving performance.

easy to take components out from a commercial library
and improve them to match the specific needs.
The library is based on Modelica and the
VehicleInterfaces Library offered by the Modelica
Association ([1], [2]). Following the structure and the
templates of the VehicleInterfaces Library has the
advantage that components can easily be exchanged
without having any troubles with the interface
definition. A big advantage of the VehicleInterfaces
Library is the fact that there are one-dimensional
rotational and translational mechanical connectors
predefined in the templates as well as threedimensional mechanical connectors. In the basic
version, only one-dimensional effects have been taken
into account. During the remaining two semesters of
the master course, the basic models available now have
to be refined to meet certain requirements, e.g. to
enable changing the vehicles mass at bus stops due to
exchange of passengers.

1

2

Abstract
The importance of E-Mobility is rapidly increasing, not
only for private vehicle traffic but also for public
transport. In and around Regensburg, Germany there
are a lot of automotive companies. Therefore
E-Mobility is an important topic in the curriculum of
several courses of study at the East-Bavarian Technical
University of Applied Sciences Regensburg (OTH).
One Master of Applied Research student at OTH has
chosen the topic to develop an open-source simulation
tool for electric vehicles  the EMOTH Library  based
on Modelica and to refine several aspects of the library
during the one and a half year of the master course.
After one semester, the basic version of the library is
available and will be presented in this paper.

Introduction

The City of Regensburg decided to purchase
E-buses to serve the old part of the town to decrease
emissions and noise pollution in this area visited by
many tourists per year. Moreover, the City of
Regensburg maintains an E-Mobility Cluster to provide
a platform for collaboration between local automotive
companies and educational institutions. One project of
this cluster is allowed to utilize one of the above
mentioned buses for field tests of newly developed
components, also offering the possibility to gather
measurement data during real driving cycles.
OTH Regensburg joined that cluster and plans to
provide an open-source simulation tool based on
Modelica to review new components of the electrical
drive train in an early stage of development:
the EMOTH-Library. This project also permits to
validate simulation results against measurements
during real driving cycles.
Of course there are several simulation tools for
electric vehicles available, also based on Modelica, but
we found only commercial available libraries. The
drawback of commercial tools is the invest hurdle for
the cluster partners and the fact that it might be not that

DOI
10.3384/ecp17132285

Structure and Components of the Library

Figure 1 Structure of the EMOTH Library

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

285

EMOTH The EMobility Library of OTH Regensburg

The wheels are taken as ideal wheels from
Modelica.Mechanics.Rotational, but can easily be
exchanged against more sophisticated models.
Since energy consumption is one of the most
important aspects of the planned investigations, a one
dimensional model of the mass and the rotating wheels
is implemented, taking only longitudinal acceleration
and velocity into account.

2.2 Brakes
In the first version, the brakes are built with the
brake model from Modelica.Mechanics.Rotational.
A simple controller distributes the brake signal to left
and right wheel at front and rear axle. Each brake
produces its own braking torque respectively force,
according to the parameterization which allows to
specify the braking force distribution between front
and rear axle.
Driver assistance functions like antiskid braking can
be implemented in a more sophisticated controller.
Figure 2 Components used in a complete model

Figure 1 depicts the structure of the EMOTH
Library, Figure 2 shows a complete model with all
components described in the following sections.

2.1 Chassis
The central component is the chassis (here a car
with 2 axles) containing:
 the mass of the car including passengers
 the four wheels with their inertia
 the driving resistances
 connectors of the four half axles
 measurements feeding relevant signals to
the bus
According to literature (e.g. [3], [4], [5]) the driving
resistances consist of:
 drag resistance according to (1), dependent
on relative speed of vehicle with respect to
surrounding air,
 rolling resistance dependent on sine of
inclination angle according to (2),
 inclination resistance according to (3)
dependent on cosine of inclination angle .

	
	
	
	
	
	
	

A		
 	
v	
v 	
	
	
	

286


	
	
	
	
	
	
	

2
cos
sin
coefficient of drag resistance
front	cross	section	of	vehicle	
density	of	air	
vehicle	speed	
longitudinal	wind	speed	
coefficient of rolling resistance	
total	vehicle	mass	
gravitational	constant	

(1)
(2)
(3)

2.3 Drive Line
The drive line model contains the gear box, either
with fixed ratio or with gear selection by the driver
environment, and a simple model of the differential.
2.4 Electric Drive
The electric drive represents the motor, the power
electronics and control. Since a correct parameterized
current controlled drive can be represented by a second
order block (see [6]), the desired torque is calculated
from the throttle signal (in the range 0...1), taking field
weakening into account. Throttle signal = 1 is
interpreted as maximum torque available at the actual
speed. Maximum torque depends on break-down
torque of the motor and maximum current of the power
electronics. The actual torque is fed to the motors
inertia and the flange, which is connected to the drive
line.
Taking losses respectively efficiency of the motor
and the power electronics into account, an ideal power
converter draws the corresponding current from the DC
power connection, taking actual DC voltage into
account.
This simplified generic drive model ensures a
maximum of simulation performance and can be easily
improved by using more sophisticated models of
motor, power electronics and control.
2.5 Energy Storage
In the first version, the battery is simplified as
constant DC voltage and an inner resistance. However,
the calculation of relevant signals  especially the state
of charge (SOC)  is already implemented. A more
sophisticated battery model, taking into account the
SOC  dependent no-load voltage and the transient
behavior of the batteries terminal voltage as an answer

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132285

Session 6: Poster Session

to non-constant DC currents, is planned to be
implemented in a following development phase.

2.6 Electrical Accessories
Electrical accessories, especially heating and
cooling, have significant impact on energy
consumption of an electric vehicle. In order to obtain
realistic simulation results for the batteries state of
charge, the power consumption of the accessories can
be defined either constant or by a signal input from
measurements over a real driving cycle.
2.7 Range Extender
Range extenders are common practice to increase
range without increasing the batteries capacity which
in turn means rising mass. In most cases they are a
small combustion engine driven at an optimal point of
operation, which drives an electric generator charging
the battery.
The implemented range extender allows to specify
constant charging power and state of charge limits for
switching the range extender on and off.
2.8 Track
The track model defines the inclination and the road
surface with respect to actual position of the vehicle
along the track, either given by a constant value or
interpolated from a table. The user has the choice how
to extrapolate the table data if the vehicles position
leaves the range of the table definition:
 Hold the first / last point
 Extrapolation using the last two points
 Periodic repetition
 Extrapolation triggers an error.
Periodic repetition allows to define a closed loop,
where the vehicle drives as many rounds as desired.
To be able to check the definition of inclination,
especially on a closed loop track, the calculation of
actual altitude is included. Longitudinal position and
velocity of the vehicle is defined along the inclined
track.
Additionally, longitudinal wind speed can be given
either as a constant or by an input signal from an
external table, containing measured data.
2.9 Driver Environment
The driver environment provides the signals that a
driver could read from a dashboard to the driver
interface. To have a maximum of flexibility, either a
throttle and brake model (section 2.10) or a driver
model (section 2.11) following the desired driving
cycle can be connected to the driver interface.
The throttle and brake commands read from the
driver interface are fed to the recuperation controller.
The recuperation controller decides upon active
braking using the electric drive and charging the
battery (recuperation), or using the mechanical brake
DOI
10.3384/ecp17132285

system, or to distribute desired braking force between
the two alternatives. The user can switch off
recuperation.
The first implementation of the recuperation strategy
is a very simple one:
 if recuperation is not switched off and
 if the batteries SOC is not above an upper
limit and
 vehicle speed is above a lower limit
throttle and brake command (torque demand < 0
means braking) are fed to the electric drive, otherwise
throttle signal is sent to the electric drive and brake
signal is sent to the mechanical brake system.

2.10 Throttle and Brake
To be able to perform simple experiments, a throttle
and brake block has been implemented. Like a human
driver, the user can command throttle and brake
separately. The commands can be given either by
constants or by signal inputs. Additionally, the user can
demand to move either forwards or backwards along
the defined track (section 2.8).
2.11 Driver
The driver model tries to mimic a human driver. A
human driver will watch the environment and the state
of the vehicle. The decision somehow is based on a
preview of the environment. To take that into account,
the driver reads from the driving cycle the reference
speed and a preview of the future reference speed. The
preview time can be chosen to define the drivers
behavior.
Based on his decision, the driver will make his mind
of accelerating or braking the vehicle, with some delay
representing the human response time. This is modeled
by a PI-controller, fed by the difference of preview
reference speed and a prediction of actual speed:

(4)
2.12 Driving Cycle
The driving cycle is defined with table data as
reference speed versus time. The user is able to define
his own driving cycle, or choose one of the following
predefined driving cycles:
 UDC urban driving cycle
 EUDC extra-urban driving cycle
 NEDC new European driving cycle
If simulation shall last longer than the time span
defined by the driving cycle, one of the following
choices can be taken:
 Hold the first / last point
 Extrapolation using the last two points
 Periodic repetition
 Extrapolation triggers an error.
The user can decide whether to terminate the
simulation after a specified number of repetitions of the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

287

EMOTH The EMobility Library of OTH Regensburg

driving cycle, or to drive until another termination
condition is met, e.g. empty battery (SOC below
minimum SOC).

2.13 Optional Thermal Connectors
All components have optional thermal connectors
that can be switched on or off with the Boolean
parameter includeHeatPort. In case includeHeatPort =
true, the user has to connect an external thermal model
representing the thermal behavior of the complete
vehicle. This allows to develop and investigate the
thermal management system.
Components with optional thermal connector:
 brake system
 drive line
 electric drive (motor and power electronics)
 battery (energy storage)
It has been decided that the chassis model has no
thermal connector because the energy to overcome
inclination resistance is converted rather to potential
energy than to thermal energy; energy consumption
due to drag resistance and rolling resistance is
dissipated to heat, but the heat is generated at the
exterior envelope of the vehicle and is most likely not
taken into account for thermal management.
However, the power consumptions of driving
resistances are fed as signals to the bus, allowing to
analyze the power sinks of the biggest influence on
energy consumption.
2.14 Bus Concept
According to the concept, all components
communicate via their own sub-bus. All sub-buses are
collected in the central control bus. This concept eases
the distribution of signals through the whole vehicle
architecture.
For the communication between the driver and the
driver environment, a separate bus called driver
interface is implemented.
2.15 Parameterization of the Models
As shown in Figure 1, the parameterization is
managed in a flexible way by records:
 vehicleData
 inclinationData and rollingResistanceData
 driveData
 batteryData
VehicleData not only contains vehicle parameters
like mass, front cross section, wheel radius and inertia,
but also the parameters of the driveline and the brakes.
InclinationData and rollingResistaneData define
inclination and rollingResistance with respect to the
position along the track. The user can give constant
values or a table definition.
DriveData summarizes the parameters of the motor,
the power electronics and the control.

288

BatteryData gathers the parameters of the energy
storage.
The modular concept allows to define independently
a track with inclination and road surface, a vehicle and
to try different designs of the drive and / or the battery.

3

Simulation Results

For testing the library components, the parameters
summarized in Table 1 have been estimated. The drive
parameters are shown in Table 2, the parameters of the
battery in Table 3.
Table 1. Vehicle parameters

Vehiclemass
Desired
acceleration/deceleration
Frontbrake:Rearbrakeforce
Frontcrosssection
Dragcoefficient
Wheelradius
Wheelinertia
Gearratio
Gearefficiency
Efficiencyofdifferential

1500
5



50: 50
2
0,5
0,3
0.25	 
1: 5
85 %
95 %

Table 2. Drive parameters

Basespeed
Nominaltorque
Efficiency
Breakdowntorque
Maximumtorque
Substitutetimeconstant
Inertia

4500 rpm
250 Nm
90 %
1000 Nm
500 Nm
5 ms
0.1 kg  m

Table 3. Battery parameters

NominalDCvoltage
Innerresistance
NominalCharge
MinimumSOC

400
50 
100 
0.1

For the first test, the rolling resistance coefficient
was set as
0.02 and inclination of the track was
set to 0. The electrical accessories have been estimated
with a constant power consumption of 5000	 , and a
range extender with a constant power generation of
6000	 . The range extender is started if SOC falls
below 40% and is stopped if SOC rises above 80%.
Recuperation is chosen for braking if SOC falls below
98%.
The driving cycle has been chosen to meet the
NEDC (New European Driving Cycle) shown in
Figure 3. Additionally, Figure 3 shows the actual
vehicle speed which proves that the vehicle can follow
the desired driving cycle nearly perfect.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132285

Session 6: Poster Session

Subsequently, the NEDC was repeated until the
battery was exhausted. Figure 6 shows that the range
extender gets started at 7021.3 s when SOC falls below
0.4, the battery is discharged slower than before.
In Figure 7 the vehicle position is depicted. It can be
seen that the battery is exhausted after 14096 s
reaching 131.25 km.

Figure 3 NEDC New European Driving Cycle

The DC power consumption during one cycle is
shown in Figure 4, the development of the state of
charge in Figure 5. Note that the range extender is not
yet started during that cycle since SOC is high enough.
Figure 6 SOC during repeated NEDC

Figure 4 DC power consumption during NEDC

Figure 7 Vehicle position during repeated NEDC

The third experiment investigates acceleration and
maximum speed with the chosen electric drive by
setting a reference speed rising from standstill to
in 1 s. Of course, the vehicle cannot follow
250	
this reference speed but requires maximum torque from
the drive. Figure 8 proves that a maximum speed of
can be achieved. Acceleration
slightly above 225	

Figure 5 SOC during NEDC

On a notebook with Intel Core i7 processor at
2.3 GHz, 8 GB RAM, Windows 7 64 bit, using
Dymola 2017 FD01 64 bit the simulation of the 1180 s
cycle took 6 s which shows pretty good performance.

DOI
10.3384/ecp17132285

takes approximately 6.8 s.
from standstill to 100	
Of course the drive may not be operated continuously
at maximum torque, a thermal protection function
would reduce throttle signal to avoid overheating of the
motor and the motor electronics.
Figure 9 reveals both limits of field weakening:
During the first phase, torque of the motor remains
constant, and DC power consumption rises linearly
with speed. After exceeding the first limit, DC power
consumption remains constant with respect to speed as
torque is lowered reciprocal to speed. When the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

289

EMOTH The EMobility Library of OTH Regensburg

reference torque exceeds breakdown torque of the
motor dependent on speed, torque has to be reduced
more than reciprocal to speed and DC power
consumption is reduced, too.
Of course driving with maximum torque
respectively maximum power, Figure 10 confirms that
the battery gets discharged much quicker than in the
previous example.

Figure 8 Maximum acceleration and maximum speed

4

Conclusions and Outlook

During the first semester of the three semester
Master of Applied Research course the EMOTH
Library based on the Modelica Vehicle Interfaces
Library has been developed. The library shall provide a
flexible framework for longitudinal simulations of
electric vehicles to investigate energy consumption
during a defined driving cycle including accessories
and range extenders as well as the ability of the vehicle
to follow the desired driving cycle with prescribed
acceleration and deceleration.
For the project members of the E-Mobility Cluster
Regensburg it is possible to test new components in an
early design stage in the context of the full vehicle.
Up to now, full vehicle models based on the
components of the library with estimated but realistic
vehicle parameters have been tested successfully with
Dymola 2017 FD01. Since the library is conformant to
the Modelica Language Specification, it should be
possible to run the examples in other Modelica tools,
too. In a first test using OpenModelica 1.11 beta 3 the
model translates but during simulation errors occur
which have to be investigated.
During the following two semesters it is planned to
gather the necessary parameters of both the E-bus
EMIL of Regensburg as well as the E-Smart
designed by the Faculty of Electrical Engineering and
Information Technology of OTH Regensburg. With
these parameters, the results of simulations following
real driving cycles shall be validated against
measurements. Furthermore, several components of the
library shall be refined and improved, such as the
electric drive and the battery / energy storage.
It is planned to make the library public available
under the Modelica License 2.

References
Figure 9 Maximum DC power

[1] VehicleInterfaces on the Modelica website:
https://www.modelica.org/libraries
(visited 2017-01-21)
[2] Michael Tiller, Paul Bowles, Mike Dempsey:
Development of a Vehicle Modeling Architecture
in Modelica, 3rd International Modelica Conference
2003, Linkping.
[3] D.Schramm, M.Hiller and R.Bardini:
Modellbildung und Simulation der Dynamik von
Kraftfahrzeugen, Springer 2013.
[4] M.Mitschke and H.Wallentowitz, Dynamik der
Kraftfahrzeuge, Springer 2014.
[5] S.Breuer and A.Rhrbach-Kerl, Mechanik des
bewegten Fahrzeuges, Springer-Vieweg 2015
[6] D.Schrder, Elektrische Antriebe: Regelung von
Antriebssystemen, Springer 2009.

Figure 10 SOC at maximum torque / power

290

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132285

Simulating a Variable-structure Model of an Electric Vehicle for
Battery Life Estimation Using Modelica/Dymola and Python
Moritz Stber1
1 University

of Applied Sciences Vorarlberg, Austria

a so-called variable-structure model (VSM). Simulating a
VSM is potentially faster and/or more accurate than a conA variable-structure model (VSM) of a battery electric ve- ventional simulation, but VSMs are not yet supported by
hicle used for simulating the ageing of the battery pack is commonly used modeling languages and simulation envipresented. The operating principle of the software used to ronments.
simulate the models is described and a brief summary of
In this paper, the results of investigating the question
the state of science and technology regarding the simulation of VSMs is given. By comparing the performance of Does the simulation time of the ageing process of a batthe VSM to a conventional model, it is found that the sim- tery used in electric vehicles decrease if the system is
ulation time does not necessarily decrease when replacing systematically modeled as a variable-structure model?
a model with a variable-structure version. However, the (Stber 2016) are presented.
VSM has advantages regarding the handling of the result
In order to answer this question, four steps were taken.
files and the possibility to analyse the results.
First, a conventional model capable of estimating the batKeywords: Variable-structure Model, VSM, Modelica, tery life of a BEV was assembled using Modelica/Dymola.
Then, a variable-structure version of this model was imDymola, Simulation
plemented and a software capable of simulating the VSM
using Dymolas Python interface was written. Last, a se1 Introduction
ries of simulations was performed in order to investigate
In recent years, the use of electrified or electric power the influence of the model and solver settings on the time
trains in passenger cars has gained renewed research in- needed to execute the simulation.
terest. However, most currently available battery electric
In the next section, a brief introduction to the modeling
vehicles (BEVs) have a rather low driving range caused
and simulation of variable-structure models is given.
by the low energy density of the battery pack in comparison to conventional fuel. The battery pack is not only the
single most expensive part of the BEV, but also subject to 2 Variable-structure Models
significant degradation. Consequently, car manufacturers
In the context of modeling and simulation, variablehave to simulate the state of health (SOH) of the battery
structure models are models that consist of several sets
for two main reasons: on the one hand, it has to be made
of equations describing the same physical system. Each
sure that a vehicle still meets the requirements when the
set of equations is called a mode of the model; exactly
battery has aged. On the other hand, it is necessary to estione mode is active at all times during the simulation. The
mate possible warranty costs caused by battery packs that
changes between the modes are denoted transitions. For
reach the end of their life ahead of time.
each mode, the transitions define which mode becomes acWith age, the capacity of the battery decreases and
tive next, the condition ci for changing and information i j
the impedance increases. Since this affects the electrical
on how to initialize the next mode (Mehlhase 2015, chapquantities within the vehicle, there should be no separater 3.2)compare Figure 1.
tion between the model used for simulating the driving behaviour and the ageing model. Instead, the model should
cB2  iC1
cA  iB
combine electric, mechanical and thermal models and thus
be capable of calculating feedback effects. Due to the fact
cB3  iC2
that the battery life has to be simulated for 8 to 15 years,
init
B
C
A
simulating this complex model takes a substantial amount
of time. Therefore, a speed-up of the simulation is desiriA  cB1
able.
Vehicles are idle for the majority of their life. During
Figure 1. Graphical representation of a VSM with three modes
this time, the complexity of the model used for simula- A, B and C
tion can be much lower than during driving. Implementing this change in the level of detail of the model leads to

Abstract

DOI
10.3384/ecp17132291

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

291

Simulating a Variable-structure Model of an Electric Vehicle for Battery Life Estimation Using
Modelica/Dymola and Python

As the name suggests, variable-structure models exhibit
varying structural properties, which can either refer to the
properties of a real system or to the properties of the system of equations used to mathematically describe it.
In variable-structure systems (VSSs), the change in
structure is a property of the physical system. Failure
situations like breaking mechanical or electrical connections or so-called agent-based systems represent examples
of VSSs.
On the other hand, in variable-structure models
(VSMs), the change in structure is a result of abstraction;
in other words the result of creating a model of a system.
For example, if detailed information about the switching
process is not relevant for an experiment, ideal switches
are used. Since ideal switches can attach or detach whole
parts of a model, a change in the structure of the underlying set of equations occurs: variables and relations can
change and the system of equations can grow or shrink in
size.
Variable-structure models can be used to implement
changes in the behaviour or the required level of detail of the system under investigation. Components can
be added and removed during the simulation. This is
necessary for simulating agent-based systems or changing the discretization of a model by changing the number of identical components; as well as for implementing
ideal switches, breaking connections or limiters, leading
to the dynamic addition or removal of parts of the model
(Mehlhase 2015, chapter 4; Zimmer 2010, chapter 1.2).
Furthermore, changing the solver and the solver settings
during a simulation is possible when simulating VSMs.
Despite the multitude of use cases for VSMs, only very
few simulation environments support their definition and
execution. According to Zimmer (2010, chapter 1.3),
there are two main reasons for this: first, current modeling
languages lack the expressiveness required to accurately
define the structural variability. Second, it is technically
very challenging to simulate the resulting models.
Three different concepts have been developed for implementing a simulation engine that can handle variablestructure models: maximal state-space, hybrid decomposition and dynamic causalization.

dynamic causalization. Here, the model is recausalized if necessary, which is impossible when
using the usual translationcompilationexecution
sequence.
Because structural changes always cause events and
VSMs thus represent a generalization of hybrid models,
modeling languages that support them need to provide a
generalized way to define events in order to achieve the
required expressiveness.
The most recent, Modelica-based1 attempts to implement a modeling language and a corresponding simulation
environment that support the simulation of VSMs are Sol,
DySMo and MoVasE as well as an unreleased prototype
of Dymola.
Sol Sol (Zimmer 2010) is an experimental language
which is intended to serve as a proof of concept for
simulating variable-structure models using dynamic
causalization. Conditional index changes as well as
the local definition of modes within components are
supported. Sol therefore allows the modeling and
simulation of almost arbitrary structural changes
in a truly object-oriented manner (Zimmer 2013),
but the proposed language constructs and simulation
techniques have not been integrated into commonly
used languages and tools yet.
Dymola Elmqvist, Mattsson, and Otter (2014) presented
an approach to simulate VSMs in Dymola. It represents an extension to the capabilities of the synchronous state machines defined in Modelica 3.3 and
was implemented in a prototype version of Dymola
2015. Instead of defining additional language elements, the semantics of the existing language was
extended.
Using this approach, a large, but limited class of
VSMs could be simulated. Because it is not necessary to process the model definition using an interpreter, like in Sol, the simulation is significantly
faster. However, variable-structure models with
varying index could not be simulated. This possibility was added later by extending the Pantelides algorithm (Mattsson, Otter, and Elmqvist 2015), but it
has not been added to the official version of Dymola
yet.

 In a maximal state-space, state events switch on and
off algebraic conditions, which freeze certain states
for certain periods (Breitenecker 2008, page 9). The
maximal state-space-model is static and can there- DySMo (Dynamic Structure Modeling) is a Python
application that allows the simulation of VSMs
fore be simulated using conventional tools.
(Mehlhase 2015, chapter 7). Each mode is repre In contrast, when using the hybrid decompositionsented by an executable model with static structure
approach, the VSM is split into its modes, which
that terminates if the condition for a transition is trighave a static structure and can be executed sequengered. Upon termination, a variable is set that defines
tially. The order of execution is controlled at a met1 Tools that support VSMs to a certain degree, but rely on different
alevel, either within the simulation environment or
modeling concepts have been developed outside the context of simuexternally.
lating physical systems, for example Hydra (functional programming),
 The most flexible, but also the most challenging
approach from a technical point of view, is called
292

JAMES (systems biology) and A NYLOGIC (large-scale agent-based systems). They are not suited for simulating the BEV model and thus not
considered further.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132291

Session 6: Poster Session

the cause for the transition. DySMo then reads and
So far, no attempt to use a VSM of a BEV for estimating
stores the results, initializes the next mode depending its battery life has been published. In the next section, the
on the cause for the transition and starts the next sim- models used by the author are described, followed by a deulation. All modes and transitions have to be main- scription of the observed advantages and disadvantages.
tained manually.
MoVasE Esperon, Mehlhase, and Karbe (2015) propose
a methodology to append structural changes to existing models by externally defining conditional component exchanges. The tool MoVasE (Modelica
Variable-structure Editor) implements the proposed
solution. The aim of MoVasE is to provide a platform
for facilitating the investigation of VSM-design. In
contrast to DySMo, MoVasE does not require the
user to create and maintain all modes manually. By
defining the structural variability through conditional
component exchanges, many modes can be created
and maintained. However, the flexibility of this approach is still limited with regard to the dynamic addition and removal of components.
In conclusion, the approaches taken by Sol and Dymola
solve the most important technical problems, but they have
not been integrated into standard languages and tools yet.
Therefore, script-based approaches (DySMo, MoVasE)
are necessary for studying the benefits and drawbacks of
using variable-structure models.
Three levels of complexity can be distinguished when
creating VSMs: in the simplest case, the modes are defined on the highest level of the model, as shown in Figure 1. Second, individual components of the model can
exhibit modes. In the most complex case, the modes are a
result of the addition and removal of components, like in
agent-based systems.
From the point of view of the simulation engine, a
variable-structure model always consists of modes defined
at the highest level of the model, which is called the factorized version of a VSM (Mehlhase 2015, chapter 5.1.2).
Depending on the tool used for simulation, it might be
necessary to manually create the factorized version of the
VSM. Additionally, it has to be made sure that the VSM
is valid. This includes avoiding chattering or unphysical transitions and unphysical factorized modes. A set
of guidelines that is intended to help with the creation of
valid VSMs was formulated by Mehlhase, Esperon, and
Karbe (2015).

3

Implementation

In order to assess the usefulness of using a VSM of a
BEV for battery life estimation, both a conventional and
a variable-structure model were assembled and simulated.
Implementing the components used for assembling the
models was not part of this work; they are part of the
commercial Electrified Powertrains Library and the Battery Library developed by Dassault Systmes2 .
The conventional model consists of nine main components: the driving cycle, the driver model, a control unit,
the models of the energy supply, the electric power train,
the auxiliary loads, the chassis and the environment, as
well as the charger model. In contrast, the VSM has two
global modes that reflect the operating modes of the vehicle (Figure 2). The model that represents the driving
mode does not contain the charger and its control logic,
while the model that represents the idle mode only contains the battery model, the charger model and the environment model.
The inputs of both models are the desired speed of the
vehicle, the time frames the charger is plugged in, and the
ambient temperature over time. The VSM additionally has
a schedule for switching between modes based on the driving behaviour. All inputs are loaded from externally stored
files which are generated using a script. The script allows
the convenient definition of usage scenarios and ensures
that the resulting profiles are consistent.
The system of differential algebraic equations (DAEs)
of mode idle has 915 scalar unknowns and equations
and 25 continuous time states. Mode driving consists
of 3062 scalar unknowns and equations and has 29 continuous time states; the conventional model of the BEV
has 3219 scalar unknowns and equations and 38 continuous time states. Since the system of ordinary differential
equations (ODEs) that needs to be integrated differs only
slightly, it can be expected that the speed-up is small, but
noticeable. It would be straightforward to use more complex models of the power train during driving because a
template is used that allows the simple exchange of models. This would likely increase the performance gain of the
VSM compared to a conventional model, but also increase
the overall simulation time in both cases.
The VSM is simulated using a software written in
Python that allows the definition and simulation of VSMs
with globally defined modes using Modelica and Dymola.
The software is comparable to DySMo and described in
section 6.

In addition to many small examples that were used
to verify a certain language/tool (Zimmer 2010, chapter 11; Mehlhase 2015, chapter 8), several examples
of the successful application of variable-structure models for solving real-world problems have been published
(Krger, Mehlhase, and Schmitz 2012; Mehlhase, Esperon, Bergmann, et al. 2014; Mckel, Mehlhase, and
Nytsch-Geusen 2015). In these examples, a significant reduction of the overall time needed to simulate the system
2 http://org-www.3ds.com/products-services/
could be achieved due to a big difference in the complexity
of the modes and a low number ( 40) of mode switches. catia/products/dymola/industry-solutions/
DOI
10.3384/ecp17132291

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

293

Simulating a Variable-structure Model of an Electric Vehicle for Battery Life Estimation Using
Modelica/Dymola and Python

1
Driving

Idle

0

2

100
50
0
1
0.8
0.6
0.4
0.2
0

450

V pack / V

150

0

1

2

3

4

5

0

1

2

3

4

5

400
350

6

I pack / A

SOC / 1

Velocity / km h1

Figure 2. Variable-structure model of the BEV

6

0

1

2

0

1

2

3

4

5

6

3

4

5

6

0
100
200

Time / h

Time / h

Figure 3. Selected results of the experiment used for model validation

first scenario, the battery is always charged fully, whereas
in the second profile, the SOC only varies from approxiThe parameters of the models were chosen with the inten- mately 60 % to 40 %.
tion to reflect typical values for BEVs. The models were
checked for plausibility by simulating a short driving cy150
cle followed by charging. The driving phase starts after
15 min standstill and takes approximately 70 min. During
100
this time, a distance of 103 km is covered and the battery is
discharged from 90 % state of charge (SOC) to 10 % SOC,
50
which corresponds to a total consumed energy of approximately 16.2 kW h. About half an hour after the driving
0
cycle is completed (at t = 2 h), the charger is plugged in.
0
1
2
3
4
7
5
6
In Figure 3, selected results of the simulation can be seen.
Time / days
There is no noticeable difference between the results of
the conventional simulation and the results of the VSM.
Figure 4. Demanding usage scenario: desired velocity. When
Knowing that the models are properly parameterized, using this driving cycle, 658 km are driven per week; the yearly
a simulation of the SOH spanning several years could be mileage amounts to 34 238 km.
performed. Two usage profiles were created, which are
shown in Figure 4 and Figure 5. Both span a week and
The higher usage and the storage at higher SOC should
are used repeatedly if longer scenarios are needed. In the result in faster ageing of the battery in the first scenario.

Simulation Results

Velocity / km h1

4

294

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132291

Session 6: Poster Session

150
CPUtime / s

Velocity / km h1

150
100
50
0
0

1

2

3

4

5

6

100
50
0

7

conventional model
variable-structure model
0

2

4

6

8

10

12

14

Time / days

Time / days

Figure 7. CPU time; dense output enabled

Figure 5. Relaxed usage scenario: desired velocity. When using this driving cycle, 289 km are driven per week; the yearly
mileage amounts to 15 040 km.
CPUtime / s

150

The simulation results are shown in Figure 6.

SOH / 1

1

Relaxed; Ref.
Relaxed; VSM
Demanding; Ref.
Demanding; VSM

0.95

100
50
0

conventional model
variable-structure model
0

2

4

6

8

10

12

14

Time / days

0.9

Figure 8. CPU time; dense output disabled
0.85
0

2

4

6

8

10

12

Time / years

Figure 6. State of health of the battery

For the assessment of the batterys ageing behaviour,
the models were simulated until the SOH falls below 0.85.
This value was chosen because a compromise between the
time needed for simulation and the length of the calculated
trajectory had to be found and a SOH of 0.15 is regarded
meaningful. Moreover, in this case, more data does not
mean more information because all input and model parameters are estimated values anyway.
There is no significant difference between the result of
the conventional model and the VSM: the relative error is
in the range of 0.02 %.

5

Advantages and Disadvantages of
the Variable-structure Model

In Figure 7 and Figure 8, the elapsed CPU time during a
2-week simulation of the BEV model using the relaxed
driving cycle (Figure 5) is shown. The CPU time comprises the time needed for initializing the system(s) of
equations and the time needed for integration. The same
solver settings are used for both the conventional and the
variable-structure model.
In both figures, the difference between driving and
standing can be seen clearly due to the step wise increase
of the elapsed time resembling a staircase. This is the result of using a solver with variable step size: during driving, only a small step size can be used due to the dynamic
DOI
10.3384/ecp17132291

changes of the state variables. In contrast, the step size
can be greatly increased when the vehicle is idle.
There is a significant difference in the elapsed time depending on whether dense output is enabled or not. If
dense output is enabled, the conventional model takes
longer to calculate, depending on the size of the output
interval. The effect is especially noticeable during the idle
phases because during this phase, the necessary step size
calculated by the step size control algorithm is usually bigger than the desired output interval.
However, when dense output is disabled, the conventional simulation becomes faster than the variablestructure model. A reason for this is that each system of
equations (mode) needs to be initialized.
In Figure 9, a more detailed account of how much time
is spent on which part of the simulation is given. On the
right hand side, two pie charts visualize the data listed
in the table on the left. The area of the pie charts corresponds to the total duration of the simulation, whereas
the slices denote the time spent on the initialization of the
systems of equations, the integration itself and the postprocessing of the data. Additionally, time is needed for
writing the result files and consumed by the operating
system for other processes. There is a striking difference between the conventional and the variable-structure
model: in the former, the integration takes 99.9 % of the
time, but only 52.2 % of the time needed for simulating
the latter is actually spent on the integration. Therefore,
the VSM takes longer to simulate, even though the integration finishes 0.5 h earlier. A large, unnecessary part
of the overhead is caused by Dymolas Python interface:
since the simulateExtendedModel()-command only

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

295

Simulating a Variable-structure Model of an Electric Vehicle for Battery Life Estimation Using
Modelica/Dymola and Python
1.0 h

Task
Initial Compilation
Initialization
Integration
Recompilation
Reading .mat-files
Post-processing
Total Duration

Reference

VSM

4.5 s
1.3 s
7.7 h

 0.0 s
 0.0 s

7.4 s
1.0 h
7.2 h
5.6 h
19.3 s
1.2 h

7.7 h

7.7 h

1.2 h

5.6 h

7.2 h

15.1 h
Initialization
Integration

Recompilation
Post-processing

Figure 9. Comparison reference modelVSM: time measurements for a simulation of the demanding scenario for 3 years. In the
variable-structure model, 5304 mode switches were performed.

supports passing real numbers for initialization, modifiers
have to be used for passing the necessary vectors and attributes. This causes a recompilation of the model at each
mode switch. By finding a workaround for this, the overall
simulation time of the VSM could be reduced drastically.
A further reduction could be achieved by improving the
implementation of post-processing.
When working with VSMs, besides the restriction to
use the same model for all phases, also the restrictions
to use the same settings and result files for all phases no
longer exist. Therefore, the question Does it make sense
to use a variable-structure model of a BEV for estimating
its battery life? may still be answered with yes, even if
the time needed to calculate the output trajectory does not
decrease very much.
One problem that arises when estimating the battery life
using a full vehicle model is the size of the result file,
which depends on the settings for dense output and the
length of the simulation. In order to limit the amount of
data stored in the result file, the output interval needs to be
set to a constant, high value (for example 24 h when simulating 15 years). Additionally, it is necessary to select the
set of variables that has to be stored in advance, for example by using Dymolas __Dymola_selections-annotation. This means that all detailed information calculated
during the course of the simulation is irretrievably lost and
not available for analysis. When simulating a VSM, this
problem is much less likely to occur as every mode has
its own result file and the individual simulation times are
much shorter3 . Moreover, it is possible to store the results
in a high resolution when the vehicle is driving and in a
low resolution otherwise. Therefore, it becomes possible
to perform a detailed analysis of the driving behaviour at
the end of the batterys life.

6

PyVSM

In this section, the software used for implementing and
simulating the VSM of the BEV is described. It is
called PyVSM and supports the simulation of factorized
variable-structure models using Dymolas Python interface. PyVSM is intellectual property of Dassault Systmes Deutschland GmbH.
The basic idea of PyVSM is to use Dymola for simulating the modes and Python for switching between them.
Therefore, it is required that each mode of the factorized
VSM is a complete Modelica model that can be simulated
using Dymola. Modes, transitions and solver settings of
the VSM are defined using JSON-files. When a condition of a transition becomes true, the simulation of the currently active mode terminates and the initialization of the
next mode is initiated by PyVSM based on the results of
the previous mode.

In Figure 10, the processing steps taken to simulate a
VSM in PyVSM are shown in more detail. First, the
JSON-file used for the definition of the VSM is read.
Then, for each mode, a directory used during simulation is
created and the Dymola-interface is instantiated with the
working directory set to the previously created folder. The
actual simulation of the VSM starts by executing the initial
transition in order to set the initial values for the simulation. The active mode is set according to the definition of
the transition and the simulation is started. Upon termination, the relevant results are loaded to PyVSM, including the variable transitionID. Its value corresponds to
the numerical identifier of the transition that has to be executed next. If and only if it is 0, the end of the simulation is
reached. After this, the individual results of each mode are
concatenated and post-processed. This includes the calculation of characteristic values such as the time needed for
initialization or the step size and the resampling of the data
3 Strictly speaking, the memory limitations could also be avoided by
implementing the possibility to split up result files when performing a to the specified interval length. Last, the post-processed
conventional simulation in Dymola.
data is saved and plots are generated if desired.
296

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132291

Session 6: Poster Session

Load JSON files

Prepare directories
Open Dymola instances

Execute transition

Simulate active mode
Load results
transitionID 6= 0
transitionID = 0
Post-process data

is found that while the CPU time needed for integration decreases, thus matching the expectations, the overall
simulation time increases due to overhead generated by
switching between models. This is caused by the properties of the model on the one hand (low difference in the
complexity of the modes, many (> 5300) mode switches)
and the implementation of the software used for simulation on the other hand. The overhead comprises the excess time needed for compiling, initializing the systems
of equations, reading the result files and post-processing
them as well as the unnecessary recompilation of the
modes at all transitions. Nonetheless, the VSM allows
a more detailed analysis of the simulation result due to
memory limitations occurring when using a conventional
model.

Acknowledgements
This work was supervised by Markus Andres, who contributed by discussing results and giving helpful advice on
plans for further work. Marco Keler and Markus Andres
proofread the manuscript. Further help regarding the used
battery models and the experiment set-up was provided by
Lukas Rohr. The project was carried out during a paid internship at Dassault Systmes Deutschland GmbH.

References
Export data
Generate plots

Figure 10. UML-activity diagram of PyVSM

PyVSM is implemented in Python using objectoriented programming techniques. It is capable of simulating factorized variable-structure models using Modelica/Dymola, but, being a prototype, misses advanced features such as automatic validity checks of the input files
or a graphical user interface. Additionally, externally controlling the simulation via Dymolas Python interface generates an overhead. Nonetheless, PyVSM provides modelers with the possibility to simulate models that would be
difficult or even impossible to implement in a conventional
simulation environment in a straightforward manner.

7

Conclusion

A variable-structure model (VSM) of a BEV was implemented with the aim of making the simulation of the battery ageing faster by switching between a complex model
used when the vehicle is driving and a simpler model used
when the vehicle is idle. Since VSMs are not yet supported by Modelica/Dymola, a software had to be written
that provides means to define the structural variability and
performs the mode switches.
When simulating the variable-structure BEV model, it
DOI
10.3384/ecp17132291

Breitenecker, Felix (2008). Development of Simulation
Software  from Simple ODE Modelling to Structural
Dynamic Systems. In: Proceedings of the 22nd European Conference on Modelling and Simulation (ECMS
2008). DOI: 10.7148/2008-0005-0022.
Elmqvist, Hilding, Sven Erik Mattsson, and Martin
Otter (2014). Modelica extensions for Multi-Mode
DAE systems. In: Proceedings of the 10th International Modelica Conference. DOI: 10 . 3384 /
ecp14096183.
Esperon, Daniel Gomez, Alexandra Mehlhase, and
Thomas Karbe (2015). Appending Variable-structure
to Modelica Models (WIP). In: Proceedings of the
Conference on Summer Computer Simulation. SummerSim 15. Chicago, Illinois: Society for Computer
Simulation International.
Krger, Imke, Alexandra Mehlhase, and Gerhard Schmitz
(2012). Variable Structure Modeling for Vehicle Refrigeration Applications. In: Proceedings of the 9th
International Modelica Conference. DOI: 10.3384/
ecp12076927.
Mattsson, Sven Erik, Martin Otter, and Hilding Elmqvist
(2015). Multi-Mode DAE Systems with Varying Index. In: Proceedings of the 11th International Modelica Conference. DOI: 10.3384/ecp1511889.
Mehlhase, Alexandra (2015). Konzepte fr die Modellierung und Simulation strukturvariabler Modelle.
PhD thesis. Technische Universitt Berlin, Fakultt IV
 Elektrotechnik und Informatik. DOI: 10 . 14279 /
depositonce-4514.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

297

Simulating a Variable-structure Model of an Electric Vehicle for Battery Life Estimation Using
Modelica/Dymola and Python

Mehlhase, Alexandra, Daniel Gomez Esperon, Julien
Bergmann, et al. (2014). An example of beneficial
use of variable-structure modeling to enhance an existing rocket model. In: Proceedings of the 10th International Modelica Conference. DOI: 10 . 3384 /
ECP14096707.
Mehlhase, Alexandra, Daniel Gomez Esperon, and
Thomas Karbe (2015). Challenges when Creating Variable-structure Models. In: Proceedings
of the 5th International Conference on Simulation and Modeling Methodologies, Technologies
and Applications, pp. 101110. DOI: 10 . 5220 /
0005521601010110.
Mckel, Jens, Alexandra Mehlhase, and Christoph
Nytsch-Geusen (2015). Exploiting Variable-structure
Models in the Context of Building Simulations within
Modelica. In: Proceedings of BS2015. International
Building Performance Simulation Association. URL:
https : / / www . researchgate . net /
publication/301229350.
Stber, Moritz (2016). Simulating a Variable-structure
Model of an Electric Vehicle for Battery Life Estimation Using Modelica/Dymola and Python. Masters
Thesis. University of Applied Sciences Vorarlberg.
Zimmer, Dirk (2010). Equation-Based Modeling of
Variable-Structure Systems. PhD thesis. Swiss Federal Institute of Technology, Zrich. DOI: 10.3929/
ethz-a-006053740.
 (2013). A new framework for the simulation of
equation-based models with variable structure. In:
SIMULATION 89.8, pp. 935963. DOI: 10 . 1177 /
0037549713484077.

298

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132291

Model Reduction Techniques Applied to a Physical Vehicle
Model for HiL Testing
R. Gillot*

S. Gallagher**

A. Picarelli* M. Dempsey*

*Claytex Services Ltd. Edmund House, Rugby Road, Leamington Spa, CV32 6EL
{romain.gillot, alessandro.picarelli, mike.dempsey} @claytex.com

**Ford Motor Company Ltd, Dunton Technical Centre, SS15 6EE
sgalla20@ford.com

the behaviour of the full model. The idea is to have two
different models for two applications: the fully detailed

Abstract
To build a full vehicle model entirely based on physical
equations is a challenge (Dempsey M., 2006). To have
this model to run fast enough so that it is suitable for
Hardware-in-the-Loop testing is even more challenging.
The level of detail in the physical representation of the
vehicle can always be increased at the cost of simulation
time. Even if the performance of the hardware is
constantly improving, we still have to compromise.
As part of the MORSE (MOdel based Real-time
Systems Engineering) project, model reduction
techniques are developed and applied to a vehicle
model. The results in terms of accuracy and simulation
speed are then investigated.
Keywords: vehicle model, model reduction, real-time
simulation, Hardware-in-the-Loop testing

model for SiL testing and a reduced version,
automatically generated and parameterized from the
first one in order to match its results, for HiL testing. In
this paper, we present the full vehicle model and its
associated level of detail. Then we introduce the model
reduction techniques and show how they are applied to
each subsystem. The subsystems and their reduced
equivalents are tested and the results compared. Finally
the full vehicle model as well as the reduced vehicle
model are run over a series of Tip-In/Tip-Out
manoeuvres in the HiL environment and the trade-off
between accuracy and simulation performance is
investigated.

2. The Vehicle Model
Brakes

1. Introduction
MORSE
(MOdel
based
Real-time
Systems
Engineering) is a 2-year project in collaboration with
Ford and AVL, co-funded through InnovateUKs
Towards Zero Prototyping competition. The aim of the
project is to develop predictive engine and vehicle
models enabling virtual calibration of driveability
control features and validation of On Board Diagnostics
(OBD) fault paths. In order to satisfy these
requirements, we need physical models with a high level
of detail. We need, for example, a clutch with a detailed
friction model, a gear set with torque reactions, a
differential with force and torque reactions, compliant
drive shafts, Pacejka tyre model, linear engine mounts,
detailed suspensions, a crank angle resolved engine
model. We use these models for Software-in-the-Loop
(SiL) and Hardware-in-the-Loop (HiL) testing. Whilst
simulation time is not a major concern for SiL, the
models do have to run in real time and with no overruns
to be used in the HiL environment. This is why we need
model reduction techniques that will help us simplify
our models to improve simulation speed while matching

DOI
10.3384/ecp17132299

Transmission
Engine
Suspensions

Mounts

Driveline

Figure 1. Detailed view of the vehicle model with all the
subsystems.

In order to perform the driveability analysis, a certain
level of detail is required in the vehicle model.
We require a mounts model using linear springs and
dampers to constrain the motion in the three directions
(x, y, z) as well as a transmission model with a clutch
based on coulomb friction with a reliable handling of the
stuck phase and a gear set that models the gears, gear

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

299

Model Reduction Techniques Applied to a Physical Vehicle Model for HiL Testing

meshes and mesh losses and takes into account the
torque reactions.
In the driveline, the drive shafts need to be compliant
and to include backlash. The differential, in the same
manner as the gear set, models the gear contact and
considers the torque reactions.
The suspensions have a vertical degree of freedom (foreaft motion can be included) and use a linear spring and
damper (other spring and damper models are available
if required).
Another critical component in driveability studies is the
modelling of tyres; our models thus utilize the Pacejka
slip model since it is the most commonly used model to
investigate tyre dynamics.
The engine is not studied in this paper and sits outside
of the vehicle model, a torque source coupled to a
flywheel are used to transmit the torque from the engine
to the transmission.

3. Model Reduction
a. Transmission
The physical gear set (Figure 2) is a multibody model
(Dempsey M., 2009) that uses physical representations
of gears, shafts, bearings and synchronizers. Gear
engagement is achieved through translational mechanics
flanges (in green in the Figure 2) providing a clamp load
to the left or right flanges on the synchronizer dependant
on the sign of the clamp force.

1
2

4

3

Figure 3. Gear set test rig (1: Shift mechanism, 2: Speed
source, 3: Gear set, 4: Load).

The function then extends the reduced gear set model
from the PTDynamics library (Figure 4) and populates
the lumped losses component with the data records we
just created. This lumped losses component interpolates
the tables in the data records to give the losses
depending on gear, speed and load.
The inertia of the whole physical gear set for each gear
is also calculated. The reduced gear set has a lumped
inertia component that will be populated with the data
we just derived.

1

2

3
3

1

4

5

Figure 2. Physical gear set model (1: Translational flange,
2: Bearing, 3: Gear, 4: Shaft, 5: Synchronizer).

This is how the model reduction tool works internally:
The physical gear set is run on a test rig (Figure 3) in 1st
gear. The speed source ramps up from 0 to 6000 rpm. A
load is attached to the gear set. The experiment is
repeated several times, varying the load each time (from
30 to 360 N.m). The transmission is thus run over a
range of speeds and loads.
This procedure is repeated for all the remaining gears.
We now have a loss map for the transmission for all the
operating points. This data is stored in a set of data
records (one for each gear) through an automated
procedure.

300

4
5

2

Figure 4. Reduced gear set model (1: Input shaft lumped
inertia, 2: Clutch, 3: Lumped losses, 4: Ideal variator, 5:
Output shaft lumped inertia).

The gear ratio is applied using an ideal variator which
means there is a first order transfer function between the
ratio input and the applied ratio. A clutch (item no. 2 in
the Figure 4) is used in this model since the ideal variator
does not give good results when in neutral.
 =   
0 =    + 
Where  is the angular velocity at flange_a (input
flange),  is the torque at flange_a and ratio is the gear
ratio. When in neutral gear, the equations become:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132299

Session 6: Poster Session

 = 0
0 = 
The first equation forces the angular velocity at the input
flange of the gear set to be zero and as a consequence
the angular velocity of all the components rigidly
connected to it, including the engine, to also be zero.
The clutch in this gear set is always engaged except in
neutral. The equation in the variator sets the angular
velocity at the output flange of the clutch to zero but the
input flange is free to rotate as the clutch is disengaged.

The results of the reduced model match very well those
of the full gear set, there is only a small discrepancy at
around 3s. This is because in the table of lumped losses
that we got using the function, the torque ranges only up
to 350 N.m. The torque being outside of this range at the
beginning of the test, Dymola has to extrapolate from
the table of losses which leads to a small inaccuracy.
The torque range will be extended in future work.
Reduced gear set Input speed (rad/s)

Gear set Input speed (rad/s)

200
160

Let us run a fully detailed 6-speed gear set and its
reduced version we derived using the model reduction
function and compare the results. To do so, we run the
models in all the gears, feeding in a torque of 80 N.m
(see Figure 5).

120

80
40
0

0

Torque Input (N.m)

Gear number

80

7

120

6

100

5

80

4

60

3

40

2

20

1

0

0

-20

60

40

20

0

10

20

Reduced gear set Output speed (rad/s)

0

10

20

30

40

Gear set Ouput speed (rad/s)

30

40

-1

0

10

20

30

40

Figure 5. Test rig gear and torque inputs.

We can now have a look at the torque at the input and
output of the two gear sets with different levels of detail:
Reduced gear set Input torque (N.m)

Gear set Input torque (N.m)

200
150
100

Figure 7. Input and output shaft speed of a 6-speed gear
set and its reduced equivalent.

The speed curves match well too. The speed of the
reduced gear set is slightly overestimated though. This
comes from the inaccuracy in the torque curve at the
beginning of the simulation (see Figure 6) which
therefore calculates an acceleration that is too big. The
relative error in angular velocity then gets carried until
the end of the simulation but its magnitude does not
increase.

50
0
-50
-100
0

10

20

Reduced gear set Output torque (N.m)

30

40

Gear set Output torque (N.m)

The test lasts for 40s and the solver used is Radau II 
order 5 stiff with a tolerance of 1e-5, this solver will be
used to test all the subsystems in the following
paragraphs. The improvements in terms of simulation
performance are shown in the following table:

200

0

Simulation time
(s)
State events
Jacobianevaluations

-200
-400
-600
-800

0

10

20

30

Reduced gear
set

4.33

0.95

204

36

302

155

40

Figure 6. Input and output torque of a 6-speed gear set and
its reduced equivalent.

DOI
10.3384/ecp17132299

Full gear set

Most of the events happen during gearshift (see figure 8
below) so the savings in simulation time depend a lot on

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

301

Model Reduction Techniques Applied to a Physical Vehicle Model for HiL Testing

the type of test we run (i.e. how frequently we change
gear).
Number of events

Gear number

250

7
6

200
5
150
4
100

3
2

50
1
0
0
-50

-1
0

10

20

30

40

Figure 8. Correlation between number of events and
gearshift.

We presented in this section a model reduction tool
which is automatic, creates a reduced model that gives
very similar results to the full model and runs faster. The
new model is however a one-dimensional rotational
model which is then not suited for studies where force
or torque reactions are of prime importance.
b. Driveline

Figure 9. Driveline model with a complete left-hand side
driveshaft (bottom) and a reduced right-hand side
driveshaft (top).

Mass
Bearing

Here we take advantage of the fact that we are, in the
scope of the MORSE project, only performing straightline manoeuvres. The results we get on the left side of
the car (wheel angular velocity, suspensions spring
force and position, driveshaft torque etc.) are thus very
similar to the ones on the right-hand side, allowing some
simplifications. We can use ideal force and torque
sources to replace the physical actuators (translational
and rotational springs and dampers) on one side of the
vehicle. We arbitrarily chose to reduce the components
on the right side. In the case of the driveline, we then
reduce the right driveshaft, and keep the left one
unchanged.
The differential required adaptation since it now only
needs to transfer torque to one driveshaft. A standard
open differential would transfer all the torque coming
from the transmission to the right driveshaft as there is
no load on it. This new model splits the torque
independently of what is connected to its flanges. This
approximation works because we only test the vehicle
in a straight line and we assume that the road is ideal
(i.e. uniform friction coefficient, no bumps or holes).

Force
source

Torque
source
Figure 10. Reduced driveshaft using force and torque
sources.

The reduced driveshaft uses ideal force and torque
sources to replicate the behaviour of the other nonreduced driveshaft. The inputs to these force and torque
sources are set to the sensed values in the non-reduced
driveshaft.
We can switch between the full and reduced driveline
by just double-clicking on the driveline subsystem at the
vehicle level (see figure 1) and choosing between the
two models. There is a Boolean parameter that is used
to conditionally enable or disable components. The
reduced models parameters are linked to the parameters
from the full one so we do not need extra
parameterization when switching between models.
We test the reduced driveline with a trapezoidal torque
input and observe the torque and angular velocity at the
wheel hubs:

302

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132299

Session 6: Poster Session

Left hub angular velocity (rad/s)

Right hub angular velocity (rad/s)

The left suspension is kept physical while the right one
is reduced.

60

40

20

0

2
0

2

4

Left hub torque (N.m)

6

8

10

8

10

Right hub torque (N.m)

0.010
0.005
0.000
-0.005

-0.010
-0.015
0

2

4

6

1

Figure 11. Angular velocity (top plot) and torque (bottom
plot) at both front wheel hubs.

The results match perfectly. The benefits in terms of
simulation speed and number of events are not shown in
this section since the driveline itself is a subsystem that
runs relatively quickly. The results will be investigated
when testing the full vehicle model.
c.

Suspensions

In this paper, we consider a one degree of freedom
independent suspension with anti-roll bar. An optional
steering connection can be used but we leave the model
empty here since we only want to run the vehicle in a
straight line. This empty steering model holds the
steering frame in a fixed position. The linear anti-roll bar
model uses the difference in z-heights to calculate a roll
angle and apply a reaction torque.

Figure 13. Physical suspension with spring and damper (1)
and its reduced equivalent using a force source (2).

The suspension model only allows a vertical degree of
freedom. It uses a linear spring and a linear damper. The
fast oscillations that can happen when running this
model are computationally very expensive.
In the reduced suspension model, the spring and damper
are replaced by an ideal force source fed with the force
value read at the full suspension models flange. The rest
of the model, which is not computationally very
intensive, is kept identical between the left and right side
of the vehicle.
We test the suspensions on a test bed with a trapezoidal
position input at both hubs.
In this ideal experiment, where the desired behaviour of
the suspensions is exactly similar on both sides, the
results of the reduced model match perfectly those of the
full model. When tested in a vehicle, the forces and
torques applied to the left and right suspension hubs will
be slightly different, even during a straight-line
manoeuvre (the effective rolling radius is never equal in
all the wheels, the repartition of the vehicle mass is
never perfect, etc.). The reduced model will ignore these
differences and produce the exact same results on both
sides. The inaccuracies being extremely small, they are
completely acceptable for the applications targeted in
the MORSE project.

Figure 12. Front suspension model. The left linkage
(bottom) is a physical suspension model while the right one
(top) is reduced.

DOI
10.3384/ecp17132299

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

303

Model Reduction Techniques Applied to a Physical Vehicle Model for HiL Testing

Full model vertical position (m)

It is important to note that the interface of all the vehicle
models is the same as they need to be able to dialog with
the ECU without missing information. The simple
vehicle model is thus capable of sending and receiving
the same signals as the most detailed one.
The model is run first in Dymola. The simulation lasts
for 56s. The solver settings are: Step size = 0.0005s,
tolerance=1e-5, inline integration method = implicit
Euler. This has indeed proven to be the quickest inline
integration method for our application. The step size has
been calculated to be the biggest time step that gives
correct results when running the crank angle resolved
engine model, which is the subsystem that requires the
smallest sample rate.
The conditions of the tests are different from the
conditions of the tests of the individual subsystems since
we wanted to run the vehicle on a real manoeuvre like
Tip-In, Tip-Out.

Reduced model vertical position (m)

0.06
0.04

0.02
0.00

-0.02
0

5
Full model vertical force (N)

10

15

20

Reduced model vertical force (N)

4000
3000
2000
1000
0

0

5

10

15

6000

20

6000

5000
5000

40004000

[rpm]

Figure 14. Suspensions hub vertical position (top graph)
and vertical force (bottom graph) for both the complete and
reduced model.

30003000
20002000

d. Wheels

1000

4. Results
a. In Dymola
Hardware specifications: computer with Windows 10,
processor is Intel Core i7-4790K @ 4.00 GHz
Quad-core.
In this section, we run a vehicle with several levels of
model reduction on a series of Tip-in/Tip-out
manoeuvres in 2nd gear. The levels of model reduction
are as follows: Level 1: Full vehicle model. Level 2:
Vehicle with reduced transmission only. Level 3:
Vehicle with reduced transmission and reduced
driveline. Level 4: Vehicle with reduced transmission,
reduced driveline and reduced chassis (suspensions and
wheels). Level 5: Vehicle with reduced transmission,
reduced driveline and reduced chassis and only allowing
longitudinal motion.
304

1000

0

0

0

10

20

0

10

20

30

40

50

60

30

40

50

60

Figure 15. Engine speed. Blue: Level 1, Red: Level 2,
Green: Level 3, Magenta: Level 4, Black: Level 5.

The maximum error in engine speed for each level of
reduction is respectively: 1.24%, 2.69%, 2.68% and
3.05%.
The biggest error occurs at around 7s when we engage
the clutch after engaging 1st gear (i.e. at pull-away when
the vehicle starts moving). The magnitude of the error
after that moment does not increase, it remains constant
until the end of the simulation.
20
20
18
16
16
14
12

12

10

[m/s]

The wheels are reduced in the same way, a force and a
torque actuator are used to account for the tyre dynamics
in the front left and rear right wheels.
Once again we have to point out that in reality, each one
of the tyres would behave slightly differently, even in a
straight line. The reduced model ignores these
differences and replicates exactly on the right side of the
car what happens on the left side.
The reduced wheel model is not presented in detail in
this paper since it is generated following the idea as the
drive shafts and the suspensions.

8

86
4

42
0

0-2
0

0

10

10

20

20

30

30

40

40

50

50

60

60

Figure 16. Vehicle speed. Blue: Level 1, Red: Level 2,
Green: Level 3, Magenta: Level 4, Black: Level 5.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132299

Session 6: Poster Session

The maximum error in vehicle speed for each level of
reduction is respectively: 1.01%, 2.41%, 2.40% and
2.60%.
We see a slightly negative vehicle speed at the
beginning of the experiment, when the engine is idling
and the vehicle is in neutral. This is attributable to the
Pacejka tyre model which is inaccurate at very low
vehicle speeds.
7

6

6
5

44
3

[m/s2]

22
1

00
-1

-2-2
-3

-4-4 0
0

10

20

30

40

50

60

10

20

30

40

50

60

Figure 17. Vehicle acceleration. Blue: Level 1, Red: Level
2, Green: Level 3, Magenta: Level 4, Black: Level 5.

The acceleration plot shows good correlation between
the models. There are oscillations at the beginning due
to non-optimal initialisation and during clutch
engagement at 7s.

overruns of the first four models is quite high and even
though it seems to decrease when we reduce the model,
it remains too high for the model to be tested in HiL.
b. In Hardware-in-the-Loop
Hardware specifications: dSPACE DS1005 PPC with 4
cores available.
The simplest and the most detailed vehicle models are
run on the HiL rig with a step size of 0.0005 s. Due to
time constraints, we only tested two vehicle models in
HiL, the most detailed one and a reduced one.
The most detailed vehicle is the full vehicle model (i.e.
the Level 1 vehicle in the last section).
The simplest vehicle is essentially the fully reduced
vehicle (i.e. the Level 5 vehicle in the last section) with
an elasto-plastic based friction model to reduce the
number of events and thus the number of time overruns.
We could see indeed that if the Level 5 vehicle was
running very fast in Dymola it still generated a few
overruns. The elasto-plastic clutch uses a single state
and defines the friction in a continuous way without
introducing events (Dupont P., 2002).
6.5
5.5
4.5
3.5
2.5
1.5

In the table below, a time overrun happens when a time
step in Dymola lasts longer than the corresponding
amount of time in real life. For example, if we choose a
step size of 0.5 ms, it should take less than 0.5 ms for
the hardware to perform all the calculation before
moving to the next step. Otherwise, all the equations do
not have time to be solved before the next step and the
results cannot be trusted anymore so this has to be
avoided.
Simulation performance summary:

Level 1
(Full
model)
Level 2
Level 3
Level 4
Level 5
(Fully
reduced
model)

Simulation
time (s)

Number of
events

Overruns

62.2

46

>50

42.5
36.2
33.8

26
28
27

>50
>50
>50

0.5
0

10

20

30

40

50

Figure 18. Most detailed vehicles turnaround time (ms)
(blue) and target step size (red).

Maximum turnaround time: 7.4 ms
Minimum turnaround time: 0.28 ms
Number of overruns: 55
This very detailed vehicle model is on average too slow
on the current hardware and cannot achieve real-time
performance. It also generates a high number of
overruns.
1.1
0.9
0.7
0.5
0.3

16

16

12

0

We can see from the table above that each level of
reduction improves the simulation time. The number of

DOI
10.3384/ecp17132299

0.1
10

20

30

40

50

60

Figure 19. Simplest vehicles turnaround time (ms) (blue)
and target step size (red).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

305

Model Reduction Techniques Applied to a Physical Vehicle Model for HiL Testing

Maximum turnaround time: 1.18 ms
Minimum turnaround time: 0.096 ms
Number of overruns: 1
This simplified vehicle model is achieving real-time
performance and generates only one overrun. The cause
of the overrun is under investigation.
A comparison of the key variables is not very relevant
here since, due to the high number of overruns, the
results of the most complex model are rapidly drifting.
However, despite these inaccuracies, the results are still
matching well. The manoeuvre starts at time=0s, what
happens before this time can be ignored.

0

10

20

30

40

50

Figure 20. Reduced vehicles engine speed (rpm) for
single core (blue) and multicore (red) implementation.

The results are slightly different from what we got in
Dymola because of a change in vehicle parameterisation
(tyre and aerodynamic drag have been increased in the
vehicle tested in Dymola, hence smaller vehicle speeds).
Due to time constraints, a second test of the model in the
HiL environment has unfortunately not been possible.
The point here is not to compare the results between
Dymola and HiL but rather to compare the results of the
different vehicles.
The multicore capability will also be investigated in
more detail in future work; it does not show a real
benefit here since the controller we used is the software
version and thus is not very CPU demanding. The crank
angle resolved engine model has been, as part of this
project, split into three sub models (Gallagher S., 2016):
the mechanics part (included in the vehicle model), the
combustion part (one for each cylinder) and the air path.
We thus have 5 s-functions for the engine and vehicle to
run and 4 cores available. Along with these models are
the driver model and the CAN buses that also have to be
run on these 4 cores. At the time of writing of this paper,
it was still undecided how the repartition between the
cores would be done.

chassis and driveline has been maintained the same as in
the full models. While the reduced transmission has lost
the 3D capability, it still outputs the correct speed and
torque for all operating points. However, the fully
detailed model is still very much needed. It is important
to be able to model a vehicle with a physical
representation and a high level of detail to accurately
predict the vehicle behaviour to then be able to calibrate
the reduced model.
A series of assumptions and simplifications have of
course had to be made. The main one is that the results
would be the same on the left and right hand sides of the
vehicle since we test it in a straight line. This assumption
is acceptable in the MORSE project as the small
inaccuracies are acceptable. Moreover, we thought it
was more interesting to compromise on the left/right
discrepancy but to keep the same level of detail in the
model rather than reducing the capability of the
subsystems to maintain the models physical on both
vehicle sides which is not of prime importance in a
straight-line test.
More testing needs to be done in the Hardware-in-theLoop environment: we need for example to test the
vehicle over other manoeuvres than Tip-in/Tip-out, to
include the detailed Dymola engine model and to
explore further the multicore capability.
The reduced models (except the gear set) are multi-body
and could be simplified further to one-dimensional
subsystems if needed in order to still be able to achieve
real-time performance once we will have integrated the
Dymola engine in the vehicle.

References
Gallagher S. et al. (2016) Model-based Real-time Systems
Engineering, Loughborough, England, Powertrain Modelling
and Control Conference.
Dempsey M. et al. (2006) Coordinated automotive libraries
for vehicle system modelling, Vienna, Austria, Proceedings of
the 5th International Modelica Conference.
Dempsey M. et al. (2009) Investigating the Multibody
Dynamics of the Complete Powertrain System, Como, Italy,
Proceedings of the 7th Modelica Conference.
Dupont P. et al. (2002) Single State Elasto-Plastic Friction
Models, IEEE Transactions of Automatic Control.

5. Conclusion and Future work
Model reduction techniques for all the vehicle
subsystems have been implemented and tested. The
accuracy of the results is satisfying and the improvement
in performance significant. The level of detail in the
306

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132299

Towards Virtual Validation of ECU Software using FMI
Lars Mikelsons1
1 Robert

Bosch GmbH

Abstract
Connected, Automated, Electrified. These three trends in
the automotive industry require rethinking of the use of
simulation respectively models. The use of models for
evaluation of new concepts or stimulating the unit-undertest (in HiL testing), already firmly rooted in the development process of software functions, will not be sufficient
to realize visions like autonomous driving or update-overthe-air. One key enabler for such technologies is virtual
validation, i.e. the validation or release of software functions in a pure virtual setup. That is, simulation is not only
a tool to shorten the development cycle, but one of the
key technologies to release future software functions, e.g.
highly automated or autonomous driving. In this contribution a feasibility study for the validation of FMI-based virtual ECUs (vECUs) in a co-simulation setup is presented.
Thereby, the powertrain and the vECU are represented by
FMUs, while the tool CarMaker is used for vehicle dynamics. On the base of the gained experience requirements for the FMI standard are formulated that would allow to go for virtual validation of future software functions. Keywords: FMI, virtual validation, ECU, vECU,
autonomous driving

1

sic statistics, between 100 million and 5 billion kilometers
of test driving are required in order to ensure that software for autonomous driving is at least as save as a human
driver. Note that, the test procedure has to be repeated after every single update or modification. Clearly, it is not
possible to use real prototypes for those test drives due to
required time and costs (Google states that its 20 self driving cars drive 16.000 kilometers per week (goo, 2015)).
The same argumentation holds for update-over-the-air except that typically the problem arises from the number of
variants and configurations that need to be tested. Thus,
here virtual validation has to be employed. Typically, for
technologies like autonomous driving one has to couple
models from different domains (xDomain vehicle simulation), e.g. powertrain, vehicle dynamics or powernet.
One approach for xDomain vehicle simulation is to use
Modelica in order to model all involved domians in the
same tool respectively language. Though, in big companies the models for the different domains are generated
in different business units that prefer different simulation
tools (best suited for their specific problems). Hence, cosimulation is typically the way to go. Designing such a
co-simulation setup for virtual validation leads to several
challenges. Typical questions that arise are

 What is the required level of detail for my models?

Introduction

The use of models and simulation is firmly rooted in the
development process of automotive software as well as
hardware components. However, in the development of
software functions typically simulation is mostly used to
evaluate new concepts or to stimulate the unit-under-test,
e.g. HiL in testing. More precisely, the model of a a software or hardware component is typically used during development (Junghanns et al., 2014). Models and simulation are rarely used for virtual validation, i.e. validation
or even release of a software function in a pure virtual
setup. There exist examples where software validation
was done virtually, e.g. ESC homologation (Holzmann
et al., 2012). However, the validation of ECU software is
mostly performed using real prototypes. In fact, although
in many cases models are exchanged between OEMs and
suppliers, it is not a standard workflow to use them for
the application of software functions. While for "old
fashioned" software functions not using existing models may lead to a more costs, not using models is not an
options when it comes to concepts like autonomous driving or update-over-the-air. According to (Wachenfeld and
Winner, 2015) and (Winner et al., 2010), following baDOI
10.3384/ecp17132307

Roland Samlaus1

 How do I parametrize my models?
 How to validate a model?
 How big is the discretization error?
 How big is the coupling error?
 How can I integrate the software code into the simulation?
 Which portions of the ECU code do I have to integrate (where to cut)?
In this contribution only the last two questions are focused.
In fact, this contribution presents a feasibility study for integrating ECU code as an FMU into a co-simulation setup.
Thus it shows a possibility to integrate ECU code (including the formulation of further requirements on FMI)
and discusses the problem of identifying the portion of
the software stack required for a specific validation task.
Note that, the used software function is part of a function
for highly automated driving (HAD). Future work aims
at treating this HAD function as sketched in this paper.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

307

Towards Virtual Validation of ECU Software using FMI

In industry there are different meanings for vECU. Some
people just mean cross-compiled application code, others
mean ECU code running on a virtual OS and last but not
least a vECU can also include virtual hardware. In section 2 a brief overview is given and the used approach for
the vECU used in section 3 is described. In section 3 the
co-simulation setup and generated results are discussed.
Starting from a yaw rate controller implemented in ASCET a vECU is generated. This vECU, is then integrated
in a co-simulation setup consisting of Model.CONNECT
from AVL as a co-simulation middleware, an FMU containing a powertrain model generated with GT Suite from
Gamma Technologies and CarMaker from IPG for vehicle
dynamics simulation. Moreover, required additional features in the used tools and standards are discussed. The
paper closes with a summary and an outlook.

2

Virtual ECUs

Virtual ECUs (vECU) aim at running target ECU code on
standard x86 systems by virtualization. This section introduces use cases for virtual ECUs supporting the ECU
developer in creating software with higher quality faster
then with regular development processes. The basic software architecture for ECUs is explained and it is distinguished between three types of virtual ECUs that differ in
the extent of the re-used target code. Finally the virtual
ECU used in the feasibility study is presented.

2.1

The AUTOSAR software architecture

The AUTOSAR (Automotive Open System Architecture)
standard defines an architecture (see figure 1) for embedded software on ECUs. The idea is to "cooperate on standards - compete on implementation". AUTOSAR systems can be divided in six main components (see 1):
1. Application Software (ASW) is the software implementing the unique features of an ECU, e.g., the behavior of the electronic stability program (ESP) or
HAD functions.

Figure 1. The AUTOSAR software architecture

use-case, e.g., ECUs for wipers need less functionality than engine control units.
4. Operating System (OS) is a real-time system that
is responsible for executing code at the right time
and with a defined maximum duration. Therefore, runnables that contain the executable code, are
scheduled using scheduling tables. The runnables are
assigned to recurring tasks of a defined maximum
duration. For simulation it is often desired to accelerate the execution of code. Therefore the tasks are
executed as fast as possible. Furthermore, the OS is
responsible for handling interrupts, e.g., when data is
received from a sensor. This pauses the execution of
runnables until the interrupt has been handled.
5. Microcontroller Abstraction Layer (MCAL) is the
driver layer and specific for the used ECU hardware.
This should be the single software component which
is hardware dependent. For simulation on x86 systems the MCAL layer has to be exchanged.
6. Complex Device Drivers (CDD) contain special
code which is not commonly used and this not part
of the AUTOASR specification, e.g., drivers for magnetic valves.

2. Runtime Environment (RTE) is the communication layer which distributes the signals directly between ASW components or using the base softwares (BSW) communication stack. The idea of
AUTOSAR ASW components is that they can be dis- 2.2 Categories of virtual vECUs
tributed freely on different ECUs. The RTE will then
either dispatch the data from one component directly vECUs can roughly be classified into three categories:
to another component, if they are deployed on the
1. vECUs that contain only the ASW and RTE (and opsame ECU, or the data is send via the communicationally an OS). This aims at quick testing of basic
tion stack in the base software.
functions of the ASW without using base software
components like communication. If the ASW code is
3. Base Software (BSW) is software that provides baAUTOSAR compatible, vECUs for this use case can
sic functionality of an ECU. Typical software combe easily created since there are no hardware specific
ponents are communication stacks such as CAN, auparts. However, no realistic estimation of the executomotive ethernet, or flexray. Other examples are
tion behavior on real ECUs can be derived with this
memory access and diagnosis functions. The extent
kind of vECUs.
of the used base software on an ECU depends on the
308

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132307

Session 6: Poster Session

2.4

vECU for feasibility study

For the feasibility study a category 1 vECU has been
used. The vECU consists of an OS, the RTE and application software. The application software has been generated as AUTOSAR 4 compatible code from an ASCET
model. Based on the applications AUTOSAR description
the RTE has been generated. No BSW or MCAL has been
integrated at this point. This will be done as a next step
in order to send messages via CAN. This will enable to
investigate how a software function can be deployed on
more than one ECU.

2.5

vECU tool evaluation

Figure 2. Use cases for vECUs

Several tools of different vendors including ETAS ,
QTronic, Dassault, dSPACE and Mentor Graphics have
been evaluated for the creation of vECUs at Bosch. For
2. vECUs that consists of ASW, RTE, BSW, OS and a
this contribution ETAS EVE is used since it is best suited
virtual MCAL (for x86 systems). A more realistic
for the use case presented here (e.g. best integration into
behavior of the real ECU can be simulated with this
the existing ECU build tool chain).
kind of vECU. The scheduling of tasks is considered
and the functionality of the BSW can be tested. As
3 Feasibility study
an example rest-bus simulation can be performed to
mock additional ECUs in the network to test for cor- In this section it is shown how FMI is used to integrate
rect reaction of the simulated vECU.
and finally validate a software function in a co-simulation
setup. The vision is to validate HAD functions or software
3. If a more realistic behavior of the vECU is desired, for autonomous driving in the future. In this contribution,
virtual hardware can be used. All software compo- not a complete function consisting of e.g. object recognents of the real ECU can be re-used, including the nition, trajectory generation and follow-up control is used
target MCAL layer. The MCAL is used with detailed but only the lateral control since the goal is demonstrate
hardware models which simulate real timing behav- the use of FMI to integrate ECU software into a simulation
ior. Another benefit is the ability to perform fault for virtual validation (and not to investigate the numerical
injection which can be problematic when done with properties).
real hardware since the injected faults could cause In section 3.1 the co-simulation architecture is described,
damage to the devices. A drawback of using hard- while 3.2 gives a brief overview on the used models and
ware models is reduced simulation speed since the simulation results. In section 3.3 further requirements on
models are usually highly detailed.
the FMI standard and the used tools are derived.

2.3

Use cases for virtual ECUs

Virtual ECUs can be used for faster test of application
software. Based on the vECU category used, BSW functionality and timing behavior can also be considered. Typical use-cases for vECUs are displayed in figure 2.
The XCP protocol is used by tools like ETAS INCA
to measure and calibrate parameters of the ECU software,
e.g. to optimize the gasoline injection for a certain engine type. This can also be done virtually with vECUs.
Test APIs allow for automatic testing of the ECU software. Examples for commonly used testing tools are
TPT and ECU-TEST. It is also possible to write custom
tests with arbitrary programming languages like Java. The
vECU can be exported as an FMU or S-Function for cosimulation with physical and plant models. Virtual busses
(CAN, LIN, ...) can be connected to virtual ECUs using
the MCAL layer. This allows to analyze messages on the
busses and to perform rest-bus simulation with tools like
CANoe or Busmaster to simulate additional ECUs in a
network.
DOI
10.3384/ecp17132307

3.1

Co-Simulation Architecture

In order to setup a co-simulation one of the first things to
do is to define the integration platform, i.e. the tool that
executes the master algorithm. In some cases, especially
when not all involved tools offer an FMI export, it may
be the case that there is not one defined master algorithm.
Moreover, direct tool couplings (that do not rely on FMI)
written by different tool vendors tend to have different numerical properties and to produce out-of-sync signals. An
approach to face those issues is to a co-simulation middleware, that does not contain a model but only serves as a
master and coordinator. Consequently, the co-simulation
has a clean architecture with tool couplings that are consistent with each other(see figure 3). Moreover, it is easily extendable and typically offers more options to configure the co-simulation than simulation tools do. There
exist several open-source (e.g. PyFMI) as well commercial (e.g. TISC from TLK Thermo, Cosimate from ChiasTek or Silver from QTronic that also includes vECU
generation) co-simulation middlewares. In this contribu-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

309

Towards Virtual Validation of ECU Software using FMI

Figure 3. Co-simulation architecture with typical vehicle domains using a co-simulation middleware (purple rectangle)

Figure 4.
Setup of the co-simulation (screenshot from
Model.CONNECT from AVL) with two FMUs (vECU from
ETAS EVE and powertrain from GT Suite) and CarMaker

tion Model.CONNECT from AVL is used.
principle, there are some issues that prevent or will (in the
case of more complex functions) prevent FMI from being
As already described above the co-simulation consists of suited for that use case. Beside issues described in (Link
et al., 2015) the following requirements were derived:
the following participants (see figure 4)

3.2

Co-Simulation Setup

 CarMaker from IPG: Vehicle dynamics and driver
model for longitudinal control
 FMU: Powertrain model generated from GT Suite
from Gamma Technologies (see ??)
 FMU: vECU generated with EVE from ETAS GmbH

 For complex software functions lots of physical signals have to be connected to the vECU. Thus, FMI
should support vectors for easier workflows and better models (w.r.t. clarity).
 When it comes to software functions that are distributed over multiple ECUs, signals have to be exchanged between them. In many cases these signals are not just scalars or vectors (see above), but
structs. A typical example is the ADASIS protocol
(Ress et al., 2008) that is used to transmit the ehorizon from an e-horizon provider to an e-horizon
reconstructor. Thus, in order to use FMI for vECUs
it should support structs.

Throughout this section it is assumed that the software under consideration can be validated by using the ISO double lane change as maneuver. The software shall be validated if the deviation in the yaw rate is rate is not bigger than 0.021/s and the deviation in the position in the
y-direction is not bigger than 30cm. The vehicle model
(and accordingly the software function) is parametrized
according to a luxury car, however details are neglected
 In cases where not only the functionality, but also
here. Advanced co-simulation algorithms were not used,
the timing shall be validated the communication has
i.e. the models communicate using a parallel scheme usalso to be modelled, e.g. using virtual CAN. Curing zero order hold extrapolation. It is expected that this
rently, the user (FMU generator and/or integrator)
has to be changed when using a more complex powertrain
has to care about the communication between FMUs
model and a more complex software function. Input for
(at least for virtual busses etc.). In future versions it
the software function is the actual yaw rate, the desired
would be desirable to have the communication mean
yaw rate, the vehicle velocity and the steering angle. Note
as part of FMI. Note, that this will be the case for the
that, the desired yaw rate is read from a table, that will be
Advanced Co-Simulation Interface (ACI) (Krammer
replaced by a trajectory generator in the future.
et al.).
Figure 5 indicate the the simulation result lies within the
specified error bounds. In fact the maximal error in the
Beside the requirements on FMI there are also some issues
yaw rate is 0.0151/s and 29.8cm in the y-direction of
on the tool side. Among these are
the position of the vehicle. Thus (under the assumptions
stated above), the software function can be judged as val According to the list above tools (simulation tools
idated.
and co-simulation middlewares) should support vectors and structs.
3.3 Derived Requirements for Tools and Inter-

faces
While it can be seen from the previous section that a virtual validation of ECU software using FMI is possible in
310

 When more complex models are used and especially
in cases where numerically demanding couplings are
in place it is desirable to use a master algorithm that

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132307

Session 6: Poster Session

Figure 6. Screenshot showing the double lane change maneuver
in CarMaker

tions. Thus, virtual CAN will be used for signal exchange.
Therefore, the vECU has to include the communication
stack. Last but not least an interface to connect calibration
software (e.g. INCA from ETAS) will be created.

References
Google self-driving car project monthly report. August 2015.
Henning Holzmann, Karl Michael Hahn, Jonathan Webb, and
Oliver Mies. Simulation-based esc homologation for passenger cars. ATZ worldwide, 114(9):4043, 2012.
Andreas Junghanns, Jakob Mauss, and Michael Seibt. Faster
development of autosar compliant ecus through simulation.
ERTS-2014, Toulouse, 2014.
Figure 5. Variables used for validation including error bounds
for the double lane change including error bound

Martin Krammer, Nadja Marko, and Martin Benedikt. Interfacing real-time systems for advanced co-simulation - the acosar
approach.

can iterate, i.e. repeat macro steps. This is currently
not supported by the used vECU, but will be supported in the future. However, many simulation tools
do not support this (optional) FMI feature. This situation should be changed.

Kilian Link, Leo Gall, Monika Mhlbauer, and Stephanie
Gallardo-Yances. Experience with industrial in-house application of fmi. In Proceedings of the 11th International Modelica Conference, Versailles, France, September 21-23, 2015,
number 118, pages 1722. Linkping University Electronic
Press, 2015.

 Tool: If common open source implementations of Christian Ress, Dirk Balzer, Alexander Bracht, Sinisa
Durekovic, and Jan Lwenau. Adasis protocol for advanced
virtual MCALs would reduce development overhead
in-vehicle applications. In 15th World Congress on Intelligent
and enable switching between different vECU tools.
Transport Systems, page 7, 2008.

4

Summary & Outlook

Walther Wachenfeld and Hermann Winner. Die freigabe des
autonomen fahrens. In Autonomes Fahren, pages 439464.
Springer, 2015.

This paper presents a feasibility study for the use of FMI
for the validation of future ECU software. Besides a brief
overview over the concept of vECUs different use cases H. Winner, G. Wolf, and A. Weitzel. Freigabefalle des autonomen fahrens/the approval trap of autonomous driving.
for the use of vECUs are considered. For a functional valVDI-Berichte, (2106), 2010.
idation (without timing) it is shown that the integration of
ECU Code into a co-simulation works in principle. However, for more complex functions than the yaw rate controller used here, some issues arise that were collected in
section 3.
In future work a more complex (HAD) function will be
used. Consequently, more complex models have to be
used. Moreover, it is desired to do also timing investigaDOI
10.3384/ecp17132307

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

311

312

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Parameter Estimation based on FMI
Rdiger Kampfmann

Danny Msch

Nils Menager

Bosch Rexroth AG, Lohr am Main, Germany
{ruediger.kampfmann, fixed-term.danny.moesch, nils.menager}@boschrexroth.de

Abstract

the dynamic systems and the software library Ceres for
the solution of the underlying optimization problem. AfIn order to stay competitive the requirements on machin- terwards the whole architecture of the used toolchain is
ery in the producing industry have enormously increased. presented. Finally this toolchain is applied to a real probWithin the automation industry these demands, like higher lem.
throughput or better energy efficiency, result in increasing
complexity of the installed plants. Additionally, Indus- 2 Mathematical Background
try 4.0 and the Internet of Things continuously increase
the amount of software. Using model-based development In this contribution it is assumed that the simulation model
methods is one approach to deal with this complexity. But of a real plant is described in the following way:
model-based methods can also be utilized during the opx(t) = f(t, x(t), u(t), p)
(1)
erational phase of a plant in order to generate additional
y(t, p) = g(t, x(t), p)
(2)
value for the plant operator. Introducing smart services
x(tstart ) = x0
(3)
based on the usage of physical models enables new control
and diagnosis features, e.g. the utilization of inverse plant
models for feedforward control or comparing the output of
a model with measurements of the plant in order to prove
for correct behavior. For all these services the accuracy of
the considered models is crucial. With an inexact model
neither the future behavior can be foreseen nor the control
quality can be improved. The used models dont have to
be built up from scratch, existing models already created
for sizing can be reused. However, these models cannot
be used directly. First a reparametrization is necessary,
because effects like friction or manufacturing tolerances
cannot be taken into account correctly during sizing. For
this special kind of problem dedicated optimization algorithms are available for parameter estimation, which take
randomly distributed measurement errors and the special
structure of this problem class into account.
In this paper a work flow for parameter estimation based
on open source tools is presented, in which the considered
models are provided as Functional Mock-up Unit. Afterwards the performance of this work flow is demonstrated
on a real industrial problem: A three arm Delta Robot.
Keywords: Parameter Estimation, Levenberg-Marquardt
Algorithm, FMI, Least Squares Optimization, Loglikelihood Method

1

f : T  Rnx  Rnu  Rnp  Rnx ,
g : T  Rnx  Rnp  Rny ,
nx , nu , np , ny  N.
The input u from the real plant is assumed to be known
exactly over the whole interval, whereas  i denotes the
measured output vector of the real plant at time ti for
i = 1, . . . , nt . The most obvious approach for parameter estimation is just to minimize some norm kkq with
q  [1, ) or q =  of the deviation between the measured
and the simulated outputs by varying the parameters p, i. e.
nt

arg min
pRnp

The paper is structured as follows. First the considered
optimization problem is derived from an approach based
on probability theory. Afterwards suitable algorithms for
this problem class are discussed with a special focus on
the Levenberg-Marquardt algorithm, which is used in this
contribution. Then the used software tools are presented:
The Functional Mock-up Interface for the description of

 k i  y(ti , p)kqq

i=1

or
nt

arg min
pRnp

Outline

DOI
10.3384/ecp17132313

The dynamic system consists of a set of ordinary differential equations (1), a set of algebraic equations (2) and
an initial condition (3). The time interval T = [tstart ,tend ]
is considered. The functions x : T  Rnx , y : T  Rnp 
Rny , u : T  Rnu denote the states, the outputs and the
inputs, respectively. The vector p  Rnp represents the parameters. Additionally,

 k i  y(ti , p)k ,

i=1

respectively. That q = 2 is a reasonable choice is going
to be the result of the following subsections. Therefore a
little bit of probability theory has to be consulted.
Ensuing from (Krengel, 1988) the maximum-likelihood
approach is introduced first. In the next subsection the idea
is used to formulate the underlying optimization problem
which is the foundation of the presented process of parameter estimation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

313

Parameter Estimation based on FMI

2.1

Maximum Likelihood Approach

for each measurement error  i, j is obtained. Since the  i, j
are
statistically independent for all j and for all i, too, it
be a random vector with independent and idenholds
tically distributed components and concrete realizations
nt
x  Rn of X. Each component Xi has the density func
(
)
=
 ( i )
tion (|p) = (xi |p), which depends on a parameter set
i=1
p. It describes the probability of xi given the parameters
nt ny
p. Since they are independent, the joint density can be
=   ( i, j )
written as
i=1 j=1
!
n
nt ny  2
nt ny
1
k,l
(x|p) =  (xi |p).
=  
exp   
, (6)
 2k,l
 i, j
i=1
i=1 j=1 2
k=1 l=1 2

To formulate the optimization problem the likelihood where  =  1 . . .  n . Because of (4) we also get  i 
function L(|x) = L(p|x) is defined as
N(y(ti , p ),  i ) and thus
!
L(p|x) := (x|p),
 i, j  y j (ti , p ))2
(
1
 i, j ) = 
.
exp 
(
 2i, j
2
 i, j
2
which is now a function of the parameters p given the data

x. L(|x) is not a proper probability density function, since
 ... n
its integral over all parameters is not necessarily equal to For the same reason as in (6) and with  = 1
1. Therefore, it also should not be considered a conditional this leads to the conditional density function
!
probability density function, which might be supposed by
nt ny
 i, j  y j (ti , p))2
(
1
 |p) =   
(
exp 
.
the vertical bar.
 2i, j
2
 i, j
i=1 j=1 2
Thus, it is obvious to choose the optimization problem
Let X  Rn

The Log-likelihood function is then defined by

arg max L(p|x)
pRnp

n

y
nt
nt ny
) = 
ln L(p|
ln 2    ln  i, j
2
i=1 j=1

to get the maximum likelihood estimator pML which
makes the sample data x most likely. In some cases it will
n
 i, j  y j (ti , p))2
1 nt y (
simplify the optimization process if the Log-likelihood
.
 
function ln L(p|x) is chosen instead of L(p|x) as will be
2 i=1 j=1
 2i, j
seen later. In fact, it does not make a difference whether
choosing L(p|x) or ln L(p|x), since the logarithm is a Since the first and the second term are constant they can
monotonic function that does not influence the maximum. be omitted from the optimization.
Finally, the whole constrained nonlinear optimization
2.2 The Underlying Optimization Problem
problem can be formulated:
Each measured data vector  i at time ti can be expressed
1 nt 1
as the real output y(ti , p ) with the exact but naturally uni (
 i  y(ti , p))k22
arg min  k
(7a)

n
2
p
pR
known parameter set p plus a measurement error  i , i. e.
i=1
 i = y(ti , p ) +  i .

(4) subject to

x(t) = f(t, x(t), u(t), p),
It is assumed that the measurement errors  i are stay(t, p) = g(t, x(t), p)
tistically independent and underly a certain distribution.
The most common assumption is to choose a normal disx(tstart ) = x0
tributed error vector  i with statistically independent components, known (diagonal) covariance matrix  i and ex- observing the box constraints
pectation E( i ) = 0, i. e.
plower  p  pupper

 i  N(0,  i ) with  i = diag  2i,1 , . . . ,  2i,n . (5) given
In an applied sense that means that the measurements  i
do not influence each other and the errors  i do not contain
a systematic error.
With these requirements the density function
!
 2i, j
1
exp  2
( i, j ) = 
 i, j
2
 i, j
2
314

(7b)
(7c)
(7d)

(7e)

u(ti ) with ti  [tstart ,tend ] for i = 1, . . . , nt
and related measured outputs  i . The result is the parameter set pML which is the most likely for the given measured
output values. It should be noted again that it is important for the chosen approach to have measurement errors
following (5). The method is not reasonable for different
distributions, although others can be established.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132313

Session 6: Poster Session

3

Optimization Algorithms

Eliminating the ODE constraints (7b)-(7d) through numerical integration from (7a) yields a common nonlinear
optimization problem. For this kind of problem a couple of different algorithms for the efficient solution exist.
Some algorithms exploit derivative information and some
do not. The derivative-free optimization algorithms have
the advantage that they obviously do not require derivatives with respect to the varied optimization variables,
which may be costly to compute. Another advantage
is that under certain circumstances global convergence
is achieved, neglecting limited computational time and
rounding errors. In (Gedda et al., 2012) a tool chain for
parameter estimation with FMI and derivative-free methods already has been presented. Nevertheless, derivativefree optimization algorithms show very poor convergence
speed.
However, optimization algorithms, which use derivatives
of the objective function, have also distinct advantages.
The main benefit is the fast convergence rate. These methods compute iteratively starting from an initial guess a descent direction and thus reduce the objective function in
every step until a certain stop criterion is reached. The better the initial guess the faster the convergence speed. The
disadvantages of these methods are on the one hand that
the problem has to be sufficiently smooth and that derivatives have to be computed and on the other hand that these
methods may get stuck in a local minimum, if the initial
guess is too bad. The last disadvantage can be overcome
with multi start-ups, i.e. run several optimization from different initial guesses (see (Raue et al., 2013) for more information). For the purposes of this contribution, whereas
existing models from the sizing should be reused, good
initial guesses are known, because rough parameter sets
are already needed for correct dimensioning. Thus stucking in local minimum is not a problem at all. The considered models are also sufficiently smooth with respect to
the parameters. Also in (Raue et al., 2013) a benchmark of
different algorithms was conducted to an estimation problem from systems biology, demonstrating the slow convergence speed of derivative-free optimization algorithms
compared to the ones which rely on derivatives. Since
good initial guesses are known and the fast convergence
speed the demonstrated toolchain is based on derivative
based optimization algorithms.

3.1

Levenberg-Marquardt Algorithm

The investigated optimization problem (7a) has a special
structure. It is a nonlinear least squares problem. This
kind of problem is widely spread in scientific and engineering areas. Thus structure exploiting optimization algorithms have been developed, which solve this problems
efficiently. The Levenberg-Marquardt algorithm is one of
these algorithms and is used within this contribution. It
can be seen as a conjunction of the Gauss-Newton method
together with the idea of Trust-Region approaches.
DOI
10.3384/ecp17132313

To give a short overview (Bjrck, 1996), some abbreviations are introduced first:
 i  y(ti , p))
hi (p) :=  1
i (
nt

 i  y(ti , p)k22
1
H(p) :=  k
i (
i=1

y0i (p) :=

 y(ti , p)
p

Therein denotes y0i the Jacobian matrix of y at time ti with
respect to p. The Gauss-Newton method solves the linearized least squares problem
arg min
pRnp

1 nt 1
 ki (hi (pk )  y0i (pk )pk )k22
2 i=1

in each iteration step k to get a new approximation
pk+1 = pk + pk
of the exact parameter set p .
It is the idea of the Levenberg-Marquardt algorithm to add
a regularization term to the linearized objective function,
arg min
pRnp

1 nt 1

i (hi (pk )  y0i (pk )pk )k22 + k kpk k22 .
k

2 i=1
2

With the regularization the problem has always a solution
even with rank deficient Jacobians y0i . The parameter k
also controls the step length kpk k2 as well as the direction pk . It can be observed (Marquardt, 1963) that for a
large k the direction is almost a gradient step with only
small step size, whereas a small k leads to a direction
close to a Gauss-Newton step. Therefore it is reasonable
to choose a small k near the actual minimum where the
linearized problem is a rather good approximation. Hence,
choosing k is a significant task in each iteration to reach a
preferably fast convergence rate. There are different ways
to update the parameter k . A central role plays the ratio
between actual reduction and (by the linearized problem)
predicted reduction
k (pk ) =

H(pk )  H(pk + pk )
,
t
0
2
1
H(pk )  ni=1
k
i (hi (pk )  yi (pk )pk )k2

whose value decides whether pk will be updated or not and
how k will be changed.

4

Functional Mock-up Interface

The Functional Mock-up Interface (FMI) is a tool independent standard to support model exchange between different simulation environments (Blochwitz et al., 2011). A
model which is shared via FMI is referred to as Functional
Mock-up Unit (FMU). An FMU consists of a XML-File,
describing the whole model variables and parameters, and
a compiled library containing the model equations and additionally required functions, i.e. functions for initialization or data exchange. The models are described as hybrid

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

315

Parameter Estimation based on FMI

ODEs supporting state and time events. The FMI standard supports two modes to share these models. On the
one hand there is Model Exchange, whose models are described in a form similar to the equations 1 and 2, and on
the other hand the Co-Simulation mode, which delivers
the FMU additionally with its own integrated ODE solver.
In this contribution the Co-Simulation mode is used due
to the fact that no extra ODE solver is required for simulating an FMU. The models considered in the estimation
procedure are built up in a simulation environment and
exported as FMU. In 7.2 an example is described. For the
optimization derivatives with respect to the parameters are
required. With the actual standard 2.0 of the FMI, only
derivatives with respect to inputs and states are supported
(Blochwitz et al., 2012). Hence finite differences are used.
As far as the authors know, parameter sensitivities are currently considered by the FMI steering committee.

5

Ceres Solver

For the solution of the nonlinear least squares problem
(7a), (7e) the Ceres Solver (Agarwal et al.) is utilized.
The Ceres Solver is an open source C++ library for solving large optimization problems. Beneath general unconstrained optimization problems it was developed to solve
nonlinear least squares problems with bound constraints.
There are several reasons why the Ceres Solver was chosen. The solver is published under the New BSD license,
so there are almost no license restrictions for commercial
use. In addtion to the Levenberg-Marquardt Algorithm 3.1
this software library is equipped with other state of the art
algorithms and has reached a certain maturity since it is
used in commercial applications for more than four years
and still has an active community.
Furthermore the library is developed in C++ and has already been migrated to Android and iOS. Hence an migration to Bosch Rexroth embedded systems should be
possible with little effort. Ceres can compute the required
derivatives of the objective function by finite differences
or the user can provide them. Because the actual FMI
version is not supporting parameter derivatives, they are
computed by Ceres via finite differences. With upcoming features of the next FMI version, this can be easily
adapted. Ceres is one of the few libraries which is also
capable to derive covariance estimations for the solution.
Hence, confidence intervals for the computed parameters
can be computed directly.
Within Ceres a problem class needs to be implemented
which corresponds to the desired residual function (7a).
The model to be investigated and the measured data have
to be provided therefor. An additional class method handles possible solver options and is responsible for the actual optimization.

Figure 1. Structure of parameter estimation toolchain

measured outputs have to be provided as CSV-file. The
whole estimating procedure is configured by a configuration file. In this file the desired model, the parameters to
estimate and the paths of the CSV-files are denoted. Also
an initial guess and the variances for each measurement
noise have to be stated. Additionally, upper and lower
bounds for the parameters can be specified. Within Ceres
a problem class was defined which takes the configuration
file and manages the whole parameter estimation procedure. This problem class directly interfaces the FMU. No
additional library for calling the FMU functions is used.
An evaluation of the residual function implies a simulation of the FMU. In every step the inputs are written to
the FMU. Thereafter, the residual function is built up by
comparing the measured outputs with the outputs of the
FMU. Hence the whole simulation is triggered by Ceres.
The derivatives of the residual function with respect to the
parameters are computed directly by Ceres via finite differences which corresponds to multiple simulation runs.
Ceres then conducts the chosen optimization algorithm by
varying the parameters. Subsequently, an a posteriori evaluation of the covariance matrix of the estimated parameters can be conducted. Out of this matrix confidence intervals for each parameters can be derived directly. For the
import of the FMU into Ceres an own light weight framework was implemented.

7

Application of the Tool Chain

In this section the capability of the toolchain is demonstrated on a Delta Robot. This type of robot was developed in the 1980s (Clavel, 1988) and is widely used for
pick and place applications. It is built up out of parallel
bars and has 3 degrees of freedom for translational manipulation and one for manipulating the orientation. Hence it
has to be driven by 4 motors. Since the robot should move
as fast as possible, knowing the exact dynamic behavior is
advantageous, i. e. an accurate model can be exploited for
feedforward control in order to enhance the dynamic behavior. The dynamic of the robot is mainly influenced by
frictional effects and mass parameters. The mass parame6 Structure of the Tool Chain
ters underly a certain manufacturing tolerance and the fricFigure 1 shows the structure of the parameter estimation tion is hard to be known beforehand. Therefore, estimattoolchain. The stimulation of the real plant and the real ing these parameters is a good use case for the toolchain.
316

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132313

Session 6: Poster Session

7.1

Real Set-up of the Robot

Figure 3. Animation of the multi body model

considered axes are equal. Hence, the following parameters should be identified:
Figure 2. Real delta robot

 Mass of lower arm
Figure 2 shows the investigated robot. The kinematic
 Mass of upper arm
is manufactured by Autonox24 and is driven by 4 Rexroth
synchronous motors. Three MSK040B-0600 for the trans Mass of base plate
lational movement and one MS2N03-B0BYN for the orientation axis are used. The movement of the robot is con Motor and gear inertia
trolled by a Rexroth IndraControl VPB 40.3 industrial PC.
 Gear efficiency
No special trajectories were considered. The robot just executes a usual pick and place cycle and the motor torque is
 Parameter for Coloumb friction
measured via actual motor current. Through the recorded
motor torques the parameters of the robot should be iden Parameter for viscous friction
tified. Since the dynamics of the orientation axis is well
known, no measurements for this axis have been taken into The model was exported as an FMU 2.0 for Co-Simulation
containing the CVODE solver (Hindmarsh et al., 2005).
account.

7.2

Delta Robot Model

The physical model of the robot was built up in the modeling language Modelica using Dymola. The mechanical
model consists of Modelica Standard Library (MSL) components. Mainly joints and body components from the
multi body library are used.

7.3

Real Set-up of the Robot

Figure 3 shows the animation of the MSL components
within Dymola. All parallel bars were considered. No
simplifications of the mechanical structure were made.
Additionally the drive train of each axis was modeled in
the way that motor and gear inertia, gear efficiency and
Coloumb and viscous friction are considered. Therefore
own Modelica components were added to standard rotational mechanics components. As input of the model the
position, velocity and acceleration of each axis were used.
The resulting motor torques were declared as output. It
is assumed that the inertia and friction properties of all 3
DOI
10.3384/ecp17132313

7.4

Estimation of Parameters

For the measurement the robot moves the usual pick and
place cycle at four different speeds. 6250 time points were
considered. The complete cycle lasts 62.278 seconds. For
each of the three axes the position, velocity, acceleration
and torque were recorded. For the identification procedure
Ceres compares the measured motor torque with the one
resulting from the FMU.
Table 1 shows the results of the parameter estimation procedure. The residual of the objective function (7a) was
reduced significantly from 2.12  106 to 1.25  106 . The
computed parameter sets especially the friction and gear
efficiency parameter seem reasonable. Also the computed
confidence intervals, i. e. the intervals in which the real
parameters are located with a probability of  = 0.95, imply that the computed estimations are reliable. Unfortunately it is not possible to validate the estimation results
by scaling the components, because the robot cannot be
disassambled.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

317

Parameter Estimation based on FMI

Parameter

Unit

Initial Value

Estimated Value

Confidence Interval  = 0.95

Mass of lower arm
Mass of upper arm
Mass of base plate
Motor and gear inertia
Gear Efficiency
Coloumb Friction
Viscous Friction

[kg]
[kg]
[kg]
[kg m2 ]
[1]
[N m]
[N m s rad1 ]

0.1
1.5
0.87
0.000144
1.0
0.12
0.001

0.08
1.74
1.1
0.000155
0.907
0.105
0.00128

0.00350
0.0211
0.0212
2.65  106
0.0136
0.00158
1.92  105

Table 1. Parameter estimation results

Figure 4. Results for arm 1

Figure 6. Results for arm 3

measurements and the presented tool chain parameter estimations could be conducted automatically. Upon these
well known parameters and accurate models new smart
services for diagnosis or control purposes can be enabled.

References
Sameer Agarwal, Keir Mierle, et al. Ceres solver. http://
ceres-solver.org.
ke Bjrck. Numerical methods for least squares problems.
SIAM, 1996.
Figure 5. Results for arm 2

Figure 4 to 6 show a section of the results for each axes.
With the estimated parameters the accuracy of the model
has been improved significantly.

8

Summary and Outlook

Torsten Blochwitz, Martin Otter, Martin Arnold, Constanze
Bausch, H Elmqvist, A Junghanns, J Mau, M Monteiro,
T Neidhold, D Neumerkel, et al. The functional mockup
interface for tool independent exchange of simulation models. In Proceedings of the 8th International Modelica Conference; March 20th-22nd; Technical Univeristy; Dresden;
Germany, number 063, pages 105114. Linkping University
Electronic Press, 2011.

A tool chain for parameter estimation with a state of the art
Open Source software library and the Functional Mock- Torsten Blochwitz, Martin Otter, Johan Akesson, Martin Arnold,
Christoph Clauss, Hilding Elmqvist, Markus Friedrich, Anup has been presented. The capabilities of this tool chain
dreas Junghanns, Jakob Mauss, Dietmar Neumerkel, et al.
were demonstrated on a real industrial robot. The results
Functional mockup interface 2.0: The standard for tool inare very promising such that this approach should be purdependent exchange of simulation models. In Proceedings
sued. On the one hand a migration of the whole tool chain
of the 9th International MODELICA Conference; September
to embedded systems seems meaningful. For example the
3-5; 2012; Munich; Germany, number 076, pages 173184.
estimation procedure can be used for auto calibration of
Linkping University Electronic Press, 2012.
feedforward controllers using inverse models.
On the other hand with Industry 4.0 and the Internet
of Things new use cases occur. The intelligent plants Reymond Clavel. A fast robot with parallel geometry. In Proc.
equipped with sensors record all their data. With these
Int. Symposium on Industrial Robots, pages 91100, 1988.
318

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132313

Session 6: Poster Session

Sofia Gedda, Christian Andersson, Johan kesson, and Stefan Diehl. Derivative-free parameter optimization of functional mock-up units. In Proceedings of the 9th International MODELICA Conference; September 3-5; 2012; Munich; Germany, number 076, pages 819828. Linkping University Electronic Press, 2012.
Alan C Hindmarsh, Peter N Brown, Keith E Grant, Steven L
Lee, Radu Serban, Dan E Shumaker, and Carol S Woodward.
Sundials: Suite of nonlinear and differential/algebraic equation solvers. ACM Transactions on Mathematical Software
(TOMS), 31(3):363396, 2005.
Ulrich Krengel. Einfhrung in die Wahrscheinlichkeitstheorie
und Statistik, volume 8. Springer, 1988.
Donald W Marquardt. An algorithm for least-squares estimation
of nonlinear parameters. Journal of the society for Industrial
and Applied Mathematics, 11(2):431441, 1963.
A. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke,
D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis,
U. Klingmller, and J. Timmer. Lessons learned from quantitative dynamical modeling in systems biology. PLoS ONE,
8(9):e74335, Sept. 2013. doi:10.1371/journal.pone.0074335.

DOI
10.3384/ecp17132313

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

319

320

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Generic FMI-compliant Simulation Tool Coupling
Edmund Widl1

Wolfgang Mller2

1 Center

2 Institute

for Energy, AIT Austrian Institute of Technology, Austria, edmund.widl@ait.ac.at
of Analysis and Scientific Computing, TU Wien, Austria, wolfgang.mueller@student.tuwien.ac.at

Abstract

2

The Functional Mock-up Interface (FMI) specification provides a simple yet effective definition for co-simulation
APIs. Even though the number of simulation tools supporting the export of Functional Mock-up Units (FMU) is
growing steadily, there is a considerable number of wellestablished tools that do not. This paper addresses this
issue by introducing a generic and adaptable way of coupling established simulation tools in an FMI-compliant
manner. The proposed concept has been implemented as
part of the FMI++ library, which is used as basis for FMIcompliant wrappers for the TRNSYS simulation tool and
the MATLAB environment. These examples demonstrate
the potential of the proposed approach to include wellestablished simulation tools with minimal effort. This not
only enables researchers and engineers to include a diverse
range of tools more easily into their work flow, but is also
an incentive for tool developers to provide FMI-compliant
wrappers.

The FMI-compliant front-end/backend concept

The basic concept comprises two components: The frontend component to be used by the simulation master and the
back-end component to be used by the slave application.
Between these two components a proper data management
has to be established that is responsible for the communication and data exchange between both ends. The corresponding interfaces are tailored to suit the requirements of
the FMI specification. They implement the necessary functionality required for a master-slave concept, i.e., synchronization mechanisms and exchange of data. See Figure 1
for a schematic view of this concept.

2.1

Front-end component

The front-end component is the actual gateway for a master
algorithm to communicate and exchange data with an external simulation application. Its interface (see Figure 2) is
designed such that it can be easily used as an FMI compoKeywords: FMI for Co-Simulation, tool coupling, front- nent (FMI model type fmiComponent), implementing
functionalities close to the requirements of the FMI speciend/back-end concept, TRNSYS, MATLAB
fication, for instance functions initializeSlave(...),
doStep(...) or setReal(...). The front-end is responsi1 Introduction
ble for the following tasks:
The list of simulation tools offering FMI (Blochwitz et al.,
2011) support is rapidly growing1 , demonstrating the fea- 2.1.1 Information retrieval
sibility of the approach and underlining the importance of The front-end component parses the FMI model descripsuch a specification for Co-Simulation (CS) and Model tion and stores the relevant information. This includes
Exchange (ME). However, many established simulation general simulator attributes (e.g., executable name, event
tools do not yet offer APIs for co-simulation, let alone one handling capabilities) as well as specific model informathat follows the FMI specifications. This paper explores tion (e.g., simulator-specific input files, variable names and
a generic approach that facilitates the integration of FMU types, input/output relations).
CS export functionalities for such tools.
2.1.2 Variable initialization
The proposed approach uses a front-end that is exposed
to the master algorithm as FMI component, and an appropri- Once the model description information is retrieved, the
ately linked back-end that is used by the slave application. memory for the variables has to be allocated. This is done
Due to its design this approach can not only be used by with the help of the dedicated data management (see Sectool developers who have access to the (possibly closed) tion 2.3 below).
source code of the core application but also by users who 2.1.3 Variable handling
have only limited access to or knowledge of the underlying
application layers. The only requirement is the possibility The front-end has to manage the mapping between the
for users to provide custom objects based on C/C++ code model specific variable names and the associated value
(or languages with adequate bindings to C/C++) that can references according to the FMI specification. The latter
be embedded within and exchange data with the simulation are used to refer to and access the variables through the FMI
API. In addition, the front-end has to ensure during runtime
environment.
that variables are accessed properly, e.g., prohibiting write
1 See https://fmi-standard.org/tools/.
requests for output variables.
DOI
10.3384/ecp17132321

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

321

external simulation tool

FMI master algorithm

Generic FMI-compliant Simulation Tool Coupling

FMU

FMU

FMU

FMU

front-end

data
manager

FMI adapter

back-end

Figure 1. Schematics of the FMU CS export using the front-end/back-end concept: A simulation tool couples via an internal
component to the back-end. The co-simulation master algorithm uses an instance of the front-end as FMI component. Synchronization
and data exchange between the two ends is handled via a dedicated data manager.

lation component, referred to as the FMI adapter (see
Figure 1). The back-end interface is designed to make the
connection with the front-end as simple as possible, focusing on synchronization and data exchange (see Figure 2).
The adapter has to carry out the following tasks with the
help of the back-end:
2.2.1

Information retrieval

The adapter has to be a part of the model that is loaded in
the external simulator. As such is has to be able to retrieve
and store information about the model it is embedded in
at run-time, most importantly the names and types of the
inputs and outputs that should be shared within the cosimulation.
2.2.2

Establishing the data exchange

Once the names and types of all inputs and outputs are
known, the adapter has to connect to the front-end and
establish the synchronized data exchange. This is done
with the help of the back-end component, which retrieves
pointers to automatically synchronized variables via the
dedicated data management (see Section 2.3 below).
Figure 2. UML diagram of the most important features of the
front-end and back-end components and the classes responsible
for their data management (via shared memory in this specific
case). The function arguments are not shown due to space constraints.

2.1.4

Application handling

The front-end is responsible for starting the external simulation application. It also has to establish a synchronized
communication and data exchange, which is again done
with the help of the dedicated data management (see Section 2.3 below)

2.2

Back-end component and FMI adapter

2.2.3

Data exchange during simulation

The adapter has to be designed such that it knows at which
points of the simulation is has to send/receive data to/from
the front-end. Using the previously retrieved pointers it can
read/write data with the help of the back-end component.

2.3

Data management

The data manager is the crucial link between the frontend and the back-end and handles all issues regarding
Inter-Process Communication (IPC). It is split in two instances (see Figure 2), implementing the purely abstract
interface definitions provided by IPCMaster and IPCSlave, which are intended to be used by the front-end
and the back-end, respectively.

The back-end component functions as counterpart to the 2.3.1 Data handling
front-end component and is intended to be incorporated Both interfaces are primarily designed for handling FMI
within the slave application as part of a dedicated simu- scalar variables (XML type fmiScalarVariable),
322

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132321

Session 6: Poster Session

Listing 1. Implementation of function fmiDoStep(...) according to the FMI 1.0 specification.
1
2
3
4
5
6
7

f m i S t a t u s f m i D o S t e p ( fmiComponent c , f m i R e a l c u r r e n t C o m m u n i c a t i o n P o i n t ,
f m i R e a l c o m m u n i c a t i o n S t e p S i z e , f m i B o o l e a n newStep )
{
FMIComponentFrontEnd  f e = s t a t i c _ c a s t < FMIComponentFrontEnd  >( c ) ;
r e t u r n fe > d o S t e p ( c u r r e n t C o m m u n i c a t i o n P o i n t , c o m m u n i c a t i o n S t e p S i z e , newStep ) ;
}

i.e., variables that are associated not only to a value represented by a basic data type (e.g., fmiReal) but also
to model-related attributes (e.g., name, value reference or
causality). The corresponding functionality is provided via
createScalars(...) and retrieveScalars(...).
In addition, the data manager allows to handle and
access data with functions createVariable(...) and
retrieveVariable(...) for internal communication
between both ends (e.g., size of next time step, boolean
flag for rejecting the next step).
2.3.2

Synchronization

Since the data exchange between both ends has to be synchronized, the data manager is not only responsible for
allocating memory. It also has to have a way to control
the access to the data, in order to prevent non-deterministic
behavior.
This is realized via the functions waitForSlave()
and signalToSlave() for the front-end and the functions waitForMaster() and signalToMaster()
for the back-end. In both cases, variables that were instantiated via the data manager should not be read or written unless the blocking functions waitForSlave() or
waitForMaster() return. Likewise, once a component
is done reading or writing data, it is required to signal
this via signalToSlave() or signalToMaster(),
respectively, and wait again.
2.3.3

Flexibility

The abstract interfaces IPCMaster and IPCSlave have
been designed such that the actual data transfer and synchronization can be achieved in various ways. For instance,
shared memory access or communication via local or network sockets is feasible. In principle, this mechanism could
even be used to build web applications.

3

Implementation

The above concept has been implemented for the FMI CS
specification version 1.0 and version 2.0 as part of the
FMI++ library2 . The FMI++ library is an open-source
software toolbox written in C++ that provides high-level
functionality for handling FMUs. As such it intends to
bridge the gap between the basic FMI specification and
typical requirements of simulation tools. While some of

the functionality offered by the FMI++ library for importing FMUs is comparable to what it is available in other
software libraries (such as the FMU SDK3 or the FMI Library4 ), the implementation of the concept for generic tool
coupling as explained above is unique.
A data manager has been implemented that uses shared
memory access to share data, including semaphores for the
synchronization of both ends, relying on features provided
by the Boost5 library collection. In this case, both ends
of the data management can physically access the same
data. If the co-simulation master and the external application were executed on different machines (distributed
simulation environment) both ends would have to allocate
their own memory and keep their contents synchronized,
e.g., by means of the Message Passing Interface (MPI Forum, 2009).
The implementation of the front-end, the back-end and
the data management are generic, i.e., it is independent of
the external application. FMI adapter implementations obviously depend strongly on the designated application, even
though reasonably sophisticated simulation environments
should offer the possibility to design it model-independent.
Bindings for the generic back-end implementation to FMI
adapters in other languages than C/C++ can be automatedly
created with the help of the SWIG tool (Beazley, 2003).
In addition, a thin layer implementing all functions according to the FMI specification is needed, which calls the
corresponding front-end component functions, see lines 4
and 5 of the code snippet in Listing 1 for an example. Since
version 1.0 of the FMI specification defines the model name
(FMI model description attribute modelIdentifier)
as a prefix to all functions in the final shared library, this
thin layer has to be recompiled for each individual exported
model. However, this does not require any changes in the
source code, as the actual functionality remains unaltered.

4

Examples

The concept explained above is very flexible and can be
used within a broad context of applications. For developing
an FMI adapter, only three requirements need to be satisfied
by any tool:
3 Available

at http://www.qtronic.de/en/fmusdk.html.
at http://www.fmi-library.org/.
5 Available at http://www.boost.org/.
4 Available

2 Available

at http://fmipp.sourceforge.net/.

DOI
10.3384/ecp17132321

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

323

Generic FMI-compliant Simulation Tool Coupling

 Modularity: The targeted tool has to offer a mechanism for including user-defined code (including the
possibility to access memory), in order to define an
FMI adapter.
 Execution control: User-defined code has to be able to
impact the tools execution. This can be achieved either actively (e.g., by accessing methods that directly
control the execution) or passively (e.g., by halting
Figure 3. Schematic view of the functionality of the TRNSYS
the execution through a blocking function).
FMI adapter type in dependence on the simulation step.

 Language compatibility: The language of the userdefined code has to be compatible or have bindings to
an existing front-end/back-end implementation.
In the following, this is demonstrated for two distinct tools.

4.1
4.1.1

TRNSYS FMI adapter
Implementation

TRNSYS (Klein et al., 1976) is a popular and well established thermal building and system simulation environment
that comes with a validated components library. It uses
instances of so-called types to model the individual components of a building or a system. Unfortunately, it does
not provide an API that allows to use it as a slave application within a co-simulation. However, TRNSYS fulfills
all the prerequisites to use the above discussed concept to
implement an FMI adapter that overcomes this limitation:

 Modularity: In addition to providing a rich library
of validated types, TRNSYS also offers the possibility to include user-defined types. Since TRNSYS is
based on Fortran, these types are not object-oriented
components in a strict sense but follow a sufficiently
similar design pattern based on specialized function
calls.6
 Execution control: The overall simulation execution
is steered by the TRNSYS core, which calls the individual instances of the types included within a model.
During these calls the instances are told at which stage
the simulation currently is, especially whether it is the
initialization phase, a standard call during a time step
or the last call of a time step. This information can be
used by TRNSYS types to take actions accordingly.

Figure 4. Example of a simple TRNSYS model containing
blocks of Type6139 for FMU export.

Therefore the implementation of the front-end and backend concept discussed in Section 3 can be used to develop a TRNSYS type that acts as FMI adapter. Figure 3 depicts the internal use of the back-end component
within this type and its interaction with the simulation master. Please note that inputs to the TRNSYS FMI adapter
type are the FMUs outputs and vice versa. Due to the
strict fixed step size simulation paradigm of TRNSYS the
adapter enforces time steps accordingly using the backend components enforceTimeStep(...)function. The
front-end handles this information accordingly and rejects
calls of doStep(...) in case they do not conform. The
model description flag canHandleVariableCommunicationStepSize is set accordingly.
This FMI adapter has been implemented on top of the
FMI++ library and is available online7 . The provided FMI
adapter  referred to as Type6139  can be included within
a TRNSYS model like any other type, with ordinary inputs
and outputs coming from and going to other types. In
addition, the names of the input and output variables have
to be provided (as part of the Special Cards in the types
Proforma) according to the definition that is also used in
the model description. Apart from the additional input and
output block of this type, TRNSYS models are constructed
in the usual way. Given such a model, an FMU can be
generated with the help of a dedicated Python script.

 Language compatibility: Due to the TRNSYS simulation core being implemented in Fortran, userdefined types can be implemented using C/C++. Even
though the ability of Fortran programs to call compiled C/C++ functions is limited, for the task at hand
all conditions are met to establish sufficient interoper4.1.2 Example application
ability.
The example uses a simple thermal model from TRNSYS
6 Basically, every TRNSYS type is implemented as a function. Indi- (see Figure 4) that implements the following first order
vidual simulation components based on the same type are handled via the
same function call, using a unique ID and appropriate memory storage
utilities that allow to differentiate between the instances.

324

7 Available

at http://trnsys-fmu.sourceforge.net/.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132321

Session 6: Poster Session

add

FMI 1.0 CS Import

hysteresis

booleanToReal

B

-1

tRNSYS_Room_Plant_fmu

+
const

not happen at the exact edges of the controllers dead-band
(i.e., at 20.5  C and 21.5  C). Please be aware that this is
not a shortcoming of the FMU itself, but due to TRNSYSs
restriction to fixed simulation time steps. Such simulation
artifacts are unavoidable in fixed-step co-simulation and
have to be taken into account by the modeler (e.g., by
choosing an adequate simulation step size).

R

-0.5 0.5

+1

k=21.0

4.2

MATLAB FMI adapter

4.2.1 Implementation

Figure 5. Dymola model.

Despite the popularity and widespread use of the numerical
computing environment MATLAB, there is so far only comparably little support within the context of FMI. The Modelon FMI Toolbox8 and the FMI Kit for Simulink9 offer the
export of Simulink models as FMUs for Model Exchange,
but so far there is no tool available that allows to provide
MATLABs full functionality via an FMI-compliant cosimulation interface. In the following, a description is
given of how the proposed front-end/back-end concept can
be utilized to solve this issue.

21.6

21.4

21.2

21.0

20.8

20.6

20.4

20.2
0

2

4

6

8

10

12

simulation time in h

Figure 6. Example TRNSYS FMU output.

ODE:
(
Qloss
Troom =
Qheater  Qloss

if heater is off,
if heater is on.

(1)

Troom is the room air temperature, Qloss the difference between losses to the environment and inner loads, and Qheater
is the power of the heating unit. Both Qloss and Qheater are
normalized w.r.t. the thermal capacity of the room air. The
model was exported as an FMU with one input variable
(associated to the on/off signal of the heater, called control_signal) and one output variable (associated to
the room temperature, called room_temperature).
To test its functionality, the FMU was used as a
plant model in a simple closed-loop control system implemented in Dymola, see Figure 5. Depending on
the room temperature provided by FMU output variable
room_temperature, the controller turns the rooms
heating on or off by setting the FMU input variable control_signal to either 0 or 1. More precisely, the model
implements a hysteresis controller that turns the heater on
as soon as the room temperature falls below 20.5  C and
turns it off when it exceeds 21.5  C.
Figure 6 shows the results of the simulated Dymola
model. Depicted is the room temperature as computed by
TRNSYS, which is kept within 21.0  C  0.5  C by the
Dymola controller. Due to the fixed simulation step size
of 15 minutes, the switching of the controller state does
DOI
10.3384/ecp17132321

 Modularity: Since MATLAB is a multi-purpose,
multi-paradigm computing and programming environment, there are potentially many possible ways
to implement an FMI adapter. Within the context of
this work, an object-oriented approach has been chosen that relies on a base class called FMIAdapter,
which provides the full functionality of the FMI
adapter. In order to utilize its functionality, the abstract methods init(...) and doStep(...) have to
be implemented by a derived class.
 Execution control: In contrast to Simulink, MATLAB
defines itself no general notion of time. With the proposed concept, calls to the FMUs doStep(...) function are associated to a call to method doStep(...)
of class FMIAdapter (or rather the class derived
from it). For such a function call, the current communication point and communication step size are
provided as input arguments.
 Language compatibility: MATLAB provides many
ways for interfacing. Within the context of this work,
the SWIG tool has been used to create S-Function
bindings to a generic back-end implementation in
C++ that can be called from within MATLAB. Even
though these bindings can be used directly from MATLAB scripts, it is recommended to utilize their functionality through class FMIAdapter.
The MATLAB FMI adapter has been implemented on
top of the FMI++ library (for Windows with 32-bit MATLAB) and is available online10 . As mentioned above, it
requires to implement the abstract methods init(...) and
8 Available

at http://www.modelon.com/.
at http://www.3ds.com/.
10 Available at http://matlab-fmu.sourceforge.net/.
9 Available

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

325

Generic FMI-compliant Simulation Tool Coupling

Listing 2. MATLAB implementation of the FMI adapter for a simple on/off controller.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22

classdef SimpleController < fmipputils.FMIAdapter
methods
function i n i t ( obj, currentCommunicationPoint )
o b j . d e f i n e R e a l I n p u t s ( { T  } ) ;
obj.defineRealOutputs ( {  Pheat  } ) ;
end
function doStep ( o b j , currentCommunicationPoint, communicationStepSize )
realInputValues = obj.getRealInputValues () ;
T = realInputValues (1) ;
i f ( T >= 90 )
obj.setRealOutputValues ( 0 ) ;
e l s e i f ( T <= 80 )
o b j . s e t R e a l O u t p u t V a l u e s ( 1 e3 ) ;
end
end
end
end

testController_fmu

fixedHeatFlow

prescribedHeatFlow

thermal mass temperature in C

FMI 1.0 CS Import

degC

90

88

86

84

82

80

heatCapacitor

0

2

4

6

8

10

12

simulation time in h

Figure 7. Example Modelica thermal system model.

Figure 8. Example Dymola output.

doStep(...) of class FMIAdapter with the help of an
inherited class, see for instance the example code in Listing 2.
Method init(...) is intended to initialize input and
output variables needed for co-simulation. For instance,
input and output variables of type fmiReal can be initialized with the help of methods defineRealInputs(...)
and defineRealOutputs(...), whose input arguments
are cell arrays containing the associated variable names.
Method doStep(...) is called at every simulation step
(as requested by the master algorithm). During such a
call, methods getRealInputValues() and setRealOutputValues(...) can be used to get input and set
output values for instance.
Since the init(...) and doStep(...) methods may
contain any MATLAB-compliant code, virtually any MAT-

LAB functionality can be made available with the help of
this concept. In order to create an FMU from such an implementation, the dedicated script createFMU.m has to be
called from within MATLAB. Its inputs arguments are only
the intended FMI model identifier of the FMU and the path
to the class file implementing the FMI adapter. Additional
MATLAB files may also be specified, e.g., containing data
or further function definitions.
It is also noteworthy that an FMI adapters functionality can be tested and debugged directly from within MATLAB. Unless explicitly activated, instances of FMI adapters
do not try to connect to a back-end component. In this
state, the input (output) variables defined by calling the
init(...) method can be set before (read after) a call to
the doStep(...) method from within MATLAB with a set
of dedicated methods.

326

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132321

Session 6: Poster Session

4.2.2

Example application

This example uses a simple on/off controller implemented
in MATLAB, to control a thermal system implemented
in Modelica. The Modelica model consists of a thermal
mass that is connected to a constant negative heat flow
(heat sink) and a heater, see Figure 7. The underlying equations of this model are analogous to the previous example,
cf. Equation 1. The temperature of the thermal mass is sent
as input to the controller, which can set the heaters power
output. The MATLAB implementation of the controller
is shown in Listing 2. Method init(...) defines in line 6
an input variable called T, associated to the temperature of
the thermal mass, and in line 7 an output variable called
Pheat, which controls the heaters power output. Method
doStep(...) retrieves the value of previously defined input variable (lines 11 and 12) and sets the values of the
previously defined output variables according to its simple
internal logic (lines 14 and 16, respectively).
To test its functionality, the MATLAB controller was
exported as FMU and imported into the Modelica model.
Figure 8 shows the simulation results. Shown is the temperature of the thermal mass as computed by Dymola, which
is kept within the range specified by the controller implementation.

5

distinct tools, TRNSYS and MATLAB. In both examples
the same front-end, data manager and back-end have been
used, with customized FMI adapters to meet the requirements of the specific tools. With the help of two simple
co-simulation setups the functionality of both approaches
has been shown.
Future work will comprise the extension of the FMI++
implementation to support optional functionality, e.g., handling of input derivatives.

Acknowledgments
Part of this work emerged from the Annex 60 project, an
international project conducted under the umbrella of the
International Energy Agency (IEA) within the Energy in
Buildings and Communities (EBC) Programme. Annex 60
develops and demonstrates a new generation of computational tools for building and community energy systems
based on Modelica and the Functional Mock-up Interface
standard.

References
D.M. Beazley. Automated scientific software scripting with
SWIG. Future Generation Computer Systems, 19(5):599 
609, 2003.

Conclusion and Outlook

T. Blochwitz, M. Otter, M. Arnold, C. Bausch, C. Clau,
H. Elmqvist, A. Junghanns, J. Mauss, M. Monteiro, T. NeidThis work presented a generic approach for FMI-compliant
hold, D. Neumerkel, H. Olsson, J.-V. Peetz, and S. Wolf. The
tool coupling for a broad spectrum of tools. The approach
Functional Mockup Interface for Tool independent Exchange
is based on the concept of a generic front-end and backof Simulation Models. In Proceedings of the 8th International
end, with the front-end being directly accessed by a master
Modelica Conference, 2011.

algorithm as an FMI component. The back-end, which
is synchronized to the front-end via a data manager, is S. A. Klein, J. A. Duffie, and W. A. Beckman. TRNSYS: A
transient simulation program. ASHRAE Transactions, 82:623
associated to the coupled tool. The tool itself interacts with

633, 1976.
the back-end via a dedicated FMI adapter.
The proposed concept has been implemented as part The MPI Forum. MPI: A Message-Passing Interface Standard.
of the FMI++ library according to the Functional MockTechnical Report Version 2.2, Sept. 2009. URL http://
up Interface version 1.0 specification and adapted to two
www.mpiforum.org/.

DOI
10.3384/ecp17132321

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

327

328

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

FMI and IP Protection of Models: A Survey of Use Cases and
Support in the Standard
Erik Durling*

Elias Palmkvist

Maria Henningsson*

Modelon AB, Sweden, Corresponding author: erik.durling@modelon.com

*

Abstract
FMI is increasingly being adopted as a standard for
exchanging simulation models within and between
organizations. Such models often represent significant
investments for the model creator. There is thus a large
interest in protecting intellectual property while
collaborating and sharing simulation models in the form
of FMUs. This paper presents a collection of use cases
and issues related to IP protection of model contents,
that have been identified in interviews with industrial
representatives. The requirements in each use case are
described, along with an investigation of how well the
use cases can be managed within the current version of
the FMI standard, including a proposed extension of the
standard.
Keywords:

1

FMI, IP protection, model exchange

Introduction

The promise of major benefits in model-based systems
engineering and virtual development lies in reusing
models in different contexts. To develop, parameterize,
validate, and maintain models represent a significant
investment, and to maximize the return the models need
to be utilized as much as possible.
FMI is becoming the de facto industry standard for
exchanging models between different tools. Two main
directions in the FMI domain is currently integration and
democratization. Integration means software, processes,
and standards for co-simulation of multiple models from
different
tools
or
different
organization.
Democratization means effort to spread the usage of
advanced simulation models for experts using expert
tools to much larger groups of engineers to use for
design space exploration, boundary conditions for other
systems, or software development and testing.
Both these directions involve exposing models that
often represent significant investments and contain
sensitive data to a larger user base within and outside of
the original organization. The question about protecting
IP (Intellectual Property) is often raised in discussions
about exchanging models between partners with
commercial interests.
Although there exist solutions and best practices for
sharing models with existing technologies, FMI is still a
new standard, and there is a general need for knowledge
DOI
10.3384/ecp17132329

about applying similar solutions with FMI (Khler et al.
2016). One of the arguments for using FMI is that it
allows protecting the internal contents of models. But it
is important for the part sharing a model to understand
what is exposed, and what measures that can be taken to
protect what should not be shared.
The purpose of this study has been to make an
inventory of use cases and concerns related to IP
protection of FMUs, and to evaluate to what extent this
is supported by the current standard. This overview can
be of interest for users who need to understand the risks
and mechanisms for exposing and protecting the content
of their models.
The study also intends to raise the need for a
standardized way of managing IP protection
mechanisms of FMUs, or at least to provide information
to the model importer about embedded mechanisms to
restrict execution of the model.
The paper starts by outlining how the listed use cases
were elicited. The list of use cases is presented in
Section 3. An evaluation of how well the use cases are
supported by the current (2.0) FMI standard is found in
Section 4.

2

Methodology

The study was carried out in two phases. During the first
phase, information was gathered about the needs that
exist for protecting IP when sharing models within the
general area of model based systems engineering.
Interviews were carried out with 16 engineers at
Modelon and Volvo Car Group, with experience of
sharing models within automotive, energy and
aerospace industries. The interviews were typically with
a single person at a time, and lasted in the range of 30 to
60 minutes. To obtain unbiased information, open
questions were asked to let the stakeholder present their
own view of the issues they found important. The
questions concerned exchanging models in general, and
not specific to the FMI standard.
In addition to the interviews, an anonymous online
survey was sent out to additional external stakeholders.
The purpose of this survey was mainly to obtain an
impression of the importance and priorities among the
identified use-cases. The survey also included specific

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

329

FMI and IP protection of models: A survey of use cases and support in the standard

questions to identify experience and concerns specific to
the FMI standard.
During the second phase, the FMI-standard was
evaluated in terms of each of the use cases that had been
identified. The following questions were considered
when evaluating the standard:
 Is the use case relevant to be considered within the
scope of the standard?
 Is there any support for the use case within the
standard?
 Are there any obstacles or gaps within the standard
that prevents solutions for the use case from being
implemented?

3

Use Cases: Needs for Protecting IP
When Sharing Models

This section describes the different use-cases that have
been identified in this study, following a short summary
of the roles involved.
The question of IP protection is typically considered
when models are to be shared between different
organizations with commercial interests. The purpose is
to protect valuable or sensitive knowledge or data from
being accessed by someone who is not trusted. The need
for protection generally comes from the part sharing
(exporting) the model, but there are issues related to this
that may affect the receiver (importer) of the model.
A common scenario is that a component supplier
delivers a component model to an OEM (Original
Equipment Manufactory). This component model is
integrated by the OEM as part of a system model. The
opposite also occur, where the OEM supplies a system
model, to let the supplier test their component as part of
a system environment.
There are also situations where there is a need to
protect models that are shared inside the same
organization. Reasons for this can be to maintain control
over what models are being used in the organization.
Another reason can be to prevent potential leaks by
limiting access to sensitive information. This situation
could also apply during projects with external partners,
where the information is not secret to the people in the
project, but there is a need to protect the information
from being shared outside the project.
In general, the main concerns regard export of
models. This mainly covers two main issues: hiding the
model content, and controlling who can use the model.
But protecting the models can also lead to challenges for
the receiver of the model, in terms of usability, that need
to be considered.

3.1 Use Case 1: Protect Model Contents
The basic use case is that the part who shares a model
would like to hide what is inside from the receiver. The
sharing part needs to export the model in such a way that
the contents are protected. There are a number of aspects
330

that may be valuable or sensitive and needed to be
protected.
3.1.1 Model Structure

There is often a need to protect the structure or design
of the model. This consists of equations and algorithms
that describe the relationship between inputs and
outputs.
The model may be implemented using unique
methods for describing the specific component.
Examples of this could be algorithms, or representations
of equations, or clever ways to select dynamic states.
This can make the model design valuable in itself.
The model could also represent unique knowledge
about the component that is modeled, and could reveal
sensitive information about the actual component design
and properties.
Some models might be created to support multiple
application. In this case, information about the other
types of application that is supported might be sensitive.
It could be that the receiver should only have access to
information that concerns their specific application.
3.1.2 Internal Variables

Internal variables (or signals) may reveal sensitive
information about the inner workings of a model, and
could facilitate reverse engineering.
The names of the internal variables could also be
sensitive and reveal information about the model
structure and design, or ways to apply the model that the
receiver should not be aware of.
3.1.3 Parameters

Values of internal design parameters, boundary
conditions and start values, may reveal information that
would not be available to a user of the actual component
or system that the model represents. This data may be
the result of expensive research, and considered
valuable knowhow that a supplier is reluctant to share.
Parameter names may also reveal information about
model structure, in the same way as internal variables. It
could also be that the parameter values are only sensitive
with a specific parameter name. Generic parameter
names may not reveal any useful IP.
3.1.4 Black Box or Grey Box

The simplest approach is to hide everything inside the
model (black box), which may be sufficient in some
cases. However, in many cases it is necessary to expose
parts of the model contents (grey box), in order to make
the model usable. In this case, the exporter typically
would like to expose only the sub-set of the content that
is necessary for the receiver to have access to.
For example, exposing part of the model structure or
internal variables could aid in simulation debugging.
And some parameters may need to be tweaked in order
to use the same model for multiple scenarios.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132329

Session 6: Poster Session

3.1.5 External Dependencies

A model could contain external dependencies, for
example parameter files or additional model libraries.
These parts could contain IP that may not be covered by
the protection applied to the main model, and may
require specific consideration.
3.1.6 Reverse Engineering

Sharing a model always comes with a risk of reverse
engineering, either of the model itself or the component
that the model represents. The only way to be
completely protected against this is to not share any
model. The required level of protection against this
depends on the value of the model contents and the risk
of the contents being revealed. A common strategy of
handling this is to make sure that the cost of reverse
engineering is higher than the value of the contents.

3.2 Use Case 2: Limit Access to Users
A common scenario is that only a set of expected users
should have access to a model, for example to maintain
control or prevent reverse engineering. A model could
contain information that should not fall into the wrong
hands, or be used for applications other than the
exporters intention.
3.2.1 Limit Access to Specific User(s)

There are many scenarios where a model is only meant
to be shared with a limited number of users, or different
users should have different level of accessibility to the
model. It is common that the right to use a model is
given to a single organization by a partner. In sensitive
cases, some models may even be restricted to specific
groups within an organization, to minimize the risk that
it ends up in the hands of the wrong people, for example
a competitor. There are also commercial scenarios. For
example, a model library may be sold for use on a single
computer only.
Models exported from some tools may be restricted
to users who have a license for the exporting tool. Such
limitations may represent a big obstacle for some
scenarios of model sharing. It may not be feasible for
users integrating models from many different sources to
have a license for all the tools. This could also be a
problem when an exported model need to be deployed
to a large group of end-users, since the licensing fee
would become unreasonable. Some OEMs have also
expressed concerns that licensing solutions on exported
models could lead to vendor lock-in.
3.2.2 Limit the Model Over Time

There are also scenarios where one would like to limit
the model access to a specific time frame. A reason
could be that the model could contain information or be
used for applications that is only relevant during a
limited time, and the use of the model may even be
contracted between the two partners. This could for

DOI
10.3384/ecp17132329

example be during the course of a specific project, or
during a trial period of a commercial model library.
Having a time limitation on a model could also be a
benefit when it is being developed and need to be
maintained over time, since it reduces the risk that an
old version of the model is used.
The time frame could differ depending on the use
case, from a couple of days for a sales demonstration, a
few months between model release versions, or during a
project that last for years.
3.2.3 Information About the Protection

Models with limited access pose a challenge from the
model receivers perspective. Without sufficient
information about what type of protection is applied,
debugging could be difficult when the user or the
importing tool should identify that the model is not
working due to this protection.
This is especially important for a user working with
aggregates of models from multiple model suppliers,
where there may be number of different types of access
limitations that need to be managed. The workflow for
these users are improved if it is possible to easily
understand how each model is restricted and what is
required for getting access to it.

3.3 Use Case 3: Provide Information to the
Model Importer
When parts of a model are hidden, or protected, there is
an increased need for information to keep the model
useful.
3.3.1 Documentation

For a model with hidden contents, the user must rely on
the documentation for information on how to use the
model and what results to expect. It can be crucial to
understand what aspects of the physical systems are
modeled and at what degree of accuracy, especially
when integrating the model as part of a larger system, or
to understand simulation results. This could dictate what
parts are needed outside the model and how to interpret
the interface. It may also be difficult to determine what
range of operating conditions the model is valid for,
since it likely is not obvious what simplifications or
assumptions have been made. In general, it is important
that both parts have agreed on the interface of the model
inputs and outputs.
3.3.2 Debugging

It can be very challenging to debug a model without
knowledge about how it is constructed, without the
ability to measure internal variables or to get usable
error messages. This can be a challenge also when using
the model as part of a larger system. The user may have
to rely on support from the model supplier for solving
the issues. This could also pose a challenge for OEMs
that need to be able to trace issues found in simulation

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

331

FMI and IP protection of models: A survey of use cases and support in the standard

results back to the source model, many years after the
results were produced.
3.3.3 Network Dependencies

Some protection solutions may require the model to
communicate with remote network resources, for
example to gain access to using the model or to
exchange results with a simulation server. Information
about these dependencies and adequate error messages
can be important for helping the user identify any issues
related to this.

3.4 Use Case 4: Binary Platform Support
and Source Code
There is a conflict between protecting a model from
reverse engineering while at the same time allowing the
model to be used on multiple platforms (different
operating systems or processor hardware). Exporting a
model in a compiled binary format is a common way to
protect the sensitive content. However, this will limit the
model to the specific platform that the binary is
compiled for. To support multiple platforms, the
solution is often to export the model as code (commonly
C-code) and let the receiver compile the model on the
specific platform. While binary export is often
considered sufficient protection against reverse
engineering, c-code is generally not considered
sufficient, since this is more easily interpreted by a
human. Solutions for this could place requirements both
on the exporting and importing tools.
It is important to note however, that the content of a
binary also can be interpreted, while the effort to do so
is generally much higher than doing this for higher level
source code.

3.5 Knowledge Need
A general need for knowledge about the IP-risks specific
to FMI was identified during this survey. When
exporting a protected model that contains IP, it is
important for the exporter to understand what is exposed
when the model is exported, and what risks may need to
be avoided. This will help making correct decisions
about what measures need to be taken, but is also
necessary for the exporter to feel trust in the solution
used.
It is worth noting that new technologies have a startup phase in general, where potential users will be
naturally skeptical before information about the
technology is widely known, and best practices have
been established.
It may also be important also for people that are only
working indirectly with models understand how the
risks are handled. For example, a lack of knowledge
about the technology could represent an obstacle in and
negotiations about sharing models between partners. A
wider acceptance may be needed among all affected
parts of an organization before it is regarded as safe.

332

3.6 Use Case 5: Authentication
Authentication concerns the need to ensure the integrity
of a model. This question is not mainly about hiding
content, but instead of protecting it from being changed.
Although, it is sometimes discussed in relation to IP
protection, since the challenges is somewhat related.
Some of the common needs are:
 Verifying that the model comes from the expected
source.
 Verify that the model has not been altered after it
was exported. This could be important in order to
provide reliable support as a model supplier, or
when the model is deployed in safety critical
systems.
 Verify that the model is compatible with some
external dependencies, for example that the specific
version of a model is used together with the
corresponding version of parameter data.
Authentication plays a role both as a sanity check to
avoid mistakes, but also as a means of protecting against
intentional intrusion.

4

Support for Protecting IP Within
the FMI Standard

This section describes how and to what degree the use
cases described in Section 3 are supported by the FMIstandard. Some examples are used to demonstrate how
the standard supports certain use cases.

4.1 The Content of an FMU
An implementation following the FMI-standard is
called an FMU. This section describes what parts of a
model is exposed when being packaged as an FMU. An
FMU is a zip-file, with a certain file structure, that
contains the following parts:
 The model description XML-file:
Contains meta information about the model that will
be exposed to the simulation tool and user.
 Binaries:
This is the actual implementation of the model,
compiled for a specific (or multiple) target platform.
This binary exposes the standard FMI API
functions, for reading and writing variables and
performing simulation time steps.
 Source code:
C-source code for the model can be provided as an
alternative, or in addition, to a model binary.
 Additional data/resources:
This could be data stored in any format as a resource
in the FMU. This would typically be parameter data.
It is also possible for an FMU to access external
resources outside of the FMU itself.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132329

Session 6: Poster Session

The FMI standard specifies the format of the model
description XML-file, the API function interface of the
binaries or source code, and the structure of the zip-file.
The FMI-standard allows two different type of
models, one that contains a solver to simulate the model
(Co-Simulation or CS-FMU) and one that requires an
external solver to simulate (Model-Exchange or MEFMU). The functions and exposed content differ
somewhat between the two FMU flavors.
4.1.1 Content in the Model Description XML File

The model description XML-file contains necessary
meta information to the user and simulation tool, in
order to make the model useful.
The information required to be included is the type of
FMU, name of the model, and a GUID (Global Unique
Identifier).
In addition to this, XML-file is required to contain
tags for model variables and model structure, which will
contain a set of variables that are exposed. But there is
no requirement from the standard that all model content,
in terms of variable names or values, should be exposed
in the model description XML-file.
In practice, at least the top level input and output
variables are exposed. The model description could also
contain references to all, or a subset, of the internal
model variables and parameters. But it is up to the
exporting tool whether all variables should be exposed,
or none (black box) or a sub-set (grey box), and also
what names to give the variables.
For the exporting user, it could be very helpful to get
clear information from the exporting tool about what
variables are exposed. Although this information is
available in the xml-file, it can be very impractical to
obtain the information by reading the file directly,
especially for large models.
The variables defined in the model description file is
a mapping between variable names and variable
references. The variable reference (a number) is used to
access the variable value with the FMI function calls in
the binary or source. It is possible to include variables in
the binary/source, that can be accessed by reference (a
number), without having any mapping to a variable
name in the model description file. This allows for
secret variables. This also allows for defining
anonymous variable names, that do not reveal any
sensitive information about what the variables represent.
In order to avoid algebraic loops when using the
FMU as part of a system, it could be necessary to
provide a list of outputs and the variables that the
outputs depend on to the importing tool.
Additional information can be included in the model
description file that is typically not sensitive, like the
exporting tool or experiment settings.
4.1.2 FMU Binaries

The FMU binaries typically represents a compiled
implementation of the whole model. As discussed in
DOI
10.3384/ecp17132329

Section 3.4, compiling a model as a binary is commonly
considered sufficient protection of the model
implementation. It is however up to the exporting tool
to ensure that what is stored in the binary is not exposed
in an open way.
An FMI binary is only required to expose the FMI
API functions. These will provide access to values of at
least the variables defined in the model description file.
For an ME FMU, it will also be possible to access the
values of each of the internal (continuous time) state
variables, their derivatives, and any event indicators.
But the names of such internal state variables will not be
exposed.
The FMI-standard provides support for logging, so
that the FMU can generate messages for warnings and
errors to the simulation environment. The message
generated from the FMU, using the logging interface,
could depend on hardcoded messages that might include
internal model information (like variable names and
values) that is not exposed in the model description
XML-file. The standard allows using variable
references when logging, which will avoid exposure of
hidden names, but could still expose hidden value
references and their values. It is up to the exporting tool
to ensure that such internal messages are not exposing
sensitive model content.
One way to support multiple platforms is to include
multiple binaries in the same FMU. This may be an
option if it is not possible to provide source code for the
model (as described in section 4.1.3). This requires that
the exporting tool is able to compile or package binaries
supported by all different platforms. FMUs for multiple
platforms could be supported through cross-compilation
or with tools for merging multiple binaries into the same
FMU. Note that the model description needs to match
all of the binaries (including the GUID).
In some cases, the FMU binary just represents an FMI
gateway, as an interface to an external application or
interface (like another simulation tool or network
sockets).
4.1.3 FMU Source Code

An FMU could include the source code for the model,
in addition to, or instead of, the binaries. This is a way
to allow the model to be compiled to a general target
platform, to avoid supplying a binary for each platform
where the FMU is to be used. Many suppliers are
however reluctant to provide source code for their
models, since this exposes the implementations of the
models in a more open way than compiled binaries do.
Depending on how the code has been generated, this
may expose algorithms, parameters, and model
equations that represent valuable IP.
A common way to deal with this is to apply code
obfuscation, which makes the code very difficult to read.
The effort of reverse-engineering would be similar to a
compiled binary.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

333

FMI and IP protection of models: A survey of use cases and support in the standard

4.1.4 External Data in an FMU

An FMU may contain additional resources. This would
typically be parameter files. This means that even if
internal model parameters are not exposed through the
FMI interface and model description, parameter data
could still be openly readable through these resource
files. To avoid exposing sensitive data, it could be
necessary to apply encryption or some form of
obfuscation of these resources.
An FMU can contain external dependencies for example
to facilitate parameterization. The standard allows the
FMU to contain additional data such as files with data
tables. But the FMU is also allowed to access and use
external files not included in the actual FMU.
The FMI-standard only specifies the communication
interface between the model and the simulation tool.
Access to external data is not covered by the standard.
Handling of external data files needs to be considered
separately, to avoid unintentional exposure of sensitive
data.

4.2 Limit Access to the FMU
The purpose of limiting the access to the FMU is either
to restrict the usage of the model or restrict the access to
the content in the FMU. Reasons to protect the FMU is
discussed in section 3.2.
There is nothing included in the FMI standard that
either specifies or restricts how to limit the access to the
model binary or source code. This means that it is
possible to include any protection mechanism in the
source code or binaries of the FMU.
4.2.1 Examples of Access Protection

Common examples of protection that could be applied
are:
 Server Solutions: Only share access to the interface.
The model content is protected on the server. The
user can only access the FMI function calls. This
type of solution will effectively protect the model
files from unintended distribution and reverse
engineering.
 Encryption: The main reason for encryption is to
prevent the wrong user from accessing the model. In
general, the model is exposed once it has been
decrypted. There are many variations of workflows
and encryption solutions, for example licensing of
the decryption and password protected zip-file.
 Licenses: This can be applied to ensure that the
model can only be used for a certain time, or to
restrict the model to only be used by a given group
of people. This licensing protection would be
integrated into the binaries and will thus not protect
the content of the XML-file.
 Limitation over time: The binaries can be generated
to only work during a restricted timeframe. This is a
way to protect the model from being executed. But
334

it does not protect the content of the model
description XML-file.
4.2.2 Information About Applied Protection

In section 3.3, the importance of the available
information to the recipient is discussed. The FMI
standard does not specify a way to provide information
to the model receiver about the type of protection
applied or requirements for accessing the model. It is up
to the exporter to inform the receiver, either in or outside
the FMU. The standard also does not define any
requirements or interfaces for protecting the access to an
FMU.
The model description xml of FMI 2.0 may contain
an optional flag that describes information about the
intellectual property licensing. This provides
information about how the FMU may be used, but not
how it is protected in terms of technical licensing.
One proposal is to extend the standard with
information about the type of technical licensing that is
applied to an FMU. This could be added in the form of
new attributes in the model description XML:
"protection-type" and "protection-trigger", and an
additional
function
in
the
header
file
"fmi2checkProtection". The "protection-type" attribute
should contain information about what type of
protection the FMU has, like "license-file", "time" etc.
The "protection-trigger" contains information about
how the protection is triggered, like "instantiation",
"initialization", "2017-01-01" (for protection over time).
To check if the FMU can be used at the current state, the
function fmi2checkProtection can be called to perform
a "validation check".

4.3 Authentication
Use cases concerning authentication were discussed in
section 3.6. Authentication is not covered specifically in
the current standard. However, implementation of
authentication solutions in the model (binaries/sources)
does not necessarily require any specific support from
the standard. Two examples are given to demonstrate
how the use cases can be implemented without specific
support from the standard:
 Verify the source of the FMU: To verify that the
FMU comes from the correct source, the checksum
of the FMU could be digitally signed by the
exporter, and provided in addition to the FMU. The
signed checksum could then be used by importing
tool to verify the integrity of the FMU.
 Verify that the XML has not been altered: The
modelDescription.xml is most likely part of an
FMU to be altered. It would be possible to include a
function in the model binary that calculates and
verifies the hash of the XML, and prevents the
model from running if this is different from
expected.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132329

Session 6: Poster Session

5

Acknowledgements

Conclusions

We have presented a survey of common use cases and
concerns regarding IP protection when sharing models,
and we have discussed to what extent this can be
addressed within the current FMI standard.
The most common use cases concern export of
models, mainly in terms of having control and
information of what is exposed of the model content, as
well as limiting access to unintended users. But there are
aspects of this that also affect the importer, mainly in
terms of usability and platform support.
Furthermore, a general need for knowledge
dissemination was identified, regarding the risks and
mechanisms of protecting the model content, specific to
the FMI standard. One purpose of this article has been
to address this need.
No obstacles were identified within the standard. All
of the use cases described can be managed within the
standard. Tools that export FMUs are free to include any
conceivable solution for restricting the execution of the
binaries, and are free to exclude all sensitive information
from the model description file.
A risk for the model exporter is that sensitive
information may be exposed in unintended ways, like
through the logger, or through external dependencies
not controlled by the standard at all.
For most use cases, it is more a question of support
by the tool rather than support by the standard. The
amount of information that is exposed depends a lot on
the tool and specific export settings.
This leaves much freedom for tool vendors and model
exporters, which can translate to challenges for model
importers. The lack of standardized ways of imposing IP
protection on models can make it difficult to deal with a
multitude of different licensing or encryption
mechanisms. Without a standardized interface it is hard
to troubleshoot issues related to licensing issues. We
therefore propose for a future version of the FMI
standard to add an optional flag in the model description
XML scheme to provide information about embedded
protection that will limit execution.

DOI
10.3384/ecp17132329

This study was carried out within the research project
Second Road Phase 2, coordinated by Volvo Cars
Corporation and funded through the Swedish research
agency VINNOVA. Time and input from all
interviewees is gratefully acknowledged.

References
FMI for Model Exchange and Co-Simulation, Version 2.0:
https://www.fmi-standard.org/
Khler J., Heinkel H.-M., Mai P., Krasser J., Deppe M.,
Nagasawa M. Modelica-Association-Project System
Structure and Parameterization  Early Insights. The First
Japanese Modelica Conferences, May 23-24, Tokyo, Japan,
2016. doi: 10.3384/ecp1612435
Khler J., King J., Kbler M. Simulation of Complete Systems
at ZF using Modelica Standards, The First Japanese
Modelica Conferences, May 23-24, Tokyo, Japan, 2016.
doi: 10.3384/ecp1612424
Smart Systems Engineering project of the iViP Association:
http://www.prostep.org/en/projects/smart-systemsengineering.html

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

335

336

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Model-based virtual sensors by means of Modelica and FMI
M. Gonzlez1,2
1 IK4-Ikerlan
2 KU

O. Salgado1

J. Croes2,3

This paper presents an application case for the estimation
of forces using Modelica and the FMI. For that purpose
model-based virtual sensors are used. These techniques
are presented and the development of the virtual sensor for
Modelica and the FMI is discussed. The work has been
done in Python where the package pyFMI is used with
models exported with the FMI 2.0 for model exchange.
The technique is used for the estimation of forces and the
friction coefficient in a vertical transportation system. The
model of this test bench is explained and the results of the
estimation of forces and the friction coefficient are discussed. These estimations provide a valuable tool for the
condition monitoring of guiding systems.
Keywords: FMI, virtual sensors, pyFMI, Extended
Kalman Filter

Introduction

The condition of the guiding system influences significantly the riding quality and performance of transportation systems such as railways or elevators. The proper
design and the correct maintenance of the guides is therefore of high importance. Both the design and monitoring
of the guiding system require an accurate assessment of
the loading condition. However the direct measurement
of forces is not feasible, as a dedicated sensor is too costly
and intrusive. Virtual sensors are an attractive option to
overcome these difficulties.
Virtual sensors process available measurements to estimate other variables of interest that cannot be measured.
Mainly two virtual sensor approaches are suggested in the
literature: data-driven methods and model-based methods.
Data-driven methods use a machine learning perspective
to recognize patterns in the behavior of the system. These
methods require previous observations of the system in order to learn the different states and conditions of the asset. A review of data driven virtual sensors can be found
in (Kadlec et al., 2011). Some common approaches include developing autoregressive models of the system as
in (Samara et al., 2013), using artificial neural networks
((Bizon et al., 2014),(Gonzaga et al., 2009)) or using moving window methods as in (Liu et al., 2009). The required
data training may be a handicap in systems where data
cannot be acquired continuously or in which faulty conditions cannot be measured.
DOI
10.3384/ecp17132337

W. Desmet2,3

Technology Research Center, Control and Monitoring Area, Spain
Leuven, Department of Mechanical Engineering, Belgium
3 Member of Flanders Make, Belgium

Abstract

1

B. Pluymers2,3

On the other hand model-based methods combine
physics-based models and measurements of the system
by means of estimation algorithms. The model provides
knowledge of the dynamics of the system, which in combination with off-the-shelf sensors can be used to estimate
variables of interest otherwise difficult to measure. These
approaches are valuable tool in several applications such
as control techniques, condition monitoring or model updating (Isermann, 2005).
The performance of these techniques depends on the
capability of the model to accurately represent the physics
of the system (Isermann, 2005). In addition a great modeling flexibility and simplicity is required to avoid errors
and speed up the process. Using Modelica has thus a
great added value in the development of model-based virtual sensors. The acausal nature of Modelica allows efficiently modeling heterogeneous systems reusing already
developed and tested models. However, it doesnt allow
the user to manipulate the solution at each time step, as
required by estimation algorithms. In order to use Modelica for state estimation the models have to be exported and
manipulated at each time step (Brembeck et al., 2011).
Several modeling environments include model exchange capabilities. However, they are usually developed
ad-hoc to interface with one particular tool in a certain
context. Therefore they are commonly limited to certain
tools and are version dependent. The Functional Mockup Interface (FMI) is a tool independent standard that can
efficiently solve this. Furthermore the FMI 2.0 includes
some features that aid the development of state estimation
algorithms (e.g. directional derivatives).
The combination of Modelica with other programming
languages by means of the FMI provides thus a suitable
approach for the implementation of model-based virtual
sensors. The main focus of the FMI is simulation, but it
has already been applied for estimation. For instance in
(Brembeck et al., 2011) and (Brembeck et al., 2014) is
used to implement nonlinear state observers within Dymola. In (Bonvini et al., 2014) an Unscented Kalman Filter (UKF) is implemented in Python using the FMI 1.0 for
model exchange and is used for Fault Detection and Diagnosis. In this paper the FMI 2.0 for model exchange
is used to develop an Extended Kalman Filter (EKF) for
state and parameter estimation in Python. The suitability
of Modelica and FMI for state estimation is tested with a
highly nonlinear model which includes events, rotations

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

337

Model-based virtual sensors by means of Modelica and FMI

and friction.
The rest of the paper is organized as follows. Section 2
gives an overview of Model-based virtual sensors and explains the algorithms used in the current application. Section 3 explains how these algorithms are implemented using pyFMI with the FMI 2.0 for Model exchange. Section
4 describes the proposed application case along with the
proposed model, a test bench of a vertical transportation
system where contact and friction forces are estimated.
The results of these estimations are shown in section 5.
The final conclusions and the future work are drawn in
section 6.

2

Model-based virtual sensor approaches

equivalent discretization such as Euler or Runge-Kutta.
xk = Fk1 .xk1 + Gk1 .uk1 + wk1
yk = Hk .xk + vk

(2)

The KF algorithm is shown in figure 1. In each k-time
step the system model is evaluated and compared against
measured data. This is done in two steps: prediction and
update. In the prediction step an a-priori estimation of
the states mean and covariance is obtained from the systems model. In the update step this a priori estimation is
corrected using the systems output. This estimation process is done recursively: all the prior information is summarized in the initial mean and covariance of each step
(x0+ , P+
0 ). Therefore the computational effort in each time
step is the same regardless the number of measurements.

The core of model-based virtual sensors consists on the
use of state estimation algorithms. These algorithms use
the difference between the real measurements and the prediction of a physics-based model to correct the output
of the model. The most common state estimation algorithms are the Luenberger observer (LO), the sliding
mode observer (SMO) and the Bayesian estimators. LO
and SMO are simpler to implement than Bayesian estimators but under noisy measurement conditions the Bayesian
algorithms are proved to perform better (Zhang et al.,
2009),(Esteban et al., 2016). Thus the presented work is
focused only on Bayesian estimators.

2.1

Kalman Filter

The Kalman Filter (KF) is the optimal linear estimation
filter (Simon, 2006). In the case of Gaussian noise, it provides the maximum a posteriori estimate with the smallest
achievable covariance. With non Gaussian noise, it is optimal in giving the minimal mean square error. It is the
most widely used Bayesian estimator and has been successfully used in a number of applications (Simon, 2006).
The KF uses a linear model defined in state space form as
the one shown in equation 1. In the stochastic Bayesian
derivation of the KF, both the process and measurement
equations are assumed to be disturbed by zero mean white
Gaussian noise (w and v in equation 1) of covariance Q
and R respectively. The states are assumed to be Gaussian
variables with a covariance P and mean the state estimation (b
x  N (b
x, P)).
x = f (x, u,t) + w
y = h(x, u,t) + v

(1)

The most common formulation of the KF requires the dynamic system of equation 1 to be described in a discrete
form of equation 2, where for a linear model the matrices F,G and H are constant. Generally the discretization
of a state space model assumes a zero-order hold for the
input u and continuous integration for the noise v. As explained in (Simon, 2006) the discretization involves the
computation of the integral of a matrix exponential or any
338

Figure 1. Kalman Filter algorithm

Despite being widely used, the KF is limited to linear
systems, which also makes the joint estimation of states
and parameters not applicable (Simon, 2006). Several
suitable extensions of the KF to non-linear systems, such
as the EKF or the UKF can be found in (Simon, 2006). As
the current system is highly nonlinear (events, rotations)
the well known Extended Kalman Filter is used instead.

2.2

Extended Kalman Filter (EKF)

The EKF is the most widely used extension of the KF for
nonlinear systems and for the joint estimation of states and
parameters. If the model of equation 1 is nonlinear the
Fk1 and Hk1 matrices of equation 2 are no longer constant, but change at each K-step instead. Then the EKF
linearizes and discretizes the model around the KF estimate, propagating a linear approximation of the covariance (Simon, 2006). The standard KF shown in figure 1 is
then applied at this linearized point. As the estimation is
based on the linearization of the system a small step size
is required if the system is highly nonlinear. On the other
hand, the ease of implementation and the reduced computational cost of the EKF make it an attractive option for
the estimation of states in nonlinear systems.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132337

Session 6: Poster Session

2.3

Parameter identification and Virtual Sen- requesting directional derivatives is particularly useful in
the development of the EKF as they are more reliable than
sors

State estimation algorithms can be augmented to estimate
not only the states of the system but unknown parameters too. Based on the continuous state-space system representation, an augmented version of the system can be
obtained if the unknown parameters are included in the
states vector (equation 3) and their directional derivatives
are included in the system matrices (equation 4). Then a
random walk model is used for the unknown parameters:
they are assumed to remain constant except for an additive
noise (Naets et al., 2015) (equation 5). The discretization
of these matrices can later be done in the same way as for
the non-augmented model.
 
x
aug
x =
(3)
p


A =

x

f
p

0

0

 f



p(t) = 0 + w p (t)

(4)

(5)

The joint estimation of parameters makes the system nonlinear. Once defined in the proper way, this augmented
vector can be estimated by means of the EKF or any other
nonlinear filter.
Once all the states and parameters of the model are
known, we can use the model to obtain some other variables of interest (i.e. a virtual sensor). This is a postprocessing step in which the model is evaluated in the estimated set of states, parameters and inputs and the variables of interest are treated as another model output. By
means of the estimated state covariance the degree of uncertainty of the virtual sensors can be estimated as well
(equation 6).
PV S =

 f (x, u)
 f (x, u)
.Px .
V S
V S

numerical derivatives.
There are several FMI libraries aimed at programming
languages suitable for the development of state estimation
algorithms. In this work pyFMI is used, which has the
advantage of being open-source. Thus the presented Extended Kalman Filter is written in Python. In addition to
pyFMI, which allows the simulation of FMUs, Python offers several other scientific computing packages that aid
the development of custom made algorithms and applications (e.g. Numpy, Scipy, Matplotlib).
To make models compatible with the EKF, the inputs
of the filter also have to be defined as inputs in the model,
while the measurements of the system have to be defined
as model outputs. Estimated parameters are simply defined as parameters, and the newly estimated value of the
parameter is set in the model at the beginning of each step.
In addition, care must be taken when modeling, so that the
states of the model agree with the expected ones during
the whole estimation.
As explained in section 2.1, the first step of the

Kalman Filter requires the prediction of the model xk+1
=
+
f (xk , uk , k). To get this prediction the model is initialized
with the states and parameters estimated in the previous
step and is simulated from the current step to the next one.
In addition to setting the new states and parameters, in
models with events these have to be updated after setting
states and parameters. To reduce the computational time
the results are handled in memory.
For the second step of the filter the EKF requires the
matrices of the system in state space form, i.e. the system
has to be linearized before it can be used with the estimation algorithm. To achieve this the FMI functionality of
obtaining the directional derivatives of the system is used.
This function is directly implemented in pyFMI and thus
obtaining the system matrices is straightforward:
A, B,C, D = model.get_state_space_representation()

(6)

The same is not true for the directional derivatives of
the parameters, required for the estimation of parame3 State and parameter estimation ters along with states (section 2.3). As the FMI does
with Modelica and FMI 2.0 for not provide directional derivatives for model parameters,
these derivatives are computed numerically according to
model exchange
the symmetric difference quotation shown in equation 7.
This section explains the implementation of an Extended

f (x + h)  f (x  h) 
Kalman Filter that uses physics-based models developed
(7)
f(x) =

2h
in Modelica and exported by means of the FMI 2.0. The
h0
model used for this work is developed in OpenModelica
as it provides a powerful model editor that facilitates the 4 Application for the estimation of
development of models and has the advantage of being an
forces in guiding systems
open-source tool. The posterior translation of the Modelica models to FMUs is done by means of JModelica.org. The proposed application case is the guiding system of a
This tool provides full functionality to export models for vertical transportation system. T-shaped guiding rails are
model exchange with the FMI 2.0, including the possibil- used to minimize horizontal motion ensuring travel in a
ity of requesting directional derivatives. The possibility of uniform vertical direction (Janovsky, 1999). Inappropriate
DOI
10.3384/ecp17132337

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

339

Model-based virtual sensors by means of Modelica and FMI

installation of these guides and their surface roughness are
the main causes of vibration in the car frame (Janovsky,
1999). These guides are usually composed of several rail
segments aligned together. The proper alignment is, however, extremely difficult, and in general out of plane or
out of angle misalignment are common. Such deviations
increase the contact forces and induce abrupt forces in the
car frame at the rail segment joints, reducing the ride quality and efficiency of the system.
The interaction between the car frame and the guiding
system is given in four discrete contact points, by means of
so-called sliding shoes. These sliding shoes are U-shaped
polymeric pads that grab the guide rails web. The contact
forces of the guiding system are applied in these shoes
both in x and y axis. Forces in x axis may be in the positive or negative direction, whereas forces in y axis are
only directed towards the car-frame. A scaled test bench
of a vertical transportation system available at IK4-Ikerlan
is used to validate the methodology. This test bench is a
useful tool to study the behavior of such systems using
sensors not available in real installations. Additionally
it allows us to study the effect of defects that we could
not put in a real installation. The test bench is a scaled
rucksack type rigid car frame, traveling in vertical direction and constrained horizontally by two T-shaped guiding
rails (see figure 2). The system has 12 states corresponding to the 6 degrees of freedom of this car frame (x, y, z,
roll, pitch and yaw). Without loss of generality, the driving force (T ) is assumed to be known and acts as a system
input. In the scaled test bench under study this force is
measured with a load cell attached to the driving cable
(see figure 2). The numbering followed in this paper for
the four contact points is shown in figure 2. The current
system has a maximum travel length of 1.8 meters, a nominal velocity of 0.4 ms , nominal acceleration of 0.3 sm2 and a
nominal jerk of 1 sm3

4.1

Systems model

Models available in the vertical transportation literature
are mainly focused on the assessment of the vertical dynamic of elevators (Isasa, 2010). However vertical dynamics are affected by the friction forces, which are directly related to the rail forces acting on the horizontal
plane. Horizontal and vertical dynamics are therefore coupled and should be assessed as a whole. As a first step
this paper studies the possibility of using the horizontal
dynamics to assess the condition of the guiding system,
opening the way to studying the system as a whole. The
Modelica Standard Library is used to model the described
system. The inertial properties of the cabin given in table
1 are obtained from its CAD model. The contact stiffness
can be obtained from classical structural analysis, assuming the guide as a flexible beam with flexible supports.
The actual stiffness will thus be a function of the vertical
position of the cabin. However, in order to simplify the
estimation we use a constant stiffness for the whole guide.
340

Figure 2. Described system and relevant parameters
Table 1. Model parameters, positions measured from cars floor
coordinate system
PARAMETER
M
I11 , I22 , I33
Kx , Ky
Dx , Dy
ClearanceY
r10
r20
r30
r40
0
rc.g
rT0

DESCRIPTION
car f rame0 s

mass
Car f rame0 s inertias
contact sti f f ness
contact damping
sliding shoe clearance
position o f shoe 1
position o f shoe 2
position o f shoe 3
position o f shoe 4
car f rame0 s C.G
position o f cable

UNITS

VALUE

[Kg]
[Kg.m2 ]
[N/m]
[N/(m/s)]
[m]
[m]
[m]
[m]
[m]
[m]
[m]

14.287
0.28, 0.38, 0.20
600000
10
0.0
(0.085, 0.124, 0.297)
(0.085, 0.124, 0.067)
(0.085, 0.124, 0.297)
(0.085, 0.124, 0.067)
(0.0923, 0.0043, 0.08824)
(0.085, 0.0, 0.435)

4.1.1 Car frame
Due to the low contact forces and the high stiffness of the
car frame, the latest can be modeled as a rigid body. The
movement of the body is represented in the coordinate system (C.S) attached to the floor of the car frame, as it is the
location where the required sensors are installed. The rotation is constraint far away from the Gimbal lock position
due to the guide rails and consequently Quaternion representation is not required. Hence rotations of the car frame
are represented using Euler angles (,  and ).
4.1.2 Guiding rails: contact and friction model
The sliding shoes are the interface between the car frame
and the guiding rails. As such, the forces imposed by the
guide rail system on the car frame will be applied via the
sliding shoes. The sliding shoes grab the guiding rails
web, contacting it in three flanges. Contact in these three
flanges at the same time is highly unlikely and commonly
only one or two of the flanges of the sliding shoe are in
contact with the rail. From figure 3 it can be seen that
movement of the shoe in the x direction will always result
in a force opposite to the movement. Thus, for modeling
purposes, contact in x axis can be assumed to behave as

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132337

Session 6: Poster Session

a spring-damper system. Movement of the sliding shoe in
the y axis will depend on the direction of movement. Thus
contact in y direction is modeled with a modelica standard
ElastoGap model. The direction of the guides web is also
taken into account in the actuated prismatic in order to
make the model more general.

Figure 3. Model of the guiding rail

In this application high displacements between the sliding shoes and the guiding rails are expected. The friction
behavior at small displacements is not relevant and the
use of dynamic friction models such as Bouc-wen, LuGre
or Dahl is not required. A coulomb friction model is used
instead. In order to simplify the mathematics of the state
estimation algorithm, instead of using an event driven
friction element from the Modelica Standard Library
the friction is added with a MSL Multibody WorldForce model. The value of this force the absolute value
of the contact forces times a user given friction coefficient.
Froz_sup.force =mu_eq *(abs(
contactx_sup.f)+abs(contacty_sup.f)
)*{0, 0, 1};
The advantage of this approach is its simplicity. Avoiding events simplifies greatly the estimation, as the Jacobians of the system change more smoothly. On the other
hand, this simplification requires that the direction of the
force has to be specified at each simulation, and the direction of the force when the car is stopped is a-priori unknown. Physically the value of the friction coefficient is
greater than zero, however we directly include the direction of the force in this parameter. Therefore, a negative
value of this parameter just indicates that the direction of
the friction force will be negative. With this approach we
can find out the direction of the force in the estimation
phase.
DOI
10.3384/ecp17132337

5

Estimation results

In this section the results of the application of model-based
virtual sensors for the evaluation of forces in guiding rails
is presented. The estimation approach from section 2.2 is
applied to the described system. The measurements used
for the EKF are the lateral and vertical accelerations and
the vertical position of the car. These measurements are
taken with a triaxial piezoelectric accelerometer (lateral
acceleration), with a DC response accelerometer (vertical
acceleration) and with a draw-wire encoder (cabin position). The accelerometers are located in the coordinate
system at the center of the car as depicted in figure 2. Table 2 shows the assumed measurement noise matrix R (defined in section 2.1).
The measurement of the lateral acceleration provides
information of the dynamic change of the contact forces,
induced by the roughness and defects of the guiding rails.
In addition the model provides information regarding the
dynamic behavior of the car and the order of magnitude
of the forces. However, the misalignment of the guiding
rail results in a DC component of the contact forces which
cannot be estimated, as neither the lateral acceleration nor
the model have information on that regard. This misalignment affects the vertical dynamics of the system, as friction increases with it. Therefore, we are able to account
for this effect within the friction coefficient . Additionally, the friction coefficient of each sliding shoe has a significant variability, as it depends on several factors such
as, frequency of use of the system, lubrication and temperature. Consequently this parameter is estimated jointly
with the states of the system as explained in section 2.3.
This parameter contains thus information both on the actual coulomb coefficient and on the misalignment of the
guiding system. In contrast to what happens in the actual
system, where each sliding shoe has a different friction
coefficient, here only one equivalent friction coefficient is
assumed for all the contacts (eq ).
The parameters of the filters design are shown in table
2. The P and Q matrices shown in the table include the
covariance of the states and unknown parameter of the
system. The last term of these matrices is the covariance
of the unknown friction coefficient (eq ). Table 2 also
shows the initial value of the states of the system in the
following order: cabin.body1.phi[1], cabin.body1.phi[2],
cabin.body1.phi[3],
cabin.body1.phi_d[1],
cabin.body1.phi_d[2],
cabin.body1.phi_d[3],
cabin.body1.r_0[1],
cabin.body1.r_0[2],
cabin.body1.r_0[3],
cabin.body1.v_0[1],
cabin.body1.v_0[2], cabin.body1.v_0[3] and the initial expected value of the friction coefficient mueq .
In this application the estimated Virtual sensors and
comparison variables have a significant noise. For visualization purposes a smoothing has been performed.
Figure 4 shows the parameter estimated along the position of the cabin. The gray area around the estimated
eq is the 99.7% (3 ) confidence interval of the value of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

341

Model-based virtual sensors by means of Modelica and FMI

Table 2. Design parameters of the filter
PARAMETER

VALUE

States

 [rad],  [rad] , [rad],  [rad/s],  [rad/s] ,
[rad/s], x [m] , y [m] , z [m],x [m/s] , y [m/s], z [m/s]

Measurements

z [m], x [m/s2 ], y [m/s2 ],z [m/s2 ]

P

diag([ 1e-09 , 1e-09, 1e-09 , 2e-09, 2e-09 , 2e-09,
1e-09 , 1e-09, 1e-09, 1e-09 , 1e-09 , 1e-09, 1.5e-06])

Q

diag([ 0e+00 , 0e+00 , 0e+00 , 1e-03, 1e-03 , 1e-03 ,
0e+00 , 0e+00, 0e+00 , 1e-05 , 1e-05 , 1e-05, 5.0])

R

diag([ 1e-08 , 1e-16 , 1e-16 , 1e-16])

x_initial

[ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12, 0.0, 0.0, 0.0 ]

Fs [Hz]

1652

eq0 []

0.2

be due to sharp changes of guiding rail segment or imperfections on the rail. These defects induce abrupt forces in
the sliding shoes that have a negative impact on the riding
quality. Figure 5 shows the estimated contact forces in X
and Y directions along with the 99.7% confidence interval
(light gray for X direction and light blue for Y direction.
As expected, the variance of the estimated forces is relatively high. This is mainly because the model and the
measurements do not provide information regarding the
DC component of this forces.

this parameter. This confidence interval comes from the
co-variance estimated for this parameter. As explained in
section 4, this parameter includes information regarding
the actual friction coefficient of coulomb and regarding
the misalignment of the guiding rails. The negative sign
of the estimated parameter is not related to the physical
meaning of the friction coefficient, but to the direction of
the friction force instead. In addition to the friction coeffi- Figure 5. Estimated contact forces. In black the forces in X
direction and 99.7% confidence interval, in blue forces in Y direction and 99.7% confidence interval.

Finally figure 6 shows the comparison between the estimated friction force and the measured one. The estimated
friction force is computed from the sum of the friction
forces in each sliding shoe as explained in section 4.1.2.
The measured one is the direct subtraction of the cables
tension and cabin acceleration.

Figure 4. Estimated friction coefficient and the estimated 99.7%
confidence interval of the estimation

cient, the contact forces also provide information regarding the condition of the guiding system. More exactly,
they provide information regarding sharp differences in
the position of the guide rails. Such dynamic changes will
342

Figure 6. Comparison of estimated and measured friction force

The guiding system is not the most common source of
failure but it is one of the most critical systems. Failure in
guiding rails leads to large down times of the whole system and it is difficult to evaluate its condition. It is complicated thus to assess both the alignment and the smoothness

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132337

Session 6: Poster Session

of the guides, as required to ensure comfort and energy efficiency. Different condition monitoring alternatives are
suggested in the literature for guiding rails. In general vibration data processing is used to assess the condition of
the guides (Wan et al., 2015). However these methods require well trained data which in may be difficult to obtain.
Model-based virtual sensors, on the other hand, provide a
suitable approach to monitor the condition of system using
off-the-shelf sensors and without training data. The trade
off is that an accurate model of the system is required.
Nevertheless it was shown that Modelica and the FMI simplify the development of model-based virtual sensors.
The presented estimations provide a useful indicator of
the condition of the guiding system. Changes in the friction coefficient indicate misalignment and abrupt changes
in the forces indicate local damages in the guides. For
instance the estimation from figure 4 shows a significant
deviation in the friction coefficient when the cabin is at
0.6m. This deviation indicates thus a misalignment of the
guides at that position. Additionally, the abrupt change of
the contact forces at 0.9m indicates a local defect in the
web of the rail. However, further work is required to develop a methodology to set a threshold for the value of
these variables. Once the threshold is defined we can use
this to assess the condition of the system, aiding the alignment of the guides and finding early damage in the rails.

6

sors exist for that purpose it would be better to use
just sensors available in the system or easier to use,
such as the input of the controller and the currents in
the machine. To achieve this the model of the system has to be extended to include not only the cabin
of the test bench, but the controller, the electric machine, the pulley, the cable and the counterweight as
well. The model will be extended to include all the
parts of the system. The electric machine and control
systems will be included in the estimation.

 As the system grows in complexity, the use of other
state estimation algorithms such as the Unscented
Kalman Filter or the Moving Horizon Estimator will
be explored. Finally the estimation will be used to
monitor the condition of the system.

7

Acknowledgments

The authors gratefully acknowledge the European Commission for its support of the Marie-Sklodowska Curie
program through the ITN ANTARES project (GA
606817) and the support from the KU Leuven research
fund.

References
K. Bizon, G. Continillo, S. Lombardi, E. Mancaruso, and B.M.
Vaglieco. Ann-based virtual sensor for on-line prediction of
in-cylinder pressure in a diesel engine. In 24th European
Symposium on Computer Aided Process Engineering, volume 33 of Computer Aided Chemical Engineering, pages 763
 768. Elsevier, 2014. doi:http://dx.doi.org/10.1016/B978-0444-63456-6.50128-9.

Conclusions

An EKF with parameter identification capabilities has
been developed in Python using the package pyFMI and
models exported with the FMI 2.0 for model exchange.
Modelica and FMI are very useful to cope with the complexities arising from the use of Model-based virtual sensor with complex systems. The combination of these tools M. Bonvini, M. Wetter, and M. Sohn. An fmi-based framework
for state and parameter estimation. In Proceedings of the 10
reduces modeling effort and simplifies the implementath International Modelica Conference; March 10-12; 2014;
tion of the virtual sensor. As an example of the efficiency
Lund; Sweden, number 096, pages 647656. Linkping Uniof this combination the estimation of forces in a vertical
versity Electronic Press, 2014.
transportation system scaled test bench is presented. The
EKF is used to simultaneously estimate states and param- J. Brembeck, M. Otter, and D. Zimmer. Nonlinear observers
based on the functional mockup interface with applications
eters in a scaled vertical transportation system test bench.
to electric vehicles. In Proceedings of the 8th InternaAdditionally the forces acting on the guiding system are
tional Modelica Conference; March 20th-22nd; Technical
estimated. This estimations provide a mean to assess the
Univeristy; Dresden; Germany, number 63, pages 474483.
condition of the guiding system. This approach opens the
Linkping University Electronic Press, 2011.
way to condition based maintenance strategies for guiding systems. Such maintenance schemes can improve rid- J. Brembeck, A. Pfeiffer, M. Fleps-Dezasse, M. Otter, K. Werning quality, safety and efficiency of vertical transportation
ersson, and H. Elmqvist. Nonlinear state estimation with an
extended fmi 2.0 co-simulation interface. In Proceedings of
systems, fulfilling thus the requirements of modern smart
the 10th International Modelica Conference-Lund, Swedensystems. Future steps in the investigation include:
Mar 10-12, 2014, volume 96, pages 5362. Linkping University Electronic Press, 2014.
 Assessment of the estimated variables and parameters: a theoretical optimal value of the friction coef- E. Esteban, O. Salgado, A. Iturrospe, and I. Isasa.
ficient and of the contact forces should be used to set
Model-based approach for elevator performance esa threshold that aids assessing the condition of the
timation.
Mechanical Systems and Signal Processguides.
ing, 68-69:125  137, 2016.
ISSN 0888-3270.

 In this work the tension in the cable has been used as
input of the system. Even though off-the-shelf senDOI
10.3384/ecp17132337

doi:http://dx.doi.org/10.1016/j.ymssp.2015.07.005.
URL
http://www.sciencedirect.com/science/
article/pii/S0888327015003246.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

343

Model-based virtual sensors by means of Modelica and FMI

JCB Gonzaga, L.A.C. Meleiro, C Kiang, and R. Maciel Filho.
Ann-based soft-sensor for real-time process monitoring and
control of an industrial polymerization process. Computers
& Chemical Engineering, 33(1):4349, 2009.
I. Isasa. Model validation applied to locally nonlinear lift structures. PhD thesis, Mondragon Unibertsitatea, 2010.
R. Isermann.
Model-based fault-detection and diagnosis status and applications.
Annual Reviews in
Control, 29(1):71  85, 2005.
ISSN 1367-5788.
doi:http://dx.doi.org/10.1016/j.arcontrol.2004.12.002. URL
//www.sciencedirect.com/science/article/
pii/S1367578805000052.
L. Janovsky. Elevator mechanical design. Elevator World Inc,
1999.
P. Kadlec, R. Grbic, and B. Gabrys. Review of adaptation mechanisms for data-driven soft sensors. Computers & chemical
engineering, 35(1):124, 2011.
Xueqin Liu, Uwe Kruger, Tim Littler, Lei Xie, and Shuqing
Wang. Moving window kernel pca for adaptive monitoring
of nonlinear processes. Chemometrics and intelligent laboratory systems, 96(2):132143, 2009.
F. Naets, J. Croes, and W. Desmet. An online coupled
state/input/parameter estimation approach for structural
dynamics. Computer Methods in Applied Mechanics and
Engineering, 283:1167  1188, 2015. ISSN 0045-7825.
doi:http://dx.doi.org/10.1016/j.cma.2014.08.010.
URL
http://www.sciencedirect.com/science/
article/pii/S0045782514002795.
P. Samara, J. Sakellariou, G. Fouskitakis, J. Hios, and S. Fassois.
Aircraft virtual sensor design via a time-dependent functional
pooling narx methodology. Aerospace Science and Technology, 29(1):114124, 2013.
D. Simon. Optimal state estimation: Kalman, H infinity, and
nonlinear approaches. John Wiley & Sons, 2006.
Z. Wan, S. Yi, K. Li, R. Tao, M. Gou, X. Li, and S. Guo. Diagnosis of elevator faults with ls-svm based on optimization by
k-cv. Journal of Electrical and Computer Engineering, 2015:
70, 2015.
Y. Zhang, Z. Zhao, T. Lu, L. Yuan, W. Xu, and J. Zhu. A comparative study of luenberger observer, sliding mode observer and
extended kalman filter for sensorless vector control of induction motor drives. In 2009 IEEE Energy Conversion Congress
and Exposition, pages 24662473. IEEE, 2009.

344

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132337

Dymola-JADE Co-Simulation for Agent-Based Control in Office
Spaces
Ana Constantin1
1 Institute

Artur Lwen2

Ferdinanda Ponci2

Kristian Huchtemann1

Dirk Mller1

for Energy Efficient Buildings and Indoor Climate, RWTH Aachen University, Germany, {aconstantin,
khuchtemann, dmueller}@eonerc.rwth-aachen.de

2 Institute

for Automation of Complex Power Systems, RWTH Aachen University, Germany, {aloewen,
fponci}@eonerc.rwth-aachen.de

Abstract
This paper presents an application of coupling Modelica
under Dymola and JADE to test novel agent-based control for office spaces. The office space with a coupled energy system and weather boundary conditions are modeled
in Dymola. The agent platform is programmed in JADE,
where the agents communicate with each other to control
the technical equipment used to deliver thermal energy to
the room. Heating experiments, run for a one room scenario, using a radiator, show better system reaction to the
comfort desires of the user compared to a control with a
thermostatic valve, while having similar energy consumption. While the agents run in real time, the simulation
in Dymola runs faster. We focus on the particularities of
the connection for co-simulation to insure smooth transferability of the experiments from simulation to a field
test, where the energy system as well as the agent platform would be running in real time.
Keywords: agent-based control, JADE, co-simulation

1

Introduction

The energy saving potential of buildings is estimated
to be around 30% (IEA, 2015b) with the proper policies and technologies compared to continuing the current business-as-usual scenario, which accounts for over
30% of total final energy consumption for all sectors of
the economy (IEA, 2015a). One of these novel technologies being currently researched are multi-agent systems
(MAS), used for building energy and comfort management (BECM) (Shaikh et al., 2014).
An agent can be defined as an entity that perceives its
environment through sensors and according to a goal function acts upon its environment through actuators (Russell
and Norvig, 2003). For applications of indoor climatization agents of this type could be embedded on energy
generation, distribution or delivery equipment (e.g. heat
pump, circulating pump or valve on a heat exchanger).
Through negotiation, for example over the cost of energy
supplied to the room, the agents can strive to find optimal
solutions for the trade-off between thermal energy and indoor comfort. As all novel technologies MAS applications are first tested on a simulation level. According to
DOI
10.3384/ecp17132345

the state of the art (Labeodan et al., 2015) we chose JADE
for the programming of the agents. JADE is a Java based
software framework which is complaint with the specifications of the Foundation for Intelligent Physical Agents
(FIPA). The simulation setups containing the models for
the building, technical equipment as well as the boundary
conditions for the weather are done using Modelica under
the simulation environment Dymola. Dymola and JADE
are connected in a Co-Simulation by using a TCP/IP interface.
We present in this paper the methodology for building
our simulation tests with a focus on the particularities of
setting up the co-simulation. We describe the use case we
are using, information on how the agent platform works
and how the models are built and the communication with
the models takes place. Afterwards, exemplary results for
a one room scenario are presented and discussed. The paper closes with a conclusions section.

2

Method

The first steps in our work for developing MAS for BECM
was to develop an ontology and by focusing on the application on non-residential buildings adding a data model.
However, this is not within the scope of the paper and
further details will be skipped. The data models for the
energy equipment were built based on the data generally
available in manufacturer data sheets, to insure a wide applicability of the methodology to devices of the same type
but by different manufacturers. To develop a coherent control strategy we used a use case base approach. We developed use cases for one and two room scenarios, with
different type of users or for plug-in of a new component.
For exemplary purposes we focus on a one room use case
in this paper.

2.1

Use Case

We consider an office room, with one user. The user is also
an owner of the office, so his / her comfort desires will be
taken into consideration. The room is supplied with thermal energy by a system consisting of a pump and a heat
pump, which deliver energy to a radiator. The energy can
be increased either by increasing the supply temperature
of the heating fluid (action of the heat pump) or by in-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

345

Dymola-JADE Co-Simulation for Agent-Based Control in Office Spaces

creasing the volume flow through the radiator (action of
the pump). These two actions do influence one another.
In this paper we only focus on heating the room. Figure 1
presents the agents involved in the one room use case.
The following agents act in this use case:

 the personal comfort agent (ComfortAgent): receives
from the person working in the room the function for
preferred room temperature as a function of outside
air temperature, as well as the productivity function
as a function of the room air temperature. The agent
calculates the set temperature for maximum productivity and the comfort curve, which gives the costs
of comfort increases and the savings of comfort decreases.
 the heat pump agent (EnergySupplyHeatPump
Agent): has knowledge of the current operation point
of the heat pump and the corresponding energy costs.

is supplied (if the comfort costs are lower than the
costs for suppling the energy), or not.
4. If energy has to be provided to the room, the room
agent sends a request to the energy supply agent with
the lowest costs (4): this might be just one agent or
both agents, if one agent cannot supply all the energy
on its own. If the pump is chosen, it will send a request to the valve (4*). Once the action is executed,
the valve sends a confirmation back to the pump (4*).
5. The energy supply agents send messages to the room
agent on how the command was executed (5): success or failure.
6. The room agent informs the comfort agent on how
the action for improving the room conditions was executed (6).

2.2

Agent platform

 the pump agent (EnergySupplyPumpAgent): knows
the current operation point of the circulating pump We used the Java based programming language JADE
(Java Agent DEvelopment Framework) to develop the
and the corresponding energy costs.
agents. The decision for JADE was made based on its
 the room agent (RoomAgent): monitors the current implementation of the FIPA specifications. The base comroom air temperature against the desired temperature ponent of a typical agent platform is the agent, with each
and stars a negotiation between comfort and energy agent having a unique name. Agents execute tasks and insupply agents if the room temperature has to change teract with each other through the exchange of messages.
They are located on a platform, which provides them with
 sensor and actuator agents: temperature sensors basic services such as message delivery.
(room air, outside air, supply and return of the
In this application we decided to attach agents to every
medium trough the radiator) and the actuator on the system component: technical equipment, actuators and
valve of the radiator.
sensors. In this way we diverged from the given definition for an agent, as a sensor in itself cannot act upon its
We present the steps of the use case when using the
environment. However, the state of the art in agent syscontrol strategy "relaxation of comfort costs", meaning the
tems for building energy management (see for example
costs for the users productivity loss because of decreased
(Dibley et al., 2012)) have agents responsible for sensors
comfort are taken into account against the costs for energy
(reading and sending values). For a first implementation
supply to the room. While the energy costs are calculated
we decided on having agents for each sensor to enable a
according to the price of the extra energy supplied to the
closer look at the communication flow between such comroom, the comfort costs are calculated according to (Sepponents.
paenen et al., 2006).
The agents communicate with each other and with the
1. The room agent monitors the room temperature, re- attached devices. The agents have different roles to play
ceived from the sensor, against the desired room tem- and according to their goals the corresponding actions
perature, received from the comfort agent (1). If the can be grouped into so called behaviors. Exemplary we
room air temperature lies outside a tolerance interval present here the behaviors of an agent attached to a circuaround the desired temperature a call for proposal lating pump. The EnergySupplyAgentPump connects to a
(CFP) is sent to the relevant energy supply agents pump device to receive information on the devices current
that are connected to the supply circuit of the room state, answers to a CFP, receives and executes requests to
and might produce this energy: heat pump and pump change the operation point of the device:
(2). Additionally a request for the comfort costs is
 HandleSensorDataSubscription: receives and hansent to the comfort agent (1*).
dles the notifications from the sensor agents the
pump agent subscribed to: supply and return tem2. The energy supply agents send their costs and the
perature sensors for the rooms on the same supply
amount of energy they can provide for the room (3).
circuit as the pump.
3. The room agent compares the costs for supplying the
energy against the comfort costs of the user. The op EnergySupplyContractNetResponder: handles intion with the lowest costs is executed: either energy
coming CFPs, by sending a proposal, to handle
346

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132345

Session 6: Poster Session

ComfortAgent

1
1*/6
2/4
RoomAgent

EnergySupply
PumpAgent

3 /5
3 /5

2/4
Temperature sensors





EnergySupply
HeatPumpAgent

4*

Air temperature
Outside air
Flow to room
Return from room

Actuators


Valve heating

Figure 1. Agents involved in a one room use case.

accepted proposals through HandleAcceptProposal
The models available in the EBC libraries for the techand to handle rejected proposals.
nical equipment were until now a heterogeneous aggregation of all the elements needed to the describe a real
 HandleAcceptProposal: handles the acceptance of component, including the physical phenomenon in the dethe proposal, that was requested and accepted by the vice along with control dedicated blocks. We decided to
room agent. It starts the InitiateRequestToValveAc- split the models from the controllable pieces of technical
tuator behavior to send a request to the valve agent, equipment into three sub-models (see Figure 2):
which communicates with the valve device to control
 physical model: describes the physical component
the volume flow, if the pump does not allow to set the
of the device on which the energy transformation is
volume flow directly.
taking place, along with the energy sources which
 InitiateRequestToValveActuator: this behavior is inisupport this transformation. For example for a boiler
tiated by HandleAcceptProposal to send a request to
model the physical model includes a water volume, a
the valve agent as previously detailed.
hydraulic resistance and an energy source for the gas
flame.
It is important to understand, that as long as the behav internal control: describes the way in which energy
iors are not connected to each other, meaning a behavior is
flows are directed at the physical components. This
started from another behavior, that they are running in parcontrol mechanisms are a proprietary part of the deallel. An agent attached to a pump can at the same time
vice, and the user has no influence on them. In
process messages received from a temperature sensor as
the boiler example this is a PI controller which conwell as a CFP received from a room agent.
trols the thermal output of the gas burner in order to
2.3 Modeling
achieve a given supply temperature. The efficiency
of the energy transformation in burning the gas is
The simulation models were developed using blocks from
also taken into account.
the Modelica Standard Library, the open-access library of
the Institute for Energy Efficient Buildings and Indoor Cli external control: describes the control strategy that
mate (EBC), AixLib, and an institute internal Modelica
the user sets for the device. Continuing with the
library for components for energy systems.
boiler example, this is the algorithm for choosing a
The following models were used and/or developed:
set temperature for the volume flow: it might be constant, it might be given by a heating curve (state of
 Technical equipment: heat pump, boiler, circulating
the art), it might also include a night and a day mode.
pump, radiator

 Building: room with walls, windows and doors
 Internal gains from persons present in the rooms
 Boundary conditions, mainly weather
DOI
10.3384/ecp17132345

The arrows in Figure 2 describe the flow of information
between the three blocks, comprising set and measured
values.
We are partial to this modeling approach, as it gives a
good overview of the model and what it can do, and it

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

347

Dymola-JADE Co-Simulation for Agent-Based Control in Office Spaces

leads to the re-usability of the sub-models. By using the
replaceable model functionality in Modelica the external
control block can be changed between simulations, so all
other elements stay the same in the model. As such the
probability of making a mistake when setting up identical
setups with different control strategies is very low. The external control as such can be programmed in Modelica or
in another software. In the latter case the external control
block contains the Dymola implementation of the interface between the two softwares.

2.4

Simulation setup

The office space has a floor area of 19 m2 , with a height of
3 m and a large window area of 8 m2 . The construction is
W
well insulated: Uwall = 0.2 mW
2 K and Uwindow = 1.2 m2 K .
The office has one outer wall and the boundary conditions
at the other five inner walls are set as adiabatic. The energy delivery system to the room is a radiator, equipped
with a valve for volume flow control. The energy distribution system consists of a circulating pump and the energy
generation system is a heat pump.
The reference system, for comparison evaluation of the
control strategy is build the same way, with the exception
that the control of energy flow to the room is done by a
thermostatic valve.
For the weather data we used the test reference year,
TRY 05, for the area of Aachen provided by the German
meteorological service (DWD).

3
3.1

field test.
Details on a first version of the routines for the TCP/IP
communication can be found in (Schneider et al., 2015).
As set up parameters the routines only need an IP-address
and a port.
Dymola does not build a socket on its own, but can
communicate with an open socket. The socket is build in
JADE. We extended the routines by allowing for several
different TCP/IP channels to be built and used in one simulation. Additionally, we changed the state of the receiving routine for a socket from blocking to non-blocking.
In this way messages can be sent to Dymola only when a
command has to be executed. The rest of the time Dymola
listens on the socket for a given amount of time and if no
message is received it proceeds with the simulation. This
is also important for the transferability of the testing from
a simulation
to a field test, where commands are send only
5 JSON Values
when needed.
We value
wanted to have a standardized content for the mesobject
sages being sent between Dymola
and JADE. For this we
array
decided on using the Java Script
Object Notation (JSON)
number
standard (ECMA, 2013). Figure
3 shows the structure of
string
an object in JSON. The extratrue
overhead to the communication by the fact that the messages
are human readable is
false
not an issue to our applications,
were
a handful of values
null
are exchanged every couple of minutes. A further advantage of the standard is that it offered us an easy way of
6 Objects
integrating
the data model, which is also built using tuples
of label, type and value.
U+006E U+0075 U+006C U+006C

null

Insignificant whitespace is allowed before or after any token. The whitespace characters are: character
tabulation (U+0009), line feed (U+000A), carriage return (U+000D), and space (U+0020). Whitespace is not
allowed within any token, except that space is allowed in strings.

A JSON value can be an object, array, number, string, true, false, or null.

Figure 1  value

An object structure is represented as a pair of curly bracket tokens surrounding zero or more name/value pairs.
A name is a string. A single colon token follows each name, separating the name from the value. A single
comma token separates a value from a following name.

Co-Simulation
TCP/IP Communication

object
{

string

:

value

}

We decided on using a TCP/IP communication between
,
Dymola and JADE, as routines for TCP/IP communication
have been developed in previous projects for both Dymola
and JADE. Furthermore in the planned field test one com- Figure 3. Object structure according to JSON standard (ECMA,
2013)
munication possibility between agents and devices is via
TCP/IP, which means that only few modifications have to
For2 a circulating pump the message sent by the device
be carried out for moving the testing from simulation to a
to the JADE agent looks like this:
{deviceId: pump1, building: Build1, supplyCircuitId:
SC1, room: None, vFlow: 5.3239e-005, head: 0.49068,
isOn: 1, mode: 1, health: 1, control: 1, end: false}
External control
The building, supplyCircuitId and room parameters describe the position of the device in the energy system.
The values for volume flow (vFlow) and head describe
the current operation point of the pump. The values are
Internalcontrol
in SI units, as well as the algorithms inside the agents are
in SI units to make the flow of information between simulation and agent platform as lean as possible. We firmly
believe that when communication between two softwares
takes place, all measured or calculated values have to be
Physical model
provided in SI for transparency. Changes from SI to other
units should be done in the software themselves if needed.
The values for isOn, mode, health and control describe
Figure 2. Modeling approach for a piece of controllable techni- the status and settings of the pump, according to the data
cal equipment
model.
Figure 2  object

 Ecma International 2013

348

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132345

Session 6: Poster Session

The end parameter is used to signal the end of the sim- 4 Results and discussion
ulation and triggers a shutdown of the agent platform in
We present exemplary results for a one room use case,
JADE.
done using the described simulation setup with a room
(R1) where the agent based control is implemented. As
3.2 Real time vs simulation time
a reference case we use a second room (R2) where a therThe agent platform runs in real time, while the simulation mostatic valve controls the temperature in the room, concan run in real time or the time it normally takes to run the sidered to be state-of-the art for room temperature control.
simulation which we call "simulation time". Depending Both rooms are connected to the same supply circuit thus
on the complexity of the model the simulation time can be a change in the supply temperature of the heat pump afquite different, from a few seconds to a few minutes for a fects both rooms. Changes in the opening of the valves
whole simulation day. The advantage of having Dymola only affect the room in question.The users are assumed
run in "simulation time" is that more experiments can be to be present over the whole duration of the simulation.
done in a shorter period of time.
As such the room agents are continuously monitoring the
Dymola communicates with JADE at discrete time in- room conditions against the preferences expressed by the
tervals, set in the discrete blocks by the parameter sam- comfort agents.
We present a simulation for a heating scenario, done
ple rate. The challenge when running a co-simulation lies
matching the dynamics of the controller with the ones of over the first three days of January.
Expected results:
the controlled system. For us it meant identifying an adequate length of the time interval such that the response
 we expect the valve to open when the room tempertime from JADE to Dymola, for example in the case of
ature needs to increase, and the supply temperature
a CFP which leads to a command to Dymola, should be
from the heat pump to drop when the room temperareasonable. We define reasonable as 5 minutes time in the
ture needs to decrease
simulation, from the moment an uncomfortable temperature has been identified and the moment the an agent has
 we expect the valve in room R1 to open almost fully
received a command to act in this case.
during the test, as the costs of the pump are lower
than the costs of the heat pump
The communication rhythm, i.e. the sample rate, between Dymola and JADE influences the simulation-time
 we expect the value of the supply temperature to detwo fold:
crease under the value for a control strategy based
on a heating curve (in this case around 45 C), as the
 the shorter the time interval for communicating, the
volume supply through the pump increases
longer the simulation, as sampling leads to events
Achieved results
and the TCP/IP interface is programmed using algoFigure 4 presents the air temperature and valve opening
rithms which both slow down the simulation
for each room, along with the supply temperature of the
heat pump. We observe that the results are as expected.
 the commands from JADE can arrive more quickly, The supply temperature of the heat pump increases when
at the very next communication step, which can
the room temperature needs to increase, only when the
sometimes lead to an over-reaction in the system. For
valve is fully opened and as such no further action is posexample if the temperature didnt have time to be insible from the valve.
fluenced by the latest agent actions and already the
The set temperature of 20 C is given for both rooms.
room agent is initiating a new CFP
The evolutions of the room air temperatures are similar.
However the valve openings are quite different, on acOur method of finding an adequate sampling rate is count of the different control strategies. The thermostatic
trial-and-error based and has to be executed for each simu- valve has a proportional term of 1 K, which means the
lation model in part, as increased model complexity leads valve fully closes once the room air temperature is 1 K
to increased CPU time. It requires a series of simulations above the set temperature (comfort requirement R2). If
using the same model and different values for the sam- the room air temperature is lower than the set temperature
pling rate. For each simulation the time in the simulation the valve can, depending on the type of valve, open fully
between registering an uncomfortable temperature and a only when the difference between set and current temperasubsequent agent action is measured and compared to the tures is around 5 K, which explains why the valve doesnt
reasonable time frame. Additionally when waiting for an open more and the temperature drops below the set temaction confirmation (meaning set point change) from the perature. The MAS holds the room temperature in an insimulation, we assume the set point of the device should terval of +/  0.5 K around the set temperature. This is
change between two samples. As such the timeout for an the comfort preference of the user, as variations of this
agent waiting for confirmation from the device should be degree are considered unnoticeable by the user (comfort
at least 2.5 the sample time translated in simulation time. requirement R1). In the case of the user in R2, the drop
DOI
10.3384/ecp17132345

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

349

Dymola-JADE Co-Simulation for Agent-Based Control in Office Spaces

Temperature in  C

Temperature in  C

22
21
20
19
18
170
50
45
40
35
30
25
0

1.0
0.8
0.6
0.4
0.2
0.0
0

Tis_R1
Tis_R2
Tset_R1
Tset_R2
10

20

30

40

50

60

70

Supply temperature HP

10

20

30

20

30

40

50

60

70

40

50

60

70

Valve opening_R1
Valve opening_R2

10

Hour of year

Figure 4. Air temperature, supply temperature of heat pump (HP) and valve opening for room 1 (R1) and room 2 (R2) in a heating
experiment

below the set temperature is considered a violation of the
comfort requirement.
Key performance indicators (KPI) relating to energy
consumption and comfort for the two rooms are presented
in table 1. While the energy consumption is 3% higher
for room R1 than room R2, the discomfort, as calculated
according to the different comfort requirements, is a lot
lower, 97% less than for room R2. However using a common comfort criterion for both rooms, like the Predicted
Mean Vote (PMV) according to (Fanger, 1970) the comfort levels in both rooms are more similar. The energy delivery to the room is similar while having different valve
openings, because in the case of room 2 the temperature
difference between supply and return for the radiator is
higher. If both rooms had different energy generation systems, the costs for the energy generation would have been
higher for room 2.
Table 1. KPI One Room Use Case

5

Room

KPI

Value

Unit

R1
R2
R1
R2

Energy Consumption
Energy Consumption
Lost comfort
Lost comfort

20.2
19.5
0.6
18

kWh
kWh
Kh
Kh

Conclusions

an agent based control for an office space. The building,
boundary conditions and the technical equipment with the
exception of the control strategy are modeled in Dymola.
The multi-agent system containing the control strategy for
the system is setup in JADE.
The communication between Dymola and JADE is
done using a TCP/IP connection. Measured values describing the current state of the simulation, including temperatures and operation points of the technical equipment,
are sent to JADE with a fixed sample rate. Commands
from the agents in JADE are sent to Dymola over nonblocking sockets at the next available communication step.
Care has to be taken when setting up the sample rate and
the timeout for action confirmations from the simulation
as the agents are running in real-time and the simulation
can run faster.
We exemplified our concept with a simulation for a one
room scenario, using a second room controlled by a thermostatic valve as a reference case. While the energy consumption and comfort are similar the agent system reacts
better to temperature changes and can lead to lower energy costs. Future work will focus on experiments with
multiple room as well as a field test.

References
Michael Dibley, Haijiang Li, Yacine Rezgui, and John Miles.
An ontology framework for intelligent sensor-based building monitoring. Automation in Construction, 28:114, 2012.
ISSN 09265805. doi:10.1016/j.autcon.2012.05.018.

We presented in this paper the realization of a cosimulation between Dymola and JADE, for implementing ECMA. Ecma-404: The json data interchange format, 10 2013.
350

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132345

Session 6: Poster Session

URL
http://www.ecma-international.org/
publications/files/ECMA-ST/ECMA-404.pdf.
P.O. Fanger. Thermal Comfort. Danish Technical Press, 1970.
IEA. Building energy performance metrics: Supporting energy
efficiency progress in major economies. Technical report, International Energy Agency, 2015a.
IEA. Energy technology perspectives 2015. Technical report,
International Energy Agency, 2015b.
T. Labeodan, K Aduda, G. Boxem, and W. Zeiler. On the application of multi-agent systems in buildings for improved
building operations, performance and smart grid interaction
a survey. Renewable and Sustainable Energy Reviews, 50:
14051414, 2015.
Stuart J. Russell and Peter Norvig. Artificial intelligence A modern approach. Prentice Hall/Pearson Education, 2003.
Georg Ferdinand Schneider, Jens Oppermann, Ana Constantin,
Rita Streblow, and Dirk Mueller. Hardware-in-the-loopsimulation of a building energy and control system to investigate circulating pump control using modelica. In The 11th
International Modelica Conference, 2015.
Olli Seppaenen, William Fisk, and QH Lei. Effect of temperature on task performance in offfice environment. Technical report, Ernest Orlando Lawrence Berkley National Laboraory,
2006.
P. H. Shaikh, N. B. M. Nor, P. Nallagownden, I. Elamvazuthi,
and T. Ibrahim. A review on optimized control systems for
building energy and comfort management of smart sustainable buildings. Renewable and Sustainable Energy Reviews,
34:409429, 2014.

DOI
10.3384/ecp17132345

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

351

352

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Failure Modes of Tearing and a Novel Robust Approach
Ali Baharev

Arnold Neumaier Hermann Schichl

Faculty of Mathematics, University of Vienna, Oskar-Morgenstern-Platz 1, 1090 Vienna, Austria
ali.baharev@gmail.com

Abstract

p  q. Equation (3) implies that the sparsity pattern of the
Jacobian of P f is
State-of-the-art Modelica implementations may fail in var

ious ways when tearing is turned on: Completely incorA B
J
=
, where A is lower triangular,
(4)
rect results are returned without a warning, or the software
C D
fails with an obscure error message, or it hangs for several
minutes although the problem is solvable in milliseconds J is therefore bordered lower triangular. We will use the
without tearing. We give three detailed examples and an abbreviation BLTF which stands for bordered lower trianin-depth discussion why such failures are inherent in tear- gular form. We refer to a particular choice of P, Q, g, h, y,
and z satisfying equations (3) and (4) as an ordering.
ing and cannot be fixed within the traditional approach.
Without compromising the advantages of tearing, these Given an ordering, the system of equations f (x) = 0 can
issues are resolved for the first time with staircase sam- be written as
g(y, z) = 0
pling. This is a non-tearing method capable of robustly
(5)
h(y, z) = 0.
finding all well-separated solutions of sparse systems of
nonlinear equations without any initial guesses. Its ro- The requirement (3) that gi (y, z) = 0 can be made explicit
bustness is demonstrated on the steady-state simulation of in yi essentially means that we can obtain y from z by a
a particularly challenging distillation column. This col- nonlinear triangular solve. Substituting the result y = g(z)
umn has three solutions, one of which is missed by most into h yields h(g(z), z) = 0 or
methods, including problem-specific tearing methods. All
three solutions are found with staircase sampling.
r(z) = 0.
(6)
Keywords: decomposition methods, diakoptics, largescale systems of equations, numerical instability, sparse That is, the original nonlinear system (1) is reduced to the
(usually much) smaller system r(z) = 0. A commonly
matrices, staircase sampling
used objective is to find an ordering that minimizes the
border width d := dim z of J. For a given z, we call the
1 Introduction
value of r(z) the residual vector or simply the residual.
Definitions. Traditional tearing, cf. (Elmqvist, 1978;
Elmqvist and Otter, 1994; Mattsson et al., 1999; Carpan- Advanced tearing methods. There are other, more sozano, 2000; Cellier and Kofman, 2006; Tuber et al., phisticated variants of tearing, summarized in Table 1.
2014), is the representation of a sparse system of nonlinear These try to reduce the size of the final system (6) by relaxing the requirements of (3) (by allowing implicit equaequations
tions for example) and/or allowing A in (4) to have a form
n
n
f (x) = 0, where f : R 7 R ,
(1) other than lower triangular. These enhancements share
that the computation of y for a given z only involves fast
in a permuted form where most of the variables can be and numerically stable algorithms such as solving implicit
computed sequentially once a small auxiliary system has univariate equations or small systems of equations. Anbeen solved. More specifically, given permutation matri- other recent approach tries to balance between minimizing the border width and preserving the sparsity during the
ces P and Q such that after the transformation
elimination (Magnusson and kesson, 2017). The reader
 
 
is referred to (Baharev et al., 2017a) for an in-depth disg
y
= Pf,
= Qx,
(2) cussion of the variations on tearing. To keep the examples
h
z
short and simple, we only discuss the failure modes of trag (y, z) = 0 can be rewritten in the equivalent explicit form ditional tearing in the present paper.
i

Importance: initializing and solving DAE systems.
(3) The problem of solving nonlinear systems of equations
arises in the daily engineering practice, e.g., when consisusing appropriate symbolic transformations. Here the tent initial values for differential algebraic equation (DAE)
shorthand p:q is used for the index set p, p+1, . . . , q where systems are sought (Pantelides, 1988; Unger et al., 1995),
yi = gi (y1:i1 , z)

DOI
10.3384/ecp17132353

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

353

Failure Modes of Tearing and a Novel Robust Approach

Table 1. The sparsity pattern of the Jacobian in the different variants of tearing, classified by the largest subproblem size and the
level of subproblem nesting. The present paper discusses the failure modes of traditional tearing only.

Largest
subproblem

1

Maximum level of subproblem nesting
`

univariate equations
only

bordered lower triangular
(traditional tearing)



k  k systems
of equations

bordered block lower triangular
(tearing with diagonal blocks)

nested bordered block lower triangular
(hierarchical tearing)

or when solving steady-state models of technical systems.
A steady-state solution can be used as a consistent initial
set of the DAE system (Krner et al., 1997). Tearing usually also helps to speed up the solution process of DAE
systems thanks to the reduced problem size (Elmqvist,
1978; Elmqvist and Otter, 1994; Mattsson et al., 1999;
Carpanzano, 2000; Cellier and Kofman, 2006).
Even though mature equation-based componentoriented modeling environments are available, e.g.,
Modelica (Mattsson et al., 1998; Tiller, 2001; Fritzson,
2004) for multi-domain modeling of heterogeneous complex technical systems, and gPROMS, ASCEND (Piela
et al., 1991) and EMSO (de P. Soares and Secchi,
2003) for chemical process modeling, simulation and
optimization, etc., the steady-state initialization is still
not satisfactorily resolved in the general case. Often,
steady-state initialization failures can only be resolved
in very cumbersome ways, requiring user-provided good
initial values for the variables (Vieira and Jr, 2001;
Bachmann et al., 2007; Sielemann and Schmitz, 2011;
Sielemann et al., 2013; Ochel and Bachmann, 2013).

where x0 := 0.1 and x21 := 0.1 to keep the formulas simple. The only tear variable is x1 ; the residual is given by
the last equation (i = 20). The exact solution is xi = 0.1
for i = 1:20. Both Dymola and OpenModelica return completely incorrect results, for example, x20 = 32.03 and
x20 = 85.82, respectively, but claim that the simulation
was successful.
Example 2: The residual is insensitive to the changes in
the tear variable. We solve the following 20  20 linear
system in a Newton step:
xi1 + xi + 15xi+1 = 17

i = 1:20,

(8)

where x0 := 1 and x21 := 1 to keep the formulas simple.
The only tear variable is x1 ; the residual is given by the
last equation (i = 20). The exact solution is xi = 1 for
i = 1 : 20. Dymola fails with an unhelpful error message,
and does not return any result. OpenModelica emits some
confusing intermediate warnings and reports at the end
of the computations that simulation process finished successfully. But it returns incorrect results; for example, x1
still equals the initial guess, as if nothing had happened.

Example 3: Unacceptable border width, leading to
very poor performance. We solve the following N  N
Here we show the behavior of the latest release of Dymola linear system in a Newton step:
(Version 2017 FD01 (32-bit), 2016-10-11) and OpenModN
elica (v1.11.0 (64-bit); February 6, 2017) on three exam(9)
 xi = N
ples. Examples 1 and 2 demonstrate that applying tearing
i=1
can lead to completely incorrect results or to initialization
xi + xN = 2
i = 1 : N  1,
(10)
failure. However, correct results are obtained for both examples when tearing is turned off. Example 3 is about per- and we assume that the only variable that can be elimiformance: It shows that tearing can slow down the solu- nated is xN from equation (9); this can be due to the nontion process drastically. Dymola can easily hang for min- linearities of the original problem (whose Newton step we
utes on problems that are otherwise solvable in millisec- see here). All other variables are tear variables, and all
onds without tearing. The causes are discussed in Sec- other equations are residuals. For N = 300, the problem is
tion 3. The examples trigger failure only if the tearing is solved by Dymola in 74 seconds and by OpenModelica in
performed according to the specified ordering. The Mod- 37 seconds. As we argue in Sec. 3.3, the problem is solvelica source files are available in the GitHub repository of able in milliseconds: For N = 300 (the largest dimension
permitted in the free trial version we used), the AMPL
the (Online Supplement).
modeling environment (Fourer et al., 2003) is faster than
Example 1: The residual is overly sensitive to the Dymola and OpenModelica by factors of more than 1200
changes in the tear variable. We solve the following and 600, respectively. The performance of the Modelica
20  20 linear system in a Newton step:
implementations rapidly deteriorates as the problem size
increases: For N = 500, Dymola hangs for more than 6
xi1 + 10xi + xi+1 = 1.2 i = 1:20,
(7) minutes, and OpenModelica takes more than 1.5 minutes.

2

354

Demonstrative examples

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132353

Session 6: Poster Session

The examples are intentionally chosen to be easy. In
challenging real-life examples, like the one in Sec. 5.3, it
is hard to identify and understand the reasons of the failures, because different failure modes usually occur simultaneously and interact with each other. However, the simplicity of the present examples allows us to gain (in Section 3) important insights into the reasons why tearing fails
or causes very poor performance. The examples were chosen to demonstrate the reasons in isolation, one at a time.
This is also the reason why we picked linear examples;
they should be regarded as the linear system solved in a
Newton step.

3

In-depth discussion of the examples

Pathological input problems are ignored throughout this
paper, for example when the system (1) has conflicting
equations and as a consequence it is infeasible, when (1)
is singular, when it is poorly scaled, or when the problem has a huge number of solutions, etc. While these
edge cases are interesting and important, a non-tearing
approach can fail in these cases too, and therefore such
failures are not specific to tearing. Throughout this paper we only focus on those failure modes that are specific
to tearing: We assume that the input problem (1) is feasible and properly scaled, has at most a small number of
real solutions, and that these solutions can be found with
an appropriate non-tearing approach using 64-bit floatingpoint arithmetic. Traditional tearing can fail even if all
these assumptions are met.

3.1

be magnified roughly by a factor of 1019 till we compute
the residual. This has catastrophic consequences. There
is no machine representable number for x1 such that after
eliminating all the other variables according to (12) r is
sufficiently close to zero: The two closest 64-bit floatingpoint numbers enclosing 0.1 give approximately 85.82
and 101.03 for x20 , respectively, due to the roughly 1019
factor magnifying the error in x1 . In other words, (11) is
literally unsolvable in 64-bit floating-point arithmetic with
traditional tearing, whereas solving it with Gaussian elimination is numerically stable even without pivoting. The
failure is not due to a single ill-conditioned elimination
step but the sequence of well-conditioned steps becoming
ill-conditioned when they are chained together as in (12).

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 1

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

Example 1: uncontrollable residual

18

The residual can become practically uncontrollable because it depends too sensitively on the tear variables. To
see this we consider the system

19
20

1

xi1 + 10xi + xi+1 = 1.2

for i = 1:20

(11)

2
3

where x0 := 0.1 and x21 := 0.1 to keep the formulas simple. The exact solution is xi = 0.1 for i = 1:20. The coefficient matrix of the system (11) is a strictly diagonally
dominant tridiagonal matrix (cf. Fig. 1 top), hence solving (11) with Gaussian elimination produces excellent results even without pivoting (Golub and van Loan (1996,
Ch 3.4.10)). As it was demonstrated in Section 2, traditional tearing fails on this easy problem.
We order the coefficient matrix of (11) into BLTF with
minimal border width by moving x1 to the border, see on
the bottom of Fig. 1. Given an initial guess for x1 , the
formula for the forward substitution along the diagonal is:
xi+1 = xi1  10xi + 1.2

for i = 1:19,

(12)

and the residual r := x19  10x20 + 1.1 is a univariate
function of x1 , that is, we have to solve the univariate equation r(x1 ) = 0 for x1 . Because of the factor 10 in (12), the
error in our guess for x1 is multiplied roughly by a factor of 10 in each step of the elimination according to (12).
There are 19 steps in (12), meaning that the error in x1 will
DOI
10.3384/ecp17132353

4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

Figure 1. Top: The sparsity pattern of the coefficient matrix of
problem (11). Black entries correspond to 10, gray entries to 1.
Bottom: The same matrix ordered to bordered lower triangular
form. The leading lower triangular submatrix, surrounded by
dashed lines, is singular to working precision in 64-bit floating
point arithmetic.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

355

Failure Modes of Tearing and a Novel Robust Approach

A similar behavior in the nonlinear case makes the
problem practically unsolvable with iterative solvers, even
if the original problem is easy to solve without tearing.
Distillation columns are real-life examples where such
failures happen, c.f. Doherty et al. (2008).
For those familiar with linear algebra: The condition
number estimate of the coefficient matrix of (11) is 1.5
(symmetric, strictly diagonally dominant tridiagonal matrix), whereas the condition number estimate of the leading lower triangular matrix of the BLTF is 9  1016 , meaning that it is singular to working precision in 64-bit floating point arithmetic. See also Golub and van Loan (1996,
Ch 3.3, and 3.5.4).

3.2

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 1

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

Example 2: insensitive residual

18
19

It can also happen that the residual shows practically no
response to changes in the tear variables. Such an example
is the following:

20

1

xi1 + xi + 15xi+1 = 17

i = 1:20,

2

(13)

3
4

where x0 := 1 and x21 := 1 to keep the formulas simple. It
is easy to see that the solution is xi = 1 (i = 1 : 20). Solving (13) with a non-tearing approach is not a challenge.
Making x1 the only tear variable, and moving it to the
border makes the resulting BLTF have minimal border
width, see Fig. 2. Given an initial guess for x1 , the formula for the forward substitution along the diagonal is:
1
xi+1 = (xi1  xi + 17)
15

5
6
7
8
9
10
11
12
13
14

for i = 1:19,

15

(14)

16
17
18

and the residual

19

r := x19  x20 + 2

20

(15)

is a univariate function of x1 , that is, we have to solve the Figure 2. Top: The sparsity pattern of the coefficient matrix of
problem (13). Black entries correspond to 15, gray entries to 1.
univariate equation
Bottom: The same matrix ordered to bordered lower triangular
r(x1 ) = 0
(16)
form.

for x1 . As it can be seen from (14), the error in our estimate for x1 is divided roughly by a factor of 15 in each step
of the recursion, that is, the error attenuates in an exponential rate. As a consequence, we get r = 0.0000000000
(with 10 decimals) for both x1 = 1 and x1 = 3. This is
unacceptable, since x1 and many of the eliminated variables are still very far from the solution. The reason of the
failure is that the value of r(x1 ) provides no information
about the desired update of x1 : The final equation (16) is
satisfied even with grossly erroneous x1 values.
In the nonlinear case, similar issues can lead to failures
of the tearing approach. Distillation columns are again
real-life examples where such failures happen. In fact, distillation columns are difficult for tearing methods because
one part of the column can magnify the error in the tear
variables with exponential rate (similarly to (12)), while
the remaining part attenuates it with an exponential rate
(similarly to (14)). This in turn can trigger two failure
356

modes of tearing at the same time: the one described in
this section, and the one from the previous section.
As already stated, (13) is not a challenging problem;
it is just that traditional tearing fails. For those familiar
with linear algebra: Although problem (13) is mildly illconditioned, the condition number estimate is 7  1011 , one
can still get the result with several accurate significant digits in 64-bit floating point arithmetic (Golub and van Loan
(1996, Ch 3.3, and 3.5.4)).

3.3

Example 3: unacceptably wide border

Wide border due to tearing incautiously. The primary motivation behind tearing is to speed up the solution
process (Dymola User Manual, Ch. 8.8.2, pp. 433-434).
However, tearing can significantly hurt performance, especially if it is applied without any caution; Example 3

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132353

Session 6: Poster Session

at equations (9) and (10) in Sec. 2 is just one example of
that. Here the problem is that the border width is proportional to the size of the original problem. In case of Dymola, it slows down the model generation and compilation
drastically; for N = 500, the software hangs for more than
6 minutes. OpenModelica hangs for issues that are most
likely independent of tearing, but we failed to track down
the exact causes.
In comparison, solving the instance N = 300 with
AMPL takes only 61 milliseconds, although AMPL adequately performs all relevant tasks, namely:
(i) reading and parsing the model file written in the AMPL
modeling language,
(ii) instantiating the model,
(iii) flattening,
(iv) compiling the C code,
(v) generating binary opcodes for the virtual AMPL stack
machine,
(vi) launching the external solver and executing the code
to compute the solution, and
(vii) writing back the results for the modeling environment.
AMPL and the Modelica implementations have to go
through basically the same steps during the solution process of Example 3; the computational work to be done is
essentially the same for each modeling environment.
For those familiar with linear algebra: The problem
here is that tearing results in catastrophic fill-in (Duff
et al., 1986, Ch. 7). AMPL and the solver it invokes, IPOPT (Wchter and Biegler, 2006) with MA27
from (HSL, 2017), avoid this by not perform tearing, and
by using proper sparse data structures and sparse linear algebra. As far as we can tell, the state-of-the-art Modelica
implementations seem to perform O(n2 ) or more operations, and this can hurt performance already on relatively
small problems. See also (Duff et al., 1986, Ch. 5.8) regarding the so-called O(n2 ) traps.
Wide border due to trying to create a maximum-weight diagonal. Let A denote the coefficient matrix of (11). The reason why tearing failed in Section 3.1
is that the largest entries of A became off-diagonal after A
was ordered to BLTF, and the elimination happened along
the diagonal. The straightforward attempt to fix this is
to mimic complete pivoting (Golub and van Loan (1996,
Ch. 3.4.8)): We order A into BLTF but instead of having a minimal border width, our objective is to have a
maximum-weight diagonal on the lower triangular part.
Indeed, such approaches were proposed in the past, see for
example Westerberg and Edie (1971a,b) and Gupta et al.
(1974).
Although creating a maximum-weight diagonal mitigates the issue of uncontrollable residual, it can easily
lead to the opposite problem, to the issue of the insensitive residual: The example of Sec. 3.2 has a maximumweight diagonal and tearing fails on that easy problem.
Also, compare Fig. 1 with Fig. 2 where the subdiagonal
DOI
10.3384/ecp17132353

became maximum-weight. In short, creating a maximumweight diagonal can turn one failure mode to another.
However, there is another issue that creating a BLTF
with maximum-weight diagonal can also cause: It can
produce a BLTF whose border width is proportional to the
size of the input matrix, whereas if we minimized the border width, the border width would be a small constant,
independent of the problem size. Table 2 and Figure 3
show examples of such disastrous cases. Since the final
system (6) is dense, this means that tearing turns (in the
course of the elimination) a sparse problem into a dense
problem whose size is proportional to the original problem. Such dense problems become intolerably expensive
to solve as their size grows.

4

Failing due to a single elimination
step

In the previous section we discussed failure modes where
a sequence of eliminations led to the failure. In this section we show additional examples where tearing fails due
to a single elimination step, because it leads to an undefined operation (Sec. 4.1) or to a floating-point exception
(Sec. 4.2), or it is multivalued (Sec. 4.3). We comment on
the usual workaround as seen in the state-of-the-art Modelica environments, and propose a novel and better alternative in Sec. 4.4.

4.1

Undefined elimination step

For the sake of demonstration let us assume that in an
elimination step in (3) we want to eliminate x3 from
x1  x2 x3 = 0,

(17)

so we rearrange (17) as
x3 :=

x1
.
x2

(18)

However, this symbolic transformation is invalid if x2 = 0.
If x2 happens to be 0 during the iteration in the tear variables, eliminating x3 according to (18) would lead to division by zero, whereas the original equation (17) does
not suffer from this issue. It is not only division that is
problematic: Another example of this kind of failure is a
negative argument to the logarithm function during the iteration in the tear variables (when working over the set of
real numbers). In general, arguments outside the domain
of the functions involved lead to failure of traditional tearing.

4.2

Floating-point exception in an elimination
step

Floating-point exceptions can easily occur in systems involving an exponential. For example, let the tear variables
be x41 := 440 and x43 := 0.0, and the elimination steps are:
x42 := exp(x41 + 273.15)
x44 := x42 x43 .

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(19)
357

Failure Modes of Tearing and a Novel Robust Approach

Table 2. Unacceptably wide border when the matrix is ordered to BLTF with maximum-weight diagonal on the lower triangular
part.

Matrix

1

2

3

4

5

6

Minimal border

Border width with

Pattern in

width

max-weight diagonal

Figure (3)

Tridiagonal

1

Pentadiagonal

2

Arrowhead

1

7

8

1
2n
2
3n

9 10 11 12 13 14 15 16 17 18 19

1
1

2

3

3

5

4

7

5

9

6

11

7

13

8

15

9

17

10

19

11

18

12

16

13

14

14

12

15

10

16

8

17

6

18

4

19

2

2

3

4

5

6

7

8

9

(not shown)

n1

1

1

top row

10

3

10

1

10

2

9

3

8

4

7

5

6

6

5

7

4

8

3

9

2

10

1

5

7

9

bottom row

9 11 13 15 17 19 18 16 14 12 10 8

8

7

6

5

4

3

2

6

4

2

1

Figure 3. The left column shows the input matrices, the right column the corresponding matrices ordered to BLTF with maximumweight diagonal; black entries correspond to 10, gray entries to 1. The tridiagonal matrix of size n will have a border width n2 (top
row). In the worst case, when the optimal ordering is the arrowhead matrix (bottom row), the border width is n  1.

358

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132353

Session 6: Poster Session

Unlike previously, the elimination steps are mathematically sound here. However, in 64-bit floating-point arithmetic we get: x42 = inf and x44 = nan, where inf and
nan stand for infinity and not a number, see (IEEE 754).
The eliminations cannot be continued as x42 does not have
any correct significant digits, and x44 is not a number. Unfortunately, similar failures are not at all uncommon in
practice, especially with thermodynamic models.
Getting a floating-point exception due to a single elimination step is an extreme case. More common is that the
error in the tear variables is amplified during a sequence
of elimination steps, as already discussed in Sections 3.1,
and this leads to an interaction between failure modes by
triggering a floating-point exception. For example, let us
assume that x41 is not a tear variable, but an eliminated
one, and the sequence of eliminations leading up to x41
yields the value 440 for x41 due to amplification of the error in the tear variables. This is similar to Example 1 of
Sec. 3.1 where the value of x20 was three orders of magnitude off compared to the true value. In Example 1 it
was the residual that became uncontrollable, here it is a
floating-point exception that causes the ultimate failure.

4.3

Multivalued elimination step

In the equation
x12 + 2x1 x2  1 = 0,

that are perfectly eligible to become a tear variable. The
same holds for disallowing division by variables in an attempt to avoid undefined elimination steps and floatingpoint exceptions. As for multivalued eliminations, it is
left to chance whether a feasible solution is found or not,
see Sec. 4.3.
It is moderately easy to avoid single elimination steps
that can potentially become problematic depending on the
actual values of the variables involved: In Baharev et al.
(2017b) we proposed a novel pre-processing technique
based on interval arithmetic for recognizing single-step
eliminations that are guaranteed to be single-valued and
numerically well-behaved, irrespective of the actual value
of the variables involved. (Of course, it does not prevent a
sequence of eliminations from becoming ill-conditioned.)
Our approach offers more flexibility in the choice of tear
variables than the common workaround, and it does that
without risking any numerically troublesome operation.
The increased flexibility in the choice of the tears can help
to reduce the border width of the BLTF significantly. As
for multivalued elimination steps, nothing is left to chance
in our approach. For those familiar with linear algebra:
Our method is, in some sense, a nonlinear extension of
threshold pivoting (Duff et al., 1986, Ch. 4.4).

5

A novel robust approach

(20)

Staircase sampling was inspired by (Baharev and Neuthe elimination of x1 requires to solve this equation for x1 . maier, 2014), and proposed in (Baharev et al., 2016) to
mitigate all of the issues listed in Sections 3 and 4. A deHowever, there are two possibilities to perform this:
tailed presentation of this method is outside the scope of
q
q
this paper; here we only sketch the basic idea.
x1 = x2 + x22 + 1 and x1 = x2  x22 + 1. (21)
The subsystem
g(y, z) = 0
(22)
To continue the remaining eliminations, we would have to
know which solution for x1 will remain feasible, or con- in (5) is an underdetermined system of equations; it has
tinue with both possibilities for x1 . If we ignore the fact infinitely many solutions per our assumptions in the first
that the elimination step is multivalued, we either risk los- paragraph of Section 3. The aim of staircase sampling is
ing solutions, or we risk that we continue with that value to find a small set of points such that every solution of (22)
for x1 that becomes infeasible in later eliminations. This is close to one of the points in this set. We call this small
failure mode is simply ignored in state-of-the-art Model- set of points the sample: It is an approximation to a samica implementations, for example, [the solver] hopefully ple from the infinitely many solutions of (22). The samreturns the solution closest to the guess value (Dymola ple is built up incrementally, similarly to the usual tearing
User Manual, Ch. 8.9.2, p. 442); the emphasis is ours. If approach. Staircase sampling requires finite and reasonwe want to find all well-separated solutions of a nonlinear able lower and upper bounds on all of the variables; this is
system of equations, the kind of applications discussed in needed to allow an adequate sampling of the search space.
(Baharev et al., 2016), this is unacceptable.
Staircase sampling starts with an entire set of values for z (a scattered set of points between the variable
4.4 Avoiding floating-point exceptions, undebounds), and not just with a single value for z as in the
fined and multivalued elimination steps
usual tearing approach. The algorithm then proceeds simThe commonly seen workaround in state-of-the-art Mod- ilarly to the common tearing algorithms, and it performs
elica tools to avoid undefined and multivalued elimina- eliminations. A minor difference compared to (3) is that
tion steps is to chose only linearly appearing variables staircase sampling solves small nonlinear systems in the
with non-zero coefficients as tear variables. Although this elimination steps, that is, it performs block elimination.
workaround is easy to implement, it is also overly lim- The fundamental difference is that after each block elimiiting in the choice of the tear variables. This can lead nation step, the points are redistributed, and a subvector of
to a BLTF with unacceptably wide border and eventually y is recomputed as necessary. The goal of this redistributo very poor performance, because it excludes variables tion algorithm is to improve the spatial distribution of the
DOI
10.3384/ecp17132353

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

359

Failure Modes of Tearing and a Novel Robust Approach

Index i

points between the variable bounds: It discards points that adjacent indices, as shown in Fig. 4. The connecting lines
are too close, and it inserts new points where the search have no meaning, but allow us to plot without ambiguity
space has become deserted. The details of the redistri- several vectors in one figure.
bution algorithm are discussed in (Baharev et al., 2016).
1
Staircase sampling returns a set of scattered points, sat2
isfying (22) fairly well. In the current implementation,
3
those points are chosen that violate (5) the least, and they
4
5
are used as a starting point for large-scale sparse solvers
6
that target solving (1) directly. In the future, interpolation
7
and extrapolation on the complete set of scattered points
8
9
will be used to find starting points that approximately sat10
isfy (1).
11

5.1

How staircase sampling resolves the failure modes of traditional tearing

We now compare staircase sampling to traditional tearing
from the point of view of the the failure modes; the items
are enumerated in the same order as in Sections 3 and 4.

2. As a consequence of the previous point, we can minimize the border width in our ordering algorithm
without having to worry about the exponential error growth rate during the eliminations. An exact
ordering algorithm to minimize the border width is
given in (Baharev et al., 2017b). Furthermore, staircase sampling works on so-called staircase triangular
matrices, and those matrices allow more flexibility in
the orderings than the BLTFs do.
3. A single block elimination step can also fail, however, this is usually not an issue. Staircase sampling
works with a set of points, losing some of them is
typically not a problem: New points are inserted after each block elimination step in the redistribution
algorithm, which makes up for the lost points.

Index i

1. As shown in Sections 3.1 and 3.2, the error in our initial estimate for z can grow or attenuate exponentially
even in simple cases, ultimately leading to the failure
of traditional tearing. Staircase sampling breaks this
exponential change in the redistribution step; the error accumulation in an exponential rate is not possible.

12
13
14
15
16
17
18
19
20
1
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
1

0

1
Value of xi

2

3

0

1
Value of xi

2

3

Figure 4. Top: Plotting the 20-dimensional vector x in 2 dimensions by placing a dot at (xi , i) for i = 1:20. Bottom: To indicate
that the dots belong to the same vector, we connect the neighboring points with linear lines, and we may omit the dots. The
connecting lines have no meaning, but allow us to plot without
ambiguity several vectors in one figure.

4. Staircase sampling builds up a set of solution vectors, not just a single solution vector at a time as in
traditional tearing. As a consequence, multivalued 5.3 Demonstration test case
elimination steps are handled naturally.
The robustness of staircase sampling is demonstrated on a
particularly challenging distillation column. The model
5.2 A note on plotting vectors in 2 dimensions and its parameters correspond to the Auto model (GtHere we explain how the starting points and solution vec- tinger et al., 1997). The problem has three steady-state
tors will be plotted in the next section. We first select a solutions: two stable steady-state branches and an unstasubset of the variables according to an appropriate rule; ble branch. Both the inside-out procedure (Boston and
for example, we select the methanol composition in each Sullivan, 1974) and the simultaneous correction procedure
device of the system that we are simulating. Let us as- (Naphthali and Sandholm, 1971) were reported to miss the
sume that we have selected a 20-dimensional subset. We unstable steady-state solution, see (Vadapalli and Seader,
then draw each 20-dimensional vector as a curve in 2 di- 2001) and (Kannan et al., 2005). However, all steady-state
mensions by connecting the points (xi , i) (i = 1:20) with branches were computed either with the AUTO software
360

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132353

Session 6: Poster Session

1

ing Languages and Tools (Berlin; Germany; July 30; 2007),
Linkping Electronic Conference Proceedings, pages 151
163. Linkping University Electronic Press; Linkpings universitet, 2007.

Stage index

5

A. Baharev, H. Schichl, and A. Neumaier. Decomposition methods for solving nonlinear systems of equations. Submitted, 2017a. URL http://reliablecomputing.eu/
baharev_tearing_survey.pdf.

10

15

20
0.0
0.2
0.4
0.6
0.8
1.0
Liquid phase mole fraction of methanol
Figure 5. The three steady-state solutions (dashed gray lines)
and those generated starting points (solid black lines) that are the
closest to them. The gradient-based solver IPOPT converges to
the nearest solution when started from the corresponding starting
point.

package (Doedel et al., 1995) or with an appropriate continuation method (Gttinger et al., 1997; Vadapalli and
Seader, 2001; Kannan et al., 2005). The initial estimates
were carefully chosen with the / analysis (Bekiaris
et al., 1993; Gttinger and Morari, 1996), and special attention was paid to the turning points and branch switching.
Our goal with staircase sampling was to find all solutions automatically, without any initial estimates, without
relying on any domain-specific knowledge, and without
any human interaction. This goal was achieved: All three
steady-state solutions are found when IPOPT (Wchter
and Biegler, 2006) is run from the starting points generated with staircase sampling. Figure 5 shows the three
steady-state solutions of a 20-stage column and those
starting points that are the closest to them; see also
Sec. 5.2 as to how the solution vectors are plotted. For
a more detailed discussion of this example, and for other
examples see (Baharev et al., 2016).
Despite these promising results, the practical applicability and limitations of staircase sampling are yet to be
explored, and a benchmark suite with real-world problems
would be needed for that.

Acknowledgement

A. Baharev, H. Schichl, and A. Neumaier.
Ordering matrices to bordered lower triangular form with
minimal border width.
Submitted, 2017b.
URL
http://reliablecomputing.eu/baharev_
tearing_exact_algorithm.pdf.
Ali Baharev and Arnold Neumaier. A globally convergent
method for finding all steady-state solutions of distillation
columns. AIChE J., 60:410414, 2014.
Ali Baharev, Ferenc Domes, and Arnold Neumaier. A robust approach for finding all well-separated solutions of sparse systems of nonlinear equations. Numerical Algorithms, pages
127, 2016. doi:10.1007/s11075-016-0249-x. URL https:
//doi.org/10.1007/s11075-016-0249-x.
N. Bekiaris, G. A. Meski, C. M. Radu, and M. Morari. Multiple steady states in homogeneous azeotropic distillation. Ind.
Eng. Chem. Res., 32:20232038, 1993.
J. F. Boston and S. L. Sullivan. A new class of solution methods
for multicomponent, multistage separation processes. Can. J.
Chem. Eng., 52:5263, 1974.
Emanuele Carpanzano. Order reduction of general nonlinear
DAE systems by automatic tearing. Mathematical and Computer Modelling of Dynamical Systems, 6(2):145168, 2000.
Franois E Cellier and Ernesto Kofman. Continuous system simulation. Springer Science & Business Media, 2006.
R. de P. Soares and A. R. Secchi. EMSO: A new environment for
modelling, simulation and optimisation. In Computer Aided
Chemical Engineering, volume 14, pages 947952. Elsevier,
2003.
E. J. Doedel, X. J. Wang, and T. F. Fairgrieve. AUTO94: Software for continuation and bifurcation problems in ordinary
differential equations. Technical Report CRPC-95-1, Center
for Research on Parallel Computing, California Institute of
Technology, Pasadena CA 91125, 1995.
M. F. Doherty, Z. T. Fidkowski, M. F. Malone, and R. Taylor.
Perrys Chemical Engineers Handbook, chapter 13, page 33.
McGraw-Hill Professional, 8th edition, 2008.

The research was funded by the Austrian Science Fund I. S. Duff, A. M. Erisman, and J. K. Reid. Direct Methods for
(FWF): P27891-N32. Support by the Austrian Research
Sparse Matrices. Clarendon Press, Oxford, 1986.
Promotion Agency (FFG) under project numbers 846920
Dymola User Manual. Volume 2. Dymola 2017 FD01, Dassault
and 853930 is thankfully acknowledged.
Systmes AB, 2016.

References
B. Bachmann, P. Aronon, and P. Fritzson. Robust initialization of differential algebraic equations. In 1st International Workshop on Equation-Based Object-Oriented Model-

DOI
10.3384/ecp17132353

H. Elmqvist and M. Otter. Methods for tearing systems of equations in object-oriented modeling. In Proceedings ESM94,
European Simulation Multiconference, Barcelona, Spain,
June 13, pages 326332, 1994.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

361

Failure Modes of Tearing and a Novel Robust Approach

Robert Fourer, David M. Gay, and Brian Wilson Kernighan.
AMPL: A Modeling Language for Mathematical Programming. Brooks/Cole USA, 2003.

L. A. Ochel and B. Bachmann. Initialization of equationbased hybrid models within OpenModelica. In 5th International Workshop on Equation-Based Object-Oriented Modeling Languages and Tools (University of Nottingham; Nottingham, UK; April 19, 2013), Linkping Electronic Conference
Proceedings, pages 97103. Linkping University Electronic
Press; Linkpings universitet, 2013.

Peter Fritzson. Principles of Object-Oriented Modeling and
Simulation with Modelica 2.1. Wiley-IEEE Press, 2004.

Online Supplement, 2017. URL https://github.com/
baharev/failure-modes-of-tearing.

G. H. Golub and C. F. van Loan. Matrix Computations. The
Johns Hopkins University Press, Baltimore, USA, 3rd edition, 1996.

C. C. Pantelides. The consistent initialization of differentialalgebraic systems. SIAM Journal on Scientific and Statistical
Computing, 9(2):213231, 1988.

gPROMS. Process Systems Enterprise Limited, gPROMS.
https://www.psenterprise.com, 2017. [Online;
accessed 21-Jan-2017].

P. C. Piela, T. G. Epperly, K. M. Westerberg, and A. W. Westerberg. ASCEND: An object-oriented computer environment
for modeling and analysis: The modeling language. Computers & Chemical Engineering, 15(1):5372, 1991.

Hilding Elmqvist. A Structured Model Language for Large Continuous Systems. PhD thesis, Department of Automatic Control, Lund University, Sweden, May 1978.

Prem K. Gupta, Arthur W. Westerberg, John E. Hendry, and
Richard R. Hughes. Assigning output variables to equations
using linear programming. AIChE Journal, 20(2):397399,
1974.
T. E. Gttinger and M. Morari. Comments on multiple steady
states in homogeneous azeotropic distillation. Ind. Eng.
Chem. Res., 35:28162816, 1996.
T. E. Gttinger, C. Dorn, and M. Morari. Experimental study of
multiple steady states in homogeneous azeotropic distillation.
Ind. Eng. Chem. Res., 36:794802, 1997.
HSL. A collection of Fortran codes for large scale scientific
computation., 2017. URL http://www.hsl.rl.ac.
uk.
IEEE 754.
IEEE standard for floating-point arithmetic.
IEEE Std 754-2008, pages 170, Aug 2008.
doi:10.1109/IEEESTD.2008.4610935.
A. Kannan, M. R. Joshi, G. R. Reddy, and D. M. Shah. Multiplesteady-states identification in homogeneous azeotropic distillation using a process simulator. Ind. Eng. Chem. Res., 44:
43864399, 2005.
A. Krner, W. Marquardt, and E.D. Gilles. Getting around consistent initialization of DAE systems? Computers & Chemical Engineering, 21(2):145158, 1997.
F. Magnusson and J. kesson.
Symbolic elimination
in dynamic optimization based on block-triangular ordering.
Optimization Methods and Software, 2017.
doi:10.1080/10556788.2016.1270944. Published online: 17
Jan 2017.
S. Mattsson, H. Elmqvist, and M. Otter. Physical system modeling with Modelica. Control. Eng. Pract., 6:501510, 1998.
S. E. Mattsson, M. Otter, and H. Elmqvist. Modelica hybrid
modeling and efficient simulation. In Decision and Control, 1999. Proceedings of the 38th IEEE Conference on, volume 4, pages 35023507, 1999.
L. M. Naphthali and D. P. Sandholm. Multicomponent separation calculations by linearization. AIChE J., 17:148153,
1971.

362

M. Sielemann and G. Schmitz. A quantitative metric for robustness of nonlinear algebraic equation solvers. Mathematics
and Computers in Simulation, 81(12):26732687, 2011.
M. Sielemann, F. Casella, and M. Otter. Robustness of declarative modeling languages: Improvements via probability-one
homotopy. Simulation Modelling Practice and Theory, 38:
3857, 2013.
P. Tuber, L. Ochel, W. Braun, and B. Bachmann. Practical
realization and adaptation of Celliers tearing method. In
Proceedings of the 6th International Workshop on EquationBased Object-Oriented Modeling Languages and Tools,
pages 1119, New York, NY, USA, 2014. ACM.
M. Tiller. Introduction to physical modeling with Modelica.
Springer Science & Business Media, 2001.
J. Unger, A. Krner, and W. Marquardt. Structural analysis of
differential-algebraic equation systems  theory and applications. Computers & Chemical Engineering, 19(8):867
882, 1995.
A. Vadapalli and J. D. Seader. A generalized framework for
computing bifurcation diagrams using process simulation
programs. Comput. Chem. Eng., 25:445464, 2001.
R.C. Vieira and E.C. Biscaia Jr. Direct methods for consistent
initialization of DAE systems. Computers & Chemical Engineering, 25(910):12991311, 2001.
A. Wchter and L. T. Biegler. On the implementation of an
interior-point filter line-search algorithm for large-scale nonlinear programming. Mathematical Programming, 106:25
57, 2006.
A. W. Westerberg and F. C. Edie. Computer-aided design, Part 1
Enhancing Convergence Properties by the Choice of Output Variable Assignments in the Solution of Sparse Equation
Sets. The Chemical Engineering Journal, 2:916, 1971a.
A. W. Westerberg and F. C. Edie. Computer-Aided Design,
Part 2 An approach to convergence and tearing in the solution
of sparse equation sets. Chem. Eng. J., 2(1):1725, 1971b.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132353

Towards Adjoint and Directional Derivatives in FMI utilizing
ADOL-C within OpenModelica
Willi Braun1
1 FH

Kshitij Kulshreshtha2

Rdiger Franke3

Andrea Walther2

Bernhard Bachmann1

Bielefeld University of Applied Science, {wbraun,bernhard.bachmann}@fh-bielefeld.de
2 Universitt Paderborn, kshitij@math.upb.de,andrea.walther@uni-paderborn.de
3 ABB AG, Mannheim, ruediger.franke@de.abb.com

Abstract
Algorithmic differentiation has proven to be an efficient
method for evaluating derivative information for implementations of mathematical functions. In the context of
the Functional Mockup Interface (FMI) the reverse mode
of algorithmic differentiation shows immense promise.
FMI is increasingly used for model-based applications,
such as parameter estimation or optimal control. The paper motivates the exploitation of algorithmic differentiation and proposes an extension of FMI for the evaluation
of adjoint directional derivatives.
Attempts to interface algorithmic differentiation libraries with Modelica tools have been made. Instead of
generating code for the target language which is instrumented with algorithmic differentiation library API and
then compiled, in this new approach the intermediate representation used by the library is generated directly. This
avoids compilation of the target language that often takes a
large fraction of the overall simulation time. It also avoids
model execution in order to create such an internal representation at runtime. The initial results are presented
here.
Keywords: OpenModelica, ADOL-C, Derivatives, Jacobian

1 Introduction
Algorithmic differentiation (Griewank and Walther, 2008)
is a technique to compute derivatives of functions expressed as computer programs efficiently, and accurately
upto machine precision (Griewank et al., 2012). Ruge
et al. (2014) first investigated the use of the algorithmic differentiation tool ADOL-C (Walther and Griewank,
2012) in conjunction with OpenModelica (Fritzson et al.,
2006). ADOL-C is designed for the C++ programming
language and uses operator overloading to create an internal representation of the computation, called a trace, when
a program instrumented with the datatype adouble is executed. In Ruge et al. (2014) such instrumented code written in C++ was generated in addition to the usual model
code for the C-Runtime and was compiled and linked with
the ADOL-C library in addition to the C-Runtime Library
of OpenModelica.
In this work we endeavoured to generate the trace for
DOI
10.3384/ecp17132363

the use by the ADOL-C library to compute derivatives directly from within the OpenModelica compiler. Since the
compiler has all the required information about the computation of the model it can present this information in the
manner we need, without having to generate C++ code
and executing it. On the other hand the ADOL-C library
did not have any other mechanism for creation the internal data structures associated with a trace, other than executing C++ code instrumented with the datatype adouble.
The challenge was therefore two-fold: firstly to teach the
ADOL-C library to accept a trace in another format, and
secondly to generate this format from the OpenModelica
compiler while processing the model.
This paper is organized as follows: Section 2 outlines
the motivation for the exploitation of algorithmic differentiation in FMI. Further more it presents a proposal for
an extension of FMI offering the evaluation of adjoint directional derivatives. The needed details of algorithmic
differentiation as well as the implementation of ADOL-C
are described in section 3. Whereas section 4 focuses on
the implementation work in OpenModelica. Finally, the
first results are shown in section 5.

2 Adjoint directional derivatives in
FMI
FMI emerged as a new standard resulting from the ITEA2
project MODELISAR, in 2010. The standard is a response
to the industrial need to connect different environments for
modeling, simulation and control system design. Commonly, different tools are used for different applications,
whereas simulation analysis at the system integration level
requires tools to be connected. FMI provides the means to
perform such integrated simulation analysis.
FMI specifies an XML format for model interface information and a C API for model execution. The XML
format, specified by an XML schema, contains information about model variables, including names, units and
types, as well as model meta data. The C API, on the other
hand, contains C functions for data management, e.g., setting and retrieving parameter values, and evaluation of the
model equations. The implementation of the C API may
be provided in source code format, or more commonly as
a compiled dynamically linked library.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

363

Towards Adjoint and Directional Derivatives in FMI utilizing ADOL-C within OpenModelica

Starting from version 2.0, the Functional Mock-up In- computes:
terface (FMI) is well suited to hook Modelica models to


numerical solvers for model-based applications, such as
 h(vknown , vrest ) T
vknown =
vunknown .
(5)
parameter estimation or optimal control (Franke et al.,
 vknown
2015). This way numerical routines can focus on the solution process, while FMI abstracts implementation details It has the signature:
of the model. It is likely that such applications of FMI will
fmiStatus fmi2GetAdjointDerivative (
increase. FMI should provide appropriate model derivafmi2Component c ,
tives.
c o n s t f m i 2 V a l u e R e f e r e n c e vUnknown_ref [ ] ,
s i z e _ t nUnknown ,
Consider the solution of a least squares problem for pac
o n s t f m i 2 V a l u e R e f e r e n c e vKnown_ref [ ] ,
rameter estimation as example. A general model has the
s
i z e _ t nKnown ,
form
vunknown = h(vknown , vrest ),

(1)

c o n s t f m i 2 R e a l dvUnknown [ ] ,
f m i 2 R e a l dvKnown [ ] )

The new function allows to obtain one row of the Jacobian matrix, or a linear combination of rows of the JaThe task is to obtain nKnown parameters such that a sum cobian matrix, with only one model evaluation in reverse
of squared residuals for nUnknown model outputs y and mode of algorithmic differentiation. The computation of
(3) becomes significantly more efficient. Only K calls to
k = 1, . . . , K given data points yk is minimized:
fmi2GetAdjointDerivative are needed, one call for each data
K
point k and arbitray numbers of nKnown parameters or
R =  kyk  h(vknown , vrest,k )k2  min .
(2) nUnknown model outputs, when passing the values of the
vknown
k=1
residuals as seeds
h:R

nKnown

R

nRest

R

nUnknown

.

The solution must fulfill the necessary condition

vunknown,k = yk  h(vknown , vrest,k ).

R
= zeros(nKnown) =
(3)
 vknown
K 
  h(vknown , vrest,k )
2  yk  h(vknown , vrest,k )
.
 vknown
k=1
The solution process, for instance applying Newtons
method, involves the successive computation of (3), including model derivatives.
The existing API of FMI 2.0 provides the function
fmi2GetDirectionalDerivative to obtain a column of the Jacobian matrix  h(vknown , vrest )/ vknown or a linear combination of columns of the Jacobian matrix. One computation
of directional derivatives gives:
vunknown =

 h(vknown , vrest )
vknown .
 vknown

(4)

The signature of the API function is:
fmiStatus fmi2GetDirectionalDerivative (
fmiComponent c ,
c o n s t f m i 2 V a l u e R e f e r e n c e vUnknown_ref [ ] ,
s i z e _ t nUnknown ,
c o n s t f m i 2 V a l u e R e f e r e n c e vKnown_ref [ ] ,
s i z e _ t nKnown ,
c o n s t f m i 2 R e a l dvKnown [ ] ,
f m i 2 R e a l dvUnknown [ ] )

The computation of (3) requires K  nKnown calls to
fmi2GetDirectionalDerivative . This is inefficient if multiple
parameters shall be estimated (nKnown > 1).
This is why the FMI interface should be extended with
a new function fmi2GetAdjointDerivative , along with a capability flag providesAdjointDerivatives . The new function
364

(6)

3 Algorithmic differentiation using
ADOL-C
In order to apply algorithmic differentiation (AD) on a
program we model the program structure as a sequence of
instructions, which perform specific mathematical functions. This is called an evaluation procedure in Griewank
and Walther (2008). The evaluation procedure can be then
evaluated forwards or reverse to compute the derivatives
in the so called forward mode and reverse mode of AD.
Griewank and Walther (2008, Chapter 3 and 4) describe
this process in great detail and give bounds on the compexity and memory requirements. The main import of the
complexity analysis is that the reverse mode is very well
suited to compute gradient vectors for functions in much
less complexity than they can be computed otherwise, either numerically or symbolically. The same applies to
computing rows of the Jacobian matrix.
ADOL-C implements the AD process by overloading
the operators and mathematical functions in the C++ programming language for a special datatype adouble. Such
supported operations are called elementary operations.
Each of these overloaded operators and functions when
executed records the elementary operation currently being performed, the locations of the operands in working memory, and the locations of the results in working
memory. This record is created normally on runtime,
when a program, instrumented with the ADOL-C headers,
datatypes and some instructions on when to begin and end
the recording, is executed. ADOL-C is then able to use
this record, called a trace, to evaluate function values, first

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132363

Session 6: Poster Session

and higher order derivatives in forward and reverse mode
at any given point of evaluation. The trace can be made
persistent even after the program has terminated. Traditionally this trace is stored in binary format as raw data
in three different files, one for the list of operations, one
for the list of operand locations, and one for storing any
constant values that might occur. The organisation of the
trace is as follows. For each operation a character to represent it is stored. Based on what the operation actually is,
it will requires a number of operands, which are stored as
unsigned integer locations inside a data buffer, followed
by the location, where the result of the operation will be
stored. In some operations a constant may be involved,
this value is stored as is.
In the work of Ruge et al. (2014) the Modelica models were translated into C++ code instrumented with the
ADOL-C headers and datatypes, using a mechanism similar to the generation of C code for the model in OpenModelica. The drawback was that compilation linking and
one-time execution of this C++ code was quite slow due
to the use of operator overloading, compared to the generated C code. It was suggested, that since OpenModelica
was already analysing the model in great detail, could we
not create the trace of the model directly instead of generating C++ code.
/ / define independent
{ op : a s s i g n _ i n d l o c : 0 }
{ op : a s s i g n _ i n d l o c : 1 }
/ / operations
{ op : m u l t _ d _ a l o c : 0 l o c : 4 v a l :  0 . 2 5 }
{ op : d i v _ a _ a l o c : 1 l o c : 0 l o c : 5 }
{ op : p l u s _ a _ a l o c : 4 l o c : 5 l o c : 6 }
{ op : p l u s _ d _ a l o c : 6 l o c : 3 v a l : 3 . 0 }
{ op : l o g _ o p l o c : 0 l o c : 4 }
{ op : m u l t _ d _ a l o c : 4 l o c : 5 v a l :  3 . 0 }
{ op : p l u s _ a _ a l o c : 1 l o c : 5 l o c : 2 }
/ / d e f i n e depenpendent
{ op : a s s i g n _ d e p l o c : 2 }
{ op : a s s i g n _ d e p l o c : 3 }
/ / death_not
{ op : d e a t h _ n o t l o c : 0 l o c : 8 }

Figure 1. An example of a texual trace for ADOL-C

OpenModelica is able to generate textual information
rather than binary. Therefore the first step required for
creating a trace directly was to allow a textual representation of the trace and that ADOL-C understands such a
textual representation. A simple ASCII representation of
the operations, locations and constants was devised with
some delimiters to make parsing easier. Each elementary operation supported by ADOL-C is given a textual
name stored with the keyword "op:". The locations of
all the operands inside the work buffer in decimal notation follow this and then the location of the result in the
work buffer, each of these using the keyword "loc:". At
the end any required constant for the particular operation
is given in decimal floating point notation using the keyDOI
10.3384/ecp17132363

word "val:". Braces separate one such record from another. This textual representation is a natural extension of
the binary representation for ADOL-C traces, which has
long been a part of the ADOL-C public API. An ADOL-C
driver function can now be used to convert any traditional
binary trace to this textual representation and store it in a
file. This format will be made a part of the public API of
ADOL-C in the next feature release. An example of a file
containing such a textual trace is shown in Figure 1.
A driver was added to ADOL-C to be able to read and
parse a text file in ASCII notation with the above information using regular expressions to match the format described above and convert it to the traditional binary notation at runtime. Anything not matching the defined regular
expressions is considered a comment and ignored.

4 Generation of Operation Lists
In the first step of the compilation process in Modelica
tool, a model is transformed by the front-end into a flat
representation, consisting essentially of lists of variables,
functions, equations and algorithms. In this phase, a basic
structural analysis of the differential-algebraic equations
(DAE) is performed to detect the states and discrete variables and eliminate alias variables. The basic step of a
Modelica compiler is to causalize the DAE and transform
into ordinary differential equations (ODE). Then the target
code is generated from the optimized system in order to
perform the simulation. For the simulation the generated
code needs to be compiled by the target language compiler
and linked with the simulation runtime library. The default
target language of the OpenModelica Compiler (OMC) is
C and the GNU C compiler is used as default C compiler. In order to generate operation lists by OMC, which
are readable by ADOL-C, the code generation module of
OMC has been extended by a new target, the ADOL-C target. Basically the operation lists are generated by traversing the equation expressions and for every mathematical
operation creating the corresponding ADOL-C operation.
This is straight forward for assignments thus the OMC
has transformed all equations into assignments due to the
causalization. The implicit equations of the strong connected components require special treatment (Griewank
and Walther, 2008). Furthermore, the OpenModelica simulation runtime is linked with the ADOL-C library in order
to enable the usage of the ADOL-C capability during the
simulation process. At the current status of the implementation we evaluate the sparse Jacobian for the integration
process. One main advantage over the former approach is
that the compilation of the target language can be avoided
by processing the operation lists directly.

5 First Results
The first results to test the performance of the approach
presented here are based on benchmark models from the
ScalableTestSuite library (Casella, 2015). In the current
implementation status the sparse jacobian evaluation used

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

365

Towards Adjoint and Directional Derivatives in FMI utilizing ADOL-C within OpenModelica

by the time integration method ida is used for evaluation. In the tables 1 and 2 all numbers are produced
by using the model ScalableTestSuite.Elementary.SimpleODE.
Models.CascadedFirstOrder.

compilation of the model code is needed any more. The
advantage of this approach is not only good performance,
moreover it gives access to a feature-rich AD tool (e.g.
higher-derivative, reverse mode). Furthermore, an extenTable 1. Evaluation time of the Jacobian. Compare OMC sym- sion of FMI involving adjoint derivatives is proposed and
motivated by optimization-based applications, where such
bolic vs. ADOL-C
derivatives are mandatory. The implementation of this extension can be achieved by the approach described here.
N
ADOL-C
OM Symbolic
However, this requires some more implementation work,
100
0.000480442 0.000156783
since the current implementation does not yet support all
200
0.000830835 0.000413299
Modelica language features. The most important and chal400
0.00157551
0.000952923
lenging aspect is the treatment of implicit equations. In fu800
0.00294508
0.00209405
ture the authors will continue working on supporting more
1600
0.00676732
0.00536921
language features with the approach described. Further,
3200
0.0141433
0.012003
the here proposed FMI extension will be implemented and
6400
0.0390204
0.0310391
demonstrated with a complex example.
12800
0.0771545
0.0756394
7 Acknowledgments
25600
0.1532143
0.1621433
In table 1 the time of one Jacobian evaluation is stated,
calculated by totalTime
, where totalTime is the time that
N
is needed to evaluate the Jacobian over the entire simulation horizon and N is the number of evaluations done.
One can see that the evaluation time for the given model
is quite equal between the generated symbolic Jacobian by
OMC and the evaluation by ADOL-C. Note that ADOL-C
is performing additional work (e.g. memory allocation
and colouring) in the first call.
Table 2. Generation performance of Jacobian. Compare OMC
symbolic vs. ADOL-C

N
100
200
400
800
1600
3200
6400
12800
25600

ADOL-C
generate
read
0.00046 0.01475
0.00089 0.02879
0.00178 0.05794
0.00372 0.11320
0.00860 0.22766
0.01749 0.45620
0.03702 0.91150
0.07571 1.82352
0.15910 3.60362

OM Symbolic
generate compile
0.015
0.032
0.059
0.119
0.03
0.244
0.14
0.523
0.38
1.229
0.48
2.569
1.01
5.459
1.65

The presented work is part of the PARADOM project, that
is funded by the Federal Ministry of Education and Research (BMBF) under the support code 01IH15002.

References
F. Casella.
Simulation of large-scale models in Modelica: State of the art and future perspectives.
In
P. Fritzson and H. Elmqvist, editors, Proceedings 11th
International Modelica Conference, pages 459468, Versailles, France, Sep 2123 2015. The Modelica Association.
doi:10.3384/ecp15118459.
R. Franke, M. Walther, N. Worschech, W. Braun, and B. Bachmann. Model-based control with FMI and a C++ runtime for
Modelica. In Proceedings of the 11th International Modelica
Conference. Modelica Association, Paris, France, Sep. 2015.
P. Fritzson, P. Aronsson, H. Lundvall, K. Nystrm, A. Pop,
L. Saldamli, and D. Broman. Openmodelica - a free
open-source environment for system modeling, simulation,
and teaching. In Computer Aided Control System Design, 2006 IEEE International Conference on Control Applications, 2006 IEEE International Symposium on Intelligent Control, 2006 IEEE, pages 1588 1595, oct. 2006.
doi:10.1109/CACSD-CCA-ISIC.2006.4776878.
A. Griewank and A. Walther. Principles and Techniques of Algorithmic Differentiation, Second Edition. SIAM, 2008.

The performance of generating the appropriate Jaco- A. Griewank, K. Kulshreshtha, and A. Walther. On the numerbian is stated in table 2. These timings are divided in two
ical stability of algorithmic differentiation. Computing, 94
(2-4):125149, 2012.
stages. For ADOL-C it is time for the generation of the
operation list, and the time to read them at runtime. For
V. Ruge, W. Braun, B. Bachmann, A. Walther, and K. Kulthe symbolic Jacobian generated by OMC it is the generashreshtha. Efficient implementation of collocation methtion of directional derivative code and the additional time
ods for optimization using openmodelica and ADOL-C. In
to compile the generated C code. This result shows the
H. Tummescheit and K.-E. rzn, editors, Proceedings of the
linear complexity of the new approach presented in this
10th Modelica Conference, pages 10171025, Lund, Sweden,
2014. Modelica Assiciation and Lund University Electronic
paper.
Press. doi:10.3384/ECP140961017.

6 Conclusion and Future work
This paper presents a new approach to generate a model
evaluation trace for algorithmic differentiation, where no
366

A. Walther and A. Griewank. Getting started with ADOL-C. In
U. Naumann and O. Schenk, editors, Combinatorial Scientific
Computing, pages 181202. Chapman-Hall, 2012.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132363

PDEModelica and Breathing in an Avalanche
Jan ilar*+, Filip Jeek#, Ji Kofrnek+
+ Institute of Pathological physiology, First Faculty of Medicine, Charles University, Prague, Czech republic
# Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic
* Corresponding Author Institute of Pathological physiology, U nemocnice 5, Praha 2 128 00, Czech Republic,
jansilar@jansilar.cz

Abstract
This paper presents an updated version of Modelica
language extension for partial differential equations
(PDE) called PDEModelica and implementation of its
support in OpenModelica. This support is limited to
1-dimensional problems and the first and second partial
derivatives. PDEModelica is introduced by a string
equation model and later by a real life model of
respiration during a snow burial. This model describes
CO2 advection and diffusion in snow described by
advection-diffusion PDE.
PDEModelica, PDE, avalanche survival

Modeling task

Introduction
PDEModelica is a Modelica language extension for
partial differential equations (PDE). It was designed by
Levon Saldamli (Saldamli, 2006). This original
extension is currently not supported by any tool. We
focused on a subset of this extension for 1-dimensional
models only and introduced several changes and
enhancements. Support for the renewed extension has
been implemented in OpenModelica. We present the
extension using a simple string equation model at first
and then a real-life problem of modelling respiration
during a snow burial.
In the past four decades, avalanches were responsible for
around 100 deaths annually in the European Alps only
(Techel et al., 2016). When a victim is buried by an
avalanche he or she repetitively inspires previously
expired air as the motion of air in snow is restricted. The
body metabolism consumes O2 and produces CO2 and
thus the concentration of O2 decreases and the
concentration of CO2 increases in the inspired and
expired air. The concentrations of O2 and CO2 are
partially restored by diffusion. But this process is not
fast enough and if the victim is not rescued within
approximately 15 minutes he or she may die of

DOI
10.3384/ecp17132367

asphyxiation, i.e. a lack of oxygen supply to the cells.
Asphyxia could be caused by a variety of situations,
including excess of CO2. More than 75 % of deaths in an
avalanche are caused by asphyxia (McIntosh et al.,
2007). However the content of oxygen in snow should
satisfy the body needs  Radwin (Radwin et al., 2001)
proved, that volunteers buried in snow with the removal
of the expired gas did not have any problems even after
an hour long burial. In contrast, no removal resulted in
serious hypercapnia (i.e. an excessive amount of carbon
dioxide in blood) within 10 minutes. In this paper, we
focus on modeling of CO2 diffusion only, as the O2 is
then a very similar problem.

It is assumed, that a potential cavity around the mouth
and the nose significantly increase the chance of
survival. Roubk et al. carried out an experiment (Roubk
et al., 2015) where the volunteers were breathing
through a tube whose end opened into a cavity in snow
of various volumes. They proved that the size of the
cavity has a significant impact on the concentration of
O2 and CO2 in the inspired and expired air. There are at
least two possible mechanisms causing this effect. First,
the small cavity has a small surface of the air-snow
boundary and so the resistance for the air flux is high.
This causes an increase in the work of breathing, an
increase in the metabolism rate and thus an increase in
O2 consumption and CO2 production. Second, the
expired air is mixed with more fresh air in the cavity and
then the inspired air is also more fresh. Both
mechanisms probably take place in the process. The
question is which one dominates. We were asked to help
with the investigation using a model.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

367

PDEModelica and Breathing in an Avalanche

Methods



The PDE contains a partial space derivative
written using the pder operator (line 8). Also
the second derivative is allowed (not in this
example), the syntax is e.g.pder(u,x,x). It
is not necessary to write e.g. omega.x in
pder, even though x is a member of o
 mega.



The BC is on line 9. The current limitation is
that BCs may be written only in terms of
variables that are spatially differentiated.



All fields that are spatially differentiated must
have at each boundary either BC or
extrapolation. This extrapolation should be
done automatically by the compiler, but this has
not been implemented yet. The current
workaround is the usage of the
extrapolateField() operator directly in
the model.

PDEModelica
Let us introduce all new language elements of
PDEModelica on the advection equation model:
1 model advection "advection equation"
2 parameter Real pi =
Modelica.Constants.pi;
3 parameter DomainLineSegment1D omega(L =
1, N = 100);
4 field Real u( domain= omega);
5 initial equation
6 u = sin(2*pi *omega.x);
7 equation
8 der(u) + pder(u, x) = 0 indomain omega;
9 u = 0 indomain omega.left;
10 u = extrapolateField(u)
indomain omega.right;
11end advection;





The Domain omega represents the geometrical
domain where the PDE holds. The domain is
defined using the built-in record
DomainLineSegment1D (line 3). This
record contains among others L  the length of
the domain, N  the number of grid points, x 
the coordinate variable and the regions left,
right and interior, representing the left
and right boundaries and the interior of the
domain.
The field variable u is defined using a new
keyword field (line 4). The domain is a
mandatory attribute to specify the domain of
the field.

Theindomain operator specifies where the
equation containing the field variable holds. It
is utilised in the initial conditions (IC) of the
fields, in the PDE and in the boundary
conditions (BC). The syntax is
equationindomaindomain.region
If the .region is omitted, .interior is the
default.





368

The IC of the field variable u is written using
an expression containing the coordinate
variable omega.x. (line 6).

Comparison to the original version of
PDEModlica
Our extension is restricted to 1-dimensional models
only. This allows much simpler domain definition using
the built-in DomainLineSegment1D record
compared to the original extension which enables
arbitrary geometry domain definition in multiple
dimensions.
pder() is used instead of der() for partial
derivatives. A shortcut to leave out the full qualification
of the x coordinate is established. This was probably
intended in the original extension also, but was not
explicitly mentioned.
indomain is used instead of in as it is suggested in
(Fritzson, 2015) because in is already utilized in for
loops. indomain is mandatory not only in the BCs but
also in the ICs and the PDEs here.
Field literals are written as expressions containing the
coordinate variable x and thus the special syntax for the
field literal constructor of the original extension was
suppressed.

Solution process
The PDEs are solved using the method of lines (MOL)
(Schiesser, 2012): during flattening of the model, the
fields are replaced by arrays and the space derivatives

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132367

Session 6: Poster Session

are replaced by finite differences (currently only the
central difference is implemented)

and thus the PDEs are converted into a system of ODEs.
This resulting system may be written in standard
Modelica and is solved by current OpenModelica
solvers. The combination of the central space difference
with an implicit Euler time solver results in a
backward-time centered-space (BTCS) scheme which is
a common finite difference method. The usage of the
trapezoid time solver results in the Crank-Nicolson
method (Strikwerda, 2004). Other time solvers may be
also successful, even though the resulting methods were
not investigated. A selection of a proper time solver is
important.
It is also substantial to select a proper time step, so that
the CourantFriedrichsLewy (CFL) condition (Courant
et al., 1967) is fulfilled.
To enable PDEModelica in OpenModelica, the compiler
flag --grammar=PDEModelica must be set.
The features for the plotting fields (arrays) have not been
implemented in OpenModelica yet. We use Octave to
load the result file and plot the desired variables.

ice and possible melted water. The gas has a volumetric
concentration of CO2, the O2 is omitted, but it follows
the same principles. The gas transport in snow is
modeled using the advection-diffusion equation.

Figure 1  Model schematics. The organism is
producing CO2 in a constant rate and it is concentrating
in the lungs. The lungs expire to and inspire from a
cavity, in which the air is ideally mixed. The air flux is
given. The partial concentration of CO2  in the cavity is
drained by advection and diffusion through the snow.
The dead volume in the airways is omitted.

Advection-diffusion equation and its
formulation in PDEModelica
The advection-diffusion equation assuming the
incompressible gas flow is

Model of breathing in snow
For the first stages of the research, the problem is
simplified into a gas flow to and from a spherical
snowball (see Figure 1). Due to small pressure
differences, the gas is modeled as incompressible. The
only significant pressure difference could occur at the
boundary between the cavity and the snow, but Roubk
et al. (Roubk et al., 2015) did experience only small
pressure differences.

where c is the concentration, u is the velocity of
advection and D is a diffusion coefficient. We express
this equation in the spherical coordinates. As our
problem is spherically symmetrical, all derivatives
except the derivatives in a radial direction are equal to
zero. Then we obtain

The snow is a porous material, formed by ice and air.
The CO2 could flow and diffuse across the snow through
the air gaps. Given the ice density (916 kg/m3) and the
density of snow (100 - 400 kg/m3) the snow consists of
at least 55 % of air. Therefore, the air could penetrate
through the snow and mix with the air captured within
the snow. For simplification, we exclude the solubility in

DOI
10.3384/ecp17132367

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

,

.

369

PDEModelica and Breathing in an Avalanche

where r is the radius and q is a volumetric flow given by
the lungs. This equation contains two partial derivatives.
Using the principles described in the paragraphs above,
the formulation of the advection-diffusion equation in
PDEmodelica is written in the Code listing 1. The full
model of CO2 breathing is available online1.
model sb1m
(...)
Real C_CS "concentration on cavity-snow
interface";
DomainLineSegment1D omega(L = 0.5, N =
100, x0 = R_C) "x is actually r, center on
the left";
field Real C_S(domain = omega)
"concentration of CO2 in snow";
(...)
//Left BC during exhalation, extrapolation
during inhalation
C_S = if exhale then C_CS else
extrapolateField(C_S) indomain omega.left;
//The advection-diffusion equation
der(C_S) + (q / (4 * pi * omega.x ^ 2)
- 2 * D_S / omega.x) * pder(C_S, x)
- D_S * pder(C_S, x, x) = 0
indomain omega;
end sb1m;

Figure 2 Concentration (fraction) in the cavity C_C (the
Cavity volume 1 L) is changing between the inhale and
the exhale.

Code listing 1: the advection-diffusion equation
formulation in PDEModelica. New language elements
are highlighted in purple.

Note, that the boundary conditions are switched with
extrapolation every breathing cycle as the flux direction
changes. This demonstrates the acausality of the
proposed approach.

Results
In the presented model, we use the arbitrary parameter
values to demonstrate the principles of CO2 distribution.
The exact identification of the values is a subject of
additional research. However, the resulting trends are
consistent with expectation and plausibility personally
confirmed by the authors of (Roubk et al., 2015).

Figure 3: Average concentration C_C (average over 4
full breathing periods) in the snow cavity in time for
various cavity sizes (V_C) at 15min.
The CO2 concentration in the cavity rises with each
expiration (Figure 2) and is rising towards an
equilibrium. However, when the concentration of CO2 is
about 2 % the victim feels respiratory stimulation (here
approx. 200s), at 6 % starts mental confusion (approx.
400s), followed by unconsciousness at 10% (approx.
800s) and later by death.
In Figure 3 we investigate the influence of the cavity
size - the larger cavity, the longer the subject could
survive (i.e. the lower cavity CO2 concentration). If the
volume of the cavity is smaller than 1L, CO2
concentration does not change significantly. The size of
the cavity has a huge impact from 1 to 5 L, but then the
response becomes nearly linear. Unfortunately, the CO2
concentration remains at unsatisfactory high levels.

1

https://github.com/jansilar/snowbreathing/
370

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132367

Session 6: Poster Session

Figure 4 The concentration gradient dependable on the
radius of the snowball during the first exhale (a half of
breath period), the cavity volume 1 L.

N

Step

Trans

Simul

Size

50

0.02

3,5

8,2

252

100

0.01

4,9

13,7

418

200

0.005

5,5

39,2

759

500

0.002

12,2

224,9

1843

Table 1 Performance comparison: N  number of grid
points, step  the time step (s), trans  the time of
translation (s), simul  the time of simulation (s), size 
the size of the model binary (kB).
The simulation time increase substantially with
increasing number of grid points. The results seem
satisfying even for the simulation using 100 grid points
(plotted). On the other hand this results were not verified
by comparison with a different PDE simulation tool.

Discussion
The snow-breathing model

Figure 5 The concentration gradient dependable on the
radius of the snowball during a longer periods, at the
end of the breath period (i.e. after the exhale), the cavity
volume 1 L.
We can see advection and diffusion of CO2 into snow
during the first breath out close to the cavity (Figure 4).
Thanks to the r2 attenuation of advection velocity, the
CO2 concentration is virtually zero within a few
centimeters of the snow. Note that for long time periods
the CO2 proceeds further. Despite, the concentration is
negligible in around 50 cm as the distribution volume
grows rapidly with the radius (Figure 5).

Solution process performance
The model was translated and simulated several times
with a different number of grid points. The trapezoid
solver was used. The time step was chosen
proportionally to the space step. The stop time (model
time) was 5 minutes. The translation and simulation time
and the size of the model binary file are in Table 1.

DOI
10.3384/ecp17132367

A mathematical model could help to study the
countermeasures to avoid asphyxiation. This work
supports the usage of devices for CO2 removal and
explains the underlying processes with the goal to
contribute to their construction. Some CO2 removal
devices already exists, including a tube device to divert
the CO2-rich exhale (Margid et al., 1998), but additional
data are needed to prove their efficiency.
Changes in the human metabolism as a consequence of
the increasing hypercapnia and hypoxia during the snow
burial are not included in the model. Thus the presented
model cannot describe the real process of breathing into
snow. Development of the full model that includes the
human physiology as well is the aim of the subsequent
work. The current model has been greatly simplified by
omitting oxygen, dead space in airways, solubility of
CO2 in other body compartments and in water contained
in snow and also rising breath work, which produces
more CO2. Thanks to Modelica implementation, it is
planned to connect it directly with the most extensive
open model of human physiology, the Physiomodel
(Matejk and Kofrnek, 2015).
The current parameters of the model are set arbitrarily
and are not confirmed by the measurements. Therefore,
the results may be taken as demonstrative only.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

371

PDEModelica and Breathing in an Avalanche

Alternative to PDEModelica
Instead of the presented solution, some other methods of
using the PDEs in Modelica exists. One could make a
usage of creating the PDEs in some other tool and then
import them via FMI (Stavker and Fritzson, 2014). For
seamless Modelica integration, a dedicated library
PDELib (Dshabarow et al., 2007) was developed.
However, as it is not maintained, the examples are not
working in the recent OpenModelica and Dymola
versions.
We could have employed a manual PDE discretization
and thus converting the PDEs into an ODE or DAE
system. However using the manual discretization is in
conflict with Modelica declarative philosophy. Utilising
the language extension the modeller may focus on the
model itself rather than its numerical solution. Any
model written using the extension is more
understandable and maintainable compared to using the
manual discretization.

Conclusion
The presented model of breathing while buried in an
avalanche has several limitations. The main purpose of
this contribution was to demonstrate the ability of
PDEModelica to solve PDE models. This enhancement
is documented on the advection equation and then the
advection-diffusion equation modelling breathing in
snow after the avalanche burial. PDEModelica was able
to successfully express these example models and the
extended OpenModelica was able to solve them.
Nevertheless the project is not finished and more work
should be done. Automatic extrapolation on boundaries
must be implemented. Both PDEModelica language
extension and its implementation in OpenModelica have
to be yet tested thoroughly on several different models
and by comparison of results with reference PDE
simulation tools.

Approach. John Wiley & Sons.
Margid, J., Beidleman, N., Harmston, C., 1998. O2 and CO2
levels with the Black Diamond AvaLung during human
snow burials lasting up to one hour. Proceedings of the.
Matejk, M., Kofrnek, J., 2015. Physiomodel - an integrative
physiology in Modelica. In: 2015 37th Annual
International Conference of the IEEE Engineering in
Medicine and Biology Society (EMBC).
ieeexplore.ieee.org, pp. 14641467.
McIntosh, S.E., Grissom, C.K., Olivares, C.R., Kim, H.S.,
Tremper, B., 2007. Cause of death in avalanche fatalities.
Wilderness Environ. Med. 18, 293297.
Radwin, M.I., Grissom, C.K., Scholand, M.B., Harmston,
C.H., 2001. Normal oxygenation and ventilation during
snow burial by the exclusion of exhaled carbon dioxide.
Wilderness Environ. Med. 12, 256262.
Roubk, K., Sieger, L., Sykora, K., 2015. Work of Breathing
into Snow in the Presence versus Absence of an Artificial
Air Pocket Affects Hypoxia and Hypercapnia of a Victim
Covered with Avalanche Snow: A Randomized Double
Blind Crossover Study. PLoS One 10, e0144332.
Saldamli, L., 2006. PDEModelica A High-Level Language for
Modeling with Partial Differential Equations (PhD
Thesis.). Linkopings universitet.
Schiesser, W.E., 2012. The Numerical Method of Lines:
Integration of Partial Differential Equations. Elsevier.
Stavker, K., Fritzson, P. et al, 2014. PDE Modeling With
Modelica Via FMI Import Of Hiflow3 C++ Components
With Parallel Multi-core Simulations. Proceedings of the
55th Scandinavian Conference on Simulation and
Modeling.
Strikwerda, J.C., 2004. Finite Difference Schemes and Partial
Differential Equations. SIAM.
Techel, F., Jarry, F., Kronthaler, G., Mitterer, S., Nairz, P.,
Pavek, M., Valt, M., Darms, G., 2016. Avalanche
fatalities in the European Alps: long-term trends and
statistics. Geogr. Helv. 71, 147159.

References
Courant, R., Friedrichs, K., Lewy, H., 1967. On the Partial
Difference Equations of Mathematical Physics. IBM J.
Res. Dev. 11, 215234.
Dshabarow, F., Cellier, F.E., Zimmer, D., Dshabarow, F.,
Com, C., Ch, I.E., 2007. Support for Dymola in the
modeling and simulation of physical systems with
distributed parameters. In: Proceedings of the 6th
International Modelica Conference. pp. 683690.
Fritzson, P., 2015. Principles of Object-Oriented Modeling and
Simulation with Modelica 3.3: A Cyber-Physical

372

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132367

Multirotor Aerial Vehicle modeling in Modelica
Muhamed Kuric1

Nedim Osmic1

Adnan Tahirovic1

1 Department

of Automatic Control and Electronics
Faculty of Electrical Engineering
University of Sarajevo
Zmaja od Bosne bb, 71000 Sarajevo, Bosnia and Herzegovina
{muhamed.kuric, nedim.osmic, adnan.tahirovic}@etf.unsa.ba

Abstract
This paper presents a generalized Multirotor Aerial Vehicle (MAV) modeling framework which includes rigid
body dynamics, gyroscopic effect and motor dynamics.
We illustrate how this model can be used to derive any
MAV platform constructed with an arbitrary number of rotors by using the quadrotor case as an example. Based on
this result, we design the first Modelica-based MAV simulator. We validate the proposed design by using a simple
altitude and attitude stabilization control system through a
Modelica simulation setup.
Keywords: Multirotor Aerial Vehicle, Modeling, Modelica

1

Introduction

Technological advancements in recent years, including the
miniaturization in battery, sensor and actuation technologies, as well as the availability of low cost high performance computing boards have enabled the genesis of intelligent autonomous flying machines. The most popular
class of this machines are the so-called Multirotor Aerial
Vehicles (MAVs) which represent motorized rotorcrafts
that have favourable dynamical properties and can achieve
small geometries. MAVs and especially the quadrotor
configuration are now the de facto standard research platforms for aerial robotics with many potential applications including search and rescue in indoor and outdoor
environments (Tomic et al., 2012), precision agriculture
(Zhang and Kovacs, 2012), aerial construction (Lindsey
et al., 2011; Willmann et al., 2012), inspection and maintenance (Mellinger et al., 2011; Jimenez-Cano et al., 2013),
environmental monitoring (Alexis et al., 2009), exploration and mapping (Fraundorfer et al., 2012), aerial transportation (Michael et al., 2011; Mellinger et al., 2013) and
swarming (Kushleyev et al., 2013).
Due to this growing interest, there have emerged multiple MAV simulation platforms mainly in MATLAB and
ROS with notable examples being (Bresciani, 2008) and
(Furrer et al., 2016), respectively. Both provide simulation for MAV dynamics (with the former covering only
the quadrotor case) and sensors, and the latter having a
less user-friendly interface via pure code and configuration. To the best of our knowledge, there are no existing
MAV simulation platforms within the Modelica commuDOI
10.3384/ecp17132373

nity.
Our paper gives a simple way of deriving a proper dynamical model for a MAV constructed with an arbitrary
number of rotors by using a generalized MAV model.
Based on this paradigm, we also present a Modelica simulator that can be used for multirotor aerial vehicles. To the
best of the authors knowledge, this is the first Modelicabased MAV simulator available within the Modelica community.
The remainder of the paper is organized as follows.
Section 2 describes how generalized MAV dynamics can
be derived and how an appropriate dynamical model can
be extracted for a quadrotor based MAV. In Section 3, we
describe necessary classes to design the Modelica-based
simulator for MAVs, while in Section 4, we validate the
results throughout a simple altitude and attitude stabilization control system. Concluding remarks are presented in
Section 5.

2

MAV dynamics

A large number of papers address MAV modeling putting
the focus mostly on the quadrotor case. Noteworthy classical contributions include (Altug et al., 2002), (Hamel
et al., 2002), (Pounds et al., 2002) and (Bouabdallah et al.,
2004a). More recent examples of very detailed quadrotor and octorotor modeling are presented in (Bangura and
Mahony, 2012) and (Osmic et al., 2016), respectively. To
the best of our knowledge, one of the most complete work
regarding MAVs can be found in (Mahony et al., 2012),
where the authors have derived MAV dynamics, included
advanced state estimation, control and motion planning algorithms and therefore provided full system autonomy.
In this section, we will describe the dynamical model
of the quadrotor, which is frequently considered to be
the standard research platform for MAVs due to its simple construction and purposeful functionality. We use the
results and nomenclature from (Osmic et al., 2016) and
show that only minor changes are necessary to apply the
final octocopter model presented in (Osmic et al., 2016) to
any MAV, including also the quadrotor case.

2.1

MAV rigid body dynamics

In order to model the dynamics of any mobile robot it is
common to define two frames of reference. A body fixed

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

373

Multirotor Aerial Vehicle modeling in Modelica

frame {o} is attached to the robots center of mass and all
sensory data is measured with respect to this frame, while
a ground fixed frame {g} is used to define workspace goals
in a intuitive and user-friendly manner. The body fixed
and ground fixed frame represent right-handed Cartesian
coordinate systems and are usually referred to as the local
and global coordinate system, respectively.
Workspace goals can be defined in terms of global position coordinates x, y and z and orientation coordinates  ,
 and  (see Fig. 1), where positive directions of  , 
and  are chosen according to the right-hand rule. Therefore, the position vector x = [x y z]T and the orientation
vector  = [  ]T can completely determine the vehicles location in the workspace. As shown in Fig. 2,
the local coordinates are described by the linear velocities
u, v and w and the angular velocities P, Q, R. The positive directions of the angular velocities P, Q and R are also
chosen according to the right-hand rule and therefore coincide with the positive directions of  ,  and . Both linear
and angular velocity coordinates can also be expressed in
compact vector form as v = [u v w]T and P = [P Q R]T ,
respectively.
Forces and torques which act on a MAV are shown in
Fig. 3. The thrust T is a force that acts towards the positive
direction of the Z axis of the local coordinate system {o},
while the force G represents the gravitational force acting
towards the negative direction of the ZB axis of the global
coordinate system {g}. x , y and z represent the torques
that move the vehicle around the X, Y and Z axes of the local coordinate system, respectively, and can be compactly
denoted as  = [x y z ]T . Their positive direction is also
chosen to coincide with the positive directions of the angular velocities P, Q and R.
We can now describe the rigid body dynamics of any

MAV in accordance to the results presented in (Osmic
et al., 2016). The kinematic model of the linear motion
is given as
x = R ( ,  , )vv,
(1)
where R ( ,  , ) is the total rotation matrix which for the
ZYX Euler convention has the form
R ( ,  , ) = R(Z, )R(Y,  )R(X,  )


c c c s s  s c c s c + s s


s c s s s + c c s s c  c s  ,
  
 
  
 
  
s
c s
c c

(2)

and the elementary rotation matrices R(Z, ), R(Y,  ) and
R(X,  ) are defined as


1 0
0


,
R(X,  ) = 
0
c
s




0 s c


c 0 s


R(Y,  ) = 
1 0
,
 0
s 0 c


c s 0



R(Z, ) = 
 s  c 0  .
0
0
1

(3)

(4)

(5)

The kinematic model of the angulator motion can be described by
P,
 = R 1
(6)
A ( ,  , )P
where the matrix R 1
A ( ,  , ) for the ZYX Euler convention is


1 s t c t



R 1
(7)
c s 
A ( ,  , ) = 0
.
s
c
0 c
c


Figure 1. Global coordinates

374



Figure 2. Local coordinates

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132373

Session 6: Poster Session

The dynamic model of the linear motion can be repre- tensor matrix has the diagonal form
sented by the following equation


Ixx 0 0


 


0
s
(11)
J =
0 Iyy 0 
,

 





v = 
(8)
0 0 Izz
 0  + g s c  SSv ,
T
c c
mo
and I , I , I being the moments of inertia around the X,
xx

yy

zz

Y and Z axes of the local coordinate system, respectively.
where mo is the total mass of the MAV and the matrix S is These components can be derived via the Huygens-Steiner
formed as
theorem (Morin, 2008) as


0 R Q
2Mr2


Ixx = Iyy =
+ 2ml 2
(12)

S=
.
(9)
0 P
5
 R
Q P
0
Finally, the dynamic model of the angular motion can be
catched with
P = J 1 ( SSJ P ) ,
(10)
where J is a 3  3 matrix representing the inertia tensor of
the MAV.

2.2

Quadrotor modeling

To tailor the previously derived MAV model to the quadrotor case we need to derive the inertia tensor J , and define
the thrust T and the torque vector  . Since all of these
quantities depend on the MAVs geometry, we consider
a quadrotor case shown in Fig. 4 along with its simplified geometry illustrated in Fig. 5, where the length of
the four arms is l, a hardware support plate is modeled as
solid sphere of mass M having a radius r, and the four motors constructed with fixed pitch propellers are modelled
as particles with mass m.
The axes of the local coordinate system, as shown in
Fig. 4, represent principal axes of inertia, where the inertia
Figure 4. Quadrotor geometry

Figure 3. Forces and torques acting on the system

DOI
10.3384/ecp17132373

Figure 5. Quadrotor simplified geometry

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

375

Multirotor Aerial Vehicle modeling in Modelica

and

Finally, we can represent the system actuation via matrix
2Mr2
2
Izz =
+ 4ml .
(13) equation
 
5
T
  = A s ,
In order to derive the thrust T and the x and y com(24)

ponents of the torque vector  , we will consider the rotor
forces acting on the quadrotor system as depicted in Fig.
where A is the actuation matrix
6. Thus T , x and y are given as follows
T = F1 + F2 + F3 + F4 ,

(14)

x = l (F1  F3 ) ,

(15)

y = l (F4  F2 ) .

(16)



b


 bl

A=
 0

d

b

b

0

bl

bl

0

b




0

,
bl 

d

(25)

d
d
In accordance to the work presented in (Mahony et al.,
2012), the rotor forces Fi (i = 1..4) can be approximated
as
and s is the squared rotor velocity vector defined as
Fi = b2i (i = 1..4),
(17)
h 2i
h
iT
 
Ns
2 2 2 2
where b rad
is the rotor thrust constant and i rad
is
=
.
(26)


2
s
s
1
2
3
4
the angular velocity of the i-th rotor. Combining eqs. (14),
(15), (16) and (17) yields
It is evident from this result that any MAV can be mod
elled by choosing the appropriate inertia tensor J and ac2
2
2
2
T = b 1 + 2 + 3 + 4 ,
(18)
tuation matrix A as parameters, and picking the squared

rotor velocity vector s of the right size as a system input.
x = bl 21  23
(19) For any MAV constructed with n  4 rotors, the actuation
matrix has the dimension 4  n and the squared rotor veand

2
2
x = bl 4  2 .
(20) locity vector s has the length n.
Moreover, we can include the gyroscopic effect in the
The torque z is a consequence of Newtons third law and dynamic model of the angular motion given by eq. (10) as
can be formed as



z = M1 + M2  M3 + M4 ,
(21)
0



 0  ,
S
S
P = J 1 
(27)

S
J
P
S



where Mi (i = 1..4) is the counter induced torque of the
i-th rotor. According to (Mahony et al., 2012) the counter
IzzmWg
torque can approximated as
Mi = d2i (i = 1..4),

(22)

where Izzm is the rotor moment of inertia and Wg is the
gyroscopic term given as

h 2i
where d Nms
is the rotor drag constant. Combining
rad 2
Wg = 1 + 2  3 + 4
(28)
equations (21) and (22) yields

z = d 21 + 22  23 + 24 .
(23) for the quadrotor case. In order to generalize the gyroscopic term for any MAV configuration, it is more appropriate to choose the rotor velocity vector 
Z
Y

h
 = 1

iT
2

3

4

(29)

X

as system input and express the gyroscopic term as
Az )
,
Wg = sign(A

Figure 6. Rotor forces acting on the quadrotor system

376

(30)

where Az is the fourth row of the actuation matrix A , while
the squared rotor velocity vector  s can easily be computed by calculating the element-wise square of the vector
.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132373

Session 6: Poster Session

2.3

x

Motor dynamics


x

Each rotor of a quadrotor MAV is driven by a DC motor.
Therefore, in order to obtain a precise MAV model, it is inevitable to include the motor dynamics to address effects
like motor response time, saturation and power consumption. In accordance to the work presented in (Osmic et al.,
2016), a simplified model can be used for this purpose
which is given by
Km Ke
Km
i =
vi  li , i = 1..4,
(31)
R
R
 Vs 
 
where Km Nm
A is the mechanical motor constant, Ke rad
being the electrical motor constant, R denotes the armature resistance, vi is the armature voltage, with li being
the load torque of the i-th motor. The load torque is the
aerodynamic drag which can be computed as

T

MavBase



Wg


Figure 7. MavBase block

MavSimple

Izzm i +

li = d2i , i = 1..4.

x

x


Actuation

T

MavBase



Figure 8. MavSimple block

(32)

MavFull
x

The input voltage of each motor is saturated by the following box constraint
0  vi  vmax , i = 1..4

(33)



Wg

x

Motor
Dynamics

v



MavSimple




where vmax is the maximum armature voltage, and consequently the angular velocity of each rotor is also box
constrained by



Figure 9. MavFull block

0  i  max, i = 1..4,

(34)

where max is the maximum angular velocity which can
be easily computed from the stationary state of the motor
dynamic model given by (31).
Finally, the rotor moment of inertia Izzm can be approximately calculated as

with the input being the angular velocity vector  and the
outputs being the global coordinates of the system and its
derivations.
Finally, the MavFull block, as shown in figure 9, provides the greatest level of detail. It extends the MavSimple
block and adds the motor dynamics (31) to the model. The
m p l 2p
Izzm =
,
(35) block input is the motor voltage vector v with the outputs
12
being the global coordinates of the system and its derivations, as well as the angular velocity vector  . The anguwhere m p is the mass and l p being the length of the rotor.
lar velocity vector as system output is necessary to provide
motor level control possibilities.
3 Modelica design
The parameters of the blocks are given in Table 1, 2
In order to provide a greater end-user utilization, we de- and 3, and their default values match the AscTec Pelican
signed the following Modelica blocks / classes:
quadrotor (AscTec, 2016).

 MavBase

Table 1. MavFull block parameters

 MavSimple
 MavFull
The MaveBase block, as shown in Fig. 7, is the simplest
and it models the rigid body dynamics including the gyroscopic effect covered with eqs. (1), (6), (8) and (27). Its
inputs are the generalized forces acting on the system and
the outputs are the global coordinates of the system and its
derivations.
The MavSimple block, as shown in Fig. 8, extends the
MavBase block with the actuation model given by eq. (24)
DOI
10.3384/ecp17132373

Parameter

Value

Unit

Description

R

0.1107



Resistance

Km

0.01

Motor size constant

Ke

0.01

Nm
A
Vs
rad

Motor velocity constant

vmax

11.1

V

Maximum voltage

569.3572

rad
sec

Initial angular velocity

0

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

377

Multirotor Aerial Vehicle modeling in Modelica

Table 2. MavBase block parameters

Parameter

Value

Unit

Description

mo

1.32


0.0128
0
0


 0
0.0128
0 


0
0
0.0239

kg

MAV total mass

kgm2

Inertia tensor

kgm2

Rotor moment of inertia

J

4.3011  105

Izzm

Table 3. MavSimple block parameters

Parameter

Value

Unit

n

4

b

9.9865  106

Input size
Ns2
rad 2
Nms2
rad 2

1.5978  107

d

A

Description

Aerodynamic thrust constant
Aerodynamic drag constant



b
b
b
b


0.211  b
0
0.211  b
0 




 0
0.211  b
0
0.211  b


d
d
d
d

Actuation matrix

0.3

1.5
zref [m]
z[m]

ref [rad]
 [rad]
0.2

1

0.1
0.5
0
0

0

1

2

3

4

0

5

1

2

t[s]

3

4

5

t[s]

0.3

0.3
ref [rad]
 [rad]

ref [rad]
[rad]

0.2

0.2

0.1

0.1

0

0
0

1

2

3

4

5

0

1

2

t[s]

3

4

5

t[s]

Figure 10. Altitude and attitude control simulation results

378

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132373

Session 6: Poster Session

4

Simulation results

AscTec. Ascending technologies, gmbh, 2016. URL http:
//www.asctec.de/.

A simple altitude and attitude control system was designed
in order to validate the designed classes. Altitude and Moses Bangura and Robert Mahony. Nonlinear dynamic modeling for high performance control of a quadrotor. In Ausattitude control simulation results are presented in Fig.
tralasian conference on robotics and automation, pages 110,
10. We notice that the system states have been stabilized
2012.
within 1 second and that only very minor overshoots are
present in the altitude z and the pitch  .
Samir Bouabdallah, Pierpaolo Murrieri, and Roland Siegwart.
The simulation example shows that the control results
Design and control of an indoor micro quadrotor. In Robotics
are very satisfactory, in particular the system suffers only
and Automation, 2004. Proceedings. ICRA04. 2004 IEEE
a minor loss in altitude during the challenging reference
International Conference on, volume 5, pages 43934398.
orientation maneuver, which can be considered excellent
IEEE, 2004a. doi:10.1109/ROBOT.2004.1302409.
control behaviour. Additionally, the simulation results
are very similar to those obtained in (Bouabdallah et al., Samir Bouabdallah, Andre Noth, and Roland Siegwart. PID vs
LQ control techniques applied to an indoor micro quadrotor.
2004b) and (Osmic et al., 2016) which suggests that the
In Intelligent Robots and Systems, 2004.(IROS 2004). Promodel derivation in this paper is correct.

5

ceedings. 2004 IEEE/RSJ International Conference on, volume 3, pages 24512456. IEEE, 2004b.

Conclusion

This paper described how a generalized MAV modeling
framework can be used to obtain any MAV model. A
quadrotor based MAV was presented as an example, and
the final model was formed by using its rigid body dynamics, the gyroscopic effect that influences the vehicles
motion, and appropriate motor dynamics. To model the
dynamics of any given MAV platform, it was shown that is
only required to choose adequate parameter values, which
correspond to the vehicle of interest, and inject them into
the generalized MAV model.
Based on the presented generalized MAV model derivation, we have designed the following Modelica classes:
MavBase, MavSimple and MavFull. MavBase represents
the rigid body dynamics of the MAV including the gyroscopic effect. MavSimple extends the MavBase class and
adds system actuation, while MavFull extends MavSimple
with motor dynamics. These classes can be used to simulate the dynamic behaviour of any MAV within Modelica
to any required level of detail, and thus providing similar functionalities as the Gazebo simulator RotorS (Furrer
et al., 2016) which is frequently used for this purposes, but
with a more user friendly interface.
Finally, we have validated the designed Modelica simulator through a simple altitude and attitude stabilization
control system. Namely, we have obtained very similar
control results like those currently present in the state of
the art, which suggests that the generalized model derived
and the MAV simulator designed in this paper are correct.

References

Tammaso Bresciani. Modelling, identification and control of a
quadrotor helicopter. MSc Theses, 2008.
Friedrich Fraundorfer, Lionel Heng, Dominik Honegger,
Gim Hee Lee, Lorenz Meier, Petri Tanskanen, and Marc
Pollefeys. Vision-based autonomous mapping and exploration using a quadrotor MAV. In Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on,
pages 45574564. IEEE, 2012.
Fadri Furrer, Michael Burri, Markus Achtelik, and Roland Siegwart. RotorS-A Modular Gazebo MAV Simulator Framework. In Robot Operating System (ROS), pages 595625.
Springer, 2016.
Tarek Hamel, Robert Mahony, Rogelio Lozano, and James Ostrowski. Dynamic modelling and configuration stabilization
for an x4-flyer. IFAC Proceedings Volumes, 35(1):217222,
2002. doi:10.3182/20020721-6-ES-1901.00848.
AE Jimenez-Cano, Jess Martin, Guillermo Heredia, Anbal
Ollero, and R Cano. Control of an aerial robot with multi-link
arm for assembly tasks. In Robotics and Automation (ICRA),
2013 IEEE International Conference on, pages 49164921.
IEEE, 2013.
Alex Kushleyev, Daniel Mellinger, Caitlin Powers, and Vijay
Kumar. Towards a swarm of agile micro quadrotors. Autonomous Robots, 35(4):287300, 2013.
Quentin Lindsey, Daniel Mellinger, and Vijay Kumar. Construction of cubic structures with quadrotor teams. Proc. Robotics:
Science & Systems VII, 2011.

K Alexis, G Nikolakopoulos, A Tzes, and L Dritsas. Coordination of helicopter UAVs for aerial forest-fire surveillance.
In Applications of intelligent control to engineering systems,
pages 169193. Springer, 2009.

Robert Mahony, Vijay Kumar, and Peter Corke. Multirotor aerial
vehicles: Modeling, estimation, and control of quadrotor.
IEEE robotics & automation magazine, 19(3):2032, 2012.
doi:10.1109/MRA.2012.2206474.

Erdinc Altug, James P Ostrowski, and Robert Mahony. Control
of a quadrotor helicopter using visual feedback. In Robotics
and Automation, 2002. Proceedings. ICRA02. IEEE International Conference on, volume 1, pages 7277. IEEE, 2002.
doi:10.1109/ROBOT.2002.1013341.

Daniel Mellinger, Quentin Lindsey, Michael Shomin, and Vijay
Kumar. Design, modeling, estimation and control for aerial
grasping and manipulation. In Intelligent Robots and Systems
(IROS), 2011 IEEE/RSJ International Conference on, pages
26682673. IEEE, 2011.

DOI
10.3384/ecp17132373

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

379

Multirotor Aerial Vehicle modeling in Modelica

Daniel Mellinger, Michael Shomin, Nathan Michael, and Vijay Kumar. Cooperative grasping and transport using multiple quadrotors. In Distributed autonomous robotic systems,
pages 545558. Springer, 2013.
Nathan Michael, Jonathan Fink, and Vijay Kumar. Cooperative manipulation and transportation with aerial robots. Autonomous Robots, 30(1):7386, 2011.
David Morin. Introduction to classical mechanics: with problems and solutions. Cambridge University Press, 2008.
Nedim Osmic, Muhamed Kuric, and Ivan Petrovic. Detailed
octorotor modeling and PD control. In Systems, Man, and
Cybernetics (SMC), 2016 IEEE International Conference on,
pages 21822189, 2016.
Paul Pounds, Robert Mahony, Peter Hynes, and Jonathan M
Roberts. Design of a four-rotor aerial robot. In Proceedings
of the 2002 Australasian Conference on Robotics and Automation (ACRA 2002), pages 145150. Australian Robotics
& Automation Association, 2002.
Teodor Tomic, Korbinian Schmid, Philipp Lutz, Andreas
Domel, Michael Kassecker, Elmar Mair, Iris Lynne Grixa,
Felix Ruess, Michael Suppa, and Darius Burschka. Toward
a fully autonomous UAV: Research platform for indoor and
outdoor urban search and rescue. IEEE robotics & automation magazine, 19(3):4656, 2012.
Jan Willmann, Federico Augugliaro, Thomas Cadalbert, Raffaello DAndrea, Fabio Gramazio, and Matthias Kohler.
Aerial robotic construction towards a new field of architectural research. International journal of architectural computing, 10(3):439459, 2012.
Chunhua Zhang and John M Kovacs. The application of small
unmanned aerial systems for precision agriculture: a review.
Precision agriculture, 13(6):693712, 2012.

380

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132373

Rotating Machinery Library for Diagnosis
Tatsuro Ishibashi1

Bing Han2

Tadao Kawai3

Meidensha Corporation, Japan, ishibashi-tat@mb.meidensha.co.jp
Department of Mechanical & Physical Engineering, Osaka City University, Japan,
{han,kawai}@mech.eng.osaka-cu.ac.jp

1
2, 3

Abstract
This paper presents our new rotating machinery library.
Diagnosing the complex system accurately based on
stochastic method requires an enormous amount of data,
both with and without faults. Acquiring operation data
with all kinds of faults for each components is very hard
and costly. To generate data for rotating machinery
diagnosis, we developed rotating machinery library
using Modelica. It provides the basic components such
as rotor, shaft, bearing, coupling, housing and support.
Its component models are implemented on basis of rotor
dynamics theory. This library makes it possible
accessing rotating machinery operation data with
various faults such as unbalanced rotor, shaft bending
and ball bearing faults. To validate our models, we
compared both Modelica simulation and experiment
with a rotor kit as a test case.
Keywords: Rotating Machinery, Vibration, Diagnosis

1

Introduction

Preventive maintenance has been the main stay of
industry for a long time. Recently, IoT (Internet of
Things) and Industry4.0 have become very popular to
manage and control a system such as manufacturing
system. These have naturally increased the focus on
Condition-Based Maintenance (CBM). IoT makes it
possible monitoring the system state on time and
accumulating a large amount of data. So many sensors
and sensor network are attached to each component of a
system for the purpose of data acquisition. By collecting
and analyzing these acquired data, it makes feasible to
manage a system efficiently or detect problem in a
system with high accuracy at early stage.
Although this concept is very important, there are
many difficulties in measurement. It is not always
possible that we attach sensors where we would like to
measure. Neither is it possible that we measure
significant features of a system due to the lack of sensors.
By stochastic approach such as machine learning, fault
detection of complex system accurately requires an
enormous amount of data, both with and without faults
to determine the threshold of signal amplitude. As a
method of grasping the operating states with faults, it is
conceivable to collect operation data by embedding the

DOI
10.3384/ecp17132381

damaged part into the actual machine or continuing to
operate it until it gets damaged. If the equipment is large,
the lifetime is long, or the equipment is expensive, it is
difficult to accumulate data. Rotating machinery
equipment apply to the above. IoT will help us collect
and acquire data. Still, accumulating data with all kinds
of faults for each components is very hard and costly. It
is desirable to analyze the state when faults occur in the
rotating machinery. Some simple fault cases are
schematized and modeled. It is possible to generate data
of rotating machinery equipment with faults such as
unbalanced rotor, shaft bending, ball bearing faults and
misalignment of coupling by simulation.
Modelica is an object-oriented, declarative, multidomain modeling language for component-oriented
modeling of complex systems. It is a powerful tool
which simulates a complex physical system. Almost all
design parameters such as shape and rigidity are easily
set to a model and a variable behavior of a certain
component in a system is easily obtained. By building
Modelica cyber system, we can also obtain physical
quantities and features of components which are
inaccessible in a real physical system. A model-based
diagnosis and design approach including fault mode
with Modelica has recently reported (Klenk et al, 2014;
Minhas et al, 2014).
Hence, we focus on developing rotating machinery
library based on well-established rotor dynamics theory
using Modelica. It provides the basic components such
as rotor, shaft, bearing, coupling, housing and support.
Our final goal is generation of training data including
unmeasurable quantities for diagnosis by statistical
classification algorithms.
To validate our models, we compared both Modelica
simulation and experiment with a rotor kit as a test case.
We calibrated the fault related parameter embedded in
Modelica model so that simulation results were in good
agreement with the experiment. Data acquisition from
physical system was done through COMEDI (COntrol
and MEasurement Device Interface for Linux / RTAI).
The followings show our new rotating machinery
library, the example of generated data from this library
and validation of this library with a rotor kit as a test
case.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

381

Rotating Machinery Library for Diagnosis

Figure 1. An example of a rotating machinery system. The upper figure describes our new library components of Modelica
cyber system. The lower figure is corresponding physical system (The image is designed by CAD tool).

2

Rotating Machinery Library

Generally, a rotating machinery system has many
problems. Static and dynamic unbalance of a rotor, a
bend of a shaft, rigidity of housing, damaged ball
bearing. These failures are included in our rotating
machinery library for the diagnosis. Specifications of a
motor, a coupling, a shaft, a rotor and bearings are
decided at design process and set as parameters of the
model. Each component shown in Figure 1 is built based
on well-established rotor dynamics theory (Ishida
Yamamoto, 2012; Matsushita et al, 2017).
The basic flange has 5 DOF (degree of freedom),
consisting of 4 DOF (two dimensional deflection and
slope) for transverse vibration of the rotor system and 1
DOF (angle) for torsional vibration, neglecting axial
vibration. Figure 2 descripts the flange. The
followings are 10 flange variables. 5 potential
variables are
 : Deflection of horizontal direction,
 : Deflection of vertical direction,
 : Deflection angle of horizontal direction,
 : Deflection angle of vertical direction,
 : Rotational angle.
Corresponding flow variables are
382

 : Force of horizontal direction,
 : Force of vertical direction,
 : Moment of horizontal direction,
 : Moment of vertical direction,
 : Rotational Torque.

2.1 Rotor
In our library, the rotor is considered as a single mass in
the form of a point mass, a rigid disc or a long rigid shaft.
The rotor model is followed as 4 DOF Jeffcott rotor
model. The forces and moments are given from next
component through connector. The static unbalance
model equations are following.
   2 cos( + 0 )   sin( + 0 )
(1)
= 
   2 sin( + 0 ) +  cos( + 0 )
(2)
+
= 
The dynamic unbalance model equations are following.
  +    (   ) 2 cos( + 0 )
(3)
= 
      (   ) 2 sin( + 0 )
(4)
= 
Also, dynamic load torque effect is considered.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132381

Session 6: Poster Session

  =   sin( + 0 )    cos( + 0 ) + 

(5)

models also have damping factor. In addition to the
above model, a bearing damage models on inner and
outer ring are modeled by applying impulsive force.
Bearing force relationships is following.

cos


( ) =  ( ) +  (  ) +   ( sin )
(8)






Figure 2. Flow variables of flange.

Here,
 : Time-derivative operator (i.e.  ),

 : Rotor mass,
 : Eccentricity,
0 : Initial phase of eccentricity,
 : Slope of dynamic unbalance,
0 : Initial phase of dynamic unbalance,
 : Diametral moment of inertia,
 : Polar moment of inertia.

2.2 Shaft
The shaft is considered as flexible (elastic) shaft. It is a
linear elastic beam, uniform loading. The force and
deflection relationships between two flanges follow.
2 



 ( ) = ( ) +  ( ) +  ( )

2 


(6)
0
+ ( 2 )

6

2 
 

 ( ) = ( ) + ( ) +  ( )

6 
2 

(7)
0

3

+ ( ) + (
)


24
Here,
 : Shaft mass,
 : Shaft length,
 : Youngs modulus,
 : Second moment of area,
 : Constant of gravitation,
Subscript a is left flange, and b is right flange.

2.3 Bearing
Bearing models have deflection rigidities in series and
deflection angle rigidities in parallel . The bearing
DOI
10.3384/ecp17132381

Here,
 : Spring constant of bearing force,
 : Damping constant of bearing force,
 =   ( +  )/2 : Difference of deflection,
 : Quantity of impulsive force due to ball and ring
collision,
 : If collision occurs,  = 1, otherwise 0,
 : Impulsive force angle.
Subscript c is housing or support flange.
We calculate the quantity of collision force using Hertz
contact theory. Collision event is written by when
statement.
Following is outer ring case.
 = 1.1430.6 0.4  1.2
(9)
+
(10)
=
1 sin
2
 = 3.1280.4  0.4  0.2
(11)
Here,
 : Diameter of inner ring,
 : Diameter of ball,
 : Ball collision speed,
 : Number of balls,
 : Rotational speed.
1 : Ball orbital motion rotational speed,
 : Contact time,
 : Collision angle.
: Proportional constant of force.
 is determined by elastic moduli and Poissons ratio.

1 =

(12)
2( + )
From relationships above, characteristic frequency of
outer and inner ring collision events are described by
ball orbital motion rotational speed.
1
( 13)
 =
2
(  1 )
( 14)
 =
2

2.4 Coupling
Coupling models have both offset and angular
misalignment. The deflections relationships between
two flanges follow.
   = (cos( + 0 ) sin( + 0 ))
(15)
   = (cos( + 0 ) sin( + 0 ))
Here,
 : Offset misalignment length,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(16)

383

Rotating Machinery Library for Diagnosis

0 : Initial phase of offset misalignment,
 : Angular misalignment length,
0 : Initial phase of angular misalignment.
Coupling models also have deflection rigidities.

2.5 Housing
Housing model is spring damper against deflection. It
dosent have deflection angle rigidities.

amplitude(m/sec)

0.0005

0.0000

2.6 Support
Support models have simple support, rigid support and
free end. Simple support follows the condition that
deflections and moments are zero. Rigid support follows
the condition that deflections and deflection angles are
zero. Free end follows the condition that forces and
moments are zero.

-0.0005

8.988

8.995

9.002

time(sec)

Figure 3. Outer ring fault with static unbalance.

2.7 Motor
Motor

models

are

extended

0.0004

from

3

amplitude(m/s)

Modelica.Electrical.Machines.BasicMachine
s to be compatible with our library flange.

Generation of data with fault

Ball bearing in rotating machinery is very frequently
damaged during operation. Inner and outer rings in
bearing can be damaged due to over load, corrosion,
improper lubrication and installation. Over load or weak
lubrication causes friction. As a result of friction,
temperature increases, so that oil lost its properties. Also,
current flows on bearings, because of voltage difference
between stator and rotor does. Oil acts as a dielectric
material in condenser. These faults produce small
particles in bearing.
Using our library, we generated outer and inner ring
damaged ball bearing vibration case data in addition to
static unbalance respectively. Figure 3 and 4 are
simulation results respectively.
By building Modelica cyber system with the other
faults refered in previous section, we can obtain time
series data with some faults from Dymola simulation.
Using these simulation generated data for training
dataset after analysing and signal processing
experimental measured data, it is possible making
system fault detection algorithm based on machine
learning theory (Figure 5). In case of the damaged ball
bearing, envelope processing of bearing eigen frequency
is required. Our final goal is generation of training data
including unmeasurable quantities for diagnosis by
statistical classification algorithms.

0.0000

-0.0004

8.99

9.00

9.01

time(sec)

Figure 4. Inner ring fault with static unbalance.

Figure 5. Diagnosis method using simulation data as
training dataset.

4

Model Validation

4.1 Experimental setup
To validate our models, we built a rotor kit physical
system shown in Figure 6. Vertical and horizontal
deflection of a rotor were measured by two laser

384

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132381

Session 6: Poster Session

Table 1. Parameters of Modelica cyber system.

Shaft
Length L [mm]
Shaft diameter D1 [mm]
length L1 [mm]
Shaft diameter D2 [mm]
Length L3 [mm]
Length L5 [mm]

500
6
50
8
180
50

Youngs modulus [Pa]

2.06x109 Torque [N. m]

Density [kg/m3]

8000
Rotor

15
0.053
23
650
0.4
24
2500

80
62

Youngs modulus [Pa]

2.06x109

Density [kg/m3]
sensors

Voltage [V]
Rotating speed [rpm]

Diameter D4 [mm]
Width L4 [mm]

displacement

Bearing
Width L2 [mm]
Damping constant [N. m. s/rad]
Rigidity [N. m/rad]
Coupling
Rigidity [N/m]
Motor

8000
(IL-030

KEYENCE).

To acquire data from the physical system to Dymola,
we used National Instruments A/D and D/A Converter,
Modelica_DeviceDrivers, Modelica_Synchronous and
COMEDI (COntrol and MEasurement Device Interface
for Linux / RTAI) (Ferretti et al, 2005). The OS was
openSUSE Leap 42.1. The motor was AC Servomotor
(NX410AA-1 Oriental motor). The input signal voltage
driving motor was controlled through COMEDI. Figure
8 shows the rotor kit measurement and control system
we built.

Figure 6. Rotor kit physical system.

Figure 7. Parameters of Modelica cyber system.

We built Modelica cyber system based on our new
library in Section 2 (Figure 1 and Figure 7). The
parameters of Modelica cyber system are shown in
Table 1. The parameters were determined by
specifications of each component except bearing. The
bearing support was neither simple support nor rigid
support. It had some rigidity against the bending of the
shaft. We determined the bearing model parameters of
the deflection angle rigidity and damping from the
preliminary impulse experiment.

DOI
10.3384/ecp17132381

Figure 8. Rotor kit measurement and control system.

We tested the response of this system by applying step
input to both physical system and Modelica cyber
system. Figure 9 shows the response of motor speed and
the rotor horizontal displacement vibration against the
input voltage. A bit difference between experiment
(physical system) and simulation (Modelica cyber
system) was observed due to input signal overshooting
in physical system.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

385

Rotating Machinery Library for Diagnosis

4.2 Correlation to Physical Test
We calibrated the fault related parameter, as we found
the bend of shaft had strongly correlated with the
physical system. We preprocessed both simulation and
experiment data by high pass filter at cutoff frequency
 = 0.4 Hz, envelope signal processing and low pass
filter at cutoff frequency  = 10 Hz. High pass filter
was used to remove offset. Low pass filter was used to
smooth the envelope curve. We optimized the bend of
the shaft parameter by using Optimization Library (DLR,
2016). We used Integrated Squared Deviation as
Criteria function and Pure Random Search algorithm for
optimization.
 = {1 ()  2 ()}2 

Figure 9. The step response of simulation and experiment.
Input voltage, rotational speed and deflection versus time.

We also tested the ramp response of both systems. We
rose the rotation speed up to 2500 rpm over the first
critical speed 1600 rpm. Figure 10 shows the result. The
deflection beating over 1600 rpm is due to equation (5)
dynamic load torque effect of unbalance. By varying
parameters of both eccentricity and bend of shaft, the
responses of motor speed and horizontal vibration
between simulation and experiment had little
differences. By varying the bend of shaft value, we
found the simulation became well-consistent with
experiment.

(17)

Here,
1 () : Envelope processed simulation data.
2 () : Envelope processed experiment data.
Figure 11-13 show the result of the bend of the shaft
optimization. The evaluation function dicreased during
iteration (Figure 11). The envelope curve had changed
after optimization (Figure 12). The bend of shaft value
became 0.01 mm, as initial value was zero. By setting
this value as parameter for simulation model of
Modelica, the simulation envelope curve became well
consistent with experiment (Figure 13).
To validate the static unbalance model, we added a
screw on the rotor and made static unbalance at the
eccentricity  = 0.05 mm. By setting the bend of the
shaft parameter 0.01 mm and optimizing the eccentricity
as above, the eccentricity parameter became  = 4.87 
102 mm. We were able to estimate the eccentricity
value from our library and Optimization library. Figure
14 shows the envelope curves of both the eccentricity
parameter optimized simulation and experiment. We
were able to generate the unbalanced rotor vibration data
consistent with the physical system. Using Modelica
cyber system, we can access the unmeasurable physical
quantitities such as bearing load under operation.
Simulating this kind of complex physical system is very
hard by coding with Simulink. The more detailed
simulation by the FEM (Finite Element Method) takes
much time. Using Modelica, we can simulate and
generate data very easily in a reasonable amount of
calculation time

Figure 10. The ramp response of both system. Rotational
speed and horizontal deflection versus time. (a) Simulation
(Modelica cyber system). (b) Experiment (physical
system).

386

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132381

Session 6: Poster Session

5

Conclusions

This paper described Rotating Machinery Library we
had developed based on rotor dynamics theory. This
library generates rotating machinery system operation
data with some faults. We validated our models by
comparing both Modelica simulation and experiment
with a rotor kit as a test case.
Further developments will focus on not only
mechanical components, but also electrical components
failures in rotating machinery system. Also, we will
develop diagnosis methodology for identifying faults by
stochastic and physical model based approach.
Figure 11. Evaluation function against optimization
iteration.

Acknowledgements
We gratefully thank Dr. Gao at Modelon KK, Japan for
technical advices of developing library.

References

Figure 12. Envelope curve change by optimization. (a)
Before optimization. (b) After optimization. Red line
shows envelope of deflection signal.

Figure 13. Comparison between simulation after the
bend of the shaft optimization and experiment.

COMEDI
Control
and
Measurement
Interface
http://www.comedi.org/
DLR, Optimization Library for Dymola Version 2.2.2 Tutorial,
2016.
Gianni Ferretti, Marco Gritti, Gianantonio Magnani,
Gianpaolo Rizzi and Paolo Rocco. Real-Time Simulation of
Modelica Models under Linux / RTAI. Proceedings of the
4th Modelica Conference 2005, pp. 359-365 Hamburg,
Germany.
Yukio Ishida and Toshio Yamamoto, Linear and Nonlinear
Rotordynamics: A Modern Treatment with Applications,
2nd Edition, Wiley-VCH, 2012.
Matthew Klenk, Johan de Kleer, Daniel G. Bobrow and Bill
Janssen Using Modelica Models for Qualitative Reasoning.
Proceedings of the 10th International Modelica Conference
pp. 205-211, Lund, Sweden. doi: 10.3384/ecp14096205
Raj Minhas, Johan de Kleer, Ion Matei, Bhaskar Saha, Bill
Janssen, Daniel G. Bobrow and Tolga Kurtoglu. Using
Fault Augmented Modelica Models for Diagnostics.
Proceedings of the 10th International Modelica Conference
2014,
pp.
437-445,
Lund,
Sweden.
doi:
10.3384/ecp14096437
Osami Matsushita, Masato Tanaka, Hiroshi Kanki, Masao
Kobayashi and Patrick Keogh Vibrations of Rotating
Machinery Springer Japan, 2017. doi: 10.1007/978-4-43155456-1

Figure 14. Comparison between the eccentricity
optimized simulation (setting the optimized bend of the
shaft parameter) and experiment with static unbalance.

DOI
10.3384/ecp17132381

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

387

388

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Modelling and Simulation of the passive Structure of a
5-Axis-Milling Machine with rigid and flexible bodies for
evaluating the static and dynamic behaviour
Michael Schneider, B.Eng.1
1 Faculty

Prof. Anton Haumer1

Dipl.-Ing. Rupert Kckeis2

of Electrical Engineering and Information Technology , OTH Regensburg, 93053 Regensburg,

michael.schneider@st.oth-regensburg.de, anton.haumer@oth-regensburg.de
2 Department

of Electrical Engineering, MAX STREICHER GmbH & Co. KG aA , 94469 Deggendorf,
rupert.koeckeis@streicher.de

Abstract

2

Structure of the Machine

Most of the mechanical simulations for industrial usage Figure 1 shows a front view of the milling machine with
are done by finite element (FE-) analysis. Milling ma- its axis designation and its initial frame in the top right
chines are mechatronic systems, combining electrical, me- corner. Machine constructions where all linear movement
chanical and control components for machining certain
materials. Modelica provides a powerful and strong tool
Initial frame:
z
to simulate different physical areas in one model. For this
C
usage a mechanical model of a 5-Axis-Milling Machine compound slide
y-axis
y
is implemented with rigid and flexible bodies. Specific
b-axis
B
c-axis
x
attention will be paid to which components can be modTool Center Point (TCP)
elled as rigid bodies without significant deviation in accorclay
dance to the real behaviour of the machine. Two classes
milling tool
z-axis
of implementing flexible bodies in multi body systems are
given by the Flexible Bodies Library, advantages and disadapter plate
advantages of both classes will be evaluated. At the end
a comparision of the static and dynamic behaviour of the
Rail
passive structure of the model in contrast to a FE-analysis
is given.
Figure 1. Structure of the milling Machine
Keywords: milling machine, flexible body, multibody system, clay modelling

1

Introduction

High Speed Cutting (HSC) Machines are present in different technical areas today. The automotive sector uses
HSC-Machines for editing clay models of vehicles to improve the design and the aerodynamic behaviour. For this
usage high performance and very high precision is required. The validation of mechanical improvements on
existing machines is expensive and time consuming. On
the other hand FE-Models can not describe the whole
mechatronic system, because the exact influence of the
electrical drive train in mechanic models is described insufficiently. For this reason a multyphysical model with
an electrical, a mechanical and a control system model
has to be created. The mechanical model should describe
the behaviour of the passive structure in a good approximation. A time efficient model of the machine consisting
of rigid and flexible parts without major deviations is developed. During the modelling process several modelling
issues have to be solved with particular models.
DOI
10.3384/ecp17132389

axes are facing the milling tool side are called travelling
column machines. The considered machine has a horizontal tool spindle, the end of the milling tool is called "Tool
Center Point" (TCP). The three main axes (x-, y- and zaxis) realize linear movements in the cartesian space, two
minor axis (b- and c-axis) enable rocking and rolling motions of the TCP. All of the three linear movements are
equipped with linear guides for stiff transition between
the movable and the fixed part of the machine. A compound slide enables movements in y- and z-direction. At
the end of the y-axis a milling head is mounted. The linear
axes are driven by short stator linear motors, the rocking
and the rolling movement is achieved by synchronous motors. An additional synchronous motor drives the milling
tool with a very high speed to reduce the cutting force at
the TCP. A classification of the different mechanical machine parts is useful. Components with small measurements and high rigidity compared to large machine parts
are called "secondary machine parts", large components
with low rigidity are called "main machine parts".

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

389

Modelling and Simulation of the passive Structure of a 5-Axis-Milling Machine with rigid and flexible bodies
for evaluating the static and dynamic behaviour

3

Modelling of the secondary machine 3.2 Model of the adapter plate and the compound slide
parts

3.1

Linear guidances at machine tools

Linear guidances are used to achieve relative movements
between fixed and movable parts of machine tools and expose high static, dynamic and thermal stiffness. Furthermore they should show very high dynamical accuracy and
low wear running. A classification in two components is
usual, a guide carriage mounted at the movable part of the
machine and a guide rail at the fixed machine part. The
whole carriage-rail system has flexibility in three directions and could therefore deform as a result of a pulling,
compressive or a shear force. Modelling this component
with flexible elements would terminate in long simulation
times due to the incidence of this component in the whole
structure. For the purpose of simplification this component could be modeled with rigid bodies if the flexible
transition between carriage and rail is modeled in an other
more handable way(Queins, 2005, p. 50). But to represent
the flexibility of the whole carriage-rail system, that has a
significant influence on the static and dynamic behaviour
of the structure, a possible replacement for a flexible body
model of the carriage-rail system is given at Figure 2. The

The adapter plate connects the moving part of the machine
with the machine base also called "rail". This connection is obtained by a linear recirculating roller bearing,
which is especially used for longitudinal guides that provides high stiffnes of guidance systems. The adapter plate
consists of two linear guidance systems with four guide
carriages that are mounted at a mechanical cast component. Two guide rails are mounted on the rail, together
these components build the adapter plate. To reduce the
calculation effort the mechanical cast component is modeled with a rigid body due to the larger flexibility of the
carriage-rail system. Values of the spring stiffness of a
whole carriage-rail system is extracted out of Data Sheets
of the linear guidance manufacturer. Figure 3 depicts the
model of the adapter plate with the four carriage-rail transitions. The usage of two spatial separated guide units

F

Figure 3. Model and animation of the adapter plate with four
carriage-rail transitions

F

F




Front view of a flexible
body with three DOF due
to a compressive force

starrer Krper
Front view of the flexible
body replacement due to
a compressive force

Figure 2. Replacement for a flexible body system by a rigid
body system for a carriage-rail component

values of the spring stiffnesses can be calculated through
a linearization of the spring charactersistic curve of the
carriage-rail system. This curves show a progressive or a
degressive characteristic of the carriage-rail system but in
a good approximation it can be linearized at the operating
point(Queins, 2005, p. 50). The spring characteristic can
be assumed as linear subsequently to the large stiffness of
the carriage-rail system compared to other more flexible
machine components.
390

causes a distribution of the mechanical load and therefore an improved damping behaviour. The geometrical
dimensions of the guide carriage and the spring stiffness
will be presented to the carriage-rail transition models.
Therefore this model especially characterises the transition between the fixed and the movable part of the machine, deformations of the components realizing this transition are neglected(Hoffmann, 2008). With the help of a
compound slide, travel motions in y- and z-direction can
be realised. Each of the two axis motions is equipped with
two four-row linear recirculating ball bearings, where any
of them consists of two carriage guides and one guide rail.
The carriage rail system, which realises the z-motion is
mounted at the back side of a steel plate in the same way
as the adapter plate. A reverse arrangement, where the
carriage-guides are mounted at the fixed part of the machine, which is the compound slide, provides movements
in the y-direction. The carriage rails are fixed at the back
side of the y-cantilever over the wohle dimension of the
component. In the same way as the adapter plate is modeled, the compound slide will be modeled. Based on the
assumption that the shift between the fixed and the movable parts is more flexible than the self deformation of the
steel plate, only the carriage-rail systems are modeled flexibly. Figure 4 depicts the structure of the compound slide

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132389

Session 6: Poster Session

model with the eight carriage-rail transitions splitted into brary. Different parameters of the rigid components, such
the different axis movements and the related 3D-model of as the mass or geometric dimensions, are defined by dethe component. The animation of the component depicts sign data of the milling head.

4
4.1

Figure 4. Model and animation of the compound slide with
eight carriage-rail transitions splitted into the different axis
movements

the reversal arrangement of the different linear guide systems. It makes no difference whether the carriage-rail shift
between the y-cantilever and the compound slide is modeled at the slide itself or at the horizontal cantilever. In
order to the same reasons as discussed at the adapter plate,
only the flexibility of the transitions is modeled, the steel
plate is assumed to be rigid.

3.3

Modeling of the main machine parts
Modeling of the Y-Cantilever

The initial situation at the y-cantilever can be described as
follows, the cantilever is connected to the compound slide
by the linear guides as described in section 3.2. It performs movements in the YZ-plane due to external forces
caused by a linear direct drive. These forces, the connected milling head together with gravitational forces are
leading to deformations of the canteliver and therefore to
relative movements of the TCP with respect to the inital
frame. For this reasons the y-cantilever has to be modeled with flexible bodies, and therefore the usage of the
FlexibleBodies library is necessary. Choosing boundary conditions with respect to this situation would lead to
the following conditions. In Figure 6 above, the initial situation with three choosen boundary conditions (red numbers) is depicted. The boundary conditions can be chosen
cantilever (initial situation)
1

2

3

Modelling of the Milling Head

The milling head is mounted at the end of the y-cantilever,
it consists of eight parts. All of these parts are used to
achieve rotary movements of the milling tool, which is
mounted at the end of the component. Different connection flanges combine the rotary axes mechanically with
each other. In comparision with the secondary and especially with the main machine parts the dimensions of the
structural elements of the milling head are small. As a result of this assumption and as the milling head only acts
as a load at the end of the y-cantilever the components can
be modeled rigidly. In Figure 5 the model and the animation of the milling head is illustrated. The rotary motions of the different axes are implemented by components
of the Modelica.Mechanics.Multibody.Joints li-

deformed structure

1

2

3

4

cantilever (substitude model)

Figure 6. Inital situation of the y-cantilever and substituted
model

free at point 1 and 3 and as movable support at number
2 because of the parallel guidance at the compound slide.
The base class of a beam from the FlexibleBodies library enforces the user to choose boundary conditions for
each deformation type at the endings of the beam to get
correct results(Dr.-Ing. Andreas Heckmann et al., 2016).
It is not possible to choose boundary conditions at certain points within the length of the beam. Choosing the
base class of a beam model with two boundary conditions for each deformation type would therefore lead to
large errors due to neglecting the third boundary condition. Furthermore the point, where the beam is movably
supported changes during the milling process. In order
to minimize the realtive error of the y-cantilever model a
substitude model (Figure 6 bottom) has to be created. The
Figure 5. Model and animation of the milling head with rigid model is splitted into three parts, where two parts consists
bodies
of flexible beams (Figure 6 black) and one part is a rigid
DOI
10.3384/ecp17132389

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

391

Modelling and Simulation of the passive Structure of a 5-Axis-Milling Machine with rigid and flexible bodies
for evaluating the static and dynamic behaviour

body (Figure 6 blue). The whole y-cantilever is divided at
the center in two flexible beams of equal length. A rigid
body, which describes the rigid clamping of the beam at
the compound slide, is inserted between the flexible bodies. The division of the flexible structure and the insertion of a rigid body leads to a system where four boundary conditions have to be chosen but the conditions where
the flexible beams are connected to the rigid body have
to be clearly chosen as clamped. In order to align boundary conditions with the degrees of freedom of the joints,
to which the beam is attached no condition should bound
the elastic y-motion of the node attatched at the attachment frame(Heckmann, 2010). Because of the joint that
realizes the y-motion of the beam, at point 1 no boundary condition is chosen for any type of deformation and
the condition for point 4 is free. The restricition of this
model is, that only small movements of the y-cantilever
can be considered otherwise this model leads to massive
errors. However the position of the y-cantilever can be
assumed to be constant during the milling process of one
part of a vehicle such as the side or the front surface. In
addition to this problem parameters such as the cross section, the modulus of elasticity or the density can not be
chosen easily. Taking a closer look at the cross section in
Figure 7 of the flexible structures in the substituted model
illustrates this fact. The entire beam consists of two parts,

Small movements of the y-cantilever are permissible but
to consider the additional extension of the second beam,
if it is moving towards the milling head, an additional line
force has to be applied. This additive force has to be applied over the whole second beam and is depending on
the covered distance towards the milling tool. The whole
model of the y-cantilever with the additional line force acting as a point load and the animation of the component is
depicted in Figure 8. In order to reduce dynamic flexi-

a = 0.183 m
{0.183,0}

{0,0}

second coordinate

h = 0.125 m

First coordinate

Figure 8. Model and animation of the y-cantilever with an additional line load

reference point (Start)

bility, steel ribs are welded over the whole length of the
beam. This mechanical design detail could not be considtroughput direction
ered by the base class of a flexible beam without a subHydropol-filling
cast part
division of the y-cantilever model in several subsections
and therefore a higher computational effort. Because of
{0.1515,-0.125}
{0.0315,-0.125}
c = 0.12 m
the new development of different machine parts, no real
measurements are done on this components till yet. For
this reason an independent validation of the y-cantilever
Figure 7. Cross section of the y-cantilever with geometrical model with the aid of real measurements is not possible.
reference point (n)

moments of inertia

4.2

Modelling of the Z-Tower

The second main machine part that shows high static and
dynamic flexible behaviour is the z-tower. Due to the special geometry of this part, a simple beam model would not
describe the behaviour. Therefore the second base class
of the FlexibleBodies library, the ModalBody class is
used to get more accurate results. A finite element model
of the z-tower is reduced in two steps, in order to achieve a
reduction of the number of degrees of freedom. The result
(1) of this reduction is a modal representation of the component with 221 degrees of freedom. This modal representa(2) tion is stored in a standard input data file, that is the input
(3) for the ModalBody class either than for other multi-body
simulation programs like SIMPACK. The second input file
for the ModalBody provides informations of the geometri-

an empty cast part and a special vibration reducing material which is inserted there. The materials have different
modulus of elasticity E and different densities , for this
reason a fictitious material has to be developed, considering the shares V f of both materials. The material constants
of the fictitious material can be calculated in the following
way(Gross et al., 2014, p. 279-286).
Vf =

Acast
A f ill

beam = V f  cast + (1 V f )   f ill
Ebeam = V f  Ecast + (1 V f )  E f ill

392

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132389

Session 6: Poster Session

right guidance rail

simulation node 77710
coordinates {65,118.83,2859}

simulation node 82440
coordinates {65,118.83,1900}
simulation node 84378
coordinates {65,118.83,1501}

simulation node 87098
coordinates {65,118.83,941}

5

Static and dynamic investigations

The basis of the static and dynamic investigations are the
presented secondary machine parts in section 3 and the
main machine parts in section 4. Together they build
a multibody model with flexible and rigid bodies of the
milling machine.

5.1

Static investigations

The static behaviour of the multibody model will be compared with the results of a finite element simulation in order to evaluate the multibody model in contrast to a mechanic specific simulation tool. The results of the finite
element simulation are also not validated but they will
match the real static behaviour of the machine close due to
the integration of specific construction details out of CADconstructions. Both simulations are done without any load
at the end of the y-cantilever. To evaluate the static behaviour of the model a constant force in one direction is
applied at the end of the y-cantilever to get static shifts in
all three translational directions. This constant force will
be achieved through a step function with a short delay time
to provide that the whole structure is in a steady state. The
y-cantilever will therefore be in an unstable position at the
highest point at the z-tower and fully extended. The area
in which the substitute model of the y-cantilever is valid
is left and only the magnitudes of the static shifts can be
rated. After five seconds to get the structure in a steady
state, a constant force of F = 10 N is applied at the end
of the y-cantilever and after 0,35 s the structure comes already to a steady state. If the relative movement at the
Relative shift in z-direction

2.7382785

relative shift at the end of the y-cantilever in z-direction [m]

cal shape of the considered body by a wavefront file. This
file offers the user a 3D-view of the considered eg. the deformated component(Andreas Heckmann et al., p.88-94).
In order to combine the movement of the compound slide
and therefore the y-cantilever over the whole length of the
tower the usage of the extended base class MovingLoad is
suitable. It provides a connector, which allows it to attach
moving forces/bodies/systems to the flexible structure. It
is also possible to control this movement by a flange but
additional parameter need to define this movement(Dr.Ing. Andreas Heckmann et al., 2016). Shape functions
are used for defining deformations and calculating forces
acting on the ModalBody, this shape functions are only
known at certain points, specified by the Nodes parameter
vector. This makes interpolation necessary and one requirement for the ModalBody especially it needs enough
points in the vector to make this interpolation stable. The
load is only connected to the right guide rail that is close
to the milling head and the TCP. Six Simulation nodes out
of 36 on this guide rail provide a stable interpolation. Another problem is to keep small the wavefront file, that provides a 3D-view of the z-tower otherwise the internal animation of Dymola will crash. The initial object file of
the z-tower provided a mesh with 30095 elements. After applying a quadratic edge collapse decimaton filter a
reduction to 1700 elements provides a stable animation.
Figure 9 depicts the reduced animation file of the z-tower
with the six simulaton nodes.

2.7382761
z-position at the end of the y-cantilever

2.7382731
2.7382701

z2

2.7382671
2.7382641
2.7382611
2.7382581
2.7382551

z1

2.7382521
2.7382491
2.7382461
2.7382431
2.7382401
4.8256

4.8956

4.9656

5.0356

5.1056

5.1756

5.2456

5.3156

5.3856

Time [s]

simulation node 89818
coordinates {65,118.83,381}
simulation node 91474
coordinates {65,118.83,58.89}

Figure 9. Reduced animation of the z-tower with used simualtion nodes and their coordinates

DOI
10.3384/ecp17132389

Figure 10. Relative shift at the end of the y-cantilever in zdirection

end of the y-cantilever is divided by the applied force the
relative shift Vz in z-direction can be calculated.

Vz =

z2  z1 1.5974  105 m
mm
=
= 1.5974  103
F
10 N
N
(4)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

393

Modelling and Simulation of the passive Structure of a 5-Axis-Milling Machine with rigid and flexible bodies
for evaluating the static and dynamic behaviour

In the same way as shown above the relative shifts in yand x-direction can be calculated.

Tracking profile in x-direction

1.6
1.5
position of the TCP
target position of the TCP

1.4

y2  y1
=
F

m

= 1.0729  103

10 N

mm
N
(5)

1.3

Position of the TCP [m]

Vy =

1.0729  105

mm
x2  x1 5.9605  106 m
=
= 5.9605  104
Vx =
F
10 N
N
(6)

1.2
1.1
1.5618
1

1.5598
1.5578

0.9

1.5558
1.5538

0.8

1.5518
0.7

1.5498
1.5478

0.6

1.5458
1.4822 1.5222 1.5622 1.6022 1.6422 1.6822 1.7222 1.7622

0.5

Comparing the results of the multibody simulation to the
finite element solutions it can be stated that in a good approximation they are convergent. Deviations can be justified by the neglection of the flexibility of the guidance system, the disregardence of the ribs in the y-cantilever and
the desertion of the scope of the y-cantilever. Regarding
the magnitudes of the static shifts it can be said that they
are absolutely convergent to the finite element solution.

5.2

Dynamic investigations

Positioning movements will encourage oscillations of the
whole structure and therefore also vibrations of the TCP.
This oscilations will also lead to positioning errors during the milling process. To have a closer look at a positioning movement the y-cantilever will be in a stable position in the centre of the traverse range of the z-tower. A
simple ramp function will increase the x-position of the
structure till reaching a final value. The substitude model
of the y-cantilever is therefore in position that is within
the validity range. The ramp starts at position x = 0 m
at 0.5 s and increases this position till reaching the final
value of x = 1 m at 1.5 s. Figure 11 depicts the dynamical behaviour during the positioning process. The simulastructural vibrations

milling tool

z-tower

positioning movement

machine bed
x-axis

t=0 s

before force transmission

t=0 s
+ T

after force transmission

Figure 11. Dynamical behaviour during the positioning movements

0.4
0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

2.2

2.4

2.6

2.8

3

Time [s]

Figure 12. Tracking profile in x-direction

6

Conclusion and outlook

The mechanical model of the 5-axis-milling machine depicts the static and dynamic behaviour very accurate. The
simplifications made during the modeling process have
only marginal influences on the result. For modeling flexible bodies within multibody structures the FlexibleBodies library is a very accurate tool. The base classes Beam
and ModalBody offers the user different methods of implementing those flexible structures. The beam class is
only useful for describing simple beam models, complex
geometries or designs are difficult to model with this class.
An extension of the beam base class, where the user is
able to define more than two boundary conditions and
make the position of these boundary conditions time dependent would therefore be a relief. The amount of usable boundary conditions is limited to three, implementing other boundary conditions such as "movable clamped"
would make the modeling of problems, such as the movable cantilever, easier without FE-pre-processing. In order
to model such beam structures and defining input datas
such as boundary conditions or the number of the required
eigenmodes for getting correct results, a very deep theoretical background is needed. If the user only wants to implement existing models derived out of a finite element analysis the ModalBody class offers a very powerful tool for
implementing those structures. In the next step, models
of the drive trains that move the different axes will be developed. In combination with this drive models the whole
behaviour of the mechatronic system can be observed and
compared to the real system. After this validation of the
model the trajectory guidance will be improved by changing the control strategy of the drive trains.

References
tion results in Figure 12 are showing absolutely the same
Andreas Heckmann, Martin Otter, Stefan Dietz, and Jos
behaviour of the structure. After reaching the final posiDaz Lpez. The DLR FlexibleBodies library to model
tion an overshoot relative to the desired position could be
large motions of beams an of flexible bodies exported
determined. The envelope of this overshoot is an expofrom finite element programs.
In Proceedings of the
nential function which indicates a strong viscose damping
5th International Modelica Conference, pages 8595.
behaviour of the structure(Hoffmann, 2008).
URL
https://www.modelica.org/events/
394

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132389

Session 6: Poster Session

modelica2006/Proceedings/proceedings/
Proceedings2006_Vol1.pdf.
Dr.-Ing. Andreas Heckmann, Prof. Dr.-Ing. Martin Otter, Martin
Leitner, Jakub Tobolar, and Stefan Hartweg. FlexibleBodies: Library to model large motions of flexible beams, anular
plates and of flexible bodies exported from finite element programs, 2016. Version 2.2.
Dietmar Gross, Werner Hauger, Jrg Schrder, and Wolfgang A.
Wall. Technische Mechanik 2: Elastostatik. SpringerLehrbuch. Springer Vieweg, Berlin, 12., aktual. aufl. edition, 2014. ISBN 978-3-642-40965-3. doi:10.1007/978-3642-40966-0. URL http://dx.doi.org/10.1007/
978-3-642-40966-0.
Andreas Heckmann. On the choice of boundary conditions
for mode shapes in flexible multibody systems. Multibody
System Dynamics, 23(2):141163, 2010. ISSN 1384-5640.
doi:10.1007/s11044-009-9177-z.
Frank Hoffmann. Optimierung der dynamischen Bahngenauigkeit von Werkzeugmaschinen mit der Mehrkrpersimulation: Zugl.: Aachen, Techn. Hochsch., Diss., 2008, volume
2008,8 of Ergebnisse aus der Produktionstechnik Werkzeugmaschinen. Apprimus-Verl., Aachen, 2008. ISBN 978-3940565-12-9.
Marcus Queins. Simulation des dynamischen Verhaltens von
Werkzeugmaschinen mit Hilfe flexibler Mehrkrpermodelle:
Zugl.: Aachen, Techn. Hochsch., Diss., 2005, volume
2005,12 of Berichte aus der Produktionstechnik. Shaker,
Aachen, 2005. ISBN 3-8322-4224-4.

DOI
10.3384/ecp17132389

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

395

396

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Modeling and Simulation on Environmental and Thermal Control
System of Manned Spacecraft
Sun Lefeng1 Jin Jian1 Chen Liping 2 Liu Wei 2 Huang Lei2 Zhou Fanli 2 Liu Qi2
1
China Academy of Space Technology, Beijing, China,
2

sunlefeng@hotmail.com, jinjian0331@126.com
Suzhou Tongyuan Software & Control Technology Co., Suzhou, China,
{chenlp, liuw,huangl, zhoufl, liuq}@tongyuan.cc

Abstract
In order to support crew resides, key air environment
parameters of manned spacecraft should be controlled
within index range by environmental and thermal control system. In this paper a model of manned spacecraft
environmental and thermal control system in Modelica
language is developed. Using this simulation model, we
analyze air environment parameters varying trend as
the crew metabolic level variation. The results show
that crew metabolic level could influence air environment parameters dramatically. Furthermore, air environment parameters should be analyzed comprehensively due to important affection of air temperature to
oxygen partial pressure, carbon dioxide partial pressure
and relative humidity. The work in this paper is helpful
to provide a new method for analysis of environmental
and thermal control system of manned spacecraft.
Keywords: manned spacecraft, Modelica, MWorks;
temperature/humidity control, carbon dioxide removal,
oxygen pressure control

mathematical models of each component and an integral model of the entire environmental and thermal
control system. The paper has the following objectives:
1)
Establish a model of manned spacecraft environmental and thermal control system in Modelica language;
2)
Analyze the interrelationship of key parameters of manned spacecraft environmental and thermal
control system.
3)
Analyze the influence of the change of key parameters on the system.

2

System Descriptions

In this paper, the cabin environment is assumed to be
insulated from the outside. Schematic diagram of environmental and thermal control system is shown below.
oxygen
bottle
carbon
dioxide purification
fan

valve

crew
cabin

carbon
dioxide purification

1

nitrogen
bottle

valve

Introduction

Environmental and thermal control system is a system
to guarantee a good life and thermal environment and
the key technology to realize manned spaceflight [1].
The current commonly used analysis method is to establish a pressurized cabin simulation model using
CFD (computational fluid dynamics) [2-6]. The method
is used to analyze the temperature and humidity, partial
pressure of oxygen, etc. Using this design method has
the following shortcomings:
1)
In the program design, the designer is concerned with the system level indicators .CFD software
is good at equipment level analysis, not suitable for
system level analysis;
2)
CFD software is not suitable for system level
analysis so that it is difficult to analyze the interrelationship between each parameter of the system;
On the contrary, Modelica is an object-oriented
modeling and simulation language. Modelica is good at
system level analysis. With Modelica, we can establish
DOI
10.3384/ecp17132397

separator
condensate
tank

temperature and
air
humidity control
condenser
fan

cold
plate

low temperature
inner loop

low temperature
inner loop pump

cold
plate
cold
plate

heat
exchanger

outer
loop

temperature
control valve

medium temperature
inner loop

medium temperature
inner loop pump

radiator

heat
exchanger

temperature
control valve

outer loop
pump

temperature
control valve

Figure 1 Environment and thermal control system

2.1

Constitute of Environmental
Thermal Control System

and

Environmental and thermal control system includes:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

397

Modeling and Simulation on Environmental and Thermal Control System of Manned Spacecraft

1)
Cabin pressure control system: cabin is
equipped with high pressure oxygen bottle. When partial pressure of oxygen bellows the lower limit, oxygen
bottle begins to supply oxygen until partial pressure of
oxygen reaches the higher limit.
2)
Carbon dioxide purification system: cabin is
equipped with non-regenerative cabin dioxide purification tank and fan. Fan extracts air from the cabin to
purification tank. When carbon dioxide partial pressure
reaches the higher limit, a new purification tank will be
automatically replaced.
3)
Temperature and humidity control system:
cabin is equipped with air condenser, moisture separator. Air condenser provides the cold source for the temperature control loop; Fan extracts air from the cabin to
air condenser; Water and gas mixture which is collected by the air condenser enters moisture separator to
separate. The separated water enters water tank and the
separated air returns to the cabin.
4)
Low temperature inner loop control system:
low temperature inner loop is equipped with pump,
heat exchanger and temperature control valve. The
speed of pump is a parameter which is set before simulation. Temperature control valve opening is controlled
by the PID controller which is set a temperature control
point.
5)
Medium temperature inner loop control system:
medium temperature inner loop is equipped with pump,
heat exchanger and temperature control valve.
6)
Outer loop control system: heat collected by
the low temperature inner loop control system and medium temperature inner loop control system is transferred to the outer loop through heat exchanger. Outer
loop collects heat load of the cabin and equipment and
exhausts to the space through radiator.

2.2

Metabolic Level of Astronaut

The metabolic level of astronaut changes with the different forms of activities. Referring to the international
space station, this paper takes into account four metabolic levels:
1)
Sleeping: Metabolic heat production is 80W.
The rate of oxygen consumption is 0.0202kg/h. Carbon dioxide output rate is 0.023kg/h;
2)
Resting: Metabolic heat production is 100W.
The rate of oxygen consumption is 0.0252kg/h. Carbon dioxide output rate is 0.029kg/h;
3)
Mild activity: Metabolic heat production is
170W. The rate of oxygen consumption is
0.0432kg/h. Carbon dioxide output rate is 0.049kg/h;
4)
Moderate activity: Metabolic heat production is 240W. The rate of oxygen consumption is
0.0606kg/h. Carbon dioxide output rate is 0.069kg/h;

398

metabolic heat
production(W)

rate of oxygen
consumption/1

0000(kg/h)

carbon dioxide
output
rate/10000(kg/h)

Metabolic
level
240 606 690

170 432 490

80 202 230

Sleeping

100 252 290

Resting

Mild activity

Moderate activity

Active state

Figure 2 Metabolic level of astronaut at different active
state

2.3

Astronaut Schedule

This paper assumes there are three astronauts in the
cabin and they are always at the same level of metabolism. Astronaut schedule in a day is arranged as follows:
Sleeping is 7 hours. Resting is 4 hours. Moderate activity is 2 hours. Mild activity is 11 hours. Schedule is in accordance with the above order.
Active
State
Moderate
activity
Mild
activity
Resting

Sleeping

0

7

11 13

24

Time(h)

Figure 3 Crews active state diagram in a day

2.4

Indicator of Air Environment

Indicators of air environment refer to International
Space Station [7]. We can see it as follows:
Table 1 The goal of each air environment indicator

Goal

Request

temperature

2026 

relative humidity

30%70%

partial pressure
of oxygen

19000  22000
Pa

partial pressure
of carbon dioxide

700 Pa

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132397

Session 6: Poster Session

3

3.3

Models

We use MWorks as a basic platform for modeling and
simulating the environmental and thermal control system of manned spacecraft [8].

3.1

Interface Design

Interfaces for physical component models must be
physically able to connect components. Environmental
and thermal control system involves two areas of heat
and fluid so that its interfaces are heat and fluid interfaces which are shown in table 2. There are two basic
types of variables for Modelica interfaces, which are
flow variables and potential variables. Interfaces connection comply with the general theory of Kirchhoffs
law, namely the sum of flow variables is zero and the
potential variables are equal when interfaces connect to
each other. In order to meet the needs of thermal fluid
system modeling, Modelica has added a new interface
variable which is stream variable.
Table 2 Interface types and variables in interfaces

Interface type

fluid interface

thermal
face

3.2

inter-

Component Models

A component model is a restricted category of Modelica which can include parameters, variables, nested classes, equations and algorithms. A component model is
established using a bottom-up approach, inherits base
class model, declare subcomponent model and interface
and add variables and equations. Component models
correspond to the system basic physical components
such as pipe, valve, fan, heat exchanger, etc. Component models are fully functional models which can be
directly instantiated and used. Main equations of the
major components are described as follows:
3.3.1

Cabin

The cabin interacts with the outside world can be abstracted thermal and fluid interfaces. The main equations of a cabin is shown as follows:
1)
Mass conservation is calculated by the using
the following equation:

dm j

 win xin, j  wout xout , j  wlf , j

(1)

Variable

Variable type

pressure

potential variable

mass flow rate

flow variable

xin , j denotes mass percentage of the J kind ingredi-

mass ratio

stream variable

ent which flow in the cabin; wout denotes air mass

specific
enthalpy

stream variable

which flow out the cabin; xout , j denotes mass per-

temperature

potential variable

heat flow

flow variable

Medium Models

Medium models are obtained by expansion and specialization from standard medium of Modelica standard
library. Medium models and component models can be
decoupled when independent medium models are designed. Medium models are defined as replaceable
models. Component models can select medium model
by redeclaration. A medium model is a model package
which is made up of four parts:
1)
Constants, which contain the name of medium
and molar mass, etc.
2)
Attribute models, which mainly include state
equation and other thermodynamic equation.
3)
Functions, which calculate property parameters
in different states.
4)
Types, which apply to the thermodynamic variables.

DOI
10.3384/ecp17132397

dt

Where m j denotes the mass of the J kind ingredient; win denotes air mass which flow in the cabin;

centage of the J kind ingredient which flow out the
cabin; wlf , j denotes mass percentage of the J kind
ingredient metabolized by Astronaut.
2)
Energy passed to the bulkhead is calculated
by using the following equation:

dU wall
 qwall
dt

(2)

Where U wall denotes internal energy of bulkhead;

qwall denotes total heat passed to the bulkhead.
3)
Energy passed to air of the cabin is calculated by using the following equation:

dU air
 win hin  wout hout  qair
dt

(3)

Where U air denotes internal energy of air in the
cabin; hin denotes enthalpy of air which flow in the
cabin; hout denotes enthalpy of air which flow out
the cabin; qair denotes total heat added to air.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

399

Modeling and Simulation on Environmental and Thermal Control System of Manned Spacecraft

3.3.2

Crew

The crew interacts with the outside world can be abstracted thermal and fluid interfaces. The main equations of a crew is shown as follows:
1) Metabolism is calculated by the using the
following equation:



Q  Qact  Qshiv

(5)

4)
Mass conservation is calculated by using the
following equation:

Qbas

denotes basal metabolic

60000  247.35  (0.23  RQ  0.77)

mCO 2 = RQ  mO 2 

xout,CO2 =
xout,H 2O =

win, Z xin,CO2 - wCO2
wout , Z
win, Z xin,H 2O + wH 2O
wout , Z

(11)
(12)

Where xout,CO2 denotes mass percentage of carbon
dioxide in the air which flows out purifica-

Q

MWCO 2
MWO 2

denotes respiratory coefficient;

(6) tion tank; x
out,H 2O denotes mass percentage of water
in the air which flows out purification tank; win, Z
(7) denotes mass flow rate of air which flows in purification tank; wout , Z denotes mass flow rate of air
MWCO 2

is molar mass of carbon dioxide; MWO 2 denotes molar mass of oxygen.
Through inheriting interfaces and adding parameters, variables and equations, we can establish the
crew Modelica model.
3.3.3

Where MWH 2O denotes molecular weight of water;

MWCO2 denotes molecular weight of carbon dioxide.

activity of crew; Qshiv denotes heat generated by
muscle tremors.
2)
Breathing is calculated by using the following equation:

RQ

(10)

(4)

abolic activity of crew;

Where

MWH2 O
x


wH 2O  0.9185ar 1  load  mLiOH,0
MWCO2
 0.9185a 

W =  (Qact  Qbas )

Where W denotes mechanical force of every crew;
denotes mechanical efficiency; Qact denotes met-

mO 2 =

3)
Water production rate control is calculated
by using the following equation:

Carbon Dioxide Purification

The carbon dioxide purification interacts with the outside world can be abstracted thermal and fluid interfaces. The main equations of a carbon dioxide purification
is shown as follows:
1)
Total amount of carbon diox-

ide purification control of a purification tank is calculated by using the following equation:

M CO2  xload  mLiOH,0

(8)

Where xload denotes mass of carbon dioxide purified per kg in the initial state; mLiOH,0 denotes mass
per purification tank.
2)
Carbon dioxide purification rate control is
calculated by using the following equation:

xload 

wCO2  0.9185ar 1 
 mLiOH,0 (9)
 0.9185a 
Where r denotes chemical reaction rate of carbon

which flows out purification tank; xin ,CO2 denotes
mass percentage of carbon dioxide in the air which
flows in purification tank; xin,H2 O denotes mass percentage of water in the air which flows in purification tank.
5)
Momentum conservation is calculated by using the following equation:

w  w
ref
p  pref  in, Z   in, Z 
in,Z
 wref  wref

(13)

Where p denotes pressure difference of air which
flows through purification tank; pref denotes reference pressure difference of air which flows through
purification tank; wref denotes reference mass flow
rate of air which flows in purification tank; in, Z
denotes density of air which flows in purification tank;  ref denotes reference density of air
which flows in purification tank.
6)
Energy conservation is calculated by using
the following equation:

dTbed win, Z hin, Z - wout , Z hout ,Z + qreac
=
dt
M bed Cpbed

(14)

dioxide.
400

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132397

Session 6: Poster Session

Where Tbed

win  hin - hout   q
dTout
=
dt
Cp fluid   V  M dry Cpdry

denotes temperature of purifica-

tion tank; hin ,Z denotes enthalpy of air which flows

(18)

in purification tank; hout , Z denotes enthalpy of air

Where Tout denotes outlet temperature of working

which flows out purification tank; qreac denotes heat

fluid; hin denotes inlet enthalpy of working fluid;

generated by the chemical reaction; M bed denotes
total mass of purification tank; Cpbed
ic heat of purification tank.
3.3.4

hout denotes outlet enthalpy of working fluid; q dedenotes specif- notes power delivered to fluid; Cp
fluid denotes specific heat capacity of the fluid;  denotes density of
working fluid; V denotes volume of fluid; M dry

Air Condenser

The air condenser interacts with the outside world can
be abstracted thermal and fluid interfaces. The main
equations of an air condenser is shown as follows:
1)
Mass conservation of air side is calculated

by using the following equation:

wair,in = wair,out + wdrain

heat capacity of solid wall.
2)
Hydraulic efficiency is calculated by using
the following equation:

(15)

Where wair,in denotes mass flow rate of air which
flows in air condenser; wair,out denotes mass flow
rate of air which flows out air condenser; wdrain denotes mass flow rate of gas and liquid mixture which
flows in moisture separator.
2)
Liquid flow control is calculated by using
the following equation:

wdrain,liquid =  slurper xslurper,liq wair,in

denotes mass of solid wall; Cpdry denotes specific

(16)

 

3.3.6

qex = ehex min  Cair ,Ccold  Tair,in -Tcold,in 

notes heat exchange efficiency; Cair denotes heat
capacity in the gas side; Ccold denotes heat capacity

dTout win  hin - hout   q
=
dt
M dry Cpdry

(20)

Where Tout denotes outlet temperature of working
fluid; hin denotes inlet enthalpy of working fluid;

solid wall.
2)
Hydraulic efficiency is calculated by using
the following equation:

in the liquid side; Tair,in denotes inlet temperature in
the gas side; Tcold,in denotes inlet temperature in the
liquid side.
Pump

The pump interacts with the outside world can be abstracted thermal and fluid interfaces. The main equations of a pump is shown as follows:
1)
Energy is calculated by using the following
equation:

DOI
10.3384/ecp17132397

Fan

hout denotes outlet enthalpy of working fluid; q de(17) notes power delivered to fluid; M dry denotes mass
of solid wall; Cpdry denotes specific heat capacity of

Where qex denotes total heat exchange; ehex de-

3.3.5

(19)

The fun interacts with the outside world can be abstracted thermal and fluid interfaces. The main equations of a fun is shown as follows:
1)
Energy is calculated by using the following
equation:

which flows in moisture separator;  slurper denotes
liquid in mixture.
3)
Heat exchange control is calculated by using
the following equation:

W

Where  denotes hydraulic efficiency of pump;
TDH denotes total dynamic head of pump; Q denotes volume flow rate; W denotes braking power.

Where wdrain,liquid denotes mass flow rate of liquid
separation efficiency; xslurper,liq denotes mass ratio of

 g TDH Q

 

 g TDH Q
W

(21)

Where  denotes hydraulic efficiency of fan;
TDH denotes total dynamic head of fan; Q denotes
volume flow rate; W denotes braking power.

3.4

Subsystem Models

Through inheriting component models, we establish
cabin pressure control system, carbon dioxide purification system, temperature and humidity control system,
fluid loop system which includes low temperature inner

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

401

Modeling and Simulation on Environmental and Thermal Control System of Manned Spacecraft

loop, medium temperature inner loop and outer loop.
These subsystem models are shown as follows:

Figure 4 Cabin pressure control system

Figure 8 Model of environmental and thermal control
system based on Modelica

4
Figure 5 Carbon dioxide purification system

Simulations and Analysis

This paper analyzes the key parameters of the air environment of the cabin in a day. The simulation parameter settings are shown in table 3. The results are shown
in figure 9 to figure 16.
Table 3 Simulation parameter settings

Component name

Figure 6 Temperature and humidity control system

Figure 7 Fluid loop system

3.5

System Model

Through inheriting subsystem models, the model of
environmental and thermal control system is established as follows:

402

Parameter name

Values

air volume in cabin

100 m^3

cabin inner wall
area

600 m^2

carbon
dioxide purification

Mass of carbon
dioxide purifying
agent per box

2kg

carbon
dioxide purification fan

speed

150rad/s

air condenser

thermal
conductivity

350W/K

separator

speed

150rad/s

temperature
and
humidity control fan

speed

32rad/s

low
temperature
inner loop pump

speed

150rad/s

medium temperature inner loop
pump

speed

50rad/s

cabin

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132397

Session 6: Poster Session

reaches the lower limit, cabin begins to fill oxygen so
that air temperature increases. Relative humidity of air
decreases; At twenty-second hours, because the oxygen
partial pressure reaches the higher limit, cabin stops to
fill oxygen so that air temperature decreases. Relative
humidity of air increases.
In summary, air temperature has a greater impact to
relative humidity than metabolic level of crew. Relative
humidity of air is in the normal range in a day.

Figure 9 Air temperature

Air temperature in the cabin changes with the variation of crew metabolism (Figure 9). The abscissa is
time and its unit is hour. The ordinate is temperature
and its unit is centigrade. When crews are sleeping, air
temperature is about 21.5 centigrade; From fourth to
twelfth hours, air temperature increases slightly; At
twelfth hours, when crews are in moderate activity, air
temperature increases rapidly and reaches 27.7 centigrade at the highest point, beyond the upper limit of the
index; At fourteenth hours, when crews are in mild activity, air temperature decreases rapidly; At twenty-first
hours, oxygen partial pressure reaches the lower limit,
cabin begins to fill oxygen so that air temperature increases; At twenty-second hours, because the oxygen
partial pressure reaches the higher limit, cabin stops
filling oxygen so that air temperature decreases.
In summary, during a day, when the crew is in moderate activity, the air temperature is outside the normal
range.

Figure 11 Oxygen partial pressure

The partial pressure of oxygen has a relationship to
crew oxygen consumption rate, cycle of supplying gas,
air temperature, etc (Figure 11). The abscissa is time
and its unit is hour. The ordinate is the partial pressure
of oxygen and its unit is Pa. When crews are sleeping
and resting, oxygen partial pressure decreases slowly;
At twelfth hours, when crews are in moderate activity,
although the crew metabolism strengthen and oxygen
consumption increases, temperature increases rapidly
so that oxygen partial pressure increases; At fourteenth
hours, when crews are in mild activity, although crew
metabolism decline and oxygen consumption decreases,
air temperature decreases rapidly so that oxygen partial
pressure decreases; At twenty-first hours, because the
oxygen partial pressure reaches the lower limit, cabin
begins to fill oxygen so that oxygen partial pressure
increases; At twenty-second hours, because the oxygen
partial pressure reaches the higher limit, cabin stops to
fill oxygen so that oxygen partial pressure decreases.
In summary, oxygen partial pressure is in the normal
range in a day.

Figure 10 Relative humidity

Relative humidity of air is directly related to metabolic level of crew and air temperature (Figure 10). The
abscissa is time and its unit is hour. The ordinate is
relative humidity. When crews are sleeping, relative
humidity of air remains at around 38%; At fourteenth
hours, when crews are in moderate activity, although
the crew metabolic wet increases, temperature increases
rapidly so that relative humidity of air decreases; At
twenty-first hours, because the oxygen partial pressure
DOI
10.3384/ecp17132397

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

403

Modeling and Simulation on Environmental and Thermal Control System of Manned Spacecraft

Figure 12 Carbon dioxide partial pressure

Carbon dioxide partial pressure changes with the
change of crew metabolism (Figure 12). The abscissa is
time and its unit is hour. The ordinate is the partial
pressure of oxygen and its unit is Pa. We suppose the
initial carbon dioxide partial pressure is 0 .When crews
are sleeping or resting, carbon dioxide partial pressure
increases; At twelfth hours, when crews are in moderate activity, crew metabolism strengthen and more carbon dioxide is generated, carbon dioxide partial pressure increases fast; At fourteenth hours, when crews are
in mild activity, crew metabolism decline and less carbon dioxide is generated, carbon dioxide partial pressure increases slowly.
In summary, carbon dioxide partial pressure is in the
normal range in a day.
In the case of the above model parameters, the air
temperature beyond the normal range in a day. The air
temperature is controlled by the condensing dryer, and
the fluid flow into the condensing dryer is controlled by
the temperature and humidity control fan. In the case of
other parameters unchanged, we increase the temperature and humidity control fan speed to 40 rad/s and observe the change of air environmental parameters.

Figure 15 Oxygen partial pressure at 40 rad/s of fan speed

Figure 16 Carbon dioxide partial pressure at 40 rad/s of
fan speed

In summary, in a day, air temperature, air relative
humidity, oxygen and carbon dioxide partial pressure
are in the range of indicators.

5
Figure 13 Air temperature at 40 rad/s of fan speed

Figure 14 Relative humidity at 40 rad/s of fan speed

404

Conclusions

In this paper a model of manned spacecraft environmental and thermal control system in Modelica language is developed based on the professional
knowledge. Using this simulation model, air environment parameters varying trend as the crew metabolic
level variation has been analyzed. Draw the conclusion
as follows:
1)
Crew metabolic level could influence air environment parameters dramatically.
2)
Air environment parameters should be analyzed comprehensively due to important affection of air
temperature to oxygen partial pressure, carbon dioxide
partial pressure and relative humidity.
3) The simulation of the environmental and thermal control system can be carried out by modifying the
key parameters of the components, which greatly reduces the workload of the test and the working time of
the engineer.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132397

Session 6: Poster Session

References
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

Lin Guiping, Wang Puxiu. Manned space life support technology [M].Beijing: Beijing University of
Aeronautics and Astronautics press, 2006:37-147.
Cheng Wenlong, Zhao Rui, Huang Jiarong, et al.
Numerical simulation of flow heat transfer and humidity distribution in pressured cabins of an independent flight manned spacecraft[J]. Journal of Astronautics, 2009, 30(6): 2410-2416.
Fu Shiming, Xu Xiaoping, Li Jindong, et al. Carbon
dioxide accumulation of space station crew quarters
[M]. Journal of Beijing University of Aeronautics
and Astronautics, 2007, 33(5):523-526(in Chinese).
Ji Chaoyue, Liang Xingang, Ren Jianxun. Numerical study of crew carbon dioxide discharge in pressurized cabin of space station[C]. The fifth space
thermal physics conference, Chinese Astronautical
Society, 2000.9. Huangshan, 147-150.
Zhong Qi, Liu Qiang, etc. A numerical investigation
on heat transfer and flow in a pressurized cabin of
spacecraft [J]. Journal of Astronautics, 2002,
23(5):44-48(in Chinese).
Huang Jiarong, Fan Hanlin. Steady numerical simulation for the humidity distribution in manned
spacecraft habitation cabin [J]. Journal of Astronautics, 2005, 26(3):349-353(in Chinese).
Wieland P O. Living together in space: The design
and operation of the life support systems on the International
Space
Station.
NASA/TM1998206956[R].
Yu Tao, Zeng Qingliang. Multi_domain simulation based on the modeling language Modelica [J].
Journal of Shandong University of Science and
Technology, 2005, 24 (4):13-16.

DOI
10.3384/ecp17132397

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

405

406

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Modeling and simulation of a complex ThermoSysPro model with
OpenModelica
Dynamic Modeling of a combined cycle power plant
El Hefni Baligh1
1

EDF R&D STEP, Electricit de France, {baligh.el-hefni, daniel.bouskela}@edf.fr

Abstract
ThermoSysPro (TSP) is a generic library for the
modeling and simulation of power plants and other
kinds of energy systems. TSP library is developed by
EDF and released under open source license. The library
features multi-domain modeling such as thermalhydraulics, neutronics, combustion, solar radiation,
instrumentation and control.
Numerous organizations and individuals worldwide
now use TSP. Until recently, the TSP library could be
used only under Dymola for the modeling and
simulation of complex power plants. But now, with the
latest version of OpenModelica (OM), we can simulate
complex models of power plants with complex
scenarios.
To be able to use TSP under OM, some adaptations
have been applied to our models, essentially the method
used to make inverse computation.
The objective of this work is to evaluate the
potentiality, capability and efficiency of using
OpenModelica tools to perform dynamic studies of
power plants. A combined cycle power plant has been
chosen as a representative test case of the complexity of
this type of study.
The paper describes the dynamic model of a
combined cycle power plant, whose objective is to study
a step variation load from 100% to 50% and a full gas
turbine trip, using OM software. Also, the structure of
the model, the parameterization data, the results of
simulation runs, the difficulties encountered using OM
and the comparison between Dymola and OM are
presented.
Keywords: Modelica; OpenModelica; ThermoSysPro;
thermal-hydraulics; combined cycle power plant;
dynamic modeling; inverse problems.

1

Bouskela Daniel1

Introduction

Modeling and simulation play a key role in the design
phase and performance optimization of complex energy
processes. They also play a significant role in the future
for power plant maintenance and operation.

DOI
10.3384/ecp17132407

ThermoSysPro is a generic library for the modeling
and simulation of power plants and other kinds of
energy systems. ThermoSysPro library is developed by
EDF and released under open source license.
The foundations of the library are based on first
physical principles: mass, energy, and momentum
conservation equations, up-to-date pressure losses and
heat exchange correlations, and validated fluid
properties functions. The correlations account for the
non-linear behavior of the phenomena of interest. They
cover all water/steam phases, oil, molten salt and all flue
gas compositions. The granularity of the modeling may
be freely chosen. Some correlations are given by default
since they correspond to the most frequent use-cases,
but they can be freely modified by the user if needed.
This includes the choice of the pressure drop or heat
transfer correlations. Special attention is given to the
handling of two-phase flow, as two-phase flow is a
common phenomenon in power plants.
The library components are written in such a way that
there are no hidden or unphysical equations, that
components are independent from each other and to
ensure as much as possible upward and downward
compatibility across tools and library versions. This is
particularly important in order to control the impact of
component, library or tool modifications on the existing
models.
This library is aimed at providing the most frequently
used model components for the 0D-1D static and
dynamic modeling of thermodynamic systems, mainly
for power plants, but also for other types of energy
systems such as industrial processes, energy conversion
systems, buildings etc. It involves disciplines such as
thermal-hydraulics, combustion, neutronics and solar
radiation.
The ambition of the library is to cover all the phases
of the plant lifecycle, from basic design to plant
operation. This includes for instance system sizing,
verification and validation of the instrumentation and
control system, system diagnostics and plant
monitoring. To that end, the library will be linked in the
future to systems engineering via the modeling of
systems properties, and to the process measurements via
data reconciliation and data assimilation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

407

Modeling and simulation of complex ThermoSysPro model with OpenModelica - Dynamic Modeling of a
combined cycle power plant

The library may be downloaded freely together with
the OpenModelica software from
https://openmodelica.org/download/downloadwindows.
Several test-cases were developed to validate the
library in order to cover the full spectrum of use-cases
for power plant modeling:
 Dynamic model of a 1300 MWe nuclear power
plant covering the primary and secondary loops,
 Dynamic model of steam generators for sodium
fast reactor (David F., Souyri A. and Marchais G,
2009)
 Static and dynamic models of a biomass plant (El
Hefni B. and Pchin B, 2009),
 Physics/neutronics model in Modelica for a tool,
to assist the operator, to control the power plant
for infrequent transients and to establish a
strategy of optimal operating procedure (El Hefni
B., 2011),
 Dynamic model of a concentrated solar power
plant (El Hefni B., 2013),
 Dynamic multi-configuration model of a 145
MWe concentrated solar power plant with the
ThermoSysPro library (tower receiver, molten
salt storage and steam generator), (El Hefni B.,
Soler R., 2014),
 Dynamic simulation of a 1MWe CSP tower plant
with two-level thermal storage implemented with
control system (S.J. Liua et al., 2014),
 Dynamic simulation and experimental validation
of Open Air Receiver and Thermal Energy
Storage systems in solar thermal power plant
(Qing Li et al., 2015).
The objective of this paper is to show the potentiality,
capability and efficiency of OpenModelica tools to
perform dynamic studies using complex models such as
the combined cycle power plant model.
In order to challenge the dynamic simulation
capabilities of the library, a step load variation from
100% to 50% and a turbine trip (sudden stopping of the
gas turbine) were simulated.

2

How to use OpenModelica for
inverse problems (model inversion)

As the initial state of the simulation is in general
defined by the observable outputs of the system (e.g. the
nominal power output, the pressure inside the boiler,
etc.), it is necessary to solve an inverse problem to
compute the initial state. Moreover, it is necessary to
start the simulation from a stationary (or steady) state in
order to avoid the numerical difficulties which arise
when the system is started out of equilibrium
(oscillations, stiffness ).

408

The inverse problem basically consists in setting
(fixing) a state variable of the model to a known
measurement value to compute by model inversion the
value of a parameter or a boundary condition.
Modelica allows to express inverse problems, which
is a powerful feature for computing operation points,
which are defined by their observable outputs, and for
system sizing, to compute parameterised characteristics.
To implement the inverse problem under Dymola, it
is enough simply to fix the value of the state variable
and declared it to (fixed = true) and released the
parameter to be computed and declared it as (fixed =
false). However, this method is incompatible with
OpenModelica (no standard Modelica language).
Here is a simple example to illustrate the deference
between Dymola and OM for the implementation of the
reverse problem (standard Modelica language).
Furthermore, for the demonstration we use a simple
model to calculate the pressure drop in a tube, so:

Pi  Po  K 

Q Q



Pi is the fluid pressure at the singularity inlet (Pa) , Po
is the fluid pressure at the singularity outlet (Pa), Q is
the fluid mass flow rate (kg/s), K
friction pressure loss coefficient (m-4 ) and



is the
is the

3

average density of the fluid (kg/m ).
As the above equation is implemented in a TSP
component model called SingularPressureLoss, this
model component is used to illustrate inverse
calculation. The model uses the following component
models (see Figure 1):
 SingularPressureLoss model,
 SourceP model,
 SinkP model.
P0= 3e5 Pa

P0= 1e5 Pa

Figure 1. TestSingularPressureLoss model (testcase).
The equation above makes it possible to calculate the
flow rate of the fluid through the tube, provided that the
pressure drop in the tube, the coefficient of the pressure
drop and the fluid density are known (parameters).
The model inversion (calibration) consists in setting
the mass flow rate of the fluid through the tube (Q) and
the friction pressure loss coefficient of the pipe (K) can
be computed. To express this inverse problem with
Dymola, it suffices to write: [Q (fixed = true, start =
500)] and [K (fixed=false, start=100] in the parameters

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132407

Session 6: Poster Session

windows of the SingularPressureLoss model (see
Figure 2).

Steam Generator (HRSG): Thermal power: 2*360
MW,
Steam Turbine: Nominal power: 277 MW,
Condenser:
Thermal power: 428 MW.
Outlet water temperature: 305 K
Vacuum pressure: 6100 Pa.

3.1 Model description

Figure 2. Data for the SingularPressureLoss model.
On the other hand, to express this inverse problem
with OpenModelica (also valid for Dymola), it is
necessary to write: [Q (fixed = true, start = 500)] and
K = K_pipe in the parameters windows of the
SingularPressureLoss model (see Figure 3).
Also, the parameter K_pipe (new intermediary
parameter), must be created (declared) in the main
model, with [K_pipe (fixed=false, start =1.e2)], see
Table 1.

Currently, two models are used: one to simulate the
power generator step reduction load (see Figure 4), the
other to simulate the full GT trip (see Figure 5). In the
model used to simulate the GT trip, the gas turbine is
replaced by a boundary condition.
The model contains two main parts: the water/steam
cycle and the flue gases subsystem. Only one train is
modelled, so identical behavior is assumed for each
HRSG and for each gas turbine.
HRSG model:
The model consists of 16 heat exchangers (3
evaporators, 6 economizers, 7 super-heaters), 3
evaporating loops (low, intermediate and high pressure),
3 drums, 3 steam turbine stages (HP, IP and LP), 3
pumps, 9 valves, several pressure drops, several mixers,
several collectors, 1 condenser, 1 generator, several
sensors, sources, sinks and the control system limited to
the drums level control.
An important feature of this model is that the
thermodynamic cycle is completely closed through the
condenser. This is something difficult to achieve,
because of the difficulty of finding the numerical
balance of large closed loops.
The list of components used for the development of the
HRSG model is given in Table 2.
Table 2. Library components used in the HRSG
model.
Type
Model name in the library
Condenser DynamicCondenser

Figure 3. Data for the SingularPressureLoss model.
Table 1. The declaration of the K_pipe in the main
model.
model TestSingularPressureLoss
parameter Real K_pipe (fixed=false,start=1.e2)
"Pressure loss coefficient";
equation

3

Combined cycle power plant model

The power plant model is a complete model of a real
combined cycle power plant:
Gas Turbine (GT): Nominal power: 2*226 MW,

DOI
10.3384/ecp17132407

Drum

DynamicDrum

Generator

Generator

Heat
exchanger

Pipe

DynamicExchangerWaterSteamFlue
Gases
=
DynamicTwoPhaseFlowPipe
ExchangerFlueGasesMetal
HeatExchangerWall
LumpedStraightPipe

Pump

StaticCentrifugalPump

Steam
turbine
Valve

StodolaTurbine
ControlValve

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

409

Modeling and simulation of complex ThermoSysPro model with OpenModelica - Dynamic Modeling of a
combined cycle power plant

Water
mixer
Water
splitter

VolumeB, VolumeC
VolumeA, VolumeD

Heat Exchanger:
Based on first principles mass, momentum and
energy balance equations, the following phenomena are
represented:
 Transverse heat transfer,
 Mass accumulation,
 Thermal inertia,
 Gravity,
 Pressure drop within local flow rate.
Drum and Condenser:
Based on first principles mass and energy balance
equations for water and steam, the following
phenomena are represented:
 Drum level and swell and shrink phenomenon,
 Heat exchange between the steam/water and the
wall,
 Heat exchange between the outside wall and the
external medium.
Steam turbine:
Based on an ellipse law and an isentropic efficiency.
Pump:
Based on the characteristics curves.
Pressure drop in pipes:
Proportional to the dynamic pressure  the static
pressure.
Mixer/splitter:
Based on the mass and energy balances for the fluid.
GT model:
The model consists of 1 compressor, 1 gas turbine, 1
combustion chamber, sources, sinks and 1 air humidity
model.
The list of component models used for the
development of the GT model is given in Table 3.
Table 3. Library components used in the GT model.
Type
Model name in the library
Air humidity AirHumidity
Compressor

GTCompressor

Gas turbine

CombutionTurbine

Combustion
chamber

GTCombustionChamber

Gas turbine:
Based on correlations for the characteristic.
Compressor:
410

Based on correlations for the characteristic.
Combustion chamber:
Based on first principles mass, momentum and
energy balance equations. The pressure loss in the
combustion chamber is taken into account.
The CombinedCyclePowerPlant model contains
673 component models, generating 10802 variables,
257 differentiated variables, 2752 equations and 1855
nontrivial equations.

3.2 Data implemented in the model
All geometrical data were provided to the model
(pipes and exchangers lengths and diameters, heat
transfer surfaces of exchangers, volumes ).
The plant characteristics are given below.
Gas Turbine (GT)
Compressor compression rate: 14
Steam Generator (HRSG)
HRSG with 3 levels of pressure.
High pressure circuit at nominal power: 127 bar
Intermediate pressure circuit at nominal power: 27 bar
Low pressure circuit at nominal power: 5.0 bar
Steam Turbine
High pressure at nominal power: 124.5 bar, 815 K
Intermediate pressure at nominal power: 25.5 bar, 801K
Low pressure at nominal power: 4.8 bar, 532 K
Condenser
Steam flow rate: 194 kg/s
Water temperature at the inlet: 306 K

3.3 Model calibration
The calibration phase consists in setting the
maximum number of thermodynamic variables to
known measurement values taken from on-site sensors
for 100% load. This method ensures that all needed
performance parameters and size characteristics can be
computed. The variables imposed in the model are:
 Pressure at the outlet of the pumps,
 Pressure at the inlet of the steam turbines,
 Specific enthalpy at the inlet of the steam turbines,
 Liquid level in drums and in condenser,
 Overall heat exchangers coefficients,
 Isentropic efficiency of the compressor,
 Exhaust temperature of the gas turbine,
 
The main computed performance parameters are:
 The characteristics of the pumps,
 The ellipse law coefficients of the steam turbines,
 The isentropic efficiencies of the turbines,
 The CV of the valves and the valves positions
(openings).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132407

Session 6: Poster Session






Heat exchangers fouling coefficients,
Nominal isentropic efficiency of the compressor,
Nominal isentropic efficiency of the gas turbine,


3.4 Simulation scenarios
For simulation runs, two scenarios were selected. The
first scenario is a power generator step reduction from
100 to 50% load:
 Initial state (combined cycle): 100 % load
 Final state (combined cycle): 50% load (800 s
slope).
The second scenario is a full GT trip (sudden
stopping of the gas turbine):
 Initial state (GT exhaust): 894 K, 607 kg/s
 Final state (GT exhaust): 423 K, 50 kg/s (600 s
slope).

The computational time is faster than real time.

3.7 Comparison between Dymola and
OpenModelica
The simulation results of OM are very close to the
simulation results of Dymola. The simulation time with
OM is between 15% and 60% times slower than the
simulation time with Dymola, depending on the
scenario and the tolerance (see Table 4).
Table 4. Simulation time.
Simulation time (s)
Dymola 2017
Tolrance=0,001

Tolrance=0,0001

OpenModelica1.11.0
Tolrance=0,001 Tolrance=0,0001

Variation de charge
(simulation 2500 s)

58

73

75

84

Trip TAC
(simulation 10000 s)

174

310

240

492

However, OM is still 20 times faster than real time in
the worst case.

3.5 Simulation
Simulation runs were done using Dymola 2017 and
OpenModelica 1.11.0. The simulation of the scenarios
were mostly successful. However, some difficulties
were encountered when simulating large transients,
mainly stemming from the large size of the model:
 Poor debugging facility,
 Large number of values to be manually provided by
the user for the iteration variables, for the two tools.
In particular, it has been observed that, the two tools
cannot calculate the initial states, when all iterations
variables are not set close to their solution values.

3.6 Simulation results
The model is able to compute:
 The air excess,
 The distribution of water and steam mass flow rates,
 The thermal power of heat exchangers,
 The electrical power provided by the generator,
 The pressure temperature and specific enthalpy
distribution across the network,
 The drums levels and the condenser level,
 The performance parameters of all the equipments,
 The global efficiencies of the water/steam cycle and
gas turbine.
The results of the simulation runs are given in Figure
6 and Figure 7. They are consistent with the engineers
expertise. The comparison between simulation
results and GE (General Electric) results
(FOUQUET L, 2004) for 100 % load and 50 % load,
have shown that the Simulation results are very close
to the GE values (Design results).

DOI
10.3384/ecp17132407

4

Conclusion

A dynamic and rather large model of a combined
cycle power plant has been developed to validate the
ThermoSysPro library. This model comprises the flue
gas side and the full thermo-dynamic water/steam cycle
closed through the condenser. Two difficult transients
were simulated with Dymola 2017and OpenModelica
1.11.0: a step reduction load of the power generator and
a full gas turbine trip. The results are mostly consistent
with the engineers expertise.
Despite of some simulation difficulties because of the
lack of debugging tools for Modelica models, this work
shows that the library is complete and robust enough for
the modelling and simulation of complex power plants
with the two software.
The simulation results of OM are very close to the
simulation results of Dymola. The simulation time with
OM is slower than simulation time with Dymola, but
still 20 times faster than real time.
This work shows that OpenModelica software is very
satisfying for thermo-hydraulic modelling and
simulation.
Acknowledgements
This work was partially supported by the OPENCPS
project.

References
David F., Souyri A. and Marchais G., Modeling Steam
Generators for Sodium Fast Reactors with Modelica,
Modelica 2009 conference proceedings.
El Hefni B. and Pchin B., Model driven optimization of
biomass CHP plant design, Mathmod conference 2009,
Vienna, Austria.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

411

Modeling and simulation of complex ThermoSysPro model with OpenModelica - Dynamic Modeling of a
combined cycle power plant
El Hefni B. Dynamic modeling of concentrated solar
power plants with the ThermoSysPro Library (Parabolic
Trough collectors, Fresnel reflector and Solar-Hybrid),
SolarPaces 2013, Elseviers Energy Procedia,
El Hefni B., Modle physique/neutronique en Modelica
dun outil daide au pilotage du transitoire sensible de monte
en puissance  3%Pn/h aprs rechargement. Maquettage dun
outil daide au pilotage sous Excel/VB, LMCS 2011.
El Hefni B. and Soler R. Dynamic multi-configuration
model of a 145 MWe concentrated solar power plant with the
ThermoSysPro library (tower receiver, molten salt storage and
steam generator), SolarPaces 2014, Elseviers Energy
Procedia.

Liua S.J., Faille D., Fouquet M., El Hefni B., Wangc Y.,
Zhang J.B., Wang Z.F.,.Chen G.F and Soler R., Dynamic
simulation of a 1 MWe CSP tower plant with two-level
thermal storage implemented with control system,
SolarPaces 2014, Elseviers Energy Procedia.
El Hefni B., Bouskela D. Lebreton G., Dynamic
modelling of a combined cycle power plant with
ThermoSysPro, MODELICA 2011 conference.
FOUQUET
L,
EDF Ple
Industrie,
CNET:
Y.PM.X.000.PPPP.00.X.0872: PhuMy2.2: Overall plant
operation description, 2004.

Qing LiFengwu BaiBei YangBaligh El Hefni and
Sijie Liu, Dynamic simulation and experimental validation of
Open Air Receiver and Thermal Energy Storage systems in
solar thermal power plant, SWC 2015 en Kor 2015.

Figure 4. Model of the combined cycle power plant used for the power generator step reduction load.

Figure 5. Model of the combined cycle power plant used for the full GT trip.

412

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132407

Session 6: Poster Session

Figure 6. Power generator step reduction simulation (-50%): natural gas mass flow rate, air mass flow rate, excess air
temperature at the inlet of the combustion turbine, exhaust temperature (gas turbine), mechanical power of the combustion
turbine, mechanical power produced by each steam turbine, generator power, HRSG temperature at the outlet, steam mass
flow rate produced in each drum, the drums pressure, and the drums level.

DOI
10.3384/ecp17132407

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

413

Modeling and simulation of complex ThermoSysPro model with OpenModelica - Dynamic Modeling of a
combined cycle power plant

Figure 7. Gas turbine trip simulation: flue gases temperature at the inlet of the HRSG, flue gases mass flow rate at the inlet
of the HRSG, generator power, the drums pressure, steam mass flow rate produced in each drum, thermal power produced
in each heat exchanger (Evaporators HP, IP, LP and economizers HP, IP, LP), and steam mass flow rate in each steam
turbine.

414

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132407

A Power-Based Model of a Heating Station for District Heating
(DH) System Applications
Abdulrahman Dahash

Annette Steingrube

Mehmet Elci

Fraunhofer-Institute for Solar Energy Systems, Heidenhofstrae 2, 79110 Freiburg im Breisgau, Germany
{adahash, asteingr, melci}@ise.fraunhofer.de

District Heating (DH) systems are often seen as a good
practical approach to meet the local heat demand of the
districts due to its ability to provide affordable and low
carbon energy to the consumers. Yet, under todays
regulations to renovate the buildings into more energyefficient ones, the local heat demand is decreasing.
Therefore, the operation of DH systems is also affected
by the changing heat demand profile, which might lead
to less profit for the operators of DH systems. Thus, the
operators of DH systems strive for an optimal
operation at which the heat demand is met and the
profits are maximized. Due to the fact that these
systems are complex-physical systems, therefore it is
difficult to conduct any experimental investigation on
them in order to examine the optimal operation.
Accordingly, it is crucial to create fundamental models
to investigate the optimal operation of such systems. In
this paper, a power-based model is built to represent
the heating station as part of a DH system. Then, the
model is validated using real data from an existing
heating station in Freiburg, Germany. The validation
results reveal that the goodness-of-fit for the model is
held to be good enough to test it for operational
optimization cases.
Keywords: Modelica, Dymola, Dynamic Modeling,
Heating Station, District Heating System, Power-Based
Model, Optimization.

1

Introduction

District heating (DH) is considered a promising
technology to improve the energy efficiency of the
space heating systems in buildings (i.e. residential,
commercial and industrial) (Olsthoorn et al., 2016).
Thus, a greater interest in installing DH systems has
arisen in many countries such as European countries,
China and Russia. (Jie et al., 2015). DH systems have
many advantages, for instance, an optimum use of fuel
and thereby limitation of pollution (Benonysson et al.,
1995).
Generally, a DH system is represented by
transmission networks employed to supply heat from
supply side (i.e. generation site) directly and/or
indirectly to demand side (i.e. end users) to meet their

DOI
10.3384/ecp17132415

space heating and domestic hot water (DHW) demand
as shown in Figure 1.
Supply side

Fuel

Hot water
Cold water
Fuel

Heating
Station

Demand side

Transmission
network

Abstract

Pipeline
System

Consumers

Figure 1: Generic block diagram of a district heating
system

Often, DH can be coupled either with centralized
heating stations and/or distributed heating units. Thus,
numerous kinds of heat generation technologies
(boilers, cogeneration plants, heat pumps, etc.) and
energy sources (fossil fuels, renewable energies, etc.)
can be adopted (Joelsson et al., 2008).
In Germany, combined heat and power (CHP)
based DH systems are often seen as a key solution to
meet the local heat demand in buildings and, therefore,
these CHP units are frequently heat-driven (Elci et al.,
2015). This operation mode compared to electricitydriven mode is often seen as the most economical and
ecological option and therefore preferred by most
operators of distributed energy systems due to the
utilization of produced heat to meet the local heat
demand and, therefore, no heat is wasted (Shipley et
al., 2008) (Bracco et al., 2013). While the produced
heat is utilized, the generated electricity is fed into the
national power grid either at a fixed tariff, or at a
variable tariff that is depending on the electricity price
at the European Energy Exchange (EEX). However,
because of the refurbishment of buildings to be more
energy-efficient, there is a significant change in the
heat demand profile of the buildings. Accordingly, this
changing profile of the heat demand has a major
impact on the operation of CHP units in DH system,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

415

A Power-Based Model of a Heating Station for District Heating (DH) System Applications

creating the first challenge in this field by disrupting
the viable heat-driven regime mode.
Moreover, a CHP-based DH system can help the
power grid to work smoothly by generating electricity
when the renewables share in the grid is low due to
calm-dark weather (e.g. low solar irradiation) (Kelly et
al., 2009). Thus, another challenge has arisen in the
field of DH systems, especially in cases when the heat
demand is low in the buildings, the storage system is
full and it is necessary to operate the heating station to
overcome the fluctuations from renewables.
Considering these challenges (continuous changing
heat demand and renewables fluctuations), the
performance of DH systems (CHP-based) in different
operation regimes has to be examined, in order to
achieve optimal operation in which the system
responds quickly to deviations in electricity prices and
distributes the load among the heat sources in the
system, so that the highest possible financial gain is
achieved while simultaneously the heat demand is fully
met. It is surely challenging to achieve this
optimization unless fundamental models are built to
help in investigating the performance of energy
systems under different circumstances.
In this paper, the authors present an approach for
modeling of heating stations for DH system
applications. The presented model is a power-based
model and, therefore, it shows the amount of energy
flow between the different generation technologies in
the heating station (supply side). The advantages of
this modeling approach are less simulation time, better
understanding of the energy flow influence on the
heating stations operation and assistance in developing
power-based control strategies for achieving optimal
operation. Whereas the limitation is that the thermohydraulic aspects (e.g. pressure, flow rates) are
neglected.

2

Methodology

2.1 Case Study
As case study, a district in the city of Freiburg in
the south of Germany was used. This district is called
(Weingarten) and was built in the 1960s and has 9,000
inhabitants. The western part of Weingarten has a
population of 5,800 and an area of 0.3 km2, with a
gross floor area of about 271,240 m. The gross floor
area comprises: 16-floor residential tower block
buildings, 8-floor and 4-floor blocks of flats and nonresidential buildings. Under current regulations
regarding comfort, energy efficiency and modern
building technology, the buildings in the western part
have to be renovated to match current requirements.

416

This refurbishment works contains modernizing the
districts buildings, renew Weingartens energy supply
system and operate it optimally. Figure 2 shows a site
plan about the refurbishment area in Weingarten
district in which the red colored buildings are the
targeted buildings for refurbishment.

Figure 2: Site plan of the refurbishment area: the planned
to be renovated buildings are colored red (Foschung fr
die Energieeffiziente Stadt, 2016)

The heat supply is delivered by a central heating
station that supplies heat to two districts (i.e.
Rieselfeld, Weingarten) via a DH network as shown in
Figure 3 below. In the heating station, the annual heat
generation is 67,400 MWh/a, and maximum heat
output is 26,000 kW and, therefore, 6 gas-fired CHP
units are installed and the operation of them is mainly
heat-driven. Consequently, two CHP units are
operating almost continuously year-round to meet the
baseload. The six CHP units produce a total electrical
power of 7,200 kWel and a heat output of
approximately 9,600 kWth. The CHP modules attain an
average of 5,650 full load hours yearly. Hence, over 75
% of the annual amount of heat produced comes from
CHP units, while the remainder is generated by peak
boilers. Also, in order to achieve smooth operation of
the CHP units, there are two heat storage systems with
a total capacity of 360 m3. They help in meeting the
demand over short periods. Additionally, three gasfired boilers each with 9.3 MW are employed for peak
loads.
Due to the fact that CHP units can produce both
heat and electricity, the electricity from the six CHP
units is fed into the power grid while the heat produced
is used to cover the heat demand.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132415

Session 6: Poster Session

Figure 3: Top view of the Weingarten and Rieselfeld district with the central heating station and DH network
(Bachmaier et al., 2015)

2.2 Modeling of the Heating Station
The model represents the real heating station in
which an equivalent boiler component is used to
represent the three peak boilers. Also, the CHP units
are modeled to show the amount of energy flow while
the storage system is modeled as stratification water
storage. The modeling allows the different temperature
segments to be shown within the storage system. In this
work, the Modelica standard library (MSL) for basic
components (e.g. prescribed heat flow, sensors and
etc.), while buildings library is used for thermohydraulic components (e.g. flow sources/sinks, storage
etc.).

2.2.1 Consumer
This component represents the demand side to
which the heat shall be supplied. Therefore, it has two
ports, one of which is an output signal for heat demand
and the other an input signal for heat supply. The
Consumer component is afterwards connected with the
first controller in the heating station (1st CHP
controller) and is backwards connected with the heat
supply collectors using the different technologies.
Also, the heat demand profile is read from a text file
that
is
implemented
in
component
(Heat_Demand_Profile) as seen in the left part of
Figure 4.
This component plays a major role in the instant
energy balance. For example, if the heat demand is
higher than the heat supply it signals negative energy
flow as seen in the gain component in Figure 4. Then

DOI
10.3384/ecp17132415

the signal is translated in order to operate the heating
station and therefore:
demand = Supply
(1)
Also, Figure 4 shows that there is a water source (a
pump) implemented in the consumer model, the
function of this component is to provide water with a
predefined mass flowrate and temperature. Then the
supplied water gets a signal of the required heat
demand with a negative sign and a signal of the
supplied heat simultaneously in order to inspect the
energy balance and to fulfill it.

Figure 4: Structure of consumer component

2.2.2 Heat Sources
2.2.2.1 CHP unit

The CHP unit has a Boolean input that works as an
on/off button, and an output that gives the amount of
heat produced by this unit.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

417

A Power-Based Model of a Heating Station for District Heating (DH) System Applications

For the sake of simplicity in the modeling of CHP
units, the following assumptions are made:
1. The response time of the components is included in
the model. In reality, all the mechanical or electrical
equipment has a certain response time (Smit, 2006).
However, in this model, the response time is
approximated to 1800 seconds for the entire CHP
and it is given in the delay component that receives
and sends Boolean signals as shown in Figure 5.
2. CHP units do not run at partial loads, they run only
at full loads. When the CHP units run at partial
loads, the thermal and electrical efficiency of the
CHP units are different than the nominal values.
Hence, only full load operation is considered as it is
also valid in the actual system, Weingarten heating
station.
1.5 MW
CHP = {
0

(2)

3. The system is not modeled as a closed loop,
meaning that the supply and return temperature of
the water or steam in the system is not controlled.
This assumption is made to reduce the run time of
the simulation.

Figure 5: Structure of CHP unit component

The water tank, which is cylindrical in shape, loses
heat to the environment due to heat transfer
mechanisms arising through the walls of the tank
because of the different temperatures. Thus, it is
essential to obtain the optimal storage volume by
reducing the Surface Area (SA) to its acceptable
minimum value and increase the storage volume to the
maximum value. Therefore, it is assumed that the tank
height is twice its radius, to achieve the minimum SA
and maximum volume (Dearling et al., 2006):
 = 2   2  
(3)
 = 2   2 + 2    

(4)

 = 2      

(5)

Due to technical restrictions regarding storage, it is
decided to set the minimum temperature in the storage
system (maximum temperature at last segment) to
70C and the maximum supply temperature from the
storage is set to 100C. According to which the thermal
storage capacity can be obtained by the following
equation:
2

 =    ()  d =    ()  

2.2.2.2 Hot Water Storage

The main storage component has 2 ports which are
input signals; one represents the amount of heat
charging while the other is the amount of heat
discharged.
Figure 6 shows the structure of the storage
component. Obviously, the charging and discharging
ports are connected to the water tank. As the heat flow
direction is crucial to the discharging process, therefore
the discharge value is provided as a negative value.
The water tank component representing the storage
tank itself was largely built and developed by
Lawrence Berkeley National Laboratory (LBNL) and
can be found in the buildings library (Wetter, 2016).

418

Figure 6: Structure of storage model

(6)

1

This restriction plays a key role in reducing heat
losses from the tank. Heat losses are calculated within
the model, taking into account the ambient temperature
as Figure 6 shows. Ambient temperatures are given as
a measurement and implemented in the system in order
to show the real behavior of the storage system.
Moreover, TSen_Lower" component is the
temperature sensor for indicating the temperature at
lower segment of the tank while TSen_Upper is used
as an indicator for CHP units to decide whether storage
can be discharged or not.
The thermal conductance of the tank is important as
it influences the heat losses from the tank. Thus, it is

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132415

Session 6: Poster Session

calculated in such a way that the influence of the
storage medium is excluded. This assumption is true
because the impact of the storage medium on the
thermal conductivity of the tank is very small.
Therefore, the conductance is calculated as below:

(7)
 =  

The insulation layers of the tank are made of
polystyrene which has a thermal conductivity of 0.03
W/m.K with a thickness of 0.1 m (Terry et al., 2012).
Hence, the conductance is automatically calculated as a
function of the storage surface area for any given
storage volume.
2.2.2.3 Boiler

The boiler component has only two ports, one an
input and the other an output. These ports determine
the required demand and the supply from the boiler.
Figure 7 shows the configuration of the boiler in
Dymola. The boiler input is clearly seen by the port
u which is the remaining demand, and y represents
the boiler output. Also, the boiler input is the
remaining heat demand after all CHP units run and the
storage capacity is discharged.

Figure 7: Structure of boiler component

2.2.3 Central Controlling
2.2.3.1 CHP Controller

Similar to the real heating station, the bottom
segment temperature for storage is set to 70C and the
upper one is set to 100C. Moreover, for each CHP
unit, an individual CHP controller is installed in the
system. In this controller, the heat demand and the
storage temperatures (upper and bottom) are
simultaneously checked. From Figure 8, it can be

DOI
10.3384/ecp17132415

clearly seen that there are 3 cases to run the CHP unit,
which are:
1. Power case (a): if the heat demand is higher than
the nominal CHPs heat output and the temperature
of the bottom segment is higher than 70C, then the
CHP unit runs.
2. Power case (b): if the heat demand is higher than
nominal CHPs heat output and the temperature of
the bottom segment is lower than 70C, then the
CHP unit runs.
3. Power case (c): the CHP unit runs, when the
following conditions are all true:
i. The heat demand is lower than nominal CHPs
heat output, and
ii. The heat demand is higher than 95 % of the
CHPs heat output (equals 1.425 MW), and
iii. The upper storage temperature is lower than
95C.
Regarding power case (a), as the storage
temperature is equal to or higher than 70C, this means
the storage can be discharged. On the contrary, if the
storage temperature is less than the set bottom
temperature (70C), this means the energy stored in the
storage system cannot be used and, therefore, power
case (b) is activated to supply the heat directly to the
consumers. While power case (c) is activated in order
to cover the heat demand that is higher than 1.425 MW
and the remaining of the heat output charges the
storage.
Moreover, if the heat demand (or the remaining
heat demand for CHP 2-6) is less than 1.425 MW or
the upper storage temperature is higher than 95C, then
the corresponding CHP unit turns off. Moreover, if the
bottom storage temperature is set to a constant value
(i.e. 70C), then a strange behavior for CHP units is
seen because the CHP unit starts ramping up and down
between 0 and the maximum heat output in order to
maintain the storage temperature at the exact-desired
level. This results in some problems with the modeling.
This problem is seen in winter season because the heat
demand is high, therefore the storage cannot be
charged, and so the temperature cannot be kept above
the minimum level. However, keeping the temperature
right at a specific temperature is not necessary for the
model. Nevertheless, obtaining accurate results for
validation is of importance. In order to avoid such
problems in modeling, the minimum temperature shall
be set in a specific range, so instead of taking a fixed
minimum temperature of 70C, it is taken between
68C and 70C. For this reason, a hysteresis
component from Modelica standard library (MSL)
itself is implemented to solve the above mentioned
problem.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

419

A Power-Based Model of a Heating Station for District Heating (DH) System Applications

Storage upper
temperature (Tupper)

Demand
(remaining demand)

Demand >
CHP output?

Storage bottom
temperature (Tbottom)

Yes

Tbottom

70 C

No

No
(b)

Yes
Demand > 95 %
CHP output?

No

(a)

Or

CHP on

Yes

Tupper

Or

95 C

No

Calculate the
remaining
demand

(c)

Yes

CHP off

Or

Next heat
source

Storage can be discharged

Figure 8: CHP controller flowchart implemented for each chp unit
6

2.2.3.2

Storage Controller

This controller plays a secondary role in the energy
balance of the entire heating station next to the
consumer component, since it gives a signal to
discharge or charge the storage system. It has 3 input
signals and a single output signal. One of the input
signals is the storage system temperature at the bottom
of the storage tank. Based on the temperature, a
decision is made as to whether the storage system can
be discharged.
However, if the temperature of storages bottom is
higher than 70C, this sends a true signal to the switch
component to discharge the storage system to cover the
remaining demand. Otherwise the output y equals
zero when the temperature is less than 70C. The
remaining demand is given by the following equation:

420

storage = demand   CHP,

(8)

=1

Occasionally, the storage system cannot be
discharged because the last segment temperature is less
than that allowed for discharging, and therefore the
remaining heat demand proceeds to the next controller,
which is the boiler controller that runs the boiler in
order to meet the required amount of heat.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132415

Session 6: Poster Session

Bottom storage
temperature

Remaining Demand
(Demand)

Bottom storage
temperature 70C?

No

Storage cannot be
discharged

Yes
Next heat
source

Discharge storage

Figure 9: Storage controller flowchart
2.2.3.3

Boiler Controller

The boiler controller is a simple unit which
computes how much heat demand remains after the
total output of the CHP units and the discharged
capacity of the storage system as Figure 10 shows.
Next, it gives an output signal to run the boiler in a
partial mode to meet the remaining heat demand, thus:
0  boiler  27.9 MW
(9)
Here, the remaining demand is computed as below:
6

boiler = demand   CHP,  storage

(10)

=1

The term storage refers to the usable heat in the
storage system. Therefore, the usable temperature lies
between 70C and 100C.

1997). Whilst models with CV-RMSE less than 5%
can be considered excellent models, those with less
than 10% can be considered good models, those with
less than 20% can be taken as mediocre models, and
those greater than 20% are considered poor models
(Balci, 1998). However, the constraints that are set in
this article for the evaluation of the goodness-of-fit for
the model are: R2  0.7 and CV-RMSE  15%. Then it
can be said that the model is held to be good.
In validation process, the data sets of the CHP units
(both simulated and monitored) are required for
validation purposes. This is because the variation
between them is important as they are the first heat
source that runs in order to meet the heat demand, and
they are therefore the most influential parameters, with
any disruption in their output having an impact on the
other energy systems.
First, the model is visually validated for 9 days of
January as a representation of winter season (high heat
demand period) as Figure 11 shows.

Figure 10: Structure of boiler controller

3

Validation

Measured
Simulation

9

8

7

It is held that models with coefficient of
determination, R2  0.7 and coefficient of variation of
root mean square error (CV-RMSE)  7% are
arbitrarily deemed to be good models (Reddy et al.,

DOI
10.3384/ecp17132415

CHP heat output in (MW)

10

1

4
7
Day of January 2016

10

Figure 11: CHP heat output for 9 days of January 2016

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

421

A Power-Based Model of a Heating Station for District Heating (DH) System Applications

 2 = 0.84
   = 2 %
The result of CV-RMSE = 2 % indicates that only
this percentage of the real data is not explained by the
model.
As the measured data are available for other periods, it
is more obvious to validate another period of winter
season and, therefore; another 6 days of February
(from 5th to 11th of February) are taken to examine the
creditability of the model for winter season as shown in
Figure 12.

Measured
Simulation
6

7

8
9
10
11
Day of April 2016

12

13

Figure 13: CHP heat output for 7 days of April 2016

Measured
Simulation

For this time period, the R2 value of 0.87 (1  0.87
 0.7) indicates that the model can represent the real
heating station with a good approximation of its real
behavior.
As spoken earlier, due to the availability of
measured data from the heating station for other
periods, it is worthwhile to validate another time series
from summer season. Thus, a time series of 5 days is
taken from 9th to 14th May 2016 as Figure 14 shows.

9

8

8
7
5

6

7
8
9
Day of February 2016

10

11

Figure 12: CHP heat output for 6 days of February 2016

The numerical validation results are:
 2 = 0.85
   = 2 %
These results confirm again that the model has a
goodness-of-fit in the representation of the actual
system and can be used to develop and test control
strategies for the heating station. Nevertheless, an
uncertainty analysis is crucial after the development in
order to investigate the uncertainty percentage in the
model for the developments.
Regarding summer season (relatively low heat
demand compared to winter), a time series of 7 days
out of April 2016 is chosen to evaluate the goodnessof-fit for the model and it is shown in Figure 13. The
numerical results are as follows:
2

 = 0.87
   = 7 %

422

CHP heat output in (MW)

CHP heat output in (MW)

10

10
9
8
7
6
5
4
3
2
1
0

CHP heat output in (MW)

Then numerical validation is performed and the
results are as below:

7
6
5
4
3
2
Measured
Simulation

1
0
9

10

11
12
Day of May 2016

13

14

Figure 14: CHP heat output for 5 days of May 2016

Visually, the matching between both series is held
to be good enough, thus proceeding to numerical
validation:
 2 = 0.84
   = 7 %
The result of R2 confirms again the goodness-of-fit
for the model. While a CV-RMSE value of 7 %
indicates that the dispersion of the simulated and real
data around the mean of the real data is quite low, and
it is therefore clearer that the mathematical model fits
the real heating station to a high degree.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132415

Session 6: Poster Session

4

Discussion and Remarks

The model constructed represents a particularly
complex energy-supply system that comprises different
energy sources and therefore there is a challenge in
terms of energy system modelling and accurate
prediction. Any given energy system is characterized
by multiple parameters including material properties,
casing temperatures and mechanical efficiency of the
corresponding energy sources. In addition, there are
equipment maintenance schedules, mechanical
damage, HVAC and plant operation, real climate and
many other parameters to consider. All together, these
represent diverse sources for the uncertainty in the
model. However, this does not mean that the model
cannot fit the actual physical systems to an acceptable
degree, but it does lead to a basic requirement to point
out the sources of uncertainty.
The various sources of uncertainty in the model can
be classified as follows:
1. Specification uncertainty: this kind of uncertainty
refers to the physical errors that can arise from
incomplete or inaccurate specifications for the
complex physical model or process. It may also
involve excluding some physical equations or
properties, such as the geometry and material
properties of the CHP units, boiler and storage
system, and the fluctuating efficiency of the CHP
units which is taken as constant in the model.
2. Modelling uncertainty: this arises due to the
simplifications and assumptions about the complex
physical state. It may also involve the exclusion of
some energy systems due to their small effect on
the model compared to the effort that is required in
order to implement them in the model. An example
is the exclusion of the CHP casing temperature
which has an impact on total CHP efficiency.
Moreover, due to the fact that the simulation results
are discrete values while the real data are
continuous as shown in Figures 11, 12, 13 and 14,
this also has an impact on the creditability of the
model.
3. Operation uncertainty: this involves external
conditions that cannot be integrated into the model
constructed because they are unexpected. This is
mainly seen in case of damage or other unforeseen
effects on the energy conversion chain or system.
For instance, the mechanical damage that can occur
in the pump or turbocharger of each CHP unit is
always unexpected and cannot be predicted.

5

Conclusion

This paper presents the modeling process of heating
stations for DH system applications using
Modelica/Dymola to build a power-based model and
then validate it with real data from an existing heating
station (Weingarten). Validation results reveal that the

DOI
10.3384/ecp17132415

goodness-of-fit for the model is considered to be good
enough, which permits employing this model for
further research work to perform investigations for
operational optimization. Furthermore, in (Dahash,
2016), the model is tested for some operational
optimization methods and it shows good applicability
to be used for power-based optimization methods.
Also, it is worthwhile to clarify that this paper
(mainly validation results) does not confirm the
applicability of the model with the shown controllers
for any existing heating station. It simply reveals that
the representation of a specific heating station is held
to be good and then it states the sources of
uncertainties in the model. Moreover, in order to look
for other heating stations, their control strategies
should be implemented and adjusted accordingly in the
model.

Acknowledgements
This work is part of the project Weingarten 2020
Monitoring funded by the BMWi (Federal Ministry for
Economic Affairs and Energy, Project No.:
O3ET2364A). Our thanks go to the operator of
Weingarten heating station, Badenova WrmePlus, for
the cooperation in the project.
The model described in this article is built as a part of a
master thesis supervised by Prof. Dr-Ing. Peter
Treffinger and, therefore, the authors wish to thank him
for his continuous support.

Nomenclature
Symbol

 






2



Description
Coefficient of variation for
root mean square error
Conductance
Height of the storage tank
Thermal conductivity
Thickness of the insulation
Heat flow rate
Radius of the storage tank
Coefficient of determination
Surface area
Volume of the storage tank

Unit
[-]
[W/K]
[m]
[W/m.K]
[m]
[kW]
[m]
[-]
[m2]
[m3]

References
Bachmaier,A., Narmsara, S., Eggers, J. Bleicke and
Herkel, S., 2015. Spatial Distribution of Thermal
Energy Storage Systems in Urban Areas Connected to
District Heating for Grid Balancing. Energy Procedia,
Issue 73, pp. 3-11.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

423

A Power-Based Model of a Heating Station for District Heating (DH) System Applications

Balci, O., 1998. Verification, Validation, and Testing.
In: J. Banks, ed. Handbook of Simulation: Principles,
Methodology, Advances, Applications, and Practice.
New York: John Wiley & Sons, pp. 335-393.
Benonysson, A., Bhm, B. and Ravn, H.F., 1995.
Operational optimization in a district heating system.
Energy Conversion and Management, May, 36(5), pp.
297-314.
Braccoa, S., Denticib, G., and Sirib, S., 2013.
Economic and environmental optimization model for
the design and the operation of a combined heat and
power distributed generation system in an urban area.
Energy, Volume 55, pp. 1014-1024.
Dahash, A., 2016. A Comparative Study of Modeling
Approaches for District Heating Systems, Master
thesis, Offenburg-University of Applied Sciences,
Offenburg, Germany.
Dearling, C. and Erdman, W.,, 2006. Minimize the
Surface Area of a Cylinder . In: Principles of
Mathematics 9. 1st ed. Canada: McGraw-Hill, p. 640.

district heating systems: A review of modelling and
optimization. Solar Energy, 15 October, Volume 136,
pp. 49-64.
Reddy, T. A., Saman, N. F., Claridge, D. E., Haberl, J.
S., Turner, W. E. and Chalifoux, A. T., 1997.
Baselining Methodology for Facility-Level Monthly
Energy Use-Part 1: Theoretical Aspects.
Shipley, A., Hampson, A., Hedman, B., Garland, P.,
and Bautista, P., 2008. Combined Heat and Power,
Effective Energy Solutions for a Sustainable Future,
s.l.: Oak Ridge National Laboratory (ORNL).
Smit, R., 2006. Power Quality and Utilisation Guide,
s.l.: Copper Development Association.
Wetter, M., 2016. Modelica Library for Building
Energy
and
Control
Systems.
[Online]
Available
at:
https://simulationresearch.lbl.gov/modelica
[Accessed 14 August 2016].

Elci, M., Oliva, A., Herkel, S., Klein, K. and Ripka,
A.,, 2015. Grid-interactivity of a Solar Combined Heat
and Power District Heating System. Energy Procedia,
5 June, Volume 70, pp. 560-567.
Foschung fr die Energieeffiziente Stadt, 2016.
Projekt: Modellhafte Stadtquartierssanierung Freiburg
Weingarten-West.
[Online]
Available
at:
http://www.eneffstadt.info/de/pilotprojekte/projekt/details/modellhaftestadtquartierssanierung-freiburg-weingarten-west/
Jie, P., Neng, Z. and Deying L., 2015. Operation
optimization of existing district heating systems.
Applied Thermal Engineering, 6 January, Volume 78,
pp. 278-288.
Joelsson, A. and Gustavsson L., 2008. District heating
and energy efficiency in detached houses of differing
size. Applied Energy, May.pp. 126-134.
Kelly, S. and Pollitt, M., 2009. Making Combined Heat
and Power District Heating (CHP-DH) networks in the
United Kingdom economically viable: a comparative
approach, s.l.: University of Cambridge.
Nicola Terry, N., Palmer, J. and Cooper, I., 2012.
State-of-the-Art Review: Insulation and Thermal
Storage Materials, Cambridge, UK: Eclipse Research
Consultants.
Olsthoorn, D., Haghighat, F. and Mirzaei, P.A., 2016.
Integration of storage and renewable energy into
424

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132415

Model Based Design of a Split Carrier Wheel Suspension for
Light-weight Vehicles
Jakub Tobolr1
1 German

Daniel Baumgartner1

Yutaka Hirano2 Tilman Bnte1
Jonathan Brembeck1

Michael Fleps-Dezasse1

Aerospace Center (DLR), Institute of System Dynamics and Control, Wessling,
{Daniel.Baumgartner, Jakub.Tobolar}@DLR.de

2 Toyota

Motor Corporation, Future Project Division, Shizuoka, Japan,
Yutaka_Hirano@mail.toyota.co.jp

Abstract
Applying light-weight construction methods to the design
of future electric vehicles results in weight reduction of
both the vehicle body and the chassis. However, the potential for percental reduction of the sprung mass is larger
compared to that of the unsprung mass. Consequently, unfavorable consequences on the compromise, which always
needs to be found between road contact and road holding, can arise. This requires additional arrangements in
order to reach the performance of a state-of-the-art conventional vehicle. This paper presents a possible design
solution. The wheel carrier is split into two parts, thus
enabling to tune the frequency response correspondingly
to reference vehicles. Besides the technical solution the
Modelica modeling of the proposed suspension system as
well as a vehicle dynamics and ride comfort assessment
are presented.
Keywords: split wheel carrier, vehicle suspension, unsprung mass, small electric vehicle, three mass system

1

Introduction

Recently, to contribute to lower carbon dioxide emissions,
the development of light-weight electric vehicles (LEV)
has become more and more active in the automotive sector. These LEVs usually consume less energy in comparison to conventional vehicles. Though, because the sprung
mass of those vehicles tends to be reduced relatively more
than the unsprung mass of the suspension, the ratio of
sprung mass to unsprung mass is directed toward lower
values compared to those of conventional vehicles. This
means that the resonance frequency of the sprung mass becomes closer to the resonance frequency of the unsprung
mass which results in possible reduction of the ride comfort.
Furthermore, the resonance peaks associated with the
sprung mass and the unsprung one are shifted to higher
frequencies compared to those of conventional vehicles
because of reduced masses of both parts. These phenomena arises when the resonance frequency of the unsprung mass becomes close to the drive shaft twisting
DOI
10.3384/ecp17132425

mode. Thus, possibly a resonance excitation of the unsprung mass and the drive train can occur induced by adverse propelling torques.
To prevent abovementioned problems, it is necessary
to shift the resonance frequency of the unsprung mass to
lower / higher values and also to reduce the magnitude
peak of the vertical acceleration frequency response associated with the unsprung mass. However, as shortly discussed in the next section, it is theoretically proven that
the resonance frequency and the magnitude peak of the unsprung mass cannot be influenced by adjusting spring and
damper coefficients of the conventional suspension which
constitutes a two mass system of the unsprung mass and
the sprung one.
To solve this design conflict, the idea of a three mass
suspension system is introduced. In Section 2 of this paper, theoretical analysis of the effect of a three mass suspension is analyzed at first. A technical solution of the
mechanical structure of the three mass system is described
in Section 3. Actual effects of the three mass system are finally investigated by simulations using a Modelica model
(presented in Section 4) of the proposed suspension together with an advanced multi-body vehicle model in Section 5. Section 6 provides a conclusion of the investigations results.

2

Basic Idea of the Three Mass Suspension System

Figure 1 (left) shows a schematic quarter car of a conventional "two mass suspension system". Here, mb denotes
the mass of the sprung mass (representing a quarter of the
car body) and mw is the mass of the unsprung mass composed of the wheel and its carrier block. Figure 2 shows a
set of Bode magnitude plots from the acceleration of road
excitation to the sprung mass acceleration of this two mass
system. The parameter varied between the set of plots is
the suspension spring stiffness cbw in the upper chart and
damping dbw in the lower one. It can be concluded that
the resonance peak associated with the sprung mass mode
(second peak in the gain plot) can be changed neither by
varying the spring stiffness, nor by variation of the damp-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

425

Model Based Design of a Split Carrier Wheel Suspension for Light-weight Vehicles

cbw

dbw
mw
(wheel)

ct

dba

ma
(additional
mass)
caw

daw
mw
(wheel)

dt

ct

dt

Figure 1. Schematic quarter car models of a conventional two
mass suspension system (left) and of the three mass system
(right).

ing of the suspension. This corresponds to the fundamental investigations of invariance properties of a two mass
suspension system presented e.g. in (Hedrick and Butsuen, 1990) or (Savaresi et al., 2010), which emphasize
that the sprung mass acceleration near to the wheel resonance frequency is invariant regarding body spring stiffness cbw and body damping dbw . To overcome this fundamental restriction, the serial three mass suspension system as shown in Figure 1 (right) is introduced. In this
solution, the unsprung mass of the wheel carrier is divided
into two parts being insulated by an additional spring and
damping elements (caw and daw , respectively) from each
other. A detailed theoretical comparison of three mass systems with classical two mass systems highlighting the advantages of three mass systems is given in (Ryba, 1974a)
and (Ryba, 1974b).
Figure 3 shows a Bode magnitude plot comparison of
the two mass system with a set of plots for the three mass
system when changing the spring stiffness (caw ) of the additional spring element. Here, the spring stiffness of the
additional spring was set relative to the vertical tire stiffness ct using a factor k as
caw = k  ct .

(1)

It is shown by Figure 3 that by selecting a proper value
of the gain coefficient k such as k = 1.0, it is possible to
shift the frequency of the mode related to the unsprung
mass and also to reduce the magnitude of the resonance
peak. After this encouraging preliminary result it was decided to design a mechanic realization of such a three mass
suspension with split carrier which will be presented and
discussed in the following section.

3

Technical Solution

The possible technical solution of the three mass system
was developed assuming a small LEV with state-of-the-art
double wishbone front and rear suspensions.
426

vertical accel. magnitude

cba

vertical accel. magnitude

mb
(car body)

mb
(car body)

increasing stiffness cbw

increasing damping dbw
100

101
frequency f [Hz]

Figure 2. Bode magnitude plots from the acceleration of road
excitation to the sprung mass acceleration of the two mass suspension system with varying spring stiffness (above) and varying
damping (below).

The solution described below consists in splitting the
wheel carrier into two parts  the wheel hub and the carrier itself  guided and suspended to each other. Thus, the
lower part of the unsprung part (mw ) consists of a wheel,
a tire, a brake disc and a carrier which supports the wheel
hub bearing and the brake caliper. The upper part of the
split unsprung mass (ma ) incorporates parts connecting
suspension linkage mounts and the rest of the hub carrier. A mechanism to limit the relative motion between mw
and ma has also to be considered. An additional spring element (caw ) is assumed as a rubber bushing element or
combination of a bushing element and a supplementary
spring element.
Several technical solutions were examined to realize
abovementioned arrangement. Finally, the solution with
linear sliding mechanism, see Figure 4, was chosen. It
consists of two sealed linear sliding bearings (light grey
parts in Figure 4) connected firmly with the wheel hub
(purple) and guided through the supporting wheel carrier
structure (beige). This design resembles a mechanism
of a conventional telescopic fork as utilized for motorcycle front suspension; see (Stoffregen, 2012). The advantages are a simple, sealed and long-time proven design and
availability of standardized parts thus enabling relatively
cheap production and assembly. Moreover, such a design
offers high stiffness against external forces and torques.
Consequently, the wheel attitude changes under common

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132425

vertical accel. magnitude

Session 7A: Automotive III

increasing k
k = 0.25
k = 0.50
k = 0.75
k = 1.00
k = 2.00
100

101
frequency f [Hz]

Figure 3. Bode magnitude plots of the three mass suspension
system (using varying factor k according to equation (1)) compared to the conventional two mass suspension (marked with
dashed magenta line).
Figure 4. Technical solution of the split wheel carrier with sliding bearings in the context of a front right double wishbone suspension.

operating loads can be minimized, as proven by vehicle
dynamic tests, see Section 5.3. For the investigated LEV, 4 Modelica Model
this technical solution was applied for both the front and
To facilitate a simulative assessment the technical soluthe rear suspension, the latter being of the driven axle.
The wheel carrier support structure is depicted in more tion of the suspension presented in the previous section
detail in Figure 5. It consists of support tubes with inte- was modeled using Modelica. Using such a model, analgrated sliding bearings (part D in Figure 5, yellow) and a yses on a multi-body quarter car model were performed,
rubber sealing (part E, green/black/orange). The wheel see Sections 5.1 and 5.2. Additionally, the suspensions
hub (purple) together with the brakes caliper (not de- were used within a total vehicle model for vehicle dynampicted in Figure 5) is attached to immersion tubes in order ics and driving comfort assessment, as documented in Secto provide vertical deflection only between the parts of the tions 5.2 and 5.3.
In order to promote easy interoperability with the varwheel carrier.
ious existing automotive Modelica libraries, the created
The vertical motion of the split wheel carrier is sus- Modelica package containing all the models was conpended and damped by a rubber bushing element (part A sequently based upon the VehicleInterfaces base classes,
in Figure 5, dark grey) together with support coil springs see (Dempsey et al., 2006). The VehicleInterfaces library
(part C, red/orange) housed within one of the tubes (light focuses on standardizing the assemblies interface definigrey). The load springs are supported by threaded head tions without presupposing a standard vehicle model arcaps (part F, light red) for easy exchange and adjust- chitecture. Hence, the same assembly models can be
ment of the spring preload. A non-linear damping device reused in different model architectures.
(part B, pink) can be optionally installed in one of the imThe idea of template assembly models and
mersion tubes in order to improve the damping behavior parametrized models was introduced as also utilized
(if unsatisfactory) of the main bushing element.
in the PowerTrain library from DLR, see e.g. (Schweiger
Particular attention was given to the design of the sus- et al., 2005). Various parametrized models of realistic
pension elements  the coil spring and the rubber bush- assemblies are thus inherited from template models which
ing. To achieve consistent behavior of the suspension over reflect different structure and level of models detail. This
a wide range of excitation frequencies  stimulated e.g. facilitates redeclaration of the particular model within the
by road irregularities, the effect of the dynamic stiffen- overall vehicle models or virtual test rigs depending on
ing of the rubber has to be minimized, see e.g. (Mitschke the simulation purpose to be fulfilled.
The majority of virtual test rigs and maneuver scenarand Wallentowitz, 2014). The parallel arrangement of the
bushing and the springs enables shifting of the high por- ios as well as a couple of components and template models
tion of stiffness caw onto the coil spring, thus holding over needed to model and evaluate the suspension concept had
90 % of the total value. The remaining stiffness realized already been predefined within a DLR proprietary Modelby the bushing is then relatively low, additionally result- ica library for vehicle dynamics.
The multi-body models of a) the conventional two mass
ing in low damping daw and reasonably compromised dynamic stiffening.
reference suspension (see model structure depicted in FigDOI
10.3384/ecp17132425

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

427

Model Based Design of a Split Carrier Wheel Suspension for Light-weight Vehicles

jointUniversalToe

carrierBody
b

b

n=rSteer

fixA1toAX

wheelOrientation

bodyCaliper

a

fixToeRod

jointSteeringAxis

fixA1toSTR

fixA1toA3

armUpper

armLower

springDamper

6 directions
Linear

fixToeRodC

jointSphericalA3

f_nom

bushingToeRod

frameWheel
jointUniversalA1

frameChassis

Figure 6. Modelica structure of the conventional rear suspension.
Figure 5. Cross-section view of the front right wheel carrier and
components.
Table 1. Relevant masses of reference vehicle (2M) and of vehicle with proposed suspension solution (3M).

n=rSteer

b
a

jointSteeringAxis

wheelOrientation

bodyCaliper

frameWheel
jointSphericalA3

springDamper

armLower

6 directions
Linear

fixA1toA3

f_nom

jointUniversalA1

armUpper

frameChassis
bushing
body2

ure 6) and b) the proposed split wheel carrier design (its
structure is shown in Figure 7) incorporate all relevant
mass parameters as well as the nonlinearity of the force
elements. In both cases the models are parameterized
according to the considered small LEV. The particular
masses are listed in Table 1 for the conventional reference
vehicle in comparison with the vehicle with split wheel
carrier. A multi-body model of the latter is visualized in
Figure 8.
For elastic wishbone mounts, a simplification was
adopted in that the orthogonal deformations depend proportionally only on the corresponding action forces, thus


 
x
fx /cx
 y  =  fy /cy  ,
(2)
z
fz /cz

fixA1toAX

body1

872
189
23
11
175
23
15

fixToeRod

850
191
26
N.A.
178
29
N.A.

bushingToeRod

Total weight incl. driver of 75 kg
Front sprung mass mb
Front unsprung mass mw
Front add. unsprung mass ma
Rear sprung mass mb
Rear unsprung mass mw
Rear add. unsprung mass ma

fixA1toSTR

fixToeRodC

Parameter

Value [kg]
2M
3M

twoMassLinear

jointUniversalToe

fixJointA

fixJointB
a

b
n={0,0,1}

frame_a

frame_b

jointPrismaticZ

fixSpringA

fixSpringB

springDamper
visCylinderToA

visCylinderToB

carrierCAD

CAD

and, correspondingly, for rotations. Such a mounting was
additionally used to connect the toe control link of the rear Figure 7. Modelica structure of the split wheel carrier rear sussuspension. For simplicity, the main bushing mounted be- pension (above) and the split carrier submodel (below).
tween the wheel hub and the wheel carrier was modelled
428

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132425

vertical accel. magnitude

Session 7A: Automotive III

reference
proposed suspension
100

Figure 8. Visualization of the multi-body model of presented
front suspension with split wheel carrier.

on the same principle. This is reasonable for low dynamic
stiffening as explained in the previous section.
The vehicle body was modeled as a rigid structure with
an extra mass of 75 kg at the location of a drivers hip joint.
A linear spring-damper element was used to represent the
vertical force/deflection of the tire. Additionally, the horizontal tire forces were modeled using the Pacejka Magic
Formula (Pacejka, 2002) to assess the vehicle dynamics
behavior.
In the following, the model of the vehicle of the two
mass configuration and parametrization (2M in Table 1) is
called reference vehicle or simply reference.

5

Simulation Results

For the proposed split wheel carrier suspension the ride
comfort and tire/road contact were assessed simulating
both the quarter car and the full vehicle model. Additionally, vehicle dynamics were evaluated utilizing the full
vehicle model only.

5.1

Verification of the Technical Solution

For the first verification of the eligibility of the technical design, the frequency response analysis according
to (Bnte, 2011) was performed on the nonlinear quarter car multi-body models with a) the reference suspension and b) the proposed one. The vertical excitation
from 0.5 Hz to 30 Hz was considered, together with the
frequency-dependent decrease of the amplitude in order to
reproduce the amplitude progression of the road class D
from (ISO 8608). Thus, the time excitation conditions
were similar to those applied for linear system analysis
depicted in Figures 2 and 3.
The comparison of time domain simulation results is
done in Figure 9. The multi-body models prove the reduction of the second resonance peak by the three-mass system up to frequencies about 20 Hz. Above this frequency,
the third resonance peak of the proposed suspension becomes significant which increases the response amplitude
DOI
10.3384/ecp17132425

101

Figure 9. Frequency response of nonlinear quarter-car multibody models.

compared to the reference vehicle. In summary, this proof
of concept confirmed the preliminary assessment as discussed in Section 2.

5.2

Comfort Assessment

For ride comfort and tire/road contact assessment, a time
domain simulation of the vehicle placed on a virtual four
post rig was performed. The post excitation conforms to
the road class D according to (ISO 8608) driven at constant velocity of 70 km/h. The road irregularities are generated by means of a colored noise signal matching a given
power spectral density (PSD). For the generation of such a
signal in Modelica, the AdvancedNoise library (Klckner
et al., 2015) was utilized
For the full vehicle model, the vertical excitation signals
for the left and right track were generated independent of
each other, i.e. using uncorrelated signals. The excitation
signals for the rear wheels were delayed by the ratio of
wheel base and speed against the respective front wheels
running ahead. The excitation signal together with its PSD
are shown in Figure 10.
The generation of the excitation using a noise generator from the AdvancedNoise library has the advantage of a high quality stochastic signal. In contrast, this
way of signal generation is computationally expensive and
slows down simulation speed. Using DASSL as numerical
solver on a quad-core personal computer the full vehicle
simulation on average runs 50 times slower than real time.
Therefore, we restricted the simulation time for the full
vehicle simulation to 100 s which corresponds to a track
length of 1944 m. For the less expensive quarter car simulations, the simulation time of 200 s was applied in order
to reach a more significant assessment.
The evaluation with the quarter car model used the following criteria:

 RMS f z : root mean square of vertical tire load,
 RMSaz : root mean square of body vertical acceleration,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

429

Model Based Design of a Split Carrier Wheel Suspension for Light-weight Vehicles

102
ISO 8608 road class D

2
position z [m]

Table 2. Resulting comfort assessment criteria values for quarter
car simulations with a simulation time of 200 s.

1

Criteria

Unit

Reference

Proposed
suspension

Difference
[%]

0

RMS f z
RMSaz
Kges1
Kges2

N
m/s2



112.50
0.47
9.13
8.59

93.30
0.43
8.50
7.97

-17.07
-7.89
-6.96
-7.24

1
2

50

100
time [s]

200

150

Table 3. Resulting comfort assessment criteria values for full
vehicle simulations with a simulation time of 100 s.

 
PSDz m3

104

107

1010

1013
101

100

101
frequency [1/m]

Unit

Reference

Proposed
suspension

Difference
[%]

RMS f z
RMSaz
RMS pitch
RMSroll
Kges1
Kges2

N
m/s2
rad/s2
rad/s2



702.9
1.450
2.005
4.707
32.670
34.260

433.2
0.963
1.430
3.462
24.412
26.135

-38.37
-33.59
-28.68
-26.45
-25.28
-23.72

102

Figure 10. Exemplary road excitation signal used for vertical
displacement of virtual post rig (above) and its power spectral
density (PSD, below).

 Kges1 combined assessment criterion according
to (Hennecke, 1995) for the time window of 10 s and
 Kges2 similar to Kges1 but for the total time of measurement.
For the full vehicle model, the following criteria were
additionally evaluated:

 RMS pitch : root mean square of body pitch angular
acceleration,
 RMSroll : root mean square of body roll angular acceleration.
The collectivity of criteria evaluated by simulations is
shown in Table 2 and Table 3.
Supplementary to these concluding values, Figure 11
depicts the signals of the combined comfort assessment
criteria Kges1 and Kges2 from simulations on the virtual
quarter car test rig. These criteria show the improvement
for the proposed suspension (plotted in red) against the
reference vehicle (blue). For tire/road contact, the improvement of about 17 % is reached  as indicated by
RMS f z in Table 2. This trend is even more evident for
the full vehicle simulation, see Table 3. Here, the comfort
improvement is about 25 % and the road contact improvement is up to about 38 %. These results are achieved by
430

Criteria

virtue of the proposed split wheel carrier system while using a preliminary parametrization.

5.3

Vehicle Dynamics Assessment

To achieve an evaluation of the proposed suspension concept also in terms of vehicle dynamics, two standard driving maneuvers were simulated: a) quasi steady state cornering on a circle with a radius of 40 m while slowly
increasing the vehicle speed and b) steering angle sine
sweep at a constant speed of 80 km/h. For a) the necessary steering wheel angle H to keep the vehicle on the
circle was recorded and the resulting self-steering gradient
SSG was computed. During b) the magnitude ay,gain and
phase angle ay,phase of the lateral acceleration frequency
response were recorded and assessed.
The evaluation of the recorded criteria of both vehicles indicated just negligible difference for both maneuvers, i.e. the suggested technical solution of the proposed
suspension has negligible influence on the lateral vehicle
dynamics. This is particularly reached due to the sufficient stiffness of the mechanism when exposed to lateral
and longitudinal forces and torques. Consequently, only
marginal changes in the wheel attitude can be observed in
most cases, as demonstrated in some extent in Figure 12
for a toe angle change under lateral force load, and in Figure 13 for a track change under variable vertical load. Both
Figures result from the suspension elastokinematics analysis.
Concluding from the two simulated maneuvers, the vehicle equipped with the proposed suspension appears to
have also a good driving behavior.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132425

Session 7A: Automotive III

0.2

6
4
reference
proposed suspension

2

toe angle v [ ]

Kges1 []

8

0

reference
proposed suspension

0.2

0

2000

8

1000

0

1000

2000

Figure 12. Change of the wheel toe angle of rear suspension
under lateral load.

4
2
0

reference
proposed suspension
50

100
time [s]

150

Figure 11. Comfort assessment criteria signals from quarter car
simulations: Kges1 for time window of 10 s above and Kges1 for
the total simulation time (200 s) below.

track dyW [mm]

Kges2 []

lateral force fy [N]
6

0

10

6

Conclusions

2000

A suspension design solution was proposed to compensate
for unfavorable effects on ride comfort and tire/road contact in the context of light-weight electric vehicles. The
suggested mechanical design introduces the separation of
the wheel hub from the wheel carrier allowing for a vertical relative movement between both parts by means of a
prismatic joint. The realization utilizes two linear sliding
bearings which house the auxiliary suspension elements 
a design resembling a motorcycle front fork.
A comprehensive investigation on the influence of such
suspension design on the ride comfort and tire/road contact was done. Simulation results show that the ride comfort can be improved significantly while there is negligible
influence on the vehicle dynamics. The relative deflection
in the prismatic joint introduced into the split wheel carrier is bounded to a few millimeters when the system is
operated under common driving conditions.

reference
proposed suspension
1000

0

1000

2000

vertical force d fz [N]
Figure 13. Change of the wheel track of rear suspension under
vertical load change.

elica Conference, Dresden, Germany, 2011. URL http:
//elib.dlr.de/68920/.
M. Dempsey, M. Gfvert, P. Harman, Ch. Kral, M. Otter, and
Treffinger P. Coordinated automotive libraries for vehicle
system modelling. In The 5th International Modelica Conference, Vienna, Austria, 2006.
J. K. Hedrick and T. Butsuen. Invariant properties of automotive
suspensions. Journal of Automobile Engineering, pages 21
27, 1990.
D. Hennecke. On the Assessment of the Riding Comfort of
Passenger Cars under Transient Excitation. PhD thesis, TU
Braunschweig, Dsseldorf: VDI Verlag, 1995. In German.

Acknowledgements

The authors would like to thank Mr. Uwe Bleck for sharing his expertise on vehicle suspensions and vehicle dy- ISO 8608. Mechanical vibration  road surface profiles  reporting of measured data, 1995.
namics.

References
T. Bnte. Recording of model frequency responses and describing functions in modelica. In The 8th International Mod-

DOI
10.3384/ecp17132425

A. Klckner, A. Knoblach, and A. Heckmann. How to shape
noise spectra for continuous system simulation. In The
11th International Modelica Conference, pages 411418,
Paris, France, 2015. Linkping University Electronic Press,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

431

Model Based Design of a Split Carrier Wheel Suspension for Light-weight Vehicles

Linkpings Universitet. URL http://elib.dlr.de/
98408/.
M. Mitschke and H. Wallentowitz. Dynamics of Motor Vehicles.
Springer Vieweg, 5 edition, 2014. ISBN 978-3-658-05068-9.
In German.
H. B. Pacejka. Tyre and Vehicle Dynamics. Elsevier Ltd, Oxford,
2002.
D. Ryba. Improvements in dynamic characteristics of automobile suspension systems part 1: Two-mass systems. Vehicle
System Dynamics, pages 1746, 1974a.
D. Ryba. Improvements in dynamic characteristics of automobile suspension systems part 2: Three-mass systems. Vehicle
System Dynamics, pages 5598, 1974b.
S. M. Savaresi, C. Poussot-Vassal, C. Spelta, O. Sename, and
L. Dugard. Semi-active suspension control design for vehicles. Butterworth-Heinemann/Elsevier, 2010.
Ch. Schweiger, M. Dempsey, and M. Otter. The PowerTrain Library: New Concepts and New Fields of Application. In The
4th International Modelica Conference, HamburgHarburg,
Germany, 2005.
J. Stoffregen. Motorcycle technology. Springer Vieweg, 2012.
ISBN 978-3-8348-1716-7. In German, DOI 10.1007/978-38348-2180-5.

432

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132425

Development of hierarchical commercial vehicle model for
target cascading suspension design process
Kwang-chan Ko1

Jong-chan Park1
Min-su Hyun3

Dae-oh Kang2

Jae-hun Jo3

Seung-jin Heo3

1

Hyundai Motor corporation, Korea, {kcko, impactpack}@hyundai.com
2
Institute of Vehicle Engineering, Korea, bigfive@ivh.com
3
School of Automotive Engineering, Kookmin University, Korea, {bluenice8,slay,sjheo}@kookmin.ac.kr

Abstract
This paper presents the development of
framework and an industrial application of
commercial vehicle suspension & steering system
design based on the target cascading. This
framework consists of 3 main modules, those are
modeling, solving, and post-process module. Excel
GUI is employed in order to give straightforward
simulation way to the end users who are not
familiar with vehicle dynamics simulation. End
users are allowed to handle modeling parameters
using Excel to build up models in the easy way.
Key feature of solving module is that the
simulation is conducted automatically with just
selecting one of predefined scenario. The last
module whose object is to calculate Ride and
Handling performance index, is the post-process
module.
A pilot study is applied to the practical issue to
see the benefits of the framework, and design
decision is made from the application results. This
application study shows remarkable benefits not
just in terms of Ride and Handling performance,
but also in terms of solving cost. 15% of improved
performance is produced regarding Ride and
Handling, and 50% of development time is saved.
It means that the framework allow to avoid timeconsuming process to achieve required target in
the vehicle development process.
Keywords: Vehicle Dynamics, Target Cascadin
g, Commercial Vehicle, Hierarchical Model,
Suspension and Steering, Ride and Handling

1. Introduction
The framework development is explained from
section 2 to section 4. Section 2 contains the way
of modeling and testing on the main sub-systems,
and section 3 covers performance index calculator.

DOI
10.3384/ecp17132433

Figure 1. Overview of Frame Work

Section 4 is about the Excel interface development
in order to give convenience to the end user. The
optimization study is conducted to figure out the
benefits of the developed framework in the section
5.

2. Library Establishment of Vehicle
Dynamics
The main sub-systems of vehicle dynamics library
consist of suspension, body, cab, and tire. For
application to the target cascading process, each
sub-system consists of geometrical and physical
model.

2.1 Suspension and Steering system
2.1.1 Suspension Modeling

Full range of HMC commercial vehicle
suspension types are modeled by using both
Tubular Elastic Kinematic Suspension (TEKS)
and Multi body Dynamics. TEKS use lookup table
to specify suspension geometry, so TEKS model
has to reflect the unique issue about commercial
vehicle suspension. For instance, commercial
vehicles have the suspension models of dependent
type and independent type, the big difference
between those suspension types is the roll motion.
Generally in case of dependent suspension, left
and the right movement is coupled in roll motion
but the other is not.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

433

Development of hierarchal commercial vehicle model for target cascading suspension design process

The number of suspension types using in
commercial vehicles are quite large, for efficient
approach, object-oriented methodology is taken
into the Multi body dynamic modeling. Figure 2.1
shows the modeling results.

Figure 2.2. Leaf Spring Model (Modelica)
Figure 2.1 Multi Body Dynamic model

Force element of physical model was modeled
from the functional equation that has the design
variables as its factors. The parts developed by the
method above are leaf spring, coil spring, air
spring, stabilizer bar, etc. Table 2.1 show some
examples of force elements.
Table 2.1 Leaf Spring Model

2.1.2 Steering Modeling
Once steering system is modeled. Rack&Pinion

steering is modeled for the independent suspension
and Pitman-Arm steering is modeled for the
dependent suspension.
Table 2.2 Rack&Pinion, Pitman Arm Model

Leaf Spring




=
 + _
 =

Design
equation

_ =   

parameter

  modulus elasticity
  number of leaf
  Leaf Width
  Leaf thickness
  Defection Factor
  Leaf length
_  Modified number

We generate code of these functional equations in
Modelica language like Figure 2.2.

434

2.1.3 Validation

Suspension models are validated by K&C
experiment. Figure 2.3 show the comparison
results of the established suspension system
models of independent type and dependent type
with the test data. From the comparison, we reach
the conclusion that the established models have
reliability.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132433

Session 7A: Automotive III

Figure 2.4. Pacejka 02 tire model

3. Post Processor
3.1 Performance Index of R&H
Figure 2.3. Parallel wheel travel

2.2 Cab, Frame & body Model
3 types of Cabin mounting are used by HMC
commercial vehicles are built up in the library as
shown in table 2.3

The higher priority way to set up quantified R&H
performance Index is from analysing statistical
relationship between subjective feeling evaluation
and objective measurement data, but a lot more
valid sample data are demanded for the statistical
relationship analysis. Realistically it is not easy to
collect enough valid sample data due to many
reasons. Instead of those preliminary researches, 3
benchmarking vehicles are chosen and measured
to set up R&H performance indexes in this stage.

Table 2.3 Cab Mounting library

(1) Test / simulation modes, measurement methods
are established after 3 benchmarking vehicles are
chosen with considering weight, wheelbase, and
steering, suspension type. The specifications of 3
benchmarking vehicles are shown in Table 3.1.
Table 3.1 Specification of Benchmarking Vehicles

Lumped mass, C.G location, and moment of
inertia are main input parameters in case of body
model, but realistically bending and torsion can
occur due to the long length of frame in the
commercial vehicles, so bending stiffness and
torsion stiffness to the lumped mass model are
reflected.

2.3. Tire model
Pacejka 02 Tire are employed for tire library. In
order to create reliable tire model, all the
parameter that required for the Pacejka 02 are
measured. Figure 2.4 is the description about one
of the tire data.

DOI
10.3384/ecp17132433

On-Centre Weave, Steady-State Cornering, Step
Steer, Pulling Stability, Bumpy Ride are selected
for test modes. Generally too many test /
simulation modes cause a lot of solving cost in the
optimization process, so test / simulation modes
must be minimized.
(2) The 31 quantified indexes for R&H
performance indexes are calculated using
measurement data of benchmarking vehicles.
Understeer gradient which decide cornering
stability and Steering R2 value which decide
cornering linearity are shown in Fig. 1 as examples

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

435

Development of hierarchal commercial vehicle model for target cascading suspension design process

Table 3.2 Description of 24 Indexes

of graphic calculation.

Figure 3.1. Steady-State Cornering Test

(3) The 31 quantified indexes are divided into 9
groups for mapping which represent subjective
feeling. Those 9 groups consist of 3 controllability
fields (Roll Control, Response Level, Cornering
Controllability), 3 Stability fields (Understeer
Balance, Response Velocity, Directional Stability),
and 2 Steering Feel fields (Steering Sensitivity,
Pulling), 1 Ride Comfort field (Bumpy Ride). Fig.
3.2 is example of the mapping results regarding
Stability fields.

3.2 Post-Processor
To automate the performance index developed at
3.1, post-processor was developed by using
Matlab. The data used for the inputs in postprocessor comes from Dymola as mat-file form.
Figure 3.4 is GUI of the post-processor.

Figure 3.4. Performance index calculation program
Figure 3.2. Stability Feeling Matching Map

(4) 31 indexes are taken into design of experiment
(D.O.E) Screening to figure out the relationship
between individual indexes of those 31. Finally
24 indexes are selected after D.O.E Screening
except 7 indexes which have repeated performance
meaning by other indexes. The screening results
are shown in Fig 3.3.

4. Modeling tool based on Excel.
Pre-processing GUI is built based on Excel to
give end users convenience. Like Figure 4.1, preprocessing is performed by inputting the model
data first, and goes through the process that links
the cells data inputted with the parameters on
Modelica.
Data Import

Data Linking

Cabin Property

Load Mass

Frame

Figure 3.3. D.O.E Correlation of VPI

436

Figure 4.1. Parameter linking based on Excel

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132433

Session 7A: Automotive III

Linking on Excel and Modelica parameters was
processed by using the external data library which
is one out of Modelica share libraries. Excel GUI
is divided The constituted GUI is shown on Figure
4.2.

5.1.2 Explanation on the evaluation method.
ISO C-Class road profile is used for the input of
four-post test, and selected the vertical
acceleration of body as performance index.
5.1.3 Comparison analysis of the results
As shown at Figure 5.3, the test results showed
little error (RMS error: - %) in time domain.
.

Figure 4.2. Excel GUI

5. Application
To review the validity of the simulation framework
that was developed earlier, ride and handling
performance simulation was conducted.

5.1 Ride performance test
5.1.1 Model explanation

Four-post test for the ride evaluation method are
simulated, so the mulit body dynamics truck
model waw combined with four-post test rig, and
formed them as the test environment. The
constituted truck chassis model was shown on
Figure 5.1, and the four-post test environment was
indicated on Figure 5.2.

Figure 5.3. Four-Post Test Result Vertical
Acceleration

Likewise, the gradient of PSD in frequency
domain of Figure 5.4 was ilustraed with high
accuracy as well.

Figure 5.1. Truck Chassis Model
Figure 5.4. PSD

5.2 Handling performance test
5.2.1 Model explanation

Figure 5.2. Four-Post Test Environment

DOI
10.3384/ecp17132433

CRC (Constant Radius Cornering) and step-steer
maneuvers were taken into simulation to evaluate
not just steady state condition but also transient
condition response. The truck chassis model that
used in ride test is linked with the steering

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

437

Development of hierarchal commercial vehicle model for target cascading suspension design process

controller which controls the vehicle to drive in a
steady curvature, and the velocity controller which
controls to drive as the speed allowed. The stepsteer test environment was established through
combination of the steering actuator that controls
to steer towards the allowed steering wheel angle
and the velocity controller which controls to drive
in steady speed shown as Figure 5.6.
.

Figure 5.5. Step Steer Test Environment
5.2.2 Comparison analysis of the results

Figure 5.6 showed the gradient of steering wheel
angle-lateral acceleration of CRC, and it proves
that this model predicts the steady state condition
response of the truck in high accuracy. The
performance index was estimated with little error
as well.

Figure 5.7. Lateral Acceleration, Yawrate

5.3. Application of Target Cascading
Design
5.3.1 Formulation of design matters

For the application examples, RMS of body
vertical acceleration, which is the ride
performance index as the objective functions, is
chosen, together with the parameters of air spring
as the design variables. The matter was defined to
find the design variable value to minimize the
objective functions.
5.3.2 System level design

Figure 5.6. Understeer Gradient

Figure 5.7 showed the gradient of lateral
acceleration of step-steer and yaw rate, and it
proves that this model predicts the transient
condition response in high accuracy. The
performance index selected earlier was calculated
with little error as well.

438

In system level, RMS of body vertical acceleration
is extracted, and air spring property (F-D gradient)
can be optimized through genetic algorithm in
Optimization Library of Modelon. Genetic
algorithm is a probability search algorithm, and it
is favorable to the treatment for discrete variables,
not influenced from the continuity and
differentiability of functions, etc. which consist of
the matters, and able to search globally. The
formulation of design matters is the same as
follows.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132433

Session 7A: Automotive III

1 +2 +3 ++

Minimize () = 



,

 ( = 1: ) = Body vertical acceleration,

from system-level through genetic algorithm is
selected. The formulation of the optimized design
is the same as follows.
2

 = Number of data.

Minimize () = =1(,  , ) ,

Subject to 0.8 <  < 1.2

, = System-level air spring data,

, = Air spring characteristic data of base
model

, = Subsystem-level air spring data,
 = Number of data
Subject to 0.8   <  < 1.2  

Figure 5.8 shows the change of performance
index, and Figure 5.9 indicates the property of the
optimized design variables.

Base

,  = Air spring parameters of base model
Figure 5.10 shows the comparison results between
the property of air spring realized through the
optimal parameters and the property of air spring
derived from system-level, and we can see that the
property value is embodied with little error.

RMS (/ 2 )
1.8410
1.4912

Optimized

Figure 5.8. Performance Index Variation

Figure 5.10. Comparison of Air Spring Property

Table 5.3 is one that compares the design variables
of base model and the design variable values of the
optimal model.
Table 5.1 Comparison of Air Spring Property

Figure 5.9. Optimization
5.3.3 Sub-system level design

In sub-system level, optimal value of parameters
that can embody the optimized air spring derived
DOI
10.3384/ecp17132433

Nominal Preload
Force
Polytropic
Coefficient
Effective
Area
with Respect to
Volume
Effective
Area
with Respect to
Load
Constant Pressure
Spring Rate

Base

Optimal

20000 N

20000N

1.38

1.317

0.077m^3

0.09343m^3

0.07315m^3

0.0555m^3

1000000N/m

1000000N/m

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

439

Development of hierarchal commercial vehicle model for target cascading suspension design process

6. Result
Through this study, we developed the
interpretation of hierarchical structure and the
design model through object-oriented modeling
method. The merits of constituted hierarchical
structure model are as follows. Firstly, both
behavior model and physical model can be
interpreted at one platform. Secondly, design
objectives and design variables that are
indispensable for target cascading can be shared
without separate treatment of data. Thirdly, it is
easy for users, if necessary, to modify the model
since the model has been established through
object-oriented modeling method. And, to enhance
design efficiency, we raised efficiency by
developing design process through linking with
pre-processor (Excel), model (Dymola), postprocessor (matlab). To test the effectiveness on
this, we applied the established framework to the
suspension system design matters that were
considered to improve the performance of R&H.
From the result of design, we verified that
performance improved by 15%, and the time for
design decreased more than 50% as well. These
results proved that the developed framework is
suitable for the suspension system design process
of target cascading.

Reference
Kang, Ph.D: Robust Design Optimization Process Deve
lopment for Suspension System by using Target Casca
ding Method, Kookmin University, 2010.
J. Rauh: Virtual Development of Ride and Handling Ch
aracteristics for Advanced Passenger Cars, J. Rauh, Vehi
cle System Dynamics, vol. 40, no. 1-3, pp. 135-155,
2003.

440

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132433

Model Based Analysis of Shimmy in a Racing Bicycle
Nicol Tomiati1
1 Politecnico

Gianantonio Magnani1

Bruno Scaglioni1

Gianni Ferretti1

Di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria DEIB
Via Ponzio 34/5, 20133 Milano, Italy,

{gianantonio.magnani,bruno.scaglioni,gianni.ferretti}@polimi.it,
nicola.tomiati@mail.polimi.it

Abstract
In this paper we are presenting a model of a racing bicycle,
developed in Modelica language within the Dymola environment. The main purpose is to investigate the dynamic
response of the bicycle and its modes of vibration, referring in particular to shimmy. This phenomenon occurs at
high speeds and consists of sudden oscillations of the front
assembly around the steering axis. Lateral accelerations
on the horizontal tube of the frame can reach 5-10 g with
a frequency that varies between 5-10 Hz. Even if it is
quite uncommon, shimmy is a topic of great relevance, because it may be extremely dangerous for the rider. Thanks
to this model, we can show that the main elements which
contribute to the rise of the oscillations are the lateral compliance of the frame and the tyres deformation.
Keywords: bicycle, shimmy, flexible multibody systems

1 Introduction
This paper will present a multibody model of a racing bicycle developed in Modelica, within the Dymola environment. The main purpose of this work is to investigate in
depth the dynamic response of the bicycle and its modes,
referring in particular to shimmy.
Any two-wheeled vehicle is subject, during its movement, to three modes of vibration: capsize, weave and
wobble. The first two are always present; the third one
occurs occasionally.
If the capsize mode is unstable, the bicycle follows a
spiral path with increasing values of the roll angle that
leads it to a lateral fall.
The weave mode consists, instead, in an oscillatory motion of the rear frame about the yaw axis together with oscillations about the roll axis. In this case, the frequency is
of 1-2 Hz.
Finally, the wobble mode (which is often referred to
as shimmy) is an oscillatory motion of the front assembly with respect to the steering axis. When it occurs, lateral accelerations on the horizontal tube of the frame can
reach 5-10 g with a frequency that varies between 5-10 Hz
(Magnani, Ceriani, and Papadopoulos 2013). This phenomenon is therefore very violent, unexpected and can
lead to dramatic consequences, particularly if the rider
does not know it and is not able to handle it. Fortunately,
it does not occur so frequently and it is difficult that it can
DOI
10.3384/ecp17132441

lead to a fall, although this is the sensation perceived by
the cyclist. Usually, this happens at high speed, such as
the one that can be reached along a downhill road. The
phenomenon is well known among cyclists and bicycle
manufacturers. It is a topic of great relevance because it is
not still clear what are the main causes that lead to these
vibrations.
Thanks to experimental activities (Magnani, Ceriani,
and Papadopoulos 2013) and by using numerical models (Plchl et al. 2012; Klinger et al. 2014; Limebeer and
Sharp 2006), the lateral compliance of the frame and the
tyres deformation have been found to be two essential
contributors to the wobble mode. One of the goals of this
article is to understand in detail what are the causes or factors that excite these vibrations, referring in particular to a
racing bicycle.
The paper is organised as follows. Section 2 gives an
overview of the overall bicycle model, describing all the
components in detail. Section 3 explains how the elements
are connected to each other and what assumptions have
been made before running the simulations. In Section 4
simulation results are presented. Two different versions of
the model will be analysed. At the end, in Section 5 the
conclusions and some possible practical advice that may
be helpful to the rider to damp out the shimmy oscillations
are discussed.

2 Bicycle Model
The multibody model presented in this work is
based (for some components) on the Modelica
MotorcycleDynamics package, which is described
in detail in (Donida, Ferretti, Savaresi, Schiavo, et al.
2006; Donida, Ferretti, Savaresi, and Tanelli 2008). This
library, in turn, was developed by VehicleDynamics,
which shares basically the same structure (Andreasson
2003).
The following step is to run simulations to study its dynamic behaviour. Our attention has been focused on a racing bicycle, which is described in more detail in (Klinger
et al. 2014). Whenever possible, therefore, data reported
in that article has been used in order to make the model as
compliant as possible to the real behaviour.
The main components of the model are:

 the rear frame;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

441

Model Based Analysis of Shimmy in a Racing Bicycle

!
Figure 1. Rider block diagram in Dymola with the four interfaces to connect it to the other components. Four spring-damper
elements have been introduced to model the compliance of the constraints between riders hands-handlebar, feet-pedals and pelvissaddle.

 the front assembly, which includes handlebar, stem the front wheel at the hub, and with the cyclist at the two
and fork;
contact points on the handlebar.
 the cyclist;

2.3 Cyclist

 the front and rear wheels;

The third component of the model is the rider. It has
been modelled as a multibody system obtained by the
connection of solid geometric elements having different
shapes. In particular, Cylindrical elements have been
used to model limbs (i.e. arms, forearms, thighs and
legs) while Rectangular parallelepipeds for the torso, the
pelvis, hands and feet. In regards to the head, a Body element has been chosen, which is characterised by mass and
inertia tensor. It is visualised by a cylinder and by a sphere
that has its centre at the centre of mass.
To model the human articulations two types of joints
have been used, chosen depending on the possible relative
movements between the parts connected. Spherical joints
prevent all the translations but enable the rotations about
three mutually orthogonal axes. On the other hand, Revolute joints prevent all the translations and the rotations
about two axes. Therefore, they leave only one degree of
freedom (a rotation about an axis). It is important to notice
that a Spherical joint can be obtained by connecting to one
another three Revolute joints, specifying for these objects
three orthogonally axes of rotation (as has been done with
the elbows).
To make the model more realistic, elements made up of
a spring and a damper in parallel have been added: in this
way it is also possible to take into account the contribution of stiffness and damping of human muscles. Figure 1
shows the rider block diagram in Dymola. Four interfaces

 the road.

2.1 Rear Frame
The first component is modelled by a BodyShape element,
i.e. a single rigid body characterised by centre frame, mass
and inertia tensor. In order to associate to this body the
true shape of the frame, we have used a CAD model. Secondly, we have added the saddle, which is connected to
the rear frame with a Revolute joint. This type of connection allows the rotations around an axis passing through
the saddle tube. In this way, it is possible to consider the
compliance of the constraint between the saddle and the
frame.
The rear frame model presents four interfaces that allow
connecting this component with the rider (including the
saddle and pedals), with the front assembly (through the
steering axis) and with the rear wheel (at the hub).

2.2 Front Assembly
The front assembly has also been modelled as a rigid body
with its inertia tensor and whose mass is concentrated in a
single point. It consists of the fork, whose true shape has
been defined in a CAD model, the stem and the handlebar.
Four interfaces characterise this component; in fact, the
front assembly can be connected with the rear frame, with
442

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132441

Session 7A: Automotive III

Figure 2. Tyre definitions: side-slip angle  is defined as the
angle between the wheel centre plane and the direction of the
forward velocity V . Camber angle  is defined as the angle between the wheel centre plane and the vertical axis z of the road.
Fx is the longitudinal force, Fy is the lateral force and Fz is the
normal force. Mx is the overturning torque and Mz is the aligning
torque. Positive values are shown. The left figure is a top view
while the right one is a rear view.

have been included in the model. In so doing, the rider
can be connected to the front assembly and to the rear
frame. Two spring-damper elements have been added to
cyclists hands and the upper part of the front assembly to
model his grip on the handlebar. The same has been done
for the connection between riders feet and bicycle pedals.
Lastly, a spring-damper element has also been added between the cyclists pelvis and the saddle in order to model
the compliance of the sitting position (the rider, in fact, is
not rigidly attached to the saddle).
In order to verify that the behaviour of the model was
compatible with a riders real movements, different simulations have been performed (for example, by simulating
a turning manoeuvre or the execution of a curved trajectory).

2.4 Wheel Model

Figure 3. Qualitative trend of the lateral force Fy and aligning
torque Mz as a function of the side-slip  and camber  angles.

the sign convention adopted in this work.
As can be seen,  is the side-slip angle, which is defined
as the angle between the forward velocity V and the wheel
centre plane;  is instead the camber angle, defined as the
angle between the vertical axis z of the road and the wheel
centre plane.
The following step is the determination of contact
forces and torques. As stated in (Pacejka 2006), there are
different relations between forces and angles. For our purposes, a linear relation has been chosen to describe tyres
behaviour. Moreover, the model has taken into account the
tyres dynamic, i.e. the delay in the deformation due to the
elasticity properties of the material. The tyre, in fact, does
not respond immediately when it is rolled from the standstill under a slip angle. It is necessary some time before
the lateral force Fy approaches the stationary value. The
same is true for the aligning torque Mz .
The longitudinal force Fx , which can represent both
traction and braking forces, is defined as:

Wheels are modelled as rigid bodies with their mass conFx = CF   ,
(1)
centrated in the hub. Afterwards, a torus model has been
used to associate the real tyre shape to the wheel. The where  is the longitudinal wheel slip.
front and rear wheels have the same dimensions (i.e. the
On the other hand, the lateral force Fy is the sum of two
same radius), but different mass and inertial properties.
terms:
(2)
Fy = CF    +CF    .
2.5 Tyres and Wheel-Road Interaction
As already mentioned in the Introduction, to highlight the
wobble mode it is necessary to consider tyres deformation.
The tyre allows the contact between the rigid part of the
wheel (i.e. the hub) and the road surface. At the same
time, it ensures adherence to the asphalt and generates
distributed forces and torques within the contact region.
In the following, it will be assumed that these forces and
torques are instead concentrated and applied at the single contact point that represents the interaction between
wheel and road surface. In order to compute these forces,
four reference frames are needed, as explained in (Donida,
Ferretti, Savaresi, Schiavo, et al. 2006). Figure 2 shows
DOI
10.3384/ecp17132441

The aligning torque Mz also depends on both the side-slip
angle   and the camber angle   , according to this equation:
Mz = CM   +CM   .
(3)
The side-slip angle   in (2) and (3) differs from  because of the delay in the tyre response after the deformation. The same is true for the camber angle   . These dynamics have been modelled by two first-order differential
equations, i.e.:
 
 +   =  ,
(4)
Vx
 
 +   =  ,
(5)
Vx

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

443

Model Based Analysis of Shimmy in a Racing Bicycle

where Vx is the longitudinal component of the forward
velocity. The characterising parameter, called relaxation
length  , is similar to a time constant except that it has
units of length rather than time. The relaxation length is a
tyre characteristic that can be determined experimentally
(Limebeer and Sharp 2006).
Finally, the overturning torque Mx has been also considered, defined as:
Mx = CMx  .

(6)

To further improve the model, two saturation limits with
respect to the lateral force Fy and the aligning torque Mz
have been introduced. This means that, at high values of
side-slip and camber angles, this force and torque are constant (see Figure 3). In this way, the trend of the curve is
very similar to the one that can be obtained by applying
the Pacejkas magic formula described in (Pacejka 1993).
The linear approximation is valid only for small values of
the two angles.
The stiffness coefficients inside equations (1)-(6) depend on the vertical force Fz transmitted on the ground at
the contact point between tyre and road surface. Dymola
computes its value at any given time (typically, in fact,
the vertical force Fz is not constant during the movement)
and this operation allows to compute all the stiffness coefficients. When contact forces and torques are known, a
balance is carried out at the hub, i.e. the point where the
wheel is connected to the other components of the bicycle.

2.6 Road
The road surface has been modelled through
the
Environments
package
of
the
MotorcycleDynamics library.
This package allows the user to select the road slope
(level, uphill or downhill road) and its characteristics (dry
asphalt, wet and so on). To run the simulations it has been
chosen to work with a dry road, having a slope such as
the bicycle forward speed increases linearly from 10 m/s
to 20 m/s in 40 seconds (see Figure 4). From the results of
the experimental activity described in (Magnani, Ceriani,
and Papadopoulos 2013), it is shown that shimmy appears
in this speed interval. The quote z = f (x, y) of the road
surface is defined by the equations:
{
z=

0 if x < 0
,
0.035 k(x) x if x  0

(7)

where x is the position along the longitudinal direction,
while:
(
)
arctan 10x + 2
k(x) =
.
(8)


Figure 4. Road surface.

3 Model Assembly
Figure 5 shows the connections between the different
models.
In more detail, the rider is connected to the rear frame
and to the front assembly, including the saddle, the pedals
and the two contact points on the handlebar. The front
wheel is attached to the hub of the front assembly with a
Revolute joint. This element simulates the behaviour of
the ball-bearing. Similarly, the rear wheel is attached to
the bicycle main frame.
Lastly, it is necessary to connect to one another the front
assembly and the rear frame. Once again, a Revolute joint
has been used: it introduces the rotation  of the steering
axis. As previously mentioned, there is another key element that is essential to trigger the wobble mode. This is
the lateral compliance of the frame and it can be modelled
by a second Revolute joint that allows the rotations of the
front assembly around the  -axis (see Figure 6).
This axis is in the plane of symmetry of the vehicle
and it is perpendicular to the steering axis, as suggested in
(Klinger et al. 2014). The flexibility is lumped at the steering head. The user can set the values of stiffness k and
damping c coefficients that represent the structural properties of the frame. Figure 7 shows the three-dimensional
representation of the rider-bicycle model. As can be seen,
the cyclist assumes the typical position for riding a racing
bicycle, with his upper body in a bent-forward position
and his hands firmly attached to the handlebar.
Some other simplifying assumptions are also needed.
The gravity force acts on each component, and the aerodynamic drag force1 has been neglected, assuming that the
contribution related to this force is balanced by the component of the weight that appears when the bicycle is moving on a downhill road. Moreover, it has been assumed
that the aerodynamic force does not change the vertical
forces Fz acting on the wheels contact points. Actually,
the lift force reduces the vertical load on both front and

Equation (8) is necessary to avoid discontinuities on the
1 The aerodynamic force can be divided into two components: drag
road surface, i.e. it guarantees an appropriate connection force, which is directed along the longitudinal axis, and lift force, which
when the road slope changes.
is directed along the vertical axis.
444

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132441

Session 7A: Automotive III

!
Figure 5. Model assembly that highlights the connections between components. A Revolute joint with a spring-damper element
has been added to model the frame lateral compliance ( -axis).

!

Figure 6. This figure shows the steering axis  , the axis  that
is necessary to model the frame lateral compliance, roll ( ) and
yaw ( ) angular velocities, the camber angle  and the side-slip
angle  . Positive values are shown.

DOI
10.3384/ecp17132441

Figure 7. Three-dimensional representation of the racing bicycle model.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

445

Model Based Analysis of Shimmy in a Racing Bicycle

4

8

6

3

4

2

Steering axis rotation [deg]

Angular velocity [deg/s]

Roll
Yaw

2

0

-2

1

0

-1

-4

-2

-6

-3

-8
0

5

10

15

20

25

30

35

40

Time [s]

Figure 8. Roll and yaw angular velocities of the bicycle rear
frame when k   (rigid frame).

-4
12

13

14

15

16

17

18

19

20

21

22

Time [s]

Figure 9. Zoom of the steering rotation response for the lumped
flexibility frame model.

rear tyres, while the drag force increases the rear vertical
The oscillations related to the weave mode are damped
load and decreases the front one.
because the weave eigenvalue computed on the linearized
model passes through the imaginary axis, i.e. from the in4 Simulation Results
stability region of the complex plane (the right half-plane)
The aim of the simulations is to study the model dynamic to the stability area (the left half-plane). If this does not
response after the application of suitable perturbations, occur, the oscillations are different (not damped) and they
trying to point out the wobble mode. For this reason, an lead to a fall of the bicycle.
impulsive torque disturbance has been chosen. It is ap- 4.2 Lumped Flexibility Frame Model
plied on the steering axis when the forward speed is equal
Simulations have been repeated considering the lateral
to vs = 13 m/s.
compliance of the frame (hereinafter referred to as lumped
4.1 Rigid Frame Model
flexibility frame model). A zoom of the steering axis reThe first scenario considered is characterised by a rigid sponse after the torque disturbance application is shown in
version of the bicycle model. It can be obtained by setting Figure 9.
As can be seen, the model response to the disturthe frame stiffness coefficient k  . After the torque
bance
consists of low-frequency oscillations with small
application, the steering axis is subject to oscillations that
amplitude
(some tenths of a degree) together with highinitially increase in amplitude and then decrease up to befrequency
oscillations.
Steering rotation reaches in a few
ing completely damped. However, their frequency is apseconds
an
amplitude
of
some degrees. Thanks to the satproximately equal to 1 Hz, a value much smaller than 510 Hz that characterises the wobble mode. Although other uration imposed to the lateral force Fy and to the aligning
simulations have been carried out by changing the type of torque Mz , the oscillations do not diverge but their amplithe perturbation and some model parameters, we have not tude is limited in time. The initial behaviour of the steerbeen able to trigger the shimmy using the bicycle model ing rotation of the lumped flexibility frame model is very
with a rigid frame. Figure 8 shows, instead, the rear frame similar to the one that characterises the rigid version of the
bicycle. This means that the degree of freedom which reproll and yaw angular velocities.
The oscillation trend is the same that characterises the resents the lateral compliance  is, therefore, essential for
steering axis response, i.e. with oscillations that initially the high-frequency contribution in the system response.
spectrograms related to roll and yaw
increase and then disappear after a few seconds. As can Figure 10 shows the
3.
angular
velocities

be noticed, the two signals have a phase difference of 90 :
As in the previous simulations, by applying the torque
when the roll angular velocity is zero, the yaw rate reaches
disturbance
the weave mode is excited. Its frequency
its maximum (or minimum). This trend perfectly deis
now
f
weave = 0, 98 Hz. This mode is also stable:
scribes the weave mode. More specifically, supposing the
after
a
few
seconds, in fact, the oscillations disappear
rider to be sitting on the saddle, when a counter-clockwise
torque is applied to the steering axis  , the bicycle initially because they are damped. When it happens, only the
rotates counter-clockwise about the yaw axis z and then high-frequency oscillations remain in the system response.
They represent the wobble mode. As can be seen from
clockwise about the longitudinal axis x (see Figure 6)2 .
Figure 10, these oscillations are characterised by a fre2 This movement is consistent with the so-called countersteering: for
example, to perform a right curve at high speed, what is being done
is slightly push the handlebar as if you were to turn in the opposite
direction (i.e. to the left). The bicycle responds by leaning correctly in

446

the curve direction (strm, Klein, and Lennartsson 2005).
3 A spectrogram is a visual representation of the spectrum of frequencies in a signal as it varies with time.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132441

Session 7A: Automotive III

is not sufficient. In fact, if the relation is linear, the oscillations are still present in the system response, but they
are not limited in amplitude. As a consequence, both the
rider and the bicycle fall in a few seconds. By adding instead a saturation at high angle values, the amplitude of
the oscillations will remain limited in time.
Time [s]
Yaw angular velocity
Finally, some practical tips to be applied if the shimmy
occurs are discussed. Overall, there is no way to stop a
violent shimmy. These tips, however, are strongly recommended because they can contribute significantly to limit
the amplitude of the oscillations. The first tip is the rider
to assume an upright posture to increase the aerodynamic
Time [s]
drag, thus promoting a deceleration of the bicycle. It is
Figure 10. Spectrograms of roll and yaw angular velocities for also suggested to tighten the horizontal tube of the rear
the flexible bicycle. As can be noticed, the wobble frequency is frame with the legs, increasing in this way the structural
independent with respect to the forward speed.
stiffness. If necessary, gently use the rear brake. Usually,
the oscillations are not divergent so it is difficult that they
can lead to a fall, although this is the sensation perceived
quency equal to fwobble = 5, 43 Hz. In the experimental by the rider during the occurrence of the phenomenon.
activity described in (Magnani, Ceriani, and Papadopoulos 2013) it is reported that the frequency of shimmy References
for this particular racing bicycle is 7,5 Hz. This value
is higher than the one obtained by the lumped flexibil- Andreasson, J. (2003). Vehicle Dynamics Library. In:
Proceedings of the 3rd International Modelica Conferity frame model. By running other simulations, it was
ence.
noted that the wobble frequency fwobble changes varying
strm,
K. J., R. E. Klein, and A. Lennartsson (2005).
the value of the parameter related to the frame stiffness,
Bicycle dynamics and control. In: IEEE Control Sysi.e. k . The same result can be achieved by changing the
tems Magazine 25.4, pp. 2647.
parameters of the spring-damper combination that models
Donida, F., G. Ferretti, S. M. Savaresi, F. Schiavo, and M.
the riders hand grip on the handlebar.
Tanelli (2006). Motorcycle Dynamics Library in ModIn (Magnani, Ceriani, and Papadopoulos 2013) it is said
elica. In: Proceedings of 5th International Modelica
that the wobble frequency seems to be independent with
Conference. Vienna, Austria, pp. 157166.
respect to the bicycles forward speed: this important reDonida,
F., G. Ferretti, S. M. Savaresi, and M. Tanelli
sult has been obtained also through the Dymola model (see
(2008).
Object-oriented modelling and simulation of
again Figure 10).
a motorcycle. In: Mathematical and Computer Modelling of Dynamical Systems 14.2, pp. 79100.
5 Concluding Remarks
Klinger, F., J. Nusime, J. Edelmann, and M. Plchl (2014).
This work presented the development of a racing bicycle
Wobble of a racing bicycle with a rider hands on and
model in Modelica language. The model has been built
hands off the handlebar. In: Vehicle System Dynamics
trying to make it as compliant as possible to the real be52.
haviour. For this reason, attention has been focused on the Limebeer, D. J. N. and R. S. Sharp (2006). Bicycle, morider and on the wheel-road interaction.
torcycles, and models. In: IEEE Control Systems MagBy running simulations with the rigid model (without
azine.
the frame lateral compliance), the only vibrational mode Magnani, G., N. M. Ceriani, and J. Papadopoulos (2013).
that has been excited is the weave mode. It has been necOn-road measurements of high speed bicycle shimmy,
essary to modify the model by introducing an additional
and comparison to structural resonance. In: 2013 IEEE
degree of freedom to highlight the wobble mode. This
International Conference on Mechatronics, pp. 400
shows that it is necessary to consider both the frame lat405.
eral compliance and the tyres deformation (also by taking Pacejka, H. B. (1993). The Magic Formula tire model.
into account their dynamic behaviour) to trigger the highIn: Vehicle System Dynamics (supplement) 21, pp. 1
frequency oscillations characterising the shimmy.
18.
The wobble mode appears when the forces and torques  (2006). Tire and Vehicle Dynamics. Ed. by Elsevier Ltd.
that arise at the contact point of the front wheel are larger
second edition. Chap. chapter 4.
than the value needed to guarantee the longitudinal align- Plchl, M., J. Edelmann, B. Angrosch, and C. Ott (2012).
ment. In this case, the wheel begins to oscillate about the
On the wobble mode of a bicycle. In: Vehicle System
steering axis at a frequency that is too high to be counterDynamics 50.3, pp. 415429.
acted by the cyclist. The use of a simple linear relation
between forces and angles, as stated in equations (1)-(6),
Roll angular velocity

20

8

0

6

-20
-40

4

-60

2

Power (dB)

Frequency [Hz]

10

-80

0

-100

5

10

15

20

25

30

35

10

0

6

-20
-40

4

-60

2

Power (dB)

Frequency [Hz]

20

8

-80

0

-100

5

10

15

DOI
10.3384/ecp17132441

20

25

30

35

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

447

448

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Optimization-friendly thermodynamic properties of water and
steam
Marcus berg1

Johan Windahl2

Hkan Runvik2

Fredrik Magnusson1

1

Department of Automatic Control, Lund University, Sweden, {marcus.aberg@gmail.com,
fredrik.magnusson@control.lth}
2
Modelon AB, Ideon Science Park, Lund, Sweden, {johan.windahl@modelon.com, hakan.runvik@modelon.com}

Abstract
This paper describes the development of an
optimization-friendly thermodynamic property model
of water and steam that covers liquid, vapor, 2-phase
as well as the super-critical region. All equations are at
least twice continuously differentiable with respect to
all model variables and can be used in dynamic
optimization problems solved by efficient derivativebased algorithms. The accuracy has been verified
against the industry standard IAPWS IF97 and
performance and robustness have been tested by
solving a trajectory optimization problem where the
start-up time of a gas power plant has been minimized
while satisfying constraints on temperature gradients,
pressure and flows. Simulations of various plant
models have also been performed to verify and
benchmark the implementation. The results show that
the new media can be used in both solving dynamic
optimization and simulation problems yielding reliable
results. The new media has been integrated into
Modelons Thermal Power library 1.13. This article is
built upon the work in (berg, 2016).
Keywords: Dynamic optimization, Thermodynamic
properties, Power plant start-up, ThermalPower
library, WaterIF97, Optimica, JModelica.org

1

Introduction

During the last decade, optimization of large scale
dynamical systems has become more common in both
the industry as well as in academia (Magnusson, 2016).
There are several interesting areas and applications
where optimization can be used, e.g. to improve
efficiency and economical aspects in energy
applications. Examples where Modelica models have
been used include start-up of power plants (Casella,
Donida, & kesson, 2011), (Runvik, 2014), (Parini,
2015), production planning of district heating
networks (Velut, et al., 2014) and power plant load
scheduling (Kumar & Mathur, 2014). Modelica is well
suited to describe the behavior of dynamical models
and thereby also suitable to be used in the context of
optimization.
DOI
10.3384/ecp17132449

Even if the usage is more common today, the use of
dynamic optimization is still not widely spread among
the engineering community as compared to simulation.
There are several factors that have been limiting the
deployment:
 Modelica does not support formulation of
optimization problems. However, it can
easily be formulated using the Modelica
extension Optimica (kesson, 2008) or using
custom annotations
(Zimmer, Otter,
Elmqvist, & Kurzbach, 2014)
 It is more challenging to create optimization
models versus simulation models. Solving
efficiently
large-scale
dynamical
optimization problems requires the model
equations to be at least twice continuously
differentiable. In the general case when
solving non-convex dynamic optimization
problems good initial guess values,
appropriate model dynamics and as well as
good numerical properties are required to
find the optimal solution (Nocedel & Wright,
2006)
 Modelica libraries such as the Modelica
standard library have been designed for
simulation and not optimization. The lack of
libraries for optimization is usually a stopper
as creating robust models is a large effort and
requires an understanding of numerical
aspects.
This work targets the last issue and is intended as
a first step to bridge the gap between simulation
and optimization of thermo-fluid systems. We do
so by implementing an optimization-friendly
water and steam property model that fulfills a
generic media interface.
Modelica is object oriented and supports design
of interfaces and classes. This allows a library
designer to create models of various fidelity and
assumptions. Users can then change between
classes that fulfill the constraining interface.
Examples include switching to a media of lower
fidelity that is less computationally demanding

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

449

Optimization-friendly thermodynamic properties of water and steam

for e.g. real-time applications or to a model
suitable for optimization.
The choice of focus on water and steam properties
is due to its large usage in power and heat
applications. Traditional electricity-generation
sources such as coal, nuclear and natural
combined gas plants are based on a steam-cycle.
Other applications are hydro power plants and
heating and cooling distribution networks.

2

Background

The availability of a Modelica implementation of the
industry standard of water and steam properties IF97
(Wagner, et al., 2000) helped to spread the usage of the
Modelica technology to the energy and power sector
(Windahl, et al., 2014). But the high accuracy
implementation
Modelica.Media.WaterIF97
is
targeting the usage of simulation and not optimization.
The
main
issues
with
using
Modelica.Media.WaterIF97 for optimization are:




limited support of first order and no support
of second order partial derivatives of
thermodynamic properties
discontinuous first order partial derivatives
at the phase borders between liquid and
steam
discontinuous first order partial derivatives
at the region boundaries. IF97 is divided
into 5 regions that have their own
implementation (Wagner, et al., 2000)

The lack of support of derivatives is an implementation
issue.
Modelon.Media.WaterIF97,
a
similar
implementation, has support for first order derivatives.
But the discontinuity at the phase regions, as illustrated
in Figure 1, is a fundamental limitation. The formation
or depletion of a phase is a strong non-linear process
and needs to be approximated to be twice continuously
differentiable. The models in this work are
implemented to be compatible with JModelica.org's
dynamic optimization framework (Magnusson &
kesson, 2015). This framework uses CasADi
(Andersson, 2013), to efficiently compute sparse first
and second order derivatives using algorithmic
differentiation (Griewank & Walther, 2008).

2.1

Previous work

To the authors knowledge there is no published work
related to dynamic optimization of energy and power
systems that focus on a generic media implementation.
(Velut, et al., 2014) and (Runvik, 2014) mention the
use of smooth media model functions but dont go
into any detail. (Casella, Donida, & kesson, 2011)
use simplifications such as incompressible fluids with
constant heat capacity for non-saturated liquid and
steam. (Parini, 2015) approximates the subcooled
liquid as incompressible fluid and describe the
superheated vapor using a cubic equation of state but
does not describe any accuracy or region of validity.
(Windahl, et al., 2014) investigate requirements for a
new media interface, mentioning the benefit of an
interface that supports analytic calculations of the
Hessian but dont go any further. (Schulze, 2014)
focuses on numerically efficient implementation but
does so from a simulation perspective. This is also the
focus of the guideline on the fast calculation of steam
and water properties with the spline-based table lookup method (International Association for the Properties
of Water and Steam, 2015)). The latter uses quadratic
splines that are continuously differentiable once and
therefore not suitable for dynamic optimization.
This article is built upon the work in (berg, 2016). To
this publication the media implementation has been
updated with some minor modifications that have
made the model more numerically efficient compared
to the implementation used in that thesis. Therefore the
results in this article have been updated too.

3
Figure 1 Density (upper) and its partial derivative with
respect to specific enthalpy at constant pressure as a
function of specific enthalpy. At h=1250 kJ/kg is the
bubble saturation line for water which introduces a
discontinuity in the partial derivative.

450

Implementation

The approach chosen was to approximate the
thermodynamical functions with polynomials over
different operating regions in the p-h, p-s, p-T and d-T
plane. These approximations are then connected via
smooth step functions from one region to another. In
that way, the functions are twice continuously
differentiable over the whole working regime.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132449

Session 7B: Thermodynamic Systems

Polynomial approximation over different regions has
the main advantage that it is smooth over the defined
region. The main challenge here is to find a way to
accurately and smoothly connect the different regions.
In this implementation step functions are used to make
a smooth transition between the regions. These can be
defined so that the functions are twice continuously
differentiable and the smoothness requirement hence is
fulfilled.
The functions that were implemented can be divided
into 1D and 2D-functions. 1D-functions describe the
saturated behavior in the two-phase region. Saturation
temperature, bubble and dew enthalpy are quantities
that can be calculated directly from the pressure. The
2D-functions take two independent state properties
(Thorade & Saadat, 2013) and calculate
thermodynamic properties and a few partial
derivatives.

Figure 2 Phase diagram of water, saturation lines are
drawn with approximated functions. Regions are divided
into super- and sub-critical for both liquid and vapour.

The methods of least squares are used to fit a univariate
or bivariate polynomial to the specified data set. The
maximum order of the polynomials was set to  = 9
on following form.

3.2






(1, 2 ) =    1 2
=0 =0


() =    
=0

If weights are used in the least-squares regression,
certain data points can be given a greater importance
in the fitting process. This is used to give points closer
to the phase border a greater weight in the fit. Making
the residual smaller close to the border allows for a
smoother transition between the different phases.

3.1

Regions

The regions are referred to as liquid, vapor and twophase region. The liquid and vapor regions are divided
into sub- and super-critical areas. The region of a
certain point is decided by its p and h values. Figure 2
shows the phase diagram in the p-h plane with all of
the regions.

DOI
10.3384/ecp17132449

Furthermore, it was noticed later in the process that
accurate media calls were needed for very low
pressures. Thus, a super low pressure region was added
to the functions.

The smooth step function

The method used for making a smooth transition
between regions is via a smooth step function S. The
idea is to multiply the polynomial defining the function
over a certain region with a function so that the
function assumes the polynomial fits value within the
region and goes to zero outside this specific region.
The desired properties of  are
,
() = { ,
,





The right- and left borders of the step has been chosen
to 1 and 0 for easy implementation and the scaling can
be done when calling the function by scaling the input
parameter.
Since the overall goal with this implementation is to
make the media implementation twice continuously
differentiable the step function must also be so.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

451

Optimization-friendly thermodynamic properties of water and steam

the borders between different regions a higher weight
to make the linear regression generate polynomials
which are accurate at the border. However this might
cause overshoots in the rest of the region if the
border points are weighted too much. This method was
therefore used only when this phenomenon did not
cause relatively large residuals inside the considered
region.

Figure 3 Smooth step function with its first and second
derivative.

For this purpose, a generic 5th order polynomial can be
used. If the boundary conditions on the derivatives and
the function are applied the following solution is
found.
,



() = {   +  ,     
,



3.3

The approximating polynomials

The data needed for making the polynomial fits was
extracted from Modelica.Media.WaterIF97.

Furthermore, weighting is used to make the leastsquare algorithm minimize the relative errors instead
of absolute. Since some of the approximated functions
range largely in value, data points which have small
response reference values (close to zero) will get very
large relative errors if weighting is not performed.

3.4

Accuracy of implemented media
functions

Since 18 functions have been implemented, only a few
important examples will be accounted for in this
section.
3.4.1

Temperature

The temperature function is shown in Figure 4 and has
a maximum relative error of around 0.8% as seen in
Figure 5. The red line in the figure represents the phase
border. The relative error is calculated as the
percentage difference between the implemented
approximation and IAPWS IF97.

The grid in the p-h plane that was used for data
extraction was 100x100 points and linear along the haxis with range [1.0e5, 4.0e6] (J/kg). A logarithmic
scale was used for the p-axis with approximately the
range [7.6e4, 3.0e7] (Pa).
For 2D-functions that use d, T and s as inputs, the
response data from IF97 for constructing the functions
that calculates these properties from p and h were used
instead. This was done since it is hard to construct a
grid that does not contain points outside of the domain
of definition for these properties.

Figure 4 The approximated temperature function.

It is of extra importance that the polynomial fits have
high accuracy close to the borders to other regions,
since they are to be connected to another polynomial
function there. Big differences in the values of the
different surfaces close to the border will lead to a
leap in the function value at the border. Even though
the step function smoothes this leap out and makes sure
the function is continuous it is of extra importance that
this difference is made as small as possible since the
model is to be used in optimization algorithms which
can get stuck at inconsistencies like this. The approach
used for handling this problem is to give data points at
452

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132449

Session 7B: Thermodynamic Systems

Figure 5 Contour plot of relative errors of the
approximated temperature function.

There are a couple of interesting things to note from
the relative error plot. At low pressures and high
specific enthalpies there is a distinct drop in the relative
error. This is because a new region was added for sub1 bar pressures in the vapor region to get higher
accuracy at components such as condensers which
operate at very low pressures. Another thing to note is
that the highest relative error is located after the phase
border at the vapor side. The coefficients here have
been weighted in a way to be consistent with the
saturated properties at the phase border. This weighting
might cause this bulge as the least squares-algorithm
prioritizes minimizing the error at the border instead of
inside the region but with the benefit of better
consistency at the phase border.
3.4.2

Density

The density function and the corresponding relative
errors can be viewed in Figure 6 and 7, respectively.
As can be seen, there is a "spike" in the relative error
around the critical point, which is due the connection
of the three regions, and the value there is an
interpolation between the function approximations in
all three regions.

Figure 7 Contour plot of relative errors of the
approximated density function

The same behavior at low pressures in the vapor region
can be seen in the relative error plot as in the
temperature function due to the same reasons, that is,
an added region at low pressures. The spike in relative
errors is due to the fact that 3 regions meet at the
critical point. If the density function is compared with
the temperature function, which has a similar point, it
can be seen that the temperature function is rather flat
at the critical point where the density is rather steep.

4

Optimization benchmarking case:
Start-up of a Heat Recovery
Steam Generator (HRSG)

For testing the implementation in optimization
applications, a model describing a start-up phase of a
heat recovery steam generator (HRSG) has been
chosen.

4.1

Description of the HRSG model

The model used in this thesis has been built upon a
model developed for a tutorial, for further information
and material from this tutorial please see (Larsson,
2015). A similar model and optimization problem is
investigated thoroughly in a master thesis previously
written in cooperation with Modelon (Runvik, 2014).

Figure 6 The approximated density function.

DOI
10.3384/ecp17132449

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

453

Optimization-friendly thermodynamic properties of water and steam

put constraints on the rate of change of the optimizing
input signals.

Optimization problem formulation

4.2

The aim of the start-up is to take the plant from the
initial operating point to another operating point as fast
as possible without violating the problem constraints.
The preferred properties of this process to reach this
point are:



Figure 8 Model diagram view of the system used in the
optimization.

The main working components of the model are a
series of heat exchangers transferring heat from a flue
gas source to the water medium until the steam reaches
a desired working state. The flue gas is led into an
evaporator where the water is evaporated into steam. A
feedback loop connected to the evaporator keeps the
water level in the evaporator on a constant level. From
here, the steam goes through two superheaters where
the steam pressure and temperature increase to reach
the desired working levels. After superheater 2 the
steam is collected in a superheater header, where in
reality the pipes are collected and the steam can be
redirected into a turbine step. There is also a wall
model connected to the header. One of the main issues
with the start-up phase of the power plant is the
exposure of thermal stresses in the components, and
thus this has to be modelled. The wall models allows
for the modelling of these stresses. There is a valve
located after the header which can be used to control
the temperature and pressure inside the header. When
the steam has reached high enough temperature and
pressure it can instead of going through the control
valve, be redirected into a turbine step. To maximize
energy output of the plant, the steam is thereafter led
into a reheater step. After going through the reheater
header it could once again be led through another
turbine step. Again, a control valve is added to be able
to control the pressure and the temperature inside the
header.
The controllable inputs of the model are the firing
power of the gas source and the opening of the valves
located after superheater 2 and the reheater header.
These inputs can be used to control the pressure and
temperature inside the headers and consequently can
be used to limit the thermal stresses inside the header
walls. As can be seen in Figure 8 integrator steps are
added to the control inputs. This was done to be able to
454



Control the system from the initial operating
point to a point where the steam in the plant
has high enough quality to be redirected to
turbines.
The thermal stresses inside the header walls
should be limited to extend the lifespan of the
components.
The controllable inputs have rate of change
constraints which must be obeyed.

The optimal control problem defined over the time
interval [0,  ] is stated as


min  wTSH2 (TSH2  TSH2ref )2
0

+ wpSH2 (pSH2  pSH2ref )2
+ wpRH (pRH  pRHref )2
2
2
+ wSH2v  2
+ wRHv  
+ wb  2 dt

subject to
 

2 < 2

 < 

| 2 | <  2

|  | <  

|  | <  
The first three terms of the objective function
correspond to the penalties on temperature and
pressure deviations from the desired values inside the
heat exchangers (same as in the headers). TSH2 and
pSH2 are the temperature and pressure inside
superheater 2 (TSH2ref and pSH2ref the desired values),
pRH the pressure inside the reheater.  are the
corresponding weights. The last three terms represent
the derivatives of the control inputs,   is the
reheater valve signal,  2 the superheater 2 signal
and   the boiler control signal.
The model equations are the equations that describe the
dynamics of the system. 2 is the thermal gradient
in the superheater 2 header wall and  is its
counterpart in the reheater header wall. The last three

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132449

Session 7B: Thermodynamic Systems

constraints put upper and lower limits on the
derivatives of the three control signals.

4.3

Optimization

A direct collocation method (Magnusson & kesson,
2015) is used for solving the optimization problem.
The time horizon is divided into 12 elements, using 4
collocation points in each element. The element grid
points are located so that they are closer together in the
first part of the time horizon, to better capture the
transient behavior at the beginning of the start-up. 3/4
of the elements are in the first 3/8 of the time horizon
and 1/4 in the last 5/8.
Optimization statistics are summarized in Table 1. The
optimization model has 8 continuous time states and
85 algebraic variables. This model is translated into a
non-linear program with 5184 variables.
Table 1 Optimization statistics
DAE model
Number of states
Number of algebraic variables
NLP model
Total number of variables
Solution statistics
CPU-time in IPOPT (s)
CPU-time in NLP function evaluations (s)
Solution time (s)

4.4

5184
1.45
1.56
3.11

To verify the result the optimized signals were
extracted and used in a simulation experiment using
Water-IF97 media functions. The trajectories for these
simulations are displayed in Figures 9 and 10 alongside
the trajectory from the optimization.

DOI
10.3384/ecp17132449

The simulation results match the optimized trajectory
well, which indicates two things. Firstly, it indicates
that the time discretization of the optimization model
is sufficient to capture the dynamics of the model.
Secondly, it indicates that the implemented media
functions give very similar results to the IF97
functions.

8
85

Verification through simulation

Figure 9 Temperature and pressure
optimization (solid) and simulation
simulation, the optimal input signals are
and the medium is modeled with
thermodynamic property functions.

Figure 10 Metal wall temperature gradient signals from
optimization (solid) and simulation (dotted). The dashed
line represents the maximal allowed wall stress.

signals from
(dotted). In
used as input,
Water IF97

5

Dynamic simulation

To verify that the media model can also handle
industrial relevant dynamic simulation use cases, it
was tested with large dynamic simulation examples in
the Thermal Power Library. These tests expose the
media implementation over various properties and
under different operating conditions. As throughout
this article, the Water-IF97 media implementation will
be used as the reference medium.
Three use cases were set up:
1. Coal fired 400 MW electrical super-critical
steam cycle that operates at a maximum
pressure of 300 bar and 580 C. The model
consists of 5683 equations and 193 continuous
time states.
2. Heat recovery steam generator (HRSG) that
operates at a pressure around 84 bar and in a
temperature interval of 175-500 C. The model
consists of 1616 equations and 39 continuous
time states. In comparison with the
optimization test case, this model includes
more dynamics and describes the considered
system more thoroughly.
3. Nuclear steam generator system that operates
at a maximum pressure of 70bar and 285 C.
The model consists of 6708 equations and 147
continuous time states.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

455

Optimization-friendly thermodynamic properties of water and steam
Table 2 Simulation statistics use case 1 (super-critical
power plant simulated 25000s).

Figure 11 Model diagram view over the HRSG-model
(test case 2)
The test cases were simulated on a standard laptop (Dell
Latitude E7470, Intel i7-6600U) using the Modelica
simulation tool Dymola 2017 with the solver Dassl and a
tolerance of 1e-5.

5.1

Result

The result is summarized in the tables below. Using
the new media implementation, a speed-up of up to
40% can be achieved in an industrial relevant largescale power plant simulation. The difference in result
of selected important variables is below 0.6% in use
case 1 and 2 and 2.9% in use case 3, however it may
be larger for certain intermediate pressure variables.
The larger deviation in use case 3 is mainly due to a
deviation in the isentropic efficiency calculation at the
last turbine stage. This may be improved by dividing
the specific entropy polynomial into regions at lower
pressure in a similar way as was done with the density
function. If trajectories from the simulations are
compared, the results seem to match well as can be
seen in Figure 11, showing the total power transferred
from the exhaust gas to the steam through all three heat
exchanger stages in use case 2.
The CPU-time is a combination of the computational
effort that is required to do one integrator step and the
number of steps. Even if a media implementation is
faster the CPU-time of a simulation may increase due
to an increase of the number of integrator steps. This
may happen if the implementation contains variations
due to the use of e.g. higher order polynomials or
transitions between computational regions. The Fevaluations describe the number of function
evaluations of all system equations. They are used in
the integration process to evaluate derivatives and
calculate numerical system Jacobians. Dassl use the
Jacobian in its internal solver process (Petzold, 1982).

456

Optimization
media

WaterIF97
(reference)

Simulation statistics
CPU-time (s):
Solver steps
F-evaluations
Jacobian-evaluations

24.5
825
7310
125

34.6
862
8857
158

Steady-state results
Generated power
Condenser temperature

405.8 MW
297.64K

408.2 MW
297.60

Table 3 Simulation statistics use case 2 (HRSG
simulated 200s).
Optimization
media

WaterIF97
(reference)

Simulation statistics
CPU-time (s):
Solver steps
F-evaluations
Jacobian-evaluations

7.98
320
3819
105

8.38
296
3412
94

Steady-state results
Total heat transfer
Steam outlet flow
Gas exhaust temperature

286.8 MW
10.69 kg/s
554.3K

287.1 MW
10.75 kg/s
554K

Table 4 Simulation statistics use case 3 (nuclear plant
simulated 25000s).
Optimization
media

WaterIF97
(reference)

Simulation statistics
CPU-time (s):
Solver steps
F-evaluations
Jacobian-evaluations

12.9
1112
14150
448

18.3
1044
16048
392

Steady-state results
Generated power
Condenser temperature

432 MW
33.67 C

420 MW
33.37 C

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132449

Session 7B: Thermodynamic Systems

"less smooth" even though the implementation in
theoretical sense still is twice continuously
differentiable. However, making this parameter too big
will instead decrease the accuracy in a larger region
around the region borders.

Figure 12 Total power transfer from exhaust gas to steam
in use case 3.

6

Conclusions

Efficient optimization-friendly properties of water and
steam covering sub-critical and super-critical regions
have been implemented in Modelons Modelica
Thermal Power library 1.13. The new medium can
bridge the gap between simulation and optimization
and was tested against industrial relevant thermo-fluid
systems. It was shown in the optimization
benchmarking case that the implemented media
functions could be used to provide results that coincide
well with IF97 simulation results using the resulting
optimal control inputs. This shows that the
implementation suggested in this article can yield
reliable results.
The simulation benchmarking test cases aimed at
comparing the accuracy and performance of the new
implementation with the existing Water-IF97 media
implementation. The results from these simulations
show that there are some slight deviations in the results
between the implementations. However, the dynamics
of the system are captured accurately and the relative
errors are small. The largest deviations are observed at
rapid transients. That there are deviations is expected
as the implementation approximates the Water-IF97
standard. The question is whether these differences are
small enough to yield acceptable results and in the
tested simulation models this seems to be the case for
a majority of the use cases. Comparing the simulation
statistics of the large plant use cases shows that the new
implementation is up to 40% faster.

6.1

Future work and possible
improvements

It is desirable that the media is accurate at the phase
borders. The length of the smoothing interval impacts
the derivatives of the functions in the implementation.
A smaller delta makes the transition between the
polynomials go faster and hence making the function
DOI
10.3384/ecp17132449

When modelling thermodynamic properties, there are
many natural laws to consider, which might not totally
be satisfied by the approximations made as there is no
check on whether such relations are fulfilled. An
example of this is that by nature the density must
increase with increased pressure if the temperature is
kept constant. Iterative solvers that use gradients based
on the function approximations might be affected if
there are inconsistencies in such relations.
Furthermore, the choice of functional form in the least
squares approximations might be investigated. There
might be better forms of functions to represent the
functions. In (Aute & Radermacher, 2014) the use of
Chebyshev Rational polynomials is proposed for fast
evaluation of thermodynamic properties. The use of
different functional forms might be a way of making
the implementation faster and more accurate.
For easy implementation of similar models describing
the thermodynamic properties of other media than
water, it is desirable to standardize the implementation.
Ideally the whole work-flow would be automated so
that the only thing that would have to be provided to
create a new media model is the tables containing the
thermodynamic property data. This has however been
hard to achieve, as the many different functions that
have been approximated have different shapes and
appearances making it hard to construct an automated
form for all these functions. It has been necessary to
make specialized forms and adaptations for many of
the functions to achieve good accuracy.

7

Acknowledgements

Fredrik Magnusson acknowledges support from the
LCCC Linnaeus Center and eLLIIT Excellence
Center at Lund University.
8

References

Andersson, J. (2013). A general-purpose software
framework for dynamic optimization. Ph.
D. thesis. Faculty of Engineering, KU
Leuven, Leuven, Belgium.
Aute, V., & Radermacher, R. (2014). Standardized
polynomials for fast evaluation of
refrigerant thermophyiscal properties.
International Refrigeration and Air
Conditioning Conference at Purdue.
Purdue, Indiana.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

457

Optimization-friendly thermodynamic properties of water and steam

Casella, F., Donida, F., & kesson, J. (2011).
Object-Oriented Modeling and Optimal
Control: A Case Study in Power Plant
Start-Up. 18th IFAC World Congress.
Griewank, A., & Walther, A. (2008). Evaluating
Derivatives: Principles and Techniques of
Algorithmic Differentiation, second
edition. ISBN: 978-0-89871-659-7.
International Association for the Properties of
Water and Steam. (2015). Guideline on the
Fast Calculation of Steam and Water
Properties with the Spline-Based Table
Look-Up Method (SBTL) .
Kretzschmar, H.-J., & Wagner, W. (2008).
International Steam Tables. [electronic
resource] : Properties of Water and Steam
Based on the Industrial Formulation
IAPWS-IF97. Berlin, Heidelberg: SpringerVerlag Berlin Heidelberg.
Kumar, S., & Mathur, T. (2014). Dynamic Load
Scheduling of Optimization of Power
Plants. Advanced Control of INdustrial
Processes (AdCONIP). Hiroshima
University, Hiroshima, Japan.
Larsson, P.-O. (2015, October). Report from the
modelon tutorial at the 2015 modelica
conference. Retrieved from
http://www.modelon.com/blog/articles/rep
ort-from-the-modelon-tutorial-at-the-2015modelica-conference/
Magnusson, F. (2016). Numerical and symboolic
methods for dynamic optimization. PhD
thesis, Lund University, Department of
Automatic Control, Lund, Sweden.
Magnusson, F., & kesson, J. (2015). Dynamic
Optimization in JModelica.org. Processes,
3(2), 471-496.
Nocedel, J., & Wright, S. (2006). Numerical
Optimization. New York, NY: Springer
New York.
Parini, P. (2015). Object Oriented Modeling and
Dynamic optimization of energy systems
with application to combined-cycle power
plant start-up. Msc thesis, Politechnico di
Milano, Milano.
Petzold, L. R. (1982). A Description of DASSL: A
Differential Algebraic System Solver.
Presented at IMACS World Congress,
Montreal, Canada, August 8-1 3, 1982.
Runvik, H. (2014). Modelling and start-up
optimization of a coal-fired power plant.
Master's thesis, Lund University,
Department of Automatic Control, Lund.
Schulze, C. (2014). A Contribution to Numerically
Efficient Modeling of Thermodynamic
Systems. PhD thesis, Technische
458

Universitt Braunschweig, Fakultt fr
Maschinenbau.
Thorade, M., & Saadat, A. (2013). Partial
derivatives of thermodynamic state
properties for dynamic. Environmental
Earth Sciences, 70, 8, 34973503.
Wagner, W., Cooper, J., Dittmann, A., Kijima, J.,
Kretzschmar, H.-J., Kruse, A., . . .
Trbenbach, J. (2000). The IAPWS
Industrial Formulation 1997 for the
Thermodynamic propertiies of Water and
Steam. J. Eng. Gas Turbines Power 122,
150-182.
Velut, S., Larsson, P.-O., Runvik, H., Funqvist, J.,
Bohlin, M., Nilsson, A., & Modarrez
Razavi, S. (2014). Production Planning for
Distributed District Heating Networks.
11th International Modelica 2015
Conference. Versailles, France.
Windahl, J., Prlss, K., Bosmans, M.,
Tummescheit, H., van Es, E., &
Sewgobind, A. (2014).
MultiComponentMultiPhase - A fraework
for thermodynamics in Modelica.
Proceedings of the 11th International
Modelica Conference. Versailles, France.
Zimmer, D., Otter, M., Elmqvist, H., & Kurzbach,
G. (2014). Custom Annotations: Handling
Meta-Information in Modelica.
Proceedings of the 10th International
Modelica 2014 Conference. Lund, Sweden.
berg, M. (2016). Optimisation-friendly modelling
of thermodynamic properties of media.
Master's thesis, Lund University,
Department of Automatic Control, Lund.
Retrieved from http://lup.lub.lu.se/studentpapers/record/8888181
kesson, J. (2008). Optimica - An Extension of
Modelica Supporting Dynamic
Optimization. Proceedings of the 8th
International Modelica 2008 Conference.
Bielefeld, Germany.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132449

Modeling of a Thermosiphon to Recharge a Phase Change Material
Based Thermal Battery for a Portable Air Conditioning Device
Rohit Dhumane

Jiazhen Ling Vikrant Aute

Reinhard Radermacher

Center for Environmental Energy Engineering, University of Maryland, College Park, 4164 Glenn L. Martin Hall
Bldg., MD 20742, USA
{dhumane,jiazhen,vikrant,raderm}@umd.edu

Abstract
Closed loop two phase thermosiphons have a broad range
of applications due to their simplicity, reliability, low cost
and the ability to dissipate high heat fluxes from minimal
temperature differences. The present study focuses on one
thermosiphon operation which solidifies a phase change
material (PCM) based thermal battery for a portable air
conditioner called Roving Comforter (RoCo). RoCo uses
vapor compression cycle (VCC) to deliver cooling and
stores the heat released from the condenser into a compact phase change material (PCM) based thermal battery.
Before its next cooling operation, the PCM needs to be
re-solidified. This is achieved by the thermosiphon, which
operates within the same refrigerant circuitry with the help
of a pair of valves. The molten PCM which acts as heat
source affects the dynamics of the thermosiphon which in
turn affects the solidification process. Thus the dynamics
of both the PCM and thermosiphon are coupled. For accurate transient modeling of this process, the PCM model
considers the solidification over a temperature range, variable effects of conduction and natural convection during
the phase change and variable amounts of heat release
at different temperatures within the temperature range of
phase change. The paper discusses component modeling
for this transient operation of thermosiphon and its validation with experimental data.
Keywords: Thermosiphon, Thermosyphon, Phase Change
Materials

1

Introduction

A thermosiphon is an energy transfer device capable of
transferring heat from a heat source to a heat sink over
a relatively long distance, without the use of active control instrumentation and any mechanically moving parts
such as pumps (Dobson and Ruppersberg, 2007). Thermosiphons are used in diverse applications like cooling
of electronic components, light water reactors, solar water heating systems, geothermal systems, and thermoelectric refrigeration systems due to simple designs, simple
operating principles and high heat transport capabilities
(Franco and Filippeschi, 2011). Lack of moving component for pumping refrigerant also leads to higher reliability of the system. Thermosiphons may operate with
DOI
10.3384/ecp17132459

single phase fluid or two phase fluid, may consist of a
co-current or counter-current flow (Haider et al., 2002)
and have open or closed loops (Benne and Homan, 2009).
The counter-current thermosiphons are also referred to as
heat pipes. Industrial applications typically involve the
co-current thermosiphons and the term thermosiphon used
henceforth in this paper, will refer to these co-current thermosiphons.
A closed-loop two-phase thermosiphon consists of a
closed circuit of refrigerant tube filled with a working fluid
(referred to as refrigerant in this paper) and oriented in a
vertical plane. The refrigerant evaporates in the lower portion of the loop (called evaporator) due to a heat input.
The resultant vapor then travels upwards through a vertical tube called as the riser to reach the condenser, where
it rejects its latent heat. The condenser is located vertically above the evaporator and the condensed refrigerant
from its outlet trickles down into the evaporator by gravity
through the downcomer tube. The cycle repeats until the
heat source is exhausted.
The current study is motivated by a need to understand
the dynamics of a thermosiphon used to recharge the thermal battery of a portable air conditioning device called
Roving Comforter (RoCo) (Du et al., 2016). The dynamic
model is expected to aid the improvement of design and
development of controls. A brief description of RoCo is
given in the next section.

2

System Details

Traditional HVAC (Heating, Ventilation and Air Conditioning) systems consume significant amounts of energy
to maintain a uniform temperature in the buildings within
a narrow range, neither of which is necessary for delivering comfort (Hoyt et al., 2015). Personal conditioning systems like RoCo provide an opportunity to save the
building energy by relaxing the building thermostat settings without compromising occupant thermal comfort.
RoCo uses vapor compression cycle (VCC) to deliver
cooling for building occupants and stores the waste heat
from the condenser in a compact PCM based thermal battery. The schematic of the two modes of operation of
RoCo is shown in Figure 1. When the PCM is molten,
the VCC operation is terminated. Due to the poor thermal conductivity of PCM, the molten PCM cannot solid-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

459

Modeling of a Thermosiphon to Recharge Phase Change Material Based Thermal Battery for a Portable Air
Conditioning Device

Figure 1. Schematic of two modes of operation of RoCo with
the thermal battery marked in grey box
Figure 2. The thermal battery of RoCo in the experimental setup
(Du et al., 2016)

ify by itself within a reasonable time duration by rejecting heat to ambient air. Consequently, to enable a faster
recharge of the thermal battery (i.e. PCM solidification),
a thermosiphon is used. The thermosiphon operation is
ideal in this situation because of its high rate of heat dissipation even from relatively small temperature differences
between the heat source and the heat sink. The refrigerant
circuitry is designed to enable a single direction flow of
refrigerant. By operating a pair of valves, the refrigerant
circuit switches from VCC circuit to thermosiphon circuit.
The PCM selected for the current application is
paraffin-based, with the midpoint of its solidification temperature range at 35C. The temperature choice is based
on a trade-off between two opposing factors. The temperature should be high enough so that the PCM does not solidify at typical room temperatures (< 26C). At the same
time, the temperature should also be low enough so that
the condenser temperature for VCC operation is not very
high. Higher condenser temperature leads to poor coefficient of performance (COP). Thus, a very narrow range of
temperature range is applicable for the solidification temperature of PCM in RoCo. Paraffin based PCM is chosen
because as a class paraffin is safe, reliable, predictable,
less expensive and non-corrosive. It melts and freezes repeatedly without phase segregation and consequent degradation of its latent heat of fusion (Sharma et al., 2009). It
crystallizes with little or no supercooling (Sharma et al.,
2009). The only major disadvantage of paraffin based
PCM is its low thermal conductivity. To address this issue,
the thermal battery consists of helical coils of refrigerant
tubing enclosed within PCM volume (See Figure 2). This
arrangement enables higher surface area of heat transfer
and better reach within the PCM volume.
460

3

Model Development

The system model for the thermosiphon consists of several
components which are shown in Figure 3. The evaporator
(See Figure 2) consists of four symmetric refrigerant circuits and to save computational effort, only one of them
is modeled. The splitter and mixer components are
used to scale the dynamic behavior of a single refrigerant circuit to the complete evaporator. The splitter divides refrigerant mass flow rates equally into four, while
the mixer combines them. The refrigerant then flows into
the riser, condenser, refrigerant tube and downcomer before flowing back to the evaporator. The refrigerant tube is
a non-adiabatic flow passage for the refrigerant. The PCM
blocks are connected to a tube control volume, which is a
simple model of circular wall for pipes. The tube control
volume component is also used to model the pcm container. Finally, the heat losses by natural convection and
radiation from the pcm container to the ambient are incorporated. Detailed description of the component models is
provided in this section.

3.1

Phase Change Material

Recall that the PCM Heat Exchanger (PCM-HX) consists
of helical refrigerant tubes surrounded by PCM. The PCM
solidification is a complex phenomenon due to the fact that
the solid-liquid boundary moves depending on the rate of
heat transfer and hence its position with time forms part
of the solution (Zalba et al., 2003). The rate of heat transfer varies progressively during the phase change due to
the varying effects of conduction and natural convection
which depends on the state of PCM. Thus, the dynamics
of PCM and thermosiphon are coupled. The helical nature
of the refrigerant tube further increases the complexity by
making the problem three-dimensional.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132459

Session 7B: Thermodynamic Systems

duration=0

mdot

air inlet
boundary
conditions

duration=0

condenser
Condenser
duration=0

riser

Tair

RH

refrigerant tube
downcomer

Mixer

evaporator cv
tube cv

Heat losses from PCM
container to surroundings

Splitter
pCMConductor

const

pcm conductor

Gc

k=0.2322
C

pcm capacitor

convection
pCMCapacitor

fixedTemperature

bodyRadiation

K
pcm container

Gr=0.073215

T=299.35

Figure 3. Schematic of System Model for Thermosiphon.

The model used in the current work is a trade-off for ac- Modelica.Blocks.Sources.CombiTable1D block is
curacy, complexity and usability. The PCM block is taken used for input of enthalpy-temperature profile.
as a lumped control volume to eliminate the modeling of
The enthalpy-temperature profile is calculated as shown
momentum equation for the molten PCM flow from natu- in equation (2)
ral convection. Two components are used to model PCM:
R T
PCMConductor to model the rate of heat transfer from the
A

solid
RT cs dT,
PCM and PCMCapacitor to model the PCM heat storage.
TA
h(T ) =
(2)
c(T
)dT,
two phase
T

3.1.1 PCM Capacitor
h B + R TB c dT, liquid
L
fg
T
The PCM-HX is the heat source for the thermosiphon and
consequently dictates its dynamics. Very accurate descriph f g [J kg1 ] is the latent heat of melting, the PCM melts
tion of its solidification is required. The energy equation
from temperature TA [K] to TB [K], cs [J kg1 K1 ], c(T )
applied to PCM control volume gives rise to:
[J kg1 K1 ] and cL [J kg1 K1 ] are specific heat capacidh
ties of PCM in the respective phases.
m pcm
= Q
(1)
dt
The melt fraction ( ) of PCM is calculated from its enthalpy
by the following equation:
where, m pcm [kg] is the mass of PCM, h [J kg1 ] is the
specific enthalpy, t [s] is the time and Q [W] is the rate of
h
heat transfer.
 = max(0, min(1, ))
(3)
hl
The enthalpy method by Voller (1990) is used to model
the energy equation. This method requires an input
of enthalpy-temperature function of PCM solidification where hl [J kg1 ] is the enthalpy at the point where the
which is created using data from DSC readings of the PCM just turns liquid. The equation is simplified because
PCM. This ensures accurate temperature prediction of the of the fact that the enthalpy scale is defined as zero for the
PCM state during solidification. The benefit of the en- point where the PCM starts to melt. The melt fraction is
thalpy method is that it allows calculations on a fixed made available for the PCM capacitor block through the
grid with implicit treatment of the phase change boundary. RealOutput interface.
DOI
10.3384/ecp17132459

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

461

Modeling of a Thermosiphon to Recharge Phase Change Material Based Thermal Battery for a Portable Air
Conditioning Device

3.1.2

PCM Conductor

Modelica.Fluid.Interfaces.FluidPort interface.

To define the state of refrigerant inside the lumped conThe PCM Conductor block captures the variable effects
trol volume two properties are required. The average denof conduction and natural convection during the solidifisity, avg [kg m3 ] for the two phase refrigerant can be
cation of PCM. It calculates heat transfer coefficient as a
obtained as shown below:
function of melt fraction.
PCM
Conductor
block
connects
the
reVtot = Vv +Vl
(4)
frigerant
control
volume
of
the
condenser
m = vVv + l Vl
(5)
to the PCM Capacitor block.
It extends
m
Modelica.Thermal.HeatTransfer.Interfaces.
avg =
(6)
Vtot
Element1D block and provides for the heat flow, which
is calculated using CombiTable1D fitted function for
V [m3 ] refers to the volume of the refrigerant, m [kg]
heat transfer coefficient as a function of melt fraction.
The RealInput interface is used to obtain melt fraction its mass. The subscripts v and l refer to vapor and liquid
phases while tot stands for total.
input from PCM Capacitor.
The pressure of the refrigerant is the average of the
Table 1 contains the anchor points given to the Compressure
at its inlet and outlet fluid ports.A medium record
biTable block used as input for the normalized heat transfer coefficient as a function of melt fraction. The con- for the refrigerant is created and these thermodynamic
stant value used to multiply the normalized function to properties are set to determine its state.
obtain heat transfer coefficient (HTC) is 116 W m2 K1 . medium.d = rho_avg;
These numbers are obtained by matching the condenser medium.p = 0.5*(port_a.p+port_b.p);
pressure from simulation to the experiment since there are
The net pressure drop between the inlet and outlet ports
no correlations to capture the behavior in literature. Pal is assumed to equal to the gravitational head offered by
and Joshi (2001) discuss the heat transfer variation in the the refrigerant column.
four regimes captured by Table 1. The initial heat transThe evaporator CV consists of liquid refrigerant with
fer occurs in a conduction dominated regime. Then there vapor escaping from the top after absorbing heat from the
is a reduction in heat transfer coefficient with the appear- surrounding PCM. If the flow were to reverse, liquid reance of small melt layer because the velocity of the liquid frigerant will leave out from the inlet port. Thus the stream
PCM due to buoyancy force is small. The melting then variable of enthalpy in the fluid connectors are equated to
progresses to a convection dominated regime where the the enthalpies of saturated liquid and vapor.
velocity of liquid PCM increases causing a higher rate of
heat transfer. Finally, the magnitude of velocity decreases port_a.h_outflow = h_f;
as the temperature in the molten PCM becomes more uni- port_b.h_outflow = h_g;
form with time due to natural convection stirring, leading
The heat flow term of the HeatPort is calculated by multo decreased buoyancy force for convection.
tiplying heat transfer coefficient by the product of surface
area and temperature difference between HeatPort temperTable 1. Input table for PCM Conductor block.
ature and medium temperature.
Melt Fraction

Normalized HTC

0
0.2
0.4
0.7
1

1
0.9
1
0.9
0.8

heatPort.Q_flow = htc * A * (heatPort.T medium.T);

The two phase heat transfer coefficient for the refrigerant inside the helical coils is calculated first by using
Schmidt (1967) correlation to obtain single phase liquid
only heat transfer coefficient which is then used in Shah
Chart correlation (Shah, 1982).
Finally, the mass and energy balance equations are written down and state transformations applied to update the
3.1.3 PCM-HX Refrigerant Control Volume
values of pressure and enthalpy of the refrigerant CV. This
The PCM is modeled using a lumped control volume (CV) approach is pretty standard in two phase refrigerant sysand accordingly a lumped control volume on the refriger- tem and is discussed in Tummescheit et al. (2000). The
ant side is required. These two CVs are connected using equations for energy, however, involve stream connector
Modelica.Thermal.HeatTransfer.Interfaces.
variations as described in Franke et al. (2009).
HeatPort interface.
The liquid refrigerant from the downcomer reaches 3.2 Condenser
the bottom header of the PCM-HX (See Figure 2). The condenser in the system is a standard air to refrigerThen it absorbs heat from the PCM, vaporizes and ant heat exchanger. It is modeled using the heat exchanger
rises up into the riser.
The flow of refriger- developed by Qiao et al. (2015). The model neglects gravant into and out from the CV, is modeled using itational pressure drops. Thus, it can be visualized as if
462

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132459

Session 7B: Thermodynamic Systems

3.3

50

Temperature [C]

it is placed in a horizontal plane as opposed to vertical
in the real case. However, the height of the condenser is
small compared to the riser and gravitational effects can
hence be ignored for model simplicity. The refrigerant
side heat transfer coefficients for two phase flow are calculated using Shah (2016) correlation. The airside heat
transfer coefficient is calculated using (Wang et al., 2000)
correlation.

45
40

35
30
25
0

Riser

Recall that the riser is that portion of the refrigerant circuit where the refrigerant vapor rises from the evaporator
into the condenser. The timescale over which its dynamics evolves is much faster than the heat exchangers. As a
result, it is modeled as what is described as Flow Model
in literature (Tummescheit et al., 2000). Only the momentum equation is used in the model and the mass and energy
storage in the control volume are ignored. The momentum
equation for riser contains balances for the pressure force,
frictional force and gravitational force as shown in Equation 7 in which Lt [m] is the length of the riser, ddtm [kg s2 ]
is the rate of change of refrigerant mass flow rate, A [m2 ]
is the cross-section area for refrigerant flow in the tube,
pin [Pa] and pout [Pa] are inlet and outlet pressures, f is
friction factor, S [m] is the perimeter of the flow section of
the tube,  [kg m3 ] is refrigerant density and g [m s2 ] is
the acceleration due to gravity.

Lt

1 m2
d m
f SLt + AgLt
= A(pin  pout ) 
dt
2 A2

(7)

The friction factor equation incorporates laminar and
turbulent flow regimes by merging Hagen-Poiseuille and
Blasius equations. Both these equations are taken from
Bergman and Incropera (2011).

3.4 Downcomer

100

200

Expt_axis

300
Time [min]

Expt_wall

400

500

Sim_PCM

Figure 4. Comparison of PCM temperature prediction with experimental data

HeatExchanger.BaseClasses.WallConstProps.
The Tube model has two HeatPort interfaces, one
of which is connected to the PCM Capacitor
block.
The second HeatPort is connected to a
Modelica.Thermal.HeatTransfer.Sources.
FixedTemperature
block
which

has

surrounding

temperature,

via

Modelica.Thermal.HeatTransfer.Components.
Convection and Modelica.Thermal.HeatTransfer.
Components.BodyRadiation blocks to model the heat

losses.
The heat transfer coefficient by convection from the
container walls is obtained using Churchill and Chu
(1975) correlation for natural convection for vertical
plates. Radiation is calculated by taking a value of emissivity  = 0.9 for the material. The container is assumed
to be a convex body in a large enclosure. The heat transfer
coefficient from the top surface of the container is calculated using Lloyd and Moran (1974) correlation. However,
this value is negligible in comparison to the net heat loss
and omitted from the simulation.

The model for downcomer is similar to that of riser except 4 Results and Discussion
for the momentum equation in which the direction of gravFigure 3 shows the thermosiphon model with all the comitational effects are reversed. The momentum equation for
ponents described in the previous section. The boundary
downcomer is shown in Equation 8.
conditions and initial state points are provided using the
experimental results from Du et al. (2016).
1 m2
d m
Lt
= A(pin  pout ) 
f
SL

AgL
(8)
Figure 4 shows a comparison of PCM temperatures
t
t
dt
2 A2
from the experiment with the model. There are two points
from the experiment with subscripts axis and wall. The
3.5 Heat Losses
subscript axis refers to temperature probe near the PCM
The PCM loses heat by natural convection and radiation container wall while the subscript axis refers to temperawith the surroundings. The heat loss by these modes are ture probe at the axis of the helical coil. The dotted line
about 15-20% of the heat removed by the thermosiphon. in the Figure 4 shows the lumped PCM temperature from
For accurate prediction of solidification time, it is neces- the model. As can be observed, the overall prediction is
sary to include these heat losses.
good until roughly 430 minutes. The results deviate sigThe PCM is contained in a PVC container. A simple nificantly from this point. This deviation can be attributed
Tube model of circular wall with one-dimensional to the assumption of the adiabatic riser. In the experiment,
heat conduction and capacitance lumped at arithmetic there is heat loss from the refrigerant vapor as it passes
mean temperature is used.
The equations for this through the riser leading to its condensation. The heat abmodel can be found in Modelica.Fluids.Examples. sorption from PCM drops significantly when the PCM is
DOI
10.3384/ecp17132459

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

463

Modeling of a Thermosiphon to Recharge Phase Change Material Based Thermal Battery for a Portable Air
Conditioning Device
1

are discussed. The heat source of the thermosiphon is finite and the coupled dynamics is successfully predicted by
the model. It is observed that solidifying 94% of PCM is
better than full solidification for better system COP. The
model is expected to be an invaluable tool in designing
the future versions of the portable air conditioning device
with different requirements.

Melt Fraction [-]

0.8
0.6
0.4
0.2

6

0
0

100

200

300
Time [min]

400

500

Figure 5. Percentage of PCM Molten with time

Acknowledgment

This research was supported by the Advanced Research
Projects Agency - Energy (ARPA-E) with Award Number
DE-AR0000530. We thank the members of Center for Environmental Energy Engineering (CEEE) and team members of the Roving Comforter Project for their support.

solidified. The model predicts a small rate of the mass
flow rate at this point, but in reality there is no mass flow
rate. The refrigerant vapor rises up but gets condensed and
falls back down. This phenomenon is not captured by the
model.
The recharge time calculated by the model is 489 minutes when the PCM fully solidifies (See Figure 5). However, 94% percent of PCM is solidified at the 400 minute
mark. For a good overall cycle COP for RoCo, the thermosiphon can be operated for only 400 minutes and VCC
operation started at this point.
Figure 6 shows the temperatures on the airside of the
condenser. The prediction of air outlet temperature is
slightly lower in the initial 20 minute interval. This can
be attributed to the receiver present in the circuit which is
filled with hot liquid refrigerant. For the setup, the receiver
is sized in such a way that the downcomer is completely
filled with liquid refrigerant. This results in larger thermal
mass of refrigerant to be cooled.

References

5

Yilin Du, Jan Muehlbauer, Jiazhen Ling, Vikrant Aute, Yunho
Hwang, and Reinhard Radermacher. Rechargeable Personal
Air Conditioning Device. In ASME 2016 10th International Conference on Energy Sustainability collocated with
the ASME 2016 Power Conference and the ASME 2016 14th
International Conference on Fuel Cell Science, Engineering
and Technology. American Society of Mechanical Engineers,
2016. doi:10.1115/ES2016-59253.

Conclusions

A fully transient model for two phase closed loop thermosiphon is developed from first principles and used to
study the dynamics of a thermosiphon used to recharge
the thermal battery of a portable air conditioner. Equations to model various components of the thermosiphon

Temperature [C]

30

Theodore L Bergman and Frank P Incropera. Introduction to
heat transfer. John Wiley and Sons, Chichester, New York, 6
edition, 2011. ISBN 978-0470-50196-2.
Stuart W Churchill and Humbert HS Chu. Correlating equations for laminar and turbulent free convection from a vertical plate. International journal of heat and mass transfer, 18
(11):13231329, 1975. doi:10.1016/0017-9310(75)90243-4.
R T Dobson and J C Ruppersberg. Flow and heat transfer in a
closed loop thermosyphon. Part ITheoretical simulation. J.
Energy South. Afr, 18:3240, 2007.

Alessandro Franco and Sauro Filippeschi. Closed Loop TwoPhase Thermosyphon of Small Dimensions: a Review of the
Experimental Results. Microgravity Science and Technology,
24(3):165179, 2011. doi:10.1007/s12217-011-9281-6.

29
28

27
26

25
0

100
Expt_in

200

300
Time [min]

Expt_out

Sim_out

400

500

Sim_in

Figure 6. Comparison of air inlet and outlet temperatures at the
condenser

464

K S Benne and K O Homan.
Transient Behavior
of Thermosyphon-Coupled Sensible Storage with Constant Temperature Heat Addition.
Numerical Heat
Transfer, Part A: Applications, 55(2):101123, 2009.
doi:10.1080/10407780802552062.

Rdiger Franke, Francesco Casella, Martin Otter, Michael Sielemann, Hilding Elmqvist, Sven Erik Mattson, and Hans Olsson. Stream Connectors  An Extension of Modelica for
Device-Oriented Modeling of Convective Transport Phenomena. 43:108121, 2009. doi:10.3384/ecp09430078.
S I Haider, Yogendra K Joshi, and Wataru Nakayama. A natural circulation model of the closed loop, two-phase thermosyphon for electronics cooling. Journal of heat transfer,
124(5):881890, 2002. doi:10.1115/1.1482404.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132459

Session 7B: Thermodynamic Systems

Tyler Hoyt, Edward Arens, and Hui Zhang.
Extending air temperature setpoints: Simulated energy savings and design considerations for new and retrofit buildings.
Building and Environment, 88:8996, 2015.
doi:10.1016/j.buildenv.2014.09.010.
JR Lloyd and WR Moran. Natural convection adjacent to horizontal surface of various planforms. Journal of Heat Transfer,
96(4):443447, 1974. doi:10.1115/1.3450224.
Debabrata Pal and Yogendra K Joshi. Melting in a side heated
tall enclosure by a uniformly dissipating heat source. International Journal of Heat and Mass Transfer, 44(2):375387,
2001. ISSN 0017-9310. doi:10.1016/S0017-9310(00)001162.
Hongtao Qiao, Vikrant Aute, and Reinhard Radermacher. Transient modeling of a flash tank vapor injection heat pump systempart I: model development. International journal of refrigeration, 49:169182, 2015.
doi:10.1016/j.ijrefrig.2014.06.019.
Eckehard F Schmidt. Wrmebergang und Druckverlust in
rohrschlangen. Chemie Ingenieur Technik, 39(13):781789,
1967. doi:10.1002/cite.330391302.
M M Shah. Chart correlation for saturated boiling heat transfer:
equations and further study. ASHRAE Trans.;(United States),
88(CONF-820112-), 1982.
Mirza M Shah. Comprehensive correlations for heat transfer
during condensation in conventional and mini/micro channels
in all orientations. International journal of refrigeration, 67:
2241, 2016. doi:10.1016/j.ijrefrig.2016.03.014.
Atul Sharma, V V Tyagi, C R Chen, and D Buddhi. Review
on thermal energy storage with phase change materials and
applications. Renewable and Sustainable Energy Reviews, 13
(2):318345, 2009. doi:10.1016/j.rser.2007.10.005.
Hubertus Tummescheit, Jonas Eborn, and Falko Wagner. Development of a Modelica base library for modeling of thermohydraulic systems. In Modelica Workshop 2000 Proceedings,
pages 4151, 2000.
V R Voller.
Fast implicit finite-difference method for
the analysis of phase change problems.
Numerical
Heat Transfer, 17(2):155169, 1990. ISSN 1040-7790.
doi:10.1080/10407799008961737.
Chi-Chuan Wang, Kuan-Yu Chi, and Chun-Jung Chang. Heat
transfer and friction characteristics of plain fin-and-tube
heat exchangers, part II: Correlation. International Journal of heat and mass transfer, 43(15):26932700, 2000.
doi:10.1016/s0017-9310(99)00333-6.
Belen Zalba, Jose Ma Marin, Luisa F Cabeza, and Harald Mehling. Review on thermal energy storage with
phase change: materials, heat transfer analysis and applications. Applied thermal engineering, 23(3):251283, 2003.
doi:10.1016/S1359-4311(02)00192-8.

DOI
10.3384/ecp17132459

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

465

466

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Extended Modelica Model for Heat Transfer of Two-Phase Flows
in Pipes Considering Various Flow Patterns
Timm Hoppe1
1 XRG

Friedrich Gottelt1

Stefan Wischhusen1

Simulation GmbH, Harburger Schlossstr. 6-12, 21079 Hamburg Germany,
{hoppe,gottelt,wischhusen}@xrg-simulation.de

Abstract
Boiling in vertical and horizontal pipes is a complex process defining transient and static performance of various
technical applications. This work presents an extended
heat transfer model which takes the complete boiling process into account. Models from the literature for the different boiling regimes are evaluated with respect to accuracy
and suitability for system simulation application. A set
of sub-models for each of the existing boiling phenomena
is implemented and applied to the global boiling model.
Special attention is paid to smooth transition between the
sub-models and to numerical efficient solutions with respect to the consideration of the boiling crisis. The simulation results show good accordance with literature data.
Keywords: boiling model, heat transfer, two phase flow,
pipe flow, evaporation, critical heat flux, boiling crisis,
subcooled boiling, saturated boiling, flow pattern, FluidDissipation, ClaRa

1

Introduction

The heat transfer from an evaporator wall to a flowing
two-phase fluid is called flow boiling. During flow boiling three different regimes can be identified. The first one
is the subcooled boiling regime. The bulk of the fluid is
still subcooled but bubbles can already form in the wall
layer, are cooled by the surrounding liquid and thus enhance the heat transfer. It is followed by the saturated
boiling regime in which the wall is predominantly covered by the liquid phase. Bubbles are formed there, leave
the wall and exchange heat and mass with the surrounding liquid at saturation temperature. The critical heat flux
marks the beginning of the post critical heat flux regime,
where the gas phase becomes the dominating phase in the
wall layer. In all of these regimes the slope of the pipe
plays an important role. For example, a vertical pipe has a
distinct point at which the regime changes from saturated
boiling to the post critical heat flux regime. In a horizontal
pipe there is a gradually transition, as the top of the pipe
may be already covered by steam, while the bottom of the
pipe is still cooled by liquid.
During flow boiling of fluid flows high heat fluxes can
be transferred at low temperature differences. Flow boiling occurs in many industrial applications, such as thermal
power plants, air conditioning or heat exchangers in the
DOI
10.3384/ecp17132467

process industry. Exact knowledge about the two-phase
heat transfer and pressure loss is important to determine
behaviour of these applications. However, it is quite common to reduce the boiling process to the saturated boiling regime in system simulation, although several boiling
regimes can be identified which require specific models.
This assumption neglects important effects like the critical heat flux at which the heat transfer coefficient drops
by magnitudes.
An industrial example where it is important to include
this effect are different kinds of thermal power plants like
conventional coal fired steam generators, solar steam generators, natural circulation heat recovery steam generators
or nuclear steam generators.
In coal fired once-through steam generators the critical
boiling state occurs during normal operation at the end of
the evaporator. In normal operation the mass flow rate is
high enough to sustain a sufficient cooling of the pipes, see
(Brinkmeier, 2015). However, in abnormal working conditions, e.g. maldistribution of mass flow between parallel
pipes or failure of feed water supply systems the mass flow
rate may be significantly lower than during nominal operation. A detailed calculation of the heat transfer is needed
to determine the wall temperatures in this abnormal situations.

2
2.1

State of the Art of Two-phase Heat
Transfer Modelling
Literature Review

The actual steam quality of the flow is described by the
local vapour mass fraction defined by the ratio of vapour
mass flow mvap to total mass flow m:
xact =

mvap
m

(1)

If thermodynamic equilibrium is assumed the steam quality can as well be defined by the local specific enthalpy
h, the specific enthalpy at bubble point h0 and the specific
evaporation enthalpy hV :
xeq  x =

h  h0
hV

(2)

The thermodynamic equilibrium steam quality is used in
the further course of the paper and will be referred to as

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

467

Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow Patterns

x. In the subcooled area it can also be negative. The
overall boiling process with the different boiling regimes
is displayed schematically for a horizontal pipe in Figure
1. Two different heating situations are shown, one with
a high heat flux resulting in a nucleate boiling dominated
flow and one with a low heat flux resulting in a convective boiling dominated flow. The circumferential averaged
heat transfer coefficient is plotted against the actual steam
quality and the steam quality assuming thermodynamic
equilibrium.

1-PhaseSubcooled Saturated
Boiling
Flow
Boiling

Post-chf 1-Phase
Boiling Flow

Figure 1. Schematic circumferential averaged heat transfer coefficient for an evaporating flow in a horizontal pipe with a high
heat flux (nucleate boiling dominated) and a low heat flux (convective boiling dominated), according to (Steiner, 2002), flow
regime descriptions refer to nucleate boiling dominated flow

Subcooled Boiling
Bubble formation starts in the wall layer of the current
already at bulk enthalpies below the bubble enthalpy, i.e.
x < 0. These bubbles deteriorate as they move to the subcooled core of the flow, thus enhancing the heat transfer
coefficient. This is known as subcooled boiling, see Figure 1 for a schematic behaviour of the heat transfer coefficient in the subcooled boiling regime of a nucleate boiling
dominated flow.
In general the literature on subcooled boiling is sparse
compared to other boiling regimes. A comparison of
several subcooled boiling models was done by Spindler
(K. Spindler, 1990), the model proposed in the VDI heat
atlas (Schrder, 2002) shows the least error in prediction
of the measurements. At the end of the subcooled boiling
regime at a steam quality x = 0 the VDI model is by construction equivalent to the saturated boiling heat transfer
model for a vertical pipe from the VDI heat atlas. Therefore, a smooth transition to the following boiling regime
is ensured.
Saturated Boiling
In the saturated boiling regime two different boiling
modes can be observed. This is convective boiling on the
one hand and nucleate boiling on the other hand. Convective boiling describes the convective process between
the wall and the liquid phase, whereas nucleate boiling describes the heat transfer induced by formation, growth and
468

departure of the bubbles. In horizontal pipes a stratification of the fluid can occur, depending on the present flow
pattern. As the upper pipe wall is partly dry, i.e. only covered by the gaseous phase, the circumferential heat transfer coefficient is lower compared to flow patterns which
cover the wall completely with the liquid phase.
All relevant saturated boiling models are a function of
the convective boiling heat transfer coefficient, basically
calculated with convective one phase heat transfer correlations and the nucleate boiling heat transfer coefficient,
basically calculated with pool boiling heat transfer correlations. A simple addition of the coefficients is done by
the Chen model (Chen, 1966). He introduced a boiling
surpression factor and a two phase multiplier to fit pool
boiling heat transfer correlation and the one phase convective heat transfer correlation to his flow boiling data.
Shah (Shah, 1982) proposed a model which is not superimposing the convective and the nucleate heat transfer coefficients but chooses the larger of the two. Gunger
and Winterton (Winterton, 1986) developed a new form
of the Chen model, basing on a larger database. They
later also proposed a simpler version of the model (Gungor and Winterton, 1987). The VDI heat atlas (Steiner,
2002) proposes an asymptotic model which incorporates
natural limitations of the flow boiling coefficients, instead
of surpression and two phase factors as used by the other
models. It is also refered to as the Steiner-Taborek model
as it bases on a publication of the two authors (Steiner and
Taborek, 1992). The model is recommended by ASHRAE
(Owen, 2005) and Thome (Thome, 2006a).
Critical Heat Flux
In the further course of the evaporation process the critical boiling state xcrit , also known as critical heat flux, is
reached and the gas phase becomes the dominating phase
at the wall. In a vertical pipe it is a distinct point at
which the heat transfer coefficient drops suddenly by magnitudes. In a horizontal pipe the critical boiling state at the
top of the pipe can already be reached while the bottom of
the pipe is still covered with liquid. The circumferential
averaged heat transfer coefficient in such a situation can
be seen in Figure 1.
Several approaches for prediction of the critical heat
flux can be found in literature. This are on the one hand the
local hypothesis correlations which take the local conditions at the point of boiling crisis into account. Then there
are the global hypothesis correlations which consider the
conditions at the pipe inlet. A third method are the look-up
tables.
The VDI heat atlas (Auracher et al., 2002) gives the
Groeneveld tables (Groeneveld, 2007) as reference for
look-up tables and the Katto-Ohno model (Katto Y.,
1984) as reference for the global hypothesis correlations.
The Katto-Ohno correlation is also proposed by Thome
(Thome, 2006a). For medium to high pressures and mass
flow rates the VDI heat atlas proposes the local hypothesis
correlations of Doroshchuk and Konkov. They are con-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132467

Session 7B: Thermodynamic Systems

sidered as superior to the other two methods. Furthermore, plemented.
they differentiate between dry out and departure from nuIn power plant modelling the critial heat flux plays
cleate boiling.
an important role. In the freely available ClaRa library only the saturated boiling regime is covered. Also
Post Critical Heat Flux Boiling
At least two boiling regimes can be recognized after the other libraries, the freely available ThermoSysPro, the
critical boiling state. On the one hand there is the dry out freely available ThermoPower and the commercial Therof the surface. The wall is not necessarily dry, as the re- malPower, provide no correlations for determination of
maining liquid is entrained as droplets in the vapour flow, the boiling crisis.
also referred to as mist flow. Droplets may then hit the
wall and wet it temporarily. The second regime is called
film boiling or departure from nucleate boiling. It is characterized by the formation of a gas film, the corresponding
flow pattern is called inverted annular flow. The heat transfer coefficient is significantly lower than in mist flow. For
each regime different heat transfer models are required.
If the wall temperature is very high compared to the gas
temperature radiation will also play an important role in
the heat transfer.
For dry out there are two different kinds of correlations.
The simpler correlations assume thermodynamic equilibrium between gas and liquid phase. The model of Groeneveld (Groeneveld, 1973) is proposed by the VDI heat atlas (Katsaounis, 2002) and by Thome (Thome, 2006a).
The more complicated models account for thermodynamic non-equilibrium effects by an apparent superheated
gas temperature. The Khler model (Khler, 1983) proposed by the VDI heat atlas is to mention here. A model
which also includes radiation was published by Ganic and
Rohsenow (Ganic and Rohsenow, 1977).

3

Implementation

The different boiling regime correlations are implemented
in the FluidDissipation which is an open source library and freely available, see (XRG Simulation). For
implementation the functional approach described in
(Vahlenkamp and Wischhusen, 2009) is used. The main
aspects of the approach are:

 Independence of thermo-hydraulic framework
 Use of function calls
 Inputs are delivered by records

In contrast to the models already implemented in the FluidDissipation each boiling regime is implemented in a
separate model. Thus, the overall heat transfer models are
built outside of the FluidDissipation. The advantage of
this procedure is that models can be developed which are
tailored to the corresponding problem. In the following
the implementation of the separate models is shortly deSummary
scribed focussing on main declarative equations and difThe VDI heat atlas proposes correlations for all different ferences of the implementation to the VDI heat atlas modboiling mechanisms, thus the complete boiling process is els. For detailed description of the models see the Fluidcovered by the VDI proposal. In some extent the mod- Dissipation documentation.
els refer to each other. For example one model merges
by construction into the model for the following boiling 3.1 Subcooled Boiling Heat Transfer
regime. This smooth transition between the different mod- From the VDI heat atlas (Schrder, 2002) the models for
els is important in system simulation. It should be con- determination of the position, in terms of a steam quality,
tinuous, continuous differentiable, with low gradients and of initial bubble formation xi and of net vapour forming xn
without hysteresis. The proposed models are also con- are implemented. Both values are by definition of the subsidered among the most reliable ones by other authors. cooled boiling regime always negative. For xi < x < xn the
Therefore, the models of the VDI heat atlas are imple- proposed model for calculation of the heat transfer coeffimented. Where it is possible the references between the cient from VDI heat atlas is used. For xn < x < 0 the VDI
models are used to smooth or simplify the transitions.
heat atlas proposes a superposition of the nucleate boiling heat transfer coefficient and the subcooled convective
2.2 Library Review
heat transfer coefficient. However, this model incorpoIt is not known to the authors that an existing Modelica rates the wall temperature in the heat transfer coefficient
library incorporates a heat transfer model for the complete calculation, which would introduce additional iterations
boiling process. The AirConditioning library and the TIL for the solver. Furthermore, the transition to the saturated
library, which are commercially used for simulation of boiling heat transfer coefficient is only smooth if the inautomotive refrigeration cycles, cover only the saturated fluence of the flow pattern on the saturated boiling heat
boiling regime. The AirConditioning includes implemen- transfer coefficient is neglected. To simplify this model,
tations of the simple Gungor-Winterton and the Chen cor- thus making it numerical more stable, a simple smoothrelation. The TIL library includes the Chen correlation and ing from the subcooled convective heat transfer coeffithe convective boiling correlation of the Steiner-Taborek cient sc (x = xn ) to the saturated heat transfer coefficient
model. In the freely available ThermoCycle library the sat (x = 0) is done. The Stepsmoother from the FluidDisShah and the simple Gungor-Winterton correlation are im- sipation is used which makes use of the smooth transition
DOI
10.3384/ecp17132467

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

469

Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow Patterns

of the following equation
yreg = (1 + tanh(tan(x))) /2

(3)

The output yreg is between 0 and 1 for x=[-/2,/2].

3.2

Saturated Boiling Heat Transfer

The Steiner-Taborek model from the VDI heat atlas
(Steiner, 2002) is implemented. The following equation
results in an asymptotic combination of the convective
boiling conv and the nucleate boiling heat transfer coefficient nclt
q
sat =

3

3 + 3 .
conv
nclt

(4)

Convective Boiling
The VDI heat atlas distinguishes between horizontal and
vertical pipes, in consequence two different correlations
are provided. Both depend on the one phase heat transfer
coefficients for liquid and steam liq and vap , the density
ratio  0 / 00 and the steam quality x. For horizontal pipes
the VDI correlation includes a correction for stratified
flow patterns. The information of the present flow pattern
and the angle of the unwetted circumference of the
pipe is needed. The correction weights the one phase
liquid and steam heat transfer coefficients according
to the unwetted angle. In the implementation of these
functions a smoothing with the stepsmoother from the
FluidDissipation is applied for the transition between
different flow patterns.
Nucleate Boiling
The used correlation from the VDI heat atlas is a function
of heat flux q, pressure p, pipe diameter d and surface
roughness W . For horizontal pipes the correlation shows
an additional dependency on the mass flow rate m and on
the steam quality x. Furthermore, a correction includes
the dependency of the present flow pattern. The function
expects the present flow pattern of the flow as an input
and aligns a correction factor to each flow pattern.
These correction factors depend on the thickness and
conductivity of the wall. Also in this implementation the
transition between flow patterns is smoothed.

3.3

Boiling Crisis

The position of the critical boiling state in terms of a critical steam quality xcrit is determined by the correlations
which are explained in this subchapter. The critical steam
quality marks the end of the saturated boiling regime and
the begin of the post critical heat flux regime and therefore
determines in an overall boiling model at which point the
heat transfer coefficient calculation has to change from the
saturated boiling correlation to the post critical heat flux
correlation.
The local thesis correlations of the VDI heat atlas (Auracher et al., 2002) of Konkov and Doroshchuk for water
are implemented. They depend on the local mass flow
470

rate, the local pressure, diameter of the pipe and the local
heat flow rate.
The Konkov correlation predicts the critical steam quality for dry out, the Doroshchuk correlation the critical
steam quality for departure from nucleate boiling. A logic
chooses the smaller of the two. The used correlation determines whether dry out or departure from nucleate boiling
is present. Thus, it can be decided which post critical heat
flux correlation has to be used.
For horizontal pipes gravitational effects have to be
considered. With the modified Froude number Fr these
effects can be described
Fr = p

 00

xcrit m
p
.
9.81d( 0   00 )cos( )

(5)

The angle  is the inclination of the pipe. For Froude
numbers < 10 the stratification of the flow induces an occurrence of the boiling crisis at the upper side of the pipe
xcrit,up at much lower steam qualities than at the bottom
side of the pipe xcrit,low . This difference xcrit can be determined with the modified Froude number
xcrit = xcrit,low  xcrit,up =

16
.
(2 + Fr)2

(6)

With the difference xcrit the transition zone in horizontal
pipes from the saturated boiling regime to the post critical
heat flux regime can be determined.

3.4

Post Dry-Out Heat Transfer

Two different kinds of models exist for the post dry out
heat transfer. One type assumes thermodynamic equilibrium between the liquid and the vapour phase, i.e. the
temperatures are equal. The other type calculates a superheated gas temperature, which determines the temperature
difference for the heat transfer.
Thermodynamic Equilibrium
The proposed model from the VDI heat atlas (Katsaounis, 2002) is implemented. According to the heat atlas the scope of the model is only for large mass fluxes
m > 2000 kg/(m2 s) and high pressures with  0 / 00  6.
However, the model bases on data of a much wider range,
according to (Thome, 2006b).
Thermodynamic Non-Equilibrium
The proposed model for thermodynamic non-equilibrium
from the VDI heat atlas (Katsaounis, 2002) is implemented. The assumption of the vapour liquid equilibrium
is not valid in this boiling regime. The heat transferred
from the wall to the fluid is not used completely for vaporising the liquid but also for superheating the gas phase.
Thus, the temperature difference for heat flow rate calculation is calculated with the temperature of the superheated gas and the wall temperature within the scope of
the model, i.e.:
Q = ch f A(Tw  Tg ).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(7)

DOI
10.3384/ecp17132467

Session 7B: Thermodynamic Systems

For calculation of the gas temperature the model provides
an empirical correlation. It is no result of energy balancing.
The steam quality xlim gives the end of validity of the
model in terms of steam quality and is an output of the
model. For x > xlim the original source of the model (Khler, 1983) suggests to keep the wall temperatures constant.
As the object-oriented modelling approach does not allow
a direct manipulation of the wall temperature calculation,
this behaviour is approximated implicitly by keeping the
superheated gas temperature constant. This temperature is
used for calculation of the heat flux until the equilibrium
temperature of the fluid is greater.

3.5

framework of the ClaRa library, (The ClaRa development
team) and (Brunnemann et al., 2012), is used. The application is done for the three conservation equation pipe
model. The main features of the pipe model are:

 homogeneous single phase, i.e. thermodynamic
equilibrium between the phases and same velocities
for gas and vapour phase
 one dimensional flow direction
 dynamic energy and mass balances, static momentum balance
 balance equation spatially discretised in flow direction

Flow Pattern Map

The calculation bases on the flow pattern map model described in the VDI heat atlas (Steiner, 2002). To determine
the flow pattern the angle of the unwetted circumference
of the pipe  is needed. The VDI heat atlas model uses
an iteration process to calculate the unwetted angle. To
reduce iterations and make the model suitable for system
simulations some modifications have been made. The unwetted angle is calculated directly with the approximation
suggested by Biberg (Biberg, 1999).
The output of the function is the unwetted angle  and
a real variable flowPattern. To each number a flow pattern
is aligned to, see Figure 2. The variable flowPattern and
the unwetted angle are used by the saturated boiling heat
transfer model, see section 3.2. They identify with the
value of the variable the present flow pattern and correct
the heat transfer coefficient, accordingly. The transition
between two flow patterns is smoothed using the FluidDissipation Stepsmoother see, equation 3.

4.1

Transition of subfunctions

Main task of the application model is to ensure a smooth
transition between the different heat transfer modes. The
smoothing function, defined by equation 3, is used to ensure a continuous and numerical stable transition. In Figure 3 an example for the transition from saturated boiling
to post critical heat flux boiling is given. In the example
the transition zone is defined by
tz = xcrit

(8)

 Bubble flow  6
 Stratified flow  1
 Wavy flow  2
 Slug flow  3

Figure 3. Schematic picure for transition from saturated to post
critical heat flux boiling

 Annular flow  4

In the following the used submodels and the switching
between the submodels is described in detail. Figure 4
Figure 2. Flow patterns for two phase flow in horizontal straight
gives an overview of the used models and the selection
pipes.
sequence which is run by the model for determining the
heat transfer mode. The corresponding transition zone is
displayed in the figure as well. The chosen values of the
transition zone are a trade-off between accuracy and nu4 Application
merical performance.
In this section an examplary application of the functions
is described. The overall boiling process including flow
1. Superheated one-phase flow: The one-phase heat
pattern effects is implemented in the model. The combitransfer model (Dittus-Blter) from the FluidDissination of the subfunctions is done in a replaceable model
pation is used. The transition zone depends on the
applying the FluidDissipation functions. This makes the
choice of the post critical heat flux heat transfer
introduction of additional states possible. These states are
model. For the equilibrium model the transition zone
necessary due to numerical reasons. The thermo-hydraulic
is defined from x = 0.9 to x = 1.
DOI
10.3384/ecp17132467

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

471

d

su

o
w

pe
rh
e

at

ed

o
w

Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow Patterns

bo
ili

su

ng

bc

oo
le

1

sa
tu
r

at
ed

nu
cl

bo

ili

ea
te

ng

3

bo

ili

su

ng

bc

oo
l

ed

2

4

co
bo nv
ili ec
ng tiv
e

po
bo st
ili CH
ng F

4

5

Figure 4. Transition between different Boiling Regimes

2. Subcooled one-phase flow: The one-phase heat
transfer model (Dittus-Blter) from the FluidDissipation is used. The point of initial bubble formation xi is calculated by the subcooled boiling model
from section 3.1. The transition zone is defined from
xi  0.02 to xi + 0.02.
3. Subcooled boiling: The model for subcooled boiling
described in the previous section is used. At x = 0
the model is merged by construction of the equations
into the saturated boiling model described in the previous section.

2002) which assume a local hypothesis for the critical heat
flux. However, the position is calculated for the total pipe
and not for each cell. Thus, situations are avoided in which
the model calculates several boiling crises at a time in different cells. Otherwise inconsistent results could be obtained with the previously described selection sequence
of the model. As inputs to the critical heat flux model
the pressure and mass flow rate of the last cell are used.
The heat flow rate is averaged over the total pipe. Thus,
a strong numerical coupling between the wall temperatures, heat flows and the heat transfer coefficients of all
cells is introduced. To uncouple these variables and help
the simulator to break up the resulting non-linear systems
of equations a stabilizer state for the heat flow rate Q_ is
introduced with the following equation:

4. Saturated boiling: The model for saturated boiling described in the previous section is used. If the
minimum heat flux for onset of nucleate boiling is
exceeded the saturated boiling heat transfer coefficient is calculated according to equation 4 otherwise
d Q_ Q  Q_
only convective boiling is present. The critical steam
=
(9)
dt

quality xcrit is calculated by the boiling crisis model.
The transition area in terms of a steam quality difference is provided for a horizontally oriented tube
by the boiling crisis model. For vertically oriented During stationary conditions both heat fluxes are equal,
tubes a fixed value of xcrit = 0.05 is set. Thus, the thus no new information is included, the stationary results
do not change. During transient conditions the additional
transition area is defined by tz=xcrit .
state lags behind the real heat flux Q with the time constant

= 0.1s.
5. Post-CHF boiling: The models described in the previous section are used. It can be decided whether the
In consonance with the calculation of the critical heat
thermodynamic equilibrium or the non-equilibrium flux position also the point of initial bubble formation x
i
model is used.
and the point of net vapour generation x are calculated for
n

the total pipe and not for each cell. The fluid properties
4.2 Calculation of critical heat flux
of the first cell are handed over to the two models. The
The position of the critical heat flux is calculated using average stabilizer state heat flow rate of equation 9 is used
the functions of Konkov and Doroshchuk (Auracher et al., as a heat flow rate in the models.
472

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132467

Session 7B: Thermodynamic Systems

5.1

Verification and Discussion of first
Results
Verification of overall heat transfer model

For verification of the total model which is described in
section 4 two simulations of evaporation of water in a horizontal pipe are conducted. A screenshot of the used model
built with the ClaRa library is shown in Figure 5. The re-

50000

heat transfer coefficient  [W/(m2 K)]

5

40000
30000
20000
10000
0
-0.3
-0.2 -0.1

convective boiling dominated
nucleate boiling dominated
0

0.1

0.2

0.3

0.4

0.5

steam quality x [-]

0.6

0.7

0.8

0.9

1

1.1

Figure 6. Simulation results of evaporation of water in a horizontal pipe

Figure 5. Screenshot of test model

steam quality of x = 0.8. From that point on the heat transfer coefficient drops until the one phase heat transfer at a
steam quality of 1 is reached, thus no post critical heat
flux boiling is present. The nucleate boiling dominated
case shows a distinct subcooled boiling regime. A plateau
of the heat transfer coefficient follows at which a limit of
the effect of mass flow is reached, according to the nucleate boiling model from the VDI (Steiner, 2002). After that
plateau the nucleate boiling heat transfer coefficient drops
as one could expect from the schematic Figure 1. At a
steam quality of x = 0.65 the critical heat flux at the upper
side of the pipe is reached. At x = 0.9 the critical heat flux
is reached also at the bottom side, a post critical heat flux
regime follows.
In summary it can be said that the results for both extreme conditions are in very good consonance with the
schematic figure. The model predicts the occurrence of
the different heat transfer regimes correctly. Also the transition between the different subfunctions is handled in a
plausible way.

sults should show the principle behaviour of the heat transfer coefficient as can be seen in Figure 1. The boundary
conditions and geometric parameters are shown in Table
1, column "Sim. 1". The first values in column one refer to the extreme case of a convective boiling dominated
flow, the second values to the extreme case of a nucleate
boiling dominated flow. Furthermore, an independency of
the flow pattern is assumed, which occurs in pipe walls
with a good conductivity (Steiner, 2002). A circumferential uniform heating is assumed. The pipe is discretised
with 60 control volumes. The pipe length is chosen such
5.2
that the fluid is evaporated completely in both cases.
The simulation results are shown in Figure 6. The cirTable 1. Boundary conditions and geometric parameters of verification simulation

Parameter

Sim. 1

Sim. 2

Unit

Mass flow
Heat flow
Outlet pressure
Inlet spec. enthalpy
Hyd. diameter
Pipe length
Wall conductivity

500/400
20/750
50
550
0.032
600/15
high

500
600
50
800
0.032
15
low

kg/(m2 s)
kW/(m2 )
bar
kJ/kg
m
m
-

cumferential averaged heat transfer coefficient is plotted
against the steam quality. The convective boiling dominated case shows a behaviour which is to be expected from
Figure 1. The heat transfer coefficient rises with a steam
quality of zero, thus no subcooled boiling is present. It
rises further with rising steam quality until it peaks at a
DOI
10.3384/ecp17132467

Comparison with a simple saturated boiling heat transfer model

A simulation with the boundary conditions from Table
1, column "Sim. 2", is conducted with the overall heat
transfer model described in section 4 and the GungorWinterton 1986 (Winterton, 1986) heat transfer model
which is widely used in system simulation. The boundary
conditions are chosen such that they lie in between the extreme conditions of a nucleate and a convective dominated
flow. Furthermore, a pipe with a low thermal conductivity
of the wall is used.
The results are shown in Figure 7. As an interpretation of the results a schematic pipe with the present flow
pattern is drawn below the plot. The flow pattern is calculated from the functions described in section 3.5. The
overall heat transfer model predicts a distinct subcooled
boiling regime. This boiling regime is neclected in the
Gungor-Winterton model and the one phase heat transfer
coefficient is used instead. Thus, the heat transfer coefficient of the overall model is over a wide range multiple
times larger than the one of the simple Gungor-Winterton

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

473

Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow Patterns

heat transfer coefficient  [W/(m 2K)]

45000

heat crisis. The test section is a vertical pipe, electrically
heated with a length of 7 m and a diameter of 0.0149 m.
In Figure 8 the results of a simulation with the overall model using the thermodynamic equilibrium model for
the post critical heat flux heat transfer are shown. The

40000
35000
30000
25000
20000
15000
10000

Overall boiling
Gungor-Winterton

5000
0
-0.2

-0.1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

1.1

1.2

steam quality x [-]
Bubble Stratied
Flow
Flow

Slug
Flow

Annular
Flow

Dry-Out

Figure 7. Simulation results of evaporation of water in a horizontal pipe

model.
At steam qualities slightly below zero the heat transfer coefficient of the overall model peaks before it drops
again at steam qualities larger than zero. This is due to the
fact that the subcooled boiling model does not depend on
the flow pattern. Whereas with begin of saturated boiling
the heat transfer coefficient shows a high dependency on
the flow pattern. At low steam qualities a stratified flow
is present. As the upper surface of the pipe is not wetted due to stratification, the circumferential averaged heat
transfer coefficient is significantly lower than the GungorWinterton model. It predicts a up to 60% larger heat transfer coefficient, as it has no correction due to stratification
effects of the flow.
In the further course of the evaporation process the
overall boiling model predicts two more different flow patterns. Both induce only a partial wetting of the upper pipe
wall, thus the heat transfer coefficient is reduced compared
to the simple Gunger-Winterton model.
In the overall heat transfer model the saturated boiling
regime ends at a steam quality of x = 0.65. The dry out begins at the upper side of the pipe. At the end of the dry out
process at a steam quality of x = 0.9 the heat transfer coefficient is approximately 10 times smaller than predicted
by the simple Gungor-Winterton model.
The results show that the neglection of effects can lead
to over- or underestimation of the heat transfer coefficient
by magnitudes. For applications, in which crucial variables depend strongly on the heat transfer coefficient, simple models fail to produce reliable results. For example,
this may be the case for wall temperatures in the post dry
out regime. In that case it is important to include more
complex heat transfer models which cover the overall boiling process.

Figure 8. Becker Experiment Case 3 Equilibrium Model

wall temperatures before the heat crisis and the location
of the heat crisis are predicted correctly. The predicted
wall temperatures after the heat crisis until a length of approximately 5.5 m match also the measurement. Beyond
that point the post critical heat flux heat transfer model is
not valid, the overall boiling model changes to the onephase heat transfer correlation. This change leads to an
underestimation of the wall temperature, as the gas phase
is superheated in the post critical heat flux area. This underestimation has two main reasons. On the one hand the
definite temperature is underestimated as the temperature
difference for calculation of the heat flux is formed with
the equilibrium temperature. On the other hand, the heat
transfer coefficient is calculated with fluid properties at the
equilibrium temperature, the fluid properties at the superheated gas temperature should be used instead.
In Figure 9 the test case is simulated with the overall
model using the thermodynamic non-equilibrium model.
The effect of the superheating of the wall near gas phase
is included in the non-equilibrium model. Thus, it matches
the measurement much better than the simple equilibrium
model. At a length of 6 m the model keeps the wall temperatures constant. This assumption fits also better to the
measurement than the use of the one phase heat transfer coefficient as it is done by the simple thermodynamic
equilibrium model.
The thermodynamic non-equilibrium model is able to
predict the wall temperatures more accurate than the simple equilibrium model. Especially, the transition to the
5.3 Validation with measurements
purely convective one phase heat transfer regime fits much
As a validation case the Becker experiments (Abel-Larsen better to the experiment data. However, this advantage
et al., 1985) are presented. They are a series of steady state is dearly bought by a loss of numerical stability and efcritical heat flux experiments, all of them with a dry-out ficiency. This is due to the introduction of a fictive gas
474

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132467

Session 7B: Thermodynamic Systems

References
H. Abel-Larsen, A. Olsen, J. Miettinen, T. Siikonen, J. Rasmussen, A. Sjoberg, and K. Becker. Heat transfer correlations in nuclear reactor safety calculations. Technical report,
Nordic liaison committee for atomic energy, 1985.
H. Auracher, G. Drescher, D. Hein, O. Herbst, A. Katsaounis,
V. Kefer, and W. Khler. VDI Heat Atlas, chapter Hbc - Kritische Siedezustnde. 9th edition, 2002.
D. Biberg. An explicit approximation for the wetted angle in
two-phase stratified pipe flow. The canadian Jounal of Chemical Engineering, 1999.

Figure 9. Becker Experiment Case 3 Non-Equilibrium Model

N.O.W.W. Brinkmeier. Flexibilisierung von Kraftwerken. PhD
thesis, Technische Universitt Braunschweig, 2015.
J. Brunnemann, F. Gottelt, K. Wellner, A. Renz, A. Thring,
V. Roeder, C. Hasenbein, C. Schulze, G. Schmitz, and J. Eiden. Status of ClaRaCCS: Modelling and Simulation of CoalFired Power Plants with CO2 Capture. Proceedings of the
9th International Modelica Conference, Munich, Germany,
pages 609  618, 2012.

temperature and the indirect manipulation of the wall temperatures. These means are introduced to overcome the
drawback of an equilibrium temperature for gas and liquid
phase which is used for calculation of the heat balance in
the three equation pipe model. For a more accurate mod- J. C. Chen. Correlation for boiling heat transfer to saturated fluids in convective flow. Industrial and Engineering Chemistry
elling of the effects in the post critical heat flux regime a
Process Design and Development, 5:322329, 1966.
separate energy balancing of the liquid and the gas phase is
necessary. This would require a thermo-hydraulic frameE.N. Ganic and W.M. Rohsenow. Dispersed flow heat transfer.
work which includes volume models for separate balancInternational Journal of Heat and Mass Transfer, 20:855
ing of the phases, the so called five or six conservation
866, 1977.
equation models, see (Hnninen and Ylijoki, 1992).

6

Summary

D.C. Groeneveld. Post-dryout heat transfer at reactor working
conditions. In Proceedings of the National Topical Meeting
on Water Reactor Safety. Atomic Energy of Canada Limited,
1973.

In this paper an implementation of an extended heat transfer model for two phase flow in pipes is presented.
D.C. Groeneveld. The 2006 CHF look-up table. Nuclear Engineering and Design, 237:19091922, 2007.
The various correlations of the different boiling regimes
are implemented in separate subfunctions. The functional K.E. Gungor and R.H.S Winterton. Simplified general correbased approach of the FluidDissipation (XRG Simulation)
lation for saturated flow boiling and comparisons of correlais used. It enables users to create models which are taitions with data. Chemical Engineering Research and Design,
lored to their problem.
1987.

An exemplary application within the thermo-hydraulic
M. Hnninen and J. Ylijoki. The one-dimensional seperate twoframework of the ClaRa library is given. This model is
phase flow model of apros. Technical report, Technical Reused to verify the implementation. A comparison with a
search Centre of Finland, 1992.
widely used saturated boiling model is conducted. The
predicted heat transfer coefficients of the two models dif- E. Hahne K. Spindler, N. Shen. Vergleich von Korrelationen
zum Wrmebergang beim unterkhlten Sieden. Wrme- und
fer by magnitudes. These results show the importance of
Stoffbertragung, 1990.
complex heat transfer models in system simulation. These
models are relevant in applications, in which crucial variA. Katsaounis. VDI Heat Atlas, chapter Hbd -Wrmebergang
ables depend strongly on the heat transfer coefficient, e.g.
nach der Siedekrise. 9th edition, 2002.
a safety analysis concerning the pipe wall temperatures.
For validation of the extended heat transfer experiment Ohno H. Katto Y. An improved version of the generalized correlation of critical heat flux for the forced convective boiling in
data from the literature are used. The simulations match
uniformly heated vertical tubes. Int. Journal for Heat Mass
the measurement data well. Especially, the position of the
Transfer, 27, 1984.
critical boiling state is predicted correctly. For more accurate results concerning the post critical heat flux regime a W. Khler. Einflu des Benetzungszustandes der Heizflche auf
separate balancing of the phases is necessary, which is a
Wrmebergang und Druckverlust in einem Verdampferrohr.
PhD thesis, 1983.
feature of the six conservation equations models.
DOI
10.3384/ecp17132467

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

475

Extended Modelica Model for Heat Transfer of Two-Phase Flows in Pipes Considering Various Flow Patterns

M.S. Owen, editor. ASHRAE Handbook - Fundamentals, chapter 5 - Two Phase Flow. ASHRAE, 2005.
J.J. Schrder. VDI Heat Atlas, chapter Hba - Strmungssieden
unterkhlter Flssigkeiten. 9th edition, 2002.
M. M. Shah. Chart Correlation for Saturated Boiling Heat Transfer: Equations and Further Study. ASHRAE Transaction1982,
88, 1982.
D. Steiner. VDI Heat Atlas, chapter Hbb - Strmungssieden
gesttigter Flssigkeiten. 9th edition, 2002.
D. Steiner and J. Taborek. Flow Boiling Heat Transfer in Vertical
Tubes Correlated by an Asymptotic Model. Heat Transfer
Engineering, 13(2):4369, 1992.
The ClaRa development team. ClaRa - Simulation of ClausiusRankine cycles. URL www.claralib.com. fetched Dec,
15th 2016.
J. R. Thome, editor. Engineering Data Book III, chapter 10 Boiling Heat Transfer inside Plain Tubes. Wolverine Tube
Inc., 2006a.
J. R. Thome, editor. Engineering Data Book III, chapter 18 Post Dry-Out Heat Transfer. Wolverine Tube Inc., 2006b.
T. Vahlenkamp and S. Wischhusen. FluidDissipation for Applications - A Library for Modelling of Heat Transfer and Pressure Loss in Energy Systems. In Proceedings 7th Modelica
Conference, Como, Italy, September 2009.
K.E. Gungor R.H.S Winterton. A general correlation for flow
boiling in tubes and annuli. Int. J. Heat Mass Transfer, 29(3):
351358, 1986.
XRG Simulation. URL http://www.xrg-simulation.
de/de/produkte/xrg-library/
xrg-fluiddissipation-library.
fetched Dec.,
15th 2016.

476

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132467

Improved Model of Photovoltaic Systems
Dmitry Altshuller1
1

Peter Hsson1

Christopher Alain Jones1

Dassault Systemes, USA, {dmitry.altshuller, peter.huesson,
christopher.jones}@3ds.com
2
Dassault Systemes, Germany, leonard.janczyk@3ds.com

Abstract
The paper describes a model of a typical photovoltaic
(PV) system. Unlike models previously discussed in
literature, heat transfer phenomena are accounted for
simultaneously with the electrical dynamics.
Furthermore, the model is simulated for a time scale of
one full year.
Keywords: Photovoltaic system, Modelica, Thermal
effect, Modeling thermal effect, Solar power, Dymola

1

Leonard Janczyk2

Introduction

The importance of obtaining energy from renewable
resources cannot be overestimated. However,
harnessing these resources often presents considerable
technical difficulties. Furthermore, the effectiveness of
using resources such as wind or solar power depends on
the weather conditions. It is, therefore, critically
important to develop mathematical models that can
reliably predict power output before any significant
investment is made.
The main difficulty in modeling photovoltaic (PV)
systems lies in the complexity of accounting for all the
factors that may influence the performance of a PV cell.
Most of the existing models of PV systems tend to focus
only on some of these factors while simplifying the
influence of others. For example, modeling the
influence of solar irradiance is emphasized in (Tian et
al, 2012) as well as in (Khatib and Elmenreich, 2016)
while the dependence of temperature is simplified. By
contrast, a detailed thermal model is developed in (Jones
and Underwood, 2001) but the influence of electric
power output on the temperature of the system, which,
in turn, affects this power output, is considerably
simplified.
The most commonly used tool for modeling PV
systems is Simulink. PSpice is used in (Castaner and
Silvestre, 2002) and MATLAB is used in (Khatib and
Elmenreich, 2016). In this paper we propose to use
Modelica and the tool Dymola to account for the mutual
influence of the power output and temperature variation.
To this end, we start with the circuit model proposed in
(Pandiarajan and Muthu, 2011) which is then combined
with the thermal model from (Jones and Underwood,
2001). The simulation is run using the weather module
from the HVAC Library developed by XRG Simulation.

DOI
10.3384/ecp17132477

2

Mathematical Background

2.1 Equivalent Circuit
The concept of using an equivalent circuit to model a
PV cell goes back to the book (Angrist, 1982). The
model was subsequently improved in the book (Masters,
2004) and is to this day used. The circuit consists of a
signal-dependent current source connected anti-parallel
to a diode, parallel to a resistor, and in series with
another resistor. The generic schematic of the equivalent
circuit is shown in Figure 1.

Rs
ID

IPV
RL

Rsh

Iph

Figure 1. Schematic of a PV equivalent circuit.

The resistors Rsh and Rs are the intrinsic shunt and series
resistances of the cell. Typically, the value of Rsh is
several magnitues higher than Rs. Therefore, they can be
neglected to simplify some of the equations. These
parameters also affect the characteristic of the diode.
The current Iph depends on the solar radiation and the
temperature of the system. In addition, the diode current
depends on several other voltages and currents in the
circuit. In the next subsections we will give the details
of these models.

2.2 Modeling of the Current Source
The current source is the element where the solar
irradiance energy is converted into the electrical energy.
The equation for the current Iph has the form
(Seyedmahmoudian et al, 2013):
 = [ +  (   )]




(1)

In this equation ISC is the short-circuit current, Ki is
the temperature coefficient, T is the temperature of the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

477

Improved Model of Photovoltaic Systems

PV cell, Tref = 298 K is the reference temperature, G is
the solar irradiance, and Gref=1000 W/m2 is its reference
value.
The value of the solar irradiance is obtained from the
weather model which is taken from the HVAC Library
developed by XRG Simulation. The temperature is
obtained by modeling various heat transfer phenomena
described in Subsection 2.4.

2.3 Modeling of the Diode
The diode current is described by the following equation
(Pandiarajan and Muthu, 2011):
 = 0 [exp

( +   )
 1]
 

(2)

The parameters in this equation are as follows:
q=1.6E-19 C is the electron charge;
NS is the number of PV cells connected in series;
A is the ideality factor;
k=1.3805E-23 J/K is the Boltzmann constant.
Also, involved in the equation are voltage through
and current at the load. These are obtained while the
simulation is running.
The saturation current I0 is calculated from (Angrist,
1982):

The long-wave radiation comes from two sources:
sky and ground. It obeys the Stefan-Boltzmann law but
the terms must be multiplied by respective emissivity of
the sky, the ground, and the PV module. Furthermore,
for the purposes of radiation modeling, the temperature
of the sky is increased by 20 K for clear sky. This
number is reduced down to zero for the overcast sky,
proportionately to cloud cover. In addition, adjustments
need to be made for the tilt angle of the panel.
The convection flow rate is directly proportional to
the difference between the temperature of the panel and
the ambient temperature. The coefficient for the free
convection is proportional to the cubic root of this
temperature difference (Holman and Bhattacharyya,
2011, p.335) but the coefficient for the forced
convection is treated as a parameter since there are
presently no known reliable correlations for it.
The equation has the form (Jones and Underwood,
2001):


g0 ( )

) exp



(3)

In addition to the already defined variables and
parameters, B is the ideality factor and Eg0 is the band
gap. The equation for the reverse saturation current IRS
is (Pandiarajan and Muthu, 2011):
 =



exp
1
 

(4)

The new parameters in this equation are the short-circuit
current ISC and the open-circuit voltage VOC.
The reader is referred to the paper (Pandiarajan and
Muthu, 2011) and references therein for a more detailed
discussion of these equations and parameters.

2.4 Modeling of the Heat Transfer
There are four heat transfer mechanisms that must be
modelled: heating by short-wave and long-wave
radiation as well as cooling by free and forced
convection. In addition, there is heat loss equal to the
power output of the PV system. Let us describe each of
these following (Jones and Underwood, 2001).
The short-wave radiation is directly proportional to
the solar irradiance and is equal to , where  is the
absorptivity, A is the surface area, and G is solar
irradiance.
478

(5)

 (,
+ 1.31 3   )(
  )  

3

0 =  (


1 + cos 
4
=  +  (
 

2
1  cos 
4
+
 
2
4
  
)

In this equation, in addition to the already defined
variables and parameters, C is the heat capacity of the
module,  is the Stefan-Boltzmann constant,  is the tilt
angle of the panel,  refers to the emissivity, and hc, forced
is the forced convection coefficient. The indices for the
temperatures are self-explanatory.

3

Model Implementation

3.1 Electrical System
3.1.1 Overall System Model

In order to model the electrical part of a PV system, the
following Modelica classes were created: Current
Source, Diode, PV array, and PV cell.
The PV cell class connects all of these elements and
also includes the heat transfer model described below in
Subsection 3.2. It includes a two-pin electrical port
which is to be connected to the load and a temperature
port to receive the ground temperature. Additional
inputs are solar irradiance, the numerical value of the
ambient temperature, and the cloud cover fraction.
Parameters are propagated from its included classes.
The model is shown in Figure 2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132477

Session 7C: Electrical & Power Systems II

3.1.2 Diode Model

The PV_Diode model implements equations described
in Subsection 2.3. It has been modified from the MSL
Diode2 model.
The model itself has a basic electrical OnePort which
are connected in the equivalent circuit model.
Additionally, the model has four real inputs. These
inputs are the temperature of the PV module, the serial
resistance of the equivalent circuit model as well as the
current and voltage signal of the load.
In comparison to the Diode2 model of the MSL we
do not need to smooth the function, because we do not
have to consider any switching behavior.
Parameters for the diode model and their default
values are shown in Figure 4.
Figure 2. PV cell model.

The Current Source class has a two-pins electrical
port connected to the signal-driven current source. The
signal input for the source is calculated using the
equation (1) using the solar irradiance as input. The class
also has a thermal port that provides the temperature of
the cell. Parameters for this class are the same as in the
equation (1) and are propagated to the PV cell class.
PV array is a two-port electrical system. One port is
connected to the Current Source and the other to the
load. It also has a thermal port. The model includes the
shunt and the series resistances and the diode model
modified as described in the next Subsection.
Parameters are propagated from its included classes and
are further propagated to the PV cell class. The model is
shown in Figure 3.

Figure 4. Parameters for the diode model.

The model equations are implemented as follows:
equation
Tk = temperature_PV;
R_s = resistance_Rs;
I_pv = current_Ipv;
V_pv = voltage_V_pv;
Irs = Isc/(exp((q*V_oc)/(N_s*Kb*A*Tk
))-1);
I_01 = Irs*((Tk/Tr)^3)*exp(((q*Ego)/
(A*Kb))*((1/Tr)-(1/Tk)));
Figure 3. PV array model.

I_0 = I_01*(exp((q*(V_pv + I_pv*R_s)
)/(N_s*A*Kb*Tk))-1);
i = I_0;
LossPower=i*v;

DOI
10.3384/ecp17132477

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

479

Improved Model of Photovoltaic Systems

3.1.3 Verification

After modeling the electrical part of the PV-array, we
want to verify our model. Most of the literature use the
same output characteristics of PV modules to
characterize the system behavior. We use these
characteristics to verify the correct behavior of our
model.
The tests are made at a constant temperature of
293.15 K. Two variables are varied to get the typical
curve. First the system load will be varied. Second, the
irradiation will be changed.
Figure 5 shows the test setup of the verification
experiment.
Figure 6. I-V characteristics with varying irradiation.

Figure 6 shows the result of the simulation runs. You
can see the characteristic I-V output diagram of a PV
cell. The results match the results from the paper
(Pandiarajan and Muthu, 2011). Our electrical model is
therefore considered verified.

3.2 Thermal System

Figure 5. PV array test setup.

For the electrical parameters we use the references of
a Solkar 36W PV module. The electrical characteristics
can be seen in Table 1 (Pandiarajan and Muthu, 2011).

The thermal system implements the equations described
in Subsection 2.4. It has two thermal ports: one for the
ground temperature and one for the temperature of the
cell. The latter is connected to both Current Source and
the PV array classes. Additional inputs are ambient
temperature, solar irradiance, the cloud cover ratio, and
the electrical power output computed in the PV cell
model. Parameters for the heat transfer model are also
described in Subsection 2.4 and they are propagated to
the PV cell class. The model is shown in Figure 7.

Table 1. Electrical characteristic data of Solkar 36W

Electric parameters
Open circuit voltage (VOC)

21.24 V

Short circuit current (ISCr)

2.55 A

Number of cells in series (Ns)
Number of cells in parallel (Np)

36
1

For the first simulation run we take the irradiation of
200 W/sqm and change the electrical load outside of the
PV cell. This load represents the consumer. We repeat
this experiment with the irradiation of 600 W/sqm and
1000 W/sqm.

Figure 7. Heat transfer model.

Convection is modelled with the MSL Thermal
Convection component. The forced convection
coefficient is implemented as a parameter and the free
convection coefficient is computed using the cubic root
law with the provision that it can never be less than zero.
480

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132477

Session 7C: Electrical & Power Systems II

An additional class has been created for computing
the long wave radiation by modifying the MSL thermal
Body Radiation component. The two thermal ports from
this component are used to connect the ground and the
PV cell. A real input port has been added for the
temperature of the sky. The parameters for this class are
emissivities, the area of the panel and the tilt angle and
they are propagated to the heat transfer model. The
governing equation has been modified as follows in
order to comply with the equation (5):

To get a better understanding of the system it makes
sense to simulate the PV cells over the course of a year.
To see the effect of the weather on the energy output of
our solar system, it is interesting to compare different
climate conditions. To keep the simulation results
simple and comparable we only varied the cloud
coverage between 0% and 50% for this investigation.
The remaining weather conditions were kept the same
for both simulation runs.

equation
Q_flow = A*Modelica.Constants.sigma*((
(1 + cos(beta_surface))/2)*
epsilon_sky*T_sky^4+((1 - cos(
beta_surface))/2)*epsilon_ground*port_
a.T^4 - epsilon_module*port_b.T^4);

The variables in this equation correspond to those in
the equation (5). For example, beta_surface means
, the tilt angle of the panel.
Unfortunately, data in (Jones and Underwood, 2001)
does not provide enough information to verify our
model in simulation experiments.

4

Experiments and Results

Simulation experiments have been run using the tool
Dymola and the weather models from the HVAC
Library. The setup is shown in Figure 8.

Figure 9. Parameters for the simulation.

In Figure 10 the generated energy over the course of
a year is shown. One can see, that the cloud coverage
has an effect on the energy output of the PV system.
Although the simple variation of this weather input is
just effecting the long wave radiation, described in
Subsection 2.4. To get a better understanding of the
electric outputs and the possible use-cases of the
complete system, we would have to make simulations
with varying set of weather data.

Figure 8. Experimental setup.

The weather and the orientation models are taken
directly from the above-referenced library. The weather
model uses the file specifying the weather condition for
the entire year. It provides values of the ambient
temperature, the cloud cover, the ground temperature
and sun position in the sky. The latter is used by the
orientation model to calculate the solar irradiance.
We have used the following values of the parameters
for the PV cell as shown in Figure 9.

DOI
10.3384/ecp17132477

Figure 10. Electric energy over one year.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

481

Improved Model of Photovoltaic Systems

5

Conclusions and Outlook

The results of the simulation experiments demonstrate
the fundamental soundness of our modeling approach,
which is to combine the electrical and the thermal
models.
Future research may proceed along the following
lines. First, it may be beneficial to consider other
weather conditions and/or climates. Second, it may be
of interest to implement control systems and algorithms
so that various parameters can be changed in response
to changing weather conditions in order to obtain
maximum power output. Finally, it will be interesting to
investigate the feasibility of using PV systems in electric
vehicles and/or battery charging stations.

References
S. W. Angrist. Direct Energy Conversion, 4th ed. Boston:
Allyn and Bacon, Inc., 1982
L. Castaner and S. Silvestre. Modeling Photovoltaic Systems
Using PSpice. Chichester: Wiley and Sons, Inc., 2002.
J. P. Holman, S. Bhattacharyya. Heat Transfer. In SI Units.,
10th ed. McGraw Hill, 2011.
A. D. Jones and C. P. Underwood. A Thermal Model for
Photovoltaic Systems. Solar Energy, Vol. 70, No 4, pp.
349359, 2001.
T. Khatib and W. Elmenreich. Modeling of Photovoltaic
Systems Using MATLAB, John Wiley & Sons, 2016.
G. M. Masters. Renewable and Efficient Electric Power
Systems. Hoboken; Wiley and Sons, Inc., 2004.
N. Pandiarajan and R. Muthu. Mathematical Modeling of
Photovoltaic Module with Simulink. International
Conference on Electrical Energy Systems (ICEES), 3-5 Jan
2011, pp. 314-319.
M. Seyedmahmoudian, S. Mekhilef, R. Rahmani, R. Yusof
and E. T. Renami. Analytical Modeling of Partially Shaded
Photovoltaic Systems. Energies, 2013, 6, pp. 128-144. doi:
10.3390/en6010128.
H. Tian, F. Mancilla-David, K. Ellis, E. Muljadi and P.
Jenkins. A Cell-to-Module-Array Detailed Model for
Photovoltaic Panels. Solar Energy, 86, pp. 2695-2706,
2012.

482

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132477

Modelling of a Hydro Power Station in an Island Operation
Arnds Magnsdttir1

Dietmar Winkler2

1 Verks

2 University

hf, Iceland, arm@verkis.is
College of Southeast Norway, dietmar.winkler@usn.no

Abstract
There is a strong focus on new renewable energy sources,
such as, solar power, wind energy and biomass, in the context of reducing carbon emissions. Because of its maturity,
hydropower is often overlooked. However, there is an era
of hydro oriented research in improving many aspects of
this well established technology.
Representing a physical system of a hydropower plant
by mathematical models can serve as a powerful tool for
analysing and predicting the system performance during
disturbances. Furthermore it can create opportunities in
investigating more advanced control method.
A simulation model of a reference hydropower station
located in northwest of Iceland was implemented using
R
the modelling language Modelica
. The main simulation
scenarios of interest were: 20 % load rejection, worst-case
scenario of full shut-down and pressure rise in the pressure
shaft due to the water hammer effect. This paper will show
that the different simulation scenarios were successfully
carried out based on the given the data available of the
Fossrvirkjun power plant. The load rejection simulation
gave expected results and was verified against a reference
results from manufacturer.
Keywords: Hydropower in Iceland, modelling, simulation,
island operation, Modelica, Dymola, Electric Power Library, Hydro Power Library, water hammer effect

1

Introduction

The process of using the energy of moving water to create electricity is a long-standing, well-proven and reliable
technology. Unlike other renewable energy sources, hydropower is not a recent development but has been around
for several hundredths of years. As of today the availability of hydropower has been associated with kick-starting
economic growth (International Hydropower Association
2016).
There is a strong focus on renewable energy sources
in the context of the desired global reduction in carbon
emissions. Technologies such as solar power, wind energy
and biomass are in focus while hydropower is often overlooked. Hydropower has many advantage when it comes
to the effect of climate change as it is renewable, efficient
and reliable source of energy that does not directly emit
greenhouse gasses. Because of its maturity, hydropower
is often associated with conservative and perhaps stagnant technology development. However, there is an area
DOI
10.3384/ecp17132483

of hydro-oriented research in improving many aspects of
this well established technology, taking full advantage of
progress in science and engineering (Munoz-Hernandez,
Mansoor, and Jones 2013).
Around 70 % of Icelands electricity is produced from
hydroelectric power and is the worlds largest electricity
producer per capita. In cooperation with Icelandic oldest and leading consulting engineers in energy production, Verks hf, a complete dynamic hydropower model
was implemented based on a reference power station, Fossrvirkjun, located in the northwest region of Iceland. The
objective of developing such model is to study the dynamic characteristics of the plant, such as load rejection
and to explore worst-case scenario of a full shut-down of
the plant. Furthermore, the effect of water hammer, following pressure rise in the pressure shaft will be of outermost interest since Fossrvirkjuns water-way has no surge
tank installed. Water inertia is the main aspect that influences the water hammer waves in the pressure shaft.
To build such model and to simulate these different scenarios the object-oriented modelling language,
R
Modelica
, is used to model the complex, physical power
plant. The commercial modelling and simulation environment Dymola (Dassault Systmes 2016), a product of
Dassault Systmes, was used. In addition, two separate
libraries, the Hydro Power Library(HPL) and the Electric
Power Library(EPL) (Modelon AB 2016) will be coupled
together in order to represent the complete hydro power
system.

1.1

Fossrvirkjun

In the year 1937, a hydropower station was built to serve
safjrur, located in the northwest region of Iceland in
Skutulsfjrur, in the Westfjords. At that time, it was the
only electric power source for the safjrur area. Since
then there has been no refurbishment until now. The Westfjord Power Company has refurbished the existing power
station with a new turbine/generator and electrical equipment. A new pressure shaft and a new powerhouse were
constructed about 800 m from the existing one and the
new power station is named Fossrvirkjun. The existing
600 kW Pelton machine was replaced by a new 1200 kW
Pelton turbine. The new refurbished power plant serves
Savk in an island operation (Refurbishment of the Fossr hydro Power Plant 2015). Figure 1 shows the new
power house of Fossrvirkjun.
The reference system used for the modelling part is the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

483

Modelling of a Hydro Power Station in an Island Operation

actual length of the pipe segments is longer.
The turbine runner is fixed on the generators shaft. The
generator is a standard 400V AC synchronous machine
with a brush-less excitation system. The governor is a PID
controller.

2

Figure 1. Power house of Fossrvirkjun (Refurbishment of the
Fossr hydro Power Plant 2015)

Modelling

The Modelica simulation environment used in this project
was Dymola which is commercial tool for modelling and
simulation of complex systems. It is a product of Dassault Systmes. Dymola allows the user to create a graphical representation of a physical system and has different
solvers to choose from. Modelica is multidomain modelling language which means that different libraries produced by sometimes several developers can be coupled
together if needed. Taking the advantage of this multidomain modelling, two types of libraries were used to
build the dynamic model of Fossrvirkjun; Hydro Power
Library and Electric Power Library.
The complete power system of Fossrvirkjun can be
seen in Figure 3. The model entails different source components that are connected together.
The reason why the EPL has to be coupled with the
HPL is that even though the HPL contains an electrical
system, it does not give information about active or reactive power, that is, it is only calculating active power
quantities.

new refurbished Fossrvirkjun that started operation in autumn of 2016.
The reservoir is Fossavatn, a fresh water which is
mostly fed by direct runoffs and springs. The intake is
at 343 m.a.s.l. and the rated discharge is at 0.45 m3 /s. The
pressure shaft is around 1900 metres long consisting of a
DN500 GRP pipe with no surge facility. The turbine is a
two-nozzle horizontal Pelton turbine. Since Fossrvirkjun
will be running in island operation two simulation scenarios are of interest.
As has been mentioned, there is no surge tank to absorb
a sudden rise of pressure in the pressure shaft. Therefore, 2.1 The Water-Way
the pressure at the bottom of the pressure shaft, has to be
closely monitored. Table 1 summarises the general infor- The water-way was modelled using components from the
HPL that calculate the media state vectors ( f (p, T )) and
mation data of the system.
media flow of the water.
An important assumption made in the modelling is that
Table 1. General data table of Fossrvirkjun
the states are uniformly distributed. It is assumed in the
upcoming modelling that the water head is constant, that
Properties
Values unit
is, assuming that the water source is an infinite. Figure 4
Pressure shaft
shows the water-way sub-component.
Length
1 900 [m]
Mass, energy and momentum balance equations are disInner Diameter
0.50 [m]
cretised with the finite volume method using an upwind
Nominal pressure in pressure shaft
32 [bar]
discretisation scheme. State variables are pressure, temMaximum over pressure
15 [%]
perature and mass-flow for each pipe segment. Each pipe
segment is split up by a combination of closed volume
Pelton Turbine
models and mass flow models. For each pipe segment the
Number of Nozzles
2
3
two models contain the following
Rated Discharge
0.45 [m /s]
Rated Net Head
308 [m]
Closed Volume Models
Turbine Efficiency
91 [%]
 Conservation laws: Energy Balance and Mass BalSynchronous Generator
ance
Power
1404 [kVA]
 State variables: Pressure (p) and temperature (T )
Max mechanical power
1325 [kW]
Nominal Voltage
400 [V]
 Inflow and outflow: Flow of mass and enthalpy
Nominal Current
2026.5 [A]
Mass Flow Models
A rough sketch of the real water-way of Fossrvirkjun
is depicted in Figure 2. The intake is at 343 m.a.s.l. and
the connection to the turbine at 38 m.a.s.l. The length of
the water-way roughly 1900 m, keeping in mind that the
484

 Conservation Laws: Momentum Balance
 State variables: Mass flow m
 Outflow: mout

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132483

Session 7C: Electrical & Power Systems II

Figure 2. From the real water-way of Fossrvirkjun to modelled water-way in Modelica, split by segments.

Electrical

tions. The Finite Volume Method is considered to be
particularly good at maintaining the conserved quantities (Elmqvist, Tummescheit, and Otter 2003).
The conduit in Fossrsvirkjun is a uniform pipe, but
modelled with two separate pipes, the conduit and the
pressure shaft. This was done in order to be able to analyse
the pressure shaft in more details because of the special interest in the pressure rise.
The water-way sub-component consists of a head
source, reservoir (Fossavatn), conduit, closed volume and
pressure shaft:

turbineGovernor

Fossavatn

f

Langa

y

WaterWay

Head Source Infinite source of volume with prescribed
details about water height and temperature.
Pelton

Figure 3. Complete model of Fossrvirkjun in Dymola

Fossavatn

turbineGovernor

f

y

Langa

WaterWay

Pelton

b

H T

Reservoir/Fossavatn Detailed reservoir built with n segments. Using massflow models which calculates using momentum balance for fluid segments that is between two open channel segments/reservoir.
Conduit/Pressure shaft Model of discretised pipe with
massflow models at inlet and outlet. Using the upwind scheme of finite volume method to discretise
the balance equations; Mass, Momentum and Energy. Pressure, temperature and mass-flow are the
state variables. This pipe is made up of n segments.
Closed Volume Used to connect the conduit and pressure
shaft together. As the name implies, it is a closed volume with state variables as pressure and temperature.

HeadSource
Fossavatn
Conduit

closedVolume

PressureShaft

Figure 4. Submodel: Water-way

2.1.1

Finite Volume Method

For one phase flow models, the partial differential equations of mass, energy and momentum are discretised and
solved with the finite volume method where they are integrated and approximated by ordinary differential equaDOI
10.3384/ecp17132483

In relation to the model of the water-way in Figure 4
where different sub-components come together to create
the water-way,
The earlier Figure 2 shows also how the different subcomponents were used in order to build the model of the
head-race water-way. The conduit model (red line in the
figure) is divided into four segments. It begins at the intake and ends at the junction with the pressure shaft. The
pressure shaft then starts descending at this junction and
continues all the way to the turbine inlet. The real waterway of Fossrvirkun is the blue line in the background.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

485

Modelling of a Hydro Power Station in an Island Operation

As Figure 2 shows, there is some loss in detail in the
1.0
water-way while modelling. From one junction to another, the conduit pipe is modelled as a straight line. In
0.8
theory, you could have numerous of segments throughout
the conduit and subsequently minimising the loss of detail
0.6
but with the cost of the simulation being computational
demanding.
0.4
As mentioned before, the conduit is composed of two
main elements; closed volume and mass flow component.
0.2
To calculate the dynamics all three conservation equaTurbine Efficiency [pu]
Flow rate [m3 /s]
tions; Energy, mass and momentum; are used. The HPL
0.0
calculates the mass and energy balance in the closed vol0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Gate actuator signal [pu]
ume and the momentum balance in the mass flow component. One of the benefits of using Modelica language is the
Figure 5. Plot from the TurbineTable
transparency, that is, behind the sub-components/models
are the corresponding equations that describe the dynamics of the model. For example, the reservoir model that
represents Fossavatn uses the momentum balance to calFor Fossrvirkjun the maximum power arriving at the
culate the mass flow models.
turbine shaft is calculated using the maximum efficiency
2.1.2 Pelton Turbine
of 91 % (from the TurbineTable):
The HPL offers two types of turbine models; the Kaplan
turbine with guide vanes and runner blades and a basic
turbine with guide vane servo which can be used for both
Francis and Pelton turbines. The latter turbine model was
the preferred choice for Fossrvirkjun.
The turbine model is controlled via a gateActuator
input signal from the controller changing the discharge of
the turbine. For Pelton turbines this corresponds to the
nozzle opening which dictates the flow through the turbine
based on a look-up table, i.e.,, TurbineTable. This
turbine look-up table contains information about:

Pturbinemax = 0.91  304 m  9.81

m
kg
m3

1000

0.45
s2
m3
s (2)

 1.221 MW
2.1.3 Lang
The Lang component consists simply of a pipe model and
a fixed source of temperature and pressure, as can be seen
in Figure 6.
Electrical

 Nozzle Opening [pu]
 Volume Flow Rate [m3 /s]
turbineGovernor

 Turbine Efficiency [pu]

Fossavatn

Based on the nozzle vane opening, the volume flow rate
and turbine efficiency can be calculated. Therefore, the
behaviour of how the turbine responds to the control signal
depends on the TurbineTable.
The corresponding plot can be seen in Figure 5. The
red line represent the turbine efficiency [pu] and the blue
line the volume flow rate [m3 /s] corresponding to the gate
actuator signal [pu] on the x-axis.
The Pelton turbine contains two nozzle jets. The
first nozzle operates alone under relatively low flow rate
(0.124  0.224 m3 /s) until the second nozzle steps in to
aid with the increased flow at 0.225 m3 /s. This is clearly
visible in Figure 5 where there the blue line becomes suddenly steeper. At this time, the efficiency also increases as
the red line displays.
Equation (1) describes the power from the Pelton turbine.
Pturbine = hydro  Pavailable  Qmax
= hydro  Havailable  g    Qmax
486

(1)

f

y

Langa

WaterWay
Pelton

a

T p
xed_pT

DraftPipe
Figure 6. Details of the Lang model

Since the Pelton turbine does not require a draft tube,
the pipe that is connected to the output of the turbine is

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132483

Session 7C: Electrical & Power Systems II

only put in there to have the connectors compatible with
the fixed source. The fixed source is simply a constant
pressure, which is set near to atmospheric pressure.

n
ini

Governor

Active
n
ini

torque
eld

Reactive

generator
1

2

Z

syn

trafo

busbar

SensorGenerator

line

Sudavik

SensorSudavik

k=1/dataFOSS.Pref

SI2PU

Input Turbine Power

Output Turbine Speed

Mech2ElectricalFreq

e = ( f0  f ) + (Pin  Pre f )

voltage
gen

excitation

k=dataFOSS.pp

The governor component is situated above the Pelton turbine as can be seen in Figure 3. The governor is an analogue PID controller where it takes in both the power from
the generator and the frequency. The PID controller works
under two conditions; No-load and under load. These conditions are set with a Boolean condition; true when noload, false when under load. This Boolean condition
allows to run with two sets of parameters, one for speed
control and one for power control. The calculations for
the error signal into the PID controller is shown here below in Equation (3).
(3)

Since the power system will be run in speed control
the governor will have an open MCB breaker, that is the
Boolean condition is set to true. The signal will be the
speed of the rotor connected to the generator. The governor will therefore control the output by keeping the signal
at a speed of 1 pu, i.e.,, 50 Hz.

2.2

1st

SingleMassRotor

2.1.4

setPoint

exciter

Electrical

turbineGovernor

Fossavatn

Electrical grid

For the modelling of the electrical grid the Electric Power
Library was used. It is a library for electric power systems.
The library offers a choice of different phase systems:

f

y

Langa

WaterWay
Pelton

Figure 7. Electrical Component in EPL

 DC system
 AC one-phase system
 AC three-phase abc (non-transformed)
 AC three-phase dq0 (dq0-transformed)
 AC three-phase dq (dq-transformed)  for a balanced system
The electrical grid was modelled for a balanced system,
that is, represented by the AC three-phase dq0 system but
omitting the zero-component creating the AC three-phase
dq-transformation. Figure 7 shows the details of the electrical grid component.
The power generated from the Pelton turbine goes as an
input to the single mass rotor in per unit which is then connected to the generator through a flange. The synchronous
generator generates power with positive direct-quadrature
representation. The voltage and reactive power is controlled by the first order control exciter which is connected
to the field voltage. In between the load/consumer, is the
transformer.
The transformer is a step-up type, from 0.4 kV to 11 kV.
The 5 km transmission line then carries the alternating
current to the consumer. The consumer is a small fishing village, Savk, located on the west coast of Iceland,
DOI
10.3384/ecp17132483

20 km from safjrur. Half of the power consumed is
from households and the other half is consumed by a fish
factory.
The EPL is highly complex, where all the components
involved are fully mathematically represented. Since EPL
is very detailed, the amount of input parameters required
by the user is plentiful. This can be beneficial for accuracy
reasons but does invite parameterisation error. There are
a great number of input parameters that have to be known
and correspond to a real scenario power system. Compared to the HPL, EPL is very sensitive to parameter inconsistencies.
The main components involved are:
2.2.1 Single Mass Rotor
Represents one single stiff rotating mass, defined with inertia constant H [s]. The single mass rotor is used as a
connector between the generator and the Pelton turbine.
A power signal from the HPL turbine model is used to
calculate the rotational speed based on the load that the
connected generator represents.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

487

Modelling of a Hydro Power Station in an Island Operation

2.2.2

Synchronous Generator

3.1

Load Rejection

This component is a three-phase-balanced-dq, AC syn- The load rejection simulation was constructed in a way
chronous machine with electric excitation. The user can that the induction load modelled was changed from its
choose from a Y or Delta topology.
original steady active power load of 1.239 MW to a sudden
drop of 20 % resulting in an active power of 0.996 MW .
2.2.3 Exciter
Figure 8 illustrates the model basis for the simulation conThe exciter controls the excitation DC voltage with first sisting of the water-way, governor and electrical part.
order control which is directly determined by the per unit
The results from the simulation can be seen in Figure 9
voltage control signal. The exciter controls both the reac- where the plot illustrates the expected changes in active
tive power and the voltage in the field.
power, reactive power and the flow into the turbine. The
aim here was to keep the rotor speed (frequency) consis2.2.4 Transformer
tent at 1 per unit (50 Hz). The upper plot shows the roIdeal three-phase-balanced-dq step-up transformer. The
tors speed [pu] as the red line and the flow m3 /s in to the
magnetic coupling is ideal with no stray-impedance and
turbine as the blue line. The control action taken is to
zero magnetisation current. The user then chooses bedecrease the nozzle opening to compensate for the power
tween Y and Delta topology at primary and secondary
loss caused by the load rejection. Similarly, the active and
side. On the primary side there is the 0.4 kV from the
reactive power [W] decreased accordingly.
generator and on the secondary side the resulting 11 kV
Similarly, it is interesting to see if the voltage stays confrom the transformer.
stant since the aim of the exciter (voltage regulator) is to
2.2.5 Savk Load
keep the voltage steady. On the upper plot in Figure 10
Inductive three-phase-balanced-dq load. Consumes active the results from the 20 % Load Change illustrate the effect
and reactive power of nominal voltage. Power is derived it has on the voltage both on the low voltage side and the
from the apparent power multiplied with the power factor high voltage side, that is, before and after the transformer.
On the lower plot in the same Figure 10 the pressure at
input.
inlet of the turbine rises from 27.47 bar to 29.19 bar, thus
the pressure increase is 1.72 bar. This increase in pressure
3 Simulation
is a result of the output of the controller, closing the valve
The act of simulation is the experiment done on the model.
to reduce the flow.
The simulation results depend highly on how well the
To summarise, Table 2 reflects the numerical results
model represents the real system. One should always note
from the 20 % load rejection.
that the simulation is only valid under the limitation and
conditions given and can never represent the system comTable 2. 20 % load rejection
pletely, but is mainly an approximation for understanding
the system. The simulation is only valid for the given inOriginal Change Difference [%]
put data (Tiller 2016). There were two types of simulation
Active P. [MW]
1.239
0.996
19.61
scenarios of interest.
Reactive P. [Mvar]
0.138
0.111
19.56
 20 % load rejection
Pressure [bar]
27.47
29.19
5.89
Flow [m3 /s]
0.454
0.341
24.89
 The water hammer effect
Since the power system is in an island operation it is
important to monitor the behaviour of any disturbances in
the system. The load rejection simulation was constructed
by a 20 % sudden load rejection. This scenario is trying
to imitate the incidence when there is a power shut-down,
e.g.,, a shut-down of a large factory. The water hammer effect is particularly of interest for two reasons: There have
been incidents where the pressure on the bottom of the
pressure shaft raised above the pressure threshold of the
pipes material, resulting in an outburst. Second reason is
the lack of surge tank in the power system. The objective of the surge tank is to absorb the pressure and therefore take care of the sudden pressure rise in the pressure
shaft, like has been stated. Omitting the surge tank leads
to an increase in the travel distance of the impact waves in
the conduit which causes increase in inertia of the water
mass (Kiselev 1974).
488

Since the objective of the controller is to keep the rotor
speed constant, three different load rejections were implemented to see the reaction of the rotor. Figure 11 shows
the results after the following load rejections; 20 %, 40 %,
60 % and 80 %. The desired outcome is to keep the speed
at 1 pu (50 Hz) after each load-rejection.
As can be seen in Figure 11 it follows that higher the
load rejection the more amplitude the oscillations have at
the instance when the load changes.

3.2

The Water Hammer Effect

The following simulations were done in order to investigate pressure rise in the pressure shaft and the effect it
has on the governing stability due to the oscillations in
the pressure shaft. A rapid change in the flow can lead to
major oscillations in the water-way, also called the water
hammer effect. Figure 12 shows the model constructed

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132483

Session 7C: Electrical & Power Systems II

setpts

exciter
1st

n
ini

k=dataFOSS.m

Active

torque
eld
voltage
gen

LowVoltageSensor

n

HighVoltageSensor

excitation
generator

ini

SensorSudavik

1

Reactive

2

Z

syn

busbar

Transformer

SensorGenerator

Transmission

Sudavik

Input Turbine Power
turboGrp

Link EPL - HPL

SI2PU

Mech2ElectricalFreq

k=dataFOSS.pp

Fossavatn

k=1/dataFOSS.Pref

Output Turbine Speed

H T

turbineGovernor

f

y

langa

HeadSource

Fossavatn
Conduit

Turbine

PressureShaft

CV

Figure 8. Hydropower model of the load changes

20% Load Change Voltage

20% Load Rejection Flow and n Speed
FlowTurbine

n Speed

HighVoltageSensor

0.6

1.2

0.6

[m3/s]

0.5

0.8

0.4

Voltage [V]

8.0E3

1.0

[pu]

LowVoltageSensor

1.2E4

1.4

0.4

4.0E3

0.0E0

0.2

0.3
0

100

200

300

400

500

0

600

100

200

Active Power

300

400

500

600

400

500

600

Time [s]

Time [s]

20% Load Rejection Active and Reactive Power

20% Load Change Pressure

Reactive Power

PressureInTurbine

36

Pressure [bar]

Power [W]

1.2E6
8.0E5
4.0E5

32

28

24

0.0E0
0

100

200

300

400

500

600

Time [s]

0

100

200

300

Time [s]

Figure 9. Simulation results of 20 % load changes

Figure 10. 20 % load changes, voltage and pressure

for the simulation analysis. It is worth noting that there
are two water-way models. One is connected to the electric part, controlled by the load and the governor. The second water-way is situated below is a stand-alone without
a turbine, controller or an electrical part. This is modelled

this way to isolate the water hammer effect to see whether
there is a difference between the complete power system
model and the isolation of the water-way. On the standalone water-way, a valve is installed instead of the turbine,
the flow through the valve is imitated after the turbine.

DOI
10.3384/ecp17132483

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

489

Modelling of a Hydro Power Station in an Island Operation
n Rotor Speed 20%

1.4

n Rotor Speed 40%

n Rotor Speed 60%

n Rotor Speed 80%

through, is 65 seconds.

1.3

Comparison of Stand-Alone WaterWay and the Whole Power System

1.2

[Per Unit]

[pu]

NozzleOpening
1.1

1.0

ValveOpening

1
0
0

100

200

PressureInTurbine
0.8

300

400

500

300

400

500

300

400

500

Time [s]

0.9

0

500

1000

1500

2000

2500

32

3000

[bar]

Time [s]

PressureInValve

Figure 11. Rotor speed after various load rejections

28
24
0

100

200

Time [s]
FlowTurbine

0.0
0

100

200

Time [s]

Figure 13. Water hammer plot comparing both models

Electrical Part

setpts

exciter

0.4

[m3/s]

The reason for the creating a stand-alone water-way is
simply to allow more direct flow changes and investigations without a controller modifying the control signals
because of some safe-guard and control delay restrictions
that might be present/activated.

FlowValve

1st

n
ini
Active

torque
eld
voltage
gen
excitation

n

HighVoltageSensor

LowVoltageSensor

generator

ini
SensorSudavik

1

syn
SensorGenerator

Reactive

2

Z
busbar

trafo

TransmissionLine

Sudavik

Mech2ElectricalFreq

Output Turbine Speed

SI2PU

turboGrp

Input Turbine Power

Governor

turbineGovernor

WaterWay

Fossavatn

langa
H T

f

y

HeadSource
Fossavatn
Conduit

CV

PressureShaft

Turbine

WaterWay Stand-alone for comparison

Fossavatn

pwr_ref1

duration=65

H T
W_HeadSource

langa1

W_Fossavatn
W_Conduit

W_CV

PressureShaftValve

Figure 12. Overview of the model used for the water hammer
effect scenario

It follows that in order to compare these models, the
control signal from the governor in the upper model has
to be the same as the valve/nozzle closing time. The control signal to the valve in the stand-alone model is a simple ramp function. The resulting plot can be seen in Figure 13. Since the control system is involved in the complete model, it is not possible to simply close the nozzle
in the Pelton turbine. To achieve a fully closed turbine the
load has to be shut-down first. Therefore, the load is set
to zero at time 250 seconds, from its original load. The
time it takes to fully close the turbine until there is no flow
490

The top plot shows the nozzle closing signal from the
governor and the equivalent ramp signal to close the valve.
As can be seen in Figure 13 they are almost identical. The
most important is that their closing time is the same, which
it is.
The comparison between the pressure drop in the turbine and valve can be seen on the middle plot. As expected, for the whole power system there is fluctuation in
the pressure at the beginning since the governor is reacting
to the full load. However, for the stand-alone water-way
the valve starts fully opened. Eventually after 100 seconds
the pressure in the turbine settles to the same pressure as
the valve. At the 250 seconds the turbine and valve close.
Apart from the pressure oscillation in the whole system,
the models respond in a similar dynamic behaviour. Similarly, on the bottom plot the flow out from the turbine and
the valve behave in a similar manner.
Since the comparison between the stand-alone waterway and the whole system gave identical results the standalone water-way can undergo further analysis. It was important to confirm that for the same opening degree, pressure and flow the results are identical before and after closing. For worst-case scenario in terms of the water hammer
effect is if the load in Savk completely shuts-down.
This can be seen in the resulting plot on Figure 13. There
the time it takes to close the turbine is 65 seconds.
Having now an identical water-way with a simple pressure shaft with valve, an analysis of a faster closing of the
valve can take place to test the minimum closing time to
see the maximum allowable pressure in the pressure shaft.
Stated in the technical data from the manufacturer the
allowable pressure rise in the pressure shaft is 15 %. We

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132483

Session 7C: Electrical & Power Systems II

investigated how quickly the valve can close. This was
done by gradually decreasing the closing time starting
from at 56 seconds as shown in Figure 13 and then inspecting the pressure rise for smaller closing times. Table 3
displays the peak/maximum pressure rises for a series of
faster closing times.
Table 3. Closing time in water-way analysis

Closing time
[s]

Pressure
Max [bar] Rise [%]

56
40
15
12
10

32.26
32.58
34.76
35.59
36.71

0.8
1.8
8.6
11.2
14.7

The corresponding plots can be seen in Figure 14. The
upper plot shows the closing signal to the valve and the
bottom plot shows the pressure oscillations at the inlet of
the valve. The most aggressive pressure rise is between
closing time (10-15 seconds), resulting in heavy oscillating dynamic of the water wave.
Comparing Pressure In Pressure Shaft With Varying Closing Time
Closing: 56 s

Closing: 40 s

Closing: 15 s

Closing: 12 s

Closing: 10 s

1.0

[Per Unit]

4.1

Conclusion
Load Rejection

The load rejection was carried out while monitoring the
flow into the turbine, speed of the rotor, pressure, voltage and power. The variables of interest gave a promising
outcome indicating in a dynamic model that should represent Fossrvirkjun power plant adequately. Since having
information regarding 20 % load change from the manufacturer, similar load change scenario was implemented in
order to validate the results.
As for the change in active and reactive power due
to the load change, both decreased immediately around
19.6 % in power. They are controlled by separate controllers, active power by the PID governor and the reactive
by the voltage regulator, therefore a good indicator that
both controllers are taking similar action. When looking
into whether the results are as expected is to
Also the in (1) calculated theoretically available Pelton
turbine power of 1.221 MW compares well with the simulated active power of 1.239 MW .
The same can be said for the voltage in Figure 10 . The
objective of the voltage regulator is to keep the voltage
constant during load rejections. The voltage on both, the
low voltage side and the high voltage side, remains constant throughout the disturbance which results in a good
performance from the voltage regulator.

4.2

0.8

The Water Hammer effect

0.6
0.4
0.2
0.0
-0.2
0

100

200

300

400

500

Time [s]
@56 s

@40 s

@15 s

@12 s

@10 s

38
36
34

[bar]

4

32
30
28
26
0

100

200

300

400

500

Time [s]

Figure 14. Closing time analysis on stand-alone water-way

Figure 15 shows a schematic of the water-way where
the blue line represents the actual pipe alignment and the
red/yellow lines represent the pipe as modelled in Modelica split up by segments. Each pipe is divided into four
segments of equal length. One could increase the resolution by using more segments but in this case the default of four was sufficient. Both the elevation of the
pipe segments and corresponding pressure is marked on
the schematic. The pressure build-up due to the closing of
the valve from the intake at 343 m and down to the turbine
inlet can be seen in Figure 16.
DOI
10.3384/ecp17132483

The analysis of the water hammer effect was implemented
in Section 3.2 where the stand-alone water-way was compared to the whole power system. The results in Figure 13 were promising as both models yielded to similar
behaviour. Since both water-ways are identical, apart from
the valve in the pressure shaft on the stand-alone unit, it
was expected that the pressure would be the same. The
pressure and the flow in the turbine are of course more oscillating since being represented by the whole power system and thus controlled by the governor while the standalone model shows a more ideal behaviour.
After having the above results confirm that the standalone unit had identical result to the whole power system. More aggressive worst-case scenario shut-down of
the valve took place. Closing time analysis was therefore
implemented while observing the pressure in the pressure
shaft of the stand-alone unit. Figure 14 showed the pressure increases with different closing times. To no surprise,
the pressure increased as expected from the original closing time of the valve of 56 seconds down to 10 seconds.
The worst-case scenario shut-down of the valve indicated that a closing time of 10 seconds creates a maximum pressure increase to 36.71 bar. This is something
that is dangerously near the maximum allowed pressure
of 32 bar + 15%, see Table 1. Therefore, the results indicate that the valve/turbine should not be closed/shutdown
in under 12 seconds.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

491

Modelling of a Hydro Power Station in an Island Operation

Figure 15. Pipe segments Fossavatn to turbine/valve inlet

31.3 bar

32

29.3 bar
27.4 bar

28

27.3 bar

25.5 bar

25.2 bar

24

23.7 bar

23.2 bar

20

19.9 bar

[bar]

21.8 bar

17.8 bar
15.3 bar

16

12.3 bar
10.7 bar

12
8
4
0

6.9 bar

6.1 bar
1.5 bar
0

100

200

1.5 bar

Time [s]

300

400

500

Figure 16. Pressure build-up in pipe segments from segment 1 (bottom) through to turbine connection (top)

References
Dassault Systmes (2016). Dymola. Modelon. URL:
http : / / www . dymola . com (visited on
05/28/2016).
Elmqvist, Hilding, Hubertus Tummescheit, and Martin
Otter (2003). Object-oriented modeling of thermofluid systems. In: pp. 269286. URL: http : / /
elib.dlr.de/11988/ (visited on 05/30/2016).
International Hydropower Association (2016). A brief history of hydropower. International Hydropower Association. URL: http://www.hydropower.org/abrief - history - of - hydropower (visited on
05/28/2016).
Kiselev, G. S. (1974). Effect of water inertia in penstocks
on regulating characteristics of hydraulic units. In:
Hydrotechnical Construction 8.4, pp. 337341. ISSN:
1570-1468. DOI: 10 . 1007 / BF02406941. URL:
http://dx.doi.org/10.1007/BF02406941.

492

Modelon AB (2016). Modelon Libraries. Modelon. URL:
http : / / www . modelon . com / products /
modelica-libraries/ (visited on 05/28/2016).
Munoz-Hernandez, German Ardul, Saad Petrous Mansoor, and D. I Jones (2013). Modelling and controlling hydropower plants. London; New York: Springer.
ISBN : 978-1-4471-2291-3. URL : http://public.
eblib . com / choice / publicfullrecord .
aspx?p=973672 (visited on 05/25/2016).
Refurbishment of the Fossr hydro Power Plant (2015).
Verks. URL: http : / / www . verkis . com /
about - us / news / refurbishment - of the-fossarvirkjun-power-plant (visited on
05/28/2016).
Tiller, Michael M. (2016). Modelica By Example. Ed. by
Michael M. Tiller. URL: http://book.xogeny.
com/ (visited on 01/20/2017).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132483

Periodic Steady State Identification for use in Modelica based AC
electrical system simulation
Martin Raphael Kuhn
German Aerospace Center (DLR e.V.), department of system dynamics and control, Germany
Martin.Kuhn@dlr.de

star

spectrum
potentialSensor

Rf

constantSpeed

GCU

ground1

idealDiode2 idealDiode1

star1 inductor1

ground

star2

state

nonlinear load 1 - LLratio

Figure 1: Simulation model for power quality of a small
aircraft electrical network

Introduction

Testing of power quality criteria of electrical components and networks according to industrial standards,
as (MIL-STD-704F,2004), often demands testing in
settled condition. When the data is generated from a
simulation of the physical system, at best, the system
might be initialized in steady-state condition already.
For non-linear switching and periodic systems this condition might not be found easily or only approximately
from alternative representations, as in (Kuhn et
al.,2012). In this case, the time-domain simulation of
the system may converge to the exact periodic steadystate condition from a start condition, if the system is
internally stable and well damped. The correct estimation of the convergence time becomes crucial if the
evaluation of the quality criterion is part of a closedloop optimization of the system itself. Then the time
for simulation to reach steady-state condition, may affect the total time for the optimization process significantly. While the convergence rate may be known analytically for simple systems, generally this is not the
case for arbitrary systems. This chapter shows practical
methods for testing on the periodic steady-state condition of AC electrical circuits to reduce unnecessary
simulation time. Input signals can be simulation results
or measurements. It is assumed that the differential algebraic equation system or the loosely coupled subsys-

DOI
10.3384/ecp17132493

Lf

Rl

resistor1

1

steady

Lf1

rc

Keywords:
periodic
systems,
identification, wavelet, FFT

ground2

capacitor

Analysis of dynamic systems is often carried out at
steady state condition. For cyclic systems like rotating
machinery, it is not possible to detect this condition by
simply monitoring the change rate of their variables,
due to their periodicity. This paper focuses on methods
for stationary periodic steady state identification of AC
electrical systems. An overview of relevant methods is
given and mappings of periodic variables to equivalent
stationary variables are discussed. Two new periodic
steady state monitors based on Short Time Fourier
Transformation are proposed. The study was motivated
by the need to identify the steady state condition of an
aircraft electrical network for power quality checks. An
implementation with Modelica tools is demonstrated.

tem of interest is completely observable via the chosen
output.

inductor resistor

Abstract

To demonstrate the requirement, we will use the following example of a small aircraft electrical network in
Figure 1. It was used as part in a loop of an industrial
design process of a generator, whose design parameters
are generated by a foregoing routine (Kuhn et al.,
2012). The generator feeds a mixed AC resistive and
DC 6-pulse switching load. The model simulates
through an initial transient phase, till it reaches periodic steady-state. The design is then tested for conformance with industrial standards on power quality in the
AC distribution line, which is found between the generator on the left and loads on the right. Power quality
is tested via a Fast Fourier Transformation (FFT) Routine block.
The fast identification of periodic steady-state is of
wider interest in simulation technique; for example for
the non-linear transfer analysis in Saber (Saber,2016)
or a similar Modelica-based tool (Bnte,2011). Both
record the input/output behavior of a system, where the
input is a frequency sweep signal. Its rate of change is
limited in order to arrive -hopefully- in steady-state at
the output. The sweep rate may need manual tuning for
the specific condition, which may be circumvented by
an automatic steady-state detection.
This paper focuses purely on the detection of the periodic steady-state of systems with output x(t) , which

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

493

Periodic Steady State Identification of electrical circuits

can be represented by a superposition of band-restricted time-varying harmonic phasors  k (t) . with
base angular velocity base .
x(t )  k (t)e

j k base t

, K ,  , x

k K

(1)

The time variant complex variable  k (t ) is called
dynamic phasor
 k (t )=

1
T

t

 x( ) ej k   d 

(2)

e

t T

. The mathematics can be found for example in
(Demiray,2008). An example of such a system with
time-varying content around distinct frequencies is displayed in Figure 2.

. In practical applications only the detection of a minimum convergence rate x< 1 may be feasible, since a
longer duration of x=0 may not appear because of asymptotic convergence and/or additive noise. In the case
of periodic systems, the steady-state definition has to
be adapted. It is called a periodic steady-state condition, where consecutive cycles do not deviate, which
means they have an auto-correlation of 1. This can be
expressed by
x( ) x( T )=0  [tT ..t ]

(4)
, where the periodicity time constant T replaces the
infinitesimal  t in equation 3.

X ( j )

0 e



5 e

7 e

11e

Figure 2: Fourier spectrum of nonstationary signal, with
spectral content around sin (e ) , sin (e(61)) ,
sin (e(121))

This paper is structured as follows: In the following
section the difference between steady-state and periodic steady-state is highlighted. An overview on applicable methods for Steady State Identification is given
in section 3. Section 4 discusses the transformation
from periodic to non-periodic domain by pre-operators.
The main theory of three selected methods for steadystate detection is presented and tested in section 5. This
is followed by a conclusion. A theoretical investigation
on parametrization of Discrete Fourier Transformation
(DFT) for the purpose of Total Harmonic Distortion
(THD-based steady-state detection is given in the Appendix.

2

Steady state versus periodic Steady
State Identification

In general, a time-variant system F (x , x , u)=0 , excited by input u or autonomous, may show stable-stationary, unstable-stationary, stable-periodic, unstableperiodic or chaotic behavior of the state variables and
possibly of the outputs. For non-linear systems, the
system may bifurcate into several possible periodic
steady-state conditions (Schupp,2003). For linear differential algebraic systems, a steady-state detection
mechanism may search for the condition
x( t ) x (t  t )=0 or x=0

494

Figure 3: Transient of PT 1 system

13 e

(3)

To display the difference between steady-state and periodic steady-state, Figure 3 shows the output of a very
basic first-order lowpass ( PT 1 ) system, excited by a
unit step at t=0. The system is asymptotically internal
stable and converges to 1. An amplitude of 0.95 may be
seen as quasi steady-state condition, appearing after 3
times characteristic time T.

Figure 4: Transient of AC voltage of small aircraft
electrical network example (original data)

In contrast to this, the transient of phase A of a threephase AC voltage of the aircraft electrical network example is plotted in Figure 4. While it is oscillating, at
the same time, it shows a first-order like transient behavior of the envelope.

3

Overview of methods

The process of signal-based steady-state detection has
remarkable analogies with the theory of fault detection.
The signal-based fault detection observes the behavior
of a system on the change from its nominal (dynamic)
behavior. Steady-state detection basically observes the
behavior of a system on its change from past behavior.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

They differ, as fault detectors generally are designed
offline with specific fault data and models; absolute
values on nominal or faulty conditions are known.
Steady-state observers do not necessarily rely on detailed knowledge of the system. Isermann
(Isermann,2006) classifies methods for single signal
fault-detection into methods with limit or trend checking, and methods with signal models. Limit and
trend checking methods are applicable for measurable
absolute values or measures from statistical observers.
Detection by signal models include correlation methods, spectrum analysis and wavelet analysis. Isermann
(Isermann,2006) defines the basic steps of a scheme for
fault detection with signal models, as preparation and
transformation into signal model, extraction of relevant measures by feature generation and detection of
faults, or by comparison to the nominal behavior in
change detection.
Similar to it, steady-state detection can be separated
into the steps:


Signal model preparation, for periodic systems with removal of oscillation by an operator: The prepared signal can be any property in
time domain, frequency domain or stochastic
property.



Application of test on steady-state: The test itself is based on the signal model.



Decision making: the steady-state decision has
to be made. It is very specific to the system,
where noise and additional dynamics superpose the potential periodic system and the
threshold has to be set based on prior knowledge.

(additive high-frequency noise is not correlated by definition, and should be filtered out from the original signal before, by low pass filtering)
For the steady-state detection, the following methods
attracted attention in research in recent years:
The F-like test- developed first by Cao and Rhinehart
(Cao and Rhinehart,1995) - belongs to the class of index-based change-detection methods1. It relies on statistical methods to identify steady-state in noisy processes. It was tested and expanded on afterwards by
Rhinehart for a multi-variable case (Brown and
Rhinehart,2000). Applications included different processes, especially in chemical engineering. Other
works by Kelly and Hedengren (Kelly and
Hedengren,2013) concentrated on slow varying drifts
in non-stationary processes with application to a windowed signal.

put patterns. Based on this, Jiang (Jiang et al.,2000) developed a method for identification of steps, peaks,
noises, abnormal sudden changes and similar for chemical processes and reciprocally steady-state. The technique is not adapted to on-line steady-state detection.
However, in an independent work, Korbel (Korbel et
al.,2014) developed a steady-state identification for online reconciliation, based on wavelet transform and filtering for real-time data.
THD is a quality criterion, which is a measure of the
distortion of a base oscillation through its harmonics
(multiples). In case where industrial standards demand
testing for a specific maximum THD, the criterion
needs to be evaluated at periodic steady-state condition. When THD is evaluated repeatedly, observation
of convergence of  THD can be used as a direct indicator of the steady-state condition. This definition is industrially sufficient for the purpose of testing of THD.
It was proposed in (Kuhn et al.,2015).
A further method for detecting steady-state is to use
auto-regressive exogenous models with exogenous inputs (ARX). This method allows the SSI by system
identification, where an auto-regressive model is tuned
from the results of simulation or measurements. It is
not based on detailed knowledge of the system equations. The identifiability of the system is checked
where singularities in the model matrices appear in
case of steady-state. Based on this singularity, an index
is proposed (Rincn et al.,2015).
From these methods, the F-like test, wavelet-based
test, THD-based test, and an adaptation of the THDbased test in frequency domain will be discussed in detail in the next sections. The first, due to its popularity
and simplicity. The second, as a promising approach
and to test the new Modelica Wavelet library. The THD
criterion and the adapted frequency-based criterion is
chosen, since it relies on the objective criterion directly. An overview is shown in Figure 5.
Signal under Observation

RMS

Transformation
to baseband

Fourier
transformation

Wavelet
decomposition
Stochastic
F-like test

Stochastic
F-like test

Thresholding

Thresholding

THD

Z-1



Thresholding

Z-1

scaled 

Thresholding

Preparation
of
Signal Model
Application
of test

Decision
making

Figure 5: Overview on applied methods

All methods are tested for detection of steady-state oon
the small electric on-board network example from Figure 1.

Wavelet transformation can be used to analyze characteristics of a specific system and match its specific out1 A F-Test is a detector of the change in variance

DOI
10.3384/ecp17132493

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

495

Periodic Steady State Identification of electrical circuits

4

Mapping of periodic
periodic variables

to

non-

For AC circuits, the method for steady-state testing has
to be capable of detecting periodic steady-state. Either
by itself, or the signal model preparation has to transform it to an oscillation-free measure. The problem can
be overcome by mapping of the periodic signal to a
non-cyclic equivalent and identification with standard
methods. For a system of type (1), knowledge of a
dominating, excited oscillation can be exploited, to
identify the steady-state condition of the AC voltage
signal. The signals main content is a modulation of a
baseband signal xbb and forced oscillation as
x(t)=  {x bb (t ) e

j  base t

}

(5)

plus harmonic content at k base , plus uncorrelated
noise. The minimum periodic cycle is the forced
oscillations time constant T base =2  / base , 2T base in
case of additive odd harmonics, or arbitrary in case of
non-harmonic content.
Equation (4) is not useful to implement, since the condition is only fulfilled for perfect congruence. Instead,
it can be simplified by using a norm x(t ) . The steady
state condition can be identified directly via x(t)<
or
via some more advanced methods on x(t) , listed next.
The test on steady-state can be seen as testing of the
auto-regression of the signal, separated in intervals of
length T . And it is similar to regression testing of two
signals by the use of norms (e.g. (Pollok and
Bender,2014)). The maximum error norm of consecutive periods generates a periodic sampled one-dimensional output:
xme [t ]=max

(

)

x( ) x( T )
 [tT ..t ]
x( )

(6)

The norm is quite efficient, due to its simplicity. Since
it is a norm on signal amplitude rather than energy, it
will penalize sharp discontinuities and noise.
Similar to this and even more easy to implement, by a
rough knowledge of the period, only peak values
within consecutive periods can be selected. The signal
corresponds to sample-and-hold of the peak values
with sample period T . In aeronautical standards, this
is often called the envelope:
xe [t]=

^ .. t )x (t 2 T^ .. tT )
x(t T
^ .. t)
x(t T

(7)

Only one sample is gained within one interval at maximum or in case of application to the absolute value, an
additional sample at minimum. Peak values may be
prone to noise as some electronics, as rectifiers, add
high portions of distortion to the high amplitude part of
a voltage wave.

496

The temporal (time limited) auto-correlation treats
not only minimum and maximum values, but all data
of a period. It normalizes the signal to
t

 x( T ) x *( ) d 

xauto
 [t ]

=

tT

(

1/ 2

tT
2

|x( )| d 

t 2 T
t

) (

1/2

t

t T

2

|x( )| d 

)

(8)

*

 x( T ) x ( ) d 

= tT

(

1/ 2

t

2

|x( )| d 

t 2 T

)

This norm is tolerant to noise and time shifts but highly
prone to incorrect estimation on length of period T .
The temporal auto-correlation measure is similar to the
temporal auto-co-variance  yy of stochastic signals. It
is common to think complex or unmodeled processes
as stochastic processes (Oppenheim,1999), which
opens the field of stochastic data analysis for the
problem. Other coherency metrics on spectrum, energy
and time or phase-shift are listed in (Marple and
Marino,2004).
Alternatively the steady-state condition can be seen as
the steady-state condition of the baseband signal. When
the condition of a cycle is known exactly, it can be
identified by one of the following methods:
AC coupled RMS (Root Mean Square): This method is
best known for power supply networks at a fixed frequency of 50 or 60 Hz. It can be calculated as by MIL
704f, where RMS is the value for one half-cycle measured between consecutive zero crossings of the fundamental frequency component. Information on harmonic contents is lost by the integration.



T

1
2
X RMS =  x(t) dt
T 0

(9)

When the phase angle  is known, mathematical
transformations to phase-fixed reference system can
be applied (e.g. dq0/Park system or Fortescue transformation): For simulation, the phase angle is known. For
real electrical systems, for single synchronous generator fed networks, it can be obtained by measuring a
machines angular position. Without position measurement, the phase can be derived from the AC voltage by
Phase Locked Loops (PLL). A PLL is a control circuit
which generates an output signal in proportion to the
phase difference of a reference signal to a measured
signal. It can be used to adapt the frequency and phase
of an observer to the measured signal (Krause et
al.,2002).
Alternatively, the base band and harmonics can also be
identified by frequency selective filtering: Signals can
be analyzed in the spectral domain, where the base fre-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

quency is usually associated with the spectral content
of maximum amplitude. The frequency spectrum can
be computed as the correlation of the signal with theoretically infinite sinusoidal waves at certain frequencies
(Fourier transformation) or the correlation to finite
wave packages at prevailing base frequencies (wavelet
transformation (Mallat,2008)). For wavelet transform,
one has to distinguish between direct application on sinusoidal signals and application on the pre-processed
oscillation-free signal. For finite signals, the Fourier
transformation is called Short Time Fourier Transformation, which can be implemented efficiently using
Fast Fourier Transformation (FFT) (Cooley and
Tukey,1965).

5

Implementation and validation of
tests

In the following section, the selected theories of Steady
State Identification are summarised and the steadystate monitors are tested through experiments.
5.1 F-like test
The F-like test, by Cao and Rhinehart (Cao and
Rhinehart,1995) is based on statistical measures. The
algorithm tests a signal on showing settled distribution
at an associated level of significance. Possible distributions are uniform and Gaussian distribution. Measures
are variance between data, moving average value and
variance in the data itself. This method relies on sampled data.
The following steps can be implemented at low computational effort: First, the sampling vector is filtered by a
filter factor of  1 .
X f [i]= 1 X [i]+(1  1)X f [i1]

The formula includes a moving average filter with factor  3 . This second variance var 2 is given by:
var 2 [i]=

 f [i]
2

2

(14)

Finally, the Steady State Identification index R is obtained as the ratio of the two variances:
R=

(2 1 ) v f [i]
 f [i ]2

2

(15)

While R is a continuous measure, decision making
needs tuning of a threshold R t to distinguish between
steady-state R <R t and non steady-state R >R t . Filter
values have to be tuned to match the time constants of
the system under observation. Some more theoretical
considerations on correct and incorrect identification of
steady-state are given in (Cao and Rhinehart,1995),
with respect to different types of error signals.
In a first trial, the F-like test was applied directly on the
sinusoidal phase voltage. No useful results could be
gained (not plotted), which can be explained by the
strong correlation of the sinusoidal shaped signal.
Therefore, isolation of the signal of interest had to be
conducted first. For this example, simulation results
did not show significant difference between several
methods of RMS detection. Those are transformation
by phase angle, integration over one period with start
and end conditions identified by zero crossing detection, and peak-value detection. Figure 7 (top plot)
shows the source signal of the test. The AC voltage is
mostly settled after 0.1 seconds simulation time with
an additional step of 10% at 0.3 seconds.

(10)

Where X [i] are sampled data, X f [i] are filtered values and  1 is a filter factor. In the second step, a measure of the variance v 2f is computed with a moving average filter factor of  2 :
2

2

2

v f [i] = 2 ( X [i] X f [i1 ]) +(1  2) v f [i1]

(11)

The unbiased estimate of the variance based on the filtered squared deviation from previous filtered values
var 1 is given by:
2

v [i ]
var 1 [i ]=(21 ) f
2

(12)

A measure on the second filtered variance estimate  2f
is calculated based on the filtered square differences of
successive data:
2

2

2

f [i] = 3 ( X [i] X [i1 ]) +( 1  3) f [i1 ]

DOI
10.3384/ecp17132493

(13)

Figure 6: R index of F-like test for several sampling
rates; input signal see Figure 7, top diagram

The influence of different types of sampling, and therefore different dominating noise on identification index
R, can be seen in Figure 6. The plots present the results
of the F-like test, applied on the same source data but
with regular sampling intervals 6f and 24f, and irregular sampling around 6f and around 25f. The lambda
factors were tuned manually.
It can be clearly seen that the quality of the results diverge on a significant scale. The results based on the 1f

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

497

Periodic Steady State Identification of electrical circuits

sampling show some slow transient behavior, which is
hard to interpret. In contrast, 6f and 24f sampling
clearly identify changes. The R statistics show low
pass behavior at steps of the input signal. A decision
value on steady-state can be set but needs to deal with
the chattering around the boundary value R t .

steady-state condition as a local extremum where first
and second time derivative being zero, single and double wavelet transform can be applied. At a (local) minimum, the conditions

5.2 Wavelet test

must hold true. Similarly, for steady-state detection in
the time domain, specific scaling of the  would be
necessary. Where an ideal temporal derivative function
is unspecific of the frequency and a Fast Fourier Transformation based spectral decomposition lacks information on the temporal variation, a wavelet can be
adapted to the characteristic scale. This means, the
frequency of the wavelet is chosen close to the characteristic response time  of a system which acts as a
kind of a bandpass filter. This can be realized by the
sampling frequency directly, or iteratively by fragmentation into a wavelet spectrum with narrower bands of
equation (16) which is called multi-resolution representation or alternatively Jiang (Jiang et al.,2000) calls
it multi-scale process data analysis.

In wavelet analysis, the one-dimensional time variant
input signal is decomposed into time variant subspaces
with bandpass characteristics. By iterative wavelet
multi-level decomposition, the original signal f (t ) is
projected into a sequence of nested subspaces; each
subspace is characteristic for a spectral content, similar
to the indices of the Discrete Fourier Spectrum:
J

f (t )= c J , i  J , i +  d j , k  j , k
i I j

(16)

j=1 kk 1

The first sum represents low frequency content, while
the right part represents higher frequency content. The
wavelet spectrum originates from iterative bisection of
the high-frequency signal up to scale J .  j (t) are
scaled mother wavelets which define orthogonal
spaces. Filtering of a signal corresponds to variation
and limiting of its wavelet coefficients c j, i and d j , i .
Adaptive methods for filtering of Gaussian noise exist
in many wavelet toolboxes. The filtered signal in the
time domain can be restored by inverse transformation
of the conditioned data. Formulas for discrete wavelet
transformation are similar.2
Similar to the F-like test, this method needs separation
of the fundamental of the amplitude- modulated wave
first. While this can theoretically be done by an additional wavelet transformation, there is no benefit compared to the RMS method presented before. Next, the
signal can be de-noised if necessary. Jiang (Jiang et
al.,2003a) proposes to separate the baseband signal into
the desired process trend T(t) and process noise N(t),
by wavelet multi-level decomposition, filtering and reconstruction. Any other type of continuous or discrete
filters may be used equivalently. Although the signal
will suffer from a frequency dependent group delay by
the filter, for steady-state detection, this can be seen as
negligible compared to the typical time scales.
The wavelet-based detection itself uses the fact that a
wavelet transform Wf (t) of a signal f (t ) is proportional to the time derivative of the signal smoothed by
the scaling function  (see wavelet theory for details):
W f (t )=2

d
( f )( t )
dt

(17)

Furthermore, by the wavelet transform of the wavelet
transform WWf (t ) one gets an analogon to the second-order derivative. Analogue to assumption of a

Wf (t )< w 1 , d (Wf (t ))/ dt < w2 .

(18)

The steady-state index (t ) is calculated from equations (19-21), where (t ) is a factor of combined contributions from the first and second order wavelet and
(t ) is an amplitude-limiting signal operator on the
second order wavelet transform.
(t )=|Wf (t )|+ (WWf (t))

{

0
(WWf (t ))= (|WWf|T w )/ 2T W
1

(19)

,|WWf |T W
,|WWf|{T W , 3T
(20)
w}
,|WWf|3T W

 itself calculates as a threshold comparator from the
contributions factor (t) , with smoothed transient
from 0 to 1.

{

0

[ (

, (t)T u

) ]

(t )T s
(t)= 1 cos
 +1
2
T uT s
1

,T s <(t)<T u

(21)

,(t)T s

Where T s =standard deviation of Wf , T u = 3T s , T w
=median ( WWf ). In  , zero indicates unstable
status and one steady-state condition. For details, see
(Jiang et al.,2003b) and for advanced end-of-steadystate-detection see (Korbel et al.,2014).
(Jiang et al.,2003b) demonstrates steady-state detection
but does not focus on online implementation. It may
look straightforward to perform the analysis continuously on a window of past samples. Practical implementations for this thesis showed the correct choice of
the limits T s , T u and T w often fails when considering only one window. The median especially moves
quite arbitrarily. Therefore, limits are calculated noncausally by using the full data set. This proves the con-

2 For background on wavelet analysis, one may see Debnath (Debnath
and Shah,2002), section Wavelet bases and Multiresolution Analysis.

498

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

siderations of Korbel (Korbel et al.,2014) who proposes to choose the limits from past measurements.
To implement the wavelet test, the Modelica wavelet
library (Gao et al.,2014) was used. The library is similar to MATLABs wavelet toolbox. Since the Modelica
wavelet library does not support online computation
yet, this study is an offline demonstration only. The library can be developed further for online computation,
if issues regarding the initialization of buffers, data
storage and allocation of vector sizes of intermediate
variables are solved. Furthermore, the plotting relies on
Dymola-specific Modelica scripting.
The test makes use of the interpolation routine, definition of a wavelet function and the discrete wavelet
transform:
Wavelet.General.interpL()
Wavelet.Families.wavFunc(Wavelet.Records.wa
vletDefinition());
Wavelet.Transform.dwt());

Results of the test are displayed in Figure 7: From the
original signal, the RMS value is calculated via Park
transformation using generator angular information.
The RMS value is processed by first and second order
wavelet transformation. They show a clear relationship
to the temporal derivatives.  is calculated via formulas 19-21. The first steady-state condition is detected at
around 0.05 seconds. This assumption is based on the
limits T s , T u and T w and may be changed by different settings.
In summary, the wavelet-based method identifies the
steady-state condition of the base harmonic well for the
example. The signal can not be processed directly but
has to be transformed to a non-periodic representation
(RMS). The time scale for the wavelet transform and
the limits need to be adapted to the model, based on
known prior results. The computational efficiency has
to be questioned critically for the wavelet transform. It
may be improved in a future, real-time capable implementation of the Modelica library, by use of fast wavelet algorithms.
5.3 Discrete Fourier transformation based THD
criterion
In (Kuhn et al.,2015) a Total Harmonic Distortion
based steady-state detector was proposed. Its signal
model relies on the Fourier spectrum. According to
(Isermann,2006), Fourier spectra are well suited for
identification of periodic, stochastic, and non-stationary properties, and therefore for periodic Steady State
Identification.
In a first step, a vector of sampled data of the input signal is decomposed into a discrete amplitude-frequency
spectrum by a short time Discrete Fourier Transform
algorithm. THD is calculated from the spectrum by 3

Figure 7: Wavelet based test, results

3 e.g., IEEE Standard 519-2014 (IEEE,2014)

DOI
10.3384/ecp17132493

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

499

Periodic Steady State Identification of electrical circuits

THD=



M

2

 A [ hf base ]
h=2

A [ f base]

(22)

2

It is a one-dimensional norm on the M1 amplitudes
of the harmonics, which is normalized by the amplitude of the base frequency. The phase information and
DC component is not considered.
Finally, the steady-state test is designed as a normalized trend checking, based on  THD :
|THD( t x )THD(t x Np )|
yTHD =
max(THD , )
?

(23)

y THD <  steady state

The criterion relies on consecutive evaluations of the
spectra at times t x and t x + T . Each evaluation is
based on data sets of length N [s] . The time delay between the two THD windows is defined in proportion
p of the data set length, where an overlap of 50% is
proposed for the data sets. Theoretical consideration
are derived in section 7.  prevents division by zero
and influence of noise at small values of THD . While
THD could be evaluated at every sampling interval, for
efficiency reasons, the Modelica algorithm is only
evaluated every Np . When the frequency resolution
is set to 1/ rf base , the total data set length is
(1+ p )rT base and evaluated no later than prT base after an event. Example: r=4 p=1/2 criterion evaluation not later than in 2T base , based on data set length=
6T base .
The main features of the implementation by the Modelica block WithinAbsoluteFFTdomain_THD were already discussed in (Kuhn et al.,2015). It is a big advantage of this method, that the AC signal can be taken directly as an input. There is no need for pre-processing
as RMS or transformation to base band. While the expected base frequency should be given roughly, the
Modelica-based algorithm can tune itself to the dominating peak in the nearby-spectrum. Also, the block
features the option to use the criterion as an indicator
for termination of simulation; the THD is delivered as
a final result at this steady-state condition. No extra
FFT computation is necessary for this, as the computa-

tion of THD and THD-based steady-state criterion rely
on the same FFT data.
The THD-based criterion was tested with the small grid
example. Here, the criterion could NOT identify
steady-state condition. This shortcoming can be better
understood from the plot of the THD in relation to
V rms . in Figure 8, rather than the criterion itself.
As can be seen in the upper plot, the THD is not correlated with the main trend, even at steps. This is a special property of the small grid example. There exist
higher harmonics because of the rectifier, but they are
in fixed proportion to the base harmonic with fast and
well damped filter dynamics on the DC side. Therefore, normalization of THD by the base amplitude prevents a change of the criterion in this case. Furthermore
it can be proven easily, it gives the same THD if a 
on one harmonic amplitude compensates for the amplitude on other.




THD(t 1)=

2

2

A 1 +A 2 +...
Ab
2

(24)

2

( A 1 + 1 ) +( A 2 2) +...
=THD(t 2 )=
Ab

With proper choice of  1 and  2 . Strictly speaking,
for the THD identification according to industrial standards, no real steady-state condition would be necessary here, as the THD does not change. But since it is
not a proper indicator, it is not generally recommended.
But it can be adapted to overcome the obstacles as
shown next.
Adapted discrete Fourier Transformation-based criterion
In order to overcome the problems of the THD-based
steady-state monitor, the new THD-similar criterion
is proposed:
yTHD similar =
max

(

2

2

| A [ hf base [t x ]]| | A [ hf base [t x + T ] ]|
2
2
|A [ f base( t x)]| +|A nom|

)

(25)

 h [1.. M ],
?

y THD similar <   steady state

It is also based on the DFT spectrum and is inspired by
the THD criterion, maximum error norm and variation
in base amplitude. In contrast to THD, also the first
(=base) harmonic is considered. An educated guess of a
factor  of the nominal base amplitude A nom prevents
division by zero and smooths the result. The decision
threshold  has to be set based on knowledge from
past results.
Figure 8: Investigation on spectrum: THD vs. signal (FFT
window 0.017s)
500

The criterion and parameterization of FFT is discussed
in detail in section 7. It is shown, that this criterion is
well suited for identification of steady-state of dynamic

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

systems (1), where unmodeled dynamics are treated as
uniform noise.
The implementation of the function is based on WithinAbsoluteFFTdomain_THD, with the same parameters
unless stated otherwise. It shares the benefits with the
THD approach, with little simulation overhead through
the efficient FFT algorithm. As soon as steady-state is
detected, the test on conformance with the standards on
THD can be performed. The quality test is based on the
same FFT data without need for an additional FFT calculation. Results analogue to Figure 6 are shown in
Figure 9.
crit []

delta [ ]

0.08
0.04
0.00
0.00

0.04

0.08

0.12

0.16

0.08

0.12

0.16

0.20

0.24

0.28

0.32

0.36

0.40

0.20

0.24

0.28

0.32

0.36

0.40

V_rms[V]
200

0
0.00

0.04

simulation time [s]

Figure 9: Investigation on new steady-state criterion vs.
signal (FFT window 0.017s)

It can be seen that the steady-state condition is found
reliably, with proper detection of the initial transient
period. The change in amplitude at 0.3 seconds is detected shortly after the event.
Generator, phase current
100
0
-100
0.00

6

Conclusion

In this paper, procedures for Steady State Identification
were tested with an AC electrical circuit, with dominant main amplitude and harmonic distortion, and a
second example. Both methods from literature demand
a mapping of the periodic to non-periodic signals. The
F-like test showed good performance and short delays.
However, it was difficult to parameterize, and detection
was weak. The wavelet-based test was very successful,
but computational overhead and delay is high. Alternatively, an experiment based on a variation of THD was
tested. The monitor can treat the periodic signal directly, at medium computational overhead. The delay is
high but it can be seen as not critical, since evaluation
of THD in steady state is requested. This criterion was
not able to detect a transient period, where the signal
had a fixed ratio of the base amplitude and harmonics.
The THD-similar criterion was designed to also consider the base. Tests were very promising, at medium
efficiency and medium delay. Due to its generality and
efficiency, this method is proposed as the best choice
for the application. The results are summarized in Table 1. Any generalization of the methods demands an
investigation with more examples.
Test

0.04

0.08

0.12

0.16

0.20

0.24

0.28

F-like test

F-like

4

2
0.00

tion. In contrast to this, the beta parameter of waveletbased test and THD and THD-similar criterion detect
the event reliably, with high signal-to-noise ratio.

0.04
THD test

0.08

0.12

0.16

0.20

0.24

0.28

THD similar test

0.2

Quality of
SSI for the
examples
bad

Pre-operator
needed for
AC

Delay

Computation
Efficiency

yes

Short

high

Wavelet based Very good

yes

high

low

THD criterion Only partial

no

Medium-high Medium, low if
THD is needed

THD-similar
criterion

no

Medium-high Medium, low if
THD is needed

good

Table 1: Evaluation matrix of proposed methods

0.0
0.00

0.04

0.08

0.12

0.16
simulation time [s]

0.20

0.24

Acknowledgements
Some preliminary studies were performed together
with Mr. Mohamed Jmari, who did an internship at
DLR as part of his studies at ENSMM, Besanon,
France.

0.28

wavelet based test
1
0
0

25

50

75

100

125

Valuable input was given by K. Chong.

Points

Figure 10: Identification of steady-state, based on real test
data

Lastly, all methods are tested with an example based on
hardware tests. The top plot in Figure 10 shows the
measurement data of a generator connected to an electrical-driven Wing Ice Protection System (WIPS). The
load is increased at 0.15seconds. It can be seen that the
F-like criterion detects the event, but the output is
noisy although care was taken for proper parameterizaDOI
10.3384/ecp17132493

7

Appendix: parametrization of FFT
and derived measures for detection
of steady-state condition

The following section builds on the results in (Kuhn et
al.,2015) and goes into deeper discussion on the parameterization of the Discrete Fourier Transformation
needed for THD evaluation, and their influence on
steady-state detection. Use of Discrete and Fast Fourier
Transformation itself is not discussed here but (Kuhn et

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

501

Periodic Steady State Identification of electrical circuits

The FFT algorithm for use by THD calculation is well
parameterized by


The expected base frequency f base and number of harmonics demanded nharmonics ; the
maximum frequency in the spectrum f max , FFT
needs to be well above the highest treated harmonic: f max , FFT >nharmonicsf base , where sample
frequency f s =1 /T s =2f max , FFT



The type of window function, (e.g. rectangular, Hamming or Butterworth)



The window length N=nsT s=1 / f resolution ,
with the spectral resolution f resolution and the
number of sample points ns

(proper anti-aliasing by a low-pass filter is assumed).
Windows transfer the theoretical unlimited data set
to finite length by selection of N samples, where the
signal is multiplied by the window function before
DFT. Such a window function starts near or at zero,
then increases smoothly to a maximum at the center of
the time series and decreases again (see Figure 11 for a
Hamming window). The theory of DFT implicitly postulates that the input is periodic, where any waveform
must repeat itself after the window of sampled signals.
This means, for signals with sinusoidal content, the
Fourier spectra of temporal consecutive windows coincide: if the windows are of length l pT p , and time
shifted by r pT p ; with arbitrary integer numbers l p
and r p , and wavelength T p for each sinusoidal content p .

50 100 150
Samples

Magnitude (dB)

Amplitude

Time domain
1
0.8
0.6
0.4
0.2
0

200

50
0
-

50

100

-

Frequency domain

0 0.2 0.4 0.6 0.8
Normalized Frequency
( x  rad/sample)

Figure 11: Hamming window

In the following, the properties of the spectral analysis
are discussed with the purpose of steady-state identification. For better understanding, Figure 12 shows two
spectra of the voltage transient of the small aircraft
electrical network example: The amplitudes spectrum
on the initial transient phase (red) differs from the
spectrum of the settled phase (blue) in amplitude and
distinctiveness of the peak (a sinusoidal oscillation of
infinite length would result in a distinct Dirac impulse).
The example shows that the spectra clearly differ and
can be used for distinction of steady-state and non
steady-state.
400
Amplitude

al.,2015) gave a practical approach to the generation of
Fourier spectra in Modelica.4 Computation of FFT
might sound numerically demanding, but efficient routines are available as public domain software, or as
proprietary software down to chip-optimized routines
from Intel and AMD. Cyclic FFT can evaluate the FFT
at each sampling step, where results from earlier computations can be reused rather than freshly computated.
For practical reasons, one may not evaluate the FFT
and THD at every sample, since the convergence of the
signal may happen within some AC periods, but not
within some sampling intervals.

300
200
100
0
-100

0

1000
2000
Frequency in [Hz]

Figure 12: Voltage spectrum of small aircraft electrical
network example, with dominant signal
sin (2pi360 Hz) ; blue: spectrum of period [0..0.2s],
red: spectrum of period [0.2..0.4s],

The spectrum can be affected by:


a) Smearing of peaks, from non-periodicity
(energy conservation by Parsevals theorem)
or mismatch of period by window length,



b) Spectral leakage, from convolution of the
spectrum  by the windows spectrum W



c) Band restricted variation and smearing of
peaks, from unmodeled dynamics

Case a) might be used as an indicator for the variation
of the wavelengths, where non-integer l p distort the
spectrum. This is not recommended. The exact finding
of the wavelength or phase information is highly prone
to errors. Instead, the discontinuity can be removed by
application of a non-rectangular window (Henning
etc.)
Case b) can be seen a requirement on the shape and
length of the window function. For better understanding, the effect of windowing is demonstrated in Figure
13. It shows the windowing the input signal  (grey
peaks) by rectangular window (blue) and a flattop
window (green). The width of the window in frequency
domain is indirectly proportional to its length in time
domain. The window type itself is characterized by the
peak flatness (3dB bandwidth) and peak level of the
sidelobes (see overview of window types in (Heinzel et
al.,2002)).

4 In the meantime the underlying FFT algorithm found its way into the
Modelica standard library 3.2.2 as tool independent implementation
Modelica.Math.FastFourierTransform.realFFT()

502

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

0 e

5 e



7 e

11e

13 e

Figure 13: Influence of windowing and sampling
 ( j ) (grey): Dirac peaks in continuous Fourier
domain, e.g. from sine and cosine
Y ( j ) (blue): convolution of rectangular window
with  ( j )
Y ( j) (green): convolution of flattop window with
( j)

The convolution of the window with the signal in frequency domain is:
j

Y (e )=



1
  (e j) W ( e j())d 
2  

(26)

The following requirements result, to distinguish tight
steady-state and wider non steady-state spectra  of a
signal of type (1):
1) The DFT has to resolve the individual baseband signals of the spectrum, without overlapping caused by the window; (e.g. in Figure 13,
the adjacent blue wave packs shall not merge).
The window type and length nsT s have to be
chosen with focus on their broadening and
height of sidelobes.
2) The steady-state and non-steady-state condition in the basebands of  , need to have
distinguishable amplitudes in discrete Y as
well: The discretization of (26) at a given sampling rate f s results in
Y [k ]= Y (e )| =(2 / N)k

,
1
j
j( )
=
(e ) W (e
)d 

2  
 =(2 / N )k
k=0.. N1

amplitudes, in case of a frequency mismatch of signal
and discretized frequency; but overlapping and
visibility of narrow banded effects had to be prevented
by high spectral resolution and therefore be paid by
large window lengths.
Case c) is by wide the most interesting effect. Steady
-state identification can be based on prior knowledge,
with measures from a single spectrum. Measures are
the amplitudes of the main peaks, or their (3dB)
widths, or their amplitude to width ratio, or the ratios
of the main peaks. Or it can also be based on the
temporal change of these measures. For this work, we
assume there is little information on the spectrum
given. Furthermore, there is no need to tune the
algorithm for a special spectral shape, since any
distinct change is seen as non-periodic condition.
Instead, a measure is proposed based on the variation
of the noise from unmodeled dynamics.
In the 1970s a method called Welchs method of
averaging modified periodograms was developed to
improve the accuracy of periodograms. Periodograms
are estimates of the spectral density of a signal. In this
context, modified means the window is not of type
rectangular. According to (Oppenheim and
Schafer,1998), the estimate r , of a sequence of K
periodograms is given by
1
j 2
I r ()=
|Y ( e )|
(29)
NU r
, where estimates are based on non-overlapping data
segments of length N , which are taken from a total
data set length Q by a window. The correction factor
U normalizes the amplitudes of the windows (if not
already included in Y r ):
N1

U=

1
 (w[n ])2
L n =0

Averaging of the K estimates results in the averaged
periodogram

j

I ( )=

k

|

(27)

k

2) is similar to 1), but includes a further demand:
Y [k ] may not be undifferentiated for the shapes of 
with the same local area c:
(2  /N)(k +1/ 2 )



j

(e )d =c

(28)

(2 / N )(k1/2)

. This can be the case with flat top windows which
makes them not favourable for the purpose of
identification of band restricted disturbances: They
exhibit broad peaks, with 3dBwidths starting from 2.9
bins. This gives them an approximate characteristics of
j
W ( e )=1 in the interval around a discretized angular
velocity k =(2 / N) k1 /2 (called bin). This
certainly has benefits for the correct identification of

DOI
10.3384/ecp17132493

(30)

1
K

K 1

 I r ()

(31)

r =0

, respectively
I [k ]=

1
K

K 1

 N1U |Y r [k ]|

2

(32)

r =0

of a discrete spectrum. In case the properties of the
signal remain stationary, and noise is additional and
uniformly distributed, the variance of I ( ) is reduced
by a factor of 1/ K (Heinzel et al.,2002). Welch
(Welch,1967) proved that other types of windows may
be used with similar reduction in variance (modified
periodogram). Also he found, that HALF-overlapped
windows (see Figure 14) reduce the variation in the
spectral components approximately by an additional
factor of 2, if this increases the number of windows on
the data. More than 50% overlap usually gives no
additional benefit, since the cross-correlation of the
windows grows. Detailed considerations on the optimal

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

503

window

Periodic Steady State Identification of electrical circuits

overlap
Figure 14: Segmented signal, with three windows and
50% overlap

usage of the information in relation to window overlap,
are summarized in (Heinzel et al.,2002). The author
lists 33 types of windows with amplitude flatness and
power flatness in relation to overlap correlation.
Results clearly show, that an overlap of 50% is a good
choice for all windows except the flat top windows.
By Welchs method it is possible to get better, unbiased
estimates of the spectrum, and therefore better inputs
for THD calculation. Additionally, with the data of the
periodogram (32), the standard deviation of the
estimate can be computed with little extra effort. It is
possible to construct an F-like test upon these
measures, where transition to steady state can be
associated with decreasing noise, and therefore
decreasing standard deviation. This is not
recommended since the large data vector would effect
a substantial delay in the steady state detection.
Instead, an indicator named `randomness' (Heinzel et
al.,2002). is more applicable. It is the ratio of the
standard deviation to the averaged estimate of the
signal, that dominates the frequency bin under
consideration. Randomness is near unity for
stochastic signals such as noise, and small for coherent
signals such as sinusoidal wave:
( I [k])
 randomness =
(33)
E( I [k ])
This randomness criterion is proposed as base of the
THD-similar steady-state detector. Since reduction of
delay is of highest interest, the set of input data must be
kept short. This directly results in a number of 2
windows, with an overlap of 50% (more windows
might be used to filter noise). The choice of only two
windows transforms the ( I [k ]) operator into a
( I [k]) operator. ( I [k]) is evaluated per bin [k]
. Since any variation can be seen as non steady-state,
it is sufficient to map the data vector to a single value
by a maximum norm. (Euclidean norm might work as
well, with smoother output). The criterion can be made
less prone to noise if the variances [k] are normalized
by the expectation value of the main amplitude, rather
than the expectation value [k]. This results in
yrandomness=max

504

(

2

2

|A [ k[t x ]]| | A [ k [t x+ T ]]|
2
|A [ k base(t x )]|

)

k

The SSI delay needs to be kept to a minimum, where
delay is proportional to the window length, which in
turn is proportional to the resolution of the DFT
spectrum. The minimum delay is attained, when each
band restricted variation is included by one bin each,
but the window is not flat top whilst the resolution is
high enough to prevent overlap with the adjacent
harmonic by the window. Since we assume that all
non-steady-state-caused distortion is centered around
the base-frequency and the harmonics, the set of all k
in criterion (34) can be limited to all bins which
represent a harmonic of f base . With the usual notation
of expressing the number of the bins by their
equivalent frequency, the k s in (34) are replaced by
k=hf base , with h=[1.. M ] . Inserting an additional 
in the denominator to prevent division by zero and
influence of noise directly results in
yTHDsimilar =
max

(

2

2

| A [ hf base [t x ]]| | A [ hf base [t x + T ] ]|
2
2
|A [ f base( t x)]| +|A nom|

)

(35)

 h[1 .. M ]

The windows of type Bartlett, Hamming or Hanning
are especially recommended due to their small 3dB
peak width of 1.2736,1.3008 and 1.4382 bins. For
these windows the resolution of the spectrum should be
at least 1/3f base to prevent overlap.

(34)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132493

Session 7C: Electrical & Power Systems II

References
Bnte, T.. Recording of Model Frequency Responses and
Describing Functions in Modelica, Proceedings of the 8th
International Modelica Conference , 2011.
Brown, P. R. and Rhinehart, R. R.. Demonstration of a
method for automated steady-state identification in
multivariable systems. Hydrocarbon processing 79:79-83,
2000.
Cao, S. and Rhinehart, R. R.. An efficient method for on-line
identification of steady state, 5:363 - 374, 1995.
Cooley, J. W. and Tukey, J. W.. An algorithm for the machine
calculation of complex Fourier series. Math. Comput.
19:297-301, 1965.
Debnath, L. and Shah, F. A.. Wavelet transforms and their
applications. : Springer, 2002.
Demiray, T.. Simulation of Power System Dynamics using
Dynamic Phasor Models. Ph.D. thesis, ETH Zurich, 2008.
Gao, J., Ji, Y., Bals, J. and Kennel, R.. Wavelet library for
Modelica, Proceedings of the 10th International Modelica
Conference; March 10-12; 2014; Lund; Sweden , 2014.
Heinzel, G., Rdiger, A., and Schilling, R.. Spectrum and
spectral density estimation by the Discrete Fourier
transform (DFT), including a comprehensive list of
window functions and some new at-top windows.. , online.
http://www.rssd.esa.int/SP/LISAPATHFINDER/docs/Data
_Analysis/GH_FFT.pdf., 2002.
IEEE. Recommended Practice and Requirements for
Harmonic Control in Electric Power Systems. IEEE Std
519-2014 (Revision of IEEE Std 519-1992) :1-29, 2014.
Isermann, R.. Fault-diagnosis systems: an introduction from
fault detection to fault tolerance. Springer (Ed.). : Springer
Science & Business Media, 2006.
Jiang, T., Chen, B. and He, X.. Industrial application of
Wavelet Transform to the on-line prediction of side draw
qualities of crude unit. Computers & Chemical
Engineering 24:507-512, 2000.
Jiang, T., Chen, B., He, X. and Stuart, P.. Application of
steady-state detection method based on wavelet transform.
Computers & Chemical Engineering 27:569 - 578, 2003b.
Kelly, J. D. and Hedengren, J. D.. A steady-state detection
(SSD) algorithm to detect non-stationary drifts in
processes. Journal of Process Control 23:326-331, 2013.

DOI
10.3384/ecp17132493

Korbel, M., Bellec, S., Jiang, T. and Stuart, P.. Steady state
identification for on-line data reconciliation based on
wavelet transform and filtering. Computers & Chemical
Engineering 63:206-218, 2014.
Krause, P. C., Wasynczuk, O. and Sudhoff, S. D.. Analysis of
Electric Machinery and Drive Systems. : WileyBlackwell,
2002.
Kuhn, M. R., Otter, M. and Giese, T.. Model Based
Specifications in Aircraft Systems Design, 11th
international Modelica Conference , 2015.
Kuhn, M. R., Rekik, M. and Bals, J.. Modelling and Use of
an Aircraft Electrical Network Simulation for Harmonics
Consideration in Generator Design, SAE Technical Paper ,
2012.
Mallat, S.. A wavelet tour of signal processing: the sparse
way. : Academic press, 2008.
Marple, S. L. and Marino, C.. Coherence in signal
processing: a fundamental redefinition, Signals, Systems
and Computers, 2004. Conference Record of the ThirtyEighth Asilomar Conference on 1:1035-1038 Vol.1, 2004.
US Department of Defense. Aircraft electric power
characteristic.
http://www.wbdg.org/ccb/FEDMIL/std704f.pdf, 2004.
Oppenheim, A. V.. Discrete-time signal processing. : Pearson
Education India, 1999.
Oppenheim, A. V. and Schafer, R. W.. Zeitdiskrete
Signalverarbeitung. : Oldenbourg Wissenschaftsverlag,
1998.
Pollok, A. and Bender, D.. Using Multi-objective
Optimization to Balance System-level Model Complexity,
Proceedings of the 6th International Workshop on
Equation-Based Object-Oriented Modeling Languages
and Tools :69-78, 2014.
Saber. Integrated Environment for Physical Modeling and
Simulation.
Synopsys,
I.,
www.synopsys.com/prototyping/saber., 2016.
Schupp, G..
Numerische Verzweiungsanalyse mit
Anwendungen auf Rad-Schiene-Systeme. Ph.D. thesis,
Universitt Stuttgart, 2003.
Welch, P.. The use of fast Fourier transform for the
estimation of power spectra: A method based on time
averaging over short, modified periodograms. IEEE
Transactions on Audio and Electroacoustics 15:70-73,
1967.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

505

506

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Discrete-time models for control applications with FMI
Rdiger Franke1

Sven Erik Mattsson2 Martin Otter3
Karl Wernersson2
Lennart Ochel4 Torsten Blochwitz5

Hans Olsson2

1

ABB, ruediger.franke@de.abb.com, 3 DLR, martin.otter@dlr.de,
Dassault Systmes, {svenerik.mattsson, karl.wernersson, hans.olsson}@3ds.com,
4
Uni Linkping, lennart.ochel@liu.se, 5 ESI ITI, torsten.blochwitz@esi-group.com

2

Abstract
The paper proposes an extension of FMI 2.0 for the rigorous treatment of discrete-time models. This includes
the introduction of discrete-time states, the declaration
of clocks in the model description and an extension of
the calling interface for the external activation of clocks
by an importing environment.
The synchronous discrete-time extension enables for the
first time the synchronization of FMUs with the environment and with other FMUs. It specializes the existing
generic event mechanism of FMI 2.0 and maps to synchronous features of Modelica.
Discrete-time FMUs are needed for the generation of
controller code from functional models. This paper outlines different use cases, including a simple PI controller, feed forward control with a nonlinear inverse model
and nonlinear model predictive control.
The FMI change proposal FCP-001 and the Modelica
change proposal MCP-0024 describe the proposed extensions in more detail. Test implementations exist in the
simulation tools Dymola and OpenModelica and in the
importing optimization solver HQP. The use cases given
in this paper served for further refinement of the change
proposals and the test implementations.
Keywords: Modelica, Synchonous modeling, Inline Integration, Model-based Control, Nonlinear Inverse
Model, Feed Forward Control, NMPC.

1

Introduction

Control systems are composed of interconnected control
blocks that must synchronize with each other and with
real time. This requires precise time event handling and
discrete states.
Modelica 3.3 extends the scope from a language primarily intended for physical systems modeling to modeling
of complete systems. In particular, new synchronous
language primitives were introduced for increased correctness of control systems implementation (Elmqvist et
al, 2012).
DOI
10.3384/ecp17132507

Version 2.0 of the FMI standard omitted precise time
event handling. The design was considered complicated
at the time of the release of FMI 2.0 since several aspects
have to be considered (Blochwitz et al, 2012):
 The synchronous features of Modelica 3.3
should be supported.
 FMI should also be useable by tools that do not
support synchronous time event handling.
 The time event handling is to be defined in a
way that allows backward compatible extensions.
This paper discusses the progress made recently. The
work resulted in a new version of the FMI change proposal FCP-001 (Otter et al, 2016) and in the Modelica
change proposal MCP-0024 (Franke, 2016). This paper
summarizes the change proposals, provides use cases
and investigates examples using test implementations in
the simulation tools Dymola and OpenModelica and in
the optimization solver HQP (Franke and Arnold, 1997).

2

Synchronous Modelica

Modelica has always supported continuous-time variables and discrete-time variables defined as piecewise
continuous and piecewise constant functions of time, respectively. Both may change discontinuously at time instants, so called events. Events are treated at runtime.
The synchronous features of Modelica 3.3 introduce a
new Clock type. Clock variables c(tk) are special discrete
variables that are active (are ticking) at particular time
instants, see Figure 1.

r(tk)
c(tk)
t0

t1

t2

t3

time t

Figure 1: Clock variable c and clocked variable r

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

507

Discrete-time models for control applications with FMI

A clocked discrete-time variable r(tk) is associated with
exactly one clock. This enables the partitioning of a
model into sub-models for each clock at translation time.
A clock defined for one variable of a partition automatically propagates to all other variables of this partition.
This enables generic discrete-time models with inferred
sample times.
A clocked discrete-time variable only has a value when
the clock ticks. Continuous-time variables may be converted to clocked variables with the sample operator. A
clocked variable may be converted to a continuous-time
variable with the hold operator.
A clocked partition is mathematically defined as:
  =   ( 1 ,  ,   ),

 = 0,1,2,  ,   1,
 1 = 
(1)

  =  ( 1 ,  ,   ),  = 0,1,2,  , 

(2)

Here   are discrete-time states,  are inputs,   are
outputs, k is the k-th tick of the associated clock and 
is the final tick. The discrete-time states are defined with
difference equations as function   of the previous values  1 and the inputs  .

2.1

Clocked continuous-time models

A clocked partition may contain differential equations.
This allows the embedding of regular continuous-time
models from given Modelica libraries. The Modelica
translator brings the equations of a clocked partition to
the form of an ODE or semi-explicit index-1 DAE:
()
= [(), ()]


0 = [(), ()]

(3)

The translator then applies a specified solver method to
convert continuous-time differential equations to discrete-time difference equations. This mixed symbolic/numeric approach is also known as inline integration (Elmqvist et al, 1995).

The use of 1 in (5) leads to the introduction of additional discrete-time states for the delay of inputs by one
sample period, even though this is typically not wanted.
Semi-implicit Euler avoids the delay of inputs and implicit dependencies of states for non-stiff models. It results in:
    1
=   = 0  0  ( 1 ,  )
  1
0 = ( 1 ,  )

Many more solver methods exist with specific advantages and drawbacks. The choice of the best solver
method depends on the model at hand. This is why it is
advantageous that inline integration embeds the most appropriate solver method into an exported model.
Modelica 3.3 defines the operators previous(x) to access  1 and interval() to determine     1.

The Modelica change proposal MCP-0024 introduces
the operator firstTick() to determine if  = 0
(Franke, 2016).

3

0 = (  ,  )

(4)

Explicit Euler avoids the implicit equation system for the
states   in (4) for non-stiff models. It results in:
    1
=   = 0  0  ( 1 , 1 )
  1
0 = ( 1 , 1 )

508

(5)

FMI extension

FMI 2.0 defines a generic event mechanism that also covers synchronous models. The drawbacks of this generic
mechanism are that discrete states are hidden in the FMU
and that the environment does not know any details
about the events. This makes it impossible to synchronize events with the environment of an FMU. Thus, it is
not possible to re-import an exported FMU with synchronous discrete-time features and achieve a deterministic behavior. Neither it is possible to exploit a discretetime FMU for advanced applications such as parameter
estimation or model predictive control, because the discrete states are hidden.
It is proposed to extend FMI by the following:
1. Declare clocks in modelDescription.xml
2. Declare discrete-time states in modelDescription.xml

Basic solver methods are implicit Euler, explicit Euler
and semi-implicit Euler. Application of implicit Euler
results in:
    1
=   = 0  0  (  ,  )
  1

(6)

3. Let the environment activate clocks in order to
enable synchronization with the environment
and with other FMUs.
This extension is optional. A model can always hide
event details according to FMI 2.0.

3.1

Extension of modelDescription.xml

The TypeDefinitions section is extended with a
Clocks subsection that contains one or more Clock
entries.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132507

Session 7D: Control Systems III

Finally, the ModelStructure section is extended with
a subsection DiscreteStates. It provides an ordered list
of all exposed discrete states with their indices in the
ScalarVariable list. Each entry of DiscreteStates
may declare the dependencies from known inputs, continuous-time states and other discrete-time states. The
dependencies are defined under the assumption that the
respective clock ticks.

3.2

Extension of the C calling API

The C calling API is extended with four new functions
that can be called during the event mode of an FMU.
Figure 2: Kinds of Clock

Each Clock may be one of (see Figure 2):






Periodic: the clock ticks periodically with an a
priori known interval specified in the model description XML file. A priori known values
make the sampling a structural model property
for increased correctness at runtime.
Triggered: the clock is activated by a Boolean
condition in the model, e.g. for an interval that
depends on model variables.
Inferred: the clock is activated from outside
the model, e.g. for a generic discrete-time
model with arbitrary sample interval. Synchronous models do not require a parameter for the
sample time; the clock propagates with clocked
variables. Synchronous Modelica models use
the interval operator instead of a parameter.

The attributes of Periodic define the clock interval and
offset time. The basic clock interval is either specified
with a double valued baseInterval or with integer
valued intervalCounter and resolution. Both
definitions relate to each other with
baseInterval = intervalCounter/resolution
Periodic clocks may be further refined with the attributes
subSampleFactor and shiftCounter. This results in the actual

A clock is activated by the environment for the current
time instant by the function fmi2SetClock, and the status of a clock can be queried with the function
fmi2GetClock:
fmi2Status fmi2SetClock (
fmi2Component c,
const fmi2Integer clockIndex[],
size_t nClockIndex,
const fmi2Boolean tick[],
const fmi2Boolean* subactive);

Set the clock activation status by providing
the indices of the corresponding clocks
with respect to the xml element
<TypeDefinitions><Clocks> and values. A clock is activated at the current
time instant if tick[i] = fmi2True, otherwise the clock is deactivated. The environment may set subactive[i] =
fmi2True to only evaluate the output
equations (2) and replace the state equations (1) with
(7)
  =  1
This is similar to the treatment of clocked
continuous states at initial time, see (4),
(5) and (6). The argument subactive[i]
defaults to fmi2False if a NULL pointer is
passed.

interval = baseInterval/subSampleFactor
that is delayed by
offsetTime = interval*shiftCounter
The attributes of ScalarVariable are extended with two
new attributes:




previous marks a discrete-time state, similar to
the derivative attribute of continuous-time
states. The value is an index to the variable
providing the previous value of the discretetime state.
clockIndex associating a variable uniquely
with a clock in the Clocks section.

DOI
10.3384/ecp17132507

fmi2Status fmi2GetClock (
fmi2Component c,
const fmi2Integer clockIndex[],
size_t nClockIndex,
fmi2Boolean tick[]);

Query whether a set of clocks is active by
providing the indices of the corresponding
clocks with respect to the xml element
<TypeDefinitions><Clocks>.

A clock interval is set by the environment for the current
time instant by the function fmi2SetInterval, and it
can be queried with the function fmi2GetInterval:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

509

Discrete-time models for control applications with FMI

fmi2NewDiscreteStates. The FMU cop-

ies   to  1 and evaluates the discrete-time
equations, updating   , if the corresponding
clock is active. The FMU resets the clock activation after one evaluation. This means that the
environment must activate the clock again if it
wants to re-evaluate clocked equations, for instance to treat an algebraic loop (see below)

fmi2Status fmi2SetInterval(
fmi2Component c,
const fmi2Integer clockIndex[],
size_t nClockIndex,
const fmi2Real interval[]);

Set the interval value between the previous and the present tick of the clock.

3. Leave event mode:
The functions fmi2NewDiscreteStates and
fmi2Reset leave event mode and deactivate
all clocks.

fmi2Status fmi2GetInterval(
fmi2Component c,
const fmi2Integer clockIndex[],
size_t nClockIndex,
fmi2Real interval[]);

Query the interval value for the provided
clocks (periodic or non-periodic). If the
clocks are non-periodic, the interval has
to be queried at every clock tick, to define
the follow-up clock tick.

3.3

Extension of importing environment

The importing environment parses the model description
XML file and activates periodic and inferred clocks during simulation. It activates periodic clocks at sample intervals specified in the model description XML file. It
activates inferred clocks as needed by the environment
(e.g. with an externally specified sample interval or if the
clock of a connected FMU ticks). The FMU itself activates Triggered clocks.
This extension does not change the overall calling sequence of C functions for model exchange. The environment calls the new API functions additionally during
event mode as follows:
0. Enter event mode:
FMI 2.0 enters the event mode either after initialization (call to function fmi2ExitInitializationMode) or during simulation (call
to function fmi2EnterEventMode).
1. Activate clocks and set inferred intervals:
An FMU activates triggered clocks itself. The
environment may query the clock activation status with the function fmi2GetClock. The environment sets the activation status of periodic
and inferred clocks by calling fmi2SetClock.
Moreover,
the
environment
calls
fmi2SetInterval for inferred clocks. It may
query the clock interval, e.g. for triggered
clocks, with the function fmi2GetInterval.
2. Evaluate clocked equations:
The evaluation is triggered by fmi2GetXXX for
clocked variables during event mode or by

510

The environment might need to evaluate clocked discrete-time equations multiple times at one time instant,
for instance to iteratively solve an algebraic loop among
multiple connected FMUs or to calculate partial derivatives for optimization. The environment can either call
fmi2GetXXX within event mode, triggering the evaluation of clocked equations if the respective clocks are active. The FMU will update discrete-time states and deactivate the clocks. The environment may reset discretetime states by calling fmi2SetXXX, re-activate clocks
and call fmi2GetXXX again for multiple evaluations.
This also applies to all kinds of clocks, including also
triggered clocks. Alternatively, the environment may enter event mode multiple times and reset discrete-time
states for multiple evaluations.
The environment might be interested in the dependencies of model outputs from inputs and given discretetime states, independently of the state equations. This
can be achieved by passing subactive=fmi2True to
fmi2SetClock.

3.4

Relation to Simulink S-functions

The basic concept of the proposed FMI extension is well
known from other simulation technologies. The widely
used simulation tool Simulink, for example, supports an
arbitrary number of discrete sample times in an S-function, in addition to continuous-time equations. Lacking
an XML file, the sample times are defined in S-function
methods (C functions). The most important methods are
listed here and related to the proposed FMI extension.
mdlInitializeSizes(SimStruct *S)

This method declares the number of sample times with
ssSetNumSampleTimes(S, n);

It corresponds to the number of Clock entries in the
model description XML file.
mdlInitializeSampleTimes(SimStruct *S)

This method initializes each sample time i = 0,,n-1
with an interval and an offset time by calling
ssSetSampleTime(S, i, interval);
ssSetOffsetTime(S, i, offsetTime);

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132507

Session 7D: Control Systems III

The argument interval may take the special values
CONTINUOUS_SAMPLE_TIME for a continuous-time
model and INHERITED_SAMPLE_TIME, corresponding
to an inferred sample time of this proposal.
Moreover, the argument interval may take the special
value VARIABLE_SAMPLE_TIME and the argument
offsetTime
may take the special value
FIXED_IN_MINOR_STEP_OFFSET, relating discretetime sub-models to numerical integration steps of continuous-time sub-models. Such sampling can be implemented with triggered clocks of this proposal, if the
FMU activates clocks itself during transitions between
continuous-time mode and event mode.
Simulink will activate any sample time from outside Sfunctions in the case of sample hits and call the function
mdlUpdate(SimStruct *S, int_T tid)

A model must query the activation status and evaluate
the respective discrete-time equations.
if (ssIsSampleHit(S, i, tid)) {
// update discrete states that belong
// to sample time i
}

Discrete states are accessed with
real_T *x = ssGetRealDiscStates(S);

This FMI proposal uses variable references to access discrete states. It introduces optional previous values for
discrete-time states. Previous values allow the definition
of dependencies on  1 in the model structure, see (1),
(2). The environment only sets the actual value   . An
FMU with previous values copies   to  1 prior to the
evaluation of clocked equations.

4

Use Cases

This section lists use cases for control applications. A
chemical process model serves as an example.

4.1

Exemplary chemical process model

We consider a continuous stirred-tank reactor (CSTR)
with cooling jacket published by (Engell, Klatt, 1993).
This highly nonlinear model exhibits interesting properties, like nonminimum phase behavior and change of
steady-state gain at the main operating point. (Chen et
al, 1995) propose this example as a benchmark problem
for nonlinear control system design.
The following reaction describes the chemical process:
1

2

    
3

2  

DOI
10.3384/ecp17132507

(8)

The reactor primarily transforms cyclopentadiene (substance A) to the product cyclopentenol (substance B).
An unwanted subsequent reaction transforms B to cyclopentanediol (substance C). Another unwanted parallel
reaction transforms A to the by-product dicyclopentadiene (substance D). The mathematical model contains the
component balances for A and B:
 
= ,     1 ()  3 () 2




=   + 1 ()  2 ()



(9)

with the reaction coefficients


 () = ,0   ,

 = 1,2,3

(10)

as well as the energy balances for the reactor and the
cooling jacket:
 
 
(  )
= (  ) +
  
 
1
[ () 1 + 2 () 2 + 3 () 2 3]

 1

1
=
 +   (   )

 , 

(11)

Table 1 lists the model parameters.
Table 1: Parameters of CSTR model

Na
me
1,0
2,0
3,0
1
2
3
1
2
3






,

Value

Description

1.287 1
1.287 1
9.043 ( )1
9758.3 
9758.3 
8560 
4.2 /
11.0 /
41.85 /
0.9342 /
3.01 /( )
1.12 /(2 )
0.215 2
0.01 3
5.0 
2.0 /( )

Collision factor one
Collision factor two
Collision factor three
Activation energy one
Activation energy two
Activation energy three
Reaction enthalpy one
Reaction enthalpy two
Reaction enthalpy three
Density reactant
Heat capacity reactant
Heat transfer jacket
Surface reactor
Volume reactor
Mass cooling jacket
Heat capacity coolant

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

511

Discrete-time models for control applications with FMI

CSTR.cB

Table 2: Desired steady operating point

1.10
1.08
1.06
0

1000

CSTR.TK

2000

3000

1000

2000

3000

1000

2000

3000

CSTR.TF

115
110
105
100
0

CSTR.QK_flow
0

Table 2 gives the desired operating point for optimal
yield. The following subsections use this CSTR model
to outline different use cases.

4.2

[mol/l]

Description
Feed concentration
Feed temperature
Feed flow rate
Heat removal
Concentration A
Concentration B
Reactor temperature
Coolant temperature

[degC]

Value
5.10 /
104.9 
14.19 1
1113.5 /
2.14 /
1.09 /
114.2 
112.9 

[kJ/h]

Name
,

 /






1.12

-4000

-8000
0

Figure 3: Simulation results for the functional model
with plant and controller over 3000s

Functional Engineering

Modelica system models combine physical plant models
with control models. This enables the study the functional behavior of a system with simulation. Having a
functional model available, the actual controller code
shall be generated automatically from the control models.
Figure 3 shows a system model with a CSTR and a PI
control for the coolant temperature. The PI controller
uses a clock and sample blocks from the Modelica_Synchronous library (Otter et al, 2012). The clock also defines the solver method ImplicitEuler to convert the controller model to discrete time.

Figure 6 shows simulation results. The feed temperature
CSTR.TF is increased periodically by 5 K. This results
in higher reactor temperature and increased concentration CSTR.cB. The PI controller increases heat removal
to bring the reactor back to the desired operating point.
Overall the disturbance leads to large deviations of the
concentration of the product CSTR.cB from the desired
operating point of 1.09 mol/l. This is because the controller sees the disturbance only indirectly if the coolant
temperature increases. Moreover the reference value of
the coolant temperature is not adjusted to the disturbance.

The control task is to hold the coolant temperature at the
desired operating point, in order to keep the desired concentration of product B.
TF_ref

k=104.9

TF
+1

+
disturbance

controller

+1

period=2000

plant

V_flow

CSTR
PI
TK_ref

sample

PI

k=112.9

periodicClock

TF

cA

V_flow

cB

QK_flow

TK

hold

feedback

-

k=14.19

0.0

T=10
sample1

0.5 s
ImplicitEuler

Figure 4: Functional model of a plant with controller

512

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132507

Session 7D: Control Systems III

TF_ref

controller
filter
1

sample

TF
+1

k=104.9

+

PTn
disturbance

+1

f=0.01

invCSTR
cB_ref

sample2

cA

TF

cB

VF_flow

TK

QK_flow

period=2000

sample3

plant

VF_flow

k=1.09 - 0.02

CSTR

k=14.19
TF

cA

VF_flow

cB

QK_flow

TK

PI
forward
+1

feedback

+

PI

-

periodicClock

hold

+1

T=10

0.0

sample1

0.5 s
ImplicitEuler

Figure 5: Functional model with advanced controller containing a nonlinear inverse plant model
discrete-time plant model

TF

cA

CSTR
TF

cA

VF_flow

cB

QK_flow

TK

cB

VF_flow

assignClock
TK

QK_flow

periodicClock

20 s
ImplicitEuler

Figure 6: Discrete-time plant model for nonlinear model predictive control

4.3

Nonlinear inverse models for control

CSTR.cB

Feed forward is a well-known strategy to increase dynamic control performance. Modelica can invert a physical plant model analytically to get an inverse model for
the feed forward path of a controller (Looye et al, 2005).

[mol/l]

1.12
1.10
1.08
1.06
0

1000

CSTR.TK

Figure 7 shows simulation results. During the first 1000
s the controller adjusts the heat removal for the modified
reference cB_ref of 1.07 mol/l. Afterwards the disturbance in the feed temperature is rejected considerably better with feed forward control.
DOI
10.3384/ecp17132507

3000

1000

2000

3000

1000

2000

3000

[degC]

115
110
105
100
0

CSTR.QK_flow
0

[kJ/h]

Figure 4 shows an advanced controller with nonlinear
inverse model. This increases controller performance for
disturbance rejection by converting feed temperature to
an appropriate set point for heat removal and reference
point for the coolant temperature TK_ref. Moreover, this
enhances the controller with an external set point for the
concentration of the product B.

2000

CSTR.TF

-4000

-8000
0

Figure 7: Simulation results for feed forward control
with inverse plant model over 3000s

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

513

Discrete-time models for control applications with FMI

4.4

Discrete-time plant models for nonlinear
model predictive control

Nonlinear model predictive control (NMPC) treats an
optimal control problem for a given plant model at
runtime. The model is used as is, without analytical inversion. This simplifies the treatment of multi-variable
constrained problems at the cost of increased computing
requirements for numerical optimization at runtime. A
model predictive controller takes the following steps
during each cycle (Franke et al, 2015):

The solver HQP collects all states and the control inputs of all time intervals into one large vector of optimization variables
 = ( 0 , 0 ,  1 , 1 ,  ,  1 ,  1,   ).

(15)

This results in the large-scale mathematical program
()  


1. Convert continuous-time physical model to discrete-time model for control.

() = 0

()  0

2. Calculate model sensitivities.
3. Formulate a large-scale nonlinear optimization
program spanning multiple time steps.
4. Solve the large-scale nonlinear optimization
program.

:   1

:   
:   

(16)

with  = dim(),  = ( + 1)dim() and  =
2 . HQP applies Sequential Quadratic Programming
(SQP) with a sparse Interior Point QP solver to the numerical solution of the mathematical program.
CSTR.cB
1.12

[mol/l]

The synchronous features of Modelica and the discretetime extension of FMI enable to shift steps 1 and 2 from
the runtime to model translation time. Figure 5 shows
the CSTR model with clock and solver method assigned.

1.10
1.08
1.06
0

outputs  = ( ;  ;  ). The control task is formulated
as discrete-time optimal control problem over the time
horizon of 3000s with  = 150 intervals of length
20s. The optimization objective is to minimize quadratic
deviations of the concentration of substance B from the
desired operating point. A second objective term applies
a small penalty to control moves:


 1

=0

=0

 =  (  1.07)2 +

 min


+1 
 
107

2


The manipulated extraction of heat is constrained by
 = 0,  ,   1

(13)

The discrete-time state equations in the FMU define
further constraints:
 +1 =   (  ,  ),

 = 0,  ,   1

 0 = (2.14; 1.09; 114.2; 112.9)

514

1000

2000

3000

1000

2000

3000

105
100
0
CSTR.QK_flow
0
-4000
-8000

Figure 8: Results of the optimal control problem over a
time horizon of 3000s

(12)

9000 / <  < 0 /,

3000

110

0



2000

CSTR.TF

115

[degC]



1000
CSTR.TK

[kJ/h]

The resulting exported FMU has the discrete-time states

 = ( ;  ; ;  ), the inputs  =  ;  ;   and the

(14)

Figure 8 shows simulation results of the CSTR model for
the optimized control trajectory 0 / The optimal solution exploits the full range between 9000 / and
0 / to arrive at the new reference value , =
1.07 / significantly faster. It rejects the disturbance
for the feed temperature  similar to the controller with
nonlinear inverse model.

5

Conclusions

Modelica 3.3 introduced synchronous features that enable the rigorous treatment of discrete-time models. The
Modelica_Synchronous library demonstrates the relevance of these features for control (Otter et al, 2012).
The simulation tools Dymola and OpenModelica support Modelica_Synchronous so far.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132507

Session 7D: Control Systems III

This paper proposes an extension of FMI 2.0 to make
rigorous discrete-time models available for control applications. The extension is backwards compatible. It
specializes generic events towards clocks for discretetime models. Tools that do not support synchronous time
event handling can export the same model using generic
events as known from FMI 2.0. An importing tool should
parse the extensions of the XML file, in particular the
Clocks section, activate periodic clocks at the specified
intervals and activate inferred clocks on environment
needs. Alternatively, an importing tool might reject the
FMU if it finds inferred or periodic clocks in the Clocks
section. Triggered clocks are activated by the FMU itself
and need no support by the importing environment.

References

The basic concept of activation of sample times by a tool
is well known from other simulation technologies, such
as Simulink S-functions. The proposed FMI extension
exploits the XML model description to associate clocks
with variables. This enables deterministic clock propagation among multiple connected FMUs. The optional
specification of integer valued clock intervals further enhances clock inference for system level design.

H. Elmqvist, M. Otter, F. Cellier: Inline integration: A new
mixed symbolic/numeric approach for solving differentialalgebraic equation systems. In Proceedings ESM European
Simulation Multiconference, Prague, 1995.
S. Engell, K.-U. Klatt. Nonlinear control of a nonminimum
phase CSTR. In Americal Control Conference, Los Angeles,
1993.
R. Franke, E. Arnold: Applying new numerical algorithms to
the solution of discrete-time optimal control problems. In:
Computer Intensive Methods in Control and Signal Processing: The Curse of Dimensionality, Birhuser, Basel,
1997.
R. Franke, M. Walther, N. Worschech, W. Braun, B. Bachmann: Model-based control with FMI and a C++ runtime for
Modelica. Proceedings of 11th International Modelica Conference, Paris 2015. https://www.modelica.org/events/modelica2015/pro-

FMI export with synchronous features was implemented
in the tools Dymola and OpenModelica. Import was implemented in the optimization solver HQP. The paper
motivates the FMI extension with use cases for a highly
nonlinear chemical process model. The use cases include
functional engineering, nonlinear inverse models for
control and nonlinear model predictive control.
The synchronous features of Modelica also include the
automatic conversion of continuous-time models to discrete-time models with inline integration. This mixed
symbolic/numeric approach simplifies model-based
control applications considerably, because it releases an
importing environment from the treatment of continuous-time differential equations and sensitivity equations.
Run-time efficiency increases.
Discrete-time FMUs with inline integration are a work
in progress. Development versions of OpenModelica,
Dymola and HQP were used for the optimal control
problem in section 4.4. Dymola 2017 was used for the
nonlinear inverse model in section 4.3.
Discrete-time FMUs will serve for the investigation of
parallel algorithms for automatic differentiation and numerical optimization in the PARADOM project.

T. Blochwitz, M. Otter, J. kesson, M. Arnold, C. Clau, H.
Elmqvist, M. Friedrich, A. Junghanns, J. Mauss, D. Neumerkel, H. Olsson, A. Viel: Functional Mockup Interface 2.0:

The Standard for Tool independent Exchange of Simulation Models, 9th International Modelica Conference, Munich, 2012. http://www.ep.liu.se/ecp/076/017/ecp12076017.pdf
H. Chen, A. Kremling, F. Allgwer: Nonlinear Predictive
Control of a Benchmark CSTR, Proceedings 3rd European
Control Conference ECC95, Rome, 1995.
H. Elmqvist, M. Otter, S.E. Mattsson: Fundamentals of Synchronous Control in Modelica, 9th International Modelica
Conference, Munich, 2012.
http://www.ep.liu.se/ecp/076/001/ecp12076001.pdf

ceedings/html/submissions/ecp15118339_FrankeWaltherWorschechBraunBachmann.pdf

R. Franke: Initialization of Clocked Discrete States, Modelica
Change Proposal MCP-0024 2016. https://svn.modelica.org/projects/MCP/public/MCP-0024_InitializationClockedStates/MCP-0024_InitializationClockedStates.docx

Functional Mock-up Interface for Model Exchange and CoSimulation, Version 2.0, July 2014.
G. Looye, M. Thmmel, M. Kurze, M. Otter, J. Bals: Nonlinear Inverse Models for Control. Proceedings of 4th International Modelica Conference, Hamburg, 2005. https://www.modelica.org/events/Conference2005/online_proceedings/Session3/Session3c3.pdf

Modelica Association: Modelica  A Unified Ob-ject-Oriented Language for Systems Modeling. Language Specification, Version 3.3. May 9, 2012.
M. Otter, S.E. Mattsson, R. Franke, H. Elmqvist, T.
Blochwitz: Discrete States and Time Events in FMI
(#353), FMI Change Proposal FCP-001, 2016.
https://svn.fmi-standard.org/fmi/trunk/FMI_ChangeProposals/FCP_001_SampledDataSystemsForModelExchange/FMI_Proposal_DiscreteStates_TimeEvents.docx

M. Otter, B. Thiele, H. Elmqvist: A Library for Synchronous
Control Systems in Modelica, 9th International Modelica
Conference, Munich, 2012.

Acknowledgements

http://www.ep.liu.se/ecp/076/002/ecp12076002.pdf

This work was supported in parts by the Federal Ministry of Education and Research (BMBF) within the project PARADOM (PARallel Algorithmic Differentiation
in OpenModelica)  BMBF funding code: 01IH15002E.

DOI
10.3384/ecp17132507

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

515

516

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Model-based Embedded Control using Rosenbrock
Integration Methods
Hans Olsson1 Sven Erik Mattsson1 Martin Otter2 Andreas Pfeiffer2 Christoff Brger1
Dan Henriksson1
1
Dassault Systmes AB, Lund, Sweden,
{Hans.Olsson, SvenErik.Mattsson, Christoff.Buerger, Dan.Henriksson}@3ds.com
2
DLR, Institute of System Dynamics and Control, Germany,
{Martin.Otter, Andreas.Pfeiffer}@dlr.de

Abstract

Directly generating controller code from models is
important for advanced model-based design. This
paper describes how Dymola can generate embedded
C-code from Modelica models, designed to be easy to
embed, with care about minimal foot-print, traceability,
and straightforward integration in embedded platforms
and gives actual application examples.
The paper focuses on using Rosenbrock methods for
index-1 problems (instead of the normal transformation
to index 0) that allows Dymola to handle stiff systems
in a way that both is theoretically sound and has an
upper bound on the execution time per sample.
The stiff systems in the control system often occur
due to using an inverse (simplified) model of the real
plant in the controller. A nonlinear feedforward
controller and a controller with feedback linearization,
both applying an inverse model, demonstrate the
proposed process by using Rosenbrock methods for
embedded code generation.
Keywords: Modelica, inverse models, real-time,
embedded, Rosenbrock methods, inline integration,
feedforward controller, feedback linearization

1

Introduction

Modelica and Modelica tools such as Dymola are very
well suited to model and simulate complex physical
systems with primary focus on offline simulation for
design and assessment, as well as on online simulation
on special purpose hardware, e.g. for hardware-in-theloop simulations. Modelica models have been used in
controller applications where nonlinear Modelica
models are part of the real-time control system, see for
example (Looye et al., 2005). The controller could be
designed and assessed with Dymola, however, the
actual real-time controller code had to be re-built
manually either directly in C or with dedicated
software for controller code generation.
There are several activities to extend the tool chains
for Modelica models for real-time platforms, for
example (Satabin et al., 2015) for generation of
certified code of simple Modelica models via the
SCADE-suite (SCADE, 2017), or (Bertsch et al., 2015)
DOI
10.3384/ecp17132517

for utilizing Modelica code on automotive electronic
control units.
This paper describes the steps to generate embedded
real-time code using a new prototype functionality of
Dymola. The goals are (a) to generate code that can be
certified for critical applications, (b) to guarantee an
upper number of operations so that hard real-time
constraints can be fulfilled, and (c) to support advanced
controllers that can utilize nonlinear Modelica models
in the feedback or feedforward path of the controller,
which may require solving nonlinear differentialalgebraic equation systems.
Numerical integration in real-time is a challenging
task. Explicit integration, such as explicit Runge-Kutta
methods or explicit multistep methods provide
integration schemes with a deterministic number of
numerical operations, but they may fail for stiff
systems due to stability problems. Choosing a rather
small step size can help to overcome this issue, but the
sample rate and the computational power of real-time
platforms are (strongly) limited. Standard implicit
methods like implicit Runge-Kutta methods or BDF
methods are designed for stiff systems with an
acceptable step size, but nonlinear systems of equations
have to be solved in each time step. Linearly implicit
one-step methods, in particular Rosenbrock methods,
provide a compromise. They can solve stiff problems
using larger steps than explicit methods at the cost of
having to solve linear systems.
The paper describes the new contributions in the
following order: Section 2 gives an overview of the
new code generator, Section 3 explains implementation
of the Rosenbrock methods, Section 4 gives realistic
application examples, and finally Section 5 gives a
summary and outlines possible future extensions.

2

Model-based Embedded Controller
Development in Dymola

Controller code intended to be executed in real-time on
embedded devices is subject to special requirements.
For example, (Bertsch et al., 2015) discusses these
challenges in the context of automotive embedded
applications for the case of FMU source code

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

517

Model-based Embedded Control using Rosenbrock Integration Methods

Figure 1. Embedded controller development scenario with Modelica/Dymola.

generation using Modelica tools. The standard C-code
generated by Modelica tools is typically designed for
desktop computer environments, where substantial
hardware and software resources are available.
Simulation is offline and without hard real-time
constraints. Such standard code does not fulfill realtime system requirements, where code has to be
deployed on embedded targets.
The standard C-code generated by Dymola from
Modelica models is no exception; it is highly optimized
to cope with several application scenarios including
offline simulation and hardware-in-the-loop simulation
of complex plant models on dedicated hardware
platforms. However, this code includes many features
not needed (and fails to fulfill constraints) for real-time
controller code to be executed on embedded targets
where minimalistic, self-contained, and human
readable code is required.
On the other hand, Dymola provides convenient
tooling for the development of full multi-domain
system models and their simulation. It would be very
convenient if embedded code for the controller parts
also could be automatically generated and evaluated in
software-in-the-loop simulations. The advantages of
Modelica regarding complete system modeling and
simulation are then leveraged also for real-time and
embedded controller development.
Figure 1 summarizes the embedded development
scenario we like to support. Physical plant models,
controllers and test inputs for typical use cases can be
fully modeled (left part) and simulated (right part) on
system level. Throughout iterative development of all
components, the whole system can be evaluated using
standard simulation facilities. Embedded code can then
be generated for the controller and co-simulated with
the rest of the system. The results of such a softwarein-the-loop co-simulation are shown on the right. The
control signal (blue curve) is computed using the code
generated by the embedded code generator. The red
curve is the controlled plant output and the green signal
518

is a disturbance that becomes active midway through
the simulation. The embedded code generator to
support this process is described below.

2.1 Embedded Development Process
Given a physical system model in Modelica, the
experimental Dymola embedded code generator
considers the following four tasks for the design and
implementation of controllers for an embedded target:
(1) Controller modeling: Implement controllers as
Modelica models with continuous model equation parts
as done in Modelica since many years.
(2) Model decomposition: Use the controller models
in a synchronous environment as described in (Otter et
al., 2012). Sample and hold blocks are used to
incorporate the controller inputs and outputs. As
integration scheme for the clocked blocks the
Rosenbrock methods presented in Section 3 can be
used. In Modelica terms, controllers are therefore just
synchronously clocked sub-models. Their synchronous
clock models the interval in which the embedded
environment provides new real-time inputs and queries
for respective control actions.
(3) Embedded code generation: To generate the code
to be embedded for the controller parts, apply the
embedded code generator on the total model. Dymola
extracts the synchronously clocked parts and generates
C-code which is a self-contained, real-time simulator
of its clocked parts. The code is well-suited for
embedded deployment.
(4) Embedded deployment: Adapt, integrate and test
the generated controller code on a real-time platform,
like a rapid prototyping platform or embedded device.
The four tasks can be iteratively performed, in
interrelation with the development of the model of the
controlled physical systems. Co-simulation of the
generated controllers is achieved by binding the
generated C-code of controllers as external C functions
to Modelica and calling them at every sample point

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132517

Session 7D: Control Systems III

throughout the system simulation. Examples of this
procedure are given in Section 4.

2.2 Properties of Generated Code
In addition to the standard optimizations performed by
Dymolas symbolic manipulation facilities (equation
systems are automatically torn to solve as much
symbolically as possible, constant expressions are
folded and shared expressions are eliminated to be
computed at most once), the controller source code
generated by the embedded code generator complies
with the following requirements for execution on
embedded devices:
Code Integration
 All types (model variables, states and records)
relevant for user code and further code integration
are encapsulated in header files.
 Proper C data types are deduced. Substitutions are
performed to reduce memory footprint.
 A clear interface (with separate C-functions for
initialization, output calculations, etc.) enables
easy integration within external embedded
environments.
 A generic interface to a solver for linear equation
systems enables the usage of solvers tailored for
specific applications and targets. The code for a
default LU-solver is provided.
 The generated code is self-contained, without
dependencies on further libraries (including the C
standard library), supporting embedded devices
without operating system or restricted software
availability.
Traceability
 Comments link the generated code to its Modelica
model, enabling traceability of computations and
declarations. An XML file describing all variables
is generated.
Real-Time Execution
 No heap memory allocation or recursion enables
deterministic static memory allocation and
therefore memory requirement predictions.
 The Rosenbrock integration methods described in
Section 3 are applied to achieve deterministic
execution times and enable predictable response
times by preventing iterative loops with unknown
number of iterations.
 Equations and variables are only considered when
relevant for controller outputs; irrelevant
computations are removed from the code.
There are also some restrictions on the generated
embedded code:
 It does not (yet) fulfill all requirements of the
MISRA-C standard (MISRA, 2013), which is
important for safety-critical systems.

DOI
10.3384/ecp17132517




Simplified event handling is applied. Only state
events can occur, since the models do not use time
directly.
Nonlinear systems of equations to be solved in
real-time are currently not directly supported. By
using linearly implicit integration methods with an
index-1
formulation
these
systems
are
automatically avoided, see Section 3.2.

2.3 A Simple PI-Controller Example

Figure 2. Simple PI-controller with output saturation and
integer quantization.

Figure 2 shows a simple linear PI-controller. Since
the synchronous model decomposition is only required
to mark the controller for embedded code generation,
but irrelevant for the actual embedded code generated,
we can ignore the controllers clock and in- and output
samplings. Relevant for embedded code generation is
that the output u of the controller model is declared
with min and max attributes defining its saturation:
Modelica.Blocks.Interfaces.IntegerOutput
u (min = -500, max = 500) "Controller output";

The embedded code generator generates two C source
code files: a header file defining the controllers inand output types (dsembedded.h) and its actual
implementation (dsembedded.c).
The header file in Figure 3 defines a C struct that
holds all relevant model variables, each annotated with
a comment referring to its original Modelica
declaration and description. Note, that the type of the
output u is a signed 16-bit integer which Dymola has
deduced from the min and max attributes declared in
the controllers Modelica model.
Figure 4 shows parts of the generated model
implementation, in this case the start of the routine for
the calculation of controller outputs. Each calculation
is preceded by a comment that traces back to the
original component, class and equation within the
controllers Modelica model responsible for the code
generated. The comments also contain information
about alias substitutions and deduced array sizes.
Similar code is generated for model update used to
provide new sampling inputs and dynamics to compute
complex simulation steps. Using the code and the types
provided by the generated header file, the generated
controller implementation can be integrated in the
embedded software system actually deployed on some
target device. More advanced application examples
combining Rosenbrock integration methods and this
embedded code generator are given in Section 4.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

519

Model-based Embedded Control using Rosenbrock Integration Methods
/* dsembedded.h
* Model variables for Modelica model PIController */
#ifndef _dsembedded_h_
#define _dsembedded_h_
#include <dse_types.h>
#include <dsembedded_structs.h>
/* structs for records */
#include <dsembedded_prototypes.h> /* function prototypes */
/* Model variables */
struct PIController_variables {
/* input Modelica.Blocks.Interfaces.RealInput y
"Measured variable" */
real_t y;
/* input Modelica.Blocks.Interfaces.RealInput y_ref
"Reference signal" */
real_t y_ref;
/* output Modelica.Blocks.Interfaces.IntegerOutput
u(min=-500, max=500) "Controller output" */
integer16_t u;
...
/* parameter Modelica.Blocks.Types.Init
integrator.initType (min=1, max=4) =
Modelica.Blocks.Types.Init.InitialState
"Type of initialization (1: no init,
2: steady state, 3,4: initial output)" */
uinterger8_t integrator_initType;

};

/* parameter Boolean limiter.strict = false
"= true, if strict limits with noEvent(..)" */
boolean_t limiter_strict;
...

Figure 3. C header file generated for the PI-controller.

/* dsembedded.c
* Model equations for Modelica model PIController */
#include <dsembedded.h>
#include <dsembedded_codes.c>
/* functions code */
/* Model outputs */
static int model_outputs(PIController_variables* v,
PIController_states* s)
{
/* Component add1 */
/* Class
Modelica.Blocks.Math.Add */
/* y = k1*u1+k2*u2; */
/* y = Ki.u; */
/* u1 = y_ref; */
/* u2 = y; */
v->Ki_u = v->add1_k1*v->y_ref+v->add1_k2*v->y;
/* Component Kp */
/* Class
Modelica.Blocks.Math.Gain */
/* y = k*u; */
/* u = Ki.u; */
v->Kp_y = v->Kp_k*v->Ki_u;

}

/* Component add */
/* Class
Modelica.Blocks.Math.Add */
/* y = k1*u1+k2*u2; */
/* u1 = integrator.y; */
/* u2 = Kp.y; */
v->add_y = v->add_k1*v->integrator_y+v->add_k2*v->Kp_y;
...

Figure 4. Generated PI-controller implementation.

3 Rosenbrock Methods
For real-time applications of stiff systems Dymola has
historically reduced the models equation system to
index 0 (an ODE system) and used a nonlinear solver
to handle the implicit Euler discretization by a limited
number of Newton iterations, see e.g. (Elmqvist,
Mattsson et al., 2004).
One main advantage of Rosenbrock methods is to
directly solve stiff systems using only a linear solver.
520

A certain variant of the implicit Euler method doing
only one Newton iteration per step is equivalent to the
corresponding Rosenbrock method of order 1.
In the following subsection Rosenbrock methods are
introduced for index-1 DAEs which are known from
the literature. Further, the advantages of the index-1
formulation and their application on Modelica models
are presented. Finally, some properties and details of
their implementation in Dymola are discussed.

3.1 Rosenbrock Methods for Index-1 DAEs
The supported Rosenbrock methods consider nonautonomous DAE systems with index 1 of the form
 = (, )

where  is a constant and possibly singular matrix.
The Rosenbrock methods (Hairer, Wanner, 1991)
are defined by s stages for a single step from 0 to
1  0 +  with the initial state vector 0 = (0 ) to
get an approximation of the state vector (1):


1 = 0 +    ,
=1

1
   (0, 0 ),
 =

1

1

=1

=1

  = (0 +  , 0 +    ) +  



 

( = 1,  , ).
+   (0, 0 )
Fixed method coefficients are  ,  ,  ,  ,  and
 . To compute the stage vectors  a linear system of
equations has to be solved in each stage. Especially
interesting are methods with    ( = 1,  , ),
because then the iteration matrix  of the linear system
is the same in each stage  and we can drop the index.
So, only one decomposition of the iteration matrix  is
required in each time step. Rosenbrock methods
require the evaluation of the Jacobian  and the
derivative with respect to time  .
For systems with input variables  (which must not
be mixed up with the stage vectors  ):
 = (, )  , , ()

this means  =  +   with the derivatives  of the
external input signal  to be provided.
There exist coefficients of Rosenbrock methods with
convergence orders from 1 to 4 with different stability
properties. In (Lubich, Roche, 1990) an L-stable
Rosenbrock method of order 3 with  = 4 stages is
developed for index-1 systems. In (Rang, 2013) the
coefficients of Rosenbrock methods are improved to
get methods without order reduction for (very) stiff
problems.
Rosenbrock methods are interesting for real-time
simulation of stiff systems, because the computational
procedure for a step includes the solution of linear

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132517

Session 7D: Control Systems III

systems but not of nonlinear systems. For linear
systems a fixed number of computations guarantee
finding the numerical solution in contrast to the
iteration process for solving nonlinear systems.

the example in Figure 6 the first order Rosenbrock
method Rosenbrock1 is used.

3.2 Linear and Nonlinear Systems of
Equations
In comparison to the ODE representation of a Modelica
model, the index-1 formulation in Section 3.1 has some
advantages in combination with Rosenbrock methods.
Consider the example system of index 1
 = (, , ),
0 = (, , ),

where a possibly nonlinear function  couples states 
and algebraic variables . The typical transformation to
ODE form would lead to
 = , , (, ),
 = 1 (, ).

Figure 5. Menu to select a Rosenbrock integration
method in Dymola.

Here, maybe a nonlinear or at least a linear system
of equations has to be solved when inverting the
function  with respect to . This can be avoided, if
the index-1 formulation is used:
(, , )
 0 
.

  = 
(, , )
0 0 

When applying a Rosenbrock method only the right
hand side and its derivatives are evaluated. The one
step method provides an approximation of the solution
vectors ,  just by solving linear systems in the stages
of the method. So, no nonlinear or nested linear system
has to be solved. This property is very helpful for realtime simulation, because nonlinear loops in the original
Modelica model can be replaced by linear systems in
this way  leading to predictable computation times,
see Section 4.1.2 for an example.

3.3 Rosenbrock Methods in Dymola
The support of Rosenbrock methods has recently been
implemented in Dymola. The integration schemes rely
on the index-1 formulation of the manipulated
Modelica model equations. By the symbolic
manipulation algorithms of Dymola, it is structurally
guaranteed, that the system  = (, ) has index 1.
Currently, in Dymola four different Rosenbrock
methods with orders 1-4 are available. The method of
order 1 is the linearly implicit Euler method. All the
methods are available as global inline integration
methods in Dymola, see the menu in Figure 5.
Further, a Rosenbrock method can be specified as a
solver method for a clocked part, by setting the
argument solverMethod of the Modelica Clock
constructor Clock(c, solverMethod). This functionality
is then used in the Modelica_Synchronous library to
define the integration method of clocked equations. In

DOI
10.3384/ecp17132517

Figure 6. Inclusion of a continuous-time controller into a
clocked environment using Rosenbrock integration.

To complete the tool chain, the Rosenbrock methods
are also supported by Dymolas embedded code
generator. The symbolic machinery transforms the
Modelica model equations after index reduction and
fixed state selection to the form  = (, ) and
generates code for calculating  and . Additionally
the matrix  corresponding to the analytic Jacobian is
straightforward to construct and generate code for.
It is more complicated to construct the vector  .
The symbolic machinery normally deduces a total
derivative with respect to time, but for Rosenbrock
methods a partial derivative is needed. We will explain
the difference with an example. If for example
(, ) =  2 + , the total derivative with respect to
time would be  (, ()) = 2 +  , but the
partial derivative is  (, ) = 2. The symbolic
machinery has also to deal with intermediate variables
(e.g. , if we rewrite the previous equation as (, ) =
 + ;  =  2 ; and the partial derivative with respect to
time should differentiate those, but not the states).
Moreover, this time-derivative is not used by other
standard numerical integration methods, and thus some
Modelica functions do not provide the necessary
derivatives (this can be handled either by assuming that
the functions are smooth even if not specified or some
minor modifications of libraries such as Modelica

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

521

Model-based Embedded Control using Rosenbrock Integration Methods

Standard Library to specify this). This is especially the
case, if the model follows some time-dependent
trajectory ()  because we need the derivative  (),
which is not needed for other methods. For input
dependent models the derivative  of the input is
involved in  (as explained in Section 3.1) and could
be approximated by a difference quotient or the
influence of  could be neglected in the method
equations ( = 0), when we assume that the input
signal is piecewise constant. But this introduces some
non-smoothness into the right hand side , which could
lead to numerical errors especially when applying
Rosenbrock methods with orders greater than two. A
more sophisticated solution for such input dependent
models would require the additional input  for the
model. This approach has not been investigated so far.
The matrix  is generally sparse or even diagonal
with just zeros and ones on the diagonal and it would
be worth to exploit the structure of the matrix when
generating tailored code for the application of a
Rosenbrock method to a specific Modelica model  but
this is not yet realized in the implementation.
Dymolas implementation of
Rosenbrock is
generic, and some method-specific optimizations are
not yet included, e.g. some Rosenbrock methods have
several rows of the matrix ( ) that are identical, and
in those cases we could avoid re-evaluating the right
hand side . This can intuitively be explained as
performing exactly two iterations of the nonlinear
solver for that point.
There are variations of Rosenbrock methods (Wmethods) that keep the factorized matrices for several
steps. We have not considered them for real-time
applications. The reason is that for real-time code the
goal is to ensure a maximum computation time for
each sampling point  not for the average one; and we
will anyway need new factorized matrices after each
event. If we do not explicitly detect events, the
problem with W-methods would be more severe since
the continuity assumptions are silently broken.

4 Application Examples
In this section two application examples are given to
demonstrate how the embedded code generation and
the Rosenbrock methods can be used to generate realtime code for nonlinear controller structures with
guaranteed upper number of operations.

4.1 Nonlinear Feedforward Controllers
We consider a continuous-time controller with two
structural degrees of freedom and an inverse plant
model in the feedforward path. See (Looye et al., 2005)
for details on this controller structure and its
implementation in Modelica. In case the inverse plant
and the plant model are identical, they start at the same
initial values and the plant is stable, then the control

522

error is equal to zero, so the plant output follows the
filtered reference input. The feedback controller is used
to compensate for differences in the plant and inverse
plant model, as well as for external disturbances, and it
stabilizes a plant in case it is unstable.
4.1.1 Implementation in Modelica

In Modelica an inverse plant model can be constructed
by using the model component
Modelica.Blocks.Math.InverseBlockConstraints
to exchange inputs and outputs and by connecting a
filter to the input of the inverse model. As filter the
model
Modelica.Blocks.Continuous.Filter
with
parameters filterType = LowPass and analogFilter =
CriticalDamping or Bessel can be used, see Figure 7.
The minimum order of the filter results from the
structural analysis of the inverse plant model resp. the
corresponding DAE in order to only provide the input
u but not derivatives of it. The derivatives of the
smoothed input signal are computed inside the filter
model.

Figure 7. Definition of an inverse plant model.

In order that the controller can be used on a real
time system, the process of Section 2 is applied. The
continuous controller model is transformed to a
clocked system with sample and hold blocks and an
appropriate inline integrator needs to be selected for
the clock. In simple cases, an Explicit Euler method
might be enough. If the controller contains nonlinear
algebraic equations or if the model is stiff, a
Rosenbrock integrator has to be selected, see also
Section 3.3. Note, that the filter might be stiff even if
the inverse plant model might be non-stiff.
It follows an application example for the automatic
construction of nonlinear feedforward controllers that
can be used in an embedded system.
4.1.2 Example 1: Slider Crank Mechanism
with Feedforward Controller

The following example is a slider-crank
mechanism that is directed in vertical
direction. At the top a spring-mass system is
present. The goal is to move the revolute
joint of the slider-crank mechanism, such
that the mass follows a pre-defined path
without vibrations.
When kinematically driving the revolute
joint with constant velocity, then the vertical
coordinate of the top mass moves as shown

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132517

Session 7D: Control Systems III

in Figure 8. As can be seen, significant vibrations are
present in the movement of the mass. The goal is to
develop an embedded controller according to Section
2. The problem is rather challenging, because the slider
crank mechanism introduces a nonlinear algebraic
equation system in the plant, as well as in the plant
inverse.

Figure 8. Vertical movement of top-mass of the slidercrank mechanism.

Figure 9. Controlled slider crank mechanism.

In Figure 9 the overall system including a controller
is shown. The controller is detailed in Figure 10 where
for the feedforward path of the controller an inverse
model of the slider crank mechanism is present such
that the input of the inverse model is the vertical
position s of the top mass, and the outputs are (a) the
reference torque tau for the revolute joint, and (b) the
reference angle phi for the revolute joint. As filter a

third order critical damping filter is used. The control
error is the difference between the reference angle phi
computed by the inverse slider crank model and the
measured angle phi from the plant. A simple P
controller is used in the feedback loop.
Although a nonlinear system of equations appears in
the model equations of the inverse slider-crank model,
it is possible to generate embedded code for the
sampled data controller according to Section 2 by
using the newly supported Rosenbrock integrators of
Section 3. The detailed explanation of this effect is
found in Section 3.2. A proper step size of the tested
Rosenbrock methods for the controller is 1 ms.
Some simulation results are shown in Figure 11. The
Rosenbrock method of order 1 (the linearly implicit
Euler method) leads to very accurate results with
respect to the reference solution generated by a highly
accurate DASSL simulation. The numerical solution of
the Rosenbrock method with order 3 is also rather
accurate, only in the torque signal some vibrations are
visible. One reason could be neglecting the input
derivatives of s_ref and phi in the integration scheme
of Rosenbrock methods as described in Section 3.1.
Experiments show for the Explicit Euler method a
maximum step size of 0.5 ms can be used; otherwise
the numerical integration cannot be run due to
difficulties with solving the nonlinear system. There
remains still a nonlinear system of equations due to the
index-0 formulation of the translated model equations.
This also means that currently no embedded code can
be generated for this controller example when using an
Explicit Euler method as integrator.
There are two advantages of Rosenbrock methods:
Because they are implicit methods, generally greater
step sizes can be used than for explicit methods and
nonlinear system of equations present in the model
equations can be approximately solved by a
Rosenbrock solver resulting in only linear systems.

Figure 10. Sampled data controller of a slider crank mechanism consisting of inverse plant model in the feedforward
path, a filter of order 3 and a P controller in the feedback loop.

DOI
10.3384/ecp17132517

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

523

Model-based Embedded Control using Rosenbrock Integration Methods

until an analytical relation with a control input is
found. If the system model is available in Modelica,
the derivation of the control laws can be automated
using a similar procedure as described in Section 4.1.1.
However, instead of a filter with a minimal order, a
minimal set of integrators is added:

(1)
 =  () =  

where  is the new model input corresponding to the
output with relative degree . We describe the
procedure for a single output system with the
controlled output . The desired dynamic behavior of
the closed-loop system is then imposed by application
of an additional feedback law:
1

 = 0        ()

(2)

=1

with constant coefficients  . This feedback law
requires availability of the (  1)-th derivative of the
controlled output . The derivatives may be obtained
from measurements or from the computed values in the
inverse model. In case the inverted model exactly
represents the true system, the closed loop system
becomes the single output case:

Figure 11. Simulation results of the slider crank
mechanism with a nonlinear feedforward path and a P
controller in the feedback loop. The reference solution
using the continuous controller in Modelica is generated
by highly accurate BDF-methods with DASSL (blue
lines) whereas the embedded controllers contain
Rosenbrock methods of order 1 (red lines) and order 3
(green lines) with a constant step size of 1 ms.

4.2 Feedback Linearization Controllers
A further important controller structure using nonlinear
plant models is feedback linearization, see (Looye et
al., 2005) for more details including the implementation in Modelica.
4.2.1 Implementation in Modelica

The first part of this subsection is a summary of
material provided in (Looye et al., 2005). The principal
differences between a controller with feedback
linearization and a feedforward controller of Section
4.1 are that for the feedback linearization
 the inverse plant model is in the feedback part of
the controller and
 the states in the inverse model are obtained from
the actual plant via measurement and/or estimation
and not via solving a DAE (but algebraic equations
might need to be solved).
When deriving feedback linearizing control laws
manually, the outputs to be controlled are differentiated
524



()

1

+   () + 0 (   ) = 0.

(3)

=1

A disadvantage of feedback linearization is that the
state vector of the plant must be fully available from
measurement and/or estimation.
In Modelica, the inverse model is built in a similar
way as for a feedforward controller, see Figure 12:






Figure 12. Definition of an inverse plant model for
feedback linearization.

When translating this model with Dymola, typically
an error message of the following kind is displayed:
"The model requires derivatives of some inputs as
listed below: ...". For example if derivatives of order 2
are required by , then 2 more integrators have to be
added.
This inverse model with the integrators of Figure 12
is placed in the feedback-loop of the controller. If the
minimal number of integrators are added, then the
model from    has the same number of states as the
non-inverted plant. These states must be provided from
measured and/or estimated values of the plant. To
formulate this, Dymola has introduced an annotation to
map a sampled input signal, say, xs = sample(xc) to a
state x, say:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132517

Session 7D: Control Systems III
Real xs annotation(useAsInputForState=x);

well as its temperature , are measurable.
With the approach of Figure 12 it is determined that
two integrators are needed. By Equation (3) we get the
following feedback law:
 =  = 0     1 
(4)

The meaning is that
1. StateSelect.always is defined for variable x.
2. After the usual index reduction and state selection
x is deselected as state and the equation x = xs is
added. Its derivative is set as a dummy derivative.
As a result, the inverse model is no longer a
differential-algebraic equation system, but only an
algebraic equation system. In case this system is
nonlinear, the Rosenbrock method from Section 3 is
used to solve it during run-time with a fixed upper
bound on the number of operations.

whereby  is available from measurement and  is
computed from the inverse model (which in turn means
that it is computed from the measured  and ). The
following feedback coefficients are selected:
0 = 4.39e-4,
1 = 0.0419.

The complete model including the controller and the
controlled plant is shown in Figure 14. The controller
is according to (4) and includes the input to state
blocks for the states of the inverse plant model: the
concentration  and the temperature . As explained in
the previous subsection this is necessary to provide the
measured states to the inverse model of the feedback
linearization controller.
Figure 15 shows the response of the closed loop
system using the embedded controller generated
according to the process described in Section 2. The
simulation results are generated with Rosenbrock
methods of order 1-4. It is obvious that the results are
rather identical for the used step size of 5 s. It is also
possible to use the Explicit Euler method, but then a
step size of 1 s is necessary to achieve similar accuracy
as the Rosenbrock methods do.
The main novelty of this example is the support of
the newly introduced annotation useAsInputForState
within a clocked system. This feature enables the user
to develop and test a controller with feedback
linearization in a purely Modelica environment.
Previously (see Looye et al., 2005) this was only
possible by exporting the inverse model to for example
Simulink and building the controller in this
environment. The additional support by the embedded
code generator completes this feature.

Figure 13. Modelica block to apply the new annotation
useAsInputForState.

A corresponding Modelica block has been
implemented to use the annotation, see Figure 13. The
main line of code in the block is
RealInput xs annotation (useAsInputForState=x);

to enforce, that the state x is set to the input xs
according to the above logic.
In the next subsection an application example
demonstrates the general tool chain for the automatic
construction of feedback linearization controllers that
can be used in an embedded system.
4.2.2 Example 2: Mixing Reactor with Feedback
Linearization Controller

We use a mixing reactor model that is explained in
detail in (Looye et al., 2005)  including different types
of controllers for it. The reactor shall be controlled by a
feedback linearization controller. For the feedback
linearization it is assumed that the two system states,
the concentration  =:  of the chemical substance, as









Figure 14. Mixing reactor controlled by a feedback linearizing controller. The input to state blocks are used to
provide the states of the inverse model.

DOI
10.3384/ecp17132517

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

525

Model-based Embedded Control using Rosenbrock Integration Methods

initialization and event code. Additionally, the choice
of the specific Rosenbrock methods will be reinvestigated. A possible future extension would be to
use Rosenbrock methods with step-size control in offline mode; one benefit would be to quickly get an
estimate of the step-size needed for the model.

6

Acknowledgment

We would like to thank Gertjan Looye from DLR for
his help regarding modeling of feedback linearizing
controllers.

References

Figure 15. Step response of the mixing reactor controlled
by a feedback linearization controller.

5 Summary and Outlook
Directly generating controller code from models is
important for model-based design. This paper
demonstrates how Dymola can generate embedded Ccode for Modelica models (with several novel aspects)
and demonstrates this for application examples.
By using Rosenbrock methods on the index-1
problem Dymola can handle stiff systems in a way that
both is theoretically sound and has an upper bound on
the execution time per sample. The stiff systems in the
control system often occur due to using an inverse
(simplified) model of the real plant in the controller.
Additionally Dymola's generated embedded C-code
has been designed to be easy to embed, with care about
minimal foot-print, traceability, and straightforward
integration in embedded platforms.
Finally, a nonlinear feedforward controller and a
feedback linearization controller have been
implemented in Modelica for different application
examples. They show the potential of the whole
process by generating embedded real-time code for
these nontrivial examples.
Future considerations include investigating how to
handle inputs (piece-wise constant or extrapolation) for
Rosenbrock methods, and nonlinear systems in
526

C. Bertsch, J. Neudorfer, E. Ahle, S. S. Arumugham, K.
Ramachandran, A. Thuy. FMI for Physical Models on
Automotive Embedded Targets. Proc. of 11th International
Modelica Conference, pp. 43-50. Versailles, France, 2015.
H. Elmqvist, S. E. Mattsson, H. Olsson, J. Andreasson, M.
Otter, C. Schweiger, D. Brck. Realtime Simulation of
Detailed Vehicle and Powertrain Dynamics. Electronics
Simulation and Optimization. SAE 2004 World Congress,
Detroit, USA, 2004.
E. Hairer, G. Wanner. Solving Ordinary Differential
Equations II. Stiff and Differential-Algebraic Problems.
Springer, 1991.
G. Looye, M. Thmmel, M. Kurze, M. Otter, J. Bals.
Nonlinear Inverse Models for Control. Proceedings of 4th
International Modelica Conference, pp. 267-279, TU
Hamburg-Harburg, Gemany, 2005.
C. Lubich, M. Roche. Rosenbrock Methods for Differentialalgebraic Systems with Solution-dependent Singular
Matrix Multiplying the Derivative. Computing 43, 325342, Springer, 1990.
MISRA Consortium. Guidelines for the Use of the C
Language in Critical Systems. 2013.
M. Otter, B. Thiele, H. Elmqvist. A Library for Synchronous
Control Systems in Modelica. Proc. of 9th International
Modelica Conference, pp. 27-36. Munich, Germany, 2012.
J. Rang. Improved traditional Rosenbrock Wanner methods
for stiff odes and daes. Technical report, Institute of
Scientific Computing, Technical University
Braunschweig, 2013.
L. Satabin, J.-L. Colaco, O. Andrieu, B. Pagano. Towards a
Formalized Modelica Subset. Proc. of 11th International
Modelica Conference, pp. 637-646. Versailles, France,
2015.
SCADE:
www.esterel-technologies.com/products/scade-suite

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132517

Integration of complex Modelica-based physics models and
discrete-time control systems: Approaches and observations of
numerical performance
Kai Wang1

Christopher Greiner1

John Batteh2

Lixiang Li2

1

2

Ford Motor Company, USA, kwang37@ford.com, cgreiner@ford.com
Modelon, Inc., USA, john.batteh@modelon.com, lixiang.li@modelon.com

Abstract
A Modelica-based air conditioning (A/C) system
model has been integrated, closed-loop, with related Sfunction-based controls in the Simulink environment.
The integration was performed with two different
approaches, with a DymolaBlock-based S-function for
the A/C model, and as a co-simulation FMU. The
simulation performance of the integrated model needs
to be sufficiently fast for the purpose of vehicle-level
simulations and optimizations. This paper will discuss
the integrated modeling of A/C system and associated
control systems over a dynamic drive cycle, and the
associated numerical performance issues discovered, as
well as some approaches taken to increase said
performance.

2

Overview of the physical plant
model - A/C refrigerant
components, refrigerant system,
and cabin

Keywords: Modelica, discrete, variable, integration

1

Introduction

As CAE simulations become more complex, the need
for computational efficiency increases in order to
provide timely solutions and analyses. One facet of this
complexity is the integration of multiple software
modeling tools and environments in order to utilize the
most capable computational technologies for the
different features of these complex system models.
Physical plant models may be developed in Modelica
and require variable step solvers to capture both fast
and slow continuum dynamics while discrete timebased control systems may be developed in C-code or
Simulink and require fixed time step solvers.
Integrating these plant and control models into a single
environment can result in computational inefficiencies
due to conflicting solver time step requirements. This
paper will discuss the integrated modeling of an
automotive vapor compression air conditioning system
and associated control systems over a dynamic drive
cycle, and the associated numerical performance issues
discovered, as well as some approaches taken to
increase said performance.

DOI
10.3384/ecp17132527

Figure 1 (a) Hierarchy structure of the A/C model (b)
Modelon A/C model layout
For this study, only models of the complete
refrigerant system and the vehicle interior (cabin) were
required to simulate the physics of interest. The plant
models are Modelica-based and developed in Dymola
2015FD01, utilizing component and refrigerant models
from Modelon-supplied libraries. The structure and
layout of the A/C model package are shown in Figure
1. The Dymola package browser in the upper-left of
Figure 1(a) displays the package hierarchy and is
shown with the A/C model selected. There are three
sub-packages under the A/C model, namely,
parameterized components, test benches, and A/C
system model package. The parametrized components
are specific, populated component models which are

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

527

Integration of complex Modelica-based physics models and discrete-time control systems: Approaches and
observations of numerical performance

used in the refrigerant circuit models. They include an
evaporator, compressor, condenser, internal heat
exchanger, and Thermostatic Expansion Valve (TXV),
as well as piping and hoses. The test bench subpackage is a workspace for users to customize or
calibrate individual component instances, and includes
test benches for condenser, evaporator, and compressor
models. The A/C simulation model sub-package
consists of two main sub-models, the refrigerant circuit
and the cabin model (including the air duct, blower
model, etc.) as shown in Figure 1(b). Included in the
refrigerant circuit model are the evaporator,
compressor, condenser, internal heat exchanger,
piping, and hoses. The cabin model consists of cabin
interior, an air duct model, temperature blend door
model, and the blower model.
The SC03 drive cycle is part of the EPA regulatory
automotive 5-cycle fuel economy method. SC03 is a
full vehicle chassis dynamometer test performed with
the vehicle A/C unit operating with an ambient
temperature of 95F (35C) and a solar loading on the
vehicle of 850 W/m2. The cycle represents a 3.6 mile
(5.8 km) route with an average speed of 21.6 mph
(34.8 kph), maximum speed 54.8 mph (88.2 kph), and
duration of 596 seconds. The vehicle speed profile for
the SC03 test is shown in Figure 2. The SC03 drive
cycle was chosen for this study as it is the only cycle of
the EPA 5-cycle method that requires the air
conditioning system to be operating.

Figure 2 Vehicle speed race for SC03 cycle

3

Overview of the control systems
models

The control systems required for the electrified
automotive air conditioning system operation typically
consist of the climate control head, compressor control,
condenser fan control, active grille shutters, and
electric water pump, as shown in Figure 3. The climate
control head is the interface between the occupant and
the climate control system. It controls the overall
operation of the climate system, including cooling or
heat request, blower airflow setting, airflow mode
setting (location of discharge air), recirculation versus
fresh air, cabin and evaporator temperature settings,
and automatic or manual operational mode. The control
head also controls the states of ancillary systems such
as auxiliary heaters, glass fogging detection,
heated/cooled seats, heated backlight/windshield, and
heated steering wheel. Explicit modeling of a closedloop control head is not included in this study, as the
climate system settings are manually set at the start of
the cycle and remain static throughout the drive cycle,

528

and the evaporator target temperature time trace comes
from actual test data.
The compressor control modulates the compressor
speed based on temperature request and refrigerant
discharge pressure. The climate control head
determines an appropriate target evaporator outlet
temperature profile and the compressor control sets the
compressor speed to achieve the target temperature
using a PI control algorithm. If the compressor
discharge pressure exceeds a specified limit,
compressor speed is reduced and modulated using a PI
controller to maintain a maximum allowed discharge
pressure.

Figure 3 Automotive air conditioning control systems
The cooling fan control regulates the underhood
front-end airflow fan speed in order to maintain the
thermal management of systems requiring airflow
through their associated heat exchangers. These
systems typically include the A/C system, engine
coolant, engine oil, and transmission oil systems.
When the A/C system is operating the fan control
calculates a desired fan speed/duty cycle based on
compressor discharge pressure and ambient
temperature. Fan speeds/duty cycles are also calculated
for the other thermal systems and an arbitrator function
determines the maximum required fan speed/duty cycle
then commands the fan. Above certain vehicle speeds
the fan speed/duty cycle is reduced to take advantage
of ram air effect on front-end airflow.
Active grille shutters are used to balance
aerodynamic drag and front end airflow/thermal
management system requirements, closing down at
higher vehicle speeds to reduce drag and opening more
at lower speeds to enhance front end airflow. Similar to
the cooling fan control, each thermal system has a
desired shutter opening calculated and an arbitrator
determines the maximum opening required and
commands the shutters. For the A/C system, the
desired grille shutter opening is calculated based on
compressor discharge pressure and ambient
temperature and then combined with a vehicle speed
multiplier to account for aerodynamic effects.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132527

Session 7D: Control Systems III

Each of the control systems described above are
implemented in the Matlab/Simulink (Version R2014a)
environment as pre-compiled S-functions. The source
of the S-functions is based on the C-language code
implemented on the actual vehicle. While specific
control strategies are hard-coded into the S-functions
themselves, all control calibration parameters are user
accessible at run time. Also, as each of the controls are
discrete time-based systems operating with timing
loops of 10 and 100 milliseconds, execution of the
control models in Simulink require fixed step solvers.

4

Integrated Dymola/Simulink Model
- Methods of model integration

In Dymola, the A/C plant model operates in an open
loop fashion with the time varying inputs for a
simulation prescribed in advance. While this is useful
for a number of scenarios, such as plant model
development and verification, substantially more value
can be realized when the plant models are integrated
with control systems in closed loop, thereby allowing
more complex system performance and optimization
studies to be conducted. Simulink is used here as the
integration environment, and there are multiple
methods for incorporating a Dymola model into
Simulink.
The first integration approach is using the
DymolaBlock S-function interface. This Dymola
option allows models developed in Dymola to be
compiled as S-functions incorporated directly into
Simulink, enabling the powerful physical modeling
capabilities of the Modelica language to be combined
with the controls orientated approach of Simulink.
Figure 4 depicts the A/C model integrated into
Simulink as a DymolaBlock S-function.

Figure 4 Integrated A/C model as a DymolaBlock Sfunction in Simulink
The second integration method utilizes the
Functional Mock-up Interface (FMI) for model
exchange or co-simulation. FMI defines a standardized
modeling interface to be implemented by an executable
module called a Functional Mock-up Unit (FMU). The
FMI functions are used (called) by a simulation
environment to create one or more instances of the
DOI
10.3384/ecp17132527

FMU and to simulate them, typically together with
other model elements. An FMU may either have its
own embedded numerical solvers (FMI for CoSimulation) or utilize the simulation environments
own solvers (FMI for Model Exchange). [1].
In this application, we only consider the FMI for
Co-Simulation option for two reasons. First, FMI for
Model Exchange is very similar to utilizing an Sfunction function approach, like the DymolaBlock, as
they both use the Simulink solver, and the
DymolaBlock process is already incorporated into our
modeling process. Second, due to the nature of the
continuum behavior of the A/C system physics, and the
need for a variable time step solver for the plant model,
FMI for Co-Simulation allows the use of Dymolas
solver for the physics in conjunction with Simulinks
solver for the controls. Figure 5 shows an A/C model
FMU in Simulink, with open loop inputs.

Figure 5 Integrated A/C model FMU in Simulink
Closed-loop control modeling requires the A/C
system plant model to respond, minimally, at near realtime and produce physical and realistic outputs for the
control systems to properly act upon [3]. In this study,
there are three primary physical outputs from the A/C
system plant model, specifically, the evaporator air out
temperature, the vehicle cabin interior air temperature,
and the compressor refrigerant discharge pressure. The
evaporator air out temperature is the primary feedback
signal used by the compressor controller to modulate
the compressor speed, while the other two signals are
used to a lesser degree. The input signals to the A/C
system plant model from the control systems and
Simulink-based physics models are the compressor
speed, condenser airflow and air inlet temperature. The
A/C system airflow through the evaporator and cabin
interior is determined by the cabin blower fan and
controlled by the Climate Control Head. In the SC03
drive cycle the blower is set to its maximum speed and
is modeled as a constant input into the A/C model.
Additional physics required by the integrated model
are defined in Simulink, including the condenser
airflow and air temperature. These physics models are
coupled to both the control systems as well as the A/C
model, as appropriate.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

529

Integration of complex Modelica-based physics models and discrete-time control systems: Approaches and
observations of numerical performance

5

Model performance and solver
strategies

The A/C system model, including the associated
control systems, is one subsystem in a much larger and
more complex total vehicle model. Because of this, it is
desirable to optimize the computational performance of
each subsystem in order to minimize the impact on the
total vehicle model simulation time. The
aforementioned A/C model integration approaches
were selected to give the broadest range of solver and
simulation settings to minimize the subsystem
computational time.
The baseline performance for the A/C system model
is defined as the physics-only Modelica model running
the SC03 cycle open-loop in the Dymola environment,
utilizing the DASSL variable time step with a solver
tolerance of 1e-05. Baseline simulation run time was
185 seconds, about one third of the real cycle time of
600 seconds. Next, the S-functions version of the
Dymola model was run open-loop in the Simulink
environment. Due to the numerical stiffness of the
mathematics, only the Simulink ode15s variable time
solver was capable of reliable solutions, and we used a
solver tolerance of 1e-05 to provide sufficient solution
accuracy. The S-function simulation time averaged 183
seconds, essentially identical to the native-mode
Dymola model. These results are shown as the first
two bars in Figure 6. The actual SC03 cycle time
comparator of 600 seconds is the right-most bar in the
figure.

Figure 6. Comparison of the A/C system model
computational performance
Next, we consider the closed-loop integration of the
Dymola S-function with the 100ms fixed sampling
rate compressor control and the 10ms sampling rate
fan control. In Matlab R2014a, if any part of a
Simulink model requires a variable step solver, the
variable step solver must be the master solver for the
simulation. However, Simulink does allow the user to
define fixed sampling rates for parts of the model. For
the integrated Dymola S-function model, we utilized
the ode15s variable time step solver as the master
530

solver and specified a fixed sampling rate of 100ms
for the compressor control, in order for the controls
system to operate realistically. Likewise, when the
cooling fan control was added to the integrated
model, the fan control was set to run at a 10ms
sampling rate, consistent with its actual operation.
The A/C model with the compressor control model
completed the SC03 cycle in a time of 1119 seconds,
as shown in the fourth bar of Figure 6, almost twice
as slow as real time. When the fan control was added
to the A/C model and compressor control the
simulation time for the SC03 cycle increased
dramatically to 3181 seconds, more than five times
the actual cycle time.
To rationalize the performance degradation we need
to understand the interactions between the
continuous, variable step solver used for the
refrigerant system physics, and the discreet time-step
solvers used by the control systems. With the
integrated compressor control, the control module has
to communicate 100ms. Additionally, when the fan
control is also connected, it must communicate every
10ms. These sampling/exchange rates force the
variable time step solver operating on the physical
plant to synchronize the inputs and outputs of the
Dymola S-function at the communication interval
defined by the control system sampling rate. To
illustrate this effect, the Simulink model was
instrumented to record the timing rate of the variable
time step solver. Figure 7a shows a histogram of the
time step sizes used by the ode15s solver for the
stand-alone, open-loop Dymola S-function model for
the SC03 cycle. 53 percent of the time steps were
larger than 100ms. Figure 7b shows the results of the
A/C model with the integrated 100ms compressor
control. The largest variable time step for this
example was less than 80ms, and a large percentage
10ms or less. Finally, the combined A/C plant with
compressor and cooling fan controls variable solver
time steps are shown in Figure 7c, where the
maximum step size is even less than the 10ms
sampling rate of the fan controller. Combining
variable and fixed step rates in Simulink models is
referred to as a hybrid system in the Simulink
documentation, as is detailed as follows:
A hybrid system is a system that has both discrete
and continuous states. Strictly speaking, any model
that has both continuous and discrete sample times is
treated as a hybrid model, presuming that the model
has both continuous and discrete states. Solving such
a model entails choosing a step size that satisfies both
the precision constraint on the continuous state
integration and the sample time hit constraint on the
discrete states. The Simulink software meets this
requirement by passing the next sample time hit, as
determined by the discrete solver, as an additional

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132527

Session 7D: Control Systems III

constraint on the continuous solver. The continuous
solver must choose a step size that advances the
simulation up to but not beyond the time of the next
sample time hit. The continuous solver can take a
time step short of the next sample time hit to meet its
accuracy constraint but it cannot take a step beyond
the next sample time hit even if its accuracy
constraint allows it to. [2]

Figure 7 Comparison of variable solver time step of
the A/C model without/with compressor and fan
control
As we attempted to optimize the computational
performance of the combined A/C system and
associated control systems, this approach of utilizing a
Dymolablock-based S-function combined with the
discreet time-based controls in Simulink was unable to
deliver a sufficient level of performance, given the
versions of the tools utilized, Dymola 2015FD01 and
Matlab R2014a.

DOI
10.3384/ecp17132527

Next, the computational performance of the A/C
model, as a co-simulation FMU, coupled with the
control systems in Simulink, was evaluated. The
primary benefit of FMI for co-simulation is that the
FMU utilizes a native-mode solver from its parent tool,
and the integrating environment uses its own
appropriate solver, and the communication interval
between the FMU and the integrating environment can
be independently specified. After a series of tests, it
was determined that a communication interval of one
second, between the FMU and the Simulink-based
controls, was sufficient to capture the required
accuracy and dynamics of the of the A/C plant model
to support vehicle-level cycle simulations. The
following results discussed here are only for a
communication interval of one second. The A/C model
FMU utilized the Dymola DASSL solver, and the
Simulink solver used was ODE1 with a fixed time step
of 10ms, consistent with vehicle-level simulations.
Running the A/C model FMU coupled to open-loop
inputs in Simulink resulted in a run time of 314
seconds, 70% slower than the stand-alone S-function,
seen as the third bar in Figure 6. While this degradation
was not expected, it was most likely due to the
generation of time events in the FMU associated with
the open-loop inputs, and not explored in depth here.
Combining the A/C model FMU with the compressor
controls resulted in a run time of 528 seconds,
indicated by the fifth bar in Figure 6. Then, after
adding the cooling fan controls, the simulation time
only increased to 564 seconds, about a 7% increase in
simulation time. Even with both controls systems
integrated with the FMU, the model was able to
execute faster than real time, as opposed to the large
simulation times recorded utilizing the S-functionbased plant model approach.
The benefit of the FMU co-simulation modeling
approach is due to the variable time step solver for the
physical plant model not having to synchronize lockstep with the discrete-time systems in the model, thus
allowing the variable solver to run, on average, larger
time steps permitted by the physics.
There have been recent performance enhancements
and tool developments in the co-simulation software
space, as well as enhancements to hybrid-solver
simulations in more recent versions of Matlab, but
those studies are not yet complete and could not be
included in this paper.

6

Conclusions

A Modelica-based A/C system model has been
integrated, closed-loop, with related S-function-based
controls in the Simulink environment. The integration
was performed with two different approaches, with a
DymolaBlock-based S-function for the A/C model, and
as a co-simulation FMU. The simulation performance

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

531

Integration of complex Modelica-based physics models and discrete-time control systems: Approaches and
observations of numerical performance

of the integrated model needs to be sufficiently fast for
the purpose of vehicle-level simulations and
optimizations. A study has been performed to evaluate
and improve the simulation performance of the
integrated model. The execution time of A/C model
coupled with controls using Modelica FMI/FMU in
closed-loop is faster than the real time of the SC03
cycle, and it is 5 times faster than the same A/C model
using
Dymola-Simulink
interface
S-function.
Combining models that require both variable and fixed
time step solvers can lead to serious numerical
performance issues and care must be taken in
evaluating potential solutions of these hybrid models.
These performance issues are expected to grow as the
complexity of physics and control models continue to
increase, and the demand for faster model turnaround
does, likewise.

References
[1] T. Blochwitz:, M. Otter, M. Arnold, C. Bausch and H.
Elmqvist, "The Functional Mockup Interface for Tool
independent Exchange of Simulation Models," in
Proceedings of the 8th International Modelica Conference;
March 20th-22nd; Technical Univeristy, Dresden; Germany,
2011.
[2] MathWorks. [Online]. Available:
http://www.mathworks.com/help/simulink/ug/modelingdynamic-systems.html?refresh=true.

532

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132527

Improving Interoperability of FMI-supporting Tools
with Reference FMUs
Christian Bertsch1

Award Mukbil2

Andreas Junghanns3

1
Corporate Research, Robert Bosch GmbH, Germany Christian.Bertsch@de.bosch.com
Dept. of Informatics, Clausthal University of Technology, Germany, Awad.Mukbil@tu-clausthal.de
3
QTronic GmbH, Germany, Andreas.Junghanns@QTronic.de

2

Abstract
The Functional Mockup Interface (FMI) is more and
more adopted by industrial users, increasing the
pressure for higher quality and standard compliance of
FMI supporting tools. The FMI cross check
infrastructure was created to support tool vendors in
their quest for quality improvements and to give users
some measure of confidence in the tool quality.
Currently it is up to the tool vendors which FMUs to
submit there. For this reason the features tested in the
FMI cross check are incomplete and interpretation of
failures is difficult. While for FMI export there is the
FMU compliance checker to test a wide variety of FMI
features, no means are available today to prove standard
compliance for FMI import. This will be overcome by
adding reference FMUs to the FMI cross check, testing
specific features of the FMI standard for standard
compliance and giving detailed feedback, if an
importing tool violates the standard. The paper
describes the realization and the importance of reference
FMUs.
Keywords: FMI, Reference FMUs, Compliance, Testing

1 Introduction
The Functional Mock-up Interface (FMI) is a tool
independent approach for model exchange (ME) and cosimulation (CS) (Blochwitz et al. 2011, 2012), and on
the way to become the industry standard for exchange
of models and cross-company collaboration (Bertsch et
al. 2014). Its main purpose is to share and reuse
simulation artifacts among a wide variety of tools and
environments, by putting the model specifications into a
simple compressed file called Functional Mockup Unit
(FMU). The FMU contains a model description in XML
format, source written in C and/or binaries ready to run
and optional components such as documentation, model
logo, etc.
Even before the release of the first version of FMI,
several modeling and simulation tools started
supporting the FMI standard. According to the official
website of FMI project, more than 80 simulation tools
support FMI version 1.0 and more than 40 support

DOI
10.3384/ecp17132533

version 2.0. Many automotive Original Equipment
Manufacturers (OEM) have committed themselves to
support FMI as exchange format for simulation models.
Because industrial users must rely on the results of
FMI-based simulations, the maturity of FMI
implementations comes into focus. For this reason, the
FMI project has organized the FMI cross check (XC,
2014), where FMI exporting tools can upload test FMUs
together with reference solutions as comma-separated
values (CSV) files, and importing tools can run those
FMUs and report the results. Once the results have been
submitted, they are shown in the FMI cross check table
at the FMI official website, which helps users to check
which tools work well together and which vendors are
serious in supporting FMI. In our experience, this has
improved the quality and the maturity of FMI support of
tools significantly.
The FMU compliance checker (FMU CC, 2016) is an
open source software tool that was initiated by the FMI
project and implemented by Modelon AB,contracted by
the Modelica Association. Its intention is to check
compliance of a given FMU with the FMI standard.
Through this compliance checker, users can get reports
about a wide range of problems that could arise from
loading FMUs, which in turn play an important role in
validating the tools that create (i.e. export) FMUs.

Exporting  Feedback

Tool

compliant?

FMU
Compliance
Checker

Importing
? Todays ?
 Feedback

Tool
FMI Feedback


Cross Check
Reference
FMUs

Feedback

compliant?

Figure 1: Three complementary ways of FMI compliance
testing

According to the rule #8 of the FMI cross check
document (XC, 2014), vendors should test their FMUs
using the FMU compliance checker before submitting

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

533

Improving Interoperability of FMI-supporting Tools with Reference FMUs

them, with or without reference results. This allows
vendors to find problems in their implementations early.
However, it is up to the exporting tool vendors which
FMUs they submit to the FMI cross check, and (as
depicted in Figure 1) in cases of problems it can be
difficult to find out if it is a problem of the importing or
exporting tool. This shows that special testing of FMI
importing tools is no less important. We propose do
realize this with the help of reference FMUs. Executing
these in an importing tool can provide feedback on the
FMI standard compliance of this tool as described
below.
From the beginning, in the FMI cross check rules
(XC, 2014) the important role of reference FMUs was
foreseen. The contribution of this work is a step towards
realizing such reference FMUs. In Sec. 2 we introduce
the concepts, the requirements and the classifications of
the reference FMUs. In Sec. 3 we present an initial
implementation of reference FMUs. In Sec. 4 we present
the means of testing the reference FMUs and first
experience with FMI importing tools. Last but not least,
we conclude our work and give an outlook to ongoing
research in Sec. 5 respectively.

2 FMI and Reference FMUs
The FMI standard comes in textual form, supported by
graphs, e.g., of the calling sequence, and XML
schemata. (Blochwitz et al. 2012). The FMI 2.0
standard has added also a mathematical description of
FMI, which clarifies a large number of concepts.
However, the FMI standard is considered to be not fully
formalized, which means the standard specifications are
not written in formal description language. Formalizing
the standard would help automatically generating test
cases, and for validating FMUs statically or during
runtime.
Formalizing the FMI standard has been partially
addressed in some publications, e.g. (Hasanagi et al.
2016), but this seems far away from being realized for
the whole standard in the next years. Thus, testing
methods from software engineering come into the focus.

2.1

Reference FMUs and Software Testing

In order to test FMI standard compliance, we must test:
1. Exporting tools: these tools create FMUs.
2. Importing tools: these tools run FMUs.
The exporting tool should follow the FMI standard
specifications for creating FMUs, such as providing a
correct modelDescription.xml file, and use the
correct naming and implementation for the functions as
stated in the standard. The FMU compliance checker
tests the validity of the FMUs and, implicitly, the
exporting tools with respect to a large number of FMU
properties. However, the FMU compliance checker can
only check a finite number of FMU properties for
correctness and is extended step by step. If the FMU

534

compliance checker does not find a problem, it is not
guaranteed that the FMU is error free.
In software engineering, the three basic types of
software testing are (Bruegge, B., Dutoit, A. H., 2009):
 Black-Box testing: testing done by giving inputs and
analyzing outputs. Tester does not use source code.
 White-Box testing: testing done with knowledge of
the internals of the software.
 Grey-Box testing: a combination of the black-box
and white-box techniques.
Testing FMUs using the FMU compliance checker is
grey-box testing because there are open aspects about an
FMU (like the modelDescription.xml) and closed
aspects of an FMU (compiled dynamic link libraries
(DLLs) containing the model behavior of the FMU). If
the FMU comes with reference CSVs, then the FMU
compliance checker sets the inputs according to the
input CSV file, runs the FMU and compares the
resulting outputs with the reference outputs.
Dealing with the importing tools is different. Most of
the simulation tools supporting FMI are commercial,
with unknown import mechanisms. Therefore, those
importing tools are considered black-boxes, and the
only way to test them is to run special FMUs that can
spot problems and log errors. These special FMUs are
called Reference FMUs.

2.2

Definition of Reference FMUs

A reference FMU is an FMU specifically implemented
to test compliance with a certain aspect of the FMI
standard of a simulation tool. It has the ability to detect
and log errors and wrong practices according to the
FMI standard specifications. A reference FMU shall be
inspected and reviewed before being accepted and
published; thus, they must be available in source code
and all the creation tools must be freely available.
This definition makes clear, that FMUs
demonstrating a certain feature but exported by some
commercial simulation tool cannot be considered as
reference FMUs, because they might be too
complicated, coming without the full source code and
tools that are necessary to create them without having
the needed licenses. However, they can also be very
valuable. We encourage tool vendors also to export such
Feature demonstration FMUs more often to the FMI
cross check.
For the first set of reference FMUs we focus on
testing hard facts, e.g., testing standard compliance
aspects of the importing tools such as data type support
and correct calling sequences. Other goals such as
testing usability of FMUs with many parameters or large
input/output sets, simulation performance with many
states or simulation performance with many
algebraic/discrete equations are currently not covered.
We limit ourselves to positive test cases (that the
importing tool should accept) and do not consider
negative FMU cases (that should be rejected by the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132533

Session 9A: FMI I

importing tool), because we think that invalid or
incorrect FMUs should be detected by the FMU
compliance checker and in the FMI standard we have
not seen requirements on an FMI importing tool to reject
certain FMUs.

2.3

Requirements on Reference FMUs

Reference FMUs shall:
 test specific features of FMI importing tools, and the
set of reference FMUs cover many features, and
 follow the FMI standard. A minimum requirement
is, that the FMU compliance checker runs
successfully (i.e., without warnings or errors) or that
a trac issue has been created in case of limitations,
 be simple and well-documented,
 be of high quality; to this purpose they shall
 be reviewed according to defined rules
 be available with all source code and tools that are
necessary to create them  in order that the creation
process can be inspected and reproduced,
 detect and log the cause of a failure if possible, and
 fit into the FMI cross check infrastructure (if
possible), e.g. by providing output signals.
The documentation of the reference FMUs is very
important in order to reproduce the creation and
interpret the results. It shall contain the following
information:
 Authors, change history and review status of this
reference FMU.
 The test purpose: What shall be tested with this
FMU? Which potential errors of importing tools
shall be detected with this FMU? Which capabilities
of importing tools shall be tested?
 Implementation hints: How is this FMU created?
(E.g. which libraries and tools are used?) Which
steps or scripts have to be run to create the FMU?
 Test setup: What are inputs to this FMU (data type,
values over time) and what are the expected
outputs?
 Is this FMU suitable for the current FMI cross check
infrastructure?
We have created a template for the documentation
which will be made publicly available. The
documentation will be contained within the reference
FMUs as html documentation.

2.4

Sources of Reference FMUs and
Coverage

There are several ways of deriving reference FMUs:
One is to go systematically through the standard and
trying to derive FMUs testing coverage and correct
implementation of all features. Another is to implement
FMUs based on (negative) experience with importing
and simulating FMUs created by one and run in some
DOI
10.3384/ecp17132533

other (presumably buggy) tool. For creating a reference
FMU based on this experience, one should abstract the
missing feature or error of the importing tool to a simple
example fulfilling the requirements listed above and
triggering the erroneous behavior.
In the following we followed both concepts. In the
current work, we did not intent creating a complete set
of reference FMUs, but we consider this as a starting
point that can be extended by developers and users once
the reference FMUs will be released to the FMI project
and to the public.
For certain aspects of the FMI standard, measures of
coverage can be derived: E.g., we have created reference
FMUs for all supported data types or we check the
allowed function calls in all FMI states and have created
reference FMUs that reach all of these states.

2.5

Classifications of Possible Reference
FMUs

FMI standard has main features and specifications that
should be followed, and from those features we propose
this classification of reference FMUs:
 FMUs for testing data types capability (one for
each data type),
 FMUs having dependencies on binaries, e.g. DLLs,
or other resources, e.g. CSV files,
 FMUs testing correct interpretation of the
modelDescription.xml file (version string,
GUID, model identifier etc.),
 FMUs for testing access restrictions depending on
variable attributes (i.e. causality/variability
combination),
 FMUs for testing the calling sequence as specified
in the finite-state machine of the standard document,
 FMUs testing correct event handling (e.g., plausible
event localization),
 FMUs for testing optional capabilities, e.g., partial
derivatives, and
 Complex FMUs enabling the testing of the
interactions of different features (e.g., having
continuous states, multiple variables with different
attributes, different kind of events).
The first FMUs in this list can be considered as singlefeature diagnostic FMUs, i.e., they are designed to
test for a specific feature. A failure of them is very easy
to interpret. It is intended that the features to be tested
by different diagnostic FMUs are orthogonal in the
sense that the feedback is as clear as possible.
On the other hand, the more complex multi-feature
FMUs enable the detection of more subtle errors that
only occur due the interplay of different effects or due
to high complexity of the FMUs.
While in principle there could be completely different
reference FMUs for ME and CS, for our first set of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

535

Improving Interoperability of FMI-supporting Tools with Reference FMUs

reference FMUs we have created all our reference
FMUs for both ME and CS.

2.6

Feedback of Reference FMUs

If an importing tool does not support a feature (e.g.,
specific data types) it should check this during FMU
import based on the information in the
modelDescription.xml file, and give a meaningful
feedback: this is an announced incompatibility.
During runtime  especially for diagnostic FMUs 
an internal check of the reference FMU will trigger an
FMI error, so that the simulation is stopped and a
meaningful log message is created. Another possibility
is, that the FMU runs without an error, but the outputs
of the FMU are wrong. This can be detected, e.g. by the
FMI cross check infrastructure.
In the best case the reference FMU is simulated by
the importing tool without any error and produces the
correct outputs (within specified tolerances).

3 Implementation of Reference FMUs
3.1

Tools to Create our Reference FMUs

The FMU Software Development Kit (FMUSDK, 2014)
is considered a good starting point for supporting FMI
and implementing reference FMUs. The FMUSDK
demonstrates the basic use of Functional Mockup Units
(FMUs) as defined by the FMI version 1.0 and 2.0
specifications (FMUSDK, 2014) and implemented by
QTronic and freely available in open source. The
FMUSDK is suitable to create source code FMUs in a
quite simple manner, and already contains many
checking mechanism for the functions calling sequence.
Therefore, reusing and adding to this implementation
helps in creating the first reference FMUs. Furthermore,
we used the FMUSDK scripts and libraries for building
our FMUs.
For the first reference FMUs we concentrated on FMI
2.0 FMUs for Windows 64-bit binaries. Extending this
to other platforms is discussed in Sec. 4.2.

3.2

Preliminary Set of Reference FMUs

The basic structure of our reference FMUs is the same
as proposed by the FMUSDK (Figure 2).

Figure 2: Reference FMU source code structure
The fmuTemplate.c/.h source files contain all
necessary FMI function implementations and are
included by the main FMU source file fmu.c. We
consider this structure versatile, because each FMU can

536

reuse the template and just modify small code parts for
the realization of specific features. As a starting point,
we used the original template files from the FMUSDK.
For advanced checks for the calling sequence, we
modified the templates (see Sec. 3.2.5).
All of the source code is included in the FMU in order
to enable inspection and debugging. Except for the FMU
mentioned in 3.2.3, all FMUs are separately created as
ME or CS FMUs. We will briefly describe our first set
of reference FMUs:
3.2.1 FMUs for Testing Datatype Support

While the support for real variables is standard for FMI
importing tools, the support for other data types is
limited. String inputs/outputs are not standard in many
simulation tools; however, it is expected that an
importing tool gives a meaningful error message in such
a case.
We created an FMU for testing of support for
Boolean inputs/outputs (bool.fmu): We implemented a
simple test of the Boolean data type support. This model
demonstrates a simple AND gate logical operation, with
two Boolean inputs, executing AND operation and a
Boolean output with the result. This FMU uses three
model variables: two Boolean inputs and one Boolean
output.
Additionally, we implemented an FMU for testing of
support for Integer inputs/outputs (integer.fmu): It
implements the addition of two Integer inputs written to
an output.
Further on, an FMU for testing String capability
(string.fmu) was created: It gets a string input,
concatenates it with a locally defined string and writes
it to a String output. As stated in the FMI standard, the
importer should provide his own allocating and freeing
functions (e.g. calloc, free) along with the logger
function. This property gives the importer the ability to
manage memory also for the FMU. We use this
allocation function to initialize strings, and problems of
the importing tool arising from the allocation will be
detected.
3.2.2 FMU for Testing FMI Version Number for
Future Bugfix Release FMI 2.0.1 (ver.fmu)

This FMU tests if FMI 2.0 importing tools accept FMUs
with a version string 2.0.1. A future version 2.0.1 of
the FMI standard will have only clarifications about
ambiguities in the FMI 2.0 standard. FMI 2.0.1 FMUs
shall be valid FMI 2.0 FMUs (i.e., FMI 2.0 shall be
forward compatible) as mandated by the FMI
development process (FMI DEV, 2015). This reference
FMU contains no calculations.
3.2.3 FMU for Testing Events

We created an FMU with internal time events
tEvents.fmu: it increments an internal integer variable
every second; for ME, time events are defined for this

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132533

Session 9A: FMI I

purpose; for CS the events are handled internally in the
FMU.
State events are present by the bouncingBall example
described in 3.2.6. Event handling shall be tested by
more reference FMUs to be developed in the future, see
Sec. 5.4.
3.2.4 FMU for Testing the Support of both ME and
CS Support in One FMU (mecs.fmu)

This FMU contains both ME and CS binaries  without
any calculations. The FMI 2.0 standard allows for
having both ME and CS in one FMU. It is expected, that
importing tools supporting only one of these FMI
flavors, nevertheless accept such an FMU. This FMU
was inspired by negative experience with one simulation
tool only supporting ME import and rejecting FMUs
containing ME and CS. This FMU is created with
modified build scripts compared to the original
FMUSDK, which can create only FMUs supporting
either ME or CS.
3.2.5 Testing the Handling Additional Resources

We implemented an FMU testing the calling of an
additional dynamic link library (DLL) in the binaries
folder (dll.fmu): The FMI 2.0 standard allows the
exporting tools to include additional binaries to be
shipped along with the FMU. These libraries should be
placed in the same folder of the compiled FMU binary
(or binaries) and to test this capability we have created
a simple FMU that contains and uses an additional DLL.
This DLL is compiled for each specific target platform
(i.e. 32-bit or 64-bit for Windows) with /MT option to
include a run-time environment, which is also
mentioned by the FMI standard when compiling the
FMU source code. In our example, we included
square.dll, which includes a function that returns
the square of a given real value. We use this function to
calculate the square of an input and to write it to an
output.
Additionally, we implemented an FMU shipped
using a CSV file resource (csv.fmu): The FMI 2.0
standard enforced the importing tool to provide a clear,
IETF RFC3986 compliant URI of resources location
during FMU instantiation. According to the standard,
this URI could be used for a local resources folder
(prefixed by file:///) or for remote ones (prefixed by
http://, https:// or ftp://). The resources folder is
intended to be used only during FMU instantiation. To
test this feature, we created a simple FMU that is
shipped with a csv file in resources folder, which is
accessed during instantiation. This csv file contains an
integer value, and during instantiation we load this file,
set the value stored in the csv file to a local variable and
calculate the square of this value as an output.
3.2.6 FMUs for Testing the Calling Sequence

The FMUSDK has already implemented many
checks regarding the calling sequence. However, we
DOI
10.3384/ecp17132533

have gone through all states again and re-considered the
allowed function calls. The FMI standard describes the
calling sequences for ME and CS using finite-state
machines
and
textual
representations
(Blochwitz et al., 2012). The finite-state machines and
their legends also describe which functions are allowed
in which state, including which categories of the
variables are allowed to be accessed in each state,
regarding the causality-variability-initial attributes.
The FMUSDK functions knows which state the FMU
is in by an indicator and a table of allowed functions
calls in each state is defined. The following features are
already checked by the FMUSDK:
1. Whenever an FMI interface function is called, it
checks whether the current state is among the
allowed states, otherwise it returns fmi2Error.
This ensures the detection of erroneous calling
sequences.
2. fmi2Instantiate  NULL. This can happen if:
a. there is no valid logger function,
b. no allocate/free function provided by importer,
c. the GUID is inconsistent, or
d. model variables did not initialize successfully.
Those features are clearly described in the state machine
graphs. However, there are a few rules mentioned in the
textual description of the FMI standard, that should also
be checked, which are not yet handled by the FMUSDK.
Those features are:
1. Fmi2SetupExperiment should be called at least
once before fmi2EnterInitializationMode,
although they can be called in the same state:
instantiated.
2. stopTime and Tolerance are optional, but
should be handled if set. If stopTimeDefined =
fmi2True, then the independent variable time
must not be set to a value greater than stopTime.
3. In case of CS, after an fmi2SetXXX call, there
must be an fmi2DoStep before an fmi2GetXXX is
allowed. In other words, the order fmi2SetXXX fmi2DoStep - fmi2GetXXX must be followed.
Checks for these features are implemented in a
modified version of the fmuTemplate.h/.c files.
Several FMUs with an increasing difficulty using these
modified template files have been created:
An FMU testing the correct calling sequence for an
algebraic calculation for real variables has been
implemented: (real.fmu): It sums two real inputs and
writes them to the output.
An FMU testing the correct calling sequence for one
continuous state was created (dq.fmu): This is a simple
FMU with a continuous state, we used the Dahlquists
example from the FMUSDK.
Another FMU tests the correct calling sequence for
continuous states and state events (bB.fmu): this is the
BouncingBall example from the FMUSDK, which

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

537

Improving Interoperability of FMI-supporting Tools with Reference FMUs

contains two continuous states and state events. The
simulation time for running this FMU shall be 2s, so that
the phase of minimal amplitudes of the bouncing ball
including the Zeno effect (Fritzson 2004) is currently
excluded from the evaluation.
We used modified fmuTemplate.c/.h files with
the additional checks.to create these FMUs.

chosen carefully from our experience and from most
frequent errors that occur. Examples of these faults are
to initialize FMUs before instantiating, or to exit
initialization mode before entering it. Another example
for CS to call fmi2SetXXX and directly call
fmi2GetXXX afterwards without an fmi2DoStep call
between them.

3.2.7 Testing Variables Access Restrictions

4.2

One of the enhancements brought by the FMI 2.0
standard is the clear definition of variables access
restrictions. The standard added more categories to the
causality/variability attributes, and the initial attribute
was added. According to the standard, a specific set of
combinations are allowed to be used in describing model
variables. Furthermore, there are restrictions in
accessing model variables in each state according to the
attribute combinations of the variables. These
restrictions are considered to be part of the statemachine (Figure 3 and Figure 4), because not only a
specific set of functions are allowed to be called in a
state, but also a specific set of variables are allowed to
be accessed in each state. E.g., discrete variables are
only allowed to be accessed when an event is triggered.
Another example is that the simulator should never set
constant variables. A last example is, that continuous
states may not be set via fmi2SetReal, but with
fmi2SetContinuousStates. This is a basic idea of
this kind of reference FMU and the authors are still
working on these when submitting this paper.
Compared to the current implementation of the
FMUSDK, the template.c/.h and the specific
fmu.c files have to be enriched by additional
information regarding the variable attributes, as the
FMUSDK
does
not
parse
the
modelDescription.xml during FMU creation and
this information is currently not available to the
implementation of the FMU during simulation.

We tested the reference FMUs with 10 different tools
for Windows 64-bit binaries. Most of these tools cope
very well with normal FMUs generated by other
simulation tools. However, with our reference FMUs we
detect some limitations and bugs in the involved tools,
which are communicated to the tool vendors and
implementers.
In Table 1 and Table 2, we depict the result of our
checks of the ME and CS Reference FMUs:

Tests with Importing Tools - Overview

Table 1: Results for ME:
bool

integer string tEvent versionmecs csv

dll

real

dq

bB

dll

real

dq

bB

Tool A
Tool B
Tool C
Tool D
Tool E
Tool F
Tool G
Tool H
Tool I
Tool J

Table 2 Results for CS:
bool

integer string tEvent ver

mecs csv

Tool A
Tool B
Tool C
Tool D
Tool E
Tool F

4 Testing and Using Reference FMUs
We validated our reference FMUs with the FMU
compliance checker, and tested them with several tools.
This led to three tickets for clarification of the FMI
standard version 2.0.1, three tickets for extension to the
FMU compliance checker, several tickets for
improvements of the FMUSDK and several bug reports
regarding errors or improvements the tested tools.

4.1

Implementing an Erroneous Simulator

Two simple open source simulators come with the
FMUSDK that import and run FMUs, one for ME and
one for CS. We used these simulators to perform first
test of the reference FMUs. Then we injected some
faults (or wrong practices) in these simulators to check
that these errors are detected by the reference FMUs and
meaningful feedback is provided. Those faults are

538

Tool G
Tool H
Tool I
Tool J

 OK
 Announced limitation of the tool
 Error or missing feedback for limitations
 Error; possibly standard clarification needed
 ME or CS not supported by the tool
Alone for testing the Windows 64-bit combinations of
10 tools with 11 ME and 11 CS FMUs, it took the effort
of setting up and running more than 200 simulation
models. Additionally, we tested some 32-bit tools, with
no significant differences to the 64-bit results. The effort
of running the tests and diagnosing the results will be
shifted in the future to the tool vendors by including the
reference FMUs in the FMI cross check (see Sec. 5.1).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132533

Session 9A: FMI I

In most tools the FMI import support has a quite
mature quality level, and the problems encountered in
our tests mostly are mainly due to our very strict
diagnostics.

4.3

Problems Detected in Importing Tools

The reference FMUs for data type support revealed
problems of several tools for non-real data types: For the
FMUs testing for Integer and Boolean input data support
(bool.fmu and integer.fmu), five tools show errors in
ME due to violations of the calling sequence: They want
to set discrete values in continuous time mode, which is
forbidden. (Remark: this is not an incompatibilty
between hybrid modeling in Modelica and limitations of
the Modelica standard; several Modelica-based tools do
not have a problem with these FMUs).
The results for the string.fmu reflect, that String
inputs and outputs are not supported by typical blockoriented simulation tools. However, it is expected that
in this case, the tools give a meaningful diagnostic
message during FMU import and not just ignore the
string in/outputs.
The time events FMU tEvents.fmu was successfully
run by all except one tool (violating the calling
sequence).
A 2.0.1 version string in the ver.fmu as foreseen in
the FMI 2.0 standard for a future FMI 2.0.1 FMU is
problematic for all but one tested importing tools. FMUs
following a future FMI 2.0.1 bugfix release, shall be
valid FMI 2.0 FMUs, see (FMI DEV, 2015). Thus, we
suggest not to use the 2.0.1 version string in FMI
2.0.1, but 2.0. FMUs could contain the information
that they follow the FMI 2.0.1 standard in an annotation
in the modelDescription.xml file. This shall be
discussed in the FMI project and clarified for FMI 2.0.1.
Only one tool is not able to import an FMU with both
ME and CS support contained (mecs.fmu), but gives a
meaningful feedback.
The csv.fmu crashes for one tool both in ME and CS.
The dll.fmu detects in one tool a violation of the
calling sequence which is not related to DLL-access.
In ME, in none of the tools, except one, problems due
to the additional checks in the calling sequence
(real.fmu, dq.fmu and bB.fmu) have been detected.
For CS, two tools violate the rule, that there may not be
a call to fmi2GetXXX directly after an fmi2SetXXX
without an fmi2DoStep call in between for real.fmu.

5 Outlook
The implemented reference FMUs will first be
internally shared within the FMI project, e.g. within the
sandbox of the FMI cross check infrastructure. The
intention is to gather feedback both on the concept and
the reference FMUs, to fix bugs and extend the
documentation and to give tool vendors the opportunity
to fix their implementations. The cross check working

DOI
10.3384/ecp17132533

group of the FMI project will review the FMUs and
discuss the proposed requirements on reference FMUs.

5.1

Usage within the FMI Cross Check

After the feedback and review phase within the FMI
project we plan to publish the reference FMUs on the
public part of the FMI projects resources on GitHub.
After acceptance by the FMI project, the part of the
reference FMUs that fit into the FMI Cross Check
infrastructure (e.g., w.r.t. to real inputs/outputs) shall be
committed there and treated as an exporting tool and
extensions to the infrastructure shall be considered.

5.2

Versioning and Indexing

When releasing the reference to the public within the
FMI cross check, we will use a version number to refer
to this release of the reference FMUs.
With the first release, we will propose an indexing of
the FMUs by a naming convention enabling for a serial
execution of the reference FMUs in a meaningful order.
E.g. single-feature diagnostic FMUs should be
performed before complex FMUs, so that the
localization of errors is simplified. In this ordering, as
few features as possible shall be added from one FMU
to the next.

5.3

Extension of Supported Platforms

With the current solution, it is very easy to create
reference FMUs for Windows 32-bit and 64-bit binaries.
In order to support other platforms like Linux (32bit/64-bit) or MAC OS X, the port of the FMUSDK to
Linux (FMUSDK Linux, 2015) could be used.
However, this version is not up to date with the latest
version for the FMUSDK. Linux and OS X versions of
the FMUSDK would be beneficial.

5.4

Increasing the Coverage

The first set of reference FMUS shall be extended by
additional diagnostic and complex FMUs, e.g.:
 for systematically testing all kinds of events (state,
time, externally triggered, zero crossings),
 dealing with a larger number of states (e.g. >=10
states with multiple events), and
 testing for optional capabilities of FMUs (e.g.,
partial derivatives).
Additionally, reference FMUs shall be implemented as
proof of concept of new features of a future FMI
standard from FMI Change Proposals (FCPs).

5.5

Connected FMUs and Parameter Sets

We also propose to extend the FMI cross check and
reference FMUs to connected FMUs: for this purpose
one could use connected FMUs inspired by the FMI 2.0
test FMUs (Test FMUs FMI 2.0 ME). However, these
FMUs are implemented in Modelica, and need a
Modelica tool for the generation of the C-code. Thus, it

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

539

Improving Interoperability of FMI-supporting Tools with Reference FMUs

would have to be clarified, if this can be done with a
publicly available tool chain fulfilling our requirements
listed in 2.4 or a re-implementation in C-code is needed.
The definition of connected FMUs should be realized
using the future System Structure and Parameterization
(SSP) standard for the definition of connected FMUs
(Khler et al., 2016). Additionally, the SSP standard
could be used to test the correct setting of parameter
values to an FMU by the importing tool. For this
purpose, the FMI cross check will have to be extended
for connected FMUs.

5.6

Additional Benefit of Reference FMUs

Reference FMUs can also provide additional example
implementations of FMUs to the FMI community that
can serve as a starting point to implement FMI features
in a good way; in other words, they give hints to the
exporting tools of how typical FMUs could be
implemented. This could help, e.g., for the handling of
additional resources (binaries or other files), where we
have observed many problems of tools in the past.
Reference FMUs can also contribute to clarifying
unclear points of the FMI standard, as demonstrated e.g.
for the version string reference FMU.
Additionally, with reference FMUs we can provide
test FMUs for features that are not yet supported by
(many) exporting tools, e.g. string inputs, provision of
partial derivatives, and serialization of states.

6 Summary
In the current paper, we present the concept for the
creation and usage of reference FMUs. As a starting
point, first reference FMUs have been implemented and
tests with importing tools have been performed, which
led to the detection of several bugs in importing tools.
This is seen as a proof of concept for the idea of
reference FMUs. They shall be made publicly available
first within the FMI project and then publicly by
including them in the regular FMI cross check. With
FMI community effort, the set of reference FMUs and
thus feature coverage shall be increased. This will
contribute to the improvement of quality of FMI
importing tools.

Acknowledgements
The authors want to thank the members of the FMI cross
check working group for their valuable input to our
work.
Many thanks also to Torsten Blochwitz (ESI group),
Umut Durak (DLR Braunschweig), Dan Henriksson
(Dassault Systems), Adrian Tirea (QTronic), Karl
Wernersson (Dassault Systems) for their valuable input
and fruitful discussions.

540

Referenced Tools and Online Documents
(XC, 2014) FMI Cross Check Rules, v3.1, Modelica
Association Project FMI: How to Improve FMI
Compliance, June 2015. [Accessed online on Dec 16th
2016] https://www.fmi-standard.org/tools
(FMI DEV, 2015) FMI Development Process and
Communication Policy, [Accessed online on Jan 22nd 2017]
https://www.fmi-standard.org/development
(FMI 2.0 Standard, 2014) Functional Mock-up Interface for
Model Exchange and Co-Simulation, Version 2.0,
[accessed on Jan 21st 2017] https://www.fmistandard.org/downloads
(FMU CC, 2016) FMU Compliance Checker, Modelon AB,
released by Modelica Association Project FMI [accessed
on Dec 16th 2016] https://www.fmi-standard.org/downloads
(FMUSDK, 2014) FMUSDK 2.0.4, QTronic GmbH, July
2014. [Accessed online on Dec 16th 2016]
https://resources.qtronic.de/fmusdk/
(FMUSDK Linux, 2015) FMUSDK port to Linux and OS X,
[accessed on Jan 6th 2017] https://github.com/cxbrooks/
fmusdk2
(Test FMUs FMI 2.0 ME) Testing FMI 2.0 Model Exchange
features of connected FMUs, Martin Otter, DLR, [Accessed
on Jan 13th 2017] https://www.fmi-standard.org/downloads

References
Bertsch, C., Ahle, E., Schulmeister, U., The Functional
Mockup Interface - seen from an industrial perspective, In:
Proceedings of the 10th International Modelica Conference
2014, Lund, Sweden
Blochwitz, T., Otter M., Arnold, M., Bausch, C., Clau, C.,
Elmqvist, H., Junghanns, A., Mauss, J., Monteiro, M.,
Neidhold, T., Neumerkel, D., Olsson, H., Peetz, J.-V, Wolf,
S., The Functional Mockup Interface for Tool independent
Exchange of Simulation Models, In: Proceedings of the 8th
International Modelica Conference 2011, Dresden,
Germany
Blochwitz, T., Otter, M., Akesson, J., Arnold, M., Clau, C.,
Elmqvist, H., Friedrich, M., Junghanns, A., Mauss, J.,
Neumerkel, D., Olsson, H., Viel, A., The Functional
Mockup Interface 2.0: The Standard for Tool independent
Exchange of Simulation Models, In: Proceedings of the 9th
Modelica Conference 2012, Munich, Germany
Bruegge, B., Dutoit, A. H., Object-Oriented Software
Engineering Using UML, Patterns, and Java, 3rd edition,
Prentice Hall Press, 2009, Upper Saddle River, USA
Fritzson, P., Principles of Object-Oriented Modeling and
Simulation with Modelica 2.1, Wiley, 2004, Hobiken, USA
Hasanagi, M., Tran-Jrgensen, P. W. V., Lausdahl, K.,
Larsen, P. G., Formalising and Validating the Interface
Description in the FMI Standard, FM 2016: Formal
Methods, 2016, Springer, Heidelberg, Germany
Khler, J., Heinkel, H.-M., Mai, P., Krasser, J., Deppe, M.,
Nagasawa, M., Modelica-Association-Project System
Structure and Parameterization  Early Insights, Modelica
Conference Japan, 2016
Pressman, R. S., Software engineering: a practitioners
approach, seventh edition. Publisher McGraw-Hill Higher
Education, (2010), New York, USA

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132533

The Embedded Simulation via FMI
and its Application to the Simulation of Lifetime Tests Including
Wear
Julia Gundermann1

Matthias Thiele2 Sebastian Fraulob3 Susanne Walther1
Todtermuschke1 Uwe Schnabel1

Karsten

1 ESI

2 Institute

ITI GmbH, julia.gundermann@esi-group.com
of Electromechanical and Electronic Design, Technische Universitt Dresden
3 Johnson Electric Germany GmbH & Co. KG Dresden

Abstract
The "Embedded Simulation via FMI" is a new modeling
approach which allows for efficient and fast computation
of systems with a clear separation of time axis or time
scale. For its application the so-called "inner model" is
wrapped into an FMU and embedded into an outer model,
whose dynamics control the integration. The computation
of the embedded model is only utilized on demand. In this
way the "Embedded Simulation via FMI" uses the Functional Mock-up Interface for Co-Simulation in a different
way than it was provided for. The functionality has been
realized within SimulationX prototypically. It is applied to
the simulation of the lifetime test of a linear stepper motor including wear in the screw drive, for which the axial
play after several months runtime shall be determined. A
significant reduction of computing time while preserving
considerable accuracy can be shown.
Keywords: FMI, wear, SimulationX, simulation, mechatronics

1

Introduction

The functional mock-up interface (FMI) defines a tool independent standard interface used for the coupling of different simulation tools (FMI, 2014). It allows for the simulation of multi-component systems. Components of the
system are packed into an functional mock-up unit (FMU),
which is a .zip-file. It contains an xml-file with a model
description and C-functions covering the functionality and
behavior of the model by functions defined by the FMIstandard. The acceptance and application of the FMIstandard is increasing, there are about 90 tools which support FMI. Depending on the simulation task a model can
be exported with (FMI for Co-Simulation) or without its
solver (FMI for Model exchange).
The FMI-standard for Co-simulation is used for the
coupling of component models, which run independently besides the communication after predefined timeintervals. There are examples for which the simulation
of all components is not necessary throughout the whole
simulation time. This is the case, if the systems topology
DOI
10.3384/ecp17132541

can be divided into an inner and an outer model, which
have a separated time axis or time scale. In such cases the
pure FMI for Co-Simulation enforces unnecessary computations of the inner model. The "Embedded Simulation
via FMI" avoids this by calling the computation of the inner model only on demand.

Figure 1. A linear stepper motor based on a screw drive. a)
Complete assembly of the motor to be used as adjusting drive. b)
Dismantled nut thread with ball bearing. These two components
are susceptible to mechanical wear. c) Screw drive without motor in a setup for lifetime testing. The manufacturer of this and
other mechatronic components is interested in the simulation of
these lifetime tests in order to save time during the development
of new components.

One application of this concept is the simulation of lifetime tests of mechatronic (and other) components. Figure 1 shows an linear stepper motor, which underlies wear
effects due to abrasion in the screw drive. The manufacturer is faced with the following problem: the development period of a new component is comparable to the
duration of lifetime tests. The latter are necessary since
they assess the compliance of predefined criteria during
the lifetime of the component. One way out of this problem is the virtual simulation of these lifetime tests. Such
a simulation consists of a high number of repetitions of
nearly identical cycles, i.e. rotating a screw drive back and
forth. During the lifetime the component is subject to wear
and aging effects. These alter the behavior of the component slowly, i.e. on a long time scale, however barely
within the duration of one cycle. However, the current
behavior of a component and the wear phenomena cannot be considered separately, since wear is dependent on

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

541

The Embedded Simulation via FMI and its Application to the Simulation of Lifetime Tests Including Wear

the usage of the component, but vice versa wear and aging modify the response of a system, e.g. debris increases
friction. The manufacturer is interested in a fast extrapolation of the wear effects, yet not in the computation of
each cycle. The virtual simulation of a whole lifetime test
including wear and aging can help to derive information
about the accumulated effects of loads, temperature, etc.,
which in turn can be used for the re-planning, shortening
or even circumvention of real lifetime tests.
The simulation of the wear effect in a lifetime test consisting of many nearly identical cycles is slowed down by
the calculation of the fast degrees of freedom such as the
position of the screw drive. Wrapping these fast degrees
of freedom into an inner model and embedding this inner
model into an outer extrapolation enables to substantially
speed up the simulation. In the "Embedded Simulation
via FMI" the inner model containing the simulation of one
cycle is wrapped into a functional mock-up unit, and then
embedded into an outer integration, which extrapolates the
wear quantities such as the abraded volume.
The remainder of this paper is structured as follows:
In section 2 the concept of the Embedded Simulation via
FMI is illustrated. Section 3 introduces the linear stepper motor. The motor is modeled with components from
SimulationX libraries. The screwDrive - component is extended by a wear model, which is also presented here. The
preparation of the model for the Embedded Simulation is
described in section 4, and its performance is assessed in
section 5. The article closes with a summary.

2

Embedded Simulation via FMI

The Embedded Simulation via FMI allows for an accelerated computation of certain types of coupled simulations, where one models time scale or time axis is separated from the time scale or axis of the other models. The
following small examples shall illustrate the idea and what
is meant by time scale or time axis separation. One of the
examples - the linear stepper - will be illustrated explicitly
in the following section.

 Equation-free modeling / molecular dynamics (Kevrekidis and Samaey, 2009) - time scale
separation: Given is a system with many fast degrees
of freedom (such as molecules), for which the timelike evolution is defined by equations. However, one
is interested in the long-term dynamics of averaged
quantities such as the evolution of the energy or
temperature of the system.
 Simulation of lifetime tests - time scale separation:
The example of lifetime tests including wear and aging was introduced above. These tests - and hence
its simulation - contain a high number of repetitions
of nearly identical cycles. However, one is only interested in the slowly varying quantities such as the
amount of wear debris and the increase of axial backlash, but not in the fast degrees of freedom.
542

Figure 2. Reuse of the Functional Mock-up Interface (FMI).
The upper figure illustrates the usage of FMI in the way it was
designed for. Two models are connected and are simulated in
parallel independently of each other. They exchange variables at
previously defined communication times. The Embedded Simulation via FMI is shown in the lower figure. In contrast to the
Co-Simulation only the outer solver runs for the whole simulation. It calls the inner solver at each of its time steps but not at
predefined communication steps. The inner solver simulates for
the duration of one cycle only. It returns output variables to the
outer solver afterwards. Since the time steps of the outer solver
are expected to be much longer than TCycle , the outer solver continues its calculation at ti , but not at ti + TCycle .

 Model predictive control (Dittmar and Pfeiffer,
2004) - time axis separation: The model predictive
control uses a time-discrete dynamical model of the
process, which is to be controlled. This model shall
compute the future behavior of the process depending of the input signals based on an iterative, finitehorizon optimization of the underlying model.
Common to all three examples is the possibility to split
the system into an inner model - the fast molecules, one
cycle in the lifetime test, or the model predictive control
- and an outer model - the evolution of energy or temperature, the extrapolation of accumulated wear debris, or
the outer system which the controller is part of. The crucial point is that the inner system needs only to be computed on demand, but not for the whole simulation time
of the outer system. For the Embedded Simulation the
inner model is wrapped with its own solver into a FMU
and embedded into an outer model. The latter determines
the time-integration of the overall system. In contrast to
the common usage of the FMI for Co-Simulation the inner model does not run independent from the outer model
and communicates only at previously fixed points in time.
Instead it is run for a predefined (short) time interval, and
only on demand given by the outer model. The number
of calls of the inner model depends on the simulation task.
For systems with time scale separation this number will be

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132541

Session 9A: FMI I

Figure 3. SimulationX model of the linear stepper motor. The components affected by wear are the screwDrive due to abraded
volume and the ballBearing due to an increasing backlash. The latter effect is negligibly small and hence not considered further.
The FMUin/out block on the right is added in preparation of the FMU-Export.

considerably low compared to the ratio between the simulation times of the outer and inner model. In contrast,
for systems with time axis separation no general statement can be made about the number of calls of the inner
model besides that it depends on the variables exchanged
between the embedded inner and the outer model.
Every time it is initiated, it receives input values from
the outer model (such as previous wear debris), while
some other variables have default start values (such as
spindle position). The inner model is reset, initialized,
run, and returns output values to the outer model, and is
reset (Technically it is reset at the beginning of the FMUcall). Figure 2 illustrates the difference to the standard of
FMI for Co-Simulation.
With the Embedded Simulation via FMI it is possible
to speed up simulations preserving considerable accuracy.
Furthermore the inner model is replaceable more easily.
The presented method was realized and tested in SimulationX for an example with time scale separation. The
following section shall illustrate the application of the Embedded Simulation via FMI to the lifetime test of a linear
stepper motor.

3
3.1

The Linear Stepper
The SimulationX model

erage for 1000 steps in one cycle leads to a computation
time of 1.6 s, versus 20 s of real cycle length.

3.2

The wear in the screw drive

The centerpiece of wear processes is the screw drive,
which is modeled by the screwDrive element from the
PowerTransmission library in SimulationX. The linear
stepper model does not contain other wear or aging phenomena such as the increase of backlash in the ball bearing, since the increasing amount of wear debris in the
screw drive is considered as the major effect leading to
system failure.

Figure 4. Bathtub curve determining the value of the wear coefficient k (Eq. (2)) and the friction coefficient  = 0 b(V ). The
parameter b linearly decreases for V < VvEarly, stays constant
until V = VvLate and increases exponentially afterwards. The
values for the regime-changes and the exponential increase are
optimally derived from experiments, but in general they have to
be estimated.

Figure 1 shows a picture of the linear stepper model. In
preparation of the lifetime-simulation it was modeled in
SimulationX, as shown in Figure 3. It is parametrized
such that during one simulation the motor drives the nut
to rotate by a predefined angle forth and back. This rotaThe underlying wear model bases on Archards law,
tion leads to a translation of the spindle a few millimeters
forward and backward. The translation is acting against a
k Fs
dV =
,
(1)
constant force (Load) (in the example, F = 1 N). By conh
struction the angle of rotation increases stepwise, but not
continuously. Each jump triggers an event, which slows where V is the volume of wear debris, dV its increase, F
down the simulation. The step frequency of 50 Hz on av- the total normal load, s the sliding distance. The material
DOI
10.3384/ecp17132541

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

543

The Embedded Simulation via FMI and its Application to the Simulation of Lifetime Tests Including Wear

Figure 5. Simulation results of the linear stepper motor, original
model. Abraded volume in the screw drive vs. simulation time.
The overlaying oscillation is easy to see. Computation step size
was  1s.

Figure 6. Embedded Simulation via FMI of the linear stepper
motor. The wear debris Vv is integrated by the outer solver.
The function blocks event1 and 2 are used to let the outer
solver catch the transition points in the bathtub curve correctly
(cf. section 4).

quantities h and k are the Vickers hardness of the plastics
and the wear coefficient, respectively. In the model here
the wear coefficient is assumed to be dependent on the
wear debris V , and to run through a bathtub curve (Stachowiak, 2006),
integrate more accurately at the regime changes.
k = k0 b(V ).
(2)
The linear stepper model is exported as FMU for CoSimulation 2.0. The wear debris Vv0 at the beginning
The bathtub is shown in Figure 4.
of the cycle is set as input, the derivative derVv and the
The axial play in the screw drive increases due to the
bathtub-differences ZF as output. Further output variables
abraded layer on the flanks. It can be calculated by geoor parameters are optional.
metric construction. The wear debris also feeds back on
The FMU is imported into a new SimulationX model
the current wear process, since the friction coefficient is
and the modelica-component containing it is modified to
not constant, instead,  = 0 b(V ).
make the FMU run in the embedded mode (cf. Figure 2).
Technically the wear is modeled by an extension of the
The main modifications are the replacement of the comScrewDrive component.
munication step size hc by the cycle length Tcycle, and
altered calling of the fmu in order to be re-set, re4 Preparation for the Embedded Sim- the
initialized and run for one cycle everytime it is called.
ulation
Technically the latter was realized in SimulationX by
wrapping all these steps into a single function call.
Per cycle the linear stepper model computes a change in
The output of the variable of interest,
wear volume. Figure 5 shows the wear debris calculated
i.e. derVv.derh is connected to an integral eleduring four cycles. The increasing curve is superimposed
ment, whose output, in turn, is connected to the FMUs
by an oscillation with period equal to the cycle length.
input. For each component of ZF a function block is
For a simulation of approximately 60 days, i.e. rotating
added in order to trigger an event, e.g. event1.y = if
forth and back 259.200 times, one is not interested in this
(fmu.ZF.y[1]>0) then 1 else 0, cf. Figure 6.
oscillation, but more in the long term dynamics. Therefore it suffices to calculate the average change in wear
5 Performance and Validation
debris per cycle, i.e. derVv = (screwDrive.Vv0 screwDrive.Vv)/TCycle, where Vv0 and Vv are To validate the approach, the Embedded Simulation via
the values of wear debris at the beginning and end of the FMI of the linear stepper is compared with a longtermcycle.
simulation of the original model. The simulation time is
For the preparation of the Embedded Simula- set to 60 days.
tion the averaged derivative derVv is calculated in
Using the wear coefficient from experinment, k0 =
an additional element, cf. Figure 3.
Furthermore, 2  1010 , there is little wear and tear within 60 days.
a function element ZF is added, which contains The error tolerances of the outer solver have been chothe regime changes of the bathtub, i.e., ZF.y = sen such that a reduction would not improve the accuracy
{screwDrive.Vv-screwDrive.VvEarly,
significantly, but would slow down the computation speed.
screwDrive.Vv-screwDrive.VvLate}.
Trig- The deviation of calculated wear debris between original
gering events in the Embedded Simulation by adding model and Embedded simulation is smaller than 0.05 %.
if-conditions containing ZF.y forces the solver to The computation time in SimulationX was reduced from
544

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132541

Session 9A: FMI I

Dynardo GmbH Weimar and Johnson Electric Germany
GmbH & Co. KG Dresden (associated partner). Especially the authors but also the involved companies and institutes like to thank the German Federal Ministry of Education and Research (BMBF) represented by the project
coordinator German Aerospace Center (DLR) for supporting financially.

References
Federal Ministry of Education and Research BMBF. Projektblatt
Romesa, 2015. URL http://www.pt-sw.de/media/
content/Projektblatt_ROMESA.pdf.
Figure 7. Comparison of Embedded Simulation with FMI
(pluses, red) and original model (solid line, green) with accelerated effect of wear and tear. The wear behavior switches between regions after some hours, where V v = 103 mm3 , and
after 42 d, where V v = 0.1 mm3 , respectively. These behavior
changes are passed to the outer solver via triggering events. In
the second region, where the wear coefficient stays constant, the
time step size of the outer model reaches its maximal value of
5 d.

Francesco Casella. Simulation of large-scale models in modelica: State of the art and future perspectives. In Proceedings of the 11th International Modelica Conference, pages
459468. The Modelica Association, September 21-23 2015.
doi:10.3384/ecp15118459.
Franois E Cellier and Ernesto Kofman. Continuous system simulation. Springer Science & Business Media, 2006. ISBN
0387261028.
Rainer Dittmar and Bernd-Markus Pfeiffer.

Modellbasierte

about 2.5 days to 1 minute or by the factor 4000, respecprdiktive Regelung: Eine Einfhrung fr Ingenieure. Walter
tively.
de Gruyter, 2004. ISBN 3486275232.
To reveal the dynamics within the region of exponential
increase longer simulation times (with the original model) Functional Mock-up Interface FMI. FMI 2.0, 2014. URL
https://www.fmi-standard.org/.
are needed. On the other hand it is also possible to accelerate the wear by increasing the wear coefficient k0 to Ioannis G. Kevrekidis and Giovanni Samaey. Equation-free mul6  108 . Then the simulation time of 60 days is sufficient
tiscale computation: Algorithms and applications. Annual review of physical chemistry, 60:321344, 2009.
to reach all regions of the bathtub curve. The maximum
difference between the result values of both simulations is
smaller than 0.1%, cf. Figure 7, which also reveals that the G. W. Stachowiak. Wear: materials, mechanisms and practice.
John Wiley & Sons, 2006. ISBN 0-262-16209-1.
solver is able to catch the regime changes in the bathtub.
In this case the computation time was reduced from about
2.3 days to 2.5 minutes or by the factor 1300, respectively.

6

Summary and Outlook

The Embedded Simulation via FMI can speed up certain
types of simulation tasks by preserving considerable accuracy. The new simulation approach was introduced and
motivated by three potential applications. Its successful implementation was proven exemplary for the lifetime
simulation of a mechatronic component including wear.
The application of the Embedded Simulation to the other
two of the named examples or further systems is future
work. It remains to be examined whether other integration approaches such as Quantized State Systems methods (Cellier and Kofman, 2006; Casella, 2015) could serve
as an alternative.

Acknowledgements
The project Robustness and Reliability Simulation
of Mechatronic Systems including Aging and Wear
(ROMESA (BMBF, 2015)) runs in cooperation of ESI
ITI GmbH Dresden, Institute of Electromechanical and
Electronic Design from Technische Universitt Dresden,
DOI
10.3384/ecp17132541

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

545

546

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Integration Modelica with Digital Mockup Tool using the FMI
Shinji Matsuda1

Hiroshi Toriya1

Hiromasa Suzuki2

Koichi Ohtomi2

1

Lattice Technology Co.,Ltd., Japan, {matsuda,toriya}@lattice.co.jp
Department of Precision Engg., The University of Tokyo, Japan, suzuki@den.t.u-tokyo.ac.jp
koichi.ohtomi@delight.t.u-tokyo.ac.jp

2

Abstract
The Delight Design Platform Project is managed by
The University of Tokyo as part of the Crossministerial Strategic Innovation Program (SIP) which
is organized by Cabinet Office, Government of Japan.
This project recommends using 1DCAE design tools in
the concept phase of the product development. In the
Delight Design Platform, new product concepts are
simulated and evaluated as 1DCAE models. One of the
objectives of this project is to prototype a tool for
translating product concepts to 3D models. This paper
describes a method of integrating Modelica with a 3D
digital mockup (DMU) tool. The prototype is
implemented as an extension of XVL Studio, which is a
popular DMU tool provided by Lattice Technology
Co.,Ltd. The integration is implemented using the FMI
(Functional Mockup Interface).

characteristics such as weight and size, but with an
MBD human model it is possible to directly evaluate
the load on the human body. In our prototype, we tried
to perform a realistic evaluation by modeling the
product along with a human model.
This paper describes the integration of Modelica and
DMU tools and some of the resulting outputs.
Figure 1 shows the outline of the integration.

Keywords:
Modelica, 1DCAE, Functional Mockup
Interface, XVL, Digital Mockup

1

Figure 1 Outline of the integration Modelica with XVL
Studio.

Introduction

For many years, Japanese manufacturers placed top
priority on developing high quality products at low cost.
However, nowadays their primary focus is to develop
more attractive products (Ohtomi K, 2015). When
thinking about attractive product design, we focused on
the fact that there are many potentially interesting
product ideas left unattended in the backyard of the
companies without being commercialized. In the
Delight Design Platform Project, we are trying to
support the development of attractive products by
visualizing the attractive qualities of new ideas. The
technology of Model Based Design (MBD),
represented by Modelica, is one of the key
technologies in our project. In this paper, we propose a
method to visualize the MBD simulation results in a
DMU tool using FMI. By integrating with the DMU
tool, the simulation results can be represented with
realistic 3D graphics which makes the presentation
more impressive and persuasive. Also, the DMU tool
has another useful feature  it supports the inclusion of
a 3D human model, which is a very effective way to
perform human work analyses. For example, product
usability can be evaluated using estimates for product

DOI
10.3384/ecp17132547

2

XVL and DMU Tool

XVL (eXtensible Virtual reality description
Language) is a lightweight 3D file format developed by
Lattice Technology Co.,Ltd. And XVL Studio is a
digital mockup tool based on the XVL technology
(Lattice Technology, 2016). It is widely used for
design review, digital assembly and generating
technical illustrations (Toriya H. 2008).
The file size of a complete model of an automobile,
a piece of construction equipment, an agricultural
machine, a train or a ship can easily reach several GB,
and it is difficult for CAD systems to handle such large
assemblies. In these cases a lightweight 3D file format
such as XVL is more effective (Toriya H. 2014; Toriya
H., Jablonski M., 2017).
Digital Assembly is the concept of performing a
virtual assembly validation without using an actual
prototype. It requires managing multiple structures for
each product. Using XVL it is possible to define
multiple structures in a single file -- for design, for
manufacturing and for service. This makes it possible

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

547

Integration Modelica with Digital Mockup Tool using the FMI

for the user to easily change the design structure to the
desired structure, such as the manufacturing structure.
XVL is also capable of handling the large point
cloud data generated by laser scanners. 3D point cloud
data is a new technology that makes it easy to convert
existing facilities to 3D models. For example, a 3D
point cloud scan of a facility makes it possible to check
whether new equipment will fit in the existing space.
The following chapters will include an example of
using 3D point cloud data.

3

3D Model Generation

In the libraries provided by Modelica we want to
highlight here is MultiBody library. Since MultiBody
library is targeting to 3D mechanical system, we
integrate the library with a DMU tool for visualizing
mechanical simulation.

Figure 3 3D model (with NURBS surface)

3.1 Geometry

Table 1 Components supported in the prototype.

Some of the Commercial products for Modelica
modeling support 3D visualization (Figure 2). But it is
limited only for visualization purpose. In most cases,
reuse of the visualization data is not considered.

Figure 2 3D visualization in Dymola (Dassault Systmes,
2016).

Each component in the Multibody library has the
parameters of the visualization such as the sphere
diameter or the length of the cylinder. We have
implemented the parser, which parses the information
of the visualization, and a generator which generates
B-Spline surface using XVL Kernel. Most of the
Modelica tools support only polygon data as 3D model.
However, NURBS models are more common than
polygon models in 3D CAD system (Figure 3). The 3D
model can be exported as IGES file format with the
standard command of XVL Studio. The IGES files can
be imported to most of the CAD systems.

Our prototype generates 3D models from the
Modelica components listed in the Table 1.
Package
MultiBody
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Joints
MultiBody.Parts
MultiBody.Parts
MultiBody.Parts
MultiBody.Parts
MultiBody.Parts
MultiBody.Parts
MultiBody.Parts

Model
World
Prismatic
Revolute
Cylindrical
Universal
Spherical
SphericalSpherical
UniversalSpherical
JointUPS
Fixed
FixedTranslation
Body
BodyShape
BodyBox
BodyCylinder
PointMass

3.2 Assembly Structure
The CAD system or the DMU tool has an assembly
structure which is defined as a tree structure (Figure 4).

Figure 4 An assembly tree in the XVL Studio.

The assembly structure has an important
functionality in CAD system (also in DMU Tool), that
is locating its sub-components in the model coordinate
system. An assembly has the information of its sub548

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132547

Session 9A: FMI I

components and the transformation matrix for each
sub-component. User can move a sub-component by
changing its translation matrix. This functionality can
be used to animating the simulation result in the DMU
Tool. The appropriate structure should be created while
generating the 3D model from Modelica. For example
a Body component connected to a Revolute joint, has
to be moved synchronizing with the rotation of the
joint (Figure 5). To do this, the 3D model of the joint
and the model of Body should belong to one assembly
group (Figure 6).

Figure 5 Example model with a Revolute and a Body.

Figure 6 Assembly tree of the example, which shows the
shape of the body prt_body and the shape of revolute
revolute are included in one assembly body.

4

Kinematics

The MultiBody Library of Modelica is designed to
simulate both kinematic and dynamic mechanical
models (Martin Otter, et al. 2003). The analysis of
kinematics is one of the most popular features of 3D
CAD systems. XVL Studio (A DMU Tool) also has the
functionality of the kinematic analysis. The revolute
joint, the linear sliding mechanism and some other
types of kinematic objects can be defined in XVL
Studio (Figure 7).

While reading the Modelica model, the kinematic
information is translated to the kinematic objects of
XVL Studio. For example the information of the
revolute joint of the Modelica is translated to the
information of the Rotation Axis object in XVL Studio.
It has following information as the kinematic object
(Table 2).
Table 2 The kinematic information of the Rotation Axis
in XVL Studio.

information
data type
Joint Name
text
Point of the origin
vector
Rotational Axis
vector
Rotational part
text
Fixed part
text
An instance of the revolute joint defined as
revolute1 in a Modelica file is translated as follows.
The instance name of the Modelica is translated to
the name of the Rotation Axis of XVL. The Point of
the Origin of XVL is calculated by traversing the
connection of the Modelica model. The parameter n
of the revolute joint is translated to the vector of the
rotational axis in XVL. The Rotational part and the
fixed part in the XVL are also found by traversing the
connection of the Modelica model.
This information is used for the 3D animation in
XVL Studio.

5

Running Simulation

The DMU Tool does not have the functionality to
generate the executable module for simulation. The
prototype runs the simulation using FMI. We used FMI
Library by JModelica.org in our prototype for running
the simulation. FMU module is generated by using a
small batch command. Following is an example batch
command for JModelica.
@echo off
call C:\JModelica.org-1.17\setenv.bat
if %errorlevel% neq 0 exit /b 1
echo from pymodelica import compile_fmu
>>_t3.py
echo mn = '%1'>>_t3.py
echo mf = '%2'>>_t3.py
echo my = compile_fmu(mn, mf, target='cs',
version='2.0')>>_t3.py
"C:\Python27\python.exe" "_t3.py"
if %errorlevel% neq 0 exit /b 2

This batch file takes 2 arguments. One is the name
of the model, and the other is the name of the Modelica
file. It generates a python script as _t3.py and call
python.exe.

5.1 FMI Interface
Figure 7 GUI of the kinematic analysis in XVL Studio.

DOI
10.3384/ecp17132547

The FMI (Functional Mockup Interface) is the standard
which enables running the simulation from any tools
(FMI-Standard.org, 2014). There are publicly available

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

549

Integration Modelica with Digital Mockup Tool using the FMI

FMI implementations. For example, FMI Library
(JModelica.org, 2016) is a library developed by
JModelica.org can be downloaded in source code or
binaries for Windows. Using the library, all of the steps
for running the simulation can be executed by simple
function call, like unzipping the FMU module or
parsing the modelDescription.xml. Our prototype is
implemented to use the FMI Library.

5.2 3D Matrix
The connector of the MultiBody Library is defined as
the Frame. Frame model is defined in the package
Interfaces as following.
connector Frame
SI.Position r_0[3]
Frames.Orientation R
flow SI.Force f[3]
flow SI.Torque t[3]
end Frame;

To use the existing CAD data in our prototype, just
drag and drop the CAD file to XVL Studio. Following
instructions show how to use the CAD data in the
prototype.
 Import Modelica model to the prototype.
 The 3D visualization model is generated. (Figure
9)
 Import CAD data to DMU Tool. (Figure 10)
 Move parts of the CAD model to the group under
the visualization model. (Figure 11)
 Run simulation. (Figure 12)
Using the integration Modelica and DMU Tool the
simulation can be visualized with CAD model with
simple operations like this.

The position vector r_0 is directed from the origin of
the world coordinate system to the origin of the Frame.
The orientation object R describes the relative
orientation between the world frame and the Frame.
From these parameters, we can generate a
transformation matrix which is used to animate the 3D
object in DMU Tool.
. [, ]
|| = |. [, ]
. [, ]


. [, ] . [, ]
. [, ] . [, ]
. [, ] . [, ]



_[]
_[]
|
_[]


(1)

This translation matrix moves the 3D object in the
DMU model. The values r_0 and R.T of the
components in the Modelica model are referred while
running the simulation and are used for the animation
of 3D model.

Figure 9 3D visualization model generated with the
prototype.

5.3 Using CAD Model
Using the 3D CAD model of the existing products, the
presentation of the simulation result becomes more
realistic. The DMU Tool has the functionality to
import CAD model. Most of the DMU Tools support
many types of the CAD format. Figure 8 is the list of
the supported formats in XVL Studio.

Figure 10 CAD model is imported over the visualization
model.

Figure 8 CAD format supported by XVL Studio.

550

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132547

Session 9A: FMI I

Drag & Drop

Figure 11 Move CAD model to the group generated with
the 3D visualization model.

Figure 13 Modelica model of a mobile crane.

Figure 12 Simulation is visualized with the CAD model.

6

Example

We create a crane model in our project. The CAD data
of a crane is provided by a Japanese manufacturer of
mobile cranes.

Figure 14 3D skeleton data generated by the prototype

6.1 Crane Model
Figure 13 is a crane model created with Dymola. It
consists of 2 revolute joints for simulating the fall over
problem. 2 revolute joints and 4 prismatic joints are for
simulating the movement of the boom. One prismatic
joint held in the revolute joint and a universal joint are
for the extending of the wire. Figure 14 is a screenshot
of the prototype showing the 3D model generated from
the Modelica file. As instructed in chapter 5.3, CAD
model of the product can be imported (Figure 15).
Figure 16 is the screenshot of the final 3D model,
which includes the 3D skeleton model generated from
the visualization information defined in Modelica,
CAD data of the product design and point cloud of the
construction field. The point cloud is measured with
the laser scanner and imported to XVL Studio.

DOI
10.3384/ecp17132547

Figure 15 A screen shot after imported the CAD model.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

551

Integration Modelica with Digital Mockup Tool using the FMI

7

Figure 16 A screen shot after imported point cloud.

Using this model, we have simulated the swing of
the load while turning the Boom (Figure 17). Figure 18
shows the simulation of the problem of fall over of the
full vehicle.

Human Model

Analyzing the human interaction, during the
production in the factory is one of the important usecase of the DMU tool. Some of the DMU Tools has the
functionality of evaluate the posture of the worker
using 3D human model. On the other hand there are
some biomechanics software enables to analyze the
human muscle bone model. For example DhaibaWorks
developed by National Institute of Advanced Industrial
Science and Technology (AIST, 2016) is well known in
Japan. These bio-mechanics software are for the expert
users in the laboratory of the universities or the
enterprise. Our target in the Delight Design Platform is
to develop a human model easy to use for engineers in
the manufacturer using the Modelica technology.

7.1 Muscle-Bone Model Prototype
Our first prototype was a generator, which generate a
simple 3D muscle-bone model using the kinematics of
XVL. The generator reads a BVH file, and generates a
XVL model referring the structure data in the BVH file.
The BVH file format is originally developed by
Biovision as a motion capture data file format
(Autodesk, 2016).
In this model, there are 16 skeletal joints. We
defined degree-of-freedom for each joint, and
associated prime mover muscle (Table 3).
Table 3 Mapping of the skeletal joint and muscle.

skeltal joint
Left/Right Thigh

Figure 17 A screenshot simulating the swing of the load
while turning the Boom.

Figure 18 Simulating the problem of fall over when the
boom was tilted.

552

axis
associated muscle
x
psoas l/r
y
gluteus l/r
z
piriformis l/r
Left/Right Leg
x
femoris l/r
Left/Right Foot
x
surae l/r
y
peroneus l/r
Chest
x
abdominis
y
ex oblique
z
in oblique
Left/Right Shoulder
y
trapezius l/r
z
pectoralis min l/r
Left/Right Arm
x
pectoralis maj l/r
y
deltoid l/r
z
spinatus l/r
Left/Right Forearm
x
biceps l/r
y
pronator l/r
Left/Right Hand
x
digitorum l/r
y
carpi l/r
Head
x
sternocleido
y
splenius
The basic model of a set of joint and muscle is
shown in Figure 19.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132547

Session 9A: FMI I

Figure 19 The basic model with one rotational joint and
one JointUPS.

The Revolute component is associated to one degree of
freedom of a skeletal joint. The JointUPS component is
associated to the prime mover muscle. Similarly, we
generated instance for all joints (Figure 20).

Figure 22 A 3D muscle bone model with skin.

In this model the properties of mass and the inertia
tensor are calculated by the skin data of the 3D model.
This concept is as same as the one in the paper
Redundancies in Multibody System and Automatic
Coupling of CATIA and Modelica (Hilding Elmqvist et
al., 2009). Also the value in the TimeTable which is
the input of the JointUPS is embedded from the value
in the BVH motion data. Figure 23 is a table plot of the
motion data in Dymola. The input of the JointUPS is
the relative distance and it is calculated from the Euler
angles of the joint contained in the BVH file.

Figure 20 A Modelica model of the muscle bone model.

We prepared a 3D model with kinematic definitions
referring a 3D human model for anatomy (Figure 21).
The prototype generates the Modelica model from the
geometric and kinematic information in the 3d model.

Figure 23 A table plot of the motion data embedded in
the Modelica model.

Figure 21 Defining the fixing position of the muscle to
the bone. The left is an anatomy model and the right is a
kinematic model.

We have visualized the force of the JointUPS as
color mapping. Figure 24 is a sample showing the
color mapping of the human model while using the
hair-dryer. Our prototype generates the color mapping
as a key frame animation of XVL Studio.

A skin model created with CG software is added just
like the CAD model written in the section 5.3 (Figure
22).

DOI
10.3384/ecp17132547

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

553

Integration Modelica with Digital Mockup Tool using the FMI

Kinematic and Dynamic Analysis for Biped Robots
Design (David M., 2012).
We have used a modified one point contact model in
the following example. This model is a passive
dynamic walking model, which is intended to simulate
the human gait (Figure 27, Figure 28).

Figure 24 The visualization with the color mapping.

Following charts are samples of the simulation
result. Figure 25 is a chart showing the length of the
JointUPS placed at the position of the biceps. Figure 26
is the force of the JointUPS. Since the sampling rate of
the motion capture is not high, the force of the
JointUPS is filtered with Blocks.Continuous.Filter
component.

Figure 27 The passive dynamic walking model.

Figure 25 The length of the biceps.

Figure 28 Animation view of the passive dynamic
walking model.

Figure 26 The force of the biceps.

7.2 Reaction Force on the Ground
Our first prototype described in the previous section
has some problems. For example it does not simulate
the reaction force from the ground. There is a contact
library for the MultiBody Library, proposed as the
IdealizedContact (Oesterstebier et al., 2014). Also a
simple point contact model is proposed in the paper

554

In this model, 2 BodyShape components
corresponding to the legs are connected to the
PointContact component. The torque of the revolute
joint corresponding to the knee is controlled as zero
when the reaction force from the ground is zero. It
holds the knee angle while the reaction force from the
ground is above zero.
The gravity vector is tilted from Z axis. With the
gravity the walking motion is continued. Since the legs
of the model are placed at the same position in Y
direction, the model fell down sideway after 10 steps.
The simulation can be animated with the skin of the
human model installed with XVL Studio (Figure 29).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132547

Session 9A: FMI I

Figure 31
Figure 29 The walking model with the skin in XVL Studio.

8

Future Work

In the future work, we plan to extend the functionality
of the prototype, and evaluate in the actual product
design.
In the next prototype of the human model we will
not use the muscle bone model. The forces of the
muscle will be calculated from the torque of the joint
inside the DMU Tool. Because of the detailed
evaluation of each force of the muscles are not required
in the use case of the DMU Tool. The reaction force on
the ground described in the section 7.2 will be included
in the next prototype. And the calculation of the gravity
center of the whole body will be included. It helps to
evaluate the working posture which is the main use
case of the human model of the DMU Tool. In the
Figure 30 left image is a typical human model holding
a box which is created with XVL Studio. Since the
gravity balance is not considered, the simulation model
fall down foreword like the image right side.

Also, the automatic generation of the models
corresponding to human bodies of various physiques is
planned.

9

Conclusion

This project demonstrated significant advantages using
a DMU tool as a Modelica front-end. The advantages
are as follows.
 Enables visualization of simulation results with 3D
CAD models and/or 3D scan data.
 Enables easier 1D modeling by using the 3D user
interface of the DMU Tool.
 Better visualization of results will promote the use
of Model based design.
Further advantage can be expected with the future
work described in the previous section.

Acknowledgements
The authors wish to thank Takayuki Kosaka
(TADANO LTD.) and Marc Jablonski for their
contributions and feedbacks. This research and the
prototype were supported by New Energy and
Industrial Technology Development Organization
(NEDO) of Japan, and we would like to thank them for
their assistance.

References

Figure 30 A typical human model holding a box.

Figure 31 shows the posture considered gravity balance.
In this way, by using Modelica simulation in DMU
Tool more natural posture can be created.

DOI
10.3384/ecp17132547

Autodesk (2016): BVH File Specification.
http://www.autodesk.com
Dassault Systmes (2016): Dymola 2016
http://www.Dymola.com
David Mauricio Alba Lucero. (2012): Kinematic and
Dynamic Analysis for Biped Robots Design.
Felix Oestersotebier, Peng Wang and Ansgar Trachtler.
(2014): A Modelica Contact Library for Idealized
Simulation of Independently Defined Contact Surfaces.
FMI-Standard.org (2014): Functional Mockup Interface for
Model Exchange and Co-Simulation Version 2.0, July 25,
2014. https://www.fmi-standard.org

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

555

Integration Modelica with Digital Mockup Tool using the FMI

Hilding Elmqvist, Sven Erik Mattsson, Christophe Chapuis.
(2009): Redundancies in Multibody Systems and
Automatic Coupling of CATIA and Modelica. In:
Proceedings of the 7th International Modelica Conference.
JModelica.org (2016): FMI Library 2.0.2
http://jmodelica.org
Lattice Technology (2016): XVL
http://www.lattice3d.com/
Martin Otter, Hilding Elmqvist and Sven Erik Mattsson
DLR; Dynasim: (2003): The New Modelica MultiBody
Library. In: Proceedings of the 3rd International Modelica
Conference, Linkoping, November 3-4, 2003.
National Institute of Advanced Industrial Science and
Technology (AIST) (2016): DhaibaWorks
http://www.dhaibaworks.com
Ohtomi, K. (2015): Kansei Modeling for Delight Design
based on 1DCAE Concept. In: Proceedings of the 11th
International Modelica Conference, Versailles, France,
September 21-23, 2015. doi: 10.3384/ecp15118
Toriya, H. (2008): 3D Manufacturing Innovation. doi:
10.1007/978-1-84800-038-4
Toriya, H. (2014): Manufacturing Innovation Based On
Lightweight 3D Technology. In: The 4th IIEEJ
International Workshop on Image Electronics and Visual
Computing 2014.
Toriya H., Jablonski M. (2017): 3D Manufacturing
Evolution: Evolutionary Change in Global Manufacturing
with Digital Data. ASIN: B01N29ZFZM

556

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132547

Solving Large-scale Modelica Models:
New Approaches and Experimental Results using OpenModelica
Willi Braun1
1 FH

Francesco Casella2

Bernhard Bachmann1

Bielefeld, Bielefeld, Germany, {willi.braun,bernhard.bachmann}@fh-bielefeld.org
di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy,

2 Dipartimento

francesco.casella@polimi.it

Abstract
Modelica-based modeling and simulation is becoming increasingly important for the development of high quality
engineering products. Therefore, the system size of interest in a Modelica-based simulation is continuously increasing and the traditional way of generating simulation
code, e.g. involving symbolic transformations like matching, sorting, and tearing, must be adapted to this situation.
This paper describes recently implemented sparse solver
techniques in OpenModelica in order to efficiently compile and simulate large-scale Modelica models. A proof
of concept is given by evaluating the performance of selected benchmark problems.
Keywords: Modelica, large-scale, sparse solver techniques

1

Introduction

The design and safe operation of modern large-scale
cyber-physical systems requires the ability to model and
simulate them efficiently. The Modelica language is optimally suited for the modelling task, thanks to the highlevel declarative modelling approach and to the powerful
object-oriented features such as inheritance and replaceable objects. On the other hand, as noted in (Casella,
2015), until recently the development of Modelica tools
has been focused on the modelling of moderate-sized
models, optimizing the simulation code as much as possible by means of structural analysis and symbolic processing of the system of equations.
Large system models are usually characterized by a
high degree of sparsity, since each component interacts
only with a few neighbours, so that each differentialalgebraic equation in the model only depends on a handful of variables. The availability of reliable open-source
sparse solvers (Hindmarsh et al., 2005; Davis and Natarajan, 2010) and of cheap computing power and memory
even on low-end workstations opens up the possibility of
tackling much large system models, featuring hundreds of
thousands or possibly millions of equations, exploiting the
sparsity of such models for their solution.
In particular, the interest in the use of Modelica for
the modelling and simulation of national- and continentalsized power generation and transmission systems recently
DOI
10.3384/ecp17132557

motivated a first exploratory effort in this direction, using
OpenModelica as a development platform, see (Casella
et al., 2016). The methods implemented for the power system studies also allowed to efficiently simulate the cooling blanket of the future DEMO nuclear fusion reactor,
which requires the modelling of thousands of individual
heat-exchanging pipes, see (Froio et al., 2016).
The goal of this paper is threefold: to discuss different
strategies for the simulation of large-scale Modelica models using sparse solvers; to describe an implementation
of such strategies in the OpenModelica Compiler (OMC),
using open-source solvers; finally, to present and discuss the performance obtained in a number of benchmark
cases. The numerical methods are discussed in Section 2.
The simulation performance is analyzed on three sets of
benchmarks: the ScalableTestSuite library (Casella, 2015;
Casella and Sezginer, 2016), some large power system
models (Casella et al., 2016), and large high-fidelity models of the cooling system of the future DEMO nuclear fusion plant (Froio et al., 2017); results are reported in Section 3. Finally, Section 4 concludes the paper and gives an
outlook to future work.

2
2.1

Solving Modelica Models
ODE mode

2.1.1 Symbolic Transformation Steps
In common Modelica tools the compile process can be
summarized with the following steps, which are also explained in (Cellier and Kofman, 2006):
Flattening The Modelica model is transformed by the
front-end into a flat representation, consisting essentially of lists of variables, functions, equations and
algorithms.
Pre-Optimization In this phase a basic structural analysis of the differential-algebraic equations (DAE) is
performed, e.g. detecting the potential states and discrete variables, eliminating alias variables.
Causalization This is a basic step in a Modelica Compiler, the so-called BLT-Transformation. Matching,
sorting, and index reduction algorithms are applied

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

557

Solving large-scale Modelica models: new approaches and experimental results using OpenModelica

in order to causalize the DAE and transform it to a 2.1.2 Numerical Solving Process
system of ordinary differential equations (ODE).
For the simulation of the generated ODE equation (5) a
Post-Optimization In this phase further optimization numerical integration method for solving the differential
processes are applied on the equation system, e.g. equations as well as linear and non-linear system solvers
the optimization of algebraic loops, like tearing, or for the implicit equations (4) are needed . In the next secthe generation of corresponding symbolic Jacobians. tion the utilized methods and the exploitation scope for
sparsity are described.
Code-Generation The final step after the symbolic maThe numerical integration can be performed with exnipulation is the target code generation for the opti- plicit or implicit methods, whereby the implicit apmized system in order to perform the simulation.
proaches are used in a Modelica environment more often,
For this description and without lack of generality, and since most problems arising in practice are stiff. For exfor clarity of the presentation, only the continuous part of plicit methods the next step can be calculated by
the DAE is considered in the following. The result of the
Flattening is the equation system:
F(t, x(t), x(t), u(t), y(t), p) = 0,
x(t0 ) = x0

x(t + t) = (x(t), u, p,t, t, f ),

(7)

t  [t0 ,t f ]

whereby  is calculated by explicitly evaluating the func(1) tion f in formula (5). Therefore, sparse methods can only
be applied for calculating the solution of algebraic loops
where x(t)  Rnx are the potential state derivatives, x(t)  with respect to equation (4). The handling of sparse algeRnx are the potential states, u(t)  Rnu are the inputs and braic loops is described below.
y(t)  Rny are the algebraic variables. For simplicity, the
For implicit methods the next step has to be calculated
initial conditions of the DAE states are given by x0 . Intro- by
ducing z = (x y), denoting the unknowns of the DAE, and
x(t + t) = (x(t + t), u, p,t, t, f ),
(8)
v = (x u), denoting the known variables, the DAE can be
whereby the evaluation of  involves the solution of a
re-written as
F(z, v) = 0
(2) non-linear system using equation (5). The most widely
used method for solving such non-linear systems is Newthat is basically the result of the Pre-Optimization.
tons method and the core of it is to solve consecutive a
The conceptual idea of the DAE Causalization comlinear system of the form
monly used in Modelica tools is to get an ordering of the
unknowns z(t), which enables to solve them sequentially
J  (x(t + t)  x(t)) = F
(9)
nx +ny
(3)
z = G(v)  R
where F denotes the residual form of equation (8) and J
If index reduction is necessary, some of the potential states is the corresponding Jacobian matrix. The solution of this
and state derivatives become algebraic and the number of linear system offers some potential to gain performance
equations might change. The general form of the causal- for large-scale systems. Firstly, the matrix J can be calcuized system consists of a sequence of assignment state- lated by exploiting the sparsity of the system, both numerments including implicit systems of equations (algebraic ically and symbolically. Naturally, this includes the storloops)
age of the matrix in a suitable sparse format to reduce the
memory consumption. Secondly, in order to solve equa0 = gi (zi , z1 , . . . , zi1 , x, u), i = 1, . . . , k
(4)
tion (9) sparse linear solvers (e.g. sparse LU factorization)
can be utilized. For that purpose several methods have
where
k
been developed and made publicly available (Davis and
z = (z1 , . . . , zk ), zi  Rni ,  ni = nx + ny .
i=1
Natarajan, 2010; Davis, 2004).
Finally, the ODE may be re-written
For calculating the solution of algebraic loops with respect
to equation (4) the same sparse solution methods can
x = f (x, u, p,t)
(5)
y = h(x, u, p,t)
(6) be utilized to gain some performance.
where y are the outputs of the system. Note that the other
algebraic variables of y are considered to be internal to the
ODE in this representation.
In the Post-Optimization mainly algebraic loops are
torn down (Tuber et al., 2014) and the symbolical Jacobians are determined where applicable. Also the sparsity
pattern of equation (5) is detected, which can be employed
for the numerical jacobian calculation of the integration
method (see also (Braun et al., 2012)).
558

2.2

Simulation in DAE mode

An other way to go is to pass-through the whole system of
equation (2) directly to an DAE solver, instead of using the
ODE solver for integration and solve the implicit parts of
equation (5) explicitly by algebraic solvers. Due to the fact
that the index reduction is an important step for better convergence to the solution (Brenan et al., 1996), it is preferable to pass the system with index 1 (eq. (3)). Also, if
the simulation is performed with equation (3), some time

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132557

Session 9B: Numerical & Symbolic Methods

consuming steps in the Post-Optimization compiling process, which deal with algebraic loops, namely tearing and
the generation of symbolic Jacobians, can be skipped. A
DAE solver is always an implicit solver and has to solve
an non-linear system, which is usually solved using some
variants of the Newtons method (Brenan et al., 1996).
Thus, all the local implicit algebraic loops are solved all
together by the global routine. One effect of using equation (3) instead of solving equation (5) is that the Jacobian
matrix gets bigger, since the integration method needs to
solve for the variables x, x and y instead only for x. But
this also preserves the sparse structure of the equation system with respect to Modelica models. In the ODE mode
the corresponding Jacobian matrix is more dense due to
the fact that the algebraic variables y are considered as internal variables.
Note, that in the current status of the DAE mode implementation it is still mandatory to generate the causalized code for proper handling of synchronous events and
discrete variables. Therefore, OpenModelica generates
currently an additional system in DAE mode. However,
it is possible to skip unnecessary compiling steps by
some specific compiler flags, which are documented in
the OpenModelica Users Guide (Open Source Modelica
Consortium).

2.3

Implementation in OpenModelica

The default simulation in OpenModelica is performed by
solving system (5) using DASSL as a pure ODE solver.
Hereby, the implicit parts (algebraic loops) are solved explicitly with algebraic equation solvers, the linear parts
with lapack and the non-linear parts with a newton-based
solver implemented in OpenModelica (Bachmann et al.,
2015).
For the simulation of large scale Modelica models the
most important part is a suitable sparse linear solver as
depicted in section 2.1.2. Currently, one of the best under
public domain available direct sparse linear solver for unsymmetric problems is the KLU solver (Davis and Natarajan, 2010) from the sparse matrix suite SuiteSparse. This
solver is designed for solving sequences of unsymmetric
sparse linear systems that arise from differential-algebraic
equations, occurring when simulating electronic circuits.
In fact, the linear systems arisen when simulating Modelica models are in general unsymmetric and often sparse,
both in ODE and DAE mode. The open-source software
family called SUNDIALS offers as a DAE solver the IDA
solver (Hindmarsh et al., 2005). The IDA solver stands
for Implicit Differential-Algebraic solver and is based on
DASSL, but is written in ANSI-standard C. Further, for
the solution of the underlying non-linear system at each
time step, the IDA solver offers an interface to the sparse
linear solver KLU. Furthermore, the SUNDIALS suite includes also a newton-based non-linear solver KINSOL,
which is also able to use the KLU solver for the underling
linear system. Through the connection of SUNDIALS and
SuiteSparse suite to the OpenModelica environment it is
DOI
10.3384/ecp17132557

now possible to rely on sparse methods at every step of
the numerical simulation process.

3
3.1

Performance Results
Benchmarks from the ScalableTestSuite

3.1.1 Test set-up
The ScalableTestSuite (Casella, 2015; Casella and
Sezginer, 2016) contains a number of different benchmark
models, whose size can easily be chosen by setting one or
more Integer parameters. The benchmarks are designed
to stress some aspect of the code generation and execution, e.g. by possessing large implicit systems of algebraic equations, large number of states, large number of
event-generating functions, etc. Please refer to the library
documentation for further details.
This section reports the performance of a selection of
nine benchmark models, each one coming in three different sizes.The results obtained with four different numerical solution strategies are presented and compared. Note
that the current set of benchmarks does not include systems with large implicit systems of nonlinear equations 
these will be added in the final version of the paper.
The first solution strategy, labelled OD in the result table, is the default approach to solving Modelica models
implemented in the OpenModelica tool (see section 2).
The DAEs are turned into ODEs by solving them for the
derivatives, using the BLT transformation to do so efficiently, applying symbolic index reduction if the system
has index greater than one. The implicit equations in the
BLT corresponding to strong components in the dependency graph are solved with dense linear and nonlinear
equation solvers, using tearing to reduce the size of the
implicit part of the problem and thus somehow exploiting
sparsity. The ODEs are then solved by the DASSL BDF
integrator, using a dense linear solver for its internal operations.
The second strategy, labelled OS, still resorts to causalization; however, the implicit equations corresponding to
the strong components in the BLT are solved by the Kinsol/KLU sparse solvers, while the ODEs are solved by
the IDA BDF integrator, relying on the KLU sparse linear solver internally.
In this case, tearing is not applied to solve the implicit
equations corresponding to strong components in the BLT.
The rationale behind this decision is that on the one hand,
the sparse solver already vastly reduces the computational
complexity, if the system is highly sparse. On the other
hand, tearing very large systems might take a disproportionately large amount of time by the compiler back-end,
so that the time savings at run time are likely to be more
than offset by the much longer code generation time. In
fact, this trade-off would itself deserve to be studied, but
that goes beyond the scope of the present paper.
The third strategy, labelled DA, is to only apply symbolic index reduction (if needed) to the DAEs, and then

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

559

Solving large-scale Modelica models: new approaches and experimental results using OpenModelica

use the sparse IDA solver directly to solve them over time.
The fourth strategy, labelled DD, is a variant of the former one, in which the subset of the DAEs that is strictly
required to be solved in order to compute the state variables at the next time step is identified and passed to the
sparse IDA solver. Once the new time step has been computed and accepted as valid by the error estimation routine, the remaining equations are solved for the remaining variables by OpenModelica-generated code, exploiting the usual BLT decomposition to solve them efficiently.
This strategy can be advantageous because it avoids
computing unnecessary variables during the internal
solver iterations, particularly when tentatively computing
a step that may then be rejected by the error estimation
routine. Also, it is often the case that the dependencies
in the systems are such that, once the variables required
to advance the states have been computed, the remaining
ones can be computed by explicit assignments. Furthermore, these are only computed once instead of getting unnecessarily involved many times in the iterative solution
of the implicit sparse nonlinear DAEs.
As to the initialization problem, with the first strategy
the standard dense linear and nonlinear solvers with tearing are used; with the other three, the sparse solvers Kinsol/KLU without tearing are used instead.
All tests were carried out on the Open Source Modelica Consortium continuous testing infrastructure, using
the development version 1.12.0 of OpenModelica. The
computer used to run the tests is a 16-core Intel i7-6900K
CPU @ 3.20 GHz, with 132 GB RAM.
3.1.2

Results and discussion

Table 1 reports some selected results, showing the number of equations NE, number of states NS and the running times of the simulations in seconds, including the
time spent for initialization, for the four above-mentioned
strategies. The full online report for each strategy can be
retrieved by clicking on the corresponding label in the table headings of the PDF file.
Note that all the employed solvers are stiff and equipped
with automatic order and step-size adaptation, with relative tolerance set to 106 , so that accuracy of the simulation results is comparable and the comparison among
simulation times is fair and meaningful.
First of all, it is apparent how the adoption of sparse
solvers turns out to be beneficial for 7 out of 9 benchmark models, reducing the simulation times by factors
ranging from about 2 (SteamPipe and OneDHeatTransferTT_Modelica) to about 60 (TransmissionLineEquations_N_1280). It is also not significantly harmful in the
remaining two.
Although the models in the ScalableTestSuite might be
somewhat artificial and thus possibly bring higher benefits
than real-life models, in the authors opinion this result is
a clear indication that sparse solvers are the recommended
option to simulate large-scale Modelica models.
The improvement in performance can be ascribed both
560

to the more efficient solution of the large implicit systems
of equations involved in the solution process, and probably also to the lower number of time-consuming memory
cache misses, due to the much smaller memory footprint
of the simulation executable.
For some models, a large fraction of the simulation time
is spent computing the right-hand-sides of the equations,
rather then solving them, as in the case of the SteamPipe,
where most of the time is spent computing the steam properties. In these cases, the adoption of a sparse solver cannot change the situation dramatically. On the contrary,
sparse methods can bring huge benefits to models like
TransmissionLineEquations, which have a large number
of state variables, and an easy-to-compute right-hand side
of the ODEs, with a very sparse Jacobian.
The advantage of using a sparse DAE solver over a
sparse ODE solver is instead much less clear, and depends
a lot on the specific case.
The multi-body models StringModelica, a suspended
string modelled as a chain of rigid bodies and free rotational joints, and FlexibleBeamModelica, a cantilevered
beam modelled as a chain of rigid bodies with elastic rotational joints, perform much better with the DAE solver, for
reasons currently under investigation; also the SimpleAdvection models show a factor 2 improvement when using
the DAE solver.
In other cases, such qas TransmissionLineEquations
and PowerSystemStepLoad, the advantage is more limited. The TransmissionLineModelica model turns out to
be five time faster with the sparse ODE solver than with
the full DAE solver (DA strategy). The penalty is reduced
to about a factor 2 when using the more advanced DD
strategy, which is understandable, as the model is built
with basic Resistor and Capacitor models from the Modelica Standard Library and thus has a lot of redundant equations.
Finally, it seems that the DA strategy never turns out
to provide any substantial advantage over the second best
choice.

3.2

Large-scale power generation and transmission system models

The interest in Modelica modelling of national- and
continental-size power generation and transmission systems is growing. A first feasibility study in this field was
reported in (Casella et al., 2016). The relevant features of
the benchmark models are reported here for convenience;
the interested reader is referred to the above-mentioned
reference for background information and more details.
Three benchmark test cases from that study are considered in this paper, whose main features are reported in
Table 3. Note that the size of these models is much larger
than the typical size of the ScalableTestSuite examples reported in the previous section.
RETE_C is a model of the Irish power generation and
high-voltage power transmission system, while RETE_E
and RETE_G are a medium- and a high-fidelity model

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132557

Session 9B: Numerical & Symbolic Methods

Table 1. Simulation times of ScalableTestSuite benchmarks in seconds.

Benchmark

NE

NS

OD

OS

DA

DD

SimpleAdvection_N_3200
SimpleAdvection_N_6400
SimpleAdvection_N_12800

6402
12802
25602

3199
6399
12799

20.81
104.9
642.2

4.851
13.27
41.15

3.087
6.107
19.17

2.561
6.781
18.38

SteamPipe_N_640
SteamPipe_N_1280
SteamPipe_N_2560

8966
17926
35846

1280
2560
5120

169.2
395.8
1165

148.4
316.8
651.0

158.7
357.8
801.9

139.3
302.9
679.9

TransmissionLineEquations_N_320
TransmissionLineEquations_N_640
TransmissionLineEquations_N_1280

642
1282
2562

640
1280
2560

4.344
23.52
241.1

0.5742
1.133
6.099

0.2626
0.8848
4.973

0.3563
0.7923
4.621

TransmissionLineModelica_N_320
TransmissionLineModelica_N_640
TransmissionLineModelica_N_1280

6755
13475
26915

642
1282
2562

3.677
29.15
235.0

1.100
2.090
9.012

3.337
11.63
47.80

1.937
7.59
20.96

FlexibleBeamModelica_N_16
FlexibleBeamModelica_N_32
FlexibleBeamModelica_N_64

5949
10877
20733

32
64
128

26.74
111.9
1819

21.65
64.87
393.8

14.4
38.12
n.a.

9.611
28.30
65.47

StringModelica_N_16
StringModelica_N_32
StringModelica_N_64

5887
10783
20575

34
66
130

1.801
9.710
86.48

1.410
10.02
25.91

0.4385
1.541
3.756

1.012
1.897
n.a.

PowerSystemStepLoad_N_16_M_4
PowerSystemStepLoad_N_32_M_4
PowerSystemStepLoad_N_64_M_4

1059
3139
10371

193
385
769

0.2272
0.7197
2.713

0.1477
0.632
2.961

0.1329
0.4116
2.277

0.4610
0.5558
2.867

OneDHeatTransferTT_Modelica_N_320
OneDHeatTransferTT_Modelica_N_640
OneDHeatTransferTT_Modelica_N_1280

3190
6390
12790

318
638
1278

0.322
0.9237
1.822

0.2358
0.3579
1.038

0.1794
0.4711
0.9342

0.3176
0.4736
1.058

103
203
403

41
81
161

16.76
113.7
827.2

20.26
155.6
831.5

n.a.
n.a.
n.a.

n.a.
n.a.
n.a.

HeatingSystem_N_20
HeatingSystem_N_40
HeatingSystem_N_80

DOI
10.3384/ecp17132557

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

561

Solving large-scale Modelica models: new approaches and experimental results using OpenModelica

Table 2. Number of synchronous generators, transmission lines,
transformers and equations of the benchmark models

Network

Gens

Lines

Trafos

Equations

RETE_C
RETE_E
RETE_G

74
267
407

369
1458
6833

583
1202
2824

56386
157022
593886

of the Italian high-voltage power generation and transmission system, with an equivalent simplified representation
of the interconnection to the pan-European grid.
These models have a peculiar feature, i.e., their DAE
representation is highly sparse, but their ODE representation is dense, because all the synchronous generators interact instantaneously with each other, due to the phasorbased algebraic description of the transmission network.
As a consequence, the use of implicit ODE solvers is
not recommended, because the corresponding Jacobian is
very large and dense.
At the time of the writing of (Casella et al., 2016), the
sparse DAE solver only worked on the smallest test case,
so for the larger ones a variant of the the OD strategy was
employed, using an explicit Runge-Kutta solver to avoid
computing the dense Jacobian. Linearized load models
were required in order to use the linear sparse solver KLU
to compute the causalized equations. However, this approach was clearly sub-optimal, because a) realistic load
models are non-linear and b) the system models are significantly stiff. Using fully implicit sparse DAE solvers
with variable step size is clearly preferrable from a performance point of view.
In this paper, we can now report the simulation performance obtained with the DA strategy, using an Intel Xeon
CPU E5-2650 server running at 2.30GHz with 72 GB of
RAM installed. All simulations start with the system in
steady-state, then at time t = 1 s a big load is disconnected
from the grid, causing an imbalance between generated
and consumed power. The system undergoes a transient
with some voltage and frequency oscillations, until the
voltage and frequency controllers re-establish a new equilibrium in about 10-15 seconds. The simulation time span
is 20 seconds, in order to check that the system actually
returns to steady-state.
Performance results are reported in Table 2. It is worth
noting that these results were obtained with a first implementation of the DA strategy; the authors are confident
that the optimization of the IDA solver parameters and
a more thorough scaling of the problem, which is badly
scaled due to the use of SI units, could further improve the
performance significantly.

3.3

Large-scale models of nuclear fusion reactor components

The development of a conceptual design of the European
Demonstration Fusion Power Reactor (EU DEMO) is one
of the goals defined in the EU fusion roadmap Horizon
562

Table 3. Simulation performance with DA strategy

Network

Rel. tol.

No. of steps

Sim. time [s]

RETE_C
RETE_C
RETE_E
RETE_E
RETE_G
RETE_G

104

39
146
140
364
221
615

0.96
3.18
8.80
15.22
59.95
123.19

106
104
106
104
106

2020. The future DEMO reactor aims at demonstrating
industrial-scale electrical power production from nuclear
fusion processes.
Politecnico di Torino, in cooperation with Politecnico
di Milano, is developing a global thermal-hydraulic model
of the entire system, using Modelica. One important part
of that is the breeding blanket cooling system, in which
pressurized water flows through a very complex and large
system of tubes, collecting the heat generated from the nuclear fusion process and delivering it to a standard steam
generator and turbine system, similar to those used for traditional PWR nuclear power plants. The breeding blanket cooling system is highly modular and has a repetitive
structure, but its sub-components have different geometric
features, so that it necessary to simulate each and every
tube individually. As a result, models of this system can
have a very large size. The interested reader can refer to
(Froio et al., 2017) for more details.
The model reported in the above-mentioned reference
has 289126 equations and 20772 states. The simulation of
a transient of interest for the study of such system requires
64 s with the DD strategy and 146 s with the DA strategy.
The model has been benchmarked and validated against
more detailed 3D CFD models. Given the simulation
times shown above, which are obviously much faster than
those of the CFD simulation, the model is suitable for use
in parametric optimization studies, aimed at the optimal
design of the coolant flow distribution.

4

Conclusion

This paper introduces methods and strategies to solve
large-scale Modelica models and reports the performance
of their implementation in OpenModelica on selected
benchmark problems.
The main result of this study is that the use of sparse
solvers is almost always beneficial, sometimes very substantially, over the traditional use of dense solvers supported by thorough symbolic manipulation. The comparison between sparse DAE solvers and sparse ODE solvers
has many different outcomes, depending on the specific
problems at hand.
Another interesting result is that we have demonstrated
the feasibility of using such sparse solvers to successfully
simulate Modelica models of industrially relevant systems
with size up to over half a million DAEs.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132557

Session 9B: Numerical & Symbolic Methods

Further developments of this work are already planned.
First of all, it would be interesting to using the DAE solver
to simultaneously handle the differential equations and the
nonlinear algebraic implicit equations corresponding to
strong components of the BLT, while still exploiting the
BLT to compute the residuals of the DAEs by sequences of
explicit assignments. This would combine the advantages
of the sparse ODE and sparse DAE approaches discussed
in this paper, avoiding the nested iterations of the nonlinear strong components solver and of the implicit ODE
solver, possibly further improving the results reported in
this paper on some classes of models.
It will also be necessary to further optimize the code
generation for use with sparse solvers, as the current implementation is such that the code generation time is typically much larger than the simulation time, particularly for
very large models. Radically new approaches to the code
generation process are needed to break the one million
equation barrier with reasonable executable code sizes and
code generation times.
Last, but not least, although the handling of hybrid
models with DAE sparse solvers is already implemented
in OpenModelica, it has not been specifically optimized
for efficient handling of large-size models. Such optimization would be another interesting research direction.

5

Acknowledgments

son and Hilding Elmqvist, editors, Proceedings 11th International Modelica Conference, pages 459468, Versailles,
France, Sep 2123 2015. The Modelica Association. ISBN
978-91-7685-955-1. doi:10.3384/ecp15118459.
Francesco Casella, Andrea Bartolini, Simone Pasquini, and
Luca Bonuglia. Object-oriented modelling and simulation of
large-scale electrical power systems using Modelica: a first
feasibility study. In Proceedings of the 42nd Annual Conference of the IEEE Industrial Electronics Society IECON 2016,
pages 06, Firenze, Italy, Oct. 24-27 2016. IEEE, IEEE.
ISBN 978-1-5090-3474-1.
F. E. Cellier and E. Kofman. Continuous System Simulation.
Springer-Verlag, 2006.
T. A. Davis.
Algorithm 832: UMFPACK v4.3an
unsymmetric-pattern multifrontal method. ACM Transactions On Mathematical Software, 30(2):196199, June 2004.
ISSN 0098-3500. doi:10.1145/992200.992206. URL http:
//dx.doi.org/10.1145/992200.992206.
T. A. Davis and E. Palamadai Natarajan. Algorithm 907: Klu, a
direct sparse solver for circuit simulation problems. ACM
Trans. Math. Softw., 37(3):36:136:17, September 2010.
ISSN 0098-3500. doi:10.1145/1824801.1824814. URL
http://doi.acm.org/10.1145/1824801.1824814.
Antonio Froio, Francesco Casella, Fabio Cismondi, Alessandro Del Nevo, Laura Savoldi, and Roberto Zanino.
Dynamic thermal-hydraulic modelling of the eu demo
wcll breeding blanket cooling loops. Fusion Engineering and Design, in press, available online:15, 2017.
doi:10.1016/j.fusengdes.2017.01.062.

The presented work is partly financed by the PARADOM
project, that is funded by the Federal Ministry of Education and Research (BMBF) under the support code
01IH15002B.
C. Froio, F. Casella, F. Cismondi, A. Del Nevo, L. Savoldi, and
CESI S.p.A. is gratefully acknowledged for making the
R. Zanino. Dynamic thermal-hydraulic modelling of the eu
power system models available for this study.
demo wcll breeding blanket cooling loops. In Proc. 29th Sym-

posium on Fusion Technology (abstract), Prague, Czech Republic, 2016.

References
B. Bachmann, W. Braun, L. Ochel, and V. Ruge. Symbolical and numerical approaches for solving nonlinear systems.
Annual OpenModelica Workshop 2015,
2015.
URL https://www.openmodelica.org/
images/docs/openmodelica2015/
OpenModelica2015-talk04-BernhardBachmann-NLSinOpenModelica.pdf.
W. Braun, S. Gallardo Yances, K. Link, and B. Bachmann. Fast
simulation of fluid models with colored jacobians. In Proceedings of the 9th International Modelica Conference, pages
247252, Munich, Germany, Sep. 35 2012. Modelica Association. doi:10.3384/ecp12076247.
K.E. Brenan, S.L. Campbell, and L.R. Petzold. Numerical Solution of Initial-Value Problems in Differential-Algebraic Equations. Society for Industrial and Applied Mathematics, 1996.
doi:10.1137/1.9781611971224.fm.

A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban,
D. E. Shumaker, and C. S. Woodward. SUNDIALS: Suite of
nonlinear and differential/algebraic equation solvers. ACM
Transactions on Mathematical Software (TOMS), 31(3):363
396, 2005.
Open Source Modelica Consortium. OpenModelica Users
Guide. Online. URL https://openmodelica.org/
doc/OpenModelicaUsersGuide/latest/.
P. Tuber, L. Ochel, W. Braun, and B. Bachmann.
Practical realization and adaptation of celliers tearing
method. In Proceedings of the 6th International Workshop on Equation-Based Object-Oriented Modeling Languages and Tools, EOOLT 14, pages 1119, New
York, NY, USA, 2014. ACM. ISBN 978-1-4503-29538.
doi:10.1145/2666202.2666204.
URL http://
doi.acm.org/10.1145/2666202.2666204.

F. Casella and K. Sezginer. The ScalableTestSuite Modelica
Library, 2016. URL https://github.com/casella/
ScalableTestSuite.
Francesco Casella. Simulation of large-scale models in Modelica: State of the art and future perspectives. In Peter Fritz-

DOI
10.3384/ecp17132557

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

563

564

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Transformation of Differential Algebraic Array Equations to
Index One Form
Martin Otter1
1

Hilding Elmqvist2

Institute of System Dynamics and Control, DLR, Germany, Martin.Otter@dlr.de
2
Mogram AB, Sweden, Hilding.Elmqvist@Mogram.net

Abstract
Several new algorithms are proposed that in effect
transform DAEs (Differential Algebraic Equations) to
a special index one form that can be simulated with
standard DAE integrators. The transformation to this
form is performed without solving linear and/or
nonlinear equation systems, the sparsity of the
equations is kept, and array equations remain array
equations or differentiated versions of them.
Furthermore, certain DAEs can be handled where
structural index reduction methods fail. It is expected
that these new algorithms will help to treat large
Modelica models of any index in a better way as it is
currently possible. The algorithms have been evaluated
and tested in the experimental simulation environment
Modia that is implemented with the Julia programming
language.
Keywords: Modelica, Modia, Julia, DAE, sparse DAE,
large DAE, Pantelides algorithm, Dummy Derivative
Method.

1

Introduction

The objective is to handle larger Modelica models as it
is practically possible today. For this purpose new
algorithms have been developed: equations as well as
variables are not scalarized but keep their original array
types, even if differentiated. This gives a more compact
code which is a benefit with regards to code cache
behavior. Furthermore, there is a possibility to utilize
vector instructions of modern processors. With respect
to current Modelica tools, equation systems are not
solved locally in the model code but by a DAE solver
where the sparsity of the Jacobian is taken into account
and in the model code single (array) equations are
either explicitly solved if this is possible or residues for
implicit equations are computed to be solved by the
DAE solver. The new algorithms have been evaluated
and tested in the prototype Modia (Elmqvist et al.,
2016, Elmqvist et al., 2017) which is implemented with
the Julia programming language 1 (Bezanson et al.,
2017) and takes advantage of this very promising
language effort with focus on scientific computing.
Modia is available from https://github.com/ModiaSim.
1

http://julialang.org/
DOI
10.3384/ecp17132565

2

Special Index One DAE Form

The goal is to simulate physical models that are
described by a modeling language such as Modelica
and mapped to a DAE in the form
(1)
0 ( 0 ,  0 ,  0 , ) = 
0  0  0  0    0 +0

where  0 () are variables that appear differentiated
and  0 () are variables that do not appear
differentiated. Furthermore, it is assumed that a unique
solution of this DAE exists if consistent initial
conditions of  0 ,  0 ,  0 are given, and that the
equations and variables are smoothly differentiable
sufficiently often. Typically, Modelica tools transform
(1) into ODE (Ordinary Differential Equation) form
and use ODE or DAE integration methods for the
solution. In this paper, this is not done because (a) a
transformation to ODE form may destroy the sparsity
structure of the equations and (b) requires in general
solving linear and/or nonlinear algebraic equation
systems and an implicit integration method will in turn
solve nonlinear algebraic equation systems as well (so
a nonlinear solver is called within a nonlinear solver).
For certain classes of physical models, such as large 3dimensional mechanical systems, this approach might
not be efficient and not reliable. Instead a new
approach is proposed to transform (1) to the following
special index one DAE

 ( , , ) = 
 =    is regular (2b)
(2a)

 (, ) = 

without solving equation systems. DAE (2) shall have
an identical solution space as DAE (1) and  0 ,  0
shall be part of . Note, when differentiating  (..),
 ( , , ) = 


(3)
 +
= 


can be solved for  because the matrix of partial
derivatives of (3) with respect to  is the Jacobian  of
(2b) which is regular. This shows that (2) has index 1.
A number of methods exist for solving system (2)
numerically. In particular, under mild conditions BDF

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

565

Transformation of Differential Algebraic Array Equations to Index One Form

(Backward Differentiation Formula) methods with
order  ( < 7) and fixed or variable step-size 
converge with ( ), see (Brenan et al. 1996) page
51-54. This means that a DAE integrator like Sundials
IDA (Hindmarsh et al. 2005) can solve such systems.
On the other hand, solving (2) with a BDF-method
requires to solve a nonlinear equation system where the
inverse of the iteration matrix becomes singular for
  0. (Petzold and Ltstedt, 1986) point out that step
size selection is difficult if reducing the step size
makes the iteration matrix ill-conditioned and it is
proposed to scale elements of the iteration matrix with
 so that this effect does not occur. In (Arnold, 2016) it
is shown how this technique can be applied for
multibody systems. For system (2) scaling with  is
particularly simple, resulting in two possible ways:
 ( , , ) = 
 ( , , ) = 
(4a)
1
(4b)
 (, ) = 
 (, ) = 

Assume that these systems are solved with a BDF
method of order . This means that the derivatives  at
step  are approximated as:
=

0
1
  
  +    



(5)

=1

where  are constant coefficients depending on the
order of the method,  =   1 is the step size and
the sum     is a known term computed from
values of  at previous time instants. Inserting (5) in
(4a) results in a nonlinear system of equations for   :
0
 
 ,  ,   = 
   
(6)
 (  ,  ) = 

Assume that ,  ,  are sufficiently smooth and
bounded and that  1 solves (6) at the previous time
instant 1 . According to the implicit function
theorem, (6) has a unique solution at time instant
1 +  if the inverse of the Jacobian of this system




 =    =

  
   



0

+

  






 



(7)

exists for small . This is indeed the case, since for
  0 the Jacobian (7) converges to the regular
Jacobian (2b), when dividing the upper equation by the
constant 0 . A similar result can be derived for (4b).
To summarize, DAE (2) can be solved by standard
(index one) DAE integrators and a reliable numerical
solution with a BDF method can be expected even for
small step sizes when one of the  scaling methods of
(4) is used. In the remaining part of this paper it is
shown, how a large class of DAEs in the form (1) can
be transformed to (2). This transformation is performed
in several steps that are discussed now in sequence.
566

3

Index Reduction of DAEs
that have Array Equations

3.1 Algorithms for Index Reduction
In order to reduce a DAE (1) to ODE or index one
form, equations of (1) might need to be differentiated.
There are in principle many algorithms to perform this
index reduction based on the structure of the equations,
that is by the information which variable is present in
which equation. The essential idea and the key
algorithm are from (Pantelides, 1988): The structure of
the equations is described by a bipartite graph of
equations and variables. The equations are
differentiated until a complete assignment of the
highest derivative equations is possible with respect to
the highest derivative variables (which include
algebraic variables that are not differentiated).
Since the goal is to achieve complete assignment in
a bipartite graph, any matching algorithm for a
bipartite graph can be used as basis. In (Pantelides,
1988), the matching algorithm of (Duff, 1981) is
utilized which results in a very simple and elegant
implementation. It results in a worst time complexity
of (  ) where  is the number of equations in the
final system (= original and all differentiated
equations) and  is the number of entries (incidences)
in the final bipartite graph.
In (Duff et al., 2011) eight matching algorithms and
various additional heuristics are compared. Most of
them have the same worst time complexity as (Duff,
1981), a few have (  ). On average the (  )
algorithm PF+ described in this article had the best
performance on the test matrices. In (Frenkel et al.,
2012) nine matching algorithms and different
implementations for structural index reductions are
compared for multibody examples with varying
number of bodies. This evaluation indicates that PF+
has on average the best performance for index
reduction with the Pantelides algorithm.
It is well-known that complete matching in a
bipartite graph is equivalent to the network flow
problem where the maximum amount of flow shall be
determined that can be sent between two given vertices
of a graph, see for example (Skiena, 2008, page 217). It
is also well-known that both the network flow problem
and the bipartite matching problem can be formulated
as a special linear programming problem, see for
example (Edmond,1965; Cook and Rohe, 1999;
Skiena, 2008, pp. 509-510). For all these problem
classes solution algorithms are available and can be
used for index reduction. For example, (Pryce, 2001)
describes an index reduction method based on the
special linear programming problem.
All above algorithms for index reduction are
iterative and the question is when the iteration stops.
(Pantelides, 1988) provides an elegant method to test
beforehand whether the (structural) index is finite:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

Adding the relationship 0 =  ( 0, , 0, ) structurally
for all differentiated variables in (1) gives an extended
system which can be interpreted as solving (1) with an
implicit integration method. If this system has a
complete matching, the (structural) index is finite and
structural index reduction algorithms will converge.
All the algorithms mentioned above have the
disadvantage that only structural properties are utilized
and therefore will fail if state constraints are not
structurally visible. In (Chowdhry et al., 2004) a
symbolic/numeric index reduction procedure is
proposed. It is based on a symbolic numerical algebra
for pattern manipulations of the DAE (1) and reduces
the index of linear constant coefficient DAEs
numerically by LU decompositions and the index of
nonlinear parts by a structural index reduction
algorithm.
In section 5 a new method is proposed to exactly
handle singularities in the connection graph of a model,
both to treat (consistently) underdetermined and
overdetermined equation systems, as well as state
constraints that cannot be handled by a structural index
reduction algorithm. This technique transforms a DAE
(1) in a DAE (1) and is therefore a pre-processing step
for the transformations of section 3 and 4.
3.2 Index Reduction on Array Equations
The Pantelides algorithm and other structural index
reduction algorithms are designed for scalar variables
and equations. So Modelica tools typically
symbolically expand array equations into a set of scalar
equations involving the array elements and the
description with array equations is lost. This has
significant drawbacks for large array equations. In
(Schuchart, et al., 2015) it is shown how special forloops can be handled so that they need not to be
expanded for the Pantelides algorithm and are retained
in the generated code.
Below, a new technique is proposed to handle any
kind of array equations. Hereby the (conceptual)
expansion of array equations is performed only in the
bipartite graph to perform structural index reduction
and in a BLT (Block Lower Triangular) transformation
on the highest derivative equations. In order to
illustrate this technique, a tiny multibody example will
be used.
Consider the following model of a sliding mass. It is
a one degree-of-freedom model, with scalar parameters
c,d,, vector parameters , , scalar unknown  and
vector unknowns , , , , that is described by the
following equations:
 = 
 = 
(8)
 =  +  + 
0 =   
 = ( +  )
DOI
10.3384/ecp17132565

(8) is a DAE (1) with 4  3 + 1 = 13 equations in the
13 variables  0 = [; ; ],  0 = [; ].
With the Pantelides algorithm it is determined how
often every equation would have to be differentiated
until the highest derivatives variables can be uniquely
assigned to the highest derivative equations. Since we
want to keep array equations intact, it is natural to
assign array variables to array equations, provided they
have the same type and the same dimensions. See also
(Stavker, 2015) chapter 9. However, this does not
work for the sliding mass example above and any other
multibody system where bodies are connected by
joints.
The scalar variable  appears only in vector
equations, so  or a higher derivative of it can only be
assigned to an element of these equation (or a
derivative of them), which means that a vector
equation must be expanded in scalar equations.
Furthermore, the vector variable  appears as only
variable in a scalar equation (0 =   ) and therefore
one element of  must be assigned to this scalar
equation. As a result, the two other elements of  have
to be assigned in other equations, which then must be
expanded as well. In the end, all equations must be
expanded to scalar equations in order that an
assignment of all variables is possible.
After expanding all equation graphs, the Pantelides
algorithm determines that the first vector equations
must be differentiated twice and the second one time
leading to the following assignments:
assigned highest derivative equations diff. order
2

1 = 1 
2
2
2 = 2 
2
3
3 = 3 

=

1
1
1
1

=

1
 2
2
2
1
 3
 3 = 3
0
1
1 = 1 + 1 + 1
2
0
 2 = 2 + 2 + 2
3
0
 3 = 3 + 3 + 3
1
0
0 = 1 1 + 2 2 + 3 3
1
0
1 = ( +  ) 1
2
0
2 = ( +  ) 2
3
0
3 = ( +  ) 3
As will become clear in section 4, the set of highest
derivative equations must be sorted, so a BLT (Block
Lower Triangular) transformation must be applied that
identifies the order of evaluation, as well as the
algebraic loops under the assumption that the lowerorder derivative variables are known. Furthermore, the
assumption is used that array equations have full
incidence (see Assumption 1 below).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

567

Transformation of Differential Algebraic Array Equations to Index One Form

highest derivative equations
1 = ( +  ) 1
2 = ( +  ) 2
3 = ( +  ) 3
1 = 1 
2 = 2 
3 = 3 
1 = 1
 2 = 2
 3 = 3
1 = 1 + 1 + 1
 2 = 2 + 2 + 2
 3 = 3 + 3 + 3
0 = 1 1 + 2 2 + 3 3

solve for
1 , 2 , 3

 , 1 , 2 , 3 ,
1 ,  2 ,  3 ,
1 , 2 , 3

The result is that there is an algebraic system with 3
equations that has to be solved for 3 unknowns.
Afterwards an algebraic equation system with 10
equations has to be solved for 10 unknowns. Note,
whenever an algebraic loop is encountered, the
previous assignment information on equation level is
no longer relevant (which is anyway not unique in such
a case) but only the set of unknown variables of the
respective algebraic loop.
Although the Pantelides algorithm must be
performed on (conceptually) expanded scalar equations
and scalar variables, the BLT transformed highest
derivative equations can be contracted to array
equations again:
highest derivative equations
solve for
 = ( +  )

 = 
 = 
 ,  ,  , 
 =  +  + 
0 =   
The original Pantelides algorithm and the BLT
transformation are graph based algorithms that assume
nodes and vertices correspond to scalar real variables
and equations. These algorithms can be generalized to
work directly on the array variables and equations.
3.3 Properties of Array Equations
The presented approach relies on the fact that all
scalarized equations/variables appear in the same
algebraic equation system (or more precisely in the
same strongly connected component of a directed
graph). This sub-section contains the assumption under
which this property holds and the proof of the property.
Multi-dimensional arrays are treated as vectors with
length being the total number of elements.
Assumption 1: When expanding the bipartite graph of
DAE (1) regarding array variables and array
equations, it is assumed that they have full incidence.
Example: For the equation :  = (, ) with all
variables being vectors of length 2, the incidence
structure is assumed to be:
568

1
2

1 2 1 2 1 2
x x x x x x
x x x x x x

Theorem 1: If one element of an array equation needs
to be differentiated, all elements of all time varying
variables in the equation need to be differentiated.
Example: For the equation :  = () with all
variables being vectors of length 2, the incidence
structure of the differentiated equation is:
1 2 1 2 1 2 1  2
1
2

x
x

x
x

x
x

x
x

x
x

x
x

x
x

x
x

Proof: This follows since if an array variable has full
incidence, so has its time derivative. This means that
derivatives of all time varying array variable elements
will appear in the differentiated element of the array
equation. 
This is consistent with the Pantelides algorithm
because, if the function augmentPath returns false, all
variable elements with incidence are marked as
colored. All colored V-nodes to be differentiated are
then marked in the A vector.
Theorem 2: If one element of an array equation needs
to be differentiated, all other elements of the equation
need to be differentiated.
Proof: According to Theorem 3, all elements of an
array equation will appear in the same strongly
connected component. It means that there is a mutual
dependency between all array equation elements. This
means that there is also a mutual dependency between
all differentiated array variable elements. In order to be
able to solve for all derivatives, an equal number of
array equation elements are needed, that is all array
equation elements must be differentiated. 
Function augmentPath colors all equations visited. If
assignment is not possible, augmentPath tries to
reassign. Due to the mutual dependency, all of the
elements of an array equation are visited. In the Bvector of the Pantelides algorithm it is marked that all
colored equation nodes should be differentiated.
Theorem 3: If the highest derivative equations are
structurally non-singular with respect to the highest
derivative variables, all elements of an array equation
will appear in the same strongly connected component.
Proof: The incidence matrix of an array equation
consists of n identical rows with n being the number of
scalar elements of the left and right hand side. Assume
that these elements of the array equation (incidence
matrix rows) appear in different strongly connected
components. This would mean that some of these
elements of the array equation could be solved without
the others. Since they have the same incidence, it
would mean that the other elements of the array

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

equation would be structurally over-constrained. This
contradicts the assumption of structural nonsingularity. 

Limitations
It is worth noting that there are cases when symbolic
expansion of array equations is beneficial. For
example, (Elmqvist and Mattsson, 2016) discusses
detection and handling of planar loops of multibody
systems. In such cases, certain elements of position
vectors are overdetermined and certain elements of
force vectors are underdetermined. In order to reveal
this, the zeros in axis of rotation and translation vectors
must be utilized, that is, certain equations must be
expanded.
When discretized partial differential equations are
handled, the boundary elements may give rise to issues
with Assumption 1. In such a case, array equations for
the inner elements might be formulated and scalar
equations for the boundary elements added separately.
3.4 Implementation Notes
The Pantelides and BLT algorithms have as input the
incidence graph for the array variables and equations,
that is, non-expanded equation and array structure.
Additionally, a vector of lengths of each variable, that
is the number of scalar elements, and a vector of the
lengths of equations are given as inputs.
All for-loops over variables and equations in the
original algorithms are replaced with nested for loops
also looping over the lengths.
The usual indices in the assignment, lowlink and
number vectors and stack are replaced by tuples
denoting which array and which array element is
referred to. However, due to Theorem 1, the  vector
(see below) which tells which variables are
differentiated is still just a vector over array variables.
Similarly, due to Theorem 2, the  vector (see below)
for differentiated equations does not need the tuple
indexing. The strongly connected component
representation is only referring to array equations due
to Theorem 3.
3.5 Result of Structural Index Reduction and BLT

For the further processing, the result of the structural
index reduction and BLT transformation of array
equations is summarized formally. For this, the
following notation is used
 All symbols are collected in a variable vector 
and  is symbol . A symbol may represent a
scalar or an array. , gives the number of
elements of symbol .
 All equations are collected in an equation vector 
and  is equation . An equation may be a scalar
or an array equation. , gives the number of
elements of equation .
DOI
10.3384/ecp17132565





The relationship between the symbols is defined
by the variable association vector , such that:
 =   =     0.
Also the inverse relationship is needed below:
, =   =     0.
The relationship between the equations is defined
by the equation association vector , such that:
 =   =     0.
Also the inverse relationship is needed below:
, =   =     0.

Starting point is DAE (1) that can be defined with
0 = [ 0 ;  0 ;  0 ] and the 0 array equations:
(9)
0 (0 , ) = 
Structural index reduction determines the minimal
number of differentiations of (9) such that the
following conditions are fulfilled by the final system:
  ,  = 0;  = 0;   0
(10a)
  ,  = 0;  > 0;  > 0
(10b)

(10c)
structurally regular for  = 0

(10a) are 0 array equations (the highest derivative
equations) in 0 unknown arrays (the highest
derivative variables  with  = 0). The matrix (10c)
of partial derivatives of the highest derivative
equations with respect to the highest derivative
variables is structurally regular. (10b) are   0
array equations describing the constraints between the
variables appearing differentiated. The highest
derivative variables (that is  with  = 0), do not
appear in these equations.

4

Transformation to Index One Form

4.1 Overview
The transformation from (1) to index one form (2)
using (10) is made in three steps: In a first step, the
solution is sketched for multibody system equations. In
a second step this approach is generalized and in a final
step the transformation is made more efficient by
partial static state selection.
In the field of multibody systems, constraints appear
in nearly every model and hence multibody programs
need to inherently cope with the special constraints
appearing in 3-dimensional mechanical systems. It is
therefore natural to inspect the many solution methods
developed for multibody systems and try to generalize
one or more of them to general DAEs (1). In the recent
report (Arnold, 2016), a very broad and nice overview
of the current state of the art for simulation of
multibody systems is given and used as basis of this
section.
One solution method is to integrate the highest
derivative equations (10a) and when the violation of
the constraints (10b) becomes too large project on the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

569

Transformation of Differential Algebraic Array Equations to Index One Form

constraint manifold, see for example (Ascher and
Petzold, 1991; Eich, 1993). Such methods could be
implemented by utilizing an implicit one-step DAE
integrator and after every step project the solution on
the constraint manifold.
Many industrial applications of Modelica models are
best solved with an implicit multistep method.
Unfortunately, multistep methods require non-trivial
modifications to embed a projection method because
the solution is interpolated smoothly over several steps
and (potentially) in every step the solution is modified
in a discontinuous way by a projection. It seems that
the stabilized index-2 formulation according to Gear,
Gupta, Leimkuhler (Gear et al., 1985) is a more
attractive starting point especially for multistep
methods. This method is analyzed in the sequel in
some detail. The presentation is made in such a way
that a generalization is straightforward.
4.2 Transformation of Multibody Equations
Starting point is the following set of equations for a
multibody system:
 = 
(11a)
(, ) +  (, ) = (, , )
(11b)
(11c)
 = (, )

with

 =


,


 =   > 

(11d)

It is assumed that  has full row rank that is the
constraints equations (11c) are not redundant. (11) has
 +  +  real unknowns  ,  ,  for the same
number of equations. With the new array version of the
Pantelides algorithm, equation (11a) is differentiated
once and equation (11c) twice in order to arrive at the
following equation system that needs to be fulfilled by
consistent initial values 0 , 0 , 0 ,  0 ,  0 ,  0 :
 = 
 +   = (, , )
 = (, )


 =   + (1) (, )
 =   + (2) (,  , )
 = 

with
(1) =


, (2) =   +  (1)
t

(12a)
(12b)
(12c)
(12d)
(12e)
(12f)

(12g)

This is an ODAE (Overdetermined Differential
Algebraic Equation) with 2 +  + 3 equations
for the 2 +  +  unknowns  ,  ,  , . In order to
arrive at an equation system with the same number of
unknowns and equations that are consistent (so locally
a unique solution exists), the following approach of
(Gear et al., 1985) is used:

570

 =    +  
 =   +    (, , )
 = (, )
 =   + (1) (, )

(13a)
(13b)
(13c)
(13d)

These are  +  + 2 residue equations for the
 +  + 2 unknowns  ,  , , , so the number of
equations and number of unknowns is the same. (13)
has a differential index of two and has the same
solution as (12) because it can be shown that  = :
Inserting equation (13a) in equation (13d):
 =  ( +  ) + (1) (, )
and subtracting the derivative of (13c) results in the
equation  =   . Provided  has full row rank,
  is regular and therefore  = . 
This scheme can be easily generalized. For example
assume that (say due to an inverse model) the third
derivative of (12c) is needed. Then, new 2 variables
and corresponding dummy derivatives are introduced
in combination with the second derivatives of the
constraints:
 =  +  2
 =  + (2) (, , )
With the same argument as before it can be shown that
2 = : Inserting  in the second equation and
subtracting the differentiated equation (13d) results in
 =   2 and therefore 2 = . 
In (Gear et al., 1985) it is shown that variable-step
and variable order BDF (Backward Differentiation
Formula) methods converge for this index-2 DAE.
However, (13) is not yet in the desired form (2). In
particular, the BDF iteration matrix becomes singular
for a small step size. (13) can be transformed to (2) by
using the substitution (Gear, 1988):
 =   ,
 = 
(14)
as well as  = [; ;  ;  ]:

   + T  


T
 ( , , )
  +    (, , )
 = 
=
 (15)
 (, )
(, )


  +  (1) (, )


Note, the Jacobian (2b) of (15) is regular ( in (16) is a
permutation matrix to exchange the third and the fourth
equation of (15) in order that the regularity is at once
visible):




 =   =  
















  is regular



(16)

4.3 Transformation of general DAEs

The goal is to transform the ODAE (10) to (2). In a
first step the elements of vector  are identified:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

1. All variables  that appear differentiated are
collected together with their derivatives in vector
  with exception of their highest derivatives (so
, are all variables  with  > 0).
2. All variables  that do not appear differentiated
(so  with  = 0 and , = 0) are collected
either in vector   or vector  =  in such a
way that (a) all assigned variables of every BLT
block are either only differential variables
(  ;  ) or only algebraic (  ) variables and (b) a
BLT block with assigned   variables does not
contain any differential variables (  ;  ).
3. New  unknown variables  are introduced
( is defined below).
The index-one DAE (2) can now be defined as:
 
 
 

 =  ,  =   
(17a)



 
 ( , , )
 = 

 (, )

  (1:1) +   
 (0:2)

0,

 (17b)

0,
=


(0)


 (1:1) =  (1:1) +  
The variables in gray color, that is  ,  ,   , are
not used in equations (17b) and are variables needed
by the integrator. The different parts of the equations
are:
1. The index vectors (0:   2), (1:   1) are
defined in such a form that (for  = ):
 (0:2) 


=  (1:1)

2. 0, are non-differentiated equations of (10a), so
equations  with  = 0 and , = 0, that have
only differentiated variables (  ;  ) as assigned
variables of the respective BLT block.
3. 0, are non-differentiated equations of (10a), so
equations  with  = 0 and , = 0, that have
only algebraic variables (  ) as assigned variables
of the respective BLT block.
4. (0) are constraint equations (10b) that are not
differentiated, so equations  with  = 0 and
, = 0.
5. (1:1) = ( (0:2) , ) (1:1) +
( (0:2) , ) are constraint equations (10b)
that are differentiated at least once, but not the
highest derivative equations, so equations  with
 > 0 and , > 0. The number of additionally
introduces variables  is equal to the number of
equations of (1:1) .
DOI
10.3384/ecp17132565

6. Matrix  collects the linear factors of the equations
(1:1), with respect to the highest derivatives
 (1:1), appearing in the resp. equation  .
Note, as recognized in (Fhrer, 1988) in a similar
context,  is part of the iteration matrix (Jacobian)
of a BDF integrator and therefore if the iteration
matrix is computed numerically,  is determined
without additional effort, see also (Arnold, 2016).

With this structuring we can now prove the following
theorems:

Theorem 4: (17) is a DAE (2) under the assumption

that  for  = 0 in (10a) is regular (and not just


structurally regular) and  has full row rank (= the
constraints are not redundant).
Proof: (a) Due to the construction, the upper two
equations of (17b) are a function of  , ,  and the
lower three equations are not functions of  , so (17b)
has the functional dependency as required by (2a).
(b) (0:2)  = (1:1) 
 = ( (0:2)   (1:1) )
=   
   = 
(c) If the highest order constraint equations in the
lower part of (17b) are differentiated once, then these
differentiated equations, together with the second and
third equation of (17b) are the highest order derivative
equations of (10a) which can be solved for the highest
order derivatives (so for  , since   = ) due to the
assumption and therefore (2b) holds.

Theorem 5: (17) and (9) have the same solution
space.
Proof: Since  int = , (17) are equations (9) and
differentiated equations of (9). 
To summarize, every DAE (1) can be transformed to
DAE (17) without solving linear or nonlinear algebraic
equation systems provided the Pantelides algorithm or
an equivalent structural index reduction algorithm can
be applied to it. (17) is an index one DAE (2).
4.4 Example
(17) is demonstrated with the following example from
(Mattsson and Sderlind, 1993) that has been extended
with additional equations and unknowns to include
several special cases on the basis of a simple DAE:
0 = 1 () + 1  2
(18a)
0 = 2 () + 1 + 2  3 +  6
(18b)
0 = 3 () + 1 +  3  4
(18c)
0 = 4 () + 21 +  2 +  3 +  4 + 6
(18d)
(18e)
0 = 5 () + 31 + 2 2 + 5 + 0.18
0 = 6 () + 26 + 7
(18f)
0 = 7 () + 36 + 47
(18g)
0 = 8 () + 8  sin(8 )
(18h)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

571

Transformation of Differential Algebraic Array Equations to Index One Form

The  () are known forcing functions. Applying the
Pantelides algorithm (Pantelides, 1988) 2 and sorting
the equations on highest derivative level results in the
following three BLT components:
BLT component 1 (unknowns: 8 )

0 = 8 () + 8  sin(8 )

(19h)

BLT component 2 (unknowns: 6 , 7 )

(19)
(19)
BLT component 3 (unknowns: 1 ,  2 ,  3 ,  4 , 5 )
0 =  1 () +  1   2
(19 )
0 =  2 () +  1 +  2   3 + 6
(19)
0 =  3 () +  1 +  3   4
(19 )
0 = 4 () + 2 1 +  2 +  3 +  4 + 6
(19)
0 = 5 () + 3 1 + 2 2 + 5 + 0.18
(19)
0 = 
6 () + 26 + 7
0 = 
7 () + 36 + 47

Transformation to the index one DAE (17) results in:
  = [1 ; 2 ; 3 ; 4 ; 6 ; 7 ; 1 ; 2 ;
 3 ;  6 ;  7 ;  6 ;  7 ]
  = [8 ]
 = [5 ]

4 () + 21 + 2 + 3 + 4 + 
6

5 () + 31 + 22 + 5 + 0.18
= [8 () + 8  sin(8 )]

0, = 
0,

1 () + 1  2


2 () + 1 + 2  3 +  6


(0) =  3 () + 1 +  3  4 
6 () + 26 + 7



7 () + 36 + 47


 1 () + 1   2


 2 () + 1 +  2   3 +  6 
 6 () + 2 6 +  7


(1:1) = 

 7 () + 3 6 + 4 7


 6 () + 2 6 +  7



 7 () + 3 6 + 4 7

1 2
0 0 0 0 0
1
2 3 0 0 0 0


0
0
0 2 1 0 0
 = 
0
0 3 4 0 0
0
0
0
0 0 0 2 1
0
0
0 0 0 3 4
(0:   2) = [1; 2; 3; 5; 6; 10; 11]
(1:   1) = [7; 8; 9; 10; 11; 12; 13]

The result is a DAE with 21 equations that can be
solved with an index one DAE integrator.

2

For simplicity of the example, the equations contain higher
derivatives. The Pantelides algorithm can be easily generalized
to this case by providing a corresponding  vector.

572

4.5 Structuring the Constraint Sets
The direct mapping to (17) results often in
unnecessarily large DAEs. We will therefore now
improve the mapping by utilizing (partial) static state
selection. As a first step, the inherent structure of the
constraint set (10b) is (algorithmically) determined.
This can be performed elegantly by utilizing results
from the dummy derivative method of (Mattsson and
Sderlind, 1993). The "lower derivative" equations
(10b) determined by the Pantelides algorithm are
ignored in the sequel and they are instead newly
derived from the sorted highest derivative equations
(10a) by inspecting every BLT component in sequence
and for component k the follow actions are performed:
Step 1: The differentiation order of an equation in
component k is reduced by one if it is a
differentiated equation. The resulting set of
equations forms an independent constraint set.
Step 2: The differentiation order of an unknown (=
assigned variable) in component k is reduced by
one if it is a differentiated variable. The resulting
set of variables contains the unknowns of the
derived constraint set.
Step 3: Goto Step 1, if there are still differentiated
equations in the derived constraint set and apply
Step 1-3 on it. Otherwise, go to Step 4.
Step 4: Order the components in such a way that
within a BLT component first the lowest order
derivative constraints are placed, then the
constraints with one differentiation order higher
and so on. The order of the BLT components is not
changed.
Applying this procedure to (19) results in the following
sorted ODAE:
BLT component 1 (unknowns: 8 )
0 = 8 () + 8  sin(8 )
BLT component 2

BLT component 2.1 (unknowns: 6 , 7 )

0 = 6 () + 26 + 7
0 = 7 () + 36 + 47

BLT component 2.2 (unknowns:  6 ,  7 )

0 =  6 () + 2 6 +  7
0 =  7 () + 3 6 + 4 7

BLT component 2.3 (unknowns:  6 ,  7 )

0 =  6 () + 2 6 +  7
0 =  7 () + 3 6 + 4 7

(20)

BLT component 2.4 (unknowns: 6 , 7 )

0 = 
6 () + 26 + 7
0 = 
7 () + 36 + 47
BLT component 3

BLT component 3.1 (unknowns: 1 , 2 , 3 )

0 = 1 () + 1  2
0 = 2 () + 1 + 2  3 +  6

BLT component 3.2 (unknowns:  1 ,  2 ,  3 , 4 )

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

0 =  1 () + 1   2
0 =  2 () + 1 +  2   3 +  6
0 = 3 () + 1 +  3  4

BLT component 3.3 (unknowns:  1 ,  2 ,  3 ,  4 , 5 )

0 =  1 () + 1   2
0 =  2 () + 1 +  2   3 + 6
0 =  3 () + 1 +  3   4
0 = 4 () + 21 +  2 +  3 +  4 + 6
0 = 5 () + 31 + 2 2 + 5 + 0.18
Due to the construction, a variable like  6 is computed
in a BLT sub-component (here: BLT component 2.3)
and used only in later BLT components (here BLT
component 3.2).
In the next step the number of constraint equations
and unknowns shall be reduced statically. In principal
this is just a variant of the dummy derivative method.
However, (Mattsson and Sderlind, 1993) describe a
(very useful) conceptual algorithm, but not how to
implement it practically for nonlinear systems which
requires non-trivial extensions. In order to do this, an
auxiliary algorithm is needed that is described in the
next section.
4.6 Tearing with retained solution space
Starting point is a nonlinear algebraic equation system
 = (),

   ,    ,   

(21)

where the number of equations  is at most the same
as the number of unknowns , but it may be less. The
goal is to split this equation system in an explicitly
solvable part and an implicit part:
 =  ( ,  )
0 =  ( ,  )

(22a)
(22b)

where  can be solved recursively from (22a) by
utilizing only already computed elements of  when
calculating a new element of  .  are called the
explicitly solvable variables of ,  the tearing
variables of  and  the residue equations. The
interpretation is that when  is given,  can be
explicitly computed and  must be provided in such a
way that the residues equations are fulfilled.
In order that this transformation is practically useful,
the solution space of (22) must be identical to the
solution space of (21). In the following an algorithm is
derived to automatically deduce (22) from (21) such
that (22) has the same solution space as (21).
Tearing is a well-known technique and was
probably introduced by (Kron, 1962). A recent
extensive literature survey is given in (Bahainv et al.,
2016a). In (Bahainv et al., 2016b) a novel tearing
technique is proposed based on an integer
programming formulation with a custom branch and
bound algorithm. Tearing was used in object-oriented
modeling, for example in (Elmqvist and Otter, 1994)
and in (Carpanzano et al., 1997). The following
algorithm sketch for automatic tearing is due to a
DOI
10.3384/ecp17132565

development of the authors of this paper in 1999. Some
results of it have been reported in (Otter, 1999):
Equation (22a) can be interpreted as a DAG
(Directed Acyclic Graph) where the nodes are
equations , together with the explicitly solved
variables , of , , and the edges of a node i are
directed to the nodes of the remaining variables ,
appearing in , . The goal of the algorithm is to
construct such a DAG using equations and unknowns
from (21). Initially, the DAG is empty and is
constructed with the following steps:
Step 1: Select an array equation i from (21) that is not
yet in the DAG (in a first step equations are
selected according to their initial ordering; later,
heuristics for the selection are added based on
additional information).
Step 2: Select an array variable j from equation i that
is (a) not assigned to equation i, (b) not yet
selected before in this equation, and (c) can be
explicitly solved from equation i (so the array size
of variable j and of the array equation i must agree)
without changing the solution space of this
equation (e.g. using only variables  as candidates
that are within linear factors    where  is a
constant with   0; see also the discussion about
heuristics below and (Otter, 1999)).
Step 3: Add equation i and the selected variable j from
Step 2 as node to the potential DAG.
Step 4: Traverse the potential DAG starting from the
added equation node and use a standard DFS
(Depth First Search) to determine if there is a cycle
for this equation node. If there is a cycle, remove
the last added equation from it and if not all
variables of equation i have been inspected, go to
Step 2. If no cycle is present, continue with the
next step.
Step 5: If not all equations have been inspected, go to
Step 1. Otherwise, stop (equations (22a) are the
equations in the DAG,  are the assigned
variables in the DAG).
With  the number of variable incidences in the
system of equations, the worst time complexity of this
algorithm to find the tearing variables and residue
equations is (2 ) because every DFS from every
inserted node has a worst-time complexity of ()
and this operation is executed potentially  times
(since in the worst case a DFS is performed on every
variable in every equation).
In the last decade, several new algorithms have been
developed to perform incremental cycle detection when
inserting vertices and edges to an existing DAG. The
algorithm of (Bender et al., 2016) has the currently
best worst case performance for sparse DAGs with
(min(1/2 , 2/3 )  ), where  is the number of
vertices and  the number of edges. For comparison of
such algorithms, see (Sigursson, 2016).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

573

Transformation of Differential Algebraic Array Equations to Index One Form

The implementation in Modia/Julia uses currently
the simple Algorithm N of (Bender et al., 2016) that
has a worst time complexity of (  ). For example,
when an equation system of the following form is
present
0 = 1 (1 ,  )
0 = 2 (2 , 1 )
0 = 3 (3 , 2 )
(23)

0 =  ( , 1 )

and the equations are added in the order 1,2,..., n (or
also in the order n,n-1,...,1), this tearing algorithm has
a complexity of () to find the single tearing
variable. On a standard notebook, this takes about 2 s
for  = 106 .
The result of the tearing algorithm depends on the
order in which equations are added to the DAG. There
are at least two useful heuristics: (a) If the user
explicitly requires to solve equations for particular
variables (for example using the operator ":=" instead
of "=" in the Modia prototype, or the algorithm section
or a function call in Modelica), then these equations are
inspected first. All equations belonging to the
connection graph (especially all linear equations with
only Integer coefficients, see section 5) are inspected
last, because it seems most natural for a physical
system to cut an algebraic loop along the connection
graph, and not within a component.
Tearing can have a significant influence on the
reliability of the numerical solution and therefore it is
not always clear whether it is useful to apply tearing to
solve algebraic loops. For this reason, more heuristics
need to be added, for example, arrays might be solved
in Step 2 above only, if they appear as linear term and
the linear factors are the scalars +1 or -1, in order to
avoid a potential division by a small value, or if the
linear term is an orthogonal matrix so that inversion is
reliable.
4.7 Partial state selection
The tearing algorithm from the last section shall now
be used to partially solve the constraint equations and
thereby identify states and dummy states. The
constraint equation sets are derived with the approach
of section 4.5 and all these sets have the following
structure:
 = (1 , 2 )

1  1 , 2  2    ,   1

(24)

where 1 are potential states, 2 are potential states
that have been already handled in a previous BLT subcomponent (so can be treated as known variables) and
(. . ) is a set of algebraic constraint equations on 1 .
Via tearing the constraint equation set (24) can be split

574

in an explicitly solvable part  (. . ) and in an implicit
part  (. . ):
1 =  (1 , 1 , 2 )
0 =  (1 , 1 , 2 )

(25)

The explicitly solvable variables 1 are dummy states
according to the dummy derivative method of
(Mattsson and Sderlind, 1993). The tearing variables
1 remain potential states. If no residue equations
 (..) are present, the full set of states has been
identified. If the equations are linear in 1 , 1 , then
the residue equations can be transformed to a linear
equation in the tearing variables, see for example
(Elmqvist and Otter, 1994). For constant coefficient
linear systems, this equation system can be at once
solved. For variable coefficient linear systems, an
inline solution of the linear system might be used, at
least for systems with up to three unknowns. In all
these cases the full set of states has been identified as
well.
The state selection with tearing is applied on all
constraint sets starting from the lower to the higher
derivative constraint sets ec[1]...ec[end] of every BLT
component. Since by construction ec[i] is a superset of
ec[i-1], and the unknowns   of ec[i] are a
differentiated superset of the unknowns 1 , all
explicitly solvable equations of ec[i-1] are also
explicitly solvable equations of ec[i] and therefore
tearing need only to be performed additionally on
equations that are added at a higher level.
Applying the partial state selection for example on
BLT sub-component 3.1 of (20) identifies 2 as state
and computes the dummy states from:
1 = 1 () + 2
3 = 2 ()  1 + 2   6
The same analysis holds for BLT sub-component 3.2,
so  2 is also a state and the following equations are
directly deduced from the previous equations:
1 =  1 () +  2
 3 =  2 ()  1 +  2   6
Tearing must therefore only be applied for the
additional equation of this sub-component leading to:
4 = 3 () + 1 +  3
Applying the partial state selection on BLT subcomponent 2.1 of (20) identifies 6 as state and
computes the dummy state from
7 = 6 ()  26
The residue equation is linear in 6 and can then be
solved for:
6 = (7 ()  46 ())/5

Once partial state selection has been applied on all
constraint sets, all the dummy states and their
derivatives, up to the highest derivatives of the dummy
states, are removed from  and  and are computed

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

locally from the remaining  and  . The remaining
equations can be transformed to DAE (17). Hereby, the
sorting order of the locally solved equations matters
and therefore the ordering has to be performed
according to the BLT ordering and the corresponding
ordering of the constraint sets.
Applying partial state selection with tearing on
example (20) results in the following DAE (17):
  = [2 ;  2 ]
  = [8 ]
 = [ ]
  = [ ]
6 = 7 ()  46 ()5
7 = 6 ()  26
 6 =  7 ()  4 6 ()5
 7 =  6 ()  2 6
 6 =  7 ()  4 6 ()5
 7 =  6 ()  2 6
7 ()  4
6 = 
6 ()5
()
6
 26
7 = 
1 = 1 () + 2
3 = 2 ()  1 + 2   6
1 =  1 () +  2
 3 =  2 ()  1 +  2   6
4 = 3 () + 1 +  3
1 =  1 () +  2
 3 =  2 ()  1 +  2  6
 4 =  3 () +  1 +  3
5 = 5 ()  31  2 2  0.18
0, = [4 () + 21 +  2 +  3 +  4 + 6 ]
0, = [8 () + 8  sin(8 )]
 = [ ]
(0:   2) = [1]
(1:   1) = [2]

(  ,1 = ,2 )

The result is a DAE with 3 equations (without partial
state selection, it had been 21 equations).
Using tearing for the constraint equations seems to
be always a useful approach because this can
significantly reduce the number of variables that need
to be discretized by the integrator. For example,
assume a tree-structured multi-body system is modeled
with the Modelica.Mechanics.MultiBody library and
has  bodies that are connected together by revolute
joints. Without partial state selection, DAE (17)
consists of (6  3 + 4  9 + 2) = 56 equations 3.
After partial state selection with tearing the DAE
consists of the 2 equations (15), provided the simple
heuristics from section 4.6 are used.
However, it is less clear whether tearing is also
useful when applied on the highest order derivative
equations that are no derivatives of constraints. For
example, discretized partial differential equations
typically lead to structures where tearing cannot reduce
3

 =  ;  ;  ;  ;  ;  ;  ;  ;  ; 
 ;  ;   
 = 1,2, . . . 

DOI
10.3384/ecp17132565

the equation size much but will completely destroy the
sparseness and may be numerically less reliable. In
such cases it is much better to not apply tearing and
rely on the sparse matrix handling used by the
integrator. More investigations are needed here.

5

Exact Removal of Singularities

5.1 Overview
In this section a new method is proposed to exactly
remove certain types of singularities of a physical
system model provided as DAE (1). The result is again
a DAE in form (1). A typical example is shown in
Figure 1.

Figure 1. Modelica model of an electrical circuit that is
difficult to simulate. It can be automatically handled with
the method of this section.

Modelica tools transform DAEs (1) with structural
symbolic algorithms. These algorithms fail for the
circuit in Figure 1 (as well as other useful application
models). Since this electrical circuit is not grounded,
the potentials of the electrical Pins can float, that is, the
system equations are underdetermined. On the other
hand, the equations are overdetermined regarding
currents. An analysis, literature survey, and a solution
based on exploitation of the connection graph is
presented in (Elmqvist and Mattsson, 2016).
Additionally, the currents 1 , 2 appear differentiated in the inductors 1 , 2 and are therefore assumed
to be known. The two inductors are connected by two
resistors in parallel leading to the following connection
equations for the currents:

1 = 1 + 2
2 = 1 + 2

(26)

where 1 , 2 are the currents through the resistances
1 , 2 . Structurally, (26) are two equations for two
unknown algebraic variables 1 , 2 since the potential
states 1 , 2 are assumed to be known. Therefore,
structural algorithms assume that 1 , 2 can be
determined from (26). However, when subtracting the
two equations 1 + 2 = 0, that is an equation with
only known variables is obtained, which means that
one of the two variables cannot be a state. As a result
structural index reduction algorithms, as discussed in
section 3, will fail on this circuit.
The method below is based on the observation that
object-oriented models have a particular structure:
Zero-sum equations of flow variables  in connectors

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

575

Transformation of Differential Algebraic Array Equations to Index One Form

 have the form   .  = 0. After alias elimination,
relative potential variables in a component have the
form  =  .    . . All these equations have the
common property that they are linear and the
coefficients are integer (even +1 or -1). Due to the
integer coefficients exact analysis is possible. In
particular, singularities and state constraints in linear
equations with integer coefficients are identified and if
possible removed. The latter cannot be achieved with
methods based on connection graphs, such as (Elmqvist
and Mattsson, 2016) or similar techniques.
When applied to the circuit in Figure 1, the method
in section 5.3 gives the result that the following
equation shall be removed since redundant:
-L2.n.i - V.n.i = 0

In order to make all potentials well-defined, the
following equation is added:
L2.n.v = 0

In order to make the state constraints structurally
visible, the equation
-R1.p.i - R2.p.i - L1.n.i = 0

is replaced by
-L1.p.i + L2.p.i = 0

5.2 Transformation to upper trapezoidal form
The new approach is based on a utility algorithm to
perform a fraction-free Gaussian elimination of linear
algebraic equations with integer coefficients. The
algorithm is a slight generalization of (Bareiss, 1968),
see also (Turner 1995). Starting point is a linear
algebraic equation system
(27)
   = ,
  1  2 ,   1  2
where  and  are sparse, rectangular integer matrices.
The goal is to use fraction-free Gaussian elimination to
transform (27) to upper trapezoidal form:


11




12
   1  =  1 
 2
2


(28)

where  11 ,  12 , 1 , 2 are integer matrices and
 11 is quadratic, regular, and upper triangular with
non-zeros on the diagonal, that is rank() =
size( 11 , 1). Additionally, permutation vector 1
describes the accumulated row interchanges of , 
and permutation vector 2 describes the accumulated
column interchanges of  and row interchanges of 
such that   = [2 , : ]. Permutation vector 2 is
selected such that if possible the "upper" part of  is
utilized in  1 (this is used in section 5.3).
Algorithm 1 is a straightforward implementation of
Gaussian elimination with full pivoting for sparse
matrices. The key point are the two equations at the
end with the "div(a,b)" operator where equation i is
subtracted from equation k with a fraction free
operation. Here, the non-trivial to derive property is
used that the integer division div(a,b)=a/b has no
remainder in this case. For details see (Bareiss,1968).
576

Algorithm 1
(Au,Bu,rk,p1,p2) = upperTrapezoidal(A,B)
# Transform the rectangular linear system A*X=B
# to upper trapezoidal form Au*X[p2,:]=Bu
# A,B,Au,Bu are integer matrices
# initialize variables
(na1,na2) = size(A); nb2 = size(B,2); p1=1:na1; p2=1:na2
Au = copy(A); Bu = copy(B);
oldPivot = 1
# inspect all rows of Au
for k = 1:na1
# search column wise for a pivot in Au[k:,min(k,na2):]
pivotFound = false
for k2 = k:na2
for (k1,pivot) in < row indices k1 and values pivot of
non-zero entries of column k2 >
if k1 >= k && pivot != 0
pivotFound = true
p1k = k1
p2k = k2
break
end
end
if pivotFound; break; end
end
# exchange rows/columns such that Au[k,min(k,na2)]0
if pivotFound
<exchange rows k and p1k of Au, Bu, p1, and
exchange columns k and p2k of Au and row p2k of p2 >
else # submatrix Au[k:na1,:] has only zeros
rk = k-1
return (Au, Bu, rk, p1, p2)
end
# Subtract row k from rows k+1:na1
k1 = k+1
j = k1:na2
for (i,val) in < row indices i and values val of non-zero
entries of column k >
if i >= k1
Bu[i,:] = div(pivot*Bu[i,:]  val*Bu[k,:], oldPivot)
Au[i,j] = div(pivot*Au[i,j]  val*Au[k,j], oldPivot)
Au[i,k] = 0
end
end
oldPivot = pivot
end
return (Au, Bu, rk, p1, p2)

5.3 Identifying singularities in the model
Starting point is the largest subset of equations of DAE
(1) that is described by a linear algebraic system
  +   +   +   = 

(29)

where  ,  ,  ,  are sparse matrices with (scalar)
integer elements of appropriate dimensions and
 , ,  ,  are vectors of variables of (1). An
element of these vectors may be a scalar, an array, or
an instance of any data structure for which the
operators "+", "-", "*" are defined (overloaded) as
operations between instances of the same type and
between an instance of the type and a scalar integer.
Furthermore, it is assumed that within one equation the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

variables are all of the same type and arrays have the
same dimension sizes (so, one equation may state a
relationship between [3,3] matrices, whereas another
equation between [6] vectors, and yet another one
between scalars). Since an equation can only depend
on variables of the same type, equations (29) are
basically a disjunct set of equations for different types
that are analyzed conceptually in an independent way
from each other. The various vectors have the
following meaning:
 Variables used in the derivative operator, so
(, ) appears in the model.
 After removing equations (29) from (1),
variables  are no longer present in (1).
Therefore, these variables must be computed
from (29). For example, if  = .   . 
and the connector variables .  and .  are not
used otherwise in the model, they are part of
 .
 Variables defined by a parameter expression.
For example, if 0 = 5 and 0 is utilized in
other linear equations with integer coefficients,
then 0 is part of  .
 All remaining variables that do not belong to
one of the other three categories above.



with

 = [
 = [


 ],  =   


 ],  =  








(31)

With Algorithm 1 from section 5.2

(30) can be transformed to upper trapezoidal form:


,11


1

,12
     =  1   ( )
2
2


(32)

where ,11 is a quadratic, regular, upper triangular
integer matrix of size [, ] with non-zeros on the
diagonal, 1 =  [2 [1: ]] are  elements of 
and 2 =  [2 [ + 1: ]] are the remaining
elements of  . With 2 = [2,1 2,2 ], the lower
part of (32) can be stated as:
(33)
2,1  = 2,2 ( )
Using Algorithm 1 again:

( ,  ,  , 1 , 2 ) =
upperTrapezoidal(2,1 , 2,2 )

(33) can be transformed to upper trapezoidal form:

DOI
10.3384/ecp17132565

(34)

From (32) and (34) the following conclusions can be
drawn regarding singularities in the model equations:

(30)

( ,  , , 1 , 2 ) = upperTrapezoidal( ,  )

1

,12
     =  1   ( )
2
2


where ,11 is a quadratic, regular, upper triangular
integer matrix of size [ ,  ] with non-zeros on the
diagonal, 1 =  [2 [1:  ]] are  elements of
 and 2 =  [2 [ + 1: ]] are the remaining
elements of  .

In a first step, equations (29) are restructured to:
  =  ( )

11




If 2 is not the zero matrix, then there are
constraints 2  =  between the parameter
expressions  . A tool may reject such a model. In
the following it is assumed that 2 = .
If  +  < length( ), then the lower part of
(34) are zero-equations and represent redundant
equations. As a result, the original equations with
row indices 1 [ + 1 [ + 1, : ]] can be
removed since they can be expressed as a linear
combination of the other integer equations. A tool
may just remove these equations and print an
information message that it removed them.
If 2 contains elements of  , then these
variables can have an arbitrary value. For example
assume that  are scalar real variables, then (32)
can be solved for 1 :
1 = 1
,11  ,12 2 + 1  
Therefore, for given states  and given values of
2 , variables 1 can be uniquely computed.
Note, since variables  must be computed from
(29) they can be arbitrarily set, if part of vector
2 . Since variables  appear also in the
remaining model equations, they need to be
computed in these remaining model equations. A
tool may either reject a model where 2 contains
elements of  , or may set arbitrary values (say the
null-element of the respective type) and print an
information message.
The upper part of (34) can be formulated as:
(35)
11 1 = ,12 2  1 

Since 11 is regular this means that 1 can be
computed from 2 and  and therefore 1 are
(dependent) dummy states. A tool can either utilize
this information directly and transform the model
equations with this information, or the equations
leading to (35), that is the equations of (29) with
row indices 1 [ + 1 [1:  ]], are replaced by
equations (35). Since 11 is upper triangular,
the constraints between the states are structurally
visible and therefore index reduction with
structural algorithms (see section 3) is possible.
To summarize, with the transformation of the integer
equations (29) of DAE (1) to upper trapezoidal form
(32),(34) an important set of singularities can be
exactly identified and if possible and desired removed.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

577

Transformation of Differential Algebraic Array Equations to Index One Form

6

Outlook

With this paper new algorithms are provided to start
from a high level modeling language like Modelica or
Modia and generate code for standard Index-1 DAE
integrators. The algorithms are designed to keep array
data structures intact from the model language until the
generated code. Furthermore, no equation systems are
solved to transform to index 1 form and therefore the
sparsity of the model equations is kept. As a
consequence, sparse matrix methods can be utilized in
the DAE integrator.
In the paper it was not discussed how to initialize
the index-1 DAEs. In principal similar techniques can
be used as for Modelica models. Currently, in Modia it
is experimented with a new form of initialization where
start values  0 (0 ) can be provided that do not fulfill
the constraints of (2), so  ( 0 (0 ), 0 )  0. Via Dirac
impulses of the derivatives of the discontinuous start
values, consistent start values  0 (0+ ) are computed
with the new technique of impulse handling for DAEs
(2), developed in (Benveniste et al., 2017).
In industrial applications often steady-state
initialization is required. This is still a difficult topic
and not yet satisfactorily solved. Typically, reliable
steady-state initialization requires the use of a
probability one homotopy method; see for example
(Melville et. al., 1993; Sielemann, 2012). It is an open
question how to restrict the special index-one DAEs
(2) so that probability one homotopy methods can be
applied.
The goal is to further extend the algorithms and the
Modia prototype in order to be able to simulate multimode systems, where the number of equations and
unknowns can change during simulation (for example
to simulate drastic failure cases or perform end-to-end
simulations of complicated scenarios).
Acknowledgements
The authors would like to thank Martin Arnold from
University Halle-Wittenberg for discussions to
understand the fine details of multibody integrators.
References
M. Arnold (2016): DAE aspects of multibody systems. In A.
Ilchmann, T. Reis (eds.): Surveys in Differential-Algebraic
Equations IV. - Springer, 2017 (in print). - A preliminary
version of this material was published as Technical Report
01-2016, Martin Luther University Halle-Wittenberg,
Report No. 01, 2016. http://sim.mathematik.unihalle.de/reports/sources/2016/01-2016.pdf
U.M. Ascher, L.R. Petzold (1991): Projected Implicit
RungeKutta Methods for Differential-Algebraic
Equations. SIAM J. Numer. Anal., 28(4), pp. 10971120.
A. Bahainv, H. Schichl, A. Neumaier (2016a): Tearing
systems of nonlinear equations. I. A survey.
http://www.mat.univie.ac.at/~neum/ms/tearing_survey.pdf

578

A. Bahainv, H. Schichl, A. Neumaier (2016b): Tearing
systems of nonlinear equations. II. A practical exact
algorithm.
http://www.mat.univie.ac.at/~neum/ms/tearing_exact_algo
rithm.pdf
E.H. Bareiss (1968): Sylvester's Identity and Multistep
Integer-Preserving Gaussian Elimination. Math. Comp.
22, pp. 565-578.
M.A. Bender, J.T. Fineman, S. Gilbert, R.E. Tarjan (2016): A
New Approach to Incremental Cycle Detection and
Related Problems. ACM Transactions on Algorithms,
Volume 12, Issue 2.
A. Benveniste, B. Caillaud, H. Elmqvist, K. Ghorbal, M.
Otter, and Marc Pouzet (2017): Multi-Mode DAE Models
Challenges, Theory and Implementation. Lecture Notes on
Computer Science, submitted for review.
J. Bezanson, A. Edelman, S. Karpinski and V.B. Shah
(2017): Julia: A Fresh Approach to Numerical Computing.
SIAM Review, Vol. 59, No. 1, pp. 65-98.
http://julialang.org/publications/julia-fresh-approachBEKS.pdf; see also: http://julialang.org/
K.E. Brenan, S.L. Campbell, and L.R. Petzold (1996):
Numerical Solution of Initial Value Problems in
Differential-Algebraic Equations. SIAM.
E. Carpanzano, R. Girelli (1997): The Tearing Problem:
Definition, Algorithm and Application to Generate
Efficient Computational Code from DAE Systems.
Proceedings of 2nd Mathmod Vienna, IMACS Symposium
on Mathematical Modelling, Wien.
S. Chowdhry, H. Krendl, and A.A. Linninger (2004):
Symbolic numeric index analysis algorithm for differential
algebraic equations. Industrial and Engineering Chemistry
Research. Vol. 43, Issue 14, pp. 3886-3894.
W. Cook, and A. Rohe (1999): Computing Minimum-Weight
Perfect Matchings. INFORMS Journal of Computing, Vol.
11. www.math.uwaterloo.ca/~bico/papers/match_ijoc.pdf
I.S. Duff (1981): On algorithms for obtaining a maximum
transversal. ACM Trans. Math. Software, Vol. 7, Issue 3.
I.S. Duff, K. Kaya, and B. Ucar (2011): Design, Implementation, and Analysis of Maximum Transversal Algorithms.
ACM Trans. Math. Software, Vol. 38, Issue 2.
J. Edmonds (1965): Paths, Trees , and Flowers. Canadian
Journal of Mathematics. Vol. 17, pp. 449-467.
https://cms.math.ca/openaccess/cjm/v17/cjm1965v17.0449
-0467.pdf
E. Eich (1993): Convergence Results for a Coordinate
Projecion Method Applied To Mechanical Systems with
Algebraic Constraints. SIAM J. Numer. Anal. Vol. 30, No.
5, pp. 1467-1482.
H. Elmqvist, M. Otter (1994): Methods for Tearing Systems
of Equations in Object-Oriented Modeling. Proceedings
ESM94, European Simulation Multiconference,
Barcelona, Spain, June 13, pp. 326332.
H. Elmqvist, T. Henningsson, M. Otter (2016): System
Modeling and Programming in a Unified Environment
based on Julia. Proceedings of ISoLA 2016 Conference
Oct. 10-14, T. Margaria and B. Steffen (Eds.), Part II,
LNCS 9953, pp. 198-217. http://www.isolaconference.org/isola2016/proceedings.html

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132565

Session 9B: Numerical & Symbolic Methods

H. Elmqvist, S.E. Mattsson (2016): Exploiting Model Graph
Analysis for Simplified Modeling and Improved
Diagnostics. Proceedings EOOLT '16, April 18, Milano,
Italy.
H. Elmqvist, T. Henningsson, M. Otter (2017): Innovations
for future Modelica. Modelica Conference 2017, Prague.
J. Frenkel, G. Kunze, P. Fritzson (2012): Survey of
appropriate matching algorithms for large scale systems
of differential algebraic equations. Proceedings of the 9th
International Modelica Conference, Munich.
http://www.ep.liu.se/ecp/076/045/ecp12076045.pdf
C. Fhrer (1988): Differential-algebraische Gleichungssysteme in mechanischen Mehrkrpersystemen. Theorie,
numerische Anstze und Anwendungen. PhD thesis, TU
Mnchen, Mathematisches Institut und Institut fr
Informatik.
C.W. Gear (1988): Differential-Algebraic Equation Index
Transformations. SIAM J. Sci. Stat. Comput., Vol. 9, No.
1, pp. 39-47.
C.W. Gear, G.K. Gupta and B. Leimkuhler (1985):
Automatic integration of EulerLagrange equations with
constraints. J. Comp. Appl. Math., 12&13, pp. 7790.
A.C. Hindmarsh, P.N. Brown, K.E. Grant, S.L. Lee, R.
Serban, D.E. Shumaker, and C. S. Woodward (2005):
SUNDIALS: Suite of Nonlinear and Differential/Algebraic
Equation Solvers. ACM Transactions on Mathematical
Software, Vol. 31, No. 3, pp. 363396.
http://computation.llnl.gov/projects/sundials/toms_sundial
s.pdf
G. Kron (1962): Diakoptics  The piecewise Solution of
Large-Scale Systems. MacDonald & Co., London.
S.E. Mattsson and G. Sderlind (1993): Index Reduction in
Differential-Algebraic Equations using Dummy
Derivatives. SIAM Journal of Scientific Computing. 14(3),
pp. 677-692.
S.E. Mattsson, H. Olsson and H. Elmqvist (2000): Dynamic
Selection of States in Dymola. Modelica Workshop 2000,
Lund, Sweden, pp. 61-67.
https://www.modelica.org/events/workshop2000/proceedi
ngs/old/Mattsson.pdf
R.C. Melville, L. Trajkovic,S.-C. Fang, L.T. Watson (1993):
Artifical parameter homotopy methods for the DC
operating point problem," IEEE Transactions on
Computer-Aided Design of Integrated Circuits and
Systems, vol. 12, pp. 861-877.
M. Otter (1999): Objektorientierte Modellierung Physikalischer Systeme, Teil 4: Transformationsalgorithmen. at
Automatisierungstechnik, 47, 3, pp. A9-A12.
C.C. Pantelides (1988): The Consistent Initialization of
Differential-Algebraic Systems. SIAM Journal on
Scientic and Statistical Computing, 9(2):213231.
L. Petzold and P. Ltstedt (1986): Numerical Solution of
Nonlinear Differential Equations with Algebraic
Constraints II: Practical Implications. SIAM J. Sci. Stat.
Comput. Vol. 7, No. 3, pp. 720-733.
J.D. Pryce (2001). A Simple Structural Analysis Method for
DAEs. BIT Numerical Mathematics, Vol. 41, Issue 2, pp.
364-394.

DOI
10.3384/ecp17132565

J. Schuchart, V. Waurich, M. Flehmig, M. Walther, W.E.
Nagel, I. Gubsch (2015): Exploiting Repeated Structures
and Vectorization in Modelica. Proc. of the 11th Int.
Modelica Conference, Versailles.
www.ep.liu.se/ecp/118/028/ecp15118265.pdf
M. Sielemann (2012): Device-Oriented Modeling and
Simulation in Aircraft Energy Systems Design. PhDDissertation. Technische Universitt Hamburg-Harburg.
http://www.dr.hut-verlag.de/9783843905046.html
R.L. Sigursson (2016): Practical performance of
incremental topological sorting and cycle detection
algorithms. Chalmers University of Technology. Master
Thesis.
http://publications.lib.chalmers.se/records/fulltext/248308/
248308.pdf
S.S. Skiena (2008): The Algorithm Design Manual. Second
edition. Springer.
K. Stavaker: Contributions to Simulation of Modelica
Models on Data-Parallel Multi-Core Architectures. PhD
thesis. Linkping University. http://liu.divaportal.org/smash/get/diva2:806837/FULLTEXT01.pdf
P.R. Turner (1995): A simplified fraction-free Integer Gauss
Elimination Algorithm. REPORT NO: NAWCADPAX96-196-TR. Office of Naval Research.
http://www.dtic.mil/cgibin/GetTRDoc?Location=U2&doc=GetTRDoc.pdf&AD=
ADA313755

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

579

580

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Smart Processing of Function Calls
to Achieve Efficient Simulation Code
Jan Hagemann

Patrick Tuber Lennart Ochel

Bernhard Bachmann

Department of Engineering and Mathematics, University of Applied Sciences Bielefeld, Germany,
{jan.hagemann,patrick_marcel.taeuber,lennart.ochel,bernhard.bachmann}@fh-bielefeld.de

Abstract

fore the significance of the algorithm.

This paper introduces a new algorithm to increase the simulation performance of algebraic equation systems by encapsulating function calls. This avoids unnecessary evaluations of function calls and leads to positive structural
effects, such as code motion. To enable the reader to reconstruct the algorithm, all four phases of the algorithm are described in detail and the complexity of them is
analyzed. The overall complexity for practical models is
O(n), where n is the number of equations. It is shown that
the algorithm significantly decreases the simulation time
for a wide range of physical based models.
Keywords: function calls, backend, simulation

2

1

Introduction

Symbolic transformation and simplification methods (e.g.
alias elimination, tearing methods, and index reduction)
are essential within a Modelica compiler in order to
achieve efficient simulation of the underlying differentialalgebraic equation system. In this paper a proper handling
of time-consuming function calls is discussed. It will be
shown that the corresponding implementation of the module WrapFunctionCalls results in a tremendous decrease
of simulation time for many models of specific libraries
including the MSL 3.2.1. The expected performance increase has been already discussed in earlier publications
(Jorissen et al., 2015).
The module WrapFunctionCalls traverses the equation
system for occurring function calls. Those are stored in
temporary variables, which are inserted at the according
places in the equation system. This elimination is similar
to the Common Subexpression Elimination (Jakubowski,
2002), hence the auxiliary variables for the function calls
are called CSE-variables. However, the difference is that
in the case of WrapFunctionCalls also single occurring
function calls are stored.
There are some requirements on an efficient and reliable algorithm to encapsulate function calls, which are
discussed in the next section before the algorithm is presented in Section 3. Such or similar symbolic transformations of function calls could not be found in literature
or are not accessible in other simulation environments.
At the end of the paper a verification section proves the
effects on models with a practical orientation and thereDOI
10.3384/ecp17132581

Requirements on the Algorithm

To achieve efficient simulation code by processing function calls first and foremost all function calls must be
found regardless whether they occur in simple equations
or if the function itself is an argument to another function.
Consequently, nested function calls (e.g. exp(cos(time)))
must be analyzed in detail to guarantee that function calls
in arguments of other functions are replaced as well.
At this point it should be mentioned that only equations
are traversed for functions. Algorithms are not handled
by the module yet. Special Modelica constructs like impure functions are not traversed for nested calls as well and
functions which are called conditionally (i.e. functions in
bodies of when- and if-equations) are not encapsulated if
they do not appear in the rest of the equation system.
All the found functions must be stored in CSEvariables. Considering the Modelica modelling language,
it must be noted that for calls in equations of the form
variable = call

(e.g. x = cos(time))
or

tuple = call

(e.g. (a, b, _) = f (time, x))

no new CSE-variables should be introduced, because in
those cases the variables on the left-hand side already encapsulate the corresponding functions and can therefore
be used as CSE-variables.
Additionally, identical function calls, which do not necessarily have to look similar at the first sight, have to be
recognized. The following example shows three equations
with mathematically identical function calls in the second
and third equation, due to the first equation:
x = cos(time)
a = exp(x)
y = exp(cos(time))
The main objective of the algorithm is to reduce the
simulation time by encapsulating function calls. Thus, duplicated calls only need to be evaluated once instead of every time they occur in the equation system. Especially for
models with more complex functions, this will lead to vast

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

581

Smart Processing of Function Calls to Achieve Efficient Simulation Code

time savings during simulation.
Nevertheless, this is not the only way to reduce expensive
function evaluations. As already mentioned above, one difference to the well known Common Subexpression Elimination methods is that function calls that only occur once
in the whole model are encapsulated as well, because this
can lead to a desirable code motion effect. Code motion
has its origin in the optimization of standard compilers (Aho et al., 2008; Muchnick, 1997; Vogt, 2004). The code
expressions, which appear in loops (e.g. for, while, ...)
and are independent of the iteration variables and their dependencies can be moved out of the loop and be evaluated
beforehand. In Modelica code motion can be seen as the
extraction of subexpressions, i.e. function calls, out of algebraic loops. The following call illustrates the advantage
of code motion in an acausal environment by encapsulating all function calls:

the second equation, however, only the first output is used.
Additionally, both calls of f oo are identical because of the
third equation. Lastly, it must be considered that the toplevel functions in the first and third equation do not need
to be stored in CSE-variables, because the left-hand side
is already a simple variable.
1
2
3
4
5
6
7
8
9
10
11
12
13
14

f1 ( f2 (x), f3 (time))

15

model wfc
function foo
i n p u t R e a l x1 ;
i n p u t R e a l x2 ;
o u t p u t R e a l y1 ;
o u t p u t R e a l y2 ;
o u t p u t R e a l y3 ;
[...]
end f o o ;
Real a , b , x ;
equation
( , b, ) = foo ( x, s i n ( cos ( time ) ) ) ;
a = s i n ( foo ( x, x ) ) + 5 . 0 ;
x = s i n ( cos ( time ) ) ;
end wfc ;

Listing 1.

Abstract example model to introduce

Assuming this call to be part of an algebraic loop, where WrapFunctionCalls
x may be the iteration variable, by encapsulating the calls
in the following way, the calculation of function f3 can
The algorithm works with three data structures, which
be moved out of the loop because it is not dependent on
variables, that are changing its value during the iteration need to be created at the beginning. First, a hash table is
needed to store and access the found function calls effiprocess:
ciently. Due to expiriences with the MSL the size of the
cse1 = f1 (cse2 , cse3 )
hashtable is chosen accordingly to avoid collisions. The
keys of the hash table are the function calls and the values
cse2 = f2 (x)
are integers representing indices of an expandable array,
cse3 = f3 (time)
which is the second data structure. The expandable array
Without the encapsulation f3 would be evaluated in contains entries consisting of a CSE-variable, a function
call and an integer list, which represents the dependencies
each iteration step, which could be expensive.
The verification of the expected effects mentioned between function calls. As third data structure, another array is needed to store the manipulated equations and the
above is done in Section 4.
new CSE-equations (Listing 2).

3

Algorithm

1
2

The algorithm WrapFunctionCalls is divided into four
parts:

3
4
5
6

I. Analysis

7

II. Dependencies

8

//
//
//
//
//
//
//
//

Array of e q u a t i o n s : eqArray
E q u a t i o n : eq
L i s t of v a r i a b l e s of eqSystem : v a r L i s t
E x p r e s s i o n : exp
S u b e x p r e s s i o n : subExp
CSE v a r i a b l e : c s e _ v a r
Hash t a b l e : h t
Expandable a r r a y : a r r a y +

9

III. Substitution

10

IV. Creation of CSE-Equations

11
12
13

For a better understanding of the functionality the algorithm is introduced section by section with an example
and the corresponding pseudo code. After each part the
complexity is assessed.
Listing 1 shows the abstract example model that is used to
illustrate the requirements on a reliable algorithm. Thus,
not only the sine and cosine function calls must be stored
in CSE-variables but also the more complex function f oo,
which has more than one return value, that must be handled properly. The function f oo occurs in two equations.
In the first one, only the second return value is accessed. In
582

create ht :=
< key = c a l l ( e x p ) , v a l u e = i n d e x ( i n t ) >;

14

create a r r a y + :=
[ c s e _ v a r ( exp ) , c a l l ( exp ) , d e p e n d e n c i e s ( l i s t <
i n t >) ] ;

15
16

create eqArray := [ ] ;

Listing 2. Pre-phase of WrapFunctionCalls algorithm:
Create data structures

3.1

Analysis

In the first part of the algorithm all equations of the equation system are traversed top-down to collect all function calls. A detected function call is stored within the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132581

Session 9B: Numerical & Symbolic Methods

hash table, together with an index referring to the correspondent entry of the expandable array, which is basically
an incremented integer for each call starting by 0. The
corresponding entry of the expandable array contains the
CSE-variable, the function call itself and an initially empty dependency list. In the first part of the algorithm all
function calls are stored, even those which might turn out
to be identical to other ones later on. To avoid the introduction of unnecessary CSE-variables an additional conditional branch is needed to detect equations of the form
var = call and tuple = call. In that case the already existing variables are stored as CSE-variables in the expandable array. If in the expandable array a CSE-variable has
been entered for a call that turns out to be equal to an existing variable or tuple, the CSE-variable entry is overwritten
with the already existing variable (cf. Listing 3).
17
18
19
20
21
22
23
24
25
26
27
28

index = 0;
/ / I . A n a l y s i s of eqSystem
f o r each eq i n e q S y s t e m
i f eq a s ( c r e f = c a l l ) or ( t u p l e = c a l l ) t h e n
i f c a l l h a s n o t an e n t r y i n h t t h e n
create ht e n t r y := < c a l l , index >;
create a r r a y + e n t r y := [ c r e f / tuple , c a l l
, {}];
index = index + 1;
else
u p d a t e / merge a r r a y + e n t r y = [ C r e f / Tuple ,
Call , { } ] ;
end i f ;
end i f ;

Table 1. Hash table after the first part of the algorithm (Analysis)

Hash Table (ht)
Function Call
f oo(x, sin (cos (time)))
sin (cos (time))
cos (time)
sin ( f oo(x, x))
f oo(x, x)

by the index from the hash table. For the first call no additional CSE-variable is necessary because the call is equal
to a tuple, so the tuple is stored as CSE-variable. For all
other calls CSE-variables are introduced. Since the call in
the last equation is equal to x and the call already exists
in the hash table, the CSE-variable for sin (cos (time)) is
overwritten with x again. This leads to the expandable array from Table 2, where the integer dependency lists are
still empty.
Table 2. Expandable array after the first part of the algorithm
(Analysis)

Array+
CSE-Variable
(_, b, _)
x
cse2
cse3
(cse4 , _, _)

29
30
31
32
33
34
35
36
37
38

f o r each c a l l i n eq [ TopDown ]
i f c a l l h a s n o t an e n t r y i n h t t h e n
create ht e n t r y := < c a l l , index >;
c r e a t e a c s e _ v a r for c a l l ;
create a r r a y + e n t r y := [ cse_var , c a l l ,
{}];
index = index + 1;
end i f ;
end f o r ;
end f o r ;

39
40
41
42
43

i f h t i s empty t h e n
/ / algorithm terminates
return ;
end i f ;

Listing 3.
Analysis

Phase I of WrapFunctionCalls algorithm:

Since the operations depend on the number of equations
and each equation is addressed exactly one time, the complexity of the first part of the algorithm is O(n), where n
is the number of equations in the equation system.
If the analysis is performed on the example model from
Listing 1 the hash table from Table 1 is generated. Because of the top-down traversal, the first call detected
is f oo(x, sin (cos (time))). After that sin (cos (time)) and
cos (time) are found. The same applies to the second equation. In the last equation a call is found, which already
exists in the hash table, so no new hash table entry is created.
The detected function calls are also stored in the expandable array at the corresponding position determined
DOI
10.3384/ecp17132581

Integer
1
2
3
4
5

3.2

Function Call
f oo(x, sin (cos (time)))
sin (cos (time))
cos (time)
sin ( f oo(x, x))
f oo(x, x)

Integer List
{}
{}
{}
{}
{}

Dependencies

At the beginning of the second phase all the occurring
function calls are already located in the expandable array and in the hash table. In the second part the analysis
continues by considering each array entry to find the dependencies between the different function calls. To do so,
the function calls must be analyzed successively whether
there are other function calls in their arguments. If another function call is detected within an argument, the index
(value) of that call has to be determined from the hash table. Now, at the position of that index in the expandable
array, the dependency list is appended by the index of the
outer function call (Listing 4). So, at the end the dependency list for each call contains the indices of the calls in
which the current call occurs. An empty dependency list
after the second phase signifies a function call independent of all other function calls.
44
45
46
47
48

/ / I I . Dependencies
f o r each e n t r y o f a r r a y +
t r a v e r s e arguments of c a l l
add i n d e x o f c a l l t o each a r g u m e n t e n t r y ( i n
l i s t < i n t >) ;
end f o r ;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

583

Smart Processing of Function Calls to Achieve Efficient Simulation Code

dependency list is {1, 2}, while f oo(x, x) appears in entry
four and therefore has the dependency list entry 4. For the
Listing 4. Phase II of WrapFunctionCalls algorithm:
other function calls the dependency lists remain empty sDependencies
ince they are the top-level functions and do not appear in
If no nested function calls occur in the equation sys- any other function arguments.
tem, the complexity of the second phase is O(k), where k
3.3 Substitution
is the number of supposedly different function calls, i.e.
the number of array elements because each array entry is In the third part of the algorithm the equations in the equation system are traversed again but this time bottomaddressed only once.
If there are nested function calls, the complexity is s- up. The encountered function calls are replaced with the
2
maller than or equal to O(k + ai=1 i) = O(k + a 2+a ) = CSE-variables. If the corresponding dependency list has
O(k + a2 ), where a is the number of function calls in the entries, the function calls in the expandable array at which
arguments of other function calls in the model, because the indices point to are replaced as well and the dependeneach call has to be addressed again for each occurrence in cy list is deleted afterwards. Additionally, a new entry in
2
the hash table is created, which contains the new function
the arguments of another call. The worst case of k + a 2+a
call and its original index in the array, to guarantee that
operations pertains if there is exactly one nested function
occurring calls of that kind can be found as well. If this
call in the equation system because this would lead, for
entry is already existent in the hash table, then the CSEinstance, to the following entries in the array, where a is
variables have to be merged in the expandable array. After
k  1:
the processing of each equation the substituted equation
is added to the equation array if it is not redundant. If
f1 ( f2 (...( fk1 ( fk (x)))...))
the substituted equation is redundant, such as x = x, it is
f2 (...( fk1 ( fk (x)))...)
discarded (cf. Listing 5).
..
49
// III. Substitution
.
50

fk1 ( fk (x))
fk (x)

51
52
53

1 +a2
2
1
i less operations have to
i < ai=1
i + ai=1
Since ai=1
be performed if all the inner calls are not in only one call
but distributed in different calls. In practical and realistic
models the worst case would not occur for a big k, because
a high level of nesting in functions is not used. An analysis of the models of the Modelica Standard Library 3.2.1
shows that the average maximum dependency list length
is about 0.5, where the fluid and media models have the
largest nesting. Thus, with respect to the number of function calls the calls in arguments of other calls are negligible. This assumptions lead to a nearly linear complexity
of O(k).

Table 3. Expandable array after the second part of the algorithm
(Dependencies)

Array+
CSE-Variable
(_, b, _)
x
cse2
cse3
(cse4 , _, _)

Function Call
f oo(x, sin (cos (time)))
sin (cos (time))
cos (time)
sin ( f oo(x, x))
f oo(x, x)

Integer List
{}
{1}
{1, 2}
{}
{4}

Applying the second phase on the example leads to the
dependency list from Table 3. Since sin (cos (time)) occurs in the first entry index 1 is entered in its dependency
list. The cosine occurs in the first and second entry, so its
584

54
55
56
57
58
59
60
61
62
63
64

f o r each eq i n e q S y s t e m
f o r each c a l l i n eq [ BottomUp ]
g e t c s e _ v a r from a r r a y + and s u b s t i t u t e
call ;
s u b s t i t u t e the arguments with the cse_var
i n t h e c a l l s r e f e r e n c e d by t h e
dependency l i s t ;
d e l e t e t he dependency l i s t of th e c u r r e n t
cse_var ;
i f not a l r e a d y in h t then
add t h e new c a l l t o h t w i t h t h e o r i g i n a l
index ;
else
merge c s e v a r i a b l e s i n t h e e x p a n d a b l e
array
end i f
i f t h e s u b s t i t u t e d eq i s n o t r e d u n d a n t
then
add eq t o e q A r r a y ;
end i f ;
end f o r ;
end f o r ;

Listing 5. Phase III of WrapFunctionCalls algorithm:
Substitution

Since the number of operations in the equation system
depends on the number of equations, and the number of
additional operations in the expandable array depends on
the total number of all dependency list entries, which is
negligible relative to the number of equations in models
with a practical orientation, the complexity for the third
phase is nearly linear regarding n (O(n)).
If the third phase is performed on the example model,
the equations are traversed again. This time cos (time) is
the first call that is detected because now the algorithm
works bottom-up. So cos (time) is substituted by its CSEvariable cse2 . Additionally, the calls in the array the dependency list of cos(time) points to are substituted as well,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132581

Session 9B: Numerical & Symbolic Methods

so the first call is f oo(x, sin (cse2 )) and the second call
is sin (cse2 ) now. The dependency list is deleted because
this substitution only needs to be performed once. Finally, new hash table entries are created for f oo(x, sin (cse2 ))
and sin (cse2 ) with the values 1 and 2, respectively.
The next call that is found is sin (cse2 ), which is replaced
by x in the equation and in the first array entry and its dependency list is deleted. The first array entry now contains
f oo(x, x). Since this call already exists in the hash table,
this call is now equal to another call and the introduced
CSE-variables have to be merged. Therefore, the CSEvariables in the fifth array entry are changed to (cse4 , b, _).
The function call in the first array entry is also overwritten
with (cse4 , b, _).
After that, the call f oo(x, x) is found in the substituted equation. It is replaced by (cse4 , b, _) in the equation and
by cse4 in the forth array entry because there the first output is needed. The call sin(cse4 ) is added to the hash table
with value 4 and the dependency list is deleted. At the
end of the processing of the first equation the substituted
equation is (_, b, _) = (cse4 , b, _). Since this equation is
redundant it is not added to the equation array.
While processing the next equations, no more manipulations on the hash table and on the expandable array have to
be performed. At the end of the substitution of the second
equation it reads a = cse3 + 5.0. It is added to the equation
array. The third equation reads x = x and is not added to
the equation list because it is redundant.
The hash table and the expandable array after the third
phase are illustrated in Table 4 and Table 5, respectively.

3.4

Table 4. Hash table after the third part of the algorithm (Substitution)

The processed example model at the end of the WrapFunctionCalls algorithm is shown in Listing 7.

Hash Table (ht)
Function Call
f oo(x, sin (cos (time)))
sin (cos (time))
cos (time)
sin ( f oo(x, x))
f oo(x, x)
f oo(x, sin (cse2 ))
sin (cse2 )
sin (cse4 )

In the fourth and last part of the algorithm each entry of
the expandable array is considered and an equation with
the CSE-variable and the corresponding expression is generated. If that equation is not redundant it is added to the
equation array and the CSE-variable is added to the variable list (Listing 6).
65
66
67
68
69
70
71
72
74

Since each array entry is addressed one time, the complexity of this phase is O(k).
In the example, all equations derived from the expandable array, except the one from the first entry, are added to
the equation array. So the generated CSE-equations in the
example are the following:
x = sin(cse2)
cse2 = cos(time)
cse3 = sin(cse4)
(cse4, b, ) = f oo(x, x)

3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

Array+
CSE-Variable
(_, b, _)
x
cse2
cse3
(cse4 , b, _)

Function Call
(cse4 , b, _)
sin (cse2 )
cos (time)
sin (cse4 )
f oo(x, x)

DOI
10.3384/ecp17132581

Integer List
{}
{}
{}
{}
{}

add e q A r r a y and v a r L i s t t o e q S y s t e m ;

Listing 6. Phase IV of WrapFunctionCalls algorithm:
Create CSE-equations

2

Table 5. Expandable array after the third part of the algorithm
(Substitution)

/ / IV. Create cse equations
f o r each e n t r y o f a r r a y +
g e n e r a t e eq ( c s e _ v a r = c a l l ) ;
i f eq i s n o t r e d u n d a n t t h e n
add eq t o e q A r r a y ;
add c s e _ v a r t o v a r L i s t ;
end i f ;
end f o r ;

73

1

Integer
1
2
3
4
5
1
2
4

Create CSE-Equations

model w f c _ r e s u l t
function foo
input Real x1,
i n p u t R e a l x2 ;
o u t p u t R e a l y1 ;
o u t p u t R e a l y2 ;
o u t p u t R e a l y3 ;
[...]
end f o o ;
Real a , b , x , c s e 2 , c s e 3 , cse4 ;
equation
a = cse3 + 5 . 0 ;
cse3 = sin ( cse4 ) ;
( c s e 4 , b, ) = foo ( x, x ) ;
x = sin ( cse2 ) ;
cse2 = cos ( time ) ;
end w f c _ r e s u l t ;

Listing 7.
Example model after processing with
WrapFunctionCalls

To estimate the costs of the complete algorithm the
complexities of the single phases have to be considered together, so it adds up to O(n + k + n + k). Since in practical
models the number of different function calls is negligible relative to the number of equations, the complexity of
the WrapFunctionCalls algorithm can be estimated with
O(n). The actual complexity is assessed in the next section.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

585

Smart Processing of Function Calls to Achieve Efficient Simulation Code

4

Verification
Complexity
Execution time [s]

4.1

0.6

The complexity of the optimization module WrapFunc0.4
tionCalls depends on the number of given function calls and equations as described above. The estimation
of a complexity of O(n) is confirmed by a test of the
SteamPipe models of the ScalableTestSuite library (Casel0.2
la, 2015a). The ScalableTestSuite library is developed by
Francesco Casella and Kaan Sezginer, Politecnico di Milano (Casella and Sezginer, 2016). This includes different
models among others of the electrical engineering, me0
chanical science and thermodynamics. The models are
0
200
400
600
characterized by the fact that they are scalable by parameN (number of pipes)
ters, so as to test the ability of the Modelica tools in terms
of an efficient compilation and simulation time as the size
Figure 1. Graphic representation of the execution time of Wrapincreases. To do so the execution time of the algorithm for FunctionCalls for SteamPipe models
these models was measured during compilation for different parameters N which is a scalable parameter depending
linearly on the number of equations n.
Table 7. Code Motion example without WrapFunctionCalls
The results of the tests are shown in Table 6 and FigNonlinear loop.
ure 1. These tests confirm that the execution time is linear
Iteration variable: DER.medium.p
proportionate to the parameter N and thus also linear to
DER.medium.h = DER.medium.u the number of equations n. Due to experiences with a va(medium.p * DER.medium.d riety of different other libraries it is assumed that this O(n)
der(medium.p) * medium.d)/(medium.d  2.0)
bahaviour is not only valid for a certain structure of equaResidual equation:
tions.
Table 6. Execution time of WrapFunctionCalls for SteamPipe
models

Model
SteamPipe_N_10
SteamPipe_N_20
SteamPipe_N_40
SteamPipe_N_80
SteamPipe_N_160
SteamPipe_N_320
SteamPipe_N_640

4.2

N
10
20
40
80
160
320
640

n
262
522
1042
2082
4162
8322
16642

Calls
40
80
160
320
640
1280
2560

Time [s]
0.0074
0.0221
0.0298
0.0607
0.1233
0.253
0.552

Code Motion

Below it is shown that the expected effect of code motion
actually happens in practice, i.e. function calls are moved
out of algebraic loops, so that these are calculated beforehand and not in each iteration step. To do so the simulation
time of different libraries are compared with the optimization module WrapFunctionCalls deactivated and activated, respectively. The results of the test are shown in the
next section. The analysis shows that among others in the
model WaterIF97 of the MSL 3.2.1 code motion occurs
in practical relevant examples. This model has a nonlinear
algebraic loop (Table 7), whose residual equation contains
a function call that can be stored in a CSE-variable (cse4)
and thus can be moved out of the loop (Table 8).
586

Modelica.Media.Water.IF97_Utilities.rho_ph_der
(medium.p, medium.h, Modelica.Media.Water.
IF97_Utilities.waterBaseProp_ph(medium.p,
medium.h, medium.phase, 0), DER.medium.p,
DER.medium.h) - DER.medium.d = 0.0
Table 8. Code Motion example with WrapFunctionCalls
cse4 := Modelica.Media.Water.IF97_Utilities.
waterBaseProp_ph(medium.p, medium.h,
medium.phase, 0);
Nonlinear loop.
Iteration variable: DER.medium.p
DER.medium.h = DER.medium.u (medium.p * DER.medium.d der(medium.p) * medium.d)/(medium.d  2.0)
Residual equation:
Modelica.Media.Water.IF97_Utilities.rho_ph_der
(medium.p, medium.h, cse4, DER.medium.p,
DER.medium.h) - DER.medium.d = 0.0

4.3

Improvement in Simulation Time

This section shows the improvement in simulation time of
many models in specific libraries. For this purpose, Table 9 presents some extracts of single libraries with improvements of over 40 percent. The reasons for the significant upgrade are especially the described effects of code
motion and the encapsulation of expensive function calls.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132581

Session 9B: Numerical & Symbolic Methods

in contrast to the original Common Subexpression Elimination. Other peculiarities, e.g. nested function calls,
functions with multiple outputs or simple equations with
a special form such as variable = call, are considered as
well.
Additionally, the algorithm works very efficient, which is
confirmed by a complexity assessment of O(n). A test
with the help of the ScalableTestSuite approves the estimation. The desired effect of code motion also can be
found in practical models and is depicted by an example
of the MSL 3.2.1.
Moreover, single extracts of different libraries are listed,
which show vast improvements in simulation time due to
Table 9. Improvement in simulation time shown on an extract code motion and the encapsulation of function calls.
The analysis shows that the ThermoPower library achieves
the best results with an improvement of over 90 percent,
followed by the SteamPipe models of the ScalableTestSuite with more than 80%. The MSL 3.2.1 also demonstrates enhancements far above 40 percent. For example,
the already mentioned model WaterIF97 gains a speed-up
of 53%.
These absolutely positive results are confirmed by several OpenModelica power users, which also demonstrate
a magnificent improvement in runtime performance of
their applications by encapsulating function calls. (Franke
et al., 2015; Franke, 2016; Casella, 2014, 2015b).

of expressive libraries

Model (Library)

 WFC
[s]

+ WFC
[s]

Imp.
[%]

4.52
4.01
36.31
78.81
8.71
16.77
21.85
2.38
1.90

1.73
1.63
12.89
41.03
3.91
5.19
5.17
0.93
0.90

62
60
65
48
55
69
76
61
53

MSL 3.2.1
DrumBoiler
MomentumBalanceFittings
HeatExchangerSimulation
InverseParameterization
NonCircularPipes
R134a1
DryAir2
TestTwoPhaseStates
WaterIF97

Acknowledgments
This work is supported by the Ministry of Innovation, Science and Research of the German State of North RhineWestphalia (MIWF NRW) as part of the research cooperation MoRitS - Model-based Realization of intelligent
Systems in Nano- and Biotechnologies" (grant no. 321 8.03.04.03 - 2012/02).

References
Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. Compilers - Principles, Techniques, and Tools; 2. Edition. Pearson, 2008. ISBN 978-0321486813.

PlanarMechanics
KinematicLoop_
DynamicStateSelection

19.26

6.12

68

7.59

1.73

77

284.6
8.80
45.73

20.24
0.69
15.82

93
92
65

23.84
45.56
98.24
197.93
412.87

4.35
8.60
17.61
35.39
73.8

81
81
82
82
82

PowerSystems
PowerWorld

ThermoPower
CISESim180504
TestMixerSlowFastSteam
TestWaterFlow1DFV_F

ScalableTestSuite
SteamPipe_N_10
SteamPipe_N_20
SteamPipe_N_40
SteamPipe_N_80
SteamPipe_N_160

5

Conclusions

Francesco Casella. Thermopower library simulation. OpenModelica Workshop, Linkping, Sweden, Februar 3rd ,
2014, 2014.
URL http://www.modprod.liu.se/
openmodelica2014-talks/1.544931/
OpenModelica2014-talk03-FrancescoCasella-ThemoPowerLibrarySimulation.pdf.
Francesco Casella. Simulation of large-scale models in modelica: State of the art and future perspectives. In Proceedings
of the 11th International Modelica Conference, Versailles,
France, September 21-23, 2015, number 118, pages 459
468. Linkping University Electronic Press, Linkpings universitet, 2015a.
Francesco Casella.
Modelling of energy systems with OpenModelica.
OpenModelica Workshop,
Linkping, Sweden, Februar 2nd , 2015, 2015b. URL
http://www.modprod.liu.se/openmodelica2015/1.620217/OpenModelica2015-talk03Francesco-Casella.pdf.

This paper shows an optimization algorithm which enScalableTestcapsulates function calls of the given equation system in Francesco Casella and Kaan Sezginer.
Suite
homepage.
https://github.com/casella/
temporary variables. Above all, the idea is that expenScalableTestSuite, December 2016.
sive function calls should be evaluated only once. Furthermore, the effect of code motion of standard compilers
Rdiger Franke. Embedded optimizing control using the
motivates to find this effect in Modelica models. The exOpenModelica C++ runtime. OpenModelica Workshop,
traction of function calls out of algebraic loops promises
Linkping, Sweden, Februar 1st , 2016, 2016. URL http:
a huge improvement in simulation time since the iteration
//www.modprod.liu.se/filarkiv/1.672872/
does not have to be performed over a function call in each
OpenModelica2016-talk08-RudigerFrankestep. Thus, also single occurring function calls are stored
EmbeddedOptimizingControl.pdf.
DOI
10.3384/ecp17132581

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

587

Smart Processing of Function Calls to Achieve Efficient Simulation Code

Rdiger Franke, Marcus Walther, Niklas Worschech, Willi
Braun, and Bernhard Bachmann. Model-based control with
FMI and a C++ runtime for Modelica. In Proceedings of the
11th International Modelica Conference, Versailles, France,
September 21-23, 2015, pages 339347, 2015.
Jacek Jakubowski. Architekturunabhngige Quellcodeoptimierung durch Mustererkennung. Dissertation, Universitt
Dortmund, 2002.
Filip Jorissen, Michael Wetter, and Lieve Helsen. Simulation
speed analysis and improvements of modelica models for
building energy simulation. In Proceedings of the 11th International Modelica Conference, Versailles, France, September
21-23, 2015, pages 5969, 2015.
Steven S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann Publishers, San Francisco, 1997.
ISBN 978-1-55860-320-2.
Michael Vogt. Plattformunabhngige Eliminierung gemeinsamer Teilausdrcke auf Quellcode-Ebene. Dissertation, Universitt Dortmund, 2004.

588

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132581

Integrative Physiology in Modelica
Ji Kofrnek1, Tom Kulhnek1, Marek Matejk1, Filip Jeek1, Jan ilar1
1

Department of Pathophysiology, 1st Faculty of Medicine, Charles University

{kofranek, tmkulhanek, matejak.marek, jezekf, janeksilar}@gmail.com

Abstract
The integrative model of human physiology connects
individual physiological subsystems into a single unit.
They are enormous (contain thousands of variables) and
represent a formalized description of interconnected
physiological regulations. The issue of formalization
of physiological systems became part of a series of
international projects (e.g. the worldwide program
PHYSIOME, or the European program VIRTUAL
PHYSIOLOGICAL HUMAN). The development of
large-scale models of human physiology was facilitated
by a new generation (i.e. equation-based) of simulation
environments, especially by the Modelica language.
These models can be used to explain the causal relations
of the pathogenesis of many diseases. They can be applied
in the evaluation of clinical trials and they can also be
used in the core of sophisticated medical simulators.
Keywords: Simulation, Physiology, Integrative models

1 Introduction

biological systems, the process of formalization is delayed
in biological and medical sciences compared to physics,
chemistry or technical sciences.
While in physics, the formalization process began
at some point during the 17th century, in medical and
biological sciences it occurred only with the onset of
cybernetics and computer science. Computer models
developed based on mathematical description of
biological reality are used as the methodological tool in
latter sciences.
In physiology, formalized descriptions have been
used since the 1940s; at that time, McCulloch and Pitts

Multiplier

Divider





Guyton

-



Guyton



Simulink

Simulink

+

Integrator



+
+

Guyton



In 1972, Arthur Guyton published an article (A. C. Guyton,
Coleman, and Granger 1972) in the journal Annual
Review of Physiology, whose form quite surpassed the
usual forms of physiological articles of those times at the
very first sight. An extensive diagram, slightly resembling
a complex electronic circuit, enclosed as an attachment,
was used as introduction, showing interconnection of
essential subsystems, that have an effect on circulation,
by means of special symbols expressing mathematical
operations (addition, subtraction, multiplication, division,
integration and functional dependencies). The connections
of the elements thus represented mathematical equations
(Fig. 1) and the entire scheme provided a visual graphic
representation of a set of equations describing the then
available ideas of bloodstream regulation including
essential connections with other physiological systems
of the human organism (Fig. 2). This graphic scheme
of Guyton was thus one of the first mathematical
descriptions of mutually connected physiological systems
in the human organism and it initiated development
of physiological research, today sometimes described
as integrative physiology.

Summator

+

-

Simulink

Guyton
1
s

Simulink

Functional block
20

0
-4

20

50

Simulink

0
-4

50

Guyton

Figure 1. Individual elements in the scheme of Guytons
model display mathematical operations whose connections
represent graphically expressed mathematical equations.
Blocks in the original Guyton notation (1972), and the same blocks
in Simulink (1990).

2 Integrative physiology modelling
Modelling is closely related to formalization  i.e.
replacement of verbal description of physiological
systems with the exact language of mathematics in the
form of a mathematical model. Given the complexity of
DOI
10.3384/ecp17132589

Figure 2. Interconnected physiological subsystems in the
Guyton model (Guyton et al., 1972).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

589

Integrative physiology in Modelica

(McCulloch and Pitts 1943; Pitts and McCulloch 1947),
to mention some examples, designed a simplified neuron
model and Sheppard (Sheppard 1948) introduced his
compartment approach, that found quick application in
pharmacokinetics. In the 1950s, Hodkgin and Huxley
(Hodgkin and Huxley 1952) published their groundbreaking model of the neuronal excitation membrane.
In the 1960s, the development of computers supported
another wave of publications related to formalized
description of physiological reality, for example, Milhorns
monograph on the use of Automated Control Theory in
physiological systems (Milhorn 1966) or the pioneering
work of Grodins regarding the modelling of respiration
(Grodins, Buell, and Bart 1967). At the end of the 1960s
and at the beginning of the 1970s of the past century,
multicompartment systems found broad application in
biology and medicine (Atkins 1969), and computer-based
methods were developed to determine the parameters
of biological systems (Potek et al. 1977).

2.1 Integrative physiology
The above mentioned model of Guyton and his
collaborators from 1972 (A. C. Guyton, Coleman,
and Granger 1972) was one of the first extensive
mathematical descriptions of physiological functions of
mutually connected subsystems in the human organism,
which established an area of physiological research,
today described as integrative physiology (Coleman
and Summers 1997). Similarly as theoretical physics
seeks to describe physical reality and explain the results
of experimental research using formal means, integrative
physiology also seeks to create a formalized description
of mutual connections among physiological regulation
systems and to explain their role in the development of
various diseases based on experimental results. From this
point of view, Guytons model was a certain milestone
aimed at capturing the dynamics of relationships among
the regulation systems of the cardiovascular circulation,
kidneys, respiration, volume and ion composition of body
fluids using a graphically depicted network while applying
a system view of physiological regulation systems.
Guytons graphic notation of the formalized description
of physiological relationships, inspired by then commonly
used analogue computers, provides a highly visual
representation of mathematical correlations  blocks at the
network nodes represent graphic symbols for individual
mathematical operations, while the connecting lines
represent individual variables. Guytons graphic notation
was soon adopted also by other authors  for example,
Ikeda et al. (Ikeda et al. 1979) in Japan or the Amosov
research group in Kiev (Amosov et al. 1977).
With his research and teaching, Guyton changed
physiology from a science of verbal descriptions to one
of quantitative analysis. He brought mathematics and
physics into the discipline. He was a pioneer in the use
590

of computers to study of body function and has taught
scientists all over the world computer simulation.
Guytons model also served as an inspiration and
a resource for the development of complex models of
physiological regulation systems used to explain causal
chains of reactions in the human organism to various
stimuli and to understand the development of various
pathological conditions. Among others, the modified
Guyton model became part of the foundations for an
extensive model of physiological functions in the NASA
program Digital Astronauts (White and McPhee 2007).
Currently, the international project PHYSIOME
(http://www.physiome.org) is focused on the formalized
description of physiological systems; this project is the
successor of the GENOME project, which resulted in
a detailed description of the human genome. The aim
of the PHYSIOME project is to develop a formalized
description of physiological functions. Computer models
are used as the methodical tool (Bassingthwaighte 2000; P.
Hunter, Robbins, and Noble 2002; P. J. Hunter et al. 2006;
Peter J. Hunter, Crampin, and Nielsen 2008; Omholt and
Hunter 2016). VIRTUAL PHYSIOLOGICAL HUMAN
(http://www.vph-institute.org) is a European initiative in
this field, focused, among other things, on applications of
the formalized approach to human physiology in clinical
medicine (P. Hunter 2016). Descendants of Guytons
original computer model of the cardiovascular system
are some of the resources for the development of present
complex models of physiological regulation systems in

System

I
N
T
E
G
R
A
T
E

R
E
D
U
C
E

Parts
Figure 3. A system as an entity that maintains its existence
through mutual interactions of its individual parts (system
elements). In the system analysis, the system should include
only those elements that enter in mutual interactions with
each other (orange squares), while elements that may be
structurally and functionally similar to other system elements
but interact only with the surroundings of the system (an
empty square) should be excluded from the system. The
surroundings of the system interact with individual system
elements or modulate their mutual bonds (dashed arrows).
When studying a system (the transfer between individual
hierarchical levels), reductionist and integration tools and
methods need to be combined. Adapted from (Peter Kohl
and Noble 2009).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

this European project (Thomas et al. 2008).
Besides integrative models of human physiology,
integrative models of laboratory animals have also been
developed recently. The project VIRTUAL RAT is
aimed at designing a complex model of a laboratory
rat that can be validated more easily by comparing to
experimental data from laboratory animals (http://www.
virtualrat.org).

2.2 The human organism as
a hierarchical system
The task of exploring a living organism as a system unit
poses a key problem of how (with respect to the explored
problem) the system structure should be defined in the
biological object, what parts should be understood as
system elements, how to define the subsystems, etc.
According to the definition of Bertalanffy (Von
Bertalanffy 1973), the system is an entity that maintains
its existence through mutual interactions of its individual
parts (system elements). Therefore in the system analysis,
a system defined on any given real object should include
only those parts that primarily interact with each other
(see Fig. 3).
System research must include (Peter Kohl and Noble
2009):
	

Identification of individual parts of the entity;

	

Detailed characteristics of mutually interacting
parts of the entity to be included among the system
elements (while parts interacting only with the
surroundings of the system will not be included);

	

Exploration and subsequent description of mutual
interactions among individual elements;

	

Exploration and subsequent description of
interactions with the surroundings of the system
(the system surroundings have direct or indirect
effects on the system elements, by influencing
mutual interactions among the system elements);

	

Combinations of reductionist and integration tools
and methods in exploration of any system entity on
various hierarchical levels.

A system as a set of elements and integration bonds
is thus defined on a real object. Based on more detailed
exploration of the system entity, an ever a more complex
system can be defined, which may be composed of a
number of mutually integrating subsystems. However,
this is not a purely mechanical process. When passing to
a more detailed level, a number of included functions and
bonds of the higher hierarchical level must be reduced,
and on the contrary, when passing to a higher level
a number of elements and bonds must be integrated
(Fig. 4). Every model is a simplified notion of
representation of reality on various hierarchical levels.

DOI
10.3384/ecp17132589

The approach of classical molecular biology goes
from below upwards. It starts from bottom elements
of the organisms  genes and proteins. Molecular biology
models provide formalized descriptions of interactions
of gene and protein cell structures that can be used to
understand their functions.
The approach of classical physiology is the opposite 
from above downwards, somewhat resembling reverse
engineering. First, the system is studied on higher levels
and subsequently, the process goes down in an effort to
find inverse solutions. The system behaviour is used to try
to derive the functions of its individual parts.
Integrative models start from the middle. They
combine both approaches  downward to the cellular and
molecular level and upward to integration and deriving of
functionalities of the human organism as a whole (P. Kohl
et al. 2010).
The circulatory system model of the Japanese authors
Shim et al. (Shim et al. 2006) can be given as an example
of connecting models of various hierarchical levels;
these authors combined a simple model of cardiovascular
haemodynamics of the vascular system with the model
of ventricles of the heart (Fig. 5), acting as a heart pump.
The ventricles were modelled, in a simplified manner,
as spherical elastic compartments with variable tension
of their wall. This tension was obtained from the model
of actomyosin cross-bridges of the myocyte (formation
of these bridges determines the strength of the stretched
Real world

Insight

System

System

Parts

Parts

Models: simplified representations of reality

R
E
D
U
C
E

BODY
ORGAN
TISSUE
CELL
ORGANELE
NETWORK
TRASCRIPT
GENE
MOLEKULE

I
N
T
E
G
R
TIME
FUNCTION A
T
STRUCTURE
E

Figure 4. Our understanding of the real world system
usually provides only a simplified representation of
reality. The gradual evolution of our understanding of the
real biological world is based on the use and analysis of
experimental and theoretical (mathematical) models on
all hierarchical levels. The result is reflected in ever more
detailed knowledge of the structure of functional relationships
and their changes in time, gradually integrated in higher
hierarchical levels. System biology provides a framework for
targeted interconnection of various aspects of applications of
models in biomedical research and development. Adapted
from (Peter Kohl and Noble 2009).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

591

Integrative physiology in Modelica

calcium movement
model of human
ventricular
myocyte

calcium
buffer

lumped parameter model
Integrative model of
the cardiovascular
system

ventricular
pressure

calcium
transient

cross-bridge
dynamics

cell tension
half sarcomere length

calcium binding to
troponin

model of
cardiovascular
dynamics
Ventricular
volume

Compiler and loader
for HumMod model

Source code of
HumMod

simplified
hemispheric cardiac
ventricle
Laplaces law

Figure 5. The integrative model of the cardiovascular system
as a combination of models on various hierarchical levels
according to (Shim et al. 2006).

muscle cell). Their formation is affected by calcium
crossing the cell membrane and the sarcoplasmic reticulum
membrane where calcium is cyclically released and
uptaken. In the sarcoplasmic bridge model, calcium binds
to troponin. This binding of calcium causes actomyosin
cross-bridges to form, resulting in subsequent tension of
the muscle cell. The model of actomyosin cross-bridges
was therefore connected to the model of calcium passing
between the cytoplasm and sarcoplasmic reticulum.
The cardiovascular haemodynamics model is based
on a considerable simplification of reality; it is designed
as an RLC model with lumped parameters. Ventricular
pressure is found at the input; it is generated by the
cardiac ventricular model depicted as a sphere with the
wall of variable rigidity. The tension value of the myocyte
muscle fibre, being the output of the actomyosin crossbridges (validated according to experimental results),
is the starting value for calculating the ventricular wall
rigidity. The actomyosin cross-bridge model depends
on the output of the myocyte calcium dynamics model
(validated according to experimental results). The
connection of models of different hierarchical levels
integrates important outputs of lower hierarchical level
models (for example, behaviour of the myocardium as a
whole is derived from the actomyosin cross-bridge model
of one cell). Although the models of every hierarchical
level represent considerable simplification of reality,
the model outputs indicate, for example, the effect of
calcium levels in the muscle cell cytoplasm on pressurevolume curves of the left ventricle, thus illustrating, e.g.,
the clinically verified effect of pharmaceuticals acting on
the potassium pump in myocytes.

2.3 Hummod
Today, the most extensive model of integrated
physiological systems of human physiology is apparently
the HumMod model created based on international
cooperation of a group of collaborators and disciples of
A. Guyton, at the Mississippi University Medical Center,
USA (R. L. Hester et al. 2011; R. Hester et al. 2011; Lerant
592

Figure 6. The HumMod simulator has been distributed with
a compiler, loader and the source code written in thousands
of XML files.

et al. 2015; W. A. Pruett, Clemmer, and Hester 2016).
The authors do not seek to keep its structure a secret;
the source text of the model (containing more than
5,000 variables) can be downloaded from the website
of the model, http://hummod.org. The source text was
written in the special markup language XML. The entire
mathematical model is offered as open source; users
can use the website to download and install on their
computer the source code as well as the compiler and run
the model on their own machine (Figs. 6 and 7). Users
can thus adapt and modify the model. The problem is that
the XML source texts of the entire model are written in
several thousands of files located in hundreds of folders,
and it is very difficult to orient oneself in the mathematical
relationships by studying more than a thousand of
mutually connected XML files.
In the development of models in the field of integrative
physiology, many research teams actually preferred to
use older models of complex physiological regulations 
for example, the old models of Guyton (A. C. Guyton,
Coleman, and Granger 1972; A. C. Guyton et al. 1986;
A. C. Guyton, Hall, and Montani 1988; J. P. Montani,
Mizelle, et al. 1989; J. P. Montani, Adair, et al. 1989; J.-P.
Montani and Van Vliet 2009) or the old model of Ikeda
(Ikeda et al. 1979). For example, this path was taken by
the international research team of the SAPHIR (System
Approach for Physiological Integration of Renal, cardiac
and respiratory control) project in 2008 after deciding that

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

clearer in a way so that a wider spectrum of users can
understand them.
Special viewers have been created for better
understanding of the HumMod model that enable the user
to go through individual relationships within the model
(Xu et al. 2011; Wu et al. 2013; Chen et al. 2013). In spite
of this., the equations of the model and their relationships
still remain difficult to understand for the user.

2.4 Our results  Modelica libraries and
PHYSIOMODEL
One of the ways to facilitate the understanding of
complex hierarchical models consists in using the new
object-oriented modelling language Modelica. Therefore
we have decided to reimplement the entire complex model
of the American authors in this language.
We were not frightened by the complex structure of the
HumMod model (called QHP in the previous version) and
established closer cooperation with the American authors.
Figure 7. The user can compile and run the HumMod model.
Using a widely branched menu, hundreds of variables can be
monitored during simulation experiments.

the open source mathematical model of integrative human
physiology containing over 3000 variables from Guytons
laboratory (R. L. Hester, Coleman, and Summers 2008)
at that time seemed very poorly readable and difficult
to understand to the project participants. Therefore two
legacy integrated models have served as a starting point
for integrative model development (Thomas et al. 2008),
namely the classic model of Guyton et al. (1972), which
focused on blood pressure regulation, and the model of
Ikeda et al. (1979), based on Guytons models but extended
to focus on the overall regulation of body fluid. The model
of Ikeda was recently reimplemented in the modern
simulation environment (Fontecave-Jallon and Thomas
2015). Similarly, in 2011 Mangourova et al. (Mangourova,
Ringwood, and Van Vliet 2011) implemented in Simulink
an older model of Guyton of 1992 written in C instead
of the then most recent (but difficult to understand for
them) version of the large integrative model - QHP
(Quantitative Human Physiology - the predecessor of the
HumMod model) from Guytons laboratory.
It is apparent that comprehensibility of descriptions
of complex integrative models is one of their limiting
factors for their acceptance by the scientic community.
If the creators are the only ones to understand their
models, their potential of factual communication with
other scientists is thus hindered. This also limits the
possibilities of designing integrative models within
a broader scientific community. This is an important
reason why the development of methodologies has been
gaining importance; such methodologies would make the
descriptions of structures of complex hierarchical models

DOI
10.3384/ecp17132589

Figure 8. An illustration of a part of the source text of our
HumMod implementation in Modelica. The source text
resembles hierarchical physiological schemes. The content
of the component of splanchnic circulation (from the upper
figure) shows blood flow through the gastrointestinal tract
component, the elastic compartment of the portal vein, and
flow through the liver.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

593

Integrative physiology in Modelica

We developed a special software tool called QHPView
(J. Kofrnek, Matejk, and Privitzer 2010) to create a
clear visualization of the used mathematical relationships
from the thousands of the source text files. This enabled
us to orient ourselves in the large model.
The model reimplementation in Modelica resulted in
a substantially better visualization of the model structure
(see Fig. 8) and among other things, it also helped
to discover some mistakes in the original American
implementation of HumMod. We modified and expanded
the model especially regarding the modelling of the
transfer of blood gases and homeostasis of the inner
environment, especially the acid-base balance (Jiri
Kofranek, Matejak, and Privitzer 2011; Jir Kofrnek et
al. 2013; Marek Matejk 2015; M. Matejk and Kofrnek
2015).
Our version of HumMod called PHYSIOMODEL has
been developed as an open source model. Source texts
of the model (i.e. the equations, values of all constants,
etc.) representing formalized expressions of physiological
relationships are available to the public at http://www.
physiomodel.org. The development of the integrative
model of human physiology has also resulted in designing
application libraries for the modelling of physiological
and chemical systems in Modelica called Physiolibrary
and Chemical (see http://www.physiolibrary.org)
(Marek Matejk et al. 2014; Marek Matejk 2014; Marek
Matejk et al. 2015; Matejak et al. 2015).
A more detailed description of the libraries and of
our implementation of the integrative model of human
physiology is the subject of a PhD thesis (Marek Matejk
2015).

3 Importance of integrative models
A relatively logical question emerges in a connection
with the relatively demanding activities of developing
integrated models  what can these models, created while
exerting such great efforts, be used for?

3.1 Understanding of the context
The main benefit of these models consists in
understanding how the human organism works as
a whole, being a hierarchical system with complex
regulations; how individual disturbances are manifested
representing the bases of various diseases; and how an
appropriate therapy is applied.
The reason why actually Guyton with his collaborators
created the model cited in the introduction can also be
given as an example (A. C. Guyton, Coleman, and
Granger 1972). It was for the study of regulatory disorders
resulting in high blood pressure, for the study of effects
that control the heart pump activity, and for exploration
of adaptive responses to a heart failure (A. C. Guyton,
Granger, and Coleman 1971; A. C. Guyton 1981). The
594

model has helped to understand the mechanisms of these
actions.
In the past, when the physiologists focused only on
the study of the dynamics of blood circulation, a simple
mechanistic notion existed saying that high blood
pressure was caused by an elevated peripheral resistance
of blood vessels. Clinical findings in hypertonic patients
corresponded to this notion  some of them actually
did have increased peripheral resistance. However, we
can ask why in some diseases associated with increased
peripheral resistance (for example, hypothyroidism or
in conditions after amputation of multiple limbs) the
blood pressure is normal? Also, blood pressure remains
unchanged in some diseases where peripheral resistance
is decreased  for example, hyperthyroidism, beriberi,
anaemia or arteriovenous shunts. It has shown, that
exploration of regulation in the circulatory system alone is
insufficient to explain these phenomena; we need to take
into account also the regulation of volume and osmolarity
of body fluids and the regulation of water and salts intake
and output. Namely arterial blood pressure depends,
among others, not only on peripheral vascular resistance
but also on the contents of the vascular bloodstream, i.e.
on the overall volume of circulating blood and also on
the cardiac output. Blood pressure rises together with the
volume of circulating blood. Kidneys promptly respond
to this situation, excrete the excessive volume, and the
blood pressure is adjusted. When the heart starts pumping
more blood in a time unit  i.e. when the output increases,
while peripheral resistance does not decrease at the same
time, blood pressure rises, as well. On the other hand,
the heart is a special pump that is controlled also by the
pressure at its output  heart output changes also when
pressure increases in large veins at the input of the atria
of the heart. When the heart output remains increased in
the long term, it gradually leads to a regulatory response
in the periphery where peripheral resistance rises in order
to reduce chronic hyperperfusion of internal organs.
As shown by the research of Guyton using simulation
models, the pathogenesis of the hypertension disease
consists in disorders of these regulatory mechanisms  the
kidneys are wrongly set to regulating a larger volume of
circulating blood; increased contents of the bloodstream
leads to an increase of the contents of large veins; this
causes an increase in the pressure in large veins; and the
increased pressure at the input of the atria of the heart
causes increased heart output responded to in the periphery
by increased peripheral resistance after some time (in
order to reduce the hyperperfusion of peripheral organs),
and thereby the increased blood pressure becomes fixed
(A. C. Guyton, Hall, and Montani 1988).
In his models, Guyton also showed the mechanism
of adaptive response to heart failure where, again,
mechanisms related to circulatory and volume regulation
are applied (J.-P. Montani and Van Vliet 2009). The

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

results of these simulation studies have found their way
to medical textbooks.
Guyton himself paid great attention to teaching of
physicians and wrote a generally recognized textbook
of physiology that provides a logical explanation of the
mechanism of physiological regulatory actions. Guyton
died in 2003 in a car accident, but his collaborators and
students continue his work  they not only elaborated the
original Guytons model creating the above mentioned
extensive model HumMod, but they also continue
publishing his textbook complementedwith new
knowledge  currently, the 13th edition of this textbook is
available (Arthur C. Guyton and Hall 2015).
The extended integrated model has also found
application in cosmic medicine. For example, the disciples
of Guyton succeeded in using the model to explain why
the adaptation to the gravitational force of the Earth after
returning from an orbit takes about 5 times longer in
female than male astronauts. Model simulations showed
the cause of this phenomenon. In females, the centre of
gravity is found lower than in males due to anatomical
differences. The extracellular space is dewatered in the
weightless condition and rewatered again after returning
to the atmosphere  in females, the volume of fluids
moved back from the blood to the interstitium is larger
than in males due to the shifted centre of gravity, resulting
in prolonged adaptation to the force of gravity  for details
see (Summers et al. 2010).
Simulation games with an integrated model can also
contribute to the guidelines for some procedures in acute
medicine. For example, HumMod showed why (and for
how long) it is important to preoxygenate the patient
with 100% inhalatory oxygen before intubation (during
anaesthesia) (this is a guideline for anaesthesia)  the
patient namely does not breathe for a certain period of
time during the intubation procedure. Furthermore, as
shown by the model, it is needless to apply preventive
hyperventilation after intubation and after connecting the
patient to artificial pulmonary ventilation (which used to
be the routine approach of some anaesthesiologists)  for
details see (Lerant et al. 2015).
One of the bodys most critical tasks is water
homeostasis. Physical challenges to the body, including
exercise and surgery, almost always coordinate with some
change in water handling reflecting the changing needs
of the body. The HumMod integrative mathematical
model of human physiology was also validated against
six different challenges to water homeostasis with special
attention to the secretion of vasopressin and maintenance
of electrolyte balance. HumMod successfully replicated
the experimental results, remaining within 1 standard
deviation of the experimental means in 138 of 161
measurements. Only three measurements lay outside of the
second standard deviation. This validation suggests that
DOI
10.3384/ecp17132589

HumMod can be used to understand water homeostasis
under a variety of conditions (W. A. Pruett, Clemmer, and
Hester 2016).
As shown by the examples above, the use of integrated
models can help to explain causal relationships of
a number of physiological actions.

3.2 Populations of virtual patients for clinical
studies
In order to explain the course of pathogenesis of
various diseases and responses of people to administered
therapy, it is important to ensure that the integrated
model represents more than a kind of an average person.
Sensitivity analysis can show how the changes in values
of individual parameters are manifested in the overall
behaviour of the model. For the purpose of studying
individual responses, the integrated model representing a
normal patient is used to create a population of models
representing the population of various patients by variation
of parameter values (approx. by +/- 10%). Precisely this
approach then makes its possible to observe individual
variability of behaviour of the model and compare the
same to individual variability of the population of real
patients.
Thus, for example, in the study of individual
responses to bleeding (Zhang, Pruett, and Hester 2015)
the population of 395 patients was first created using
this method. About 85% of the thus created population

Figure 9. A possible way of using integrative models for
interpretation of clinical study results. (1) A variation of
parameter values is used to create a population of virtual
patients. (2) Patients whose variable values exceed normal
ranges are excluded from the thus created population
of patients. (3) The remaining healthy heterogeneous
population of virtual patients is used to perform the clinical
experiment (simulated administration of pharmaceuticals).
(4) The virtual patients are sorted in groups with similar
responses to the virtual therapy. (5) For the given groups
of virtual patients, we try to find matching groups of real
patients with similar responses in the clinical study. Analysis
of behaviour of the simulation model during the simulated
therapy is used to seek explanations of individual differences
in responses to the administered therapy.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

595

Integrative physiology in Modelica

of virtual patients showed normal physiological values
 and only 15% showed abnormal values, which were
removed from the population. This is how a single
integrated model of the average patient was used to
create the population of models representing a set of
individual (virtual) patients. And this heterogeneous
population was then used for research aimed at revealing
the causes of individual deviations in patient responses
to a pathogenic noxa (bleeding in the given case) or to
administered therapy. Results of the study (behaviour
of virtual patients in haemorrhage) were then classified
using cluster analysis in order to sort patients with similar
behavioural patterns; these groups of virtual patients were
then compared to similar behavioural patterns in real
patients. Subsequently, qualitative analysis of the model
behaviour could be done in order to find the causes of the
individually different responses.
The analysis of sensitivity of parameters affecting the
blood pressure value was performed similarly, resulting
in the population of individual models with similar
behavioural patterns based on an older model of Guyton
(Moss et al. 2012).
It thus seems that the path leading to future application
of integrative models in clinical situations (especially in
clinical studies) consists in generating a population of
models representing the population of virtual patients,
subsequent modelling of the given pathology or effect
of medications using this heterogeneous population
of models, and sorting of the simulated virtual patients
to groups according to similar responses. Based on
comparison with a group of similarly responding patients
of the clinical study, analyses of the model behaviour
can reveal the causes of different responses in the patient
groups to the given pathogenic noxa or to the therapy (see
Fig. 9).
The pathology or the effect of the therapy in integrated
models is usually modelled by changing some parameters
that cause an appropriate (pathogenic or therapeutic)
response.
As follows from simulation studies, the cause of
differences of some individual responses need not be
based on a difference in only one parameter  but in
combined changes of several parameters.
Let us explain this problem using an illustrative
example (Fig. 10) (P. Kohl et al. 2010). For a clearer idea,
only the parametric state space of two parameters, P1
and P2 will be considered. The value of the hypothetic
biological function is the axis z differentiated by its height
and colour. We shall consider a patient whose biological
profile is located at the position A. The required action
(simulating the effect of the therapy or the effect of a side
effect of some other medication) consists in reducing
the parameter P1 to its target value. A direct change of
parameter P1 (the path from A to C) leads to a serious
596

Patology

C
A

D

A

Norm

P2
B

P1
P

alue
get v
1 -tar

Figure 10. The state space of parameters P1 and P2. The
vertical axis represents the size of the biological response
with the given values of parameters P1 and P2. The
purpose of a targeted intervention is to change the value
of parameter P1 to its target value. No biological response
is induced by a concurrent change of parameters P1 and
P2 (path from A to B). The change of parameter P2 to the
target value results in a biological effect (path from A to C).
Similarly, if only parameter P2 changes (while parameter P1
remains unchanged), a biological response is induced. This
illustrative example demonstrates that isolated changes of
individual parameters may result in a biological effect while
a covariant, concurrent change of two parameters may not
cause any effect at all.

biological (pathological) response. The covariance of
both parameters P1 and P2 (the path A  A  B) makes
it possible to move to the required level P1 without any
harmful consequences. An isolated reduction of the
parameter P2 in the same range as at the point B (without
changing P1) would also be harmful; as can be seen
intuitively, precisely the path of gradual modification
of both parameters (P1 and P2) from A to B causes no
biological response.
And vice versa  only a concurrent change of several
parameters causes an unfavourable biological effect,
while changes in individual parameters cause no adverse
biological effect  and frequently, this is also the core
of the robustness and ultrastability of physiological
regulations that can be revealed precisely and only using
integrative models.
Thus for example, variations of parameters of the
HumMod model were used to monitor the sensitivity
of blood pressure changes after a salt intake (W. Pruett,
Husband, and Hester 2014). It was shown that no single
parameter which would lead to an increased blood
pressure after an increased salt intake existed  this is the
core of high stability of physiological regulations. Only
the change of several parameters resulted in a pathological
response.
By comparing classified groups of virtual patients with
the same behaviour and groups of real patients in clinical
studies  and subsequent qualitative analysis of the courses
of the modelled actions, the cause of individual deviations

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

in response to an appropriate stimulus can be revealed 
no matter whether the stimulus is a pathological noxa or
the effect of a medication.
This is why integrated models will also find their
future application in clinical studies. The project of the
European Union called AVICENNA  A Strategy for
in silico Clinical Trials (see http://avicenna-isct.org),
currently under preparation, will focus on the topic of
using simulation models in clinical studies.

3.3 Medical simulators
Medical simulators represent another extensive field
for the application of integrative models; similarly as
flight simulators, medical simulators provide quite a new
mode of teaching where students can train diagnostic
and therapeutic tasks in virtual reality without any risk
for the patient. In sophisticated medical simulators,
students can also observe in detail the course of values
of various quantities that are commonly not available
for clinical examination in real patients, which supports
deeper understanding of the pathophysiological core of
the development of the clinical condition and its affection
by therapeutic interventions.
The important thing is that unlike the real world, mistakes
are reversible in virtual reality. When a flight simulator is
used to train landing we can crash many times in a row,
while in the real world an airplane crashes only once as
a rule. In acute care medicine, diagnostic and therapeutic
procedures can be trained on a virtual patient who can be
brought back to life at any time. However, patients in the
real life have no reset button and, as expressed by one
harsh proverb, the mistakes of rescuers are covered by
soil.
Similarly as a sophisticated airplane model is the core
of flight simulators, an integrative patient model is the
key component of current top medical simulators (for
example, in CAE Healthcare simulators  see http://www.
caehealthcare.com).

4 Development tools for integrative
models
Formerly, dynamic systems were often programmed using
analogue computers, while later they were combined with
a digital computer in the so-called hybrid computers. The
program was created by connecting individual computing
elements (integrators, summators ...) using connection
cables. The computer processed analogue (continuous)
electrical signals whose changes were responded to
immediately, and therefore it remained a suitable tool for
solving sets of differential equations of simulation models
until the increasing power of digital computers removed
this advantage of analogue solutions.

4.1 Classical programming languages for the

DOI
10.3384/ecp17132589

Figure 11. Mistakes in the Guytons graphic scheme and
their corrections.

development of simulation models
The era of analogue computers inspired also the
graphic notation of Guyton used to write physiological
models using a network of mutually connected computing
blocks (integrators, summators, dividers, multipliers and
function blocks). However, in 1972, at the time when
the groundbreaking paper of Guyton (A. C. Guyton,
Coleman, and Granger 1972) was published, models
were implemented predominantly on digital computers
using classical programming languages (e.g.Fortran,
C, C++ etc.). The graphic scheme in the paper served
only as an illustrative picture used to provide a compact
description of the model structure. The model itself was
programmed in the programming language Fortran for
digital computers.
However, this scheme was not flawless (Ji Kofranek
and Rusz 2010)  some errors were apparent at first
sight (for example, a wrongly connected integrator that
would soon result in its overloading with an infinitely
rising value due to the feedback), while others required
a deeper analysis, understanding of the text of the article
and knowledge of physiology (Fig. 11). Actually, these
were easily detectable graphic typing errors (switched
signs, shifted connectors) without any effect on the model
functionality because the entire scheme was created only
as an illustration and not as the source code of the model
(programmed in Fortran). The picture itself was a part
of the PhD thesis of a co-author of the Guytons article,
Thomas Coleman, and today, it can be find as a certain
scientific relic in a display case of the Guytons research
centre at the University of Mississippi.

4.2 Simulation chips in block-oriented languages
At the beginning of the 1990s, specialized modelling
tools emerged. These tools used computing blocks (very
similar to those used by Guyton in his graphic notation);
these blocks are connected on the computer screen using
the mouse to create a simulation network.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

597

Integrative physiology in Modelica

XHB

TBEox

<TBEOX>

<BEOX>

BEOX

ACID BASE METABOLIC BALANCE

A

yTA
yNH4

<YNH4>

yCO3

<YCO3>

yKHi

<YKHI>

yNHi

<YNHI>

yHin

<YHIN>

<PO2A>

AH

OUTPUTS:
XHB - Vector of coefficients derived from hemoglobin concentration
STBC - Standard bicarbonate concentration [mmol/l]
BE - Base Excess concentration in arterial blood
AH - Hydrogen ions concentration [nmol/l]
PHA - arterial plasma pH
SO2A - Oxygen hemoglobin saturation in arterial blood (expressed as ratio from 0 to 1)
XCO3 - Actual bicarbonate concentration in arterial blood
UCO2A - Content of CO2 in arterial blood [l STPD/l]
UO2A-Content of O2 in arterial blood [l STPD/l]
PO2A
PCO2A

PHA
SO2A
XCO3A

<CGL1>

UO2A

yINS

<YINS>

SO2A

CGL3

<CGL3>

UCO2A

yGLI

<YGLI>

UO2A

BEEC

YGLS

yKGLI

YKGLI

zGLE

ZGLE

xGLE

XGLE

21.8.2001

YINT 0

<YINT0>

Scope2

yGLU

ZGLE 0

<ZGLE0>

YGLU

Blood Glucose Control

BEOX 0

<BEOX0>

yGLS

OUTPUTS:
yINT - insulin secretion [unit/min]
yGLS - glucose flow rate from ECF into cells [mEq/min]
yKGLI - K flow rate from ECF to ICF accompanying secretion of insulin [mEq/min]
zGLE - ECF glucose content [mEq]
xGLE - ECF glucose concentration [mEq]
yGLU - renal excretion rate of glucose [mEq/min]

GFR

<GFR>
BEEC

INPUTS:
TYINT - time constant of insulin secretion
xGL0 - reference value of ECF glucose concentration
CGL1 - parameter of glucose metabolism
CGL2 - parameter of glucose metabolism
yINS - intake rate of insulin[unit/min]
CGL3 - parameter of glucose metabolism
yGLI - intake rate of glucose [g/min]
vEC - ECF volume [l]
GFR - glomerular filtration rate [l/min]

BLOOD GLUCOSE
CONTROL

vEC

<VEC>

ZBEEC 0

<ZBEEC0>

CGL2

<CGL2>
PHA

YINT

BLOOD GLUCOSE CONTROL

CGL1

AH

MRH

<MRH>

yINT
xGL0

<XGL0>

XCO3

UCO2A

variables. Simulation chips in block-oriented languages
have a hierarchical structure  they may contain a network
of mutually connected subsystem blocks of a lower
hierarchical level. Simulation chips can be grouped
in libraries and their individual instances can be created
using the mouse; their inputs and outputs are connected
using connecting lines, through which information (i.e.
the values of variables) flows. The entire complex
model can be thus depicted as interconnected simulation
blocks, while the structure of their connection provides
clear information about what values are calculated and
how.

TYINT

<TYINT>

BE

Blood Acid Base Balance

OUTPUTS:
BEox - (** Base excess in fully oxygenated blood [mEq/l]*)
BEEC - (*ECF Base excess concentration

yCO3in

<YCO3IN>

<PCO2A>

A

STBC

BE

BLOOD ACID
BASE BALANCE

HB

<HB>

BEOX

ACID BASE
METABOLIC
BALANCE

VEC

<YTA>

BEox

INPUTS:
TBEOX - (*Time constant*)
VB (*Blood Volume [l]*)
HB (fore XHB) (*Blood hemoglobin concentration [g/100 ml]*)
A [11] - (* vector of coeficients, see "Blood Acid Base Balance" *)
pCO2A - (*CO2 tension in arterial blood [Torr]*)
VEC (*Extracelular fluid volume [l]*)
yTA (*Renal excretion rate of titratable acid [mEq/min]*)
yNH4 - (*Renal excretion rate of ammonium [mEq/min]*)
yCO3 - (*Renal excretion rate of bicarbonate [mEq/min]*)
yKHi - (*Potassium ions flow rate from ECF into ICF
exchanged with hydrogen ions [mEq/min]*)
yNHi - (*Hydrogen ions flow rate from ECF into ICF
exchanged with sodium ions [mEq/min]*)

pCO2A

<PCO2A>
<VEC>

U(E)
U
Selector

STBC

INPUTS:
BEOX - Base Excess in fully oxygenated blood [mmol/l]
HB - Hemoglobin concentration [g/dl]
PCO2A - CO2 tension in arterial blood [torr]
PO2A - Oxygen tension in arterial blood [torr]

HB

<A>

XHB

BLOOD ACID BASE BALANCE

VB

<VB>
<HB>

Scope

Acid Base Metabolic Balance1
Acid base metabolic balance

Scope1

Blood acid base balance

Scope3

Blood glucose control

qIN

<QIN>

HB

qVIN

<QVIN>

HB

<VEC>

vEC

zCaE

ZCAE

VB

<VB>

QCO

QCO

qIWL

<QIWL>

INPUTS:
qIN - drinking rate [l/min]
qVIN - intravenous water input [l/min]
qIWL - insensible water loss [l/min]
qMWP - metabolic water production [l/min]
qWU - urine output [l/min]
qLF - lymph flow rate [l/min]
CFC - capillary filtration coefficient [l/min/torr]
pICO - interstitial colloid osmotic pressure [torr]
pPCO - plasma colloid osmotic pressure [torr]
pC - capillary pressure [torr]
pIF - interstitial pressure [torr]
CSM - transfer coeff. of water from ECF to ICF
xNE - ECF Na concentration [mEq/l]
xKE - ECF K concentration [mEq/l]
xGLE - ECF glucose conc. [mEq/l]
zKI - ICF K content [mEq]
vRBC - volume of red blood cells [l]
xHBER - hemoglobin concentration in the red blood cells [g/100 ml]

qLF
CFC

<CFC>

pICO

<PICO>

pPCO

<PPCO>

pC

<PC>

pIF

<PIF>

CSM

<CSM>

xNE

<XNE>

xKE

<XKE>

zKI

<ZKI>

vRBC

<VRBC>

xHBER

<XHBER>

<GFR>

VB

<YMGI>

vP

yCaI

vEC

INITIAL CONDITIONS:
zCaE0 - ECF calcium content [mEq]
zMgE0 - ECF magnesium content [mEq]

zCaE0

yCa

zMgE0

VIF

CARDIOVASCULAR BLOCK

KL

OUTPUTS:
QCO - Cardiac output [l/min]
PAP - Pulmonary arterial pressure [torr]
PAS - Systemic arterial pressure [torr]
pC - Capillary pressure [Torr]
PVS - Central venous pressure [torr]
PVP - Pulmonary venous pressure [torr]

ZMGE
KR

XMGE
DEN

<DEN>

yMg

YMG

PAP

INPUTS:
VB - Blood volume [l]
RTOT - Total resistance in systemic circulation [Torr * Min / l] (norm.=20)
RTOP - Total resistance in pulmonary circulation [Torr * Min /l] (norm. =3)
KL - Parameter of the left heart performance [l/min/torr] (norm.=0.2)
KR - Parameter of the right heart performance [l/min/torr] (norm.=0.3)
DEN - Proportional constant between QCO AND VB [1/min] (norm.=1)
KRAN - Parameter of capillary pressure (norm.=5.93)

RTOP

<RTOP>
YCA

<KR>

xMgE

CARDIOVASCULAR BLOCK

RTOT

<RTOT>

XCAE

<KL>

zMgE

30.7.2001

<ZMGE0>
vIF

OUTPUTS:
zCaE - ECF calcium content [mEq]
xCaE - ECF calcium contentration [mEq/l]
yCa - calcium renal excretion rate [mEq/min]
zMgE - ECF magnesium content [mEq]
xMgE - ECF magnesium contentration [mEq/l]
yMg - magnesium renal excretion rate [mEq/min]

yMgI

VEC

vTW

xCaE

INPUTS:
vEC - ECF volume [l]
yCaI - calcium intake [mEq/min]
yMgI -magnesium intake [mEq/min]
GFR - glomerular filtration rate [l/min]

CALCIUM AND
MAGNESIUM
BALANCE

GFR

VP

<ZCAE0>

24.8.2001

VIN 0

<VIN0>

<YCAI>

HT

vB

OUTPUTS:
HB - blood hemoglobin concentration [g/100 ml]
HT - hematocrit
vB - blood volume [l]
vP -plasma volume [l]
vEC - ECF volume [l]
vIF - interstitial fluid volume [l]
vTW - total body fluid volume [l]
vIC - ICF volume [l]

xGLE

<XGLE>

HT

BODY FLUID
VOLUME
BALANCE

qWU

<QLF>

CALCIUM AND MAGNESIUM BALANCE

BODY FLUID VOLUME BALANCE

qMWP

<QMWP>
<QWU>

pC

PVS

24.8.2001 edited by Tom Kripner

KRAN

<KRAN>

PAS

PVP

Calcium and Magnesium Balance

PAP

PAS

PC

PVS

PVP

Cardiovascular Block

VTW

VP 0

<VP0>

VIF 0

<VIF0>

Scope5

vIC

Scope4

VIC

VIC 0

<VIC0>

Body Fluid Volume Balance

Scope6

Body fluid volume balance
Calcium and magnesium balance

Cardiovascular block

vEC

<VEC>

DIURESIS AND URINE OSMOLARITY
zCLE

CHLORIDE BALANCE
yNU

<YNU>

yKU

<YKU>

yNH4

<YNH4>

yCa

<YCA>

yMg

<YMG>

INPUTS:
vEC - ECF volume [l]
yCLI - chloride intake [mEq/min]
yNU - Na renal excretion rate [mEq/min]
yKU - K renal excretion rate [mEq/min]
yNH4 - ammonium renal excretion rate [mEq/min]
yCa - calcium renal excretion rate [mEq/min]
yMg - magnesium renal excretion rate [mEq/min]
ySO4 - sulphate renal excretion rate [mEq/min]
yCO3 - bicarbonate excretion rate [mEq/min]
STPG - summary renal excretion rate of phosphates and org. acids
related to arterial pH [mEq/min]

yGLU

yURU

<YURU>

yCLU

STPG

Scope7

QWU

<ALD>

<CPR>
<THDF>
<YNIN>
<PHA>
<CBFI>
<CHEI>
<YKGLI>
<ZKI0>
<CKEI>
<YKIN>
<VEC>
<ZNE0>
<ZKE0>
<ZHI0>

PIF

QLF

16.8.2001

QLF0

PIF

This facilitates interdisciplinary cooperation in the
development of integrative models where experimental
physiologists do not have to explore in detail what
mathematical relationships are hidden inside the
connected subsystem blocks, and from the connections
among individual subsystem blocks the physiologists
can understand the model structure and verify the model
behaviour in an appropriate simulation visualization
environment of the block-oriented simulation language.

QLF

Interstitial Pressure and Lymph Flow Rate

OSMU

OSMU

Scope8

yTA1

yNU

SODIUM AND POTASSIUM BALANCE

yNH4
yCO3
ALD
GFR
CPR
THDF
yNIN
PHA
CBFI

INPUTS:
yTA1 - Arterial pH dependent portion of titrable acid excretion rate
yNH4 - ammonium renal excretion rate [mEq/min]
yCO3R - bicarbonate reabsorption rate [mEq/min]
ALD - aldostrone effect [x normal]
GFR - glomerular filtration rate [l/min]
CPR - excretion ratio of filterd load after proximal tubule
THDF - effect of 3rd factor (natriuretic horm.) [x normal]
yNIN - sodium intake [mEq/min]
PHA - Arterial blood pH
CBFI - Parameter of intracellular buffer capacity
CHEI - Transfer coeff. of H ions from ECF to ICF
yKGLI - K flow rate from ECF to ICF accompanying secretion of insulin [mEq/min]
zKI0 - normal ICF K content [mEq]
CKEI - Transfer coeff. of K ions from ECF into ICF (exchanged with H ions)
yKIN - K intake [mEq/min]
vEC - ECF volume [l]

CHEI
yKGLI
zKI0
CKEI
yKIN
vEC
ZNE 0

yNH

SODIUM AND
POTASSIUM
BALANCE

xNE

YNU

VTW

<VTW>

YND

QCO
PBA

<PBA>

fCO2i

zNE

yNHI

yKHI

ZNE

VAL

<VAL>

fO2i

<FO2I>
<UCO2V0>

YKHI

yKU

yKD

ZKI

<FO2A0>

UCO2V 0
UO2V 0

PLASMA OSMOLARITY

OUTPUTS:
uCO2V - (** Content of CO2 in venous blood [l STPD/l]*)
uO2V - (** Content of O2 in venous blood [l STPD / l*)
pCO2A - (*CO2 tension alveoli [Torr]*)
fCO2A - (*Volume fraction of CO2 in dry alveoli gas*)
pO2A - (*O2 tension in alveoli [Torr]*)
fO2A - (*Volume fraction of O2 in dry alveoli gas*)

UO2V

PLASMA
OSMOLARITY

xURE

xGLE

<XGLE>

xNE

<XNE>

PCO2A

pO2A

INPUTS :
XMNE - ECF mannitol concentration [mmol/l]
XURE - ECF urea concentration [mmol/l
XGLE - ECF glucose concentration [mmol/l]
XNE - ECF sodium concentration [mmol/l]
XKE - ECF potassium concentration [mmol/l]

OSMP

OSMP

OUTPUT :
OSMP - plasma osmolarity

xKE

<XKE>

Plasma osmolarity calculation

FCO2A

PO2A

8.10.2001

<FCO2A0>

ZKE

uO2V

pCO2A

fCO2A

VA

<VA>
YNHI

<UO2V0>
zKI

zKE

xMNE

<XMNE>

UCO2V

<XURE>

O2 AND CO2
EXCHANGE

uO2A

<QCO>

XNE

INPUTS:
mrCO2 - (*Metabolic production rate of CO2 [l STPD/min]*)
uCO2A - (*Content of CO2 in arterial blood [l STPD/l]*)
VTW (*Total body fluid volume [l]*)
mrO2 - (*Metabolic consumption rate of O2 [l STPD/min]*)
uO2A - (*Content of CO2 in arterial blood [l STPD/l]*)
QCO - (*Cardiac output [l/min]*)
PBA - (*Barometric pressure*)
fCO2i - (*Volume fraction of CO2 in dry inspired gas*)
VAL - (*Total alveolar volume (BTPS)*)
VA (*Alveolar ventilation [l BTPS/min]*)
fO2i - (*Volume fraction of O2 in dry inspired gas*)

mrO2

<MRO2>

YNH

uCO2V

O2 and CO2 EXCHANGE

<FCO2I>

OUTPUTS:
yNU - Na renal excretion rate [mEq/min]
yNH - Na excretion in Henle loop [mEq/min]
yND - Na excretion rate in distal tubule [mEq/min]
xNE - ECF Na concentration [mEq/l]
zNE - ECF Na content[mEq]
yNHI - H ions flow rate from ECF to ICF (exchanged w. Na) [mEq/min]
yKHI - K flow rate from ECF to ICF (exchanged w. H) [mEq/min]
zKI - ICF K content [mEq]
zKE - ECF K content [mEq]
yKU - K renal excretion rate [mEq/min]
yKD - K excretion rate in distal tubule [mEq/min]
xKE - ECF K concentration [mEq/l]

ZKE 0

uCO2A

<UCO2A>

<UO2A>
yND

Scope9

Interstitial pressure and lymph flow rate

mrCO2

<MRCO2>

<GFR>

INTERSTITIAL PRESSURE
AND
LYMPH FLOW RATE

INPUTS:
vIF0 - normal interstitial fluid volume [l]
vIF - interstitial fluid volume [l]
qLF - normal lymph flow rate [l/min]

Diuresis and Urine Osmolarity

Diuresis and urine osmolarity

<YCO3>

VIF

OUTPUTS:
pIF - interstitial pressure [torr]
qLF - lymph flow rate [l/min]

Chloride Balance

<YTA1>

VIF0

<VIF>

ZCLE 0

<ZCLE0>

<YNH4>

<VIF0>

yKU

<YKU>
YCLU

QWD

<QLF0>

17.8.2001

yNU

<YNU>

qWU

OUTPUTS:
qWD - rate of urinary excretion in distal tubule [l/min]
qWU - urine output [l/min]
OSMU - urine osmolality [mOsm/l]

yMNU

<YMNU>

30.7.2001

<STPG>

XCLE

DIURESIS
AND URINE
BALANCE

yKD

<YGLU>
xCLE

qWD

INPUTS:
ADH - effect of antidiuretic hormone [x normal]
OSMP - plasma osmolality [mOsm/l]
yND - sodium excretion rate in distal tubule [mEq/min]
yKD - potassium excretion rate in distal tubule [mEq/min]
yGLU - renal excretion rate of glucose [mEq/min]
yURU - renal excretion rate of urea [mEq/min]
yMNU - renal excretion rate of mannitol [mEq/min]
yNU - sodium renal excretion rate [mEq/min]
yKU - potassium renal excretion rate [mEq/min]

yND

<YKD>

OUTPUTS:
zCLE - ECF chloride content [mEq]
xCLE - ECF chloride concentration [mEq/l]
yCLU - chloride renal excretion rate [mEq/min]

yCO3

<YCO3>

OSMP

<OSMP>

ZCLE

<YND>

CHLORIDE
BALANCE

ySO4

<YSO4>

INTERSTITIAL
PRESSURE AND
LYMPH FLOW
RATE

ADH

<ADH>
yCLI

<YCLI>

FCO2A 0

fO2A

FO2A

FO2A 0

O2 and CO2 Exchange

YKU

YKD

27.7.2001
xKE

ZHI 0

XKE

Scope12
Na & K Balance
Scope11

Sodium and potassium balance

Scope10
O2 and CO2 exchange
Plasma osmolarity

<VEC>

<YPO4I>

<YSO4I>

<YORGI>

<GFR>

<ZPO4E0>

<ZSO4E0>

<ZORGE0>

vEC

yPO4I

ySO4I

yORGI

GFR

ZPO4E 0

ZSO4E 0

ZORGE 0

PHOSPHATE
AND
ORGANIC
ACIDS
BALANCE

PHOSPHATE, SULPHATE AND ORGANIC ACIDS BALANCE
INPUTS:
vEC - ECF volume [l]
yPO4I - phosphate intake [mEq/min]
ySO4I - sulphate intake [mEq/min]
yORGI - organic acids intake [mEq/min]
GFR - Glomerular filtration rate [l/min]

OUTPUTS:
zPO4E - ECF phosphate content [mEq]
xPO4 - ECF phosphate contentration [mEq/l]
yPO4 - Phosphate renal excretion rate [mEq/min]
zSO4E - ECF sulphate content [mEq]
xSO4 - ECF sulphate contentration [mEq/l]
ySO4 - sulphate renal excretion rate [mEq/min]
zORGE - ECF organic acids content [mEq]
xORGE - ECF organic acids contentration [mEq/l]
yORG - organic acids renal excretion rate [mEq/min]
30.7.2001

zPO4E

ZPO4E

<VIF>

pICO

vIF

<TPHA1>

PICO

PROTEIN BALANCE
xPO4

XPO4

yPO4

<QLF>
<PC>

YPO4

<YPLIN>
zSO4E

ZSO4E

xSO4

<VP>

XSO4

ySO4

<ZPG0>
<ZPIF0>

YSO4

<ZPP0>
zORGE

ZORGE

xORGE

<ZPLG0>

<PHA>

qLF
pC
YPLIN
vP
ZPG 0
ZPIF 0

INPUTS:
vIF interstitial fluid volume [l]
qLF - lymph flow rate [l/min]
pC - capillary pressure [torr]
YPLIN - rate of intravenous plasma protein input [g/min]
vP -plasma volume [l]

PROTEIN
BALANCE

OUTPUTS:
pICO - interstitial colloid osmotic pressure [torr]
xPIF - interstitial protein concentration [g/l]
zPIF - interstitial protein content[g]
zPP - plasma protein content [g]
xPP - plasma protein concentration [g/l]
pPCO - plasma colloid osmotic pressure [torr]

xPIF

XPIF

<YORG>
<YPO4>

zPIF

zPP

ZPIF

<YTA0>
<ALD>

ZPP

<TPHU2>
xPP

ZPP 0

XPP

<TPHU1>

10.7.2001

<YNH40>

ZPLG 0

pPCO

PPCO

<QWU>

Protein Balance

XORGE

<PCO2A>
yORG

YORG

<GFR>

Phosphate, Sulphate and Organic Acids Balance

ano XCO3

<XCO3>
<PHA0>
<PHU20>

Phosphate sulphate and organic acids balance
Protein balance

<VEC>

<VA0>

vEC

CONTROLLER OF RENAL FUNCTION

<PAS>

<XKE>

<YNH>

<PVP>

<OSMP>

INPUTS:
vEC - ECF volume [l]
pAS - systemic arterial pressure [torr]
xKE - ECF K concentration [mEq/l]
yNH - Na excretion in Henle loop [mEq/min]
pVP - pulmonary venous pressure [torr]
OSMP - plasma osmolality [mOsm/l]
pPCO - plasma colloid osmotic pressure [torr]

GFR

xKE

yNH

pVP

OSMP

ALD

<PCO2A>

ALD

HIDDEN CONSTANTS:
vEC0 - normal ECF volume [l]
GFR0 - normal glomerular filtration rate [l/min]
___

ADH

<PHA>

VA0

pO2A

pCO2A

pHA

RESPIRATION CONTROL

<PHU10>

INPUTS:
VA0 - normal value of alveolar ventilation [l BTPS/min]
pO2A - O2 partial pressure in alveoli [Torr]
pCO2A - CO2 partial pressure in alveoli Torr]
pHA - arterial blood pH
AH - concentration of hydrogen ions in arterial blood [nM/l]

VA

yORG

yTA0
ALD

<AH>

<YURI>

<GFR>

AH

RENAL ACID
BASE CONTROL

TPHU2
TPHU1
yNH40

yTA1

PHU

qWU
OUTPUT VARIABLES:
S TPG - summary renal excretion rate of titratable acids, phosphate and org. acids [mmol/mi
yNH4
yTA - renal excretion rate of titratable acids [mmol/min]
pCO2A
yTA1 - on arterial pH dependent portion of titratable acid secretion rate [mmol/min]
PHU - urine pH
GFR
YNH4 - Ammonium renal excretion rate [mmol/min]
YCO3 - Bicarbonate excretion rate [mmol/min]
YCO3R - Bicarbonate reabsorption rate [mmol/min]
xCO3
yCO3

PHA 0

24.7.2001

YTA

YTA1

PHU

YNH4

YCO3

PHU2 0
yCO3R
PHU1 0

vTW

yURI

GFR

<YMNI>

yMNI

Respiration Control
<VEC>

ADH

yTA

INPUTS:
TPHA1 - Time constant of titratable acid [1/min]
PHA - arterial pH
yORG - Renal excretion rate of organic acid [mEq/min]
yPO4 - Renal excretion rate of phosphate [mEq/min]
yTA0 - Normal value of renal excretion rate of titratable acid [mmol/min]
ALD - Aldosterone effect [x normal]
TPHU1 - Time constant of ammonium secretion [1/min]
TPHU2 - Time constant of titratable acids secretion [1/min]
yNH40 - Normal value of ammonium renal excretion rate [mmol/min]
qWU - Urine output [l/min]
pCO2A - Alveolar pCO2 [torr]
GFR - Glomerular filtration rate [l/min]
xCO3 - Actual bicarbonate concentration [mmol/l]

VA

OUTPUTS:
VA - alveolar ventilation [l BTPS/min]

STPG

RENAL ACID BASE CONTROL

yPO4

Scope15

YCO3R

Renal Acid Base Control

<VTW>

RESPIRATION
CONTROL

STPG
PHA

4.10.2001

OUTPUTS:
GFR - glomerular filtration rate [l/min]
ALD - aldosterone effect [x normal]
ADH - effect of antidiuretic hormone [x normal]
THDF - effect of 3rd factor (natriuretic horm.) [x normal]

vEC

zUR

ZUR

UREA AND MANNITOL BALANCE

UREA AND
MANITOL
BALANCE
INPUTS:
vTW - total body fluid volume [l]
yURI - intake rate of urea [mEq/min]
GFR - glomerular filtration rate [l/min]
yMNI - intake rate of mannitol [mEq/min]
vEC - ECF volume [l]

OUTPUTS:
zUR - total body-fluid urea content [mEq]
xURE - ECF urea concentration [mEq/l]
yURU - renal excretion rate of urea [mEq/min]
zMNE - ECF mannitol content [mEq]
xMNE - ECF mannitol concentration [mEq]
yMNU - renal excretion rate of mannitol [mEq/min]
21.8.2001

<ZUR0>

ZUR 0

xURE

yURU

XURE

YURU
Urea and mannitol balance

zMNE

xMNE

ZMNE

XMNE

17.8.2001
THDF

<PPCO>

GFR
<PO2A>

CONTROLLER
OF RENAL
FUNCTION

pAS

Scope14

Scope13

Block-oriented simulation languages provided
a considerable simplification of implementation of
simulation models. The most widely used block-oriented
languages include, for example, Mathworks Simulink
(http://www.mathworks.com/products/simulink)
or
Visual Solution VisSim (http://www.vissim.com).

TPHA1

pPCO

THDF

<ZMNE0>

ZMNE 0

yMNU

YMNU

Urea and Mannitol Balance
Controller of Renal Function

Scope16

Scope17
Scope18
Renal acid base control

Controller of renal function

Respiration control

Chloride balance

1
Inputs

INPUTS

1
Outputs

Figure 12. Structure of the connected blocks that implement
the model for the Golem simulator in the block-oriented
language Simulink. The inputs and outputs of 18 blocks
modelling individual physiological subsystems are connected
through a common bus.

These so-called block-oriented simulation languages
utilize connected blocks. Signals flow through the
connecting lines between individual blocks and transfer
the values of individual variables from the output of
one block to the inputs of other blocks. The inputted
information is processed in the blocks to obtain the output
information. The connections among individual blocks
show how the values of individual variables are calculated
 i.e. the algorithm of the computation.
Blocks can be grouped in individual subsystems that
communicate with their surroundings through input and
output pins, thus representing certain simulation chips.
These subsystem blocks hide the simulation network
structure from the user, similarly as electronic chips hide
the connection structure of individual transistors and
other electronic elements so that the user need not take
care of the internal structure and of the computational
algorithm used to obtain output variables from input
598

In the past, we used Simulink to create a freely available
library of blocks for the modelling of physiological
systems (http://www.physiome.cz/simchips), which
also included the source code of an integrated model of
physiological systems used as a source for our teaching
simulator Golem (Fig. 12). The teaching simulator Golem
was developed by us at the end of the 1990s and at the
turn of the millennium it was intended for teaching
the homeostasis of the inner environment in clinical
physiology. The simulator was used at some national as
well as foreign faculties of medicine (Ji Kofrnek et al.
2001).

4.3 Disadvantages of block-oriented simulation
languages
Blocks in block-oriented languages have a hierarchical
structure. On the lowest level, the blocks are created as a
network of interconnected numeric blocks that use input
values to calculate output values. The connections among
the numeric blocks represent a solution of mathematical
equations of the model designed so that output values are
calculated from input values.
However, the connection of blocks in the network of
relationships cannot be arbitrary. No algebraic loops may
occur in the connected elements  i.e. cyclic structures
where an input value brought to the input of a computing
block depends in the same time step (through several

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

intermediators) on the output value of the same block.
Development environments of block-oriented
languages provide tools to avoid algebraic loops; however,
their use often results in transformations that make the
model structure less clear.
The main problem of block-oriented languages is
that the simulation network composed of hierarchically
connected blocks shows a graphic representation of a
chain of transformations of input values to output values,
meaning that when the model is designed, an exact
computational algorithm must be defined from input to
output values of the model.
The requirement of a fixed direction of connections
from inputs to outputs means that the connections of the
blocks reflect the computation procedure and not the
very structure of the modelled reality.
For example, when the direction of the computation is
reversed (by replacing inputs with outputs), the algorithm
will be different although the model equations remain the
same. Thus for example, in the model of an electrical RLC
circuit (or its hydraulic analogy) it will make a difference
if the voltage (pressure in the hydraulic domain) or
(electrical or hydraulic) current is used as the input for the
circuit although the electrical (hydraulic) scheme itself
does not change. The Simulink network representing the
computational process will be different.
In complex models, it is usually not simple to derive
the computation causality (i.e. to derive the algorithm of
computing output variables from input variables).

4.4 Modelica  the best tool for development
models of integrative physiology

of modelling tools emerged, which makes it possible
to leave the computation aside and describe directly
equations in the modelling blocks. A special objectoriented equation-based language called Modelica was
developed.
Modelica, originally developed as an academic project
in cooperation with small development companies
associated with Lund and Linkping universities, soon
showed to be a very efficient tool for the modelling of
complex models applied particularly in mechanical
engineering, in the automobile and airline industries.
The development of Modelica therefore gradually gained
support of the commercial sector.
The speed at which the new simulation language
Modelica spread in various industries and at which it
was embraced by various commercial development
environments is astonishing. Today, several commercial
and non-commercial development tools exist that use this
language (see https://www.modelica.org).
In Modelica, the connection of individual components
results in the connection of sets of equations with each
other. The component connections thus define the
modelled reality instead of the computation process.
The way of resolving the equations is thus left up to the
machines.
Unlike block-oriented languages where the structure
of connections among hierarchical blocks represents
rather the computation process instead of the modelled
reality, the structure of models in Modelica shows the
structure of the modelled reality (see fig. 13 and 14). This
is why even complex models are sufficiently transparent
and comprehensible in Modelica (Kulhnek, Kofrnek,

At the turn of the millennium, a completely new category

Figure 13. Circulatory dymamics - more detailed central
structures of the Simulink implementation of Guytons
model, representing flows through aggregated parts of the
circulatory system and the activity of the heart as a pump..
DOI
10.3384/ecp17132589

Figure 14. The same model structure as is shown in figure
13 implemented in Modelica. The structure of the model
in Simulink corresponds to the structure of computational
steps, while the Structure of Modelica model reflects the
structure of the modeled physiological reality.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

599

Integrative physiology in Modelica

and Matejk 2014).
This is very important precisely for the development
of complex integrated models. The task of unifying and
designing complex models faces another problem due to
the complicatedness. Usually, only the authors are able to
understand and use complex models. Modelica partially
resolves this problem thanks to its characteristics and a
complex model of human physiology designed in Modelica
may lead to a wider use of the model in the scientific
community. The source text of our integrated model of
human physiology PHYSIOMODEL in Modelica (see
http://www.physiomodel.org) resembles hierarchical
physiological schemes (see Fig. 8). PHYSIOMODEL is
an implementation of HumMod (modified and expanded,
particularly in the field of acid-base balance and the
transfer of blood gases) (Jiri Kofranek, Matejak, and
Privitzer 2011; Jir Kofrnek et al. 2013; Marek Matejk
2015; M. Matejk and Kofrnek 2015).

5 Prospects of integrative models of
human physiology
5.1 Prospects of sharing and publishing
integrative models
The development of integrative models in physiology
exhibits an exclusively interdisciplinary nature. The
team needs to have broad knowledge of physiology as
well as knowledge of computer sciences, mathematics,
the theory of control, and cybernetics. In addition, the
team members of various professions must dispose of a
considerable intersection of their knowledge.
This is also why there are not many scientific teams that
develop large integrative models in physiology.
The developed integrative models should be
comprehensible not only within the development team,
but also externally  if a model is comprehensible only to
its authors, it will hardly receive the necessary feedback
and new impulses from specialized scientific community.
The issue of a suitable form of publishing the achieved
results is also related to this issue. Reproducibility is
the main attribute of any scientific result. Leaving aside
certain acts of deception not discovered by reviewers,
the principle of reproducibility is a key for the gradual
discovery of the secrets of nature. This principle is often
violated in the field of scientific publications related to
biomedical models (both small and large). It is not always
the fault of the authors  many times the reason is that a
sign or an index is omitted in equations while the paper
is prepared for printing, which causes a lot of problems
to readers who seek not only to understand, but also to
implement the described model.
In addition, in many cases biomedical models are as
complex that the limited space for the article is sufficient
only for fundamental equations of the model (and often
600

not even all of them), while no space remains for more
detailed information (initial values of state variables,
values of all parameters, etc.), necessary to set up the
model at a different department. Therefore the classical
form of publications of models in journals is insufficient.
A specialized article that describes a model should
include, as a minimum, a digital (available through the
Internet) appendix giving a detailed description of the
model structure including the values of all parameters
(preferably in the form designed in some modelling
language), sufficient for the reader to be able to reproduce
the model (and perhaps follow up in his or her own work).
This solution has already been approached by a number
of journals that publish specialized articles on computer
models.
If the model is published in a modelling language that
requires a commercial licence (for example, in MathWorks
Matlab&Simulink), a problem arises because the reader
needs to have an appropriate licence to be able to run the
given model in the licensed development environment.
Considerable efforts were thus developed in the
international project PHYSIOME to create databases 
repositories of models that, besides storing the source
text of the model in the defined format, offer publicly
available tools for their simulation. Given that Modelica is
a standardized language  and not a corporate proprietary
product (such as MathWorks Matlab&Simulink) and
given that open source development tools exist today for
this language (for example, OpenModelica  see https://
openmodelica.org)  Modelica seems to be a highly
promising tool for publishing and sharing biomedical
models.
So far, no other open source alternative besides
Modelica exists that could be used for publishing
extensive models. For example, Guytons model version
of 1992, implemented by Montani in C using the
C-MODSIM environment (J. P. Montani, Adair, et al.
1989), is divided in the cellML repository in 22 modules
in the open source cellML language. However, attempts
at running these modules connected in one unit were not
successful (https://models.cellml.org/exposure), while the
Simulink version of the model works without problems
(Mangourova, Ringwood, and Van Vliet 2011) (however,
it requires the commercial environment of Matlab@
Simulink).
For the sake of completeness, we should note
that theoretically, also the environment used to
publish HumMod is an open source environment for
implementation of large models  the source code of the
model is saved in a number of XML files. This is sufficient
for simple models; however, complex models are difficult
to be understood by users  the reader can compare for
themselves the HumMod model structure in the original
form (http://hummod.org) and its implementation in

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems

Modelica (http://www.physiomodel.org).
Modelica thus seems to be a promising publication
tool for extensive integrated models.

5.2 Prospects of commercial application of
integrative models
The potential of commercial application especially in
the two areas below will provide a powerful stimulus
for further development of integrative models of human
physiology:
	

in medical teaching simulators;

	
in the development of new therapeutic methods
and in clinical testing of new pharmaceuticals.
Medical simulators provide a very efficient teaching
aid. They enable the students to train basic examination
and therapeutic techniques and also the process of
decision-making in medicine. Sophisticated medical
simulators utilize a robotized patient mannequin as the
user interface. A model of interconnected physiological
systems of the body is the core of modern medical
simulators. Integrative physiology and integrated models
of physiological systems thus become the technological
know-how for the development of products with a high
added value in the form of medical information and
robotic knowledge that can find applications on the
rapidly developing market.
Integrative models of human physiology will allow
detailed monitoring of causal chains of application of
various therapeutic or pathogenic stimuli, thus providing
a wide potential for application of integrative models
of human physiology especially in clinical testing of
pharmaceuticals and in the development and testing of
modern medical instruments (see Section 3.2).
The pressure of possible commercial applications leads
to the fact that formalized descriptions of physiological
regulations expressed as an integrated model often
become carefully protected information, which limits the
sharing of the results of scientific physiological research
and undermines the possibilities of scientific cooperation.

In order to ensure the development of complex
integrated models in physiology, it will probably be suitable
to seek such forms that will combine entrepreneurial
opportunities and financing by the commercial sector
with open scientific development.
One of the possibilities is to utilize a similar form in
which the product OpenModelica has been developed in
the open community (see https://openmodelica.org). The
development of products is ensured by the consortium
of 23 universities and 23 companies and institutions as
well as a number of individual developers (Open Source
Modelica Consortium  see https://openmodelica.org/
home/consortium). Research is financed using member
contributions whose amount is determined based on
the size of the company and based on the number of
sold products in whose development OpenModelica
licences have been used. OpenModelica has created a
circle of a relatively large community of users as well
as a high number of cooperating developers; the result
is a functional open source product equivalent in terms
of functionality to competitive expensive commercial
implementations of Modelica such as Dymola from
Dassault Systmes), MapleSim from MapleSoft),
Wolfram SystemModeler from Wolfram, etc. Commercial
companies may use and further develop any part of the
OpenModelica environment in their own commercial
applications, also in the development of competitive
commercial implementations of Modelica (this is why
companies such as Wolfram Math Core or MapleSoft are
also members of the consortium).
Perhaps a consortium of the academic community and
commercial companies built on similar foundations 
called e.g. Physiomodelica Open Source Consortium
could ensure further development of an integrated model
of physiology in the future.

Acknowledgements
The authors appreciate the partial funding of this work
by PRVOUK P/24/LF1 and FR Cesnet 551/2014.

5.3 Prospects of combining commercial and
academic development
However, international cooperation and openness
to sharing the results are the driving force of scientific
development in todays globalized world. For example, as
shown by experience, a community of users and developers
as wide as possible is important for the development of
complex software systems, thus a community that can
provide feedback and ensure further innovations of a
complex product through cooperative development, while
subsequently, further entrepreneurial opportunities open
up in the connection with this product  this is why such
a great spreading of the development of projects with the
open source code has been seen in recent years.
DOI
10.3384/ecp17132589

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

601

Integrative physiology in Modelica

References
Amosov, N. M., B. L. Palec, B. T. Agapov, I. I. Jermakova,
E. G. Ljabach, S. A. Packina, and V. P. Solovjev.
1977. Theoretical Research of Physiological Systems:
Matematical Modeling (in Russian). Naukova Dumka.
Atkins, Gordon Leslie. 1969. Multicompartment Models for
Biological Systems. Methuen London.
Bassingthwaighte, J. B. 2000. Strategies for the Physiome
Project. Annals of Biomedical Engineering 28 (8).
Springer: 104358.
Chen, Jian, Keqin Wu, William A. Pruett, and Robert L.
Hester. 2013. HumMod Browser: An Exploratory
Visualization Tool for Model Validation of Whole-Body
Physiology Simulation. In Eurographics Conference
on Visualization (EuroVis)(short Paper). researchgate.
net. https://www.researchgate.net/profile/Keqin_Wu2/
publication/303290077_HumMod_Browser_An_Exploratory_Visualization_Tool_for_Model_Validation_of_Whole-Body_Physiology_Simulation/
links/573f6ab108ae298602e8f3cf.pdf.
Coleman, T. G., and R. L. Summers. 1997. Using Mathematical Models to Better Understand Integrative Physiology.
Journal of Physiology and Biochemistry 53: 4546.
Fontecave-Jallon, J., and S. R. Thomas. 2015. Implementation
of a Model of Bodily Fluids Regulation. Acta Biotheoretica 63 (3): 26982.
Grodins, F. S., J. Buell, and A. J. Bart. 1967. Mathematical
Analysis and Digital Simulation of the Respiratory Control System. Journal of Applied Physiology 22 (2). DTIC
Document: 26076.
Guyton, A. C. 1981. The Relationship of Cardiac Output and
Arterial Pressure Control. Circulation 64 (6): 107988.
Guyton, A. C., T. G. Coleman, and H. J. Granger. 1972. Circulation: Overall Regulation. Annual Review of Physiology 34. annualreviews.org: 1346.
Guyton, A. C., H. J. Granger, and T. G. Coleman. 1971. Autoregulation of the Total Systemic Circulation and Its Relation to Control of Cardiac Output and Arterial Pressure.
Circulation Research 28 (January): Suppl 1:9397.
Guyton, A. C., J. E. Hall, and J. P. Montani. 1988. Kidney
Function and Hypertension. Acta Physiologica Scandinavica. Supplementum 571: 16373.
Guyton, A. C., R. D. Manning Jr, R. A. Norman Jr, J. P. Montani, T. E. Lohmeier, and J. E. Hall. 1986. Current Concepts and Perspectives of Renal Volume Regulation in
Relationship to Hypertension. Journal of Hypertension.
Supplement: Official Journal of the International Society
of Hypertension 4 (4): S4956.
Guyton, A. C., and John E. Hall. 2015. Guyton and Hall Textbook of Medical Physiology. Elsevier Health Sciences.
Hester, R., A. Brown, L. Husband, and R. Iliescu. 2011. HumMod: A Modeling Environment for the Simulation of Integrative Human Physiology. Frontiers in. journal.frontiersin.org. http://journal.frontiersin.org/article/10.3389/
fphys.2011.00012.
Hester, R. L., T. Coleman, and R. Summers. 2008. A Multilevel Open Source Integrative Model of Human Physiology. The FASEB Journal 22 (1 Supplement): 756.8756.8.
Hester, R. L., R. Iliescu, R. Summers, and T. G. Coleman.

602

2011. Systems Biology and Integrative Physiological
Modelling. The Journal of Physiology 589 (Pt 5). Wiley
Online Library: 105360.
Hodgkin, A. L., and A. F. Huxley. 1952. A Quantitative
Description of Membrane Current and Its Application
to Conduction and Excitation in Nerve. The Journal of
Physiology 117 (4). ncbi.nlm.nih.gov: 500544.
Hunter, P. 2016. The Virtual Physiological Human: The Physiome Project Aims to Develop Reproducible, Multiscale
Models for Clinical Practice. IEEE Pulse 7 (4). ieeexplore.ieee.org: 3642.
Hunter, P., J. Edmund, J. Crampin, and Poul M. F. Nielsen.
2008. Bioinformatics, Multiscale Modeling and the IUPS
Physiome Project. Briefings in Bioinformatics 9 (4). Oxford Univ Press: 33343.
Hunter, P., P. Robbins, and D. Noble. 2002. The IUPS Human
Physiome Project. Pflugers Archiv: European Journal of
Physiology 445 (1). Springer: 19.
Hunter, P. J., W. W. Li, A. D. McCulloch, and D. Noble. 2006.
Multiscale Modeling: Physiome Project Standards, Tools,
and Databases. Computer 39 (11). ieeexplore.ieee.org:
4854.
Ikeda, N., F. M., M. Shirataka, and T. Sato. 1979. A Model of
Overall Regulation of Body Fluids. Annals of Biomedical
Engineering 7 (2): 13566.
Kofranek, J., M. Matejak, and P. Privitzer. 2011. HummodLarge Scale Physiological Models in Modelica. In Proceedings of the 8th International Modelica Conference;
March 20th-22nd; Technical Univeristy; Dresden; Germany, 71324. Linkping University Electronic Press.
Kofrnek, J., M. Matejk, P. Privitzer, M. Tribula, T. Kulhnek,
J. ilar, and R. Pecinovsk. 2013. HumMod-Golem Edition: Large Scale Model of Integrative Physiology for
Virtual Patient Simulators. In Proceedings of the International Conference on Modeling, Simulation and Visualization Methods (MSV), 1. The Steering Committee of The
World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp).
Kofranek, J., and J. Rusz. 2010. Restoration of Guytons
Diagram for Regulation of the Circulation as a Basis for
Quantitative Physiological Model Development. Physiological Research / Academia Scientiarum Bohemoslovaca
59 (6). Institute of Physiology: 897.
Kofrnek, J., L. D. Anh Vu, H. Snaselova, R. Kereke, and T.
Velan. 2001. GOLEM-Multimedia Simulator for Medical
Education. Studies in Health Technology and Informatics, no. 2. IOS Press; 1999: 104246.
Kofrnek, J., M. Matejk, and P. Privitzer. 2010. Web Simulator Creation Technology. MEFANET Report 3: 3297.
Kohl, P., E. J. Crampin, T. A. Quinn, and D. Noble. 2010.
Systems Biology: An Approach. Clinical Pharmacology
and Therapeutics 88 (1): 2533.
Kohl, P., and D. Noble. 2009. Systems Biology and the Virtual Physiological Human. Molecular Systems Biology 5
(July): 292.
Kulhnek, T., J. Kofrnek, and M. Matejk. 2014. Modeling
of Short-Term Mechanism of Arterial Pressure Control in
the Cardiovascular System: Object-Oriented and Acausal
Approach. Computers in Biology and Medicine 54 (November): 13744.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132589

Session 9C: Acoustic & Medical Systems
Lerant, A. A., R. L. Hester, T. G. Coleman, W. J. Phillips, J.
D. Orledge, and W. B. Murray. 2015. Preventing and
Treating Hypoxia: Using a Physiology Simulator to Demonstrate the Value of Pre-Oxygenation and the Futility of
Hyperventilation. International Journal of Medical Sciences 12 (8). ncbi.nlm.nih.gov: 62532.
Mangourova, V., J. Ringwood, and B. Van Vliet. 2011. Graphical Simulation Environments for Modelling and Simulation of Integrative Physiology. Computer Methods and
Programs in Biomedicine 102 (3). Elsevier: 295304.
Matejk, M.. 2014. Physiology in Modelica. MEFANET
Journal 2 (1). Facta Medica: 1014.
Matejk, M. 2015. Formalization of Integrative Physiology.
Charles University in Prague. Edited by Ji Kofrnek.
Ph.D., Charles University. https://github.com/MarekMatejak/dissertation/blob/master/thesis.pdf.
Matejk, M-, F. Jeek, M. Tribula, and J. Kofrnek. 2015.
Physiolibrary 2.3-An Intuitive Tool for Integrative Physiology. IFAC-PapersOnLine 48 (1). Elsevier: 699700.
Matejk, M., T. Kulhnek, J. ilar, P. Privitzer, F. Jeek, and
J. Kofrnek. 2014. Physiolibrary-Modelica Library for
Physiology. In Proceedings of the 10 Th International
Modelica Conference; March 10-12; 2014; Lund; Sweden,
499505. Linkping University Electronic Press.
Matejk, M., M. Tribula, F. Jeek, and J. Kofranek. 2015.
Free Modelica Library for Chemical and Electrochemical
Processes. In Proceedings of the 11th International Modelica Conference, Versailles, France, September 21-23,
2015, 35966. Linkping University Electronic Press.
Matejk, M., and J. Kofrnek. 2015. Physiomodel-an Integrative Physiology in Modelica. And Biology Society
(EMBC), 2015 37th . ieeexplore.ieee.org. http://ieeexplore.ieee.org/abstract/document/7318646/.
McCulloch, Warren S., and Walter Pitts. 1943. A Logical
Calculus of the Ideas Immanent in Nervous Activity. The
Bulletin of Mathematical Biophysics 5 (4). Kluwer Academic Publishers: 11533.
Milhorn, H. T. 1966. Application of Control Theory to Physiological Systems. W.B. Saunders.
Montani, J. P. and Bruce N. Van Vliet. 2009. Understanding
the Contribution of Guytons Large Circulatory Model to
Long-Term Control of Arterial Pressure. Experimental
Physiology 94 (4). Wiley Online Library: 38288.
Montani, J. P., T. H. Adair, R. L. Summers, T. G. Coleman, and
A. C. Guyton. 1989. A Simulation Support System for
Solving Large Physiological Models on Microcomputers.
International Journal of Bio-Medical Computing 24 (1):
4154.
Montani, J. P., H. L. Mizelle, T. H. Adair, and A. C. Guyton.
1989. Regulation of Cardiac Output during AldosteroneInduced Hypertension. Journal of Hypertension. Supplement: Official Journal of the International Society of
Hypertension 7 (6): S2067.
Moss, R., T. Grosse, I. Marchant, N. Lassau, F. Gueyffier,
and S. R. Thomas. 2012. Virtual Patients and Sensitivity Analysis of the Guyton Model of Blood Pressure
Regulation: Towards Individualized Models of WholeBody Physiology. PLoS Computational Biology 8 (6):
e1002571.
Omholt, S. W., and P. J. Hunter. 2016. The Human Physiome:

DOI
10.3384/ecp17132589

A Necessary Key for the Creative Destruction of Medicine. Interface Focus 6 (2). Royal Society: 20160003.
Pitts, W., and W. S. McCulloch. 1947. How We Know Universals; the Perception of Auditory and Visual Forms.
The Bulletin of Mathematical Biophysics 9 (3). Springer:
12747.
Potek, J., M. Hjek, V. Brodan, and E. Kuhn. 1977. The
Method of Estimating Biological System Parameters on
Hybrid Computer. Kybernetika 13 (2). Institute of Information Theory and Automation AS CR: 15364.
Pruett, W. Andrew, John S. Clemmer, and Robert L. Hester.
2016. Validation of an Integrative Mathematical Model
of Dehydration and Rehydration in Virtual Humans.
Physiological Reports 4 (22). doi:10.14814/phy2.13015.
Pruett, W., L. Husband, and R. Hester. 2014. Understanding
Variation in Salt Sensitivity in HumMod, a Human Physiological Simulator (857.11). The FASEB Journal 28 (1
Supplement). http://www.fasebj.org/content/28/1_Supplement/857.11.abstract.
Sheppard, C. W. 1948. The Theory of the Study of Transfers
within a Multi-Compartment System Using Isotopic Tracers. Journal of Applied Physics 19 (1). AIP: 7076.
Shim, E. B, Ch. H. Leem, Y. Abe, and A. Noma. 2006. A New
Multi-Scale Simulation Model of the Circulation: From
Cells to System. Philosophical Transactions. Series A,
Mathematical, Physical, and Engineering Sciences 364
(1843): 14831500.
Summers, R. L., S. Platts, J. G. Myers, and T. G. Coleman.
2010. Theoretical Analysis of the Mechanisms of a Gender Differentiation in the Propensity for Orthostatic Intolerance after Spaceflight. Theoretical Biology & Medical
Modelling 7 (March): 8.
Thomas, S. R., P. Baconnier, J. Fontecave, J. P. Franoise,
F. Guillaud, P. Hannaert, A. Hernndez, et al. 2008.
SAPHIR: A Physiome Core Model of Body Fluid Homeostasis and Blood Pressure Regulation. Philosophical
Transactions. Series A, Mathematical, Physical, and Engineering Sciences 366 (1878). rsta.royalsocietypublishing.
org: 317597.
Von Bertalanffy, L. 1973. General Systems Theory. George
Braziller Inc., New York.
White, R. J., and J. C. McPhee. 2007. The Digital Astronaut:
An Integrated Modeling and Database System for Space
Biomedical Research and Operations. Acta Astronautica
60 (47). Elsevier: 27380.
Wu, K., J. Chen, W. A. Pruett, and R. L. Hester. 2013. Hummod Browser: An Exploratory Visualization Tool for the
Analysis of Whole-Body Physiology Simulation Data. In
2013 IEEE Symposium on Biological Data Visualization
(BioVis), 97104. ieeexplore.ieee.org.
Xu, L., J. Lyle, Y. Wu, Z Pan, M. Zhang, D. H. Laidlaw, R. L.
Hester, and J. Chen. 2011. HumMod Explorer: A MultiScale Time-Varying Human Modeling Navigator. In SIGGRAPH Asia 2011 Posters, 28:128:1. SA 11. New York,
NY, USA: ACM.
Zhang, S., W. A. Pruett, and R. Hester. 2015. Visualization
and Classification of Physiological Failure Modes in Ensemble Hemorrhage Simulation. In SPIE/IS&T Electronic Imaging, 93970O  93970O  8. International Society
for Optics and Photonics.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

603

604

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Sound Source Extension Library for Modelica
Johann Emhofer

Raimund Zitzenbacher

Christoph Reichl

Center for Energy, AIT Austrian Institute of Technology, Giefinggass 2, 1210 Wien, Austria.
{johann.emhofer,raimund.zitzenbacher.fl,christoph.reichl}@ait.ac.at

Abstract
Transient thermodynamic models in Modelica are widely
used for energetic simulations of machines and systems
which are located nearby people. Nevertheless, so far no
libraries exist which consider the noise of such machines
in the simulations. The Sound Source Extension library
(SSElib) proposed in this work, should close this gap.
With the aid of the SSElib, acoustic characteristics can be
added to existing Modelica models (e.g. to a compressor
or a pump model). The acoustic characteristic added to the
existing model is frequency dependent in the one-octave
band and could further depend on an input parameter like
the rotational speed of a compressor. With the inclusion of
sound sources into energetic models, the sound behavior
of machines can be considered and control strategies can
be optimized to lower the noise of machines.
Keywords: Modelica, sound, noise, acoustics, heat pump

1

Introduction

Due to local mechanical vibrations of a component in air,
local displacements of the air atoms and changes in local pressure or density are excited. The local changes
propagate to the neighboring atoms. The propagation of
these vibrations are better known as sound which can be
recognized by the human ear. Speech, music or acoustic signals are wanted effects of sound, whereas the noise
of machines are experienced as disturbing. The aim of
the Sound Source Extension Library (SSElib) is to consider the unwanted noise excited from machines. With
the SSElib one can extend existing Modelica components
with a sound source that can depend on a variable of the
component itself. This variable could be a frequency of a
fan, the pressure drop over a heat exchanger or any other
variable that influences the sound characteristic of the machine. In other words, an acoustic characteristic which
depends on the operating conditions of a component can
be added to a new or existing component.
In the SSElib we use basic acoustic calculation methods to estimate the all over loudness of a machine. Note
that the main aim of the library is not an accurate prediction of the loudness but it should show how the operation
point of a machine influences their noise emission. Hence,
solely simple correlations for noise propagation and reduction are included in the library to give a first hint about
how the acoustic characteristic of machines behave. The
strength of the SSElib is the easy integration into existing
DOI
10.3384/ecp17132605

models without the need of significant extra computational
power in Modelica.
Several mature methods like Finite Element Methods
(FEM), Boundary Element Methods (BEM) or Computational Aero Acoustics (CAA) exist for accurate sound
propagation calculations and therefore such methods
should be used if a detailed sound analysis is needed. A
good overview of these methods can be found in (Crocker,
2007).
The SSElib was developed in Dymola 2016 and testing was performed within the Testers and Examples package of the library. The SSElib builds on the Modelica
Standard Library (MSL) and no additional libraries are
needed. Most of the Testers were also tested in OpenModelica 1.9.6 without any problems. Besides this publication, a UsersGuide package was added to the library
on top level, to help users with the implementation of the
SSElib into their models.
SSElib is published under the Modelica License 2.

2

Methodology

2.1

General

The following assumptions were made in order to keep the
equations simple:

 All sound sources are independent point sources.
 The sound fields considered in the SSElib are assumed to be diffuse and incoherent in all frequencies.
 The noise source volume has to be less than about
0.3 to 0.4 of an enclosure volume for calculations of
damping (Crocker, 2007). If the noise source occupies more than a third of the enclosed volume of the
sealed enclosure, the sound field is neither reverberant nor diffuse. Nevertheless, the discussed methods will be used as a first approximation of insertion
losses in an enclosure even if this requirement is not
fulfilled.
In this work, we concentrate on the sound pressure p
and the sound power W . The sound pressure is always
connected to a location and describes the local pressure
amplitude at this location. Therefore, the sound pressure
depends on the distance from the sound source ( 1/r2
for a point source) and the symmetry of the emitted sound
waves from the source (monopole, dipole, etc.). From

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

605

Sound Source Extension Library for Modelica

the sound pressure one can calculate the sound intensity arithmic dB units:
I which takes the material properties of the sound propagating media into account. For both, a radial symmetric
L p (dB) =
point source and a plane wave moving in one direction,
this gives (Crocker, 2007):
LW (dB) =
I=




p
20 log
p0
 
W
10 log
W0

(4)
(5)

p2rms
c

(1) where p0 is the absolute threshold of hearing at 2105 Pa
and W0 is 1012 W.
Combining (3),(4),(5) and concerning that W0 =
for the time averaged sound intensity, where  is the den2 /(c), leads to a direct link between L and L :
p
p
W
0
sity of the medium (air) and c is the speed of sound in


the medium. In the SSElib, the denisty of air and the
S
speed of sound in air are assumed as constant values with
(6)
L p = LW  10 log
1 m2
1.204 kg/m3 and 343 m/s, respectively. Subsequently, the
sound power W of a sound source can be calculated from As already noticed in (3), a change of the enclosed surface
integrating the sound intensity over an enclosing surface through which the sound from the sound source propaaround the sound source in a far field assumption:
gates leads to a reduction or an enhancement of the sound
pressure level. From (6) follows for two different locations A and B:
W=
(2)
 
S
SB
(7)
L p,B = L p,A  10 log
SA
where prms, j is the sound pressure and S j is a partial area
of the enclosing surface where constant sound pressure where SA and SB are two different enclosing surfaces with
prms, j is assumed. From (2) one can see, that if two vari- constant sound pressure level L p,A and L p,B , respectively.
ables from (W ,p,S) are known, the third can be calculated. If the enclosed surface increases e.g. if the distance beFor unsymetrical sound sources, the sound pressure on the tween sound source and observer increases, the sound
enclosing surface becomes rapidly complex, hence only pressure level decreases. If the enclosed surfaces detwo special cases are considered in the SSElib: a spherical creases e.g. at the inlet into a duct, the sound pressure
propagation and a one dimensional propagation. For both level increases.
one finds:
For a radial symmetric point source (6) leads to an equa1 2
tion where S can be described with the radial distance r
p S
(3)
W=
directly:
c rms


 r 
where S represents the surface through which the sound
4  p20
(8)
 10 log
L p = LW  20 log
propagates and prms is the effective sound pressure at S.
1m
c W0
If a point source is located in the free room, S would be
4r2 where r is the radial distance from the point source. The last term is dominated by 10 log (4 ) and is usually
If a rigid surface is located below the point source, the approximated with 11 dB in various textbooks.
The difference of two sound pressure levels of a consound will only propagate to a spherical half space with a
2
stant
radial symetrical point source changes with the dissurface of 2r , therefore S is only half of the free room
tance.
From (8) follows for two different locations A and
situation. For a sound source standing on a rigid surface in
B:
front of a wall and for a sound source located in a corner,
 
rB
S would even be a fourth or an eight compared to the free
L p,B = L p,A  20 log
(9)
rA
room situation. In other words, for a given sound power,
the sound pressure could be significantly higher for differ- where rA and rB are the different distances to the point
ent installation situations compared to the free room situ- source. Hence, doubling the distance leads to a reduction
ation, due to the fact that the kinetic energy generated by of 6 dB. Note that doubling the distance in (9) is equivalent
the sound source has to be transported through a smaller to quadruple the surface of constant sound pressure.
surface (c.f. Table 1).
As already discussed, p2rms will be doubled if the sound
Contrary to the sound pressure, the sound power is a source stands on a rigid floor and the same sound power
characteristic value of the sound source which is indepen- level of the source is assumed. Hence, the sound presdent of the location or the symmetry of the sound source. sure level will be enhanced by 3 dB. Similar consideraHence, once the sound power level is known, the sound tions lead to an enhancement of 6 dB and 9 dB for a sound
pressure level can be calculated for known geometries.
source standing on a rigid surface in front of a wall and a
Usually both the sound pressure level and the sound sound source in a corner, respectively. Therefore, simple
power level of a single frequency source, are given in log- rules as summarized in Table 1 hold for these scenarios.
Z

606

1
p2rms
dS =
p2rms, j S j
c
c 
j

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132605

Session 9C: Acoustic & Medical Systems

Table 1. Noise enhancement for different installation situations

Situation

L (dB)

floor

Lp,total (dB) = 10 log

 10Lp,i /10
n

wall and floor

LW,total (dB) = 10 log

S f ree /4

+6

(13)

i=1

S f ree /2

+3

!

n

S

 10

!
LW,i /10

(14)

i=1

corner

2.2

S f ree /8

+9

Frequency analysis

Up to this point, only single frequency sources were considered. But both, sound pressure and power can be broken down into frequency bands as shown by Fourier over
200 years ago. It is common in acoustics to divide the frequency spectrum into frequency bands like the one-octave
ot the one-third-octave band. For an octave band the lower
and upper cutoff frequencies ( fl and fu ) are defined as:


fl = fc / 2; fu = 2 fc

(10)

where fc is the center frequency of the band. From (10)
follows the center frequency:
fc =

p

(11)

fl fu

Furthermore, from (10) follows that the upper cut off
frequency is always twice the lower cutoff frequency fu =
2 fl and that the bandwidth is  f = 2 fc . For the i-th
frequency band, the center frequency follows:

The same addition rules (13) and (14) are valid if
the sound pressure or sound power levels of independent
sound sources have to be added to a total sound pressure
or sound power level, respectively.
The relative loudness of sound that can be perceived
by the human ear is usually calculated by weighting the
instrument-measured sound levels with a frequency dependent curve or table. The most common used curve is
the A-weighting curve which is defined in several national
and international standards, like the (IEC 61672-1, 2003).
This curve dampens the sound at low and high frequencies whereas the intermediate frequencies stay unfiltered
or are slightly enhanced. Table 4 in the Appendix shows
the weighting coefficients i used for A-weighting at different center frequencies in the one-octave band which
are used in the SSElib. If the one-octave band is chosen, the weighting coefficient vector is A = (-56.7,-39.4,26.2,-16.1,-8.6,-3.2,0,1.2,1.0,-1.1,-6.6)T dB.
The A-weighted total sound pressure level can then be
calculated with:
!
n
Lp,i +A,i )/10
(
L
( dBA) = 10 log
10
(15)



p,total

i=1
n

fc,i = 2(i1) fc,1

LW,total ( dBA) = 10 log

(12)



!
10(LW,i +A,i )/10

(16)

i=1

It is common, that A-weighted sound levels are dewhere fc,1 is the first center frequency (15.625 Hz in the
scribed
with the unit dBA or dB(A).
one-octave band).
One has to be aware if data is given in the unit dB or
Considering frequency analysis, the frequency dependent sound pressure level Lp and the sound power LW are dB(A). However, with (15) one can always convert the
units to each other.
generally described as vectors in the SSElib:



Lp,1
 .. 
 . 



Lp = 
 Lp,i  ,
 .. 
 . 
Lp,n




LW,1
 .. 
 . 



LW = 
 LW,i 
 .. 
 . 
LW,n

where each row corresponds to a frequency band
with a center frequency fc = ( fc,1 . . . fc,i . . . fc,n )T .
The values of fc , as well as the number of rows n
depend on the chosen frequency band. E.g. if the
octave band is choosen, the center frequencies are
fc =(16,31.5,63,125,250,500,1e3,2e3,4e3,8e3,16e3)T Hz
and therefore n=11 (c.f. Table 4). The logarithmic sum of
the sound pressure levels at different center frequencies
gives then the total sound pressure level and the total
sound power level, respectively:
DOI
10.3384/ecp17132605

2.3

Noise reduction

Noise reduction can be achieved with several active and
passive methods. An active method could be to operate
a machine in a silent operating point. Such points can be
found by extending simulation models with the SSElib.
A passive method is the integration of sound absorbing
materials or silencers. Currently, two main noise reduction methods are implemented in the SSElib. The first one
describes the reduction with frequency dependent differences on the sound pressure or power level. Such a description is often used for silencers in ducts. Manufacturers usually provide these data to their customers. Table 5
in the Appendix shows typical values for the differences
in sound pressure level Ls in a 6060 cm rectangular silencer with a length of 50 cm. Using the vector notation
one can easily describe the noise reduction with:
Lp,out = Lp,in +  Ls

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(17)
607

Sound Source Extension Library for Modelica

where Lp,out is the frequency dependent sound pressure
level at the outlet of the silencer, Lin is the frequency dependent sound pressure level at the inlet of the silencer and
 Ls has to be taken from manufacturers data or text books.
Note that according to (6) the reduction of Lp in (17) goes
hand in hand with a reduction of the sound power level
LW as sound power is converted to heat in the absorber
material.
The other noise reduction method implemented in the
SSElib uses absorbing material mounted in the enclosure
of a machine or on the enclosing walls of a room. As
the assumed sound fields are diffuse and reverberant the
noise in the enclosure can be described with an average
sound pressure level inside the enclosure. For this, we
have to introduce frequency dependent sound absorption
coefficients  for given surfaces and center frequencies.
The absorbed sound power is therefore given with:
Wabs =

p2
 jS j
4c 
j

Although logarithmic units are common in sound calculations, decimal units were used to describe the sound
power to circumvent problems if the flow direction is unknown. Since also negative logarithmic sound levels have
still a positive sound power, the descriptions with flow
variables was not possible without introducing a further
variable. Therefore, and for the sake of simplicity decimal units are used in the SSElib to describe the sound
power in the connectors. Currently, only the one-octave
band is implemented in the SSElib, hence the sound power
W and the center frequencies fc are described as vectors
with 11 rows according to the one-octave band (c.f.Table
4). The center frequency vector fc is located in the Constants package.

3.2

Components

Several components were realized in the SSElib. Table 2
gives an overview of the components and links them to the
(18) equations and tables used in this work.
Table 2. Components of the SSElib

where p is the diffuse sound pressure in the enclosure,
p2 /(4c) represents the equivalent power per m2 and S j
and  j are partial surfaces and their corresponding absorption coefficients, respectively. The term  j  j S j is often
referred to as the equivalent area of an open window in an
enclosure with no absorption.
In the steady-state, the absorbed sound power has to
be equal to the sound power propagating from the sound
source inside the enclosure. Hence,Wabs is equal to W.
From (18) it is obvious that the sound pressure p becomes
smaller for higher absorption coefficients or higher surface areas. Using logarithmic notations one finds (see also
(Mser, 2012)):


 j  jS j
+ 6 dB
(19)
Lp = LW  10 log
1 m2
Dependent on the material and the geometry of the enclosure, a part of the absorbed sound power is converted
to thermal energy whereas the other part remains sound
and will be radiated from the outer surface of the enclosure. Similar to  , the transmission can be described by
frequency dependent transmission coefficients  :
W = W 

 j  jS j
j Sj

(20)

Name

Reference

AcousticSource

-

AcousticSink

-

Add
Converter_dBA

(13),(14)
(15),(16)

InstallationSituationFloor

Table 1

InstallationSituationWall

Table 1

InstallationSituationCorner

Table 1

RadialDistance

(8),(9)

OpenWindow

(6)

Silencer

(17)

Enclosure
EnclosureWithTransmission

3.3

(18),(19)
(18),(19),(20)

Sensors

where W is the sound power propagating from the outer In order to observe the sound pressure and sound power
levels at different locations inside the models, four sensurface of the enclosure.
sors are provided in the library which can be connected
3 Implementation
in between an acoustic connection. For both, the sound
power and the sound pressure sensors, an unfiltered ver3.1 Connectors
sion and an A-weighted version exist. Table 3 shows the
The acoustic port ( ) in the SSElib consists of two vari- four sensors. Please note that we have used dB instead of
ables namely, the frequency dependent sound power W dB(A) or dBA as unit for the A-weighted variables. The
(flow variable) and the enclosing surface S at the ports lo- reason is that dB(A) or dBA arent valid units in Modelica.
cation.
608

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132605

Session 9C: Acoustic & Medical Systems

Table 3. Sensors of the SSElib

3.4

Name

Reference

SoundPressureSensor

(4),(6),(13)

SoundPressureSensor(dBA)

(4),(6),(15)

SoundPowerSensor

(5),(6),(14)

SoundPowerSensor(dBA)

(5),(6),(16)

Sound Source Extension

The main task of the SSElib is to provide a model to extend existing models with acoustic characteristics. This
model is the AcousticExtensionOneOctave model ( ) located in the SoundSourceExtension package. It should be
used in the following way:

 Create a model which represents your new acoustic
component
 Extend your new model with the sound source extension from the SSElib

Contrary to the connections of the original pump model,
the new model has now an additional real input and a
sound source connector as depicted in the lower right corner. The additional input is simply called "soundInput"
and can be used to influence the sound source levels. In the
case of the pump, the rotational speed of the pump would
be a reasonable input variable, due to the fact that the
acoustic characteristic of the pump is expected to change
significantly with the pump speed.
Figure 2 shows artificial sound data for a pump. We assume that sound power level at the rotational speeds n =
30, 50, 70 and 90 Hz have been measured and should be
used for the simulations. They are depicted as bar plots in
Fig. 2. In order to estimate the correct sound pressure levels at different rotational speeds, one could use the measured data directly in Modelica as table data and calculate
the corresponding sound power levels with the aid of interpolation functions. As this method would lead to significant loss of time, we propose to use polynomial functions
to describe the sound power data. The surface plot in Fig.
2 shows a polynomial function which was fitted to the data
using polynomial functions from the Numerical Python library NumPy (Oliphant, 2006).

 Extend your new model with your non-acoustic component e.g. a fluid pump
 Use your new model in the simulations instead of
the old model and modify the acoustic parameters to
match your components sound characteristic. Dont
forget to connect your new model to at least one
acoustic sink.
A new model for an extended fluid pump was
implemented in the following way using the
PrescribedPump model from the MSL (Modelica.Fluid.Machines.PrescribedPump):
model Example_AcousticPump
extends SSElib.Extension.\
AcousticExtensionOneOctave;
extends \
Modelica.Fluid.Machines.PrescribedPump;
end Example_AcousticPump;

Figure 2. Sound power LW dependency on the rotational speed
of the pump n and the frequency bands around the center frequency fc . The surface around the bar plots represents a polynominal fit.

To use polynomial functions, polynomial coefficients
have
to be passed to the extended model as a parameter.
The extended pump can be found in the TestersAndExIn
general
these coefficients c should have the form:
amples package. Figure 1 shows the graphical representation of the pump from the MSL extended with a sound
source.
LW (i, n) =  ck,l ik nl
(21)
k,l

where i is the frequency band of the octave band (c.f. Table 4) and n is the rotational speed of the pump. Note that
we used the integer of the frequency band instead the center frequency on purpose, as it is easier to fit the polynomial functions into data with linear distributed nodes. CurFigure 1. Fluid pump from the MSL extended with a sound rently, the SSElib only supports polynomials with k=l=3
source.
or k=l=4.
DOI
10.3384/ecp17132605

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

609

Sound Source Extension Library for Modelica

Figure 3. System sketch of the SSElib example SSElib.TestersAndExamples.Example.

3.5

Testers and Examples

Each component of the library has a testing model located
in the Testers and Examples package. Furthermore, there
is one extended component (Example_AcousticPump, Fig.
1) and one example (Example, Fig. 3) located inside this
package.
The example was derived from the PumpingSystem
example of the MSL, originally written by Francesco
Casella.
Contrary to the original example the current pump can
operate at different pump speeds and is controlled by a not
very well designed PI-controller. Furthermore, the pump
was extended with an acoustic sound source (c.f. section
3.4). A water pump which is sound-optimized for an operation around 50 Hz or 3000 rpm was assumed and polynomial coefficients were used to represent this behavior (c.f.
Fig. 2).
The A-weighted sound pressure level close to the machine (1m distance) can be observed with SensorMachine.L_p_total_dBA and the speed of the pump can be
observed with pumps.N_in and pumps.soundInput in rpm
and Hz, respectively (Fig. 4). Starting from the soundoptimized speed of 3000 rpm or 50 Hz, the pump speed
decreases to around 2260 rpm or 38 Hz in the steady state
after around 1200 s. Simultaneously, the sound pressure
level increases from 88 dB(A) to 103 dB(A) (red line in
Fig. 4).
From an engineers point of view several options exists
to lower the noise of the pump. One option could be, that
the sound pressure measured at the machine or simulated
on a computer is used to optimize the control strategy of
the system. Another option could be to install sound absorption measures. The effect of the latter measure can be
estimated by adding components from the SSElib.
In this example the second option is real610

ized.
The pump was covered with an enclosure (EnclosureWithTransmission) which stands on a floor
without walls nearby (InstallationSituationFloor). An observer located 10 m away from the pump (RadialDistance)
finally hears the pump with 66 dB(A) in the steady state
(c.f. SensorObserver.L_p_total_dBA in Fig. 4).

Figure 4. Time dependent pump speed (top) and time dependent
total sound pressure level L p,total in dBA at different locations.

3.6

Heat pump example

Figure 5 shows a further example, where an air source
heat pump, realized with the aid of the TIL library (TLKThermo GmbH) and self-written components, was extended with sound sources. Please note, that this example
is not included in the SSElib.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132605

Session 9C: Acoustic & Medical Systems

Figure 5. Air source heat pump model with an additional characteristic for the compressor and the fan. The components of the
SSElib are mainly located at the lower right corner of the figure.

pump at time = 0, the controller needs about 100 s to
reach a steady-state condition. During this time, the sound
power level reaches a significant maximum around 20 s.
In a sound optimized heat pump such peaks in the sound
pressure level could be easily avoided if the controller considers this peaks at the start of the machine.

4

Outlook

The presented work shows the first version of a library
which should continuously grow in the years to come. The
following features should be implemented soon:

 Frequency resolutions in the one-third octave band

Figure 6. Transient behavior of the heat pump in the one-octave
band.

The fan is housed in a casing with a 0.6 m0.6 m opening, which is represented by the OpenWindow component.
At the outlet of the casing a silencer (Silencer) is connected. The compressor is inside an casing without any
free opening (EnclosureWithTransmission). The transmission coefficient to the outside for all frequencies is assumed with =0.01. Both sound sources are located on
a floor (InstallationFloor) and an observer (SoundPressureSensor_dBA) is 10 m away (RadialDistance). The total sound pressure level that the observer hears is about
57.4 dB(A) at the operating point.
Figure 6 shows the transient behavior of the sound pressure level at the observer location. After starting the heat
DOI
10.3384/ecp17132605

 Additional description methods for the acoustic behaviour besides the description with polynomials and
constants.
 Validation of the models with measurement on an air
source heat pump in AITs acoustic lab.

Acknowledgment
The Austrian Research Promotion Agency (FFG) is gratefully acknowledged for funding this work within the
SilentAirHP project under Grant No. 848891. Furhtermore, we thank TLK-Thermo for technical advice.

References
M. J. Crocker, editor. Handbook of Noise and Vibration Control.
Wiley, New Jersey, 2007.
IEC 61672-1.
Electroacoustics - Sound level meters Part 1:
Specifications ( International Electrotechnical Commission Standard No. 61672-1).
Onlline on:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

611

Sound Source Extension Library for Modelica

https://webstore.iec.ch/publication/5708, last visited: 201703-07, 2003.
M. Mser. Technische Akustik. Springer-Verlag, Berlin Heidelberg, 9th edition, 2012. doi:10.1007/978-3-642-30933-5.
Travis E. Oliphant. Guide to NumPy. Provo, UT, March 2006.
URL http://www.tramy.us/.
TLK-Thermo GmbH. TIL suite and TIL media: Commercial library for steady-state and transient simulation of thermodynamic systems such as heat pump,refrigeration, a/c,
cooling and Rankine systems. Onlline on: https://www.tlkthermo.com/, last visited: 2017-01-22.

Appendix
Table 4. Frequency band index i, center frequencies fc and Aweighting coefficients A,i for the one-octave band. The coefficients were taken from (IEC 61672-1, 2003)

i
1
2
3
4
5
6
7
8
9
10
11

fc (Hz)
16
31.5
63
125
250
500
1 000
2 000
4 000
8 000
16 000

A,i (dB)
-56.7
-39.4
-26.2
-16.1
-8.6
-3.2
0
1.2
1
-1.1
-6.6

Table 6. Typical values for the sound absorption coefficient  of
5 cm thick melamine foam taken from the data sheet of a commercial available noise insulation material

center frequency fc (Hz)
125
250
500
1000
2000
4000

 (-)
0.13
0.41
0.6
0.9
0.85
0.93

Table 5. Typical values for the differences in sound pressure
level Ls in a 60  60 cm rectangular silencer with a length
of 50 cm taken from the data sheet of a commercial available
silencer.

center frequency fc (Hz)
63
125
250
500
1000
2000
4000
8000

612

Ls (dB)
-2
-4
-10
-18
-25
-24
-17
-11

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132605

Towards Medical Cyber-Physical Systems:
Modelica and FMI based Online Parameter Identification
of the Cardiovascular System
Jonas Gesenhues1
1 Institute

Marc Hein2

Maike Ketelhut1

Dirk Abel1

of Automatic Control, RWTH Aachen University, Germany j.gesenhues@irt.rwth-aachen.de
2 Department of Anesthesiology, RWTH Aachen University Hospital, Germany

Abstract
This paper presents a concept for online parameter identification intended to be used within cardiovascular research labs and hospitals of the future featuring a data
network of medical sensors. It is based on iterative nonlinear optimization using a moving horizon scheme and
object-oriented Modelica models. Special FMUs have
been developed to interface the optimization module and
the sensor hardware. The concept is demonstrated on an
exemplary application of identifying the parameters of a
model for the systemic circulation. Unlike classical online
parameter identification methods, this concept allows for
quickly implementing changes of the underlying model.
Keywords: Online Parameter Identification, Moving Horizon, FMI, ModeliChart, JModelica.org, CasADi, Cardiovascular, Medical

1

Thivaharan Albin1

Introduction

Throughout many countries around the globe, public
health care systems are being faced by the ongoing trend
of increased demand for health care services. On the
one hand, this is due to the consequences of demographic
changes towards an aging population. On the other hand,
scientific progress allows for increased treatment possibilities (European Commission, 2016). At the same time,
public hospitals, a major pillar within the health care systems, are faced by a lack of qualified health care personal.
Supporting health care personal in public hospitals by
smart technology might provide an essential component to
meet those challenges. In this regard, ongoing trends such
as digitalization of information, large scale data agglomeration (Big Data), interconnection of devices (IoT) and
smart algorithms that allow for e.g. automated monitoring
of a patients status and early recognizing and possibly automatically resolving critical conditions can be expected
to find their way into hospitals in the future and have the
potential to improve the outcome of patients.
Within this context, the research focus of our interdisciplinary group consisting of engineers and physicians is on
improving the therapy of terminal heart failure, the most
prevalent cause of death in the western world (Nichols
et al., 2012). Specifically, we are working on control
DOI
10.3384/ecp17132613

strategies for technological heart assist devices, such as
blood pumps that are connected to the body to assist
the heart (Ventricular Assist Devices). Here, mathematical models of the cardiovascular system are applied in
many different ways, ranging from computer model in the
loop simulations of new control strategies (e.g. Habigt
et al. (2016); Ketelhut et al. (2017)) over driving test
benches for hardware and software in the loop hardware
tests (e.g. Misgeld et al. (2015)) to state estimation (e.g.
Rschen et al. (2016)) and model based control (Gesenhues et al., 2016).
Although much literature exists describing the observed
behavior of the healthy body, few is known about the underlying mechanisms and how they are affected by diseases, drugs or the interaction with technical devices.
Consequently, the adaption, refinement and creation of
new models is an integral part within this field. Here,
over the years the object-oriented modeling paradigm using Modelica has turned out invaluable for its flexibility
for modifications and the concept of acausal formulation
of components (Gesenhues et al., 2017) and has motivated
the creation of libraries such as the Physiolibrary (Matejk
et al., 2014) or our in-house developed library HumanLib
(Brunberg et al., 2009).
Besides model structure, the identification of the contained model parameters is important. When it comes to
biomedical dynamical systems such as the cardiovascular system, there is generally a great extent of variation
considering parameters. First of all, parameters vary with
countless individual characteristics of patients such as age,
height, weight, gender, lifestyle etc. Second, the presence
and extend of diseases directly affects the parameters. Finally, even in a specific single patient at a specific state,
the parameters vary because the body possesses numerous physiological control mechanisms to adapt to external
conditions such as temperature, exercise or even the current posture (standing upright or lying). Thus, the model
parameters need to be considered time varying and can
change within seconds. All in all, parameters identified
from measured data represent a snapshot of an individual
patient at a specific time.
For all of those reasons and having smart algorithms
and features of hospitals in the future in mind, an au-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

613

Towards Medical Cyber-Physical Systems: Modelica and FMI based Online Parameter Identification of the
Cardiovascular System

Online Parameter Identification
ModeliChart

.mop
Optimica Problem

.mo
Modelica Model

CAN
FMU

Model
FMU

Network
Socket

CAN-Bus

Microprocessor

Hardware
Inteface

Channel Links

TCP/IP
FMU

Python
Routine

Optimization
Module
MH-Buffer,
Optimica,
JModelica,
CasADi,
Ipopt

Infrastructure

Sensors
ADCs (Pressure, Flow)

.fmu
FMU

Figure 1. Architecture and components of the online identification concept. MH: Moving Horizon, CAN: Control Area Network,
ADC: Analog-Digital Converter.

tomated online model parameter identification procedure
that is capable to be included in a hospitals data network
and which continuously identifies model parameters based
on live patient data provides many benefits including diagnostic assistance to doctors (model parameters can be used
to asses a patients status), smart alarms that are raised
when selected parameters exceed a certain threshold up
to model based control of medical devices, for which an
adequately parametrized model is an essential prerequisite. In-vivo animal trials are an integral element of our research. The infrastructure that we have developed to conduct such trials features a large number of sensors which
are connected to a data network (currently we are using
the Control Area Network (CAN) bus). This infrastructure bears resemblance to the possible infrastructure of future hospitals. Thus, our trials and infrastructure provide a
test bed for the implementation of medical cyber-physical
systems.
The current state of technology includes many classical online and offline parameter identification methods,
which have been adapted and applied to virtually any
physical domain. Specifically for the cardiovascular system, those include attempts using reformulation of model
equations to allow for (recursive) least square techniques
(Clark et al., 1980; Hann et al., 2006; Kosaka et al., 2002)
and Bayesian approaches like the (extended) Kalman filter (Yu et al., 1998). Although it has been shown that the
results yielded from classical approaches are valid and reliable, a major limitation consists in the fact that there is an
enormous effort to reformulate the model into the specific
form needed for the identification method. This generally
includes manually rearranging equations and to transform
the system by introducing new state variables and parameters (e.g. to resolve non-linearities). Shortly, classical
methods might be satisfactory when the underlying model
meets the requirements of the identification method and
can be considered frozen with the start of development
as revisions to the model at a later time can be laborious
and even impossible to implement.
614

As mentioned above, cardiovascular system models
are subject to frequent changes. Thus, the applicability of classical methods is limited in this regard. Those
limitations motivate new online identification procedures
which do not require excessive reformulation efforts of
the underlying model. Recently, we have started to
consider non-linear optimization based identification using our Modelica models in combination with Optimica,
JModelica.org and CasADi as a possible solution. A recent study focusing on the offline identification of patient
specific parameters using those tools comes to the conclusion that patient specific parameter identification has the
potential to be a promising component for patient assessment in the clinic (Moza et al., 2017).
The contribution of this paper is a concept that allows
for the automated online parameter identification based on
those ideas and tools which does not exhibit the described
limitations of the previous state of the art and can be used
within our animal trial infrastructure. The general idea
is to repeatedly (re-)identify the current parameter values
by solving a non linear optimization problem over a short
time interval. The paper is organized as follows: first, the
next section provides a general overview over the concept
and its components and the typical setup work flow involved. Section 3 details the iteratively carried out optimization procedure. Afterwards, the concept is demonstrated by the exemplary application of identifying the parameters involved in a simple model of the systemic circulation (Section 4). Finally, the results are presented and
a discussion on current limitations and further enhancements is given (Section 5).

2

Concept Overview and Work Flow

The components involved within the presented concept
are summarized in Figure 1. The concept consists of our
FMU-master ModeliChart (see Section 2.2 below) which
serves as the central hub and graphical user interface and
of the optimization module, which constantly calculates

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132613

Session 9C: Acoustic & Medical Systems

current parameter values. It is further described in Section
3. The optimization module is implemented as a Python
routine. Data exchange between those two components is
realized through a TCP socket stream using a simple custom protocol. This design allows for either running the
optimization module on the same machine that is running
ModeliChart as well as running the optimization module
on a different machine (possibly outside of the lab) connected to the local area network (LAN).

2.1

Interface FMUs

To realize the architecture depicted in Figure 1 two
FMUs complying with the FMI 2.0 co-simulation standard have been developed to allow for data exchange between the individual components of the concept. Both interface FMUs have in common that they are fully configurable through the modelDescription.xml and additional configuration files provided as resources. So far,
both FMUs only support the Real data type. An arbitrary number of input and output channels that appear
as scalar FMU variables can be set. Input channels are
intended for receiving data, output channels, which are
marked with the attributes causality="parameter"
and variability="tunable" are intended to send
data. For each of both FMUs a convenient software tool
has been developed to automatically generate the according modelDescription.xml, additional configuration
files and the packed FMU.
The first FMU constitutes a TCP/IP based network
socket interface used for the connection between the optimization module and ModeliChart. During the initialization of the FMU, a TCP server accepting connections
on a configurable port is started waiting for a client (here
the optimization module) to connect. At this point, only
a single client is supported. On every execution of the
doStep(...) method, the values of the output channel
scalar variables are sent to the connected client using a
simple custom protocol. Similarly, the getReal(...)
function returns the latest value of the specified input
channel scalar variable. The client is allowed to send values at any given time.
The second FMU allows for the interaction with the
CAN bus of our infrastructure which distributes the sensor signals. This FMU uses the API provided by the manufacturer of the CAN interface hardware (PEAK-System
Technik GmbH, Darmstadt, Germany). The CAN FMU
listens to CAN messages of preconfigured message identifiers and returns the last received value whenever the corresponding getReal(...) function is called. Although
not required in the here presented application, the CAN
FMU also supports sending values to the CAN bus.

2.2

ModeliChart

ModeliChart is our self-developed freely available FMU
host. The original motivation has been to provide a free
and intuitive opportunity to asses and play with simulation models to physicians. However, the ease of use and
DOI
10.3384/ecp17132613

the hardware interaction capabilities through the interface
FMUs described above have turned ModeliChart into a
Swiss army knife for all steps during rapid control prototyping cycles. Based on the .NET framework (Microsoft,
Redmond, WA, US), it provides a simple intuitive graphical user interface. ModeliChart supports FMUs complying with the FMI 2.0 co-simulation standard. The main
intended use case is real time operation by periodically
calling the doStep(...) method of all FMUs after a
configurable time interval. So called channel links allow individual FMUs to be connected: Internally, for each
channel link the SetReal(...) method of the receiving
FMU is called at each time step. More details on ModeliChart can be found in (Gesenhues et al., 2017).
Within the here presented application, three FMUs are
used. The CAN FMU is used to fetch the measurements of
the sensors of interest from the CAN bus. Through channel links, the measurement data is handed to the TCP/IP
FMU which in turn sends the measurement data to the optimization module. In this regard ModeliChart serves as
a CAN to TCP/IP bridge. After new identified parameters are available from the optimization module, they are
sent to ModeliChart through the TCP/IP FMU. The third
FMU contains the model under investigation. Through
channel links the current parameter values are set to the
model FMU. In combination with the measurement data
from the CAN FMU used as input into the model FMU, it
is possible to compare chosen simulated signals with corresponding measured signals. Each channel can be plotted
allowing to observe trends of parameter values and to visually asses the validity of the results by comparing the
simulated and measured signals.

2.3

Typical Setup Work Flow

Typically, the setup starts with a Modelica model that contains the parameters of interest. The model should contain variables that correspond to measured signals. Obviously it is required that the parameters are adequately
related to the variables representing the measured signals
(i.e. observability, correlation etc.). Next, an Optimica
file is created containing the optimization problem. The
optimization class should extend from the Modelica
model. In simple cases, it can be sufficient to just mark
the parameters to be identified as free when a quadratic
penalty cost function is to be used. Nevertheless it is also
possible to define custom cost functions. For consistency,
certain variable expressions for optimization parameters
such as final time or limits on allowed parameter values
can be used which are later overwritten when the Optimica file is loaded in the optimization module. An exemplary Optimica file can be seen in Listing 2. Both files are
placed in a folder accessible for the optimization module.
Next, some adaption of the Python routine is necessary to
match the measurement data to the corresponding model
variables and to set optimization parameter settings (see
Section 3). Besides, an FMU of the Modelica model to be
used within ModeliChart is created and if necessary the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

615

Sample Values

Towards Medical Cyber-Physical Systems: Modelica and FMI based Online Parameter Identification of the
Cardiovascular System

Preceding
Horizon

Current
Horizon

Start

Load files

Prepare
optimization
problem
TH
T
Connect to
ModeliChart

Time
Figure 2. Illustration of the moving horizon scheme.

Receiving
samples

configuration of the interface FMUs is adapted. Finally,
a ModeliChart setup (loading the FMUs and creating the
channel links) is created and optionally saved for later use.
As soon as the setup has been loaded in ModeliChart, the
optimization module can be started.

3

Optimization Module

The online parameter identification is realized through
continuously iteratively solving the optimization problem
defined within the Optimica problem using the measurement data samples within a most recent finite time frame
(horizon). Using a moving horizon scheme (Figure 2), as
soon as enough samples for a new horizon spanning the
time TH and enough time since the preceding horizon T
has passed, a new optimization job on the current horizon
measurement data is dispatched.
The optimization module has been implemented as a
Python routine. It uses the modules provided by JModelica.org (version 1.17) and in particular the integrated
CasADi based optimization tool chain (kesson et al.,
2010; Andersson et al., 2011). CasADi is a nonlinear
optimization framework that is capable to automatically
discretize the optimization problem using a collocation
scheme and to calculate the necessary derivatives through
algorithmic differentiation. The tool chain automatically
transforms the formulated Optimica problem to be solved
by a non linear optimization solver. Here, Ipopt has been
used (Wchter and Biegler, 2005).
Figure 3 provides an overview of the routine. After the optimization module has been started, the Modelica and Optimica files are loaded. The variable expressions in the Optimica file (see Listing 2) are replaced by the configured values within the routine, i.e.
%FINAL_TIME% is set to the value TH . Using the according modules, the Modelica model is simulated with
artificial input signals over the time frame TH to provide initial trajectories of all variables. Afterwards, the
optimization problem is compiled and discretized using the prepare_optimization(...) function of the
transfer_optimization_problem module. The so
prepared discretized problem will be used for each of the
following optimizations. Since this compilation process
takes significantly longer than the actual solution of the
616

When
sample
received
Set new horizon

Buffer sample

Enough
samples for
next horizon?

no

yes
Check results
validity

Run optimization

Send results to
ModeliChart
Figure 3. Flow diagram of the optimization module routine.

optimization problem, reusing the prepared discretization
saves a lot of computation time. Afterwards, as soon the
connection to ModeliChart is established, incoming samples are awaited and buffered. As soon as a new horizon
is collected according to the described moving horizon
scheme, the samples within the horizon are set as the new
external data. Furthermore, the initial trajectories for the
solution of the optimization problem are set to the solution
trajectories of the preceding optimization. Afterwards the
solver is started.
For a number of reasons depending on the application
(some examples will be shown in Section 4), the solution
obtained from the solver might be invalid or the solver
might even fail to find a solution within a reasonable time.
At this point, it is just checked whether the found parameters are within defined limits to decide on the validity of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132613

Session 9C: Acoustic & Medical Systems

Listing 1. Modelica model for the identification of the TEW
parameters. The associated Modelica library HumanLib can
be found as online supplement.
model Ident3ElemWK
import HumanLib.Basics.*
import HumanLib.Vessels.*
parameter Real param_Z=0.1;
parameter Real param_R=1;
parameter Real param_C=1;
Resistance Z(R=param_Z);
Compliance C(V_0=0, C=param_C,
V(start=100, fixed=false));
Resistance R(R=param_R);
Sources.PressureSource_Variable P_Ao;
Sources.PressureSource_Variable P_CV;
input Real AoP;
input Real CVP;
Sensors.FlowSensor Q_Ao;
equation
connect(Z.cnStreamOut, R.cnStreamIn);
connect(C.cnBloodStream, R.cnStreamIn);
connect(R.cnStreamOut, P_CVP.cnBloodStream
);
connect(P_Ao.P, AoP);
connect(P_CV.P, CVP);
connect(Z.cnStreamIn, Q_Ao.cnStreamOut);
connect(P_Ao.cnBloodStream,
Q_Ao.cnStreamIn);
end Ident3ElemWK;

Flo
w

Aorta PAo (t)
Sen
so

rQ

Ao (

t)

Ascending

From (left) heart

Descending

To (right) heart
Further Systemic Circulation:
Arteries, Capillaries, Veins

Central Veins PCV (t)
Figure 4. Schematic overview of the systemic circulation.
Flow Sensor
Compliance Pressure Source
Pressure Source
Resistance
Resistance

Listing 2. Optimica optimization problem for the identification
of the TEW parameters.
optimization OptimizeWKParams(startTime=0,
finalTime=%FINAL_TIME%)
extends Ident3ElemWK(
param_Z(free=true,min=%MIN_Z%,max=%MAX_Z%),
param_R(free=true,min=%MIN_R%,max=%MAX_R%),
param_C(free=true,min=%MIN_C%,max=%MAX_C%)
);
end OptimizeWKParams;

the results but in the future it might make sense to evaluate other criteria like residuals, solution time etc. Therefore, an additional parameter is reported back indicating
whether the result is considered valid. This provides feedback for the user on which it can be decided to just ignore
sporadically invalid results or to investigate the reason.

4

Exemplary Application: Identification of the Systemic Circulation

The concept is demonstrated on the simple but relevant in
practice use case of identifying the parameters involved in
modeling the flow dynamics of the systemic circulation.
The systemic circulation refers to all blood vessels (arteries, capillaries, veins) between the outlet of the left (side
of the) heart, which pumps the blood into the systemic
circulation and the right heart, which pumps blood into
the pulmonary (lung) circulation (Figure 4). The vessels
DOI
10.3384/ecp17132613

PAo (t)

QAo (t)

Z

TEW
C

R

PCV (t)

Figure 5. Graphical representation of Listing 1: the threeelement-windkessel (TEW) in model combination with additional components for the parameter identification process.

within the systemic circulation start with the arteries and
branch up more and more into smaller vessels (ultimately
into so called capillaries) running through all parts of the
body (muscles, organs) except the lungs. The capillaries
end up in the veins, which in turn ultimately end in the big
central veins and finally in the right heart.
The large arteries, most importantly the aorta are elastic
and have the ability to distend with raising blood pressure
and recoil with falling blood pressure (indicated through
the dashed line in Figure 4). This leads to a damping of
the amplitude of the pulsating blood pressure wave coming from the heart, an effect that is commonly referred
to as the physiological windkessel effect. A very simple
model for the systemic circulation is the three-elementwindkessel (TEW) model (Westerhof et al., 2009). It consists of two hydraulic resistances (P = R  Q, with P
being the blood pressure difference across the element, Q
the blood flow and R the resistance parameter) and a compliance element (V = C  P with V being the current blood
volume inside the element, P the current blood pressure
inside the element and C being the compliance parame-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

617

Towards Medical Cyber-Physical Systems: Modelica and FMI based Online Parameter Identification of the
Cardiovascular System

ter). For convenience, the elements and parameters will
be referred to as Z, R (resistances) and C (compliance). A
graphical representation of the model can be seen in Figure 5.
During a typical in-vivo animal trial on an anesthetized
pig, the chest is opened and the heart and the aorta uncovered. This allows for the placement of various sensors.
For this application two invasive pressure sensors are used
that are placed inside the Aorta (PAo (t)) and inside one
of the central veins (PCV (t)). Furthermore, an ultrasonic
flow sensor is placed at the beginning of the Aorta (QAo ,
see Figure 4). Listing 1 contains the complete Modelica
model based on components from our library HumanLib
(Brunberg et al., 2009). The blood connector used in Listing 1 consists of the potential variable blood pressure (traditionally denoted in mmHg where 1 mmHg = 133.3 Pa,
referred to atmospheric pressure) and the flow variable
blood flow in ml/sec.
Listing 2 contains the according optimization problem. In this example the parameters to be identified are
marked free. The optimization problem consists in finding those parameter values that minimize the quadratic
difference between the measured signals and the simulated signals. For this, the ExternalData class
of the pyjmi.optimization.casadi_collocation
module has been used. It allows to optimize for all three
sensor signals at the same time without the need for deciding which signals are considered as input or output signals. The extend of individual signal differences can be
weighted against each other. Here, the parameters given
in Table 1 have been used to roughly normalize the signals.
To influence the parameters all sorts of experiments can
be performed during an animal trial. Here, we consider
the constriction of the aorta using a surgical band at two
different positions: at the ascending part right at the beginning of the aorta and at the descending part of the aorta as
indicated by the dashed lines in Figure 4. It is important to
note that the pressure sensor measuring PAo measures the
aortic pressure right behind the constriction of the ascending position but way before the descending position. Each
of those constriction positions should have a different impact on the model parameters.

5

Results and Discussion

For the results presented in this section, already available
raw data recorded during animal experiments conducted
on anesthetized pigs (approved by local animal care authorities) has been used. There were no animal trials conducted for this study. Accordingly, the infrastructure has
been emulated to generate the results presented in this section. The raw data contained the sampled values of the
sensors at a sample rate of 1 kHz. The settings that have
been used are summarized in Table 1.
Two different experiments are investigated. The first
experiment is a short constriction of about 20 seconds
618

Table 1. Settings that have been used to obtain the presented
results. All other settings have been left at their default values.

Name

Value

General:
Horizon length TH ,%FINAL_TIME%
Time between horizons T
Validity criteria:
Maximal value %MAX_R%, %MAX_C%
Maximal value %MAX_Z%
Minimal value %MIN_R%, %MIN_C%
Minimal value %MIN_Z%
Quadratic penalty weight factors:
For PAo
For PCV
For QAo
Optimization settings:
Number of collocation elements
Max. Ipopt iterations

1.5 sec
0.8 sec
3.5
1
0.1
0.001
10
20
1
23
300

at the ascending position (Figure 6). The PCV signal is
not shown in the plots since it remains almost constant at
around 15 mmHg during the experiments. The pressure
PAo is measured behind the ascending occlusion position.
Hence, constricting the aorta at the ascending position
limits the blood flow but hardly affects the properties of
the systemic circulation. It can be seen that the parameters
change only slightly during the constriction and return to
their initial values some time after releasing the constriction. The immediate parameter value changes (most notably the sudden decrease of Z) can be explained by nonlinearities of the real system which become apparent when
the blood flow is significantly reduced. The slow changes
of parameters after the constriction are due to reactions
of the bodies regulation mechanisms; trough muscle cells
within the wall of some of the arteries the cross section
area of the vessel and thus the resistance of the vessel can
be controlled by the body. The increase in Z can be explained by the aim of the body to increase the pressure in
the aorta (the so called baroreceptor reflex). Similar, the
reduced supply of oxygen (hypoxia) leads to a widening
of the blood vessels to allow for increased blood flow and
results in a reduction of R. After the release, the regulatory mechanisms slowly revert the parameters back to the
original values.
For the second experiment, a constriction at the descending position for several minutes is performed (Figure
7, release not shown in the figure). When the aorta is constricted at the descending position, the overall resistance
of the systemic circulation is drastically increased which
is reflected in a significant increase of R. However, due
to impaired draining a significant expansion of the aorta
results in a reduction of Z due to the increase of the cross
section area of the aorta. For the same non-linearity reasons as in the first experiment, the expanded aorta exhibits
a reduce elastance. Hence, the value of the compliance

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132613

Session 9C: Acoustic & Medical Systems

Z [mmHg sec/ml]

Constriction

Release

0.04

0
0.6

0.5

0.4
4

C [ml/mmHg]

R [mmHg sec/ml]

0.02

Valid Result
Invalid Result

3

2

60

100

50
40

0

PAo [mmHg]

QAo [ml/sec]

70
200

30
0

5

10

15

20

25

30

40
35
Time [sec]

45

50

55

60

65

70

Figure 6. Short constriction of the aorta at the ascending position with subsequent release after about 20 seconds.

C decreases. Again, although small compared to the effects of the constriction, slight changes of the parameters
can be observed after the constriction due to the regulatory
mechanisms described above.
As seen in both experiments, the assumed proportionality between pressure and volume to model the compliance
C is only valid within a limited range that has been exceeded during the experiments. Based on this findings it
can be considered to revise the model accordingly. Here,
the major advantage of the here presented concept consists
in the fact that such model adaption can be implemented
quickly.
The limitations considering what can be modeled are
mostly determined by the features yet supported by JModelica.org, CasADi and Ipopt. A major limitation is the
requirement of the model equations to be twice continuously differentiable (Wchter and Biegler, 2005) for each
optimization variable. This prohibits the use of switching components that commonly include if...else statements. In our applications, this affects models containing
heart valves. To work around this limitation continuous
approximations have been used (Gesenhues et al., 2016,
2017).
On a standard personal computer, the average computation time for a valid result was 0.45 sec for the first experiment and 0.36 sec for the second experiment. Since the
DOI
10.3384/ecp17132613

solution of the preceding optimization are used as the initial trajectories for the solver, the solution converges faster
if there is less change of the parameters between horizons.
Currently, a limitation of the current design of the routine of the optimization module is the requirement of the
preceding optimization being finished before the next optimization can be started. Consequently, the time between
two horizons T needs to be chosen sufficiently high to
avoid additional delays from waiting for the preceding optimization to finish. Settings that affect the solution time
include the number of collocation elements and the number of collocation points within the discretization of the
optimization problem.
For verification purposes and to investigate the impact
of the length of the horizon TH , a test case has been constructed based on data obtained by a simulation of the
model. Here, the exact parameter values that should result out of the identification are known. All three parameters have been varied during the simulation to evaluate the
dynamical effects of the identification procedure. Using a
sinus signal as input for PAo (t) and a constant signal for
PCV (t), the resulting QAo (t) was obtained. The so artificially created signals were used to emulate the sensor signals. The results of this test case are contained in Figure
8. As it can be seen, a smaller value for the horizon length
TH results in a faster response to changing parameters. On

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

619

Towards Medical Cyber-Physical Systems: Modelica and FMI based Online Parameter Identification of the
Cardiovascular System
Constriction

Z [mmHg sec/ml]

0.08
0.06
0.04
0.02

1.5
1
0.5
4
Valid Result
Invalid Result

3
2
1

QAo [ml/sec]

400

140
120
100
80
60
40

300
200
100
0
0

10

20

30

40

50

60

70
80
Time [sec]

90

100

110

120

130

140

PAo [mmHg]

C [ml/mmHg]

R [mmHg sec/ml]

2

150

R [mmHg sec/ml]

In the future, it is planned to further evaluate the concept considering other aspects of the cardiovascular system. Besides, further improvements to the optimization
module will be made to improve the robustness and the
performance. This includes canceling optimizations that
do not converge within a given time. Similarly, it will be
considered to adapt the time between horizons T depending on the necessary solution time. Another interesting
idea that has come up is the synchronization of the horizons to heartbeats. Besides, improvements will be made
to the setup work flow aiming at eliminating the need to
adapt the Python code for new setups. Furthermore, we
will be looking into changing the settings of within the
optimization module through the ModeliChart interface
without the need to stop and restart the optimization module.

0.25

TH = 0.5 sec
TH = 1.5 sec
TH = 5 sec
Actual Values

0.2
0.15
0.1
2
1.5
1
1.6

C [ml/mmHg]

the other hand, fluctuations are more damped for bigger
values of TH . Especially in the presence of noise, choosing a bigger value for TH might be preferable. However,
significant parameter changes within the horizon lead to
invalid results (the outliers for TH = 5 sec in Figure 8).

Z [mmHg sec/ml]

Figure 7. Long constriction at the descending position of the aorta.

1.4
1.2
1
0

20

40
60
Time [sec]

80

100

Concluding, the concept that has been integrated into Figure 8. Verification trough identification of known parameter
our lab infrastructure presents a valuable addition for our values for different horizon lengths TH . The outliers in the TH =
5 sec test are invalid results.
research on the cardiovascular system and has the potential to be used as a clinical tool in the future.
620

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132613

Session 9C: Acoustic & Medical Systems

Acknowledgments
This work was supported by the German Research Foundation (DFG) within the Smart Life Suport 2.0 PathoMod
project (PAK 183-2).

References
J. kesson, K.-E. rzn, M. Gfvert, T. Bergdahl, and
H. Tummescheit. Modeling and optimization with Optimica and JModelica.orglanguages and tools for solving
large-scale dynamic optimization problems. Computers &
Chemical Engineering, 34(11):17371749, November 2010.
doi:10.1016/j.compchemeng.2009.11.011.
Joel Andersson, Johan kessona, Francesco Casellad, and
Moritz Diehl. Integration of CasADi and JModelica.org.
In Proceedings from the 8th International Modelica Conference, Technical Univeristy, Dresden, Germany, pages
218231. Linkoping University Electronic Press, June 2011.
doi:10.3384/ecp11063218.
A. Brunberg, J. Maschuw, R. Autschbach, and D. Abel. Objectoriented model library of the cardiovascular system including
physiological control loops. In IFMBE Proceedings, pages
166169. Springer Nature, 2009. doi:10.1007/978-3-64203895-2_48.
John W. Clark, Robert Y. S. Ling, R. Srinivasan, J. S. Cole,
and Roderick C. Pruett. A two-stage identification scheme
for the determination of the parameters of a model of
left heart and systemic circulation. IEEE Transactions on
Biomedical Engineering, BME-27(1):2029, January 1980.
doi:10.1109/tbme.1980.326687.
European Commission. Joint report on health care and long-term
care systems & fiscal sustainability. European Economy Institutional Papers, (037), October 2016. doi:10.2765/680422.
Jonas Gesenhues, Marc Hein, Moriz Habigt, Mare Mechelinck,
Thivaharan Albin, and Dirk Abel. Nonlinear object-oriented
modeling based optimal control of the heart: Performing precise preload manipulation maneuvers using a ventricular assist device. In 2016 European Control Conference (ECC).
Institute of Electrical and Electronics Engineers (IEEE), June
2016. doi:10.1109/ecc.2016.7810603.
Jonas Gesenhues, Marc Hein, Maike Ketelhut, Moriz Habigt,
Daniel Rschen, Mare Mechelinck, Thivaharan Albin, Steffen Leonhardt, Thomas Schmitz-Rode, Rolf Rossaint, Rdiger Autschbach, and Dirk Abel. Benefits of object-oriented
models & ModeliChart: Modern tools and methods for the
interdisciplinary research on smart biomedical technology.
Biomedical Engineering / Biomedizinische Technik, 2017.
doi:10.1515/bmt-2016-0074.
Moriz Habigt, Maike Ketelhut, Jonas Gesenhues, Frank
Schrdel, Marc Hein, Mare Mechelinck, Thomas SchmitzRode, Dirk Abel, and Rolf Rossaint. Comparison of novel
physiological load-adaptive control strategies for ventricular
assist devices. Biomedical Engineering / Biomedizinische
Technik, 2016. doi:10.1515/bmt-2016-0073.

DOI
10.3384/ecp17132613

C.E. Hann, J.G. Chase, and G.M. Shaw.
Integral-based
identification of patient specific parameters for a minimal cardiac model.
Computer Methods and Programs in Biomedicine, 81(2):181192, February 2006.
doi:10.1016/j.cmpb.2005.11.004.
Maike Ketelhut, Frank Schrdel, Sebastian Stemmler, Jesse Roseveare, Marc Hein, Jonas Gesenhues, Thivarian Albin, and
Dirk Abel. Iterative learning control of a left ventricular assist
device. In 19th IFAC World Congress, Accepted for publication. Toulouse, France, 2017.
Ryo Kosaka, Yoshiyuki Sankai, Tomoaki Jikuya, Takashi Yamane, and Tatsuo Tsutsui. Online parameter identification of
second-order systemic circulation model using the delta operator. Artificial Organs, 26(11):967970, November 2002.
doi:10.1046/j.1525-1594.2002.07112.x.
Marek Matejk, Tom Kulhnek, Jan ilar, Pavol Privitzer,
Filip Jeek, and Jir Kofrnek. Physiolibrary - modelica
library for physiology. In Proceedings of the 10th International Modelica Conference, March 10-12, 2014, Lund,
Sweden. Linkoping University Electronic Press, March 2014.
doi:10.3384/ecp14096499.
Berno J.E. Misgeld, Daniel Rschen, Sebastian Schwandtner, Stefanie Heinke, Marian Walter, and Steffen Leonhardt.
Robust decentralised control of a hydrodynamic human circulatory system simulator.
Biomedical Signal Processing and Control, 20:3544, July 2015.
doi:10.1016/j.bspc.2015.04.004.
Ajay Moza, Jonas Gesenhues, Dirk Abel, Rolf Rossaint,
Thomas Schmitz-Rode, and Andreas Goetzenich. Patient
specific parameter estimation for cardiovascular system models based on clinical measurements. Biomedical Engineering / Biomedizinische Technik, 2017. doi:10.1515/bmt-20160078.
M Nichols, N Townsend, R Luengo-Fernandez, J Leal, A Gray,
P Scarborough, and M Rayner. European cardiovascular disease statistics 2012. european heart network, brussels, european society of cardiology, sophia antipolis. 2012. Cerebrovasc. Dis, 25:457507, 2012.
Daniel Rschen, Miriam Rimke, Jonas Gesenhues, Steffen
Leonhardt, and Marian Walter. Online cardiac output estimation during transvalvular left ventricular assistance. Computer Methods and Programs in Biomedicine, August 2016.
doi:10.1016/j.cmpb.2016.08.020.
Andreas Wchter and Lorenz T. Biegler. On the implementation
of an interior-point filter line-search algorithm for large-scale
nonlinear programming. Mathematical Programming, 106
(1):2557, April 2005. doi:10.1007/s10107-004-0559-y.
Nico Westerhof, Jan-Willem Lankhaar, and BerendE. Westerhof. The arterial windkessel. Medical & Biological Engineering & Computing, 47(2):131141, 2009. ISSN 0140-0118.
doi:10.1007/s11517-008-0359-2.
Yih-Choung Yu, J.R. Boston, M.A. Simaan, and J.F. Antaki.
Estimation of systemic vascular bed parameters for artificial
heart control. IEEE Transactions on Automatic Control, 43
(6):765778, June 1998. doi:10.1109/9.679017.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

621

622

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

The DLR RailwayDynamics Library: the Crosswind Stability
Problem
Andreas Heckmann1
1,2 Institute

Gustav Grether2

of System Dynamics and Control, German Aerospace Center (DLR), Germany,
andreas.heckmann@dlr.de

Abstract

dynamic properties and multibody simulations to study
the mechanical behavior of the railway vehicle under conHigh crosswinds affect the stability of railway vehicles, in sideration.
particular if they run on very high speed to reduce traveling time, if they are configured as double-deck cars to inWith this background, a subpackage of the DLR
crease the number of passenger seats and if they use light- RailwayDynamics Library (Heckmann et al., 2014a),
weight design in order to reduce life-cycle costs. This (Schwarz et al., 2015) has been implemented in Modelis why crosswind stability is an active field of research ica which aims at the assessment of railway vehicles with
within the project Next Generation Train. However, this respect to crosswind stability. To a large extent, the tool
field relies on the cooperation of two different domains, is oriented towards (EN 14067-6: 2010) and the simulanamely aerodynamics and vehicle dynamics. With this tion procedures defined there including a non-normative
background a crosswind stability tool was implemented in but promising stochastic approach in Appendix J. But beModelica as a part of the DLR RailwayDynamics Library. yond that, the implementation is intended to support varThis tool gathers data from scaled wind tunnel measure- ious research activities in aerodynamics and vehicle dyments and multibody data on the railway vehicle in order namics control within the NGT project, see e.g. (Fey et al.,
to rapidly analyze and assess the risk of overturning due 2014), (Heckmann et al., 2014b).
to high crosswinds. To a large extent the tool is oriented
towards the associated homologation rules and standards.
However, the tool is as well supposed to support future 1.2 Overview on Vehicle Assessment
advancements of these standards by providing capabilities
for the stochastic analysis of the crosswind stability probThe basic assessment scenario is defined in (EN 14067-6:
lem.
vehicle dynamics, aerodynamics, railway vehicles, cross- 2010) as follows: At given train speed, wind velocity and
wind stability, aerodynamic admittance, stochastic analy- wind direction, aerodynamic forces and torques are applied to a multibody train model. These applied forces and
sis
torques lead to an unloading of the wheels at the windward
side of the train. This unloading is interpreted to indicate
1 Introduction
the risk of overturning.

1.1

Motivation

Crosswind stability addresses the risk, that vehicles running on high speed are prone for overturning, if high crosswinds occur. At DLR, it is a particular subject of research,
since the long-term internal project Next Generation Train
(NGT) copes with three key features that aggravate the
problem: it is a very high-speed train in double deck configuration and light-weight design. Nevertheless, this train
concept has been proposed since it facilitates objectives
such as low energy consumption and low life-cycle costs
per passenger even for reduced traveling times.
From the technical point of view, crosswind stability is
a multidisciplinary issue, since aspects of aero- and vehicle dynamics have to be taken into account. This is why
the homologation rules, specified by regulation of the European Commission (TSI HS RST 2008) and the associated standard (EN 14067-6: 2010) address both: scaled
wind tunnel experiments in order to characterize the aeroDOI
10.3384/ecp17132623

In detail, a major assessment issue is the so-called critical wind speed that is defined as the wind velocity, at
which 90 % wheel unloading compared to the static load
occurs. In general, the evaluation procedure requires to iteratively vary the wind velocity as an input parameter till
the multibody simulation results show that the remaining
wheel load is 10 % of the static load.
The critical wind speed is evaluated for several train
velocities, these sample points are then connected to
construct a curve called the Characteristic Wind Curve
(CWC). In order to meet the homologation criterion the
CWC of the considered vehicle must completely run
above the Characteristic Reference Wind Curve (CRWC)
defined by (TSI HS RST 2008). As illustrative examples,
Fig. 1 presents the CWC of the NGT train head which
meets the homologation criteron, while the initial NGT
coach design does not.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

623

The DLR RailwayDynamics Library: the Crosswind Stability Problem

NGT train head
NGT coach
CRWC TSI

38

wind velocity u [m/s]

36
34
32
30
28
26
24
22

150

200

250

300

350

400

vehicle speed v [km/h]

Figure 1. Characteristic Wind Curve (CWC) of the NGT
train head and the NGT coach compared to the reference curve
CRWC from (TSI HS RST 2008), cf. (Heckmann et al., 2014b).

2
2.1

Figure 3. Calculated streamlines and pressure distribution on
the NGT model scale 1:25 in the Cologne Cryogenic Wind Tunnel under cross wind conditions, see (Heckmann et al., 2014b).

Aerodynamic Loads
Fundamentals

The above described assessment scenario requires to specify loads, i.e. the aerodynamic forces and torques that are
to be applied to the mechanical train model. These loads
are commonly expressed by means of aerodynamic coefficients ci = ci ( ) and c j = c j ( ) as function of the yaw
angle  as follows (Baker et al., 2009):
1
fi =  A ci ( ) V 2
2
1
m j =  A h c j ( ) V 2 .
2

Eq. (1) and (2) define the aerodynamic loads as a function of V which in turn depends on the wind velocity u according to Fig. 2 or more general, on the underlying wind
gust model. Three different approaches to represent the
wind gust are implemented in the Modelica RailwayDynamcis Library:
1. Steady approach: u = const

(1)
(2)

In (1) and (2), fi and m j represent the vector components
of force and torque,  is the density of the air, A and h
the reference area and height, respectively. V denotes the
wind speed relative to the vehicle, which follows from
vectorial decomposition considering the vehicle speed v,
the wind velocity u and the angle w between track and
wind, see Fig. 2.

2. Quasi-steady approach: Eq. (1) and (2) are assumed
to be valid even if the wind velocity changes in time,
i.e. u = u(t). In detail, (EN 14067-6: 2010) defines
the so-called Chinese Hat gust model in Fig. 4 which
specifies a wind field fixed along the track at which
the vehicle runs at constant speed v. For (1) and (2),
u then follows from u = u(s) = u(v  t),
3. Unsteady approach: The mean wind forces fi and
torques m j are superimposed with fluctuating parts
fi0 and torques m0j (Baker, 1991), i.e.
fi = fi + fi0 ,

m j = m j + m0j ,

(3)

Figure 2. Vector decomposition to evaluate the wind speed relative to the vehicle V .

crosswind velocity u [m/s]

30
25
20
15
10

5
It is state-of-the art to identify aerodynamic coefficients
in scaled wind tunnel measurements as visualized in Fig. 3
0
0
500
1000
1500
2000
2500
3000
3500
and normalize the results with A = 10 m2 and h = 3 m acposition s [m]
cording to (TSI HS RST 2008). Note that the (EN 140676: 2010) also approves numerical CFD simulation under Figure 4. Crosswind velocity definition "Chinese Hat" according to (EN 14067-6: 2010).
certain conditions.

624

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132623

Session 9D: Wind & Naval Engineering

1.2

90
80

u = 20 m/s

70

u = 30 m/s

aerodynamic admittance |XK |2 []

power spectral density Su [m2/s]

u = 10 m/s

60
50
40
30
20
10
0 2
10

1

0

10

10

1

0.8

0.6

0.4

0.2

1.0, 1.0, 1.0
1.0, 0.6, 2.0
1.0, 1.0, 2.0
1.0, 2.0, 2.0

0 2
10

1

10

Figure 5. Power spectral density example of the turbulent wind
according to (Cooper, 1984) for three different wind velocities
u, train speed v = 400 km/h and wind angle w = 90 .

1

10

0

10

1

10

normalized frequency f[]

frequency f [Hz]

Figure 6. Aerodynamic addittance function for various parameter triples k,  , f.

lag, so that an additional dynamics transfer behavior has
which are specified in the frequency domain as de- to be considered by the aerodynamic admittance function
scribed in the next section.
|XK ( f )|2 for each of the six force or torque components K
and their associated spectra SK :
2.2 Unsteady Aerodynamics
Unsteady wind may be approximated as a Gaussian
stochastic process and therefore may be characterized by
the power spectral density (PSD). Cooper derived the following wind spectrum relative to the moving vehicle Su as
function of the frequency f (Cooper, 1984):


4 f
u2
0.5 + 94.4 f2
Su =
c
+
(1

c
)
(4)
u
u
f [1 + 70.8 f2 ] 56
1 + 70.8 f2

|XK ( f )|2 :=

SK
1
,
(Ack u)2 Su

k = i, j , K = fi0 , m0j . (6)

The measurement of the aerodynamic admittance for
high-sped trains is a field of active research, which the
RailwayDynamics Library is supposed to support. As
an initial approach, it is refered to the following model,
which uses three free, dimensionless parameters k, f and

that include the following definitions and parameter val-  , which are fitted to approximate wind tunnel measurements as good as possible (Sterling et al., 2009):
ues:
2
1
 the coefficient cu : cu = Vu cos w + Vu .
(7)
|XK ( f )|2 :=
!


  2 2 h  i2 2
 the root mean square of the wind velocity fluctuak 1  ff
+ 2 ff
tions u : u = 0.245  u, here inserted according to
(EN 14067-6: 2010).
Fig. 6 gives an impression on parameter values from liter the turbulence length scale in wind direction x Lu:
ature specifying the aerodynamic admittance.
x Lu = 96.0395 m, see (EN 14067-6: 2010).

 the compound
p length scale Lu :
Lu = x Lu cu + 0.706(1  cu )
 the normalized frequency f: f = f LVu
Fig. 5 shows exemplary spectra in order to illustrate (4).
In order to generate a representation of Su in time domain, the fluctuation wind velocity u0 may be evaluated by
superimposing n discretized frequencies fi with amplitude
Ai = Ai ( fi ) and random phase i :
q
n
u0 =  Ai sin(2 fi  t + i ) , Ai = 2Su,i ( fi+1  fi ) . (5)
i=1

In reality, it has been observed that force fluctuations dont
follow wind velocity fluctuations without attenuation or
DOI
10.3384/ecp17132623

3

Vehicle Dynamics

The (EN 14067-6: 2010) refers to three vehicle models
with increasing complexity:

 The 2D three-mass model, which is not implemented
in the RailwayDynamics Lib.
 The five-mass model without wheel-rail contact
which is supposed to be used in a steady-state scenario.
 The multibody model with wheel-rail contact which
is intended to be utilized for transient simulation
tasks, in which quasi-steady or unsteady aerodynamic loads are applied.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

625

The DLR RailwayDynamics Library: the Crosswind Stability Problem

3.1

The Simplified Five-Mass Model

Fig.7 presents the structure of the five-mass model, as it
is defined in (EN 14067-6: 2010, Appendix H) It considers two unsprung bodies which are the wheelsets of the
railway vehicle, two primary suspended bodies representing the bogie frames including all attachments and the car
body, which is connected to the bogies via secondary suspensions.
The four wheel-rail forces Qi j , i, j = 1, 2, in Fig.7 are interpreted as supporting or reaction forces due to the condition that the wheels do no lift off. Note, that at most
90 % wheel unloading is permitted which in turn defines
that lift-off or loss of contact at the wheel-rail interface is
not admissable and motivates to disregard the wheel-rail
contact for the sake of simplicity.
The model takes all together 11 degrees of freedom into
account. These are the lateral, vertical and roll motion
of bogies and the car body, which may in addition rotate
around its pitch and yaw axis. The vertical and lateral
spring elements of the primary and secondary suspensions
are equipped with bump stops specified by a non-linear
stiffness characteristic as well proposed in (EN 14067-6:
2010, Appendix H). The rotational stiffness of an anti-roll
bar as part of the secondary suspensions is supposed to
reduce the tilting of the carbody due to wind torques acting
around the longitudinal or x-axis.
Since this model is used in a steady-state scenario, transient behavior or modeling of damping devices actually is
irrelevant but nevertheless is introduced in parallel to all
spring elements. Due to the bump stops, the model is nonlinear and the analysis is organized as a time simulation
that is intended to converge against its final and steady
state as a result of the applied constant wind loads.
In summary, the five-mass model is supposed to facilitate a simple analysis to be feasible in early engineering
phases yielding conservative results with comparable low
critical wind speeds. To this aim, the suspension elements
are not modeled considering design details but are represented by a set of generalized stiffness parameters and

Figure 7. Structure of the simplified five-mass model according
to (EN 14067-6: 2010).

626

Figure 8. Animation of the five-mass-model.

very essential geometric information. Fig. 8 shows an animation of the five-mass model in Modelica.

3.2

The Multibody Model

The multibody model to described here is tailored to the
lightweight intermediate car of NGT project, but may easily adapted to conventional high-speed railway vehicles.
The most prominent up-grade to the five-mass model concerns the non-linear wheel-rail contact that is considered
on basis of the geometry of the standarized UIC 60 rail
and the WS 1002 profile geometry.
To this aim, the Modelica RailwayDynamics Library
(Heckmann et al., 2014a) employs the distance  =
(s, y, , ) as a function of the wheel profile coordinate s,
s  s  s, and the lateral displacement, roll and yaw angle
between wheel and rail, see Fig. 9. The contact position
s defined as a weighted mean value of s using the regularization parameter  is a continuous function of y,  and
 and thus constitutes a smooth contact formulation, see
(Arnold and Netter, 1997):
Z s



s e  ds
s

s := Z

s

.



(8)

e  ds
s

However for transient analysis, the (EN 14067-6: 2010)
allows to monitor the wheel-rail forces utilizing a 2 Hz
low-pass filter to evaluate the wheel unloading criterion.
Therefore, it cannot be completely ruled out that loss of
contact occurs and is admissible for very short time periods. In addition, overloading and in turn wheel lift-off

Figure 9. Sketch to illustrate the wheel-rail contact quantities
(exaggerated presentation of the penetration  ).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132623

normal force fN [kN]

Session 9D: Wind & Naval Engineering

14

original Hertzian force law

12

regularized force law

10
8
6

0

4
2
0
20

15

10

5

0
5
10
penetration  [m]

15

20

25

30

Figure 10. Illustration of the regularized contact force law.

may occur during the iteration process to determine the
critical wind speed.
In order to take this into account, the wheel-rail contact algorithm of the Modelica RailwayDynamics Library
had to be adapted. In particular the kinematic constraint
(Heckmann et al., 2014a, (6)) is replaced by a regularized
penalty contact formulation, in which the penetration  of
the wheel and the rail body in Fig. 9 features a non-linear
spring element to evaluate the normal contact force fN according to the Hertzian theory (Hertz, 1882):
(
2
 < 0 : a  eb(c+ ) ,
(9)
fN =
3
  0 : cH   2 ,

Figure 11. Structure of the multibody model of the NGT intermediate car (all springs include dampers connected in parallel).

Sec. 3.1 that requires the consideration of all together
31 degrees of freedom which are indicated in Fig. 11.
Apart from that, the multibody model, whose animation
is shown in Fig. 12, sticks to the concept of the five-mass
model to present all suspension elements by a set of generalized stiffness and damping parameters and very essential
3 3
3
2
geometric information. This modeling idea is well suited
where 0 > 0, a := cH e 4 0 , b := 4 2 , c := 20 .
0
to be used in early engineering phases, when detailed inThe coefficient cH is a function of the material proper- formation on the design of the suspensions are not yet
ties and the local curvatures of the contact partners at the available and therefore fits to the scope of the Railwaypoint of contact, while a, b and c are defined in such a way Dynamics Library.
that fN is two times continuously differentiable for all val3.3 Negotiating Curves
ues of  and in particular for  = 0 , see Fig. 10. The
proposed regularization prevents chattering in the vicin- For comfort reason, the maximum lateral acceleration that
ity of wheel lift-off situations and therefore improves the passengers are supposed to experience while the vehicle
numerical robustness. In addition, this elastic contact, to is negotiating curves is restricted to 1m/s2 . Therefore, the
be distinguished to the quasi-elastic formulation in (Heck- lay-out of railway tracks also includes superelevations and
mann et al., 2014a), requires damping to be numerical fea- the maximum speed at which the vehicles runs through the
sible.
curve is limited as a function of curve superelevation and
It is state of the art in multibody analysis of railway ve- radius in order to meet this requirement.
hicles to take the elastic compliance of the track into acThis property is exploited by the (EN 14067-6: 2010) to
count that is excited by large wheel-rail forces. This is in
particular important if these forces are a significant result
of the analysis. Therefore, the track superstructure shown
in Fig. 11 is presented as one body with three sprung and
damped degrees of freedom, which is assumed to follow
each wheel pair as a so-called moving track model, e.g.
see (Iwnicki, 2006, Ch. 12)
The NGT running gears use so-called independently rotating wheel sets (IRW set) with two wheels attached to
a wheel carrier. Active guidance control (Kurzeck et al.,
2014) provides running stability and low wear properties
of this configuration which is a main objective of the NGT
project.
In order to be consistent, these model upgrades impli- Figure 12. Animation of the NGT intermediate car multibody
cate a more complex motion composition compared to model.
DOI
10.3384/ecp17132623

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

627

The DLR RailwayDynamics Library: the Crosswind Stability Problem

Figure 14. Parameter menu of the scenario data record.
Figure 13. Diagram layer of a crosswind stability model of the
Modelica RailwayDynamics Library.

address the crosswind stability while negotiating curves.
The evaluation of the CWCs are additionally parametrized
with the so-called unbalanced lateral acceleration aq ,
which can take values between 1 and 1 [m/s2 ] , i.e.
1m/s2  aq  1m/s2 . The introduction of this parameter into the Modelica crosswind scenario is straight forward by specifying the direction and value of the gravity
vector accordingly.

4

Implementation

In order to determine the critical wind speed, a function find_Vcwc is defined, which iteratively simulates the
crosswind stability model, while the wind speed is varied
systematically. The function terminates and returns the
critical wind speed, if the model simuation results show
90% wheel unloading:
f u n c t i o n find_Vcwc
i n p u t R e a l v V e h i c l e _ k m h ( u n i t = "km / h " ) =80 "
v e h i c l e speed " ;
i n p u t S I . A n g l e betaW=
Modelica.SIunits.Conversions.from_deg
( 9 0 ) " wind a n g l e " ;
i n p u t S I . A c c e l e r a t i o n aq =1 " u n b a l a n c e d
lateral acceleration " ;
i n p u t S I . V e l o c i t y vW[ 2 ] = { 2 0 , 3 0 } " r a n g e t o
l o o k f o r v_cwc " ;
i n p u t S t r i n g modelName ;
input Real t o l e r a n c e =0.1 " t o l e r a t e d
d e v i a t i o n of t a r g e t unloading =0.9 " ;
i n p u t R e a l t _ s t o p =110 " end t i m e "
o u t p u t S I . V e l o c i t y v_cwc ;

Fig. 13 gives an overview on the structure of a crosswind stability model of the Modelica RailwayDynamics
Library. Vehicle data are separated from the model instances and organized by data records, which in turn are
substructured in aerodynamical and mechanical information. Another record called Scenario organises information to perform the specific simulation task, see Fig. 14.
Wind generation, aerodynamical load evaluation and
A second function plot_CWC not only evaluates one
vehicle running dynamics are separated in three model
critical wind speed, but provides a plot of the critical wind
components, so that it is easy to exchanged e.g. the
curve as shown in Fig. 1.
stochastic wind with a chinese hat wind gust instance or
f u n c t i o n plot_CWC
subsitute steady for unsteady aerodynamic approach.
" i t e r a t i o n p r o c e s s t o e v a l u a t e v_cwc=
In order to facilitate robust initialization, the application
v_cwc ( v V e h i c l e , b e t a W , aq ) "
of the aerodynamic loads fi and m j from (3) is delayed in
i n p u t R e a l v V e h i c l e _ k m h [ 2 ] ( u n i t = "km / h " )
time using a first order low pass filter with time constant
={120,400} " c o n s i d e r e d speed range " ;
t0 , i.e.:
i n p u t S I . A n g l e betaW=
fi = (1  e

 tt

0

) fi ,

 tt

m j = (1  e

0

) m j.

(10)

The railCar instance in Fig. 13 provides the wheelunloading of each running gear as a function of time,
which then is low-pass filtered according to (EN 140676: 2010). The output of the max() block evaluates the
final simulation result or the crosswind stability criterion,
respectively.
628

Modelica.SIunits.Conversions.from_deg
( 9 0 ) " wind a n g l e " ;
i n p u t S I . A c c e l e r a t i o n aq =1 " u n b a l a n c e d
lateral acceleration " ;
i n p u t S I . V e l o c i t y vW[ 2 ] = { 2 0 , 3 0 } " r a n g e t o
l o o k f o r v_cwc " ;
i n p u t S t r i n g modelName ;
i n p u t I n t e g e r n u m b e r O f V v e h i c l e s = 15 "
number o f s p e e d s a m p l i n g p o i n t s " ;
input Real t o l e r a n c e =0.1 " t o l e r a t e d
d e v i a t i o n of t a r g e t unloading =0.9 " ;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132623

Session 9D: Wind & Naval Engineering

40

i n p u t R e a l t _ s t o p =110 " end t i m e "
o u t p u t S I . V e l o c i t y v_cwc [
numberOfVvehicles ] ;

Exemplary Results

5.1 The Five-Mass Model
The (EN 14067-6: 2010) offers the opportunity to verify
the implementation of the steady scenario with the fivemass model, since its Appendix H contains the input data
and the results of two example vehicles. Fig. 15 presents
a comparison of Modelica RailwayDynamcis Library results with the CWC from the EN standard for Vehicle 2
and two unbalanced accelerations. The large correspondence of results can be stated, a slight derivation only occurs for v = 80 km/h vehicle speed, which is to be further
investigated.
The CWC of the NGT in Fig. 1, which has been introduced in order to give an overview on the vehicle assessment methodology in Sec. 1.2, has also been generated using the five-mass model, see also (Heckmann et al.,
2014b) for a more detailed discussion.

5.2

The Multibody Model of the NGT Coach

With the exception of Fig. 19, all results to be given in this
section have been obtained using the scenario shown in
Fig. 14, which will turn out to lead to 90% wheel unloading. The associated transient wind velocities are plotted in
Fig. 16.
The parameters to be used in (6) are intended to be
gained in wind tunnel measurements, which are not yet
available. Therefore, hypothetical addmittance parameters have been introduced in order evaluate preliminary
and exemplary results. Following a proposal of (Baker,
2010), the values below have been chosen for the most
important force and torque components:
side force:
k = 1,  = 1,
lift force:
k = 1,  = 1,
roll moment: k = 1,  = 1,

f = 2.0  sin( ),
f = 2.5  sin( ),
f = 2.0  sin( ).

wind velocity u, u + u| [m/s]

5

buffeting wind
35

mean wind velocity

30
25
20
15
10
5
0

20

40

60

80

100

time t [s]

Figure 16.
Transient velocities of buffeting wind (u =
22.307 m/s, u = 0.245  u , w = 90 , v = 140 km/h).

The admittance of all other wind load components have
been set to |XK ( f )|2 := 1 as recommended in (EN 140676: 2010, Appendix J).
Fig. 17 presents the transient wheel forces, which all
start from the static wheel load fw (t = 0) = 57727 N, since
the wind loads are applied according to (10) with time
constant t0 = 2 s.
The lowest frequency that has been considered in (5)
to transfer the PSD in Fig. 5 into the time domain is
f1 = 0.01 Hz. In the (EN 14067-6: 2010, Appendix J),
it is proposed to choose the simulation time in such a way,
that one full period of the lowest frequency is covered, i.e.
100 s here. The additional 10 s have been appended in order to account for the low passed filtered load application
at the beginning of the simulation. Note, the (EN 140676: 2010) requests to repeat this simulation with different
random phases i in (5) and to statistically determine the
mean value of the critical wind velocity and its confidence
interval.
The fifth curve in Fig. 17 displays the low pass filtered
wheel unloading that reaches the crosswind stability criterion at t = 90.3 s.

(11)
4

x 10

Modelica: aq = 0 m/s2

wind velocity u [m/s]

45

EN14067: aq = 1 m/s2
40

Modelica: aq = 1 m/s2

35
30
25
20
80

100

120
140
160
vehicle speed v [km/h]

180

200

Figure 15. Comparison of the CWC evaluated in Modelica with
(EN 14067-6: 2010), Vehicle 2 in Appendix H.

DOI
10.3384/ecp17132623

10

1.0

8

0.8

6

0.6

leeward leading wheel
unloading

windward leading wheel
4

unloading [-]

EN14067: aq = 0 m/s2

vertical wheel force fN [N]

12

50

0.4

leeward trailing wheel
windward trailing wheel

2
0
0

0.2

20

40

60

80

100

0

time t [s]

Figure 17. Transient vertical wheel force and unloading results
based on hypothetical admittance parameters.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

629

The DLR RailwayDynamics Library: the Crosswind Stability Problem

leeward train side

windward train side

Figure 18. Wheel-rail contact configuration with flange contact
at the leeward train side

Fig. 18 illustrates the corresponding contact configuration between wheel and rail. Due the lateral wind load
the complete car is displaced in lateral direction until the
wheel flange is touched and counteracts the load force.
Fig. 19 shows the CWC of the NGT coach, which summarizes the critical wind velocities for 15 different vehicle speeds (aq = 0 m/s2 ). Note, that all curves in Sec. 5.2
are preliminary results. Measured admittance functions
for the NGT are not yet available, so that the associated parameters only have been chosen on a trial basis.
The introduced root mean square of the wind fluctuations
u = 0.245  u that lead to rather large peaks of the wind
velocities in Fig. 16 is another parameter to be substantiated in the future.
182 cpu-s on a lap-top with Core-i7 processor and 2.9
GHz clock rate were required to get the above given results associated to 110 s simulation time. It took less than
an hour to evaluate the CWC in Fig. 19, which relies on
an iterative process to obtain the critical wind velocity for
all 15 vehicle speeds.

6

Conclusions and Outlook

Dynamics Library has been implemented. The tool offers
the capability of use and combine several vehicle models
and aerodynamic approaches in order to assess the crosswind stability of railway vehicles.
The consideration of unsteady aerodynamics within this
task is a active field of research at DLR. The current focus
is the measurement of the aerodynamic admittance function in a reproduceable and reliable manner. The RailwayDynamics Library now affords to rapidly analyze the vehicle dynamics once a aerodynamic admittance is available
and that way provides a quick insight on further implications with respect to the risk of overturning.
Another future field of application of the presented capabilities concerns the dimensioning of suspension parameters of a railway vehicle in early engineering phases.
Although the multibody model considers all relevant degrees of freedom and suspension components only moderate computational resources are required. The employment of the vehicle dynamics model in optimization tasks
seems to be feasible, which may include multiple design
objectives such as passenger comfort or running behavior
besides crosswind stability.

Acknowledgment
An initial version of the Modelica crosswind stability tool
has been implemented by Dr. Antonio Carrarini during his
period of employment at DLR.
Wind tunnel measurements on the steady aerodynamics
of the NGT have been provided by Sigfried Loose and his
colleagues from the DLR Institute of Aerodynamics and
Flow Technology, see Fig. 3 and cf. (Heckmann et al.,
2014b).

References
M. Arnold and H. Netter. Wear profiles and the dynamical simulation of wheel-rail systems. Progress in Industrial Mathematics at ECMI, 96:7784, 1997.

In the course of the DLR project Next Generation Train Chris Baker, Federico Cheli, Alexander Orellano, Nicolas
Paradot, Carsten Proppe, and Daniele Rocchi. Cross-wind
the subpackage CrosswindStability of the DLR Railway-

effects on road and rail vehicles. Vehicle System Dynamics,
47(8):9831022, 2009. doi:10.1080/00423110903078794.

NGT coach
CRWC TSI

wind velocity u [m/s]

38

34

C.J. Baker. Ground vehicles in high cross winds part II: unsteady
aerodynamic forces. Journal of fluids and structures, 5(1):
91111, 1991.

30

C.J. Baker. The simulation of unsteady aerodynamic cross wind
forces on trains. Journal of Wind Engineering and Industrial
Aerodynamics, 98(2):8899, 2010.

26

22

18
120

160

200

240

280

320

360

400

vehicle speed speed v [km/h]

Figure 19. Preliminary critical wind curve of the NGT coach
based on hypothetical admittance parameters for stochastic analysis.

630

R.K. Cooper. Atmospheric turbulence with respect to moving
ground vehicles. Journal of wind engineering and industrial
aerodynamics, 17(2):215238, 1984.
EN 14067-6: 2010. Railway Applications -Aerodynamics- Requirements and test procedures for crosswind assessment.,
2010.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132623

Session 9D: Wind & Naval Engineering

Uwe Fey, Johannes Haff, Mattias Jnsson, Sigfried Loose, and
Claus Wagner. Experimental investigation of topological
changes in the flow field around high-speed trains with respect to reynolds number scaling effects. In J. Pombo, editor,
The Second International Conference on Railway Technology: Research, Development and Maintenance, number P32
in Civil Comp Proceedings, pages 120. Civil-Comp Press,
Stirlingshire, UK, 2014. doi: 10.4203/ccp.104.32.
A. Heckmann, A. Keck, I. Kaiser, and B. Kurzeck. The Foundation of the DLR RailwayDynamics Library: the Wheel-RailContact. In 10th International Modelica Conference, 2014a.
Andreas Heckmann, Bernhard Kurzeck, Tilman Bnte, and
Sigfried Loose. Considerations on active control of crosswind stability of railway vehicles. Vehicle System Dynamics,
52(6):759775, 2014b.
Heinrich Hertz. ber die Berhrung fester elastischer Krper.
Journal fr die reine u. angewandte Mathematik, 92, 1882.
S. Iwnicki. Handbook of railway vehicle dynamics. CRC Press,
2006.
B. Kurzeck, A. Heckmann, C. Wesseler, and M. Rapp. Mechatronic track guidance on disturbed track: the trade-off between actuator performance and wheel wear. Vehicle System
Dynamics, 52(sup1):109124, 2014.
Christoph Schwarz, Andreas Heckmann, and Alexander Keck.
Different models of a scaled experimental running gear for
the DLR RailwayDynamics Library. In 11th International
Modelica Conference, 21.-23. Sep. 2015, 2015.
Mark Sterling, Chris Baker, Abdessalem Bouferrouk, Hugh
ONeil, Stephen Wood, and Ewan Crosbie. An investigation
of the aerodynamic admittances and aerodynamic weighting
functions of trains. Journal of Wind Engineering and Industrial Aerodynamics, 97(11):512522, 2009.
TSI HS RST 2008. 2008/232/EC: Commission Decision of 21
February 2008 concerning a technical specification for interoperability relating to the rolling stock sub-system of the
trans-european high-speed rail system, 2008.

DOI
10.3384/ecp17132623

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

631

632

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

R


The OneWind Modelica Library for Floating Offshore Wind
Turbine Simulations with Flexible Structures
Mareike Leimeister Philipp Thomas
Fraunhofer Institute for Wind Energy and Energy System Technology IWES Northwest, Germany,
{mareike.leimeister,philipp.thomas}@iwes.fraunhofer.de

Tasks4 , floating wind turbine systems are included.
In order to contribute to code-to-code comparison
Floating offshore wind turbines are getting more and more analyses, a fully flexible model for floating wind turbine
R
into the focus of interest, as industries aim for larger tur- systems is developed in the OneWind
Modelica Library.
bines and deeper water areas. Fully coupled analyses of
those highly complex systems are challenging. In this paIn this paper, first, the different components of a
per, the hierarchical programming structure in Modelica is floating offshore wind turbine system and their impleused to model a fully flexible floating wind turbine system. mentation in Modelica, based on the Modelica MultiBody
The single components, as well as special difficulties that Library, are explained in Chapter 2. Chapter 3 outlines
have to be dealt with during modeling, are addressed. On the limitations of the implemented floating wind turbine
basis of a reference floating offshore wind turbine, the im- model. The OCx offshore wind turbine designs, elaboplemented fully flexible model is compared with its rigid rated in the IEA Wind Tasks, are used in Chapter 4 as
equivalent, as well as results from code-to-code compar- basis for comparison of reference load case simulation
isons of free-decay simulations. The findings are satisfac- results, as well as for demonstrating the high flexibility
tory and confirm the theoretical assumptions. In addition, for adaptions and ease of model modifications. Finally,
further applications of the created model are shown.
Chapter 5 summarizes the developed approach and gives
Keywords: offshore wind energy, floating platform, fully recommendations for further work on fully flexible
coupled aero-hydro-servo-elastic simulation, Euler- floating offshore wind turbine systems in Modelica.
Bernoulli beam, OneWind Modelica Library, MultiBody

Abstract

1

Introduction and Outline

Many promising offshore sites for wind energy utilization
are in deep water. For water depths larger than 50 m,
commonly used bottom-fixed foundations, as for example
monopiles, jackets, or tripods, are no longer suitable.
However, floating platforms, such as spar-buoys, semisubmersibles, or TLPs (tension leg platforms), could be a
potential solution for deep water operations. Easier and
faster installation due to onshore assembly, as well as
reduced noise during erection are some advantages that
floating support structures have over bottom-fixed designs. On the other hand, floating wind turbines are very
complex systems. Motion-coupling, wave excitation, and
additional components like mooring lines are inter alia
new challenges for accurately modeling and simulating
those systems, and allowing fully coupled load analyses.
Extensive research on floaters is conducted and several
prototypes are designed1,2,3 . Even in the IEA Wind
1 https://www.statoil.com/en/news/hywindscotland.html
(Accessed: 02 March 2017)
2 http://principlepowerinc.com/en (Accessed: 02 March 2017)
3 http://ideol-offshore.com/en (Accessed: 02 March 2017)

DOI
10.3384/ecp17132633

2

Components and Implementation in
Modelica

Object-oriented programming in Modelica enables a hierarchical structure of the complex wind turbine system.
The implemented floating wind turbine model contains six
main components (rotor, nacelle, operating control, support structure, wind, and waves), which are possibly using further subcomponents, as presented in the following
Modelica code and in Figure 1.
model O f f s h o r e W i n d T u r b i n e
e x t e n d s O ne W i nd .W in d T u r bi n e . O ff s h or eW T
(
/ / === r o t o r ===
, r e d e c l a r e model R o t o r = OneWind.Rotor
(
r e d e c l a r e record RotorData
, r e d e c l a r e model Hub
, r e d e c l a r e model B l a d e
)
/ / === n a c e l l e ===
, r e d e c l a r e model N a c e l l e =
OneWind.Nacelle
4 http://www.ieawind.org/taskWebSites.html
September 2016)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(Accessed:

23

633

The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures

(
redeclare
, redeclare
, redeclare
, redeclare

record
model
model
model

NcData
Drivetrain
Generator
YawController

)
/ / === o p e r a t i n g c o n t r o l ===
, r e d e c l a r e model O p e r a t i n g C o n t r o l =
OneWind.OperatingControl
(
redeclare record OperatingControlData
, r e d e c l a r e model M a i n C o n t r o l
(
r e d e c l a r e model P i t c h C o n t r o l
, r e d e c l a r e model
GeneratorTorqueControl
)
, r e d e c l a r e model G e n e r a t o r S p e e d F i l t e r
)
/ / === s u p p o r t s t r u c t u r e ===
, r e d e c l a r e model S u p p o r t S t r u c t u r e =
OneWind.FlexibleFloater
/ / === wind ===
, r e d e c l a r e model Wind = OneWind.Wind
(
r e d e c l a r e r e c o r d WindData
)
/ / === waves ===
, r e d e c l a r e model Waves = OneWind.Wave
(
r e d e c l a r e r e c o r d WaveData
)
);
end O f f s h o r e W i n d T u r b i n e ;

are implemented either as rigid bodies or as flexible
structures, which could be based on modal reduction
techniques or finite-elements (Thomas et al., 2014). The
structure model is connected to the aerodynamic model,
which uses unsteady blade element momentum theory for
load calculation, and takes aero-structure-coupling into
account.

2.2

Nacelle

The model of the nacelle contains two subcomponents:
the drivetrain and the generator. Furthermore, the yaw
controller is included. The nacelle is basically represented
as rigid link with mass and inertia, while drivetrain and
generator provide also stiffness and damping (Strobel
et al., 2011).

2.3

Operating Control

The operating control covers algorithms and parameters
for pitch and generator torque control, using either built-in
PID-algorithms (Jonkman et al., 2009) or an external
control DLL. The latter one is obtained from a simulation
tool, Bladed (GL Garrad Hassan, 2010) or Hawc2 (Larsen
and Hansen, 2014), and accessed via a generic DLL
interface. A bus system forms the link between rotor,
nacelle, and operating control (Otter, 2009). There is
no direct link to the support structure, as the control
parameters are initially adjusted based on the floating
system design. Furthermore, different operating phases,
such as startup, shutdown, or idling, can be realized.

2.4

Support Structure

The support structure model defines everything related to
the floating device, including the tower from the RNA
(Rotor Nacelle Assembly) down to the substructure, the
floater itself, station-keeping system, and all loads acting
on the entire support structure. Furthermore, it contains
the FreeMotion, relevant for modeling the motions of the
floating body. An overview of the structure of the model
SupportStructure is given in the following:

Figure 1. Components and interactions of a floating wind turbine, using the example of a semi-submersible platform.

2.1

Rotor

The rotor model extends the basic model for a hub
with one blade to a three-bladed rotor. The blades
634

model S u p p o r t S t r u c t u r e
/ / s u b s t r u c t u r e P a r t i a l 
extends OneWind.SubstructurePartial ;
/ / s t r u c t u r e E l e m e n t 
TopologyData = OneWind.FloaterTopologyData ;
S t r u c t u r e E l e m e n t = OneWind.BernoulliBeam3D ;
/ / a d a p t e r s 
OneW in d.A dap ter Fem Fram eTo Fr am e_f ree
topAdapter ;
OneW in d.A dap ter Fem Fr ameToFr am e_f i xed
bottomAdapter ;
OneW in d.A dap ter Fem Fram eTo Fr am e_f ree
fairleadAdapter [3];
/ / a d d i t i o n a l w e i g h t s 
OneWind.AdditionalWeightLoadElement
ballastWeight [ noElementsBallast ] ;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132633

Session 9D: Wind & Naval Engineering

OneWind.AdditionalWeightLoadElement
capsWeight [ noElementsCaps ] ;
/ / s t a t i o n  k e e p i n g s y s t e m 
OneWind.DynamicMooringLines m o o r i n g L i n e s
[3];
MultiBody.Parts.FixedTranslation
fTrFairleads [3];
M u l t i B o d y . P a r t s . F i x e d T r a n s l a t i o n fTrAnchors
[3];
/ / f r e e M o t i o n 
FreeMotion = M u l t i B o d y . J o i n t s . F r e e M o t i o n ;
end S u p p o r t S t r u c t u r e ;

computation is directly included in the setup of the
subcomponent StructureElement (Subsection 2.4.2). A
schematic overview of these main loads is presented in
Figure 2.

Wave Loads The hydrodynamic load calculation uses
Morisons equation, as given in Equation 1, and is performed for each structure element that is initially below
the water surface, based on its diameter D, length  z, hydrodynamic drag coefficient CD , and added mass coefficient Ca , as well as velocities (structure velocity q, water
particle velocity vwater , relative velocity vwater  q), accel2.4.1 SubstructurePartial
erations (structure acceleration q, water particle acceleraThe basis of the support structure model is formed by the tion vwater ), and water density water .
partial model SubstructurePartial. This covers all main
loads, as well as the visualization of the environment, rep1
resented by a squared FixedShape for the seabed and a
Fwaves = waterCD D (vwater  q) |vwater  q|  z
2
moving surface for animating the wave motion, and conD2
tains the model World. The structure of the partial model
(1)
vwater  z
+ water (1 +Ca )
4
SubstructurePartial is presented in the following:
D2
 waterCa
q z
4
p a r t i a l model S u b s t r u c t u r e P a r t i a l
o u t e r MultiBody.World world ;
/ / v i s u a l i z a t i o n 
M u l t i B o d y . V i s u a l i z e r s . F i x e d S h a p e ground ;
MultiBody.Visualizers.Advanced.Surface
surface ;
/ / wave l o a d s 
On eW in d. Mor ison Lo ad Ele me nt waveLoads [
noElementsUnderWater ] ;
OneWind.MorisonLoadHeavePlate
morisonLoadHeavePlate [ noHeavePlates ] i f
heavePlates ;
/ / wind l o a d s 
OneWind.TowerLoadElement windLoads [
noElementsOverWater ] ;
/ / b u o y a n c y l o a d s 
OneWind.BuoyancyLoadElement b u o y a n c y L o a d s [
noStructureElements ] ;
end S u b s t r u c t u r e P a r t i a l ;

As offshore wind turbines often have to deal with large
dimensioned support components, a separate parameter
is introduced to select whether a fixed value for the
added mass coefficient should be used, which is only
valid for slender structures, or the added mass coefficient
is calculated depending on the wave number, known
as MacCamy-Fuchs approach for large diameters (Yu,
2015). Furthermore, if the floater is equipped with heave
plates, acting as motion suppression device, as it is
the case for semi-submersible platforms, an additional
hydrodynamic heave force due to these heave plates is
included.

Wind Loads In the aerodynamic load calculation, the
drag forces at each emerged support structure element are
The determination of the loads due to waves, wind, computed by means of Equation 2, based on the density of
and buoyancy is covered in the following in more detail. air air , the aerodynamic drag coefficient Cd of the cylinThe gravity force is not elaborated explicitly, as its drical element, its diameter D and length  z, as well as the
local relative velocity, resulting from the local wind speed
vwind and the velocity of the structure element q.
1
Fwind = airCd D (vair  q) |vair  q|  z
2

(2)

Buoyancy Loads Because a floating wind turbine system is considered, buoyancy force and center of buoyancy
will vary with the motion of the floater. Therefore, these
two variables have to be computed for each structure
element at each time step, depending on the actual
position. The coordinate system, used in this calculation,
as well as the degrees of freedom (DoFs) of a floating
Figure 2. Schematic representation of the main loads acting on wind turbine are presented in Figure 3.
the support structure.

DOI
10.3384/ecp17132633

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

635

The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures

sidered beam, defined in the subcomponent StructureElement, as further explained in Subsection 2.4.2, a straight
equation can be defined for the considered structure element. The intersection of this straight with the moved
water plane is analyzed according to the following case
discrimination:

 An infinite number of cross points corresponds to the
structure element lying exactly in the water plane,
leading to a buoyant volume of half of the element
volume.
 The solution of having no cross points corresponds
to the structure element being parallel to the water
plane. Depending on the node positions in relation
to the translational motion, the element is either fully
submerged or not submerged at all.

Figure 3. Coordinate system of a floating wind turbine, using
the example of a spar-buoy platform, adapted by the author from
(Tran et al., 2014).

 Finally, when having one cross point of straight and
plane, the buoyant volume can be computed as fraction of the element volume, if the cross point lies
within the actual length of the structure element. If
the straight would intersect the water plane at an extension of the structure element, the buoyant volume
is either equal to the element volume or zero, depending on the relative position of the element nodes to
the translated water plane.

In an extensive computation, first, the sequential
rotation, defined by roll, pitch, and yaw angles, is transformed into a combined rotation, expressed in terms of a
combined rotation angle combined and the corresponding
From the determined buoyant volume VB , the buoyancy
axis of the combined rotation. Instead of having the
load
of each structure element at each time step is obtained
complex floater geometry rotated, the following approach
by
multiplication
with the water density water and graviis used: it is assumed that the floater remains in its initial
tational
acceleration
g, as given in Equation 3.
position and the water plane area is rotated with the
combined rotation angle around the axis of combined
Fbuoyancy = VB water g
(3)
rotation, however, in opposite direction, as schematically
shown in Figure 4.
The buoyancy force is then connected to the frame_c
of the element (introduced in Subsection 2.4.2), which
is located in the middle of the element axis, including
deformation. As, however, the point of attack of the
buoyancy force varies with the motion of the floater, the
distance from the actual point of attack to the central point
(frame_c) is computed according to the different element
positions elaborated in the above case discrimination. The
resulting moment due to the shifted center of buoyancy is
finally added as torque load to the frame_c, so that correct
loads due to buoyancy are represented.
2.4.2
Figure 4. Schematic representation of the used buoyancy calculation approach.

Including the translational motion of the floater, given
by surge, sway, and heave values of the platform, and used
as the distance from the initial origin to the moved water plane, the equation for the rotated and translated water
plane can be set up. With the node positions of the con636

StructureElement

In the subcomponent StructureElement, all members of
the support structure (floater and tower up to the RNA)
are defined, based on a record for the topology data. This
record contains number and coordinates of the nodes, as
well as number and definition of the members, specified
by the two end nodes and the structural properties of
the element. The tubular beam properties are defined
by an isotropic material (with elastic modulus and shear
modulus, density, and Rayleigh damping parameters),

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132633

Session 9D: Wind & Naval Engineering

as well as start and end diameters and wall thicknesses.
This record can either be written manually, or generated
by means of a MATLAB code. The latter method makes
it easy to change subdivisions of the beam elements
and is thus useful for a more comprehensive structural
analysis. The TopologyData record is used for setting up
the structure elements, using an extended 3D-Bernoulli
beam element model, which is also applicable to branched
geometries and has an external load connector frame_c.

and ballast have to be integrated into the model. The
subcomponent AdditionalWeightLoadElement, similar
to the BuoyancyLoadElement, however, just using the
simple time- and position-independent weight calculation,
has the weight as output, which is implemented in the
vertical component of a force equation.
2.4.4 Station-Keeping System

The station-keeping system contains three different components: fairleads, mooring lines, and anchors, as
Avoiding Closed Loops Offshore substructures might schematically shown in Figure 5.
be branched structures, like semi-submersibles, TLPs,
or also bottom-fixed support structures, such as tripods
and jackets. This will lead to closed loops in multibody
applications that use the floating frame of reference, what
makes it impossible to calculate the unique orientation
of each frame, especially where branches are connected.
This problem is addressed here by excluding orientation
from the node connectors that are used to build up the
substructure by defining the position of each member and
connecting the members. In case internal forces need to
be resolved between local beam and world frame, a local
Figure 5. Schematic representation of a catenary mooring line.
beam orientation is constructed by means of absoluteRotation() and axesRotations(). This beam orientation only
Fairlead and anchor positions are defined by fixed
depends on the initial node positions and is independent
translations,
while the mooring lines are implemented by
of the body motion. Therefore it is combined with a
means
of
a
separate
model. This (1) models the mooring
reference orientation from the bottomAdapter to calculate
lines,
divided
into
several elements, as mass-springan approximation of the local beam orientation, assuming
damping
systems,
(2) considers velocity-dependent
small flexible body motion, which is sufficient for rigid
(Morison)
and
inner
damping, (3) computes weight
body motion. Since the multiplicity of external floating
frame connectors rely on correct orientation, each frame and buoyancy of the lifted parts of the catenary lines,
orientation is exactly calculated from a combination of and (4) includes bottom contact reaction forces. Thus,
the shape of the mooring lines, as well as the effective
reference orientation and local elastic rotation.
lengths are internally determined at each time step, based
on the common catenary equation, given mooring line
Adapters Since the structure is built by 3D-Bernoulli parameters, and the actual fairlead positions. (Feja, 2013)
beams, which have FEM-nodes with node position,
cut force, cut torque, elastic displacement, and elastic
rotation as variables, adapters between the FemFrame 2.5 Wind
connectors and the common Modelica Frame connec- Several wind models, either deterministic, based on gust
tors, not having the elastic deformation variables but models, or stochastic, using binary or ASCII data, are
the frame orientation in addition, are needed. Two available. Different gust profiles, such as 1-cosine gust,
different adapters are used: AdapterFemToFrame_fixed extreme coherent gust, extreme direction change, or
and AdapterFemToFrame_free.
The fixed adapter extreme operating gust, can be selected; wind shear can
(bottomAdapter), where the boundary conditions are set, be included by means of an exponential or logarithmic
is needed for the structure node that will be connected to profile; and the tower effect can be considered either for
the FreeMotion, while the free adapter is for connecting upwind or downwind turbines. Two different guidelines
any other components, such as mooring lines at the can be chosen: IEC-61400-1 edition 3 (International
fairleads (fairleadAdapter), or RNA on the tower top Standard, 2005) or GL guideline for certification of wind
(topAdapter).
turbines (GL Rules and Guidelines, 2010). Corresponding
to this, the wind turbine class (I, II, III), depending on
the reference wind speed average over 10 minutes, the
2.4.3 Additional Weights
turbulence characteristic (A, B, C), for high, medium,
Besides the main loads due to waves, wind, and buoyancy, or low turbulence, as well as the turbulence model
which are already included in the partial model Substruc- (e.g. normal or extreme) have to be specified. For the
turePartial, covered in Subsection 2.4.1, additional weight simulation of the wind, ramped, steady, turbulent, as well
due to column caps, not considered as beam elements, as upwind or downwind steady or turbulent wind types
DOI
10.3384/ecp17132633

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

637

The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures

 Wave and wind loads are actually only calculated
based on the elements above and below the still water level in the initial undisplaced position, not taking into account that elements could emerge or submerge during simulation due to the motion of the
floater. In addition, the wave load calculation only
accounts for relative velocities but not for relative
accelerations, as otherwise the initialization of the
time-domain simulation in Dymola does not finish.
Any loads on the submerged structure due to currents are not included. Furthermore, for correct simulation of floating offshore wind turbines in different
sea states, the actual wave height has to be included
in the buoyancy calculation.

for turbine wake simulation using two or more turbines,
can be chosen. Finally, the basic parameters, such as
hub wind speed, density and dynamic viscosity of air,
wind direction, and flow inclination, are defined in the
WindData record. (Thomas et al., 2014)

2.6

Waves

Two basic wave models are implemented in Modelica:
one model for regular waves and one for irregular random
waves. Water parameters, like water depth and density,
as well as the option to use Wheeler stretching or linear
extrapolation method, are common for both wave models.
The regular waves are further specified by wave period,
wave height, and phase angle. The irregular waves,
on the other hand, are defined by a Pierson Moskowitz
or JONSWAP wave spectrum, significant wave height,
spectral period, random phase angles, and number of
frequencies, because irregular waves are obtained as
superimposition of several regular waves of different
frequencies.

3

Limitations

Holistic modeling of a flexible floating offshore wind turbine system is, because of non-linear physics and fully
coupled aero-hydro-servo-elastic simulation, very complex and extensive. Therefore, some simplifications have
to be made in the first step of implementation, which are
depicted in the following:

 Additional weights due to caps and ballast are
computed for each element and connected to their
frame_c, which is located at the midpoint along the
central axis of each element. However, this does not
correspond to the correct center of gravity in case of
the caps and the uppermost element containing ballast, if this element is only partially filled with ballast. This inaccuracy can be removed by adding a
torque load to the frame_c resulting from the different center of gravity, similar to the method applied in
the buoyancy load calculation, described in Subsection 2.4.1.

Those simplifications are rather minor and do not affect
the system performance in the free-decay simulations,
except for the neglect of the relative acceleration in the
wave load calculation, as shown in Section 4.1. However,
for an offshore floating wind turbine system, which
should represent accurate system performances and
valid results for any simulation and load case, the above
mentioned points have to be included in the model.

4

Results and Applications

The practical use of the offshore wind turbine model in
Modelica is presented by analyzing simulation results
based on the implemented code (Section 4.1) and pointing
out the feasibility of model adaption (Section 4.2).

4.1

Simulation Results

In order to examine the developed code for a floating
offshore wind turbine system, the NREL offshore 5-MW
reference wind turbine (Jonkman et al., 2009) on top
of a floating spar-buoy, defined in OC35 Phase IV
(Jonkman, 2010), is implemented in Modelica, based
on the created floating wind turbine model presented in
Chapter 2, as shown in Figure 6. In order to point out

 In case of a branched structure, like the semisubmersible floater, there is an overlap of elements.
For example, the pontoons are connected to the
nodes at the central axis of the columns, however, the
pontoon structure itself should just start from the column surface instead of the column center. This leads
to some additional incorrect weight, which has to be
removed, for example by using massless elements for
connecting branched elements to the surface of an- Figure 6. Visualization of the OC3-spar floating wind turbine
other element. However, the type and characteristics system (top grey area: water surface, dotted red lines: mooring
of those massless elements have to be chosen such lines, bottom brown area: seabed).
that they would not affect the real structural perfor5 Offshore Code Comparison Collaboration
mance.
638

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132633

Session 9D: Wind & Naval Engineering

time series are then compared with the results from
the code-to-code comparisons (Jonkman et al., 2010).
As, however, the relative acceleration is not included
in the wave load calculation, the same simulations are
performed with the fully rigid equivalent of the floating
wind turbine model, once considering, once neglecting
Table 1. Dymola statistics of translated OC3-spar wind turbine the relative acceleration.
the complexity of the implemented model, some main
statistics are presented in Table 1. The simulation settings
and performance, as well as the hardware properties are
listed in Table 2.

model.

Figure 8 presents the time series of the free-decay simulations exemplarily for the surge DoF. The rigid wind turbine model, taking the relative acceleration into account,
Continuous time states (scalars)
866
yields similar results as obtained by the code-to-code comTime-varying variables (scalars)
34,341
Sizes after manipulation of linear systems {436, 3, 2} parison (Jonkman et al., 2010), shown in Figure 8(a). The
effect of neglecting the relative acceleration is shown on
DAE scalar equations
121,139
the rigid model and compared to the results from the fully
flexible model, not yet capable of taking this parameter
Table 2. System properties, simulation settings, and perfor- into account. From Figure 8(b) it can be seen that the
shorter eigenperiod and stronger damping, obtained by the
mance.
time series of the fully flexible model, are mainly due to
the disregarded relative acceleration in the wave load calParameter
Value
culation.
Clock frequency
3.10 GHz
Operating system
64-bit
Statistical Parameter

Value

Simulation interval
Output interval length
Solver
Tolerance

600 s
0.05 s
Esdirk45a
1.0E-4

CPU time for integration
CPU time for initialization

38,041.8 s
83.3 s

With this model, free-decay simulations, as specified in
OC3 Phase IV (Jonkman et al., 2010), are carried out in
Dymola6 . OC3 mainly focuses on (1) discussing modeling strategies, (2) developing a suite of benchmark models and simulations, (3) running the simulations and processing the simulation results, and (4) comparing and discussing the results (Jonkman et al., 2010, pp. 1-2). The
OC3 participants, together with their simulation tools, are
listed in Figure 7, which represents the legend to Figure
8(a).

Figure 7. Participants and used simulation tools within the OC3
code-to-code comparison.

(a) Rigid model and code-to-code comparison results, legend
given in Figure 7

(b) Consideration and neglect of relative acceleration

Figure 8. Free-decay time series in surge.

The free-decay tests are performed with the fully
flexible support structure, while the turbine is modeled
The system response by the end of the decay process
as rigid structure. Furthermore, aerodynamic damping
turns out to depend on the chosen solver. This, however,
is deactivated, so that the hydrodynamic damping can
is expected to be caused by the damping parameters set in
be elaborated in detail. The obtained motion response
the TopologyData record of the StructureElement. At this
6 http://www.3ds.com/products-services/catia/products/dymola
stage, the Rayleigh damping parameters are computed
(Accessed: 22 August 2016)
manually, based on the system eigenfrequencies, and
DOI
10.3384/ecp17132633

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

639

The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures

used for all beam elements. However, for the sake of
accuracy and in order to obtain more realistic estimates
for the structural damping parameters, it is recommended
to compute those Rayleigh damping parameters for
each beam element individually and internally within
Modelica.

4.2

Model Adaption

Due to the hierarchical programming in Modelica and
the multibody approach, single components can easily
be adapted or exchanged. This way, other floating wind
turbine designs, bottom-fixed offshore or even onshore
wind turbine systems can be modeled, using the basic
structure of the implemented fully flexible model for a
floating offshore wind turbine system. Thus, the presented
model can be used as a simple tool for elaborating new
research topics and different or innovative wind turbine
system designs.

Table 1 for the spar-buoy floating wind turbine model.
This underlines the enlarged calculation effort due to the
increased number of system parameters, which comes
with more complex and highly branched structures. But
nevertheless, it is feasible to model and simulate very
sophisticated wind turbine system designs.

5

Conclusion and Outlook

This paper presents the modeling of a fully flexible
floating offshore wind turbine system in Modelica. Based
on the Modelica MultiBody Library and the hierarchical
programming structure in Modelica, the complex system
is implemented via six main components and several
subcomponents. Floating systems bring new challenges,
such as buoyancy, free motion, station-keeping system, as
well as relative velocities and accelerations. Furthermore,
closed loops have to be avoided, when handling branched
structures in multibody applications, and certain adapters,
This flexibility of model adaption is demonstrated as well as a special load frame, are needed to connect
on the example of the OC4 semi-submersible platform external components to the flexible Bernoulli beams.
(Robertson et al., 2014), the OC3 tripod (Nichols et al.,
2009), and the OC4 jacket (Jonkman et al., 2012), shown
Due to the complexity of fully flexible modeling of a
in Figures 9(a), 9(b), and 9(c), respectively. Further- floating offshore wind turbine system, some simplificamore, Table 3 compares the complexity of those mod- tions are made. Most of them have minor impact on the
els, using the same statistics from Dymola as presented in behavior of the system and the simulation results. Never-

(a) Semi-submersible

(b) Tripod

(c) Jacket

Figure 9. Other wind turbine systems, implementation based on the basic model.

Table 3. Dymola statistics of translated adapted wind turbine models.

Statistical Parameter

Semi-submersible

Tripod

Jacket

Continuous time states (scalars)
Time-varying variables (scalars)
Sizes after manipulation of linear systems

1,658
64,139
78
983
237,246

796
35,079
94
499
148,435

2,056
75,425
366
1,681
374,173

DAE scalar equations
640

Vector length
Maximum value

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132633

Session 9D: Wind & Naval Engineering

theless, the proposed methods for accurate modeling have
to be implemented in the next stage. More challenging
and more relevant for correct simulation results, however,
is the inclusion of the relative acceleration in the wave
load calculation. In order to account for this, further work
on an alternative way to connect external loads to the
structure elements is in progress. In this approach, each
structure element is made up of two Bernoulli beams,
while the mid-node is added separately and connected to
a free adapter. To avoid too small beam elements, the
TopologyData record is adapted and the number of nodes
and members is reduced. A more realistic estimation of
the Rayleigh damping parameters, which could be directly
included as internal computation within Modelica, is as
well of relevance for obtaining correct system responses.
Further fine tuning and detailed examination of the environmental models should be carried out in order to get
even closer to the reference results. Finally, with regard
to the computational effort and simulation performance,
additional work on speeding up the initialization process
is recommended.

International Standard. Wind turbines - Part1: Design requirements. International Electrotechnical Commission, Geneva,
Switzerland, IEC 61400-1, 3rd edition, 2005.
J. Jonkman. Definition of the Floating System for Phase IV
of OC3. Technical Report NREL/TP-500-47535, National
Renewable Energy Laboratory (NREL), Golden, Colorado,
USA, 2010.
J. Jonkman, S. Butterfield, W. Musial, and G. Scott. Definition
of a 5-MW Reference Wind Turbine for Offshore System Development. Technical Report NREL/TP-500-38060, National
Renewable Energy Laboratory (NREL), Golden, Colorado,
USA, 2009.
J. Jonkman, T. Larsen, A. Hansen, T. Nygaard, K. Maus,
M. Karimirad, Z. Gao, T. Moan, I. Fylling, J. Nichols,
M. Kohlmeier, J. Pascual Vergara, D. Merino, W. Shi, and
H. Park. Offshore Code Comparison Collaboration within
IEA Wind Task 23: Phase IV Results Regarding Floating Wind Turbine Modeling. In 2010 European Wind Energy Conference and Exhibition (EWEC), Warsaw, Poland,
April 2010. Conference Paper NREL/CP-500-47534. doi:
10.13140/2.1.3576.5768.

Thus, the presented model should be seen rather as J. Jonkman, A. Robertson, W. Popko, F. Vorpahl, A. Zuga,
M. Kohlmeier, T.J. Larsen, A. Yde, K. Saetertro, K.M.
a work in progress than as a fully established Modelica
Okstad, J. Nichols, T.A. Nygaard, Z. Gao, D. Manolas,
code, as further work on small but important details is
K. Kim, Q. Yu, W. Shi, H. Park, A. Vasquez-Rojas, J. Dubois,
still needed for proper representation of fully flexible
D. Kaufer, P. Thomassen, M.J. de Ruiter, J.M. Peeringa,
floating wind turbine systems. However, the implemented
H. Zhiwen, and H. von Waaden. Offshore Code Comparison
model is a very good basis for simulation of fully flexible
Collaboration Continuation (OC4), Phase I - Results of Coufloating offshore wind turbines and already reproduces
pled Simulations of an Offshore Wind Turbine with Jacket
the dynamics of such a complex system quite well.
Support Structure. In Proceedings of the 22nd International
Society of Offshore and Polar Engineers Conference, 17-22
Furthermore, using the Modelica MultiBody Library and
June 2012, Rhodes, Greece, pages 337346, June 2012. Conthe object-oriented programming in Modelica comes with
ference Paper NREL/CP-5000-54124.
the great advantage to quickly adapt the implemented
basic model. This makes it a simple tool, which can be T.J. Larsen and A.M. Hansen. How 2 HAWC2, the users manused in other research projects and for modeling of novel
ual. Ris-R-Report Ris-R-1597(ver. 4-5), Ris National
wind turbine designs.
Laboratory, 2014.

Acknowledgements
This work is financially supported by the German Federal
Ministry of Economics and Technology, funding code
0325841A.

References
P. Feja. Dynamische Modellierung von Verankerungsleinen
fr schwimmende Offshore-Windenergieanlagen mit Modlica. Bachelors Thesis, RWTH Aachen University, Fraunhofer Institute for Wind Energy and Energy System Technology (IWES), Germany, 2013.
GL Garrad Hassan. V4 Bladed Multibody dynamics. Garrad
Hassan & Partners Ltd., Bristol, UK, Bladed User Manual,
Version 4.0, 2010.
GL Rules and Guidelines. IV: Industrial Services, Part 1:
Guideline for the Certification of Wind Turbines. Germanischer Lloyd, Hamburg, Germany, 2010.

DOI
10.3384/ecp17132633

J. Nichols, T. Camp, J. Jonkman, S. Butterfield, T. Larsen,
A. Hansen, J. Azcona, A. Martinez, X. Munduate, F. Vorpahl, S. Kleinhansl, M. Kohlmeier, T. Kossel, C. Bker, and
D. Kaufer. Offshore Code Comparison Collaboration within
IEA Wind Annex XXIII: Phase III Results Regarding Tripod Support Structure Modeling. In 47th AIAA Aerospace
Sciences Meeting Including The New Horizons Forum and
Aerospace Exposition, 5-8 January 2009, Orlando, Florida,
USA, January 2009. Conference Paper NREL/CP-500-44810.
M. Otter. Modeling, Simulation and Control with Modelica 3.0
and Dymola 7. Technical Report, Deutsches Zentrum fr
Luft- und Raumfahrt e.V. (DLR) - Institut fr Robotik und
Mechatronik, Wessling, Germany, 2009.
A. Robertson, J.M. Jonkman, F. Vorpahl, W. Popko, J. Qvist,
L. Fryd, X. Chen, J. Azcona, E. Uzunoglu, C. Guedes
Soares, C. Luan, H. Yutong, F. Pengcheng, A. Yde,
T.J. Larsen, J. Nichols, R. Buils, L. Lei, T.A. Nygaard,
D. Manolas, A. Heege, S. Ringdalen Vatne, T. Duarte, C. Godreau, H.F. Hansen, A.W. Nielsen, H. Riber, C. Le Cunff,
F. Beyer, A. Yamaguchi, K.J. Jung, H. Shin, W. Shi, H. Park,
and M. Alves. Offshore Code Comparison Collaboration

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

641

The OneWind Modelica Library for Floating Offshore Wind Turbine Simulations with Flexible Structures

Continuation Within IEA Wind Task 30: Phase II Results Regarding a Floating Semisubmersible Wind System. In Proceedings of the ASME 2014 33rd International Conference on
Ocean, Offshore and Arctic Engineering, OMAE 2014, San
Francisco, California, USA, volume 9B, OMAE2014-24040,
page V09BT09A012. American Society of Mechanical Engineers, June 2014. doi:10.1115/OMAE2014-24040.
M. Strobel, F. Vorpahl, C. Hillmann, X. Gu, A. Zuga, and
U. Wihlfahrt. The OnWind Modelica Library for Offshore
Wind Turbines - Implementation and first results. In Proceedings of the 8th International Modelica Conference 2011,
Dresden, Germany, pages 603609. Modelica Association,
March 2011.
P. Thomas, X. Gu, R. Samlaus, C. Hillmann, and U. Wihlfahrt.
R

The OneWind Modelica Library for Wind Turbine Simulation with Flexible Structure - Modal Reduction Method in
Modelica. In Proceedings of the 10th International Modelica
Conference 2014, Lund, Sweden, pages 940948. Modelica
Association, March 2014. doi:10.3384/ECP14096939.
T. Tran, D. Kim, and J. Song. Computational Fluid Dynamic
Analysis of a Floating Offshore Wind Turbine Experiencing
Platform Pitching Motion. Energies, 7(8):50115026, 2014.
doi:10.3390/en7085011.
W. Yu. Dynamic Modeling of a Floating Wind Turbine. Technical Report, Fraunhofer Institute for Wind Energy and Energy
System Technology (IWES), Germany, 2015.

642

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132633

Modelica Based Naval Architecture Library for Small Autonomous
Boat Design
Thom Trentelman1

Joshua Sutherland2

Kazuya Oizumi2

Kazuhiro Aoyama2

1

Maritime Engineering, Delft University of Technology, The Netherlands,
t.r.trentelman@student.tudelft.nl
2
Systems Innovation, University of Tokyo, Japan, {joshua, oizumi, aoyama}@m.sys.t.u-tokyo.ac.jp

emissions of greenhouse gasses (GHG), ranking 2nd as
transport related polluter after road transport (24.3%)
and just above aviation (3.1%). Although road transport
is the major source of transport related emissions,
shipping is the only sector where the GHG emission
rates are still rising (Maragkogianni, Papaefthimiou, &
Zopounidis, 2016). A publication of the International
Maritime Organisation (Buhaug et al., 2009) described
a scenario where without political involvement the
growth of ships GHG emissions would grow by
150~250% between 2007 and 2050.

Abstract
This paper describes a method for early stage boat
design by creating and utilizing a library of naval
architecture based boat components in Modelica. The
method involves the construction of stand-alone boat
components which can be assembled into a simulation
model. Structuring the model into multiple system
levels provides a clear overview. Utilizing the partialcomplete methodology ensures that all system levels are
replaceable within the simulation. This allows the user
to construct many different boat models and experiment
with unconventional or innovative designs. By
comparing the performance and behaviour of different
assemblies of components the most ideal design for a
given purpose can be found and used as a starting point
for the in-depth design process. By organizing the
components in a library they can be re-used in future
projects as well. It is noted that when additional libraries
are utilized the effectiveness of this design method
increases significantly. As the availability of component
models increases, users can save time on the physical
design and modelling of the individual components and
instead focus on assembling working simulation models
right from the beginning. To illustrate this, the
construction of a few simple boat components is
described in this paper. These components are then
combined to simulate multiple concept designs.

1.1

The design process of ships from scratch to seaborn is
costly and requires large amounts of detailed analysis, is
subject to extensive safety and environmental
legislation and to remain competitive, the time-span for
this design process is ever decreasing. There is little
room for uncertainty or assumptions. And whilst most
drastic and influential decisions are made in the early
stages of the design process, most design software tends
to emphasise more on the detailed phases in later stages
of the design process (Abt, Bade, Birk, & Harries, 2001;
Bole & Forrest, 2005). For these reasons ship design
often loses its innovative character and mostly evolves
around the slight improvement of existing designs.
However, due to international political involvement
the imposed legislation on the emission of GHG has
increased in the recent years. Stricter emission quotas
and the introduction of eco-zones at major ports have
forced the industry to innovate (Rue & Anderson,
2015). Moreover, not only stricter legislation has moved
the industry; in recent years the direct influence of
global warming have exposed itself more clearly where
conditions on sea have become more challenging for
existing vessels due to the changing climate. Reports of
an increase in storms and higher rising waves have set
high performance demands for the vessels in order to
maintain safety for their passengers and crew on board
(Bitner-Gregersen, Eide, Hrte, & Skjong, 2013).

Keywords: early stage ship design, model based design,
object-orientated , innovative naval architecture

1

Introduction

Shipping nowadays is one of the worlds most important
means of transport. Not only for product or passenger
transport, but also for leisure such as pleasure yachts and
sport boats. The volume of world seaborne trade
exceeded 10 billion tons in the year 2015. Together this
volume was accountable for more than 80% of the total
worldwide merchandise trade, growing with 2.1% over
the year 2014 (UNCTAD/RMT, 2016). A downside to
this key global trade enabler is the overall environmental
pollution that comes from the industry. In 2012 ship
emissions were responsible for 3.4% of the worldwide
DOI
10.3384/ecp17132643

The Importance of Innovative Naval
Architecture Design

1

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

643

Modelica Based Naval Architecture Library for Small Autonomous Boat Design

1.2

that project must be made based on what value they
provide. Conceptual modelling languages such as
SysML provide a structure to describe a system and its
purpose, but fail to provide feedback on the performance
of the system being designed. Conversely 3D CAD, can
give clear and direct feedback on the geometry of a
system but requires the designer to commit to a great
deal of detail which often occurs later in the design
lifecycle.
1 Dimensional Computer Aided Engineering (1D
CAE) is a broad term used to cover methodologies and
tools which aid the early stages of engineering lifecycles
by the utilization of computers (Sawada, 2012). By
deliberately neglecting 3D geometry the engineer can
quickly prototype designs and crucially; predict the
performance by simulating the models created rather
than creating a physical prototype. Likely leading to cost
and time savings for a given project and making it easier
to complete difficult trade-off decisions which must
made to select a combination of components to form a
system which serves its purpose best.
Modelica is an example of a numerical modelling
language popular in the 1D CAE paradigm. Equations
capture the behaviour of individual components which
are then connected together to develop subsystems
which ultimately form the system being modelled. Its
object orientated features make it possible to quickly
create and modify models including the sharing of
interfaces and inheritance of common attributes.
Features of which are vital for the handling highly
complex systems being developed by large teams.
This is particularly useful when attempting to create
highly innovative designs where experimental or
extraordinary components can be realized as models by
their particular domain experts and integrated into a
system by an engineer who is not a specialist in those
particular domains.

A New Method for Innovative Early
Stage Concept Design

Using Model Based Design (MBD) in the early design
stage makes it possible to experiment with innovative
techniques. For example, 3-Dimensional simulation
gives direct performance output of the created concept.
However, the level of detail of the simulation output will
vary greatly based on the complexity of the simulation
model. This results in the necessity for further
investigation. This in-depth design stage follows a spiral
path. Such a design path has an iterative character; the
concept design should run down all design stages
multiple times. At the end of every iteration the concept
design should be adjusted to ultimately result in a
suitable design (Papanikolaou, 2014). Even though
eventually this high detail design path is inevitable for
every concept design, this method only states whether
the chosen concept is suitable for its goal or not after one
or more iterations. When the concept turns out to be
unsuitable for its goal, the process must start over from
the very beginning. Although this method allows
innovative decisions to made regarding concept designs,
it does not solve the time issue.
In this paper, we present a complimentary method
utilizing the Modelica modelling language in the early
design stages, with the simulation model subdivided
into multiple system levels. The advantage is that these
system levels have a replaceable properties, with every
system level consisting of one or more components. The
components can be anything the user wants to attach to
his simulation model e.g. thrusters, motors, solar panels,
gearboxes and batteries. Connecting these components
all the way through to the top level creates a complete
simulation model arranged in a hierarchy to aid the
management of complexity. By swapping components
within these levels multiple concepts are established on
the same structure. Still the level of detail of the
simulation output is heavily reliant on the complexity of
these individual components. However, at this design
phase the suitability of the designs can be determined by
comparing the performance of various concepts. Only
the most promising concept designs will be subjected to
the advanced design stage. Meanwhile all created
components can be exchanged or stored in a library for
use in later projects.

2

2.2

A review of the current literature shows the use of
Modelica in the naval architecture has been focusing on
the design of highly detailed specific systems aboard
ships. For example (Dong, Wu, Zhang, & Peng, 2011)
have constructed a simulation model of a hydraulic
rudder and used it for the analysis of shock resistant
effects while (Marty, Corrignan, Gondet, Chenouard, &
Htet, 2012) focussed on simulating energy flows and
fuel consumption on board of a large cruise vessel.
The high level of detail of these simulation models is
typical for the advanced design stage of a ship or boat
and as such these stand-alone simulations are not meant
to be integrated into a larger holistic simulation model
of the entire ship or boat. The amount of detail in these
individual component models would be excessive for
the construction of an early design stage model.

Background to Model Based Design
and its Application in Navel
Architecture

2.1

Model Based Design

Model Based Design (MBD) is a design method which
enables the rapid creation of design concepts in software
by leveraging advances in computing technology.
While various modelling languages exist their choice
to be used on a specific project and lifecycle stage within
644

Current Applications of Modelica to
Naval Architecture

2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132643

Session 9D: Wind & Naval Engineering

Through the course of a literature review no prior
attempt at using Modelica to model an entire ship or boat
was found. As such we conclude the navel architecture
preliminary design process is likely still reliant on other
software languages other than Modelica and so is not
experiencing the benefits described in Section 2.1 of this
paper.

3

4

Methodology for Creating
Replaceable System Levels

As shown in Figure 1 the simulation model is
subdivided into four systems levels. All system levels
are linked to one another and ultimately make up the
Solar Boat Model. All system levels are replaceable
since they are all constructed using the partial-complete
methodology. With one click a component, subsystem
or system of interest can be swapped for an alternative.

Contributions of this Paper

Earlier literature from authors including (Sutherland,
Oizumi, Aoyama, Eguchi, & Takahashi, 2016;
Sutherland, Oizumi, Aoyama, Takahashi, & Eguchi,
2016; Sutherland, Salado, Oizumi, & Aoyama, 2017)
has focused on the practical use of a Modelica based
naval architecture library. It describes the process of
designing a race winning model boat for an annual
student contest. The boat model needed to be rather
innovative as it was assigned to sail autonomously on
solar energy. This paper will describe the details and
architecture of the navel architecture library used.
The focus will be on the replaceable components,
system level characteristics and the hierarchal structure.
Successively the architecture of several components
will be described to aid reader comprehension.
Through this paper the authors aim to inspire
engineers from the naval community to take benefit
from advanced design methods and tools. The
effectiveness of the design method will grow
exponentially as more naval component model libraries
become available.

4.1

System Levels

The hierarchical structure provided by the four system
levels offers a clear overview of the simulation model as
demonstrated in Figure 1. In Modelica these system
levels are introduced as separate packages. Underneath
these, every system level has their own sub-packages
containing relevant models.
At the bottom level (Level 4) all individual
components are arranged in a library. This library
provides fundamental elements to the simulation model,
where other system levels are introduced for enabling
quick and drastic concept changes. The number of
possible components is infinite and the level of
complexity per component is variable. Components can
often be broken down into separate sub-components.
These sub-components can then be reconnected at the
subsystem level. However, it is important to
acknowledge that this method is used in the early (lower
detail) design stage.
The subsystem level (Level 3) contains assemblies of
Level 4 components which interact one-on-one to
function properly in a system. Every unique

Figure 1. Schematic view of system level hierarchy; enabling the creation of several ready to simulate Solar Boat models
by alternating various replaceable complete components from the library (Level 4). System Levels 2 and 3 are also
replaceable as shown in Figure 4 and Figure 5.

DOI
10.3384/ecp17132643

3

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

645

Modelica Based Naval Architecture Library for Small Autonomous Boat Design

combination of components within a subsystem requires
a different subsystem name at this level.
The systems of interest level (Level 2) combines all
subsystems which will be used in the concept. It is at
this level that changes will radically influence the
appearance of the concept design.
At the top level (Level 1) the final concept design is
assigned and connected with external factors. These
external factors could be weather conditions, but also
payloads or obstacles in the simulated space the vehicle
operates in. At this level the model is complete and
ready to simulate.

4.2

A partial record states all the parameters without
assigning a value to them. For example, these
parameters could be dimensions, mass, cost,
conductivity, material characteristics and cost. A
complete record extends the partial record and
ultimately assigns values to the parameters. By creating
various complete records with alternating values, every
time extending the same partial record, many different
components of the same type can be created at the one
instant. Using the partial-complete methodology on a
record level ensures that components of the same type
are using identical parameters.
The partial component is used to describe the outlines
of the component and can include both interfaces and
behaviour. When used for describing the outline of a
component, it must declare replaceable the partial
record and therefore gain access to the parameters.
These parameters must then be complemented with
additional variables which will solely be used in the
characteristic set of equations of the component. Note
that every time a component desires a new set of
equations, a new partial component has to be created.
In order to make the components connectable to other
components all output forces expressed by the different
components must be attached to the same frame. To
enable this a connector from the Modelica
Mechanics.Multibody library is used in the Diagram
view
of
the
partial
specifically:
Interfaces.Frame_a. By using this library the
Modelica compiler can automatically combine the
forces and torques excreted by the components and
compute the resulting net acceleration on the entire boat
assembly. In some cases (e.g. components affected by
hydrodynamics)
it
is
useful
to
attach
Mechanics.Multibody.Sensors to the frame. The
data from this sensors could be used in the equations of
the same partial model (e.g. compute drag from
velocity). Lastly, for a clearer understanding of the 3D
simulation of the model Mechanics.Multibody.
Visualizers can also be attached to the frame. The
template for the Diagram view is shown in Figure 3.

Partial-Complete Methodology

The partial-complete methodology, as the name
suggests, makes use of a partial model to create multiple
complete models of the same type. This objectedorientated inheritance scheme uses a partial model to
state the characteristic parameters and equations for
every component, subsystem or system of interest. Each
complete model then extends their corresponding partial
model and assigns real values to the parameters. The
partial-complete methodology allows the models to be
replaceable and enables the rapid creation of multiple
complete components using the same architecture.
Figure 2 shows a flow-chart which demonstrates the
methodology for a simplified (Level 4) component.

X_force

partial_Pr

x_force
Y_Force

Figure 2. Flow chart demonstrating the partial-complete
methodology for creating a replaceable propeller
component (Level 4). The component parameters and
equations have been heavily simplified.

y_force
Z_force

b

v

a

resolve

force

z_force

L_Torque

4.2.1 Component Modelling (Level 4)

l_torque

Not only do all components have to be replaceable, for
experimenting it is also desirable to make the
components easily adjustable and scalable. The use of
records ensures this. A record formulates all constant
parameters which are used in the physical description of
the component. The very base of a component is a
partial record.
646

absVel
resolve

M_Torque

absPos
torque

m_torque
N_Torque

b

a

r

resolve
resolve

n_torque

Figure 3. Diagram template used for creating general
boat components (Level 4).

4

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132643

Session 9D: Wind & Naval Engineering

The last step for creating a Level 4 component is to
create a complete component. The complete model
extends its corresponding partial component and
inherits the values for the parameters by re-declaring the
partial record with the chosen complete record. Every
complete record should be re-declared in a complete
model in order to create the eventual replaceable
components.

Clearly, within a subsystem, components should be
connected in using the appropriate connectors (i.e.
mechanical, electronical, etc.). And to enable interaction
with other subsystems external connectors must be
added.
The complete subsystem is constructed in the same
way as at the component level. First it extends the partial
subsystem, then re-declares the partial components with
their corresponding complete components. Figure 4
demonstrates the construction of two different complete
subsystem architectures by alternating the thruster
component (propeller to jet).

4.2.2 Subsystem Modelling (Level 3)

Subsystems (Level 3) are models that state one or more
component types which the designer decides should be
grouped together. In the partial subsystem the partial
components are assigned. Constraining the replaceable
partial components to their own types (complete
components) makes a subsytems distinctive. This is
illistrated in the following Modelica code for a partial
Electrical to Thrust partial subsystem which is also
shown as a diagram in the central layer of Figure 4:

4.2.3 System of Interest Modelling (Level 2)

The Systems of Interest level (Level 2) is the level the
full architecture of the simulation model is brought
together into a complete concept design. The method for
coding is no different than on the subsystem level. Again
the subsystems should be connected at this level as
required. Figure 5 demonstrates the construction of two
different complete systems of interest by alternating the
energy source subsystems.

model ElectricalToThrust
replaceable motors.motor_partial
constrainedby motor;
replaceable gearbox.gearbox_partial
constrainedby gearbox;
replaceable propellers.propeller_partial
constrainedby propeller;
end ElectricalToThrust;

4.2.4 Simulation Level Modelling (Level 1)

The simulation level assigns the concept design from the
System of Interest level. On this level external factors

Figure 4. Schematic view of the partial-complete methodology as used for the creation of replaceable subsystems (Level
3). In this specific example both replaceable complete subsystems will use a motor and a gearbox. The difference comes
from the variation of propeller (dotted line) and jet (dashed line) as main thruster.

Figure 5. Schematic view of the partial-complete methodology used for the creation of replaceable systems of interest
(Level 2). In this specific example both replaceable complete systems of interest will use a motor, gearbox and propeller
propulsion system, as well as a mono-hull buoyancy generation. The difference comes from the variation of solar panels
(dotted line) and windmills (dashed line) as main energy source.

DOI
10.3384/ecp17132643

5

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

647

Modelica Based Naval Architecture Library for Small Autonomous Boat Design

such as weather can be linked to the concept design,
making it ready to simulate.

5

value to reach the solar panel component it needs to be
implemented as an input in the Modelica Diagram view
of the partial solar panel component.

The Modelica Naval Architecture
Library

5.1.2 DC Electrical Motor and Gearbox Components

The electrical motor component and the gearbox
component are selected from the Modelica Standard
Library. Without any adjustment these component will
respond to the appropriate inputs and generate an output.
These inputs and outputs need to be connected within a
subsystem, and on the system of interest level.
Both the electrical motor and the gearbox need some
additional adjustment before they can be successfully
implemented in the simulation model. Just like the solar
panel component, the motor and gearbox need to have
parameters for size, mass and cost assigned. Also, it is
important to determine a gearbox ratio. Which of course
is also adjustable.
Every time an adjustment in one of the parameter
values is desired, a new complete component has to be
created, extending the partial component.

This chapter demonstrates the practical application of
the design method as described in Chapter 4 in order to
construct a complete simulation model. The simulation
model will be a solar powered model boat. Although this
design method has the potential to model the simulation
model with six degrees of freedom (see Figure 3), for
reasons of simplification this paper will model in only
two degrees of freedom. This means that the eventual
simulation output will only contain a boat travelling in a
straight line and moving up and down along its vertical
axis.

5.1

The Library: Component Modelling
(Level 4)

This section describes the individual components which
are used in the simulation model. Even without precise
knowledge about the physics of every type of
component, it is still possible to construct functioning
components by yourself. This method allows using
existing
literature
to
formulate
component
characteristics and equations. This makes it possible to
construct components even without knowledge or
thorough research. In this paper the solar panel
components are based on existing literature. In some
occasions components, such as motors and gearboxes,
could be implemented from the Modelica Standard
Library. As a result, very few parameters and equations
have to be formulated in the partial models, keeping the
components simple. In other occasions the components
will be based on the authors expertise, resulting in more
complex, yet more adjustable components (as shown
with the propeller and buoyancy components later in the
paper).

5.1.3 Propeller Component

The propeller is a propulsion device often mounted at
the stern of the boat. Although there are many different
types of propulsion devices, the propeller is the most
commonly used. A boat can be designed having more
than one propeller. The direction of the propeller can be
fixed or with the ability to rotate around its vertical axis
in order to adjust the direction of the boat, like the
propellers on typical outboard motors. In this
simulation, a fixed single propeller is used as the thruster
of the boat.
The propeller generates the thrust which will
ultimately displace the boat in the simulation. The thrust
is calculated using the basic equation:
 =     2   4

At the same time a propeller generates a torque. This
toque is described by using a similar basic equation:

5.1.1 Solar Panel Components

The solar panel components are implemented as
modelled by (Esram, 2010). Most parameters are predefined and do not need to be changed. However, for
simulation purposes the solar panel components needs
additional parameters such as surface area, mass and
cost. These additional parameters should be formulated
in the partial record along with the other pre-defined
parameters and later assigned by a complete record in a
complete component.
Also it is possible to vary the distribution of the solar
panels over the length of the boat model. Every unique
distribution requiring a different partial component,
later extended by corresponding complete components.
For a solar panel to generate electricity it needs solar
irradiation. This solar radiation needs to be modelled on
the simulation level (Level 1). In order for this external

648

(1)

 =     2   5

(2)

Where () is the density of the water,  is the
revolutions per second of propeller,  the diameter of
the propeller and ( ()) and ( ()) are the
parametrised thrust and torque coefficients,
respectively. Since  is determined by the environment
and  is as a result of interaction with torque from either
the gearbox or the motor, only the diameter and the
coefficients have to be formulated in the partial record
of the propeller.
The coefficients are found by a 4th-order polynomial
in the form of    +   2 +   3 +   4 , where  is
the advance ratio of the propeller. The advance propeller
is determined using the equation:

6

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132643

Session 9D: Wind & Naval Engineering


=


 =
(3)

1

(()1.6 + ()1.6 + ()1.6 )1.6
1
 =  4
2
3

5.1.4 Buoyancy Component

The buoyancy component describes the hull used in the
simulation and the interaction with its surrounding. The
hull of a boat can come in various shapes and sizes. In
addition there is possibility to design a mono-hull,
double-hull or even a triple-hull. The shape and weight
of the hull mainly affects the resistance from the water
and the stability of the boat. However its hydrodynamic
outline and the interaction with the water are extremely
difficult to accurately model without resorting to
calculations within the field of advanced 3D fluid
dynamics. But in the preliminary design stage it is not
necessary to calculate so accurately and some basic
equations are sufficient as described in the following
subsections.

5.1.4.2 Buoyancy force

The buoyancy force keeps the vessel floating on the
water and maintains its stability. It has an upward force
component along the z-axis and restoring moments
around the x-,y- and z-axes of the construction. In the
simulation the restoring moments have been neglected
for simplification. The equation for the buoyancy force
along the z-axis then becomes:

To reduce complexity the resistance of the buoyancy
component calculation is primarily calculated by the
friction force (Equation 4) using the ITTC-57 equation
(Equation 5).



 =     

0.075
(10 ()  2)2

DOI
10.3384/ecp17132643

(9)

(4)
The water displacement (  ) would normally be
calculated using the block coefficient, length of the
water line, breadth and draft of the hull. The equation is
as follows:

(5)

Where  is the friction coefficient,  is the density
of the water,  is the wetted surface area of the hull and
 is the absolute velocity of the model.
The friction coefficient itself is a function of the
number of Reynolds Number, hence the following
equations:
 =

(8)

Where  is the overall length of the hull,  the
greatest width and  the depth, vertically measured from
the bottom to top of the ellipsoid.
The frictional resistance always works in the opposite
direction of the traveling direction of the boat. More
resistance components such as air resistance and wavemaking resistance could be added in order to increase
the accuracy of the resistance simulation but they are
neglected at this time.

5.1.4.1 Resistance force

1
=        2
2

(7)

Reynolds Number as shown in equation 7 is
calculated using the length of the waterline ( ) of the
hull rather than the overall length but for simplification
this could be equalled to the overall length. It is
multiplied with the absolute the velocity and then
divided by the kinematic viscosity of the water (). This
parameter is determined as a function of temperature
and water density, but could also be implemented as a
constant. For salt water with a density of 1025kg/m3 and
a temperature of 15C,  = 1.188  106 is used.
The wetted surface () is for simplification equalled
to the surface of the under half of an ellipsoid and
assumed to be constant:

Where  stands for the advance velocity (the
velocity of the water as it reaches the propeller, which
in practice is influenced by the shape of the hull). For
simplification, the advance velocity in this simulation is
equalled to the absolute velocity of the simulation, the
value for which is extracted from the implemented
velocity sensor.
The , ,  and  polyfits within the 4th order
polynomial are determined for a particular propeller
design by iterative calculation using a calculation
executed in Matlab as described by the blade element
theory presented by (Auld & Srinivas, 2016). But of
course experimentally derived functions could also be
used.

 = 

  


 =       

(10)

However, to remain consistent with previous
calculations, the displacement will again be calculated
using an ellipsoid equation:
=

(6)

7

1 3
 
2 4

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(11)

649

Modelica Based Naval Architecture Library for Small Autonomous Boat Design

Again only the bottom half of the ellipsoid will be
submersed. The coefficients  are used the same as in
equation 8.

Figure 7 shows a Diagram view of an electrical to
thrust subsystem containing a motor, gearbox and
propeller. These components are mechanically linked to
each other. The motor component has two wires with
pins attached, which will be used to link this
components in the system of interest level to the energy
source (see Figure 9).

5.1.5 Overhead Components

The overhead components make up for weight or cost
values of components which have not been modelled or
used in the simulation model. Moreover they could be
used as the safety margin of the design. The overhead
components have no further dimensions or forces
applied other than weight.

5.2

p

n

The Library: Subsystems (Level 3)

m

The subsystems which are used in the boat model are
Solar to Electrical, Electrical to Thrust, Buoyancy
Generation and Overhead Structures (as shown in
Figure 1, overhead structures excluded).

g

pp

frame_a

5.2.1 Solar to Electrical

Figure 7. Diagram view of Electrical to Thrust subsystem.

The Solar to Electrical subsystem consists of solely the
solar panels. The distribution of solar panels is
determined at this level. The output from the solar
panels is an electrical connection which has to be
connected to an electrical motor. In the subsystem an

5.2.3 Buoyancy Generation

The buoyancy generation subsystem is used to connect
the hull component with external factors such as water
velocity or wind speed. A single hull subsystem will
contain only one hull component.
If the concept design should contain multiple hull
components, as seen on catamaran or trimaran boats, a
separate partial subsystem must be created. Two or more
replaceable components can be implemented and
attached to the frame.
Figure 8 show a Buoyancy Generation subsystem
with a single hull component, connected to a water
velocity input.

Electrical.Analog.Interfaces.PositivePin
and a .NegativePin are utilized. In the systems of

interest level these pins can be used to connect the
electrical current to the electrical to thrust subsystem
(see Figure 9). Figure 6 show a possible composition for
the Diagram view of the Solar to Electrical subsystem.
Solar_Irradiation

Water_Velocity

Temperature

p

Hull

n

S
frame_a

Figure 8. Diagram view of Buoyancy Generation
subsystem.
5.2.4 Overhead Structures

frame_a

The overhead structures subsystem is a stand-alone
subsystem which assesses the overhead structure
component of choice and make it possible to fit this into
the simulation in the systems of interest level.

Figure 6. Diagram view of Solar to Electrical subsystem.
5.2.2

Electrical to Thrust

The electrical to thrust subsystem is responsible for the
transformation of the electrical current generated by the
solar panels into a thrusting force. It accesses electrical
current via the connection of the pins at the system of
interest level (Level 2).
Several configurations could be made to convert the
electrical signal and the resulting thrusting force with
every configuration should be constructed in a separate
partial subsystem.
650

5.3

The Library: Systems of Interest
(Level 2)

The systems of interest model combines various
subsystems to form a model of the system for
assessment (i.e. a boat). At this system-level (Level 2) it
is possible to change entire subsystems with the use of
the partial-complete methodology described previously.

8

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132643

Session 9D: Wind & Naval Engineering

Solar_Irradiance

left for adding a seventh solar panel. By simulating both
boats subject to the same environmental conditions of
average solar irradiance of a day in August in Japan (610
W/m2) it is possible to construct Figure 11 with time
series of velocity and Table 2 containing data selected
from the point when the simulation reached a steady
state (simulation time = 25s). As mentioned previously
no steering component is attached to the boat and hence
the boat only moves in the X and Z axis.

Temperature

temp_kelvin

solarInsolation

No MPPT

O_C

S_to_E

ground

waterVelocity X

B_G

E_to_T

B_G

E_to_T

Figure 9. Diagram view of Systems of Interest (Level 2).

waterVelocityX

5.4 The Library: Simulation Level
ground

(Level 1)
The simulation level contains the chosen concept design
and connects it to all the external parameters such as
environmental elements or payloads. It is at this level
that the simulation is ready to run. Chapter 6 gives an
example of simulating multiple concept designs.

Figure 11. Simulation results of two concept designs.
Table 2. Simulation data of two concept designs.

Simulation

O_C

S_to_E
6

Concept
Efficiency of solar panels [%]
Area per solar panel [m2]
Area of six solar panels [m2]
Mass of six solar panels [ kg]
Spin speed motor [rpm]
Thrust generated [N]
Draft boat [m]
Maximum velocity [m/s]

In this section we present the results of simulating boat
concept designs constructed in Modelica. With the use
of 3D animation (by means of Mechanics.Multibody
library) it is possible to visualize the behaviour of a
particular concept (see Figure 10). While detailed
performance can be analysed using charts. When
multiple different concept designs are simulated, the
data from the charts can be compared to determine the
most suitable design for its purpose.
solarInsolation

6.2

No MPPT
temp_kelvin

Temperature

Solar_Irradiance

Simulating the Concepts

To demonstrate, we compare the results of simulating
two competing boat designs. Both designs are based on
the basic set of components as described in Chapter 5.
However, they vary with Concept 1 being powered by
mid-range efficiency solar panels (12.5%, 3.24kg).
Demanding a higher maximum boat velocity, the second
simulation will be powered by more efficient, however
slightly heavier solar panels (21.5%, 5.40kg). It should
be noted that the maximum allowable solar panel
surface may not exceed 2 m2. Six mid-range efficiency
solar panels almost perfectly fill up all the available
space, where six of the high efficiency solar panels only
fill up 89% of all the available space. There is no room
DOI
10.3384/ecp17132643

2
21.5
0.297
1.78
5.40
13300
118
0.185
3.53

Analysing the Simulation Results

The expectation would be that the design with the most
efficient solar panels, generating more power, will result
in a faster concept. However, by looking at the output
results from both simulations we find both concepts
reaching about the same maximum velocity. We
therefore conclude that the more efficient solar panels,
used in Concept 2, are not appropriate to increase the
velocity of the boat.
In order to increase the velocity of the boat we could
run more simulations with different hull designs in order
to decrease the draft and ultimately the drag, swap
motors, gearboxes and propellers or simply try to find
lighter solar panels with a sufficient efficiency.

Figure 10. Screenshot of the 3-Dimensional simulation.

6.1

1
12.5
0.333
1.99
3.24
12900
111
0.166
3.56

7
7.1

Discussion
Benefits

By using the design strategy utilizing Modelica
described in this paper for preliminary ship design
engineers are able to rapidly construct working
assemblies and cut valuable time on their early design
research. Even without detailed domain knowledge of
naval architecture a user is able to assemble and
compare different models.

9

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

651

Modelica Based Naval Architecture Library for Small Autonomous Boat Design

By using Modelicas object oriented features the
methodology enables radical or minor changes to a
simulation model with one mouse-click. With the
possibility to directly run a 3D animation of the
simulation model the reaction to these changes can be
reviewed immediately.
There is basically no limit of components to add to
the simulation and it is also it is possible to break up
existing components into several separated components.
For example, a rudder can be simply modelled by the
deflection of alternating a single value for the angle, or
if desired be split up into different components, where
the mechanism to initiate this deflection is implemented
as individual components.

7.2

References
Abt, C., Bade, S., Birk, L., & Harries, S. (2001). Parametric
hull form design-a step towards one week ship design. In
8th international symposium on practical design of ships
and other floating structures (pp. 6774).
Auld, & Srinivas. (2016). Blade Element Propeller Theory.
Retrieved November 10, 2016, from
http://s6.aeromech.usyd.edu.au/aerodynamics/index.php/sa
mple-page/propulsion/blade-element-propeller-theory/
Bitner-Gregersen, E. M., Eide, L. I., Hrte, T., & Skjong, R.
(2013). Ship and offshore structure design in climate
change perspective. Springer.
Bole, M., & Forrest, C. (2005). Early stage integrated
parametric ship design. In Proc. ICCAS (pp. 447460).
Buhaug, ., Corbett, J. J., Endresen, ., Eyring, V., Faber,
J., Hanayama, S.,  others. (2009). Second IMO GHG
Study 2009. London UK: International Maritime
Organization.
Dong, R., Wu, C., Zhang, J., & Peng, W. (2011). Modeling
and simulation for ship hydraulic rudder system based on
Modelica/MWorks [J]. Ship Science and Technology, 11,
20.
Esram, T. (2010). Modeling and Control of an AlternatingCurrent Photovoltaic Module. University of Illinois at
Urbana-Champaign.
Maragkogianni, A., Papaefthimiou, S., & Zopounidis, C.
(2016). Shipping Industry and Induced Air Pollution. In
Mitigating Shipping Emissions in European Ports (pp. 1
9). Springer International Publishing.
Marty, P., Corrignan, P., Gondet, A., Chenouard, R., &
Htet, J.-F. (2012). Modelling of energy flows and fuel
consumption on board ships: application to a large modern
cruise vessel and comparison with sea monitoring data. In
Proceedings of the 11th International Marine Design
Conference, Glasgow, UK (pp. 1114).
Papanikolaou, A. (2014). Ship Design: Methodologies of
Preliminary Design. Athens Greece: Springer.
Rue, C. D. L., & Anderson, C. B. (2015). Shipping and the
Environment. New York USA: Routledge.
Sawada, H. (2012). Upstream design and 1D-CAE. Journal
of System Design and Dynamics, 6(3), 351358.
Sutherland, J., Oizumi, K., Aoyama, K., Eguchi, T., &
Takahashi, N. (2016). System-Level Design Tools
Utilizing OPM and Modelica. In ASME 2016 International
Design Engineering Technical Conferences and
Computers and Information in Engineering Conference
IDETC2016. Charlotte, North Carolina.
Sutherland, J., Oizumi, K., Aoyama, K., Takahashi, N., &
Eguchi, T. (2016). System-Level Design Trade Studies by
Multi Objective Decision Analysis (MODA) utilizing
Modelica. In The First Japanese Modelica Conference,
May 23-24, Tokyo, Japan (pp. 6169). Tokyo Japan:
Linkping University Electronic Press.
Sutherland, J., Salado, A., Oizumi, K., & Aoyama, K.
(2017). Implementing Value-Driven Design in Modelica
for a racing solar boat. In 15th Annual Conference on
Systems Engineering Research. Los Angeles, California
(accepted for presentation).
UNCTAD/RMT. (2016). Review of Maritime Transport
2016. Geneva Switserland: United Nations Publication.

Limitations

As for every design method, the simulation output will
never be an exact representation of reality. The methods
used for describing the boat components are by
necessity based on approximations. Given the stated
goals of the 1DCAE method can only be used for
preliminary ship design, the engineer must still run
detailed design iterations on the eventual chosen model
in order to create a system which is producible and
successful.

8

Conclusions and Future Work

8.1

Conclusion

This paper set out to describe a new method for the early
stage design of ships which are highly innovative. We
achieved this by introducing the use of Modelica for
complete ship design. Combined, they form a working
simulation of a boat that travels in a straight line. While
the accuracy of the simulation may not be very high, at
this stage it is already possible to determine the
difference between the performance and behaviour of
different assemblies. Only once the demands for the
eventual design rise, must the simulation increase in
accuracy.

8.2

Future Work

Primarily the content of the library must be expanded in
the future. Further, the availability of many different
types of components will make it possible to assemble
innovative simulation models. Therefore, the authors
hope to see more marine engineers finding their way to
Modelica.
In addition, given the complexity level can vary per
component and every ship design has its own purpose
and requires different accuracies from the simulation a
balance must be made on how complex to make each
component. However, if for example waves are to be
simulated all forces in the six degrees of freedom must
be formulated in every component. Which in turn will
make the library more useful.

652

10

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132643

FMI Go! A simulation runtime environment with a client server
architecture over multiple protocols
Claude Lacoursire, claude@hpc2n.umu.se
Tomas Hrdin, tomas.hardin@umu.se
HPC2N/UMIT, Ume University
SE-901 87, Ume, Sweden

Abstract
We present a distributed software infrastructure to perform
distributed simulations with Functional Mockup Interface
(FMI) compatible components. The current implementation supports both TCP/IP and MPI. This is a client-server
design where the client is the global simulation stepper
and the servers are the simulation modules. Features on
the master time stepping algorithm currently include several time stepping algorithms including one which can
handle algebraic constraints, root finding for cases involving loops, and support for asynchronous data exchange
with monitors and observers which only consume
data. The servers provide support for numerical directional derivatives, filtering, and interpolation. Support is
provided for the System Specification and Parameterization (SSP), an emerging standard aimed at supporting the
FMI.
The software is open source with a permissive license
and designed to be used inside simulation environments
and platforms with user interfaces. The focus being on
the mathematical and runtime aspect of FMI based simulations.

1

Introduction

No one simulation tool can satisfy everyones needs and
yet, full system simulation is the order of the day. Models created using different tools must be made compatible with each other for data transfer at least, and by force
of reality, a lowest common denominator must be found
for numerical time integration of modular, heterogeneous
systems. In this model, subsystems are black boxes connected with simple elements representing boundary conditions. The (FMI)(MODELISAR, 2014) standard specifies
an API which answers the first question of data formats as
well as fundamental functionality to initialize and terminate modules, and defines semantics to handle events etc.
However, this standard does not specify the requirements
on the runtime environment or the master stepper.
We consider both these issues with the aim of providing
a minimal runtime infrastructure which is fully standards
compliant as well as open. We also intend to develop a
number of numerical methods for time integration. This
should allow academics to test their new numerical methDOI
10.3384/ecp17132653

ods on nontrivial examples. The hub based design should
also allow people to write their own interfaces to connect
with the data analysis and visualization tools they prefer,
and can serve as a foundation for commercial integration
tools with sophisticated user interfaces.
In what follows we describe the nature of the problem
we are trying to resolve in Sec. 2, then cover some previous work in Sec. 3. We then describe some details of our
architecture in Sec. 4. Force based model coupling and is
described in Sec. 5 and a kinematic coupling as well as a
differential algebraic stepper is found in Sec. 6. Experiments and discussions are in Sec. 7,8,9 and in Sec. 10.

2

Problem statement and objectives

Software tool interoperability requires a standardized interface to be implemented by vendors, as well as a standard format to describe and exchange source or binary
code implementing a Functional Mockup Unit (FMU).
Also needed mathematical model which corresponds to
the interface, a configuration format and editor for producing configuration files. Then comes a runtime environment which can read these, load the FMUs and perform time integration. One also needs data collection from
the runtime environment, data formats and communication protocols. Of course, one also needs one needs numerical methods for time integration. When all this is in
place, one can create simulations, run them, gather data,
and analyze it with the tools of their choice.
The FMI specifies only the first three items: interface,
exchange formats, and high level mathematical formulation. The emerging standard System Specification and
Parametrization (SSP) (Kler et al., 2016) aims at defining the structure of a simulation  which FMU connects
to which and on what port  as well as parameterization,
including unit conversion etc. This is in the process to be
adopted by the FMI committee. Editors for SSP are under
development by vendors. There is also a Software Development toolKit (SDK)(QTronic, 2017) which is a reference implementation of the FMI API and can serve as a
foundation for writing runtime environments.
We decided to develop components of the runtime environment including SSP, protocols and formats for data
communication and handling, as well as stepping methods. We believe that these are the components missing to

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

653

FMI Go! A simulation runtime environment with a client server architecture over multiple protocols

achieve a genuinely modular solution which avoids vendor lock-in, as well as a sufficiently complete environment for researchers to test their numerical methods and
simulation master algorithms. We are also considering IP
and secrecy issues which can be supported with our client
server design. Of course, we believe that performance is a
fundamental aspect.
Loading many shared libraries as is suggested by the
FMI documentation always leads to problems. This is
why we chose a client server architecture which we implemented over TCP/IP for LAN and WAN configurations,
and MPI for standalone of cluster ones.
User interfaces we leave for others.
The objective is to provide a robust runtime environment with good numerical methods which goes from SSP
to data files, based on standards and protocols so that visualization and analysis software of choice can be plugged
in easily.

3

Previous work

Nearly twenty FMI import tools are listed on the FMI
website (MODELISAR, 2014) and these fall unevenly
into two categories. First come the well established simulation packages which support import functionality in order to connect to third party tools. Second come integration tools only designed to couple simulation and analysis
tools, which is close to our own work. These divide further into commercial and open source ones. Of the latter,
DACCOSIM (Galtier et al., 2015) is the closest to our
effort.
Yet all integration tools we know of aim at providing a
full environment and it appears that the issue of the quality
of time integration is secondary at best, yet the numerical
methods are locked down which isnt good if one has a
particularly recalcitrant and difficult model. We dont see
the need to keep numerical methods secrets. And this prevents experimentation on real-life problems by academics.
One of our motivations.
Distributed and modular simulations isnt new and
predecessors include the High Level Architecture
(HLA) (IEEE, 2010) for instance, which has even been
adapted to FMI (Awais et al., 2013). Focusing on FMI
compatible efforts, Ptolemy (Ptolemaeus, 2014) is an
object oriented peer-to-peer agent based simulation environment and has now FMI (Broman et al., 2013; Cremona
et al., 2016) capabilities with an eye on meeting the requirements for discrete-continuous simulations (Zeigler,
Praehofer, and Kim, 2000), and DACCOSIM (Galtier et al.,
2015) which is most similar to ours. There are others yet
but too numerous to list here.
Why a new effort? First because there is a need for a
test environment for new time integration methods which
is not possible with commercial tools. The open source
projects did not seem to have this as a focus.
Then comes a more contentious issue: software license.
The commercial dimension here weights heavily so we
654

chose the permissive MIT (MIT, nodate) license to avoid
any problem.
It is clear from the literature about time integration for
cosimulations methods (Fiedler and Arnold, 2014; Martin,
Christoph, and Tom, 2013; Schierz, Arnold, and Clauss,
2012; Schierz and Arnold, 2012; Arnold, 2010; Bernhard Schweizer, Li, and Daixing Lu, 2015; Bernhard
Schweizer, Daixing Lu, and Li, 2015; B. Schweizer and
D. Lu, 2015) that it is hardly possible to control errors or
reach stability without having access to directional derivatives or at least the ability to rollback which isnt available
in too many cases. However, both of these features can
be provided by the runtime environment with numerical
differentiation and various brute force techniques. This is
clearly not addressed in any of the tools we looked at. One
can provide these features when wrapping a ME FMU into
a CS FMU, since one, which means that it might be advantageous to export as ME when possible and let a wrapper
take care of more advanced features.
The DAE stepper presented in Sec. 6 is different from
that of Schweizer (Bernhard Schweizer, Daixing Lu, and
Li, 2015) in that we are using a previously published relaxation and regularization technique (Lacoursire, 2007)
which is provably linearly stable, unlike the variants
Schweizer analyzed (Ascher and Petzold, 1993). Experience has proved that our method does not require the solution of nonlinear systems of equations as the linearized
approximation is sufficiently stable and produces no systematic drift.
Therefore, we believe that our work has much orthogonality with what already exists, enough to add yet one
more FMI runtime environment to the list.

4

Software design

We opted for a client-server architecture in which each
server process hosts an individual FMU. The global stepper is then a client, consuming results produced by the
FMUs, and serves also as a data hub. It is also a server
to monitors which are read-only applications for interactive, online visualization and data analysis, as well as data
storage. See Fig. 2. We decided against peer-to-peer communication
We used Protobuf (Protocol Buffers 2017) to map the
twenty or so functions in the FMI API to messages
which can be passed via ZeroMQ (iMatrix, 2017). The
servers dynamically load an FMU and using the QTronix
SDK (QTronic, 2017). The same was repeated to use the
Message Passing Interface (MPI) (MPI, 2017) which has
the benefit of not needing to pack and unpack data. We
chose to use (MPICH, 2017) because it is better than other
implementations at handling oversubscription, i.e., when
there are more processes than cores available. On Windows, we use the native library (Microsoft, 2017).
The numerical Jacobians were implemented in the
servers using simple first order finite differences. These
computations are done in the servers which can exploit

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132653

Session 10A: FMI II

x = f (x,u,t)
z = x,

(1)

and then the reported output is
y = g(x,u)

(2)

instead of g(x,u) at the end of the communication step.
The averages can be, e.g.,
y = g(

1
(z0 + z1 ),u)),
2H

(3)

where H is the communication step, and z0 ,z1 are the values of z at the beginning and end of the communication
step (Drenth, 2016). The advantage of such filters is to
offset the noise produced by the discontinuous inputs at
each communication point. Such functionality is clearly
not possible when using a CS FMU, and we believe that it
is good to leave the choice open. We have automated the
augmentation of the equations of motion. Other types of
filters are straight forward to implement.
The overall design is shown in Fig. 1. Here, one goes
from a FMU via the Qtronix library to the FMI API. At
this point, depending on whether the FMU is ME or CS,
support libraries are used to deliver additional functionality to the global stepper. This funnels through the FMI/X
communication library towards the global stepper, and
said returns results to be processed by the FMU.
DOI
10.3384/ecp17132653

FMU server

t,u,y,  uy

common

numerical
derivatives
y
y
 u  u

FMI API
FMU

model exchange

FMI/TCP FMI/MPI
FMI/X API
cosimulation

parallelism to perform this task. This requires the ability
to rollback a simulation one or several times, and if possible, to clone it for parallelism. In the best case, FMUs
provide rollback functionality. The second best case is a
functional serialization and deserialization. We are investigating other methods, as well as the trade off between
doing much more work per step vs step size and accuracy.
Support for Model Exchange (ME) FMUs is in development on two fronts. One is a global stepper capable of handling ME FMUs or combinations of ME and CS FMUs,
i.e., integrating discrete and continuous systems(Zeigler,
Praehofer, and Kim, 2000). The other is to include a local ME stepper inside the servers so that ME FMUs can
be transformed to be CS ones. The advantage here is that
even though CS export tools make a choice of numerical
time integration which cannot be changed, yet is critical
for stability and application dependent. Therefore, delaying the decision until runtime is appealing. In addition,
ME FMUs are required to be able to cancel a step as long
as no event is crossed which makes it easier to compute
numerical derivatives and rollback. Access to the ME
FMU also allows the support of extrapolation and interpolation methods (Bernhard Schweizer, Li, and Daixing
Lu, 2015) after the model has been exported, and to introduce other types of filters on the inputs (M. Benedikt et
al., 2013; Drenth, 2016). We have already automated the
latter. Briefly, assuming a module has continuous states
x, inputs u and outputs y = g(x,u), the dynamics is augmented so that

numerical
derivatives
y
y
 u  u
filtering
y = g(x,u)
numerical
integration
x =  ds f (x,u)

Figure 1. Server architecture

The global stepper program has a barebone, command
line interface to describe the connections, as well as support for SSP files which is much more convenient.
The global stepper can also resolve loops at initialization using Newton-Raphsons method, and we intend to
use this feature for the ME stepper so that it can process
DAEs.
As the kinematic stepper requires the solution of linear
problems, we currently use U MFPACK (Davis, 2004).
The overall design of the system appears diagrammatically in Fig. 2.
For TCP/IP, there are a number of issues related to the
GRID computing concept of network weather service,
which is about resource discovery and allocation. This is
not implemented yet but there are simple tools for this.
Hardware in the Loop (HIL) functionality has not been
developed at this time though the architecture is compatible with this.
The software runs on Linux, Mac OS X and Windows.
To emphasize, this type of design is not entirely novel as
mentioned in Sec. 3. What is different however is the restriction we imposed ourselves to the runtime environment
and not the user environment. In addition, the existing
functionality and what is in planning will hopefully provide building blocks for the development of new numerical time integrators, since typical restrictions of FMUs 
absence of directional derivatives or rollback functionality
 will be compensated for by the support modules, as described above, i.e., wrappers for ME FMUs to transform
them into CS FMUs.
We follow the UNIX philosophy here: Do one thing
and do it well. For our case, the pipe model is initial
conditions in, data out. Clearly, there is more than one
thing going on here, but we are aiming at being atomic
and modular: all thats needed to perform time integration
of systems made of FMUs, but only that.
To confirm that this is a position statement, we believe that numerical algorithms have little if anything to
do with trade secrets, yet should be tested extensively in
real situations. When an engineer runs a simulation, the
same wants to have confidence that the results make sense.
For that reason, the numerical time integration software
should open. If successful, the best methods will be available for all to use.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

655

FMI Go! A simulation runtime environment with a client server architecture over multiple protocols

FMU

FMU

...

FMU

FMI/X
Kinematic stepper

Simple Stepper
step control
DoStep(. ..)
(parallel/serial)
y = getReal(. . .)
u = L(y)
setReal(. .. , u)

s = saveState(. . .)
DoStep(. . ., False)
y = getReal(. . .)
J = getDerivatives(. ..)
Solve: GJu = a
u = L(y, u)
SetState(. ..,s)
setReal(. . . , u)
DoStep(. .., True)

Monitors

Visualization

Command line
Python parsing
System Specification and Parametrization
Time stepper

Figure 2. Overall architecture

5

Force subsystem couplings

Splitting a system leads to having one variable, x, say,
which appear in two subsystems. For instance, the output shaft of an engine is the very same as the input shaft
of a clutch so the angle of said should be the same in each
module.
As the systems are integrated independently, the duplicates, x (1) ,x (2) cannot remain in sync. One strategy for
physical systems at least is to introduce a generally stiff
spring-damper in one or both subsystems. There are several choices as described previously (Bernhard Schweizer,
Li, and Daixing Lu, 2015) namely, force-displacement
or force-velocity in which one of the units contains a
spring-damper but not the other. These we call holonomic and non-holonomic, respectively. Then there is
displacement-displacement coupling in which case there
are spring and dampers on both sides. Finally, there
is the spring free case described in Sec. 6 which requires a global solver to computes the force required so
that x (1) = x (2) at each communication step, an algebraic
condition. The latter requires both rollback and directional derivatives which is not often supported. Rollback
is also required for iterative methods which are essentially fixed point iterations (Bernhard Schweizer, Li, and
Daixing Lu, 2015) and have good stability properties. As
mentioned, we aim at making our software capable of applying these methods for any FMU, whether it has these
features natively or not.
We chose force-velocity in our examples.
Whenever there is a spring-damper at the input of a system, system 1, say, there is an input signal

coupled element. When x (2) is not reported, the approximation
x(t)  x    ds(v  v)
(6)
0

is used and x(t)  x is reset to 0 at the beginning of each
communication step.
A variety of methods can be used to improve on the
Zero Order Hold (ZOH) including extrapolation, or combination of extrapolation and interpolations, often called
iterative methods (Bernhard Schweizer, Li, and Daixing
Lu, 2015, and references therein).
One thing remains though, the spring-dampers
k (c) , (c) are not in the original model and introduce
artificial dynamics. One needs to keep the frequencies
due to the couplings much higher than the design frequencies, i.e., time scales involved by the couplings
should me much smaller than those of interest in order to
not interfere with the results as we show in Sec. 9, and
this leads to communication steps which are orders of
magnitude smaller than the time scales of interest, and
introduces stiffness in the individual modules as they fight
against the spring force in Eqn. (5). As we show below in
Sec. 9, coupling frequencies need to be at least one order
of magnitude above the design frequencies, meaning that
coupling springs must be two order of magnitude above
the stiffness of the internal force derivatives.
There are alternatives to this which do not involve a
global solver as the one in Sec. 6, such as bilateral delay lines (TLM) (Dag Fritzson, 2007; Krus, 1995). This
is still a spring-damper coupling but motivated by the fact
that a force takes finite time to traverse any form of physical coupling, interactions are interpolated between the two
previous steps. The main issue here is that this only works
with intermediate steps within the DoStep calls. Something which can only be addressed with ME FMI using
state machines without continuous states, one of our next
steps. An effort similar to ours but based on TLM is in
the process of being released to the public (Sjlund et al.,
2010).
As far as trying to damp the high frequencies due
to coupling and avoid oversampling the system, an antialiasling technique as been presented recently (Drenth,
2016) which is promising. We have introduced it into our
software though we are not including this in our results as
explained below in Sec. 11.

6

A differential algebraic stepper

u (1) = x (2) , or u (1) = v (2) or both (with abuse of notation).
(4)
But this signal is not available continuously, only at the
beginning once per communication step. This values are
denoted as x (2) and v (2) . The coupling force, given spring
and damping constants k (c) ,  (c) , respectively, is then

As mentioned in Sec. 5, a split model involves algebraic
conditions, and these can be taken care of directly by a
DAE method (Bernhard Schweizer, Daixing Lu, and Li,
2015; Bernhard Schweizer, Li, Daixing Lu, and Meyer,
2015; Bernhard Schweizer and Li, 2015; B. Schweizer
and D. Lu, 2015), though that requires rollback and directional derivatives. There are no spring-dampers in this
f (c) = k (c) (x (1)  x (2) )   (c) (x (1)  v (2) ). (5) model and therefore, no parasitic dynamics. Also, the
problems related to choosing suitable spring and damping
The reaction force  f (c) at the end of the reported to the constants for the couplings is now entirely avoided, so are
656

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132653

Session 10A: FMI II

artifacts introduced by the numerical integration methods
because of stiffness, or unnaturally small time steps.
We reuse ideas from multibody dynamics (Lacoursire,
2007) to design a stepper which computes the interaction
forces required to maintain the constraints at least linearly,
and uses damping to stabilize the symmetric average of the
algebraic conditions.
Consider two systems with output variables y (1) ,y (2)
as well as time derivatives y (1) , y (2) . These variables are
constrained either holonomically or nonholonomically, respectively, meaning that in discrete time we should have
(1)

(2)

(1)

(2)

(1)

(2)

g(yk ,yk ) = 0 or q(yk ,yk ) = G (1) yk + G (2) yk = 0,
(7)
respectively, where k is the discrete time index. We also
write G =  g/ y so that Gy = 0 holds for both cases, abusing notation. First we make the assumption that
( j)

( j)

( j)

yk+1  yk + hyk+1 ,

(8)

where H is the communication step is a reasonable approximation. This is the case for the S HAKE (Hairer, Lubich, and Wanner, 2001) stepper and a variant of ours (Lacoursire, 2007). Note that k +1 is used on the time derivatives. Next we write a time translation operators as
( j)

( j)

( j)

( j)

( j)

( j)

yk+1 = k (uk ) and yk+1 = k (uk ).
( j)

(9)

dynamics on the algebraic condition. Our method is of
first order only and this is what provides stability. We also
use a symmetric form of the constraint so that in fact, we
are enforcing


1
(gk+1 + 2gk + gk1 ) + Gk vk+1 + uk+1 = 0,
4
h
h

(12)

where  is a relaxation time and serves as stabilization.
This is clearly of first order in and of itself, but of course,
the averaging does introduce oscillations, damped by the
 term. Such symmetric projections have been shown to
have good energy preservation properties (Hairer, 2000)
when  = 0 and the nonlinear equations are solved exactly. The parameter  has the same unit of the inverse
of a spring constant if we assume that u has units of force,
and is there only to prevent against constraint degeneracy
but can be shown to introduce physical compliance when
 is sufficiently small. However,  serves as a low pass
filter and when  = 2h, the oscillations are just below critical damping. This is needed to stabilize on the constraint
manifold. This analysis is found in part in our own work
cited above. With this parameterization, /h is the rate of
exponential decay of the constraint violation. There is no
such guarantee of stability with the standard scheme (Ascher and Petzold, 1993). A more thorough stability analysis is in preparation. We linearize Eqn. (12) to avoid having to solve the nonlinear system of equations. Introducing the parameter
1
(13)
=
1 + 4/h

The aim now is to compute uk in such a way that
Eqn. (7) is satisfied at k + 1. Assuming that all modules
( j)
can rollback, we start with a guess uk and from this we we need to solve the following linear system of equations
expand the constraint equations in Eqn. (7) to compute for  u
( j)
( j)
( j)
uk = uk +  uk such that the constraints are satisfied.
4
  4
(k+1)
This requires the directional derivatives
+
] u =  gk + Gy (k)  Gy
(14)
[G
u
h
h
( j)
( j)
 k
 yk
=
,
(10) In practice, one performs a step with some guess for in( j)
( j)
puts uk to obtain a preliminary estimate on the velocities
 uk
 uk
yk+1 , rollback, compute  u, and then step forward again
which are mobilities in the case of multibody dynamics, or with uk = uk +  u. This has been shown to work very well
admittance for electrical circuits. Dropping superscripts even for nonsmooth, event driven systems (Lacoursire
on all variables and writing G for the agglomerated Jaco- and Sjstrm, 2014) dozens of units simulated in paralbian of the constraint equations and gk for the value of the lel.
constraint equation at discrete time k,  u should satisfy
Note here that if there are n observables y  Rn and m
control inputs u  Rm , the system is underactuated if m <
gk+1  gk + hGyk+1
n, overactuated if m > n and fully actuated when m = n.
The matrix G / u has full row rank when m  n but is
= gk + hGk (uk +  u)
(11) degenerate otherwise, and this is where   0 comes in to
 k
 gk + hGyk + h[G
] u.
regularize the system.
 uk
The control flow is described in the following. In this
notation,
each statement is understood to be applied to all
This linear approximation can be stabilized as shown in
FMUs
in
parallel and all superscripts are removed.
our previous work (Lacoursire, 2007), which is unconditionally stable, unlike more popular methods (Ascher and
s = GetState(...)
SetXXX(...), u
Petzold, 1993) variants of which have been studied also in
the context of cosimulation (Bernhard Schweizer, Daixing
DoStep(...,t,t + h, False)
GetReal(..., y)
Lu, and Li, 2015). However, methods mentioned above all
GetDirectionalDerivative(..., / u)
based on spring-damper ideas and introduce second order
DOI
10.3384/ecp17132653

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

657

FMI Go! A simulation runtime environment with a client server architecture over multiple protocols

Per process timing on single computer

Assemble system matrix G / u
Solve for inputs  u from Eqn. (14)
SetState(...,s)
SetRealXXX(..., u +  u)
DoStep(...,t, h, True)

Experimental methodology

In evaluating the performance of FMIGo! we focused
on the latency introduced by the FMI/X communication
layer. We looked at scalability here and worked strictly
with the best case scenario using loopback ports. Overhead due to TCP/IP routers or switches varies greatly, but
are in the millisecond range.
For the rest, we compare both the accuracy of cosimulated systems with respect to reference or analytic solutions, and pay attention to the small time scales introduced
by the spring-damper couplings.
Two examples are considered, chains of spring damper
systems with uniform masses, and a simple truck model
often used for elementary analysis (Eriksen and Nielsen,
2014). The latter example contains large mass ratios.
In all cases, we choose our time steps using dimensional
analysis and compare them the periods of oscillations in
the systems, the rationale being that accurate solutions
should require around twenty steps per period of oscillation  the smallest in the system  , as is the case for most
good numerical time integration methods as easily verified. For instance, an embedded Runge Kutta method of
order 4/5 requires 15 steps per period for the simple harmonic oscillator to reach local tolerance of 104 , involving
90 function evaluations, though forward Euler requires at
least 50 function evaluations (steps) to produce a reasonable solution, though more than 200 to deliver any form of
accuracy. And because ZOH techniques are very akin to
forward Euler, this is the best one can expect.

8

Timing

Measurements on 4 cores i7 2.8GHz, sufficient memory
and a vanilla Linux installation. We had 4GB available,
but the footprint of the program was small enough as to
be irrelevant for common hardware. Results will vary for
different systems but this should give a good idea of the
overhead involved.
Using /usr/bin/time utility we extracted user,
system and wall time. The user time is spent in computation and signal routing and communication packaging
and a part of the time spent in moving data via sockets.
For TCP/IP version, system includes time for polling,
waiting and going through the TCP/IP stack. For the
MPI version, system includes interprocess communication which depending on the MPI library, might also go via
sockets and TCP/IP. So, this time has to be considered in
the present case as it is used by the application. There are
other unrelated processes counted in system but that was
made negligible by stopping all irrelevant applications.
The wall time is larger than the sum of user and
658

Time [s]

7

150

wall
system+user
user

100

idle
communication

50

computations

1

20
N FMUs

40

Figure 3. Timing measurements in loopback configuration

m1

m1

m2

m3

f3

f5
m3

m2
v2

m4

m5

m4

m6

v4

Figure 4. A chain of mass spring-dampers split into subunits

system because the CPU is not fully utilized and spends
cycles waiting for packets and communication.
Note that this timing is sensitive to the choice of MPI
library for the case of oversubscribing, i.e., when there are
more processes than cores. OpenMPI performs badly in
this case and seems to have quadratic complexity. MPICH
however is well behaved and delivers linear performance
as shown in Fig. 3. The Microsoft MPI library did perform
well also.
Our experiment consisted of minimal FMUs which contained a point mass and a spring-damper. Computations
were minimal and represent a lower bound on any practical simulation. What is therefore included here is all the
time needed to perform time integration on said physical
model, communication to the master stepper, routing of
signals and communication back to the individual FMUs.
The conclusion is that a distributed design, at least
when using MPI, is negligibly slower than one based
purely on dynamic loading. The benefits of MPI however are immense as one can simulate on clusters, and as
for the TCP/IP version, enables IP protection by hosting
FMUs on secured computers.

9

Chains of mass-spring-dampers

The purpose of this experiment is to see at which point
the time scales of the models and those of the couplings
are sufficiently far apart that the dynamics of interest is
negligibly disturbed and from there, made an estimate of
the kind of time step required, in proportion to that one
would use for the individual systems.
We consider a chain of N elements with ideal springs as

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132653

Session 10A: FMI II

1.0

seen in Fig. 4
x

= k

( j1)

(x

( j)

 x

( j1)

)k

( j)

(x

( j)



),
(15)

with j = 2,3,...,N  1, and
= k (1) (x (1)  x (2) ) and

m (N) x

(N)

= k (N1) (x (N)  x (N1) ).

(16)

We call these spring constants the design variables as they
are the ones included in the original model. The undamped case is the only irrelevant one for this analysis
as it is the worst case scenario for testing the schemes.
This considerably reduces the dimension of the parameter
space. Then we split each mass except the first and last so
that for j = 2,3,...,N  2
m (i) = m (1) ,m (2N2) = m (N) , and
m (2 j) + m (2 j+1) = m ( j+1) .

log10 (x  xref )

(1)

m (1) x

Position of Second mass

( j+1)

x

m

( j)  ( j)

0.0

1.0
100

Differences with reference

102
104
106
0

5
r1 = Time
4 [s] r2 = 32
r3 = 320
reference

10

Figure 5. Influence of coupling springs on natural dynamics

(17)
The interaction between m (2 j1) and m (2 j) is the same
as that between m ( j) and m ( j+1) , but we now introduce spring-damper coupling k (c) , (c) between m (2 j)
and m (2 j+1) so that
m (2 j) x (2 j) = k ( j) (x (2 j)  x (2 j1) ) + f (2 j,2 j+1) , and
m (2 j+1) x (2 j+1) = k ( j) (x (2 j+1)  x (2 j+2) )  f (2 j,2 j+1) ,
m (1) x (1) = k (1) (x (1)  x (2) ),
m (N) x (N) = k (N) (x (N)  x (N1) ), and
f (2 j,2 j+1) = k (c) (x (2 j)  x (2 j+1) )
  (c) (x (2 j)  x (2 j+1) ), j = 1,2,...N  1.
(18)
and therefore, we should have
x (2 j) k (c)  x (2 j+1) .

(19)

if the damping is correctly adjusted. We chose the nondimensional damping parameter such that
 (d)
m (2 j) m (2 j+1)
= 0.7 where  = (2 j)
.
= 
m
+ m (2 j+1)
2 k (c)

(20)

known. We expect the time step to decreases linearly
with the smallest period of the system, which should be
O(k (c) ) unless an implicit integration strategy can be implemented.
We now look at ratio  between the coupling frequencies  (c) and those of the original system  (d) , and estimate how large  must be to minimize interference. In
our experiments, we set x (1) (0) = 1 so as to inject energy
in the natural modes. As expected for a linear system, the
modes are separated and do not interact very much so the
overall dynamics is similar. What is worrisome however
that it takes a ratio of coupling of more than 100 before
the errors go below 103 .
As seen in Fig. 4, one needs frequency ratios of around
30 to start recovering the correct solution and from Fig. 5
there is quadratic convergence towards the original solution. But given that this is a forward Euler technique, we
get less. We found that we needed at least 50 times more
step per coupling period than the minimum required by an
good numerical integrator to have stability and some stability. This means 30  50 = 1,500 more steps per unit time
than for the isolated models. Thats three orders of magnitude more work. The DAE stepper of Sec. 6 produced
very good solutions with a step commensurate with the
design frequencies. We used a holonomic coupling here
and included the positions in the model.

This means that  (c)   as k (c)   as required for
convergence. The effect of this is also that in the stability
analysis, we are at the same location in the complex plane
10 Experiments with a truck model
as long as
Here we investigate a simple truck model with an engine

 k(c)
modeled with a point mass  the flywheel , a PI control
 i
(c)
(c)
(c) 
h1 1 = h2 2 , where i =
.
(21) which aims at reaching a given speed, a clutch, a gearbox

and a shaft, each represented with a pair of masses couNote that it is not generally possible to pick the damp- pled with spring-dampers  piecewise linear for the clutch
ing constant  optimally since internal inertiae and fre- as in Fig. 7, and a trailer modeled as a point mass but inquencies of any given FMU cannot be assumed to be teracting with a road with variable slope following a sine
DOI
10.3384/ecp17132653

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

659

FMI Go! A simulation runtime environment with a client server architecture over multiple protocols

Angular velocity at engine

40

Position of Second mass
 [rad/s]

x

1.0

0.0

kin 20 spp
kin 120spp
fv 350spp
fv 640spp

20

1.0
100

Angular velocity at trailer

Differences with reference
 [rad/s]

log10 (x  xref )

0

102

 [rad/s]

10
5
Time [s] npp = 450
npp = 50
npp = 4500
kin, npp = 20
reference

2
1

0
100

104
0

3

Clutch engine  

102
104

Figure 6. Simulation results for chains

106
4

10

3

0

Clutch model

10

Figure 8. Cosimulation of a truck model. The spp key stands
for steps per period.

2
[Nm]

5
Time [s]

0
2
0.1

0
  [Rad]

0.1

0.2

Figure 7. A piecewise linear clutch model

wave, and subject to gravity, rolling and dry friction, as
well as air resistance. This is a textbook model (Eriksen
and Nielsen, 2014).
The engine delivers 1,350 Nm max torque, the target
speed is 100 km/h, and the trailer has a mass of 10,000 kg.
The slope of the road was made sinusoidal. The interesting aspects here are the mass ratio and the large torques
involved. The kinematically coupled model simply constraints velocities and coordinates between the components, i.e., the flywheel angle should match that of the in
plate of the clutch, etc.
Each FMU has its own time integration and we chose
the GSL for that. We used the fourth order Runge Kutta
method rkf45 for our experiments with 106 tolerance.
For the kinematic stepper, we computed the effective mobility by integrating and rollback and then using finite differences.
Here we compare our kinematic stepper of Sec. 6 with
a step of 1/20 and 1/120 of the smallest period in the design. In this case, this is in the clutch and gearbox dynam660

ics. The case of 120 steps per period offers good results,
though as low as 10 steps per period as stable. However,
for the force-velocity coupling using either sequential or
parallel simulation required more than 350 steps per period before stability. Good results come after 640 steps
per period. Things were worse yet when we used holonomic coupling, i.e., including spring dampers for positions as well as velocities. We needed more than 10 times
as many steps for the force-velocity versions, though with
kinematic coupling, we had high accuracy at 20 steps per
period already (results not shown). To be considered here
is that the mass of the trailer is so much larger than the
driveline that very stiff springs would be needed to reach
the correct result. Considering the previous experiment in
Sec. 9 we used coupling springs 30 times larger those in
the design. This leads to 30  350/20  500 more steps than
necessary just for stability. The DAE stepper does perform
more work per step: solving a small system of linear equations, computing directional derivatives, and performing
two sub-steps per step. But even thats not a fair comparison since the FMUs in the kinematic coupling setup do
not contain stiff coupling springs and therefore, they also
perform an order of magnitude less work. In this case, the
best result from the DAE stepper used four times fewer integration steps overall, and thats despite the fact that we
used numerical directional derivatives, which takes four
times as many steps.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132653

Session 10A: FMI II

11

Discussion

Bibliographic References

The main lesson here is that when it comes to forcevelocity couplings at least, but this applies to the other
cases of spring-damper type couplings, one needs at least
30:1 ratio of frequencies and as far as ZOH techniques
goes, this introduces orders of magnitude more work than
an all-at-once method, or a DAE based one. Though
the frequency ratio appears inevitable, there is recent
work (Drenth, 2016) indicating that the communication
step size can be kept modest by filtering the high oscillations. We have not been able to use this technique or reproduce the results in our experiments, something which
the author relates to admittance or mobility ratio between
the FMUs.
Kinematic coupling offers very good solutions at relatively large steps and were able to use holonomic couplings as well at moderate steps. Of course, this requires
functionality that is not often seen in CS FMUs, namely,
rollback and directional derivatives.

12

Conclusion

The software we introduce should be of interest for being
minimalistic and offering a good foundation to build integration environments for cosimulation. It offers very good
performance for a standalone computer yet can be distributed over WAN. We hope that the functionality we are
developing will open the door to more advanced time integration methods. We will soon start collaborations with
the OpenModelica and OpenCPS groups, which will provide user interfaces.
Our kinematic stepper can produce very good results in
keeping time steps commensurate with the model frequencies and offers parallelism, at least on simple models. Further investigation is needed clearly, but the benefit in comparison to force-velocity coupling is significant and we believe that, despite the difficulties associated with roll-back
and computation of directional derivatives, is worth much
attention.
As part of future work, we intend to support TLM as
it is popular, provide a fully functional ME simulation
master, and improve the numerical directional derivatives
functionality to be fully parallel. Other features such as
extrapolation and interpolation in the ME FMU wrapper,
as well as iterative and implicit time integration methods,
or various types of filtering are under consideration.
The software is available on a request basis at this
time at git clone at https://mimmi.math.umu.se/
users/sign_in. Anonymous access is forthcoming.

Acknowledgments
This work is a part of the project "Virtual Truck and Bus"
supported by the Swedish Energy Authority, and is a collaboration between Scania CV AB, Algoryx Simulation
AB, Modelon AB, Ume University and Volvo Car Corporation. Previous contributions to the software development were made by Stefan Hedman and Adeel Ashgar.
DOI
10.3384/ecp17132653

References
Arnold, Martin (2010). Stability of Sequential Modular
Time Integration Methods for Coupled Multibody System Models. In: Journal of Computational and Nonlinear Dynamics 5.3, pp. 031003031003.
Ascher, Uri M. and Linda R. Petzold (1993). Stability
of Computational Methods for Constrained Dynamics
Systems. In: SIAM J. Sci. Computing 14.1, pp. 95120.
Awais, M. U. et al. (2013). Distributed hybrid simulation
using the HLA and the Functional Mock-up Interface.
In: Industrial Electronics Society, IECON 2013 - 39th
Annual Conference of the IEEE, pp. 75647569.
Broman, D. et al. (2013). Determinate composition of
FMUs for co-simulation. In: 2013 Proceedings of the
International Conference on Embedded Software EMSOFT, pp. 112.
Cremona, F. et al. (2016). Step revision in hybrid Cosimulation with FMI. In: 2016 ACM/IEEE International Conference on Formal Methods and Models for
System Design (MEMOCODE), pp. 173183.
Dag Fritzson Johas Sthl, Iakov Nakimovski (2007).
Transmission line co-simulation of rolling bearing applications. In: The 48th Scandinavian Conference on
Simulation and Modeling. Ed. by Claus Fhrer Peter
Bunus Dag Fritzson, pp. 2439.
Davis, Timothy A. (2004). Algorithm 832: UMFPACK
 an Unsymmetric-Pattern Multifrontal Method. In:
ACM Transactions on Mathematical Software 30.2,
pp. 196199.
Drenth, Edo (2016). Robust Co-Simulation Methodology
of Physical Systems. In: 9th Graz Symposium Virtual
Vehicle.
Eriksen, Lars and Lars Nielsen (2014). Modeling and control of engines and drivelines. John Wiley & Sons.
Fiedler, Robert and Martin Arnold (2014). Coupled differential algebraic equations in the simulation of flexible multibody systems with hydrodynamic force elements. In: PAMM 14.1, pp. 523524.
Galtier, Virginie et al. (2015). FMI-based Distributed
Multi-simulation with DACCOSIM. In: Proceedings
of the Symposium on Theory of Modeling & Simulation: DEVS Integrative M&S Symposium. DEVS 15.
Alexandria, Virginia: Society for Computer Simulation
International, pp. 3946.
Protocol Buffers (2017). https : / / github . com /
google/protobuf.
Hairer, E. (2000). Symmetric Projection Methods for
Differential Equations on Manifolds. In: BIT Numerical Mathematics 40 (4), pp. 726734.
Hairer, E., C. Lubich, and G. Wanner (2001). Geometric Numerical Integration. Vol. 31. Springer Series in
Computational Mathematics. Berlin: Springer-Verlag.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

661

FMI Go! A simulation runtime environment with a client server architecture over multiple protocols

IEEE (2010). IEEE Standard for Modeling and Simulation (M&S) High Level Architecture (HLA) Framework and Rules. In: IEEE Std 1516-2010, pp. 138.
iMatrix (2017). ZeroMQ. http://zeromq.org/.
Kler, Jochen et al. (2016). Modelica-AssociationProject System Structure and Parametrization"  Early
Insights. In: Proceedings of the 1st Japanese Modelica
Conference. Modelica Association. Linkping University Electronic Press, pp. 3542.
Krus, Petter (1995). Modelling of Mechanical Systems
using Rigid Bodies and Transmission Line Joints. In:
ASME J. Dyn. Sys., Meas., Control 121.4, pp. 606611.
Lacoursire, Claude (2007). Ghosts and Machines: Regularized Variational Methods for Interactive Simulations of Multibodies with Dry Frictional Contacts.
PhD thesis. Dept. of Computing Science, Ume University.
Lacoursire, Claude and Sjstrm (2014). A non-smooth
event-driven, accurate, adaptive time stepper for simulating switching electronic circuits. Tech. rep. UMINF
16.15. Dept. of Computing Science, Ume University.
M. Benedikt et al. (2013). NEPCE - A nearly energypreserving coupling element for weak-coupled problems and co-simulations. In: V International Conference on Computational Methods for Coupled Problems
in Science and Engineering. Ed. by S. Idelsohn, M. Papadrakakis, and B. Schrefler, pp. 10211032.
Martin, Arnold, Clauss Christoph, and Schierz Tom
(2013). Error Analysis and Error Estimates for CoSimulation in FMI for Model Exchange and CoSimulation V2.0. In: Archives of Mechanical Engineering 60. 1, pp. 7594.
Microsoft (2017). Microsoft MPI. http://tinyurl.
com/mpilib-microsoftv85.
MIT (n.d.). MIT license.
MODELISAR (2014). FMI website. last retrieved 201701-22. URL: https : / / www . fmi - standard .
org.
MPI (2017). A Message Passing Interface Standard.
http://mpi-forum.org/.
MPICH (2017). High performance, widely portable implementation of the Message Passing Interface. http:
//mpi-forum.org/.
Ptolemaeus, Claudius, ed. (2014). System Design, Modeling, and Simulation using Ptolemy II. Ptolemy.org.
URL: http://ptolemy.org/books/Systems.
QTronic (2017). QTronic FMI SDK. http : / / www .
qtronic.de/en/fmusdk.html.
Schierz, Tom and Martin Arnold (2012). Stabilized overlapping modular time integration of coupled differential-algebraic equations. In: Applied Numerical Mathematics 62.10. Selected Papers from
NUMDIFF-12, pp. 14911502.
Schierz, Tom, Martin Arnold, and Cristoph Clauss (2012).
Co-simulation with communication step size control
in an FMI compatible master algorithm. In: Proceedings of the 9th International MODELICA Conference.
662

Schweizer, B. and D. Lu (2015). Predictor/corrector cosimulation approaches for solver coupling with algebraic constraints. In: ZAMM 95 (9), pp. 911938.
Schweizer, Bernhard and Pu Li (2015). Solving
Differential-Algebraic Equation Systems: Alternative
Index-2 and Index-1 Approaches for Constrained Mechanical Systems. In: Journal of Computational and
Nonlinear Dynamics 11.4, pp. 044501044501.
Schweizer, Bernhard, Pu Li, and Daixing Lu (2015). Explicit and Implicit Cosimulation Methods: Stability and
Convergence Analysis for Different Solver Coupling
Approaches. In: Journal of Computational and Nonlinear Dynamics 10.5, pp. 051007051007.
Schweizer, Bernhard, Pu Li, Daixing Lu, and Tobias Meyer (2015). Stabilized Implicit Cosimulation
Method: Solver Coupling With Algebraic Constraints
for Multibody Systems. In: Journal of Computational
and Nonlinear Dynamics 11.2, pp. 021002021002.
Schweizer, Bernhard, Daixing Lu, and Pu Li (2015). Cosimulation method for solver coupling with algebraic
constraints incorporating relaxation techniques. English. In: Multibody System Dynamics, pp. 136.
Sjlund, Martin et al. (2010). Towards Efficient Distributed Simulation in Modelica using Transmission
Line Modeling. In: Proceedings of the 3rd International Workshop on Equation-Based Object-Oriented
Languages and tools. Ed. by Peter Fritzson et al.,
pp. 7180.
Zeigler, Bernard P., Herbert Praehofer, and Tag G. Kim
(2000). Theory of Modeling and Simulation. 2nd ed.
Academic Press.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132653

Experimenting with Matryoshka Co-Simulation: Building Parallel
and Hierarchical FMUs
Virginie Galtier1 Michel Ianotto1 Mathieu Caujolle2 Rmi Corniglion2 Jean-Philippe Tavella2
Jos vora Gmez3 Jos Juan Hernndez Cabrera3 Vincent Reinbold4 Enrique Kremers5
1 CentraleSuplec,
2 EDF

France, {first.last}@centralesupelec.fr
R&D, France, first.last@edf.fr

3 SIANI,

Spain, jose.evora@siani.es, josejuanhernandez@siani.es
of Leuven, Belgium, vincent.reinbold@kuleuven.be
5 EIFER, Germany, enrique.kremers@eifer.uni-karlsruhe.de

4 University

Abstract
The development of complex multi-domain and multiphysic systems, such as Smart Electric Grids, have
given rise to new challenges in the simulation domain.
These challenges concern the capability to couple multiple domain-specific simulators, and the FMI standard is
an answer to this. But they also concern the scalability
and the accuracy of the simulation within an heterogenous
system. We propose and implement here the concept of a
Matryoshka FMU, i.e. a first of its kind FMU compliant
with the version 2.0 of the FMI standard. It encapsulates
DACCOSIM  our distributed and parallel master architecture  and the FMUs it controls. The Matryoshka automatically adapts its internal time steps to ensure the required accuracy while it is controlled by an external FMUcompliant simulator. We present the JavaFMI tools and
the DACCOSIM middleware used in the automatic building
process of such Matryoshka FMUs. This approach is then
applied on a real-life Distributed Energy System scenario.
Regarding the Modelica system simulated in Dymola, improvements up to 250% in terms of computational performance are achieved while preserving the simulation accuracy and enhancing its integration capability.
Keywords: co-simulation tool, multi-threaded execution,
master algorithm, FMU, FMI standard

1

Introduction

Complex systems can be characterized by a great number of heterogeneous entities in interaction. The Smart
Grids provide a typical example: over a large territory
a multitude of devices produce, transport, store and consume electricity, while some are being monitored and controlled in order to best adjust the dynamic configuration of
the electric network to the current and forecasted weather
conditions and client needs. Co-simulation is essential to
design and study such complex systems.
In this context, the FMI (Functional Mockup Interface) standard (Blochwitz and Otter, 2011) allows users
to share and combine their models across simulation tools
by wrapping them with a native solver in a package, called
DOI
10.3384/ecp17132663

an FMU for Co-Simulation, that is composed of an XML
model description and a compiled C code. But the orchestration of the execution of the multiple FMUs forming the
co-simulation of a complex system is up to the user. DAC COSIM , as an FMU-based co-simulation platform able to
define and simulate complex calculation graphs, proposes
an answer to this matter.
Furthermore, solvers usually used to simulate multiphysics systems are single-threaded. They may thus encounter scaling problems when simulating larger systems.
This is the same for those included in FMUs. DACCOSIM
provides a master code orchestrating the execution of
FMUs in parallel, synchronizing their data exchanges and
adjusting the internal step size to ensure accuracy.
Our objective is to get the best of both worlds by wrapping a DACCOSIM co-simulation in an FMU. We refer to
this englobing FMU as a "Matryoshka" FMU.
This article is organized as follow: Section 2 provides
a quick overview of DACCOSIM features and inner architecture. Section 3 lists the benefits of encapsulating DAC COSIM within an FMU. Section 4 presents JavaFMI, a tool
which greatly facilitates the construction of FMUs from
Java code. Section 5 explains how a Matryoshka FMU is
built with and by DACCOSIM. A real-life Distributed Energy System is then considered and the results obtained
in terms of accuracy and computation efficiency are presented in Section 6. Finally Section 7 points out a few
directions we would like to explore in the future.

2

DACCOSIM, a Powerful FMI for
Co-Simulation Platform

DACCOSIM (Galtier et al., 2015) is a Java co-simulation
middleware able to define and simulate complex calculation graphs consisting of multiple FMUs compliant with
the FMI 2.0 standard for Co-Simulation. It relies on
JavaFMI (see Section 4) and is available1 under AGPL for
both Windows and Linux operating systems, whether 32bit or 64-bit.
1 https://daccosim.foundry.supelec.fr

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

663

Building Parallel FMUs (or Matryoshka Co-Simulations)

It consists of two complementary parts:
 A user-friendly Graphical User Interface (GUI)
that facilitates the definition of multi-domain studies
(Figure 1). It enables to easily design the calculation
graph of the simulation case, i.e. the FMUs involved
and the variables exchanged in-between. It also allows the user to set the resources used for the simulation case (local multi-threaded machine or HPC
cluster) as well as its setup (simulation duration, coinitialization method, time step control strategy, tolerance allowed to internal solver and variables...).
Results can be displayed a posteriori or in real-time
during the simulation. In addition, a Domain Specific
Language allows the user to write scripts to define,
configure and run parametric studies on large cosimulation cases involving hundreds of FMUs and
thousands of variable exchanges.

Figure 2. DACCOSIM distributed architecture

into one or more DACCOSIM masters depending on the resources considered. These masters launch the simulation
and run concurrently till the end of the simulation case.
If it is above all a robust and scalable co-simulation
middleware able to simulate large and complex use cases,
DACCOSIM is also an experimental playground for the
FMI standard where innovative features are tested, such
as the ahead implementation of proposed FMI primitives (Tavella et al., 2016), or the Matryoshka FMU approach presented in this paper.

3

Figure 1. Screenshot of DACCOSIM GUI for a system of 14
FMUs with 110 variables exchanged

The Benefits of Encapsulating DAC COSIM within an FMU

DACCOSIM itself is a powerful FMI for co-simulation
middleware able to perform fully parallel and distributed
co-initialisation and co-simulation tasks. But as a standalone tool, its scope remains limited:
 Only FMUs compliant with the FMI 2.0 for CS standard are supported. Consequently simulators such
as NS-2 (a communication networks simulator), or
HLA federates with no FMI interface cannot be included into its co-simulation graph.
 It cannot be integrated within domain-specific tools
able to import FMUs, tools which become more and
more widespread nowadays.

 A parallel and distributed execution architecture
which manages the initialization and the execution of
the involved FMUs. To maximize performance and
scalability, DACCOSIM runs the FMUs involved in
the co-simulation in parallel, using multiple threads
on a node, and using multiple nodes when a clusDesigning a specific control API for DACCOSIM would
ter is available. Each FMU is executed by a wraphelp
to meet these needs, but encapsulating it all into a
per directly connected to other wrappers to import
Matryoshka
FMU fulfills even more of them:
and export variable values at each communication

Such
an
FMU can be imported into any FMI comstep. To provide the best trade-off between precipliant
simulation
tool or platform such as Dymola or
sion and computational speed, DACCOSIM integrates
MECSYCO
(Vaubourg
et al., 2015). This opens new
fixed and adaptive time step control strategies to dyperspectives since some of these tools might as well
namically adjust the simulation step size of all FMUs
handle non-FMI components with which DACCOSIM
to the estimated error. In order to perform this cois not able to directly interact.
ordinated step-size adjustment, DACCOSIM relies on
 Taking advantage of DACCOSIM efficient, multia hierarchy of "masters", one on each computation
threaded, step-size control solution helps simulatnode, controlling the set of FMU wrappers executing
ing faster larger models within traditional monoon this node. This architecture (Figure 2) is used durthreaded simulation tools. It makes particular sense
ing both co-initialization and co-simulation stages.
for domains where few parallel solvers are available.
The transition from the calculation graph designed with
 Initialization of complex graphs is taken care of
DACCOSIM GUI to its execution with DACCOSIM calcuwithin the Matryoshka thanks to DACCOSIM generlation engine relies on Acceleo2 : the graph is translated
alized co-initialization algorithm.
2 https://www.eclipse.org/acceleo/
 A complex simulation graph can be reused directly
664

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132663

Session 10A: FMI II

without having to re-write anything and with no risk
of disclosing industrial and intellectual property.
 The co-simulation process can be finely tuned: when
a solver typically uses only one accuracy objective
for the whole model, DACCOSIM allows the user to
define different tolerance values for every output and
internal variable of each FMU.

4

JavaFMI Tools to Generate and Execute FMUs

JavaFMI is a software project devoted to provide a toolbox that allows to import and export Functional Mock-up
Units (FMU) to/from Java in conformance with the FMICS 1.0 and 2.0 standards. This project is developed by
SIANI3 university institute and its license is LGPL. Main
contributors of this project are EDF Lab, EIFER, and CentraleSuplec. This project is composed of two main tools:
a wrapper and a builder.

4.1

FMI Wrapper

The FMI wrapper allows to import FMUs into a Java
application supporting the creation of Master Algorithms
(Evora et al.). It provides two types of interface: simulation (simplified interface) and access (full interface).
The simulation class (FmiSimulation) provides a very
simplified access to the FMU. This way, the user of the
wrapper can load FMUs without having a deep knowledge of the FMI standard. Its methods are init, doStep,
terminate, read and write variable, getSimulationTime, isTerminated and reset.
The access class allows invoking all available methods of the standard depending on the version that is being
used. This way, the simulation class can be wrapped by
the access class allowing for an advanced usage. Methods
like get, set and free state can be invoked among others.
Basically, all the primitives specified in the FMI-CS standard can be found as methods in this class.

4.2

FMI Builder

The FMI builder allows to create an FMU based on a
Java application or any program that can be controlled
by a simple Java code. That is, any Java simulation can
be exported to an FMU. This tool provides an automated
solution to create an FMU covering the development of the
dynamic libraries, the generation of a model description
file and the packaging of the needed resources.
The builder provides a framework to convert a Java simulation into an FMU. It is required to extend the FmiSimulation class where, at least, the following methods should
be implemented:
 define. It returns a model that contains the information to be rendered in the modelDescription.xml
 init. It is called in the instantiation process of the
FMU. It should register all input and output variables
3 http://www.siani.es

DOI
10.3384/ecp17132663

Figure 3. Communication between the JavaFMI wrapper and
the FMU JAR through the libraries (dll, so)

with their corresponding getter and/or setter methods so that the framework can later get and set the
FMU variables during the initialization and simulation stages.
 doStep. It advances the simulation according to the
given step size.
 reset. It resets the simulation to its initial state.
 terminate. If needed, it should be filled with a termination code.
Once these methods are implemented, the FmiSimulation class is packaged into a JAR (Java ARchive) file and
processed by the builder so that an FMU is created. The
builder creates an FMU file containing:
 Dynamic libraries (dll and so) in the binaries folder.
 Model description.
 JAR file tuned to the model in the resources folder.
 Additional FMU resources in the resources folder if
any are defined by the user.
The resulting FMU is compliant with the version 2.0
of the FMI standard which makes it applicable within any
FMI compliant tool. Basic primitives like init, doStep,
terminate, etc. are available as well as advanced ones like
get, set and free state. For these advanced methods, the
FMI builder has a default implementation that can be overridden in case a custom implementation is needed.
At runtime, the FMU dynamic libraries are programmed so that an instance of a Java Virtual Machine
(JVM) is created in order to load the FMU JAR file. Once
this happens, all functions invoked by the user of the library are directly bridged to the Java application by using
pipes. Associated data flows are explained in Figure 3.
When using JavaFMI wrapper to load the FMU, this
data flow can be shortened: if the JavaFMI wrapper
detects that the FMU has been built with the JavaFMI
builder, it takes the JAR located in the resources folder,
loads it in the JVM in which the wrapper is, and communicates directly with the FMU methods through Java
(Figure 4). This yields a significant improvement in the
communication speed.
The JavaFMI project also contributes to make the FMI
standard evolve. New co-simulation concepts (Tavella
et al., 2016) are being trialed and validated by implementing newly defined primitives linking compliant FMUgenerating tools to master algorithms.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

665

Building Parallel FMUs (or Matryoshka Co-Simulations)

Figure 4. Direct communication between the JavaFMI wrapper
and the FMU JAR created by the builder

5

Matryoshka FMU Building Process

In this section we first describe the steps taken by a
DACCOSIM user to build a Matryoshka FMU for his cosimulation test case. Next we expose the behind the scene
mechanisms, i.e. how DACCOSIM 2017 was augmented to
support the construction of a Matryoshka FMU and which
operations it performs during the building process. Last
we present the result of the building process.

5.1

The Users Perspective: How to Build a
Matryoshka FMU from DACCOSIM

Exporting a Matryoshka FMU is quite simple for DAC COSIM users. Only a few additional steps are required
after having designed the co-simulation graph.
During this initial stage, the user sets the simulation
configuration as he would do for any co-simulation test
case. These settings determine the internal behavior of the
Matryoshka, with in particular:
 the co-initialization mode (none, sequential output
propagation, Newton or a mix of both),
 the step size control method (constant step size
or the adaptative Euler, Richardson or AdamsBashforth methods) and its step size characteristics
(initial, minimum and maximum step size),
 the event detection method (bisectional approach
(Camus et al., 2016) or minimum step-size).
The users only task is then to define the inputs and outputs of the Matryoshka FMU and link them to the variables of its internal FMUs:
1. The user uses a specific interface (Figure 5) to create the external variables of the graph and set for
each its name, causality (input or output), type (real,
integer, boolean, string, enumeration), variability
(constant, discrete or continuous) and initialization
mode (exact, approximated or calculated). Adding a
description of the variables is also possible.
2. He defines default initial values for each external
input variable.
3. He adds external connectors, connects them to the
FMUs own connectors in the graph and associates
their variables as depicted in Figure 6.
4. Finally he generates the Matryoshka FMU by
clicking the toolbar export button of the GUI.
666

Figure 5. DACCOSIM interface enabling external IO definition

Figure 6. DACCOSIM graph with external connectors

5.2

Behind the Scene: the Steps Towards the
Matryoshka FMU

We describe in the following subsections the sequence of
actions that are automatically performed by DACCOSIM
and result in the Matryoshka FMU generation when clicking the "Generate DACCOSIM Matryoshka FMU" button
of DACCOSIM GUI toolbar.
5.2.1 Creating DACCOSIM master external API
DACCOSIM 2017 was augmented to be controlled from the
outside when executed on a local machine. The result is a
DACCOSIM GlobalMaster class that is tailored to a particular co-simulation configuration, and can be instantiated from another Java program. The obtained master
class retains its internal mechanism specificities (multithreaded architecture, adaptive step size control...) while
adapting to the constraints imposed by the control program (external step size, input values...): if the internal
step size leads to exceed the external step bound, the internal step size is truncated to meet this limit. It is afterward
restored to its non-truncated value at the beginning of the
following external step. Only DACCOSIM cluster features,
i.e. its distributed architecture, are for now not exploited
in the context of the Matryoshka FMU.
The master class is generated with Acceleo. It inte-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132663

Session 10A: FMI II

grates a set of basic functions enabling external interactions with the master, among which:
 instantiating DACCOSIM global master;
 setting the start and stop times of the simulation;
 setting and getting the value of the external variables of the Matryoshka. Inner variables are not accessible for now;
 changing the state of the master, i.e. initialization
or simulation mode;
 performing the co-initialization of the internal
graph considering imposed input variable values;
 performing a co-simulation step whose size is imposed by the control program;
 terminating the co-initialization and/or cosimulation process.
5.2.2

Specifying Matryoshka interface to JavaFMI

All these functions are called by a Java interface code extending the FMISimulation class defined in the JavaFMI
tools. This interface is used to perform the mapping between the primitives defined by the FMI standard and
DACCOSIM masters own interaction functions. It is automatically generated with Acceleo. The modelDescription.xml file of the Matryoshka FMU is later generated
based on the information specified in this interface class,
and especially the list and characteristics of the external
input and output variables of the DACCOSIM co-simulation
graph.
One characteristic of the Matryoshka that has to be calculated prior to the interface generation is the dependency
of the external output variables regarding its external input variables. This information is important when performing the co-initialization of a co-simulation scheme
involving the Matryoshka to ensure that the variables are
initialized in the correct order.
The calculation of the Matryoshka output dependencies
is automated by DACCOSIM. It first computes the oriented
acyclical causality graph of the Matryoshka co-simulation
scheme (Figure 7). The graph is then reversibly parsed
from the external outputs (blue dots) until its reaches the
graph seeds that include the external inputs (large yellow
dots). Optionally, this process can be disabled to let the
user define the dependencies manually.
5.2.3

JavaFMI interface compilation with Ant

The two Java files (Master and Interface) are put into Java
packages and compiled into a JAR using Ant. The Ant
command file is tuned to each use-case and generated with
Acceleo. The resulting JAR is an essential input component for the FMU builder.
5.2.4

Building the FMU using JavaFMI builder

The Matryoshka FMU is finally created by using JavaFMI
builder (see Section 4). The following components are
assembled as the super FMU resources:
 the previously constituted Jar file;
 the resources required by DACCOSIM master, i.e.
the inner FMUs, the csv files defining the variables
DOI
10.3384/ecp17132663

to log and the variables exchanged, a modelDescription file generated by DACCOSIM (different from Matryoshkas own modelDescription file generated by
the builder, even though theyre quite similar);
 the library files required by DACCOSIM calculation engine. If most are platform independent, a few
such as 0MQ require OS specific components. This
results in an OS specific Matryoshka that can be used
either on Windows 64 bit or Linux 64 bit systems.
A simple call to the FMU builder command line pointing to these resources is then sufficient to automatically
create the Matryoshka FMU.

5.3

What is a Matryoshka FMU like

The result is an FMU embedding DACCOSIM with the following capabilities:
 Can manage variable simulation time step.
 Can be instantiated several times.
 Cannot get and set FMU state, serialize its state or
provide directional derivatives.
Generated Matryoshka FMUs have been successfully
tested with the FMU checker, as well as imported and run
in FMI 2.0 compliant tools (Dymola, DACCOSIM...).

6
6.1

Application to an Industrial Simulation Use Case
Presentation of the District Energy System
Use Case

A District Energy System (DES) consists of components
that enable the delivery of energy services in a district.
This includes all possible carriers, most frequently electricy, heating, cooling and gas networks. Research interests mainly focus on the modelling of electrical and heat
grids on a neighbourhood scale to optimize the topology
and sizing of the electrical network, as well as to design
the energy management system (Baggi et al., 2014; Zucker
et al., 2016; Wetter et al., 2015).
6.1.1 Problematics
One of the main issues of such models is their lack of
scalability, i.e. the inability to study a growing number of
buildings connected to real size distribution networks in an
appropriate amount of time: long time-scale simulation of
a DES can thus easily reach limits in terms of memory and
simulation time when using one generic solver since most
of them are mono-threaded. As a result, the simulation of
large and complex DES usually leads to simplifications either on the building side or on the network side. The alternative is to distribute the simulation by decomposing the
problem into smaller interconnected sub-problems. DAC COSIM is then a suitable candidate tool.
6.1.2 Model Description
We consider a fixed district model written in Modelica (Baetens et al., 2015) involving 12 grid-connected
Smart Buildings in a heterogeneous district (Figure 8).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

667

Building Parallel FMUs (or Matryoshka Co-Simulations)

Figure 7. Complete causality graph (on the left) and its acyclic view (on the right) of a simple co-simulation graph.

For each building, we consider 3 thermal zones and one
heating-pump (HP) connected to a 3-phases linear feeder.
Thermal, electrical, ventilation, hot-water demand and
occupancy profiles are heterogeneous and derive from a
stochastic model (Baetens and Saelens, 2015). We employ complex quasi-stationary equations of the grid in order to study the influence of the load demand on the maximal/minimal tension of the grid (Protopapadaki et al.,
2015). The impact of the MV network is also considered:
it is modeled by a voltage source following real unbalanced LV busbar measurements. No hot water network is
considered here.

idOcc  {1, .., 12}, is related to resources profiles, i.e.
electrical energy and hot water demands, occupancy and
reference temperatures. This allows to keep the FMU general so that only a single profile needs to be loaded. The
frequency of the network propagated to each of its components is also represented as an FMU, as is the LV voltage
information imposed on the busbar.
This results in a system composed of 15 FMUs. All of
them except for the LV voltage FMU are included within
the Matryoshka FMU (Figure 9). This split allows to make
the Matryoshka sensitive to its electrotechnical environment, i.e. to the MV network behavior. This would also
allow to easily connect several DES Matryoshka FMUs to
a MV network and see how they interact.

Figure 8. Illustration of the District Energy System use case

This basic scenario is already complex enough to exhibit scalability issues when using a standard solver. For
illustration, it takes about 1 full day for 2 weeks of simulated time on our standard PC with Dymola 2016.
To distribute this use-case, the global model must be
divided into multiple FMUs. The use of componentoriented modeling languages like Modelica usually makes
the cutting decisions easy. Moreover, DES usually offer a
lot of similarities, thus, one could consider creating communications between clusters of buildings, buildings or,
even deeper, between heating systems, thermal envelope,
and the network. In this section, we consider each building as one FMU, and the electrical network as another
one, in order to simplify the understanding of the results.
A smart handling of occupancy profiles has been implemented in the building models: the identity key, noted
668

Figure 9. Screenshot of DACCOSIM showing the Matryoshka of
the 12 Smart Buildings as a system of 14 FMUs with its external
inputs and outputs

6.2

Description of the Experiments

The pure Modelica model simulated under Dymola is used
as the reference for all the simulations performed in this
article. This allows us to assess the performance of the
other solutions in both their accuracy and computational
time. The Matryoshka FMU is compared to this reference.
This FMU is built by DACCOSIM integrating the electrical

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132663

Session 10A: FMI II

6.3
6.3.1

Results

1.0
0.8

Voltage (V)
Current (A)
Temperature (K)

0.6
0.4
0.2
0.0

10 -9 10 -8 10 -7 10 -6 10 -5 10 -4 10 -3 10 -2 10 -1 10 0 10 1 10 2
Absolute error

Figure 10. Cumulated distribution of the absolute error on voltage, current and temperature in one building zone: Matryoshka
compared to pure Modelica simulation in the 5 days case

It is especially important to correctly capture the minimum and maximum values of both grid voltages and currents in order to properly design the grid. The extrema
of the Matryoshka simulation should be close to the ones
computed with the pure Modelica model so that we can
use DACCOSIM results with as much trust as Dymola ones.
Table 2 shows the minimum, mean and maximum error
over the 12 buildings on the maximum values of current
and voltage. The error is kept low with maximum errors
of 5 mA, 0.7 mV and 1.6 mV.
With such error levels, using a Matryoshka in a cosimulation is relevant for distribution grid design. The
representation of the use case dynamics as well as its accuracy are sufficient for a correct simulation of the network
and its usages.
6.3.2 Matryoshka Computational Performance

Matryoshka Accuracy

Providing sufficient accuracy is a key-aspect of a cosimulation. Splitting a model such a DES into smaller
subparts exported and then interconnected as FMUs creates propagation delays: they depend on the largest number of linked FMUs separating the start from the end of the
co-simulation graph and the sum of the varying time step
sizes observed for each propagation sequence. It is thus
important to use time step adaptive strategies to shorten
the time steps when model dynamics are important and
enlarge them when they stabilize.
Using Euler adaptive approach in the Matryoshka, we
obtained the cumulated distribution displayed in Figure 10. It illustrates the repartition of the absolute error of
the Matryoshka model to the pure Modelica model chosen
DOI
10.3384/ecp17132663

as reference, respectively for voltage, current and temperature norms for the five days simulation case. 95.0 % and
99.8 % of the measurement points have an absolute error lower than 101 for respectively current and voltage.
This is to be compared with the current Smart Meter capabilities: on voltage an accuracy of 0.5 % of the nominal
voltage, i.e. about 1.15 V , is expected.

Cumulative distribution

network and its 12 Smart Buildings as FMUs. Each inner
FMU is generated using Dymola 2016.
Similar tests are performed in DACCOSIM and Dymola
environments: considering a constant step size, a voltage
is imposed to the DES system FMUs. This input comes
from a Modelica block in Dymola and from its FMU counterpart in DACCOSIM.
The comparisons are carried out for a simulated time
from one to five days. Realistic demand and occupancy
data as well as weather data are used, therefore creating
a variability in the calculations between each simulated
day. The accuracy of several variables is relevant regarding the validation of the design of the electric grid with
Smart Buildings, among them:
 the inner temperature of the buildings;
 the norm of the voltage and the current;
 the correct capture of the extrema of these quantities.
The Dymola model was simulated with tolerances of
104 , 105 and 106 . Output points are saved every 60 s.
The Matryoshka is set up with a relative tolerance on each
FMU internal solver of 104 , as well as a relative tolerance on the outputs of the FMUs of 103 for temperature and voltage, and 102 for currents. Euler algorithm is
used inside the Matryoshka to manage the step size, with
a minimum step size of 1 s and a maximum of 40 s. The
Matryoshka is then simulated along the voltage data FMU
with a constant step size of 60 s. The results obtained for
these four configurations for a one and five days of continuous simulation are shown in Table 1. It is clear that
the results of the Matryoshka co-simulations are closer to
the ones of the Dymola model with a tolerance of 106
than to the other Dymola setups. Thus in the following,
the performance of the Matryoshka will be compared with
the Dymola model with a tolerance of 106 on longer simulations.
All the simulations are performed on a laptop computer
with 4 physical cores and 8 logical threads with a maximum speed of 2.50 GHz (Intel i7-4710MQ) and 8 Gb of
RAM running under Windows 8.1 64 bit.

The computation time of the pure Modelica model simulated under Dymola should not be lower than the one of
the FMU co-simulation under DACCOSIM to make it relevant to use Matryoshka FMUs.
The results of the execution time measurement can be
seen on Figure 11. The speed up starts around 1.5 for one
day, grows and stabilizes itself around 3.5. This performance is quite interesting when doing simulation on long
time scales. The changes of the speed up might be due
to the variable calculation load induced by the different
occupancy and weather profiles considered for every day.
Using a Matryoshka co-simulation also enables to tune
the tolerance on the relevant variables when doing simulations for design purposes. The user can thus have the
accuracy he needs in a shorter time.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

669

Building Parallel FMUs (or Matryoshka Co-Simulations)

Table 1. Performances of the different configurations for one and five days simulations

Mean RMSE over the 12 buildings
Model

Computation time (s)

Dymola (104 tolerance)
Dymola (105 tolerance)
Dymola (106 tolerance)
Matryoshka

On current (A)

On voltage (V)

1 Day

5 Days

1 Day

5 Days

1 Day

5 Days

191
169
139
79

2633
2329
2375
666

1.34
3.25  101
reference
7.99  102

8.69  101
2.52  101
reference
1.39  101

1.17  101
3.13  102
reference
7.08  103

7.10  102
2.04  102
reference
1.18  102

Table 2. Errors on extrema aggregated on the 12 buildings

Error type

Absolute Error

Max. error on max. voltage
Max. error on min. voltage
Max. error on max. current

6.97  101 mV
1.62 mV
5.04 mA

builder makes its generation automatic: once the simulated use-case is set, a single click in the DACCOSIM user
interface generates such an FMU.
With DACCOSIM Matryoshka FMUs, complex real-life
systems can thus be easily simulated, finely tuned, and improved in their computation efficiency while allowing an
easy implementation within any FMI-CS compliant simulation environment.

Work is currently being carried out to further improve
their capabilities. Some can be performed with the current
FMI standard, while others require new attributes :
 When the user chooses the target platform and architecture (Linux, Windows or both) for the Matryoshka
FMU we will check that the choice is conform with
the platform(s) targeted by the inner FMUs.
 We are working to allow the Matryoshka FMU to
save and restore its state (if all its inner FMUs have
this capability). So, the Matryoshka could be included into any co-simulation which might require
FMUs to rollback.

We are investigating a way to build a Matryoshka
Figure 11. Computation time of the pure Modelica and FMU
which distributes its simulation on multiple cluster
simulations with speed up
nodes. We also wish to include new information
about the number of inner FMUs in its modelDescription.xml file. This would provide useful infor7 Conclusions and Future Work
mation about the number of created threads in order
The Matryoshka FMU we have presented in this paper
to automate its placement on HPC cluster nodes.
and successfully implemented on a real-life test case is a
first of its kind that is compliant with the latest version
of the FMI 2.0 standard and built with an open-source so- 8 Acknowledgment
lution DACCOSIM. The FMIBench commercial tool can
also build hierarchical FMUs but supports fully only the Authors thank Region Grand Est and RISEGrid institute
version 1.0 of the FMI standard and we have no knowl- for their support to this research. The modeling of the
edge about the co-initialization and co-simulation features electrical network and the smart buildings was conducted
within the EFRO-SALK project, which receives the supimplemented within the embedded master.
By taking advantage of the FMI standard capabilities, port of the European Union, the European Regional Dea Matryoshka FMU can be easily integrated within any velopment Fund, Flanders Innovation & Entrepreneurship
FMI-CS compliant simulator on any Windows or Linux and the Province of Limburg.
64 bits system. Such FMU could even be easily deployed
on a node of a HPC-cluster environment. The use of DAC - References
COSIM parallel master architecture allows to achieve both R. Baetens and D. Saelens. Modelling uncertainty in discomputational efficiency and accuracy thanks to its intrict energy simulations by stochastic residential occupant
ternal adaptive time step mechanisms and its capability to
behaviour. Journal of Building Performance Simulation,
finely tune the tolerance on its variables. The JavaFMI
(September), 2015.
670

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132663

Session 10A: FMI II

R. Baetens, R. De Coninck, F. Jorissen, D. Picard, L. Helsen,
and D. Saelens. OPENIDEAS - An Open Framework for
Integrated District Energy Simulations. In Proceedings of
Building Simulation 2015, 2015.
S. Baggi, D. Rivola, V. Medici, G. Corbellini, D. Strepparava,
and R. Rudel. Modeling and Simimulation of a residential
Neighborhood with Photovoltaic System Coupled to Energy
Storage Systems. In 29th European Photovoltaic Solar Energy Conference and Exhibition, 2014.
T. Blochwitz and M. Otter. The Functional Mockup Interface
for Tool independent Exchange of Simulation Models. 8th
International Modelica Conference, 2011.
B. Camus, V. Galtier, and M. Caujolle. Hybrid Co-simulation of
FMUs using DEV and DESS in MECSYCO. In Symposium
on Theory of Modeling and Simulation, 2016.
J. Evora, J. J. Hernandez, and O. Roncal. JavaFmi. URL
https://bitbucket.org/siani/javafmi/.
V. Galtier, S. Vialle, C. Dad, J-P. Tavella, J-P. Lam-Yee-Mui,
and G. Plessis. FMI-Based Distributed Multi-Simulation with
DACCOSIM. In Symposium on Theory of Modeling and Simulation - TMS15, 2015.
C. Protopapadaki, R. Baetens, and D. Saelens. Exploring the impact of heat pump-based dwelling design on the low-voltage
distribution grid. In 14th Conference of International Building Performance Simulation Association, 2015.
J-Ph. Tavella, M. Caujolle, S. Vialle, C. Dad, C. Tan, G. Plessis,
M. Schumann, A. Cuccuru, and S. Revol. Toward an Accurate and Fast Hybrid Multi-Simulation with the FMI-CS Standard. IEEE ETFA Track 9 - Information and Communication
Technology in Energy Systems, 2016.
J. Vaubourg, Y. Presse, B. Camus, C. Bourjot, L. Ciarletta,
V. Chevrier, J-P. Tavella, and H. Morais. Multi-agent MultiModel Simulation of Smart Grids in the MS4SG Project. In
PAAMS15, 2015.
M. Wetter, M. Bonvini, and T. Nouidui. Equation-based languages - A new paradigm for building energy modeling, simulation and optimization. Energy and Buildings, 2015.
G. Zucker, F. Judex, M. Blchle, M. Kstl, E. Widl, S. Hauer,
A. Bres, and J. Zeilinger. A new method for optimizing operation of large neighborhoods of buildings using thermal simulation. Energy and Buildings, 2016.

DOI
10.3384/ecp17132663

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

671

672

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs
on Infiniband Cluster
Stephane Vialle1,2

Jean-Philippe Tavella3 Cherifa Dad1 Remi Corniglion3
Vincent Reinbold 4

Mathieu Caujolle3

1 UMI

2958 - GT-CNRS, CentraleSupelec, Universit Paris-Saclay, 57070 Metz, France
2 LRI - UMR 8623, 91190 Gif-sur-Yvette, France
3 EDF Lab Saclay, 91120 Palaiseau, France
4 University of Leuven, Department of Civil Engineering, 3001 Leuven, Belgium

Abstract
In recent years, co-simulation has become an increasingly
industrial tool to simulate Cyber Physical Systems including multi-physics and control, like smart electric grids,
since it allows to involve different modeling tools within
the same temporal simulation. The challenge now is to integrate in a single calculation scheme very numerous and
intensely inter-connected models, and to do it without any
loss in model accuracy. This will avoid neglecting fine
phenomena or moving away from the basic principle of
equation-based modeling.
Offering both a large number of computing cores and
a large amount of distributed memory, multi-core PC
clusters can address this key issue in order to achieve
huge multi-simulations in acceptable time. This paper introduces all our efforts to parallelize and distribute our
co-simulation environment based on the FMI for CoSimulation standard (FMI-CS). At the end of 2016 we succeeded to scale beyond 1000 FMUs and 1000 computing
cores on different PC-clusters, including the most recent
HPC Infiniband-cluster available at EDF.
Keywords: Multi-Simulation, FMI, Scaling, Multi-core,
PC Cluster

1

Introduction and Objectives

A multi-simulation based on the FMI for Co-Simulation
standard is a graph of communicating components (named
FMUs) achieving a time stepped integration, under supervision of a global control unit (named Master Algorithm
in the standard), as illustrated in Fig. 1. During a time
step, all FMU inputs remain constant and all FMUs can be
run concurrently. When all FMU computations of a time
step are finished, the FMU outputs are routed to connected
FMU inputs, and all FMUs communicate with the Master
Algorithm. When using adaptive time steps or managing
events inside the time steps, the Master Algorithm has a
complex role to decide on the next time step to execute.
In order to run wide multi-simulations requiring large
memory and heavy CPU resource consumption, we first
need to distribute and process a co-simulation graph on
several PCs. Second, to achieve scaling we need (1) to
speedup a co-simulation using more computing resources
(cores and PCs), and (2) to strive to maintain the same execution time when running larger co-simulations on more
DOI
10.3384/ecp17132673

Figure 1. Generic FMU graph implementing a multi-simulation

PCs. Of course to achieve this, we attempt to minimize the
global execution time as the sum of all the parallel FMU
computation substeps, the FMU communication substeps,
and the graph control substeps.
In 2014 we designed a distributed and parallel
FMI based multi-simulation environment, named DACCOSIM1 (Galtier et al., 2015), integrating a hierarchical and distributed Master Algorithm. Available under
AGPL for both Windows and Linux operating systems,
DACCOSIM2 achieves a multi-threaded execution of local FMUs on each node with concurrent run of different
FMUs on cluster nodes, and frequent data exchange between nodes (see section 2). Then, we decided to optimize and facilitate the execution of our environment on
multi-core PC clusters, which are our typical computing
platforms. Unfortunately, FMUs are kind of opaque computing tasks frequently exchanging small messages. They
are very different from optimized High Performance Computing tasks, and we faced different difficulties. In 2016
we succeeded to exhibit scaling on a co-simulation of heat
transfers in a set of n three-floor buildings, and we efficiently run up to 81 FMUs on a 12-node PC cluster with a
10 Gbit/s Ethernet interconnect and 6 cores per node (Dad
et al., 2016). However, we needed to identify the optimal distribution of one building on a minimum set of
cluster nodes after running several benchmarks, and we
scaled our co-simulation replicating our initial building
and its optimal distribution. This approach has proven it is
possible to achieve scaling on distributed FMI based cosimulations, despite the unusual features of an FMU task
graph, from a classic parallel computing point of view. We
have carried on with this work, in order to automate the ef1 https://daccosim.foundry.supelec.fr
2 Partially

supported by Region Lorraine (France)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

673

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster

ficient distribution of wide co-simulations on large multicore PC clusters, aiming to distributed thousands of FMUs
on thousands of computing cores.
The paper is organized as follow. Next section describes the features of an FMU graph execution, the principles of its execution, and the choices done when designing the DACCOSIM architecture. Section 3 lists all
sources of parallelism and also performance losses in an
FMU graph running on a multi-core PC cluster, in order to design an efficient software architecture of multisimulation. Section 4 investigates the distribution of the
FMU graph on a multi-core PC cluster, with poor or rich
meta-data on the FMU graph, in order to maximize performance. Then, section 5 introduces our new large scale
benchmark detailing reached numerical results, perforFigure 2. DACCOSIM software architecture
mance and scalability. Finally, section 6 lists our current
library being either a self-contained executable comporesults and remaining challenges.
nent or a call to a third-party tool at run-time (tool coupling). FMI-CS is focused on the slave side (FMU) and
2 FMI-CS based Multi-Simulations
remains very discreet on the master side (Master Algorithm). The way a simulation tool utilizes the functional2.1 FMI-CS Strengths and Limitations
ity provided by FMUs is strongly related to the simulation
Modern electric systems are made of numerous interactparadigm on which the tool relies:
ing subsystems: power grid, automated meter management, centralized and decentralized production, demand  Some co-simulation middleware use the Agent & Artifact paradigm (Ricci et al., 2007) to describe an hetside management (including smart charging for electric
erogeneous multi-model, and they rely on the Disvehicle), storage, ICT resources. . . Beyond a consensus on
crete EVent System Specification (DEVS) formalthe language to use, modeling wide and complex systems
ism (Zeigler et al., 2000) to conceive a decentralized
in one universal modeling tool implies to make some simexecution algorithm respecting causality constraints.
plifications that may lead to minimize important phenomBut conservative algorithms, such as Chandy-Misraena. As historic and domain-specific tools validated their
Bryant (Chandy and Misra, 1979) used in some A&A
business libraries since a long time, the most rational aptools like MECSYCO4 , do not integrate the concept of
proach to simulate wide Cyber Physical Systems (CPSs)
rollback. They must be adapted to restore FMUs to a
consists in recycling specialized simulation tools in a coprevious state and adjust the step size in case of events
simulation approach.
or fast system dynamics (Camus et al., 2016).
The Functional Mock-up Interface for Co-Simulation
(FMI-CS) specification can now be considered as a well-  Another class of tools is based on the synchronization
established standard for co-simulation thanks to numerof the communication points of all the FMUs involved
ous developments done by industrial parties (Blochwitz
in a calculation graph. Unfortunately these tools often
et al., 2011). A growing number of business tools - like
stick to the master pseudo codes given as examples in
EMTP-RV3 for electromagnetic transient modeling - have
the FMI standard with a centralized algorithm acting as
adopted the standard and added FMI connectors to their
a bottleneck for all the communication (data exchanges
products. FMI-CS allows to obtain a fairly realistic repreand control information).
sentation of the whole system behavior since all the subsystems are equally taken into account without the pre- 2.2 DACCOSIM Architecture Choices
eminence of a domain (e.g. ICT) on another (e.g. physics). In our attempts to design, distribute and co-simulate on
It allows the building of stand-alone active components cluster nodes very wide systems composed of thousands
(FMUs) that can be executed independently of each other. of FMUs, we need both to synchronize all the communiFMUs exchange data (with other FMUs or with external cation points (for accuracy purpose) and decentralize the
components) only at some discrete communication points. usual control function of the Master Algorithm (for perIn the time interval between two communication points formance purpose). First versions of these features were
each FMU model is simulated by its own numerical solver, available within DACCOSIM in 2014.
and a Master Algorithm controls the FMU graph at each
DACCOSIM 2017 emphasizes a complete and usercommunication point (see Fig. 1).
friendly Graphical User Interface (GUI) to configure and
An FMU for Co-Simulation consists of a ZIP file con- perform local or distributed co-simulations with potentaining an XML-based model description and a dynamic tially many heterogeneous FMUs compliant with the co3 http://emtp-software.com/

674

4 http://mecsyco.com/

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132673

Session 10A: FMI II

simulation part of the FMI 2.0 standard (FMI-CS 2.0). A
DACCOSIM calculation graph consists of blocks (mainly
FMUs) that are connected by data-flow links and potentially distributed on different computation nodes. The
graph is then translated into Java master codes in conformance with the features described in the FMI-CS 2.0 standard. More precisely, DACCOSIM notably offers for the
co-initialization of its calculation graph:

 Automatic construction of the global causal dependency graph, built both from the FMUs internal dependencies and the calculation graph external dependencies. An acyclic view of the graph is generated by
aggregating each cycle as a super-node composed of
Strongly Connected Components (SCCs);

Figure 3. Concurrent run times on a 2x4-core node

 Generalized distributed co-initialization algorithm,
mixing a sequential propagation method applied to
the acyclic dependency graph, and a Newton-Raphson
method solving its SCCs.
And for co-simulation, it offers among others:

 Implementation of each FMU wrapper as two threads
allowing to concurrently run computations and send
messages (FMU & control) while receiving incoming
messages;

Figure 4. Slow down of concurrent runs on a 2x4-core node

middleware, allowing direct communications between dif Overlapped (optimistic) or ordered (pessimistic) data ferent threads located on the same or on different PC clussynchronization inside distributed masters (see section ter nodes. For intra-node communications, a mechanism
3.3), that can operate with constant time steps or with of shared message queue is also available.
adaptive time steps controlled by one-step methods
(Euler or Richardson) or a multi-step method (Adams- 3 Parallelism Sources and Limitations
Bashforth);

3.1

FMU Computations

 Approximate event detection while waiting for a new
version of the FMI standard able to correctly handle hy- Each computing substep is a high source of parallelism,
as all FMUs can concurrently achieve their computations.
brid co-simulations (Tavella et al., 2016).
However, running n f FMUs on nc cores of the same comDACCOSIM generated master codes follow a central- puting node can lead to imperfect concurrency: (1) when
ized hierarchical approach (see Fig. 2). A unique global there are less cores than FMUs (nc < n f ), and (2) when the
master located on one cluster node is in charge of han- FMU computations access the node memory and saturate
dling the control data coming from several local masters the memory bandwith. Taking into account this FMU conlocated on other cluster nodes and taking step by step de- currency imperfection, we will deduce the optimal number
cisions based on this information. Every master, whether of FMUs to run on each computing node, and so the total
global or local, aggregates these control data that are com- number of nodes to use (see section 4).
ing from each FMU wrapper present on its cluster node.
This is done before communicating synthesized informa- 3.1.1 FMU Concurrency Experiment
tion to the global master. The control data exchanged be- We concurrently run HPC computing kernels of dense matween masters and between FMUs and masters are called trix product (C = A  B, a reference HPC benchmark) on
vertical data. Of course when the co-simulation is run on one of our cluster computing node. We used an OpenBLAS
a single machine, only one master code is generated.
dgemm kernel, and a NUMA dual-haswell node with 2  4
An original feature of the DACCOSIM architecture lies physical cores at 3.5 GHz, and 2  15 MB of cache memin the fact that the FMU variable values to be exchanged at ory. Fig. 3 shows the execution times measured on difeach communication step are directly transmitted from the ferent problem sizes, with optimized OpenBLAS kernels
senders to receivers without passing by a master. The mas- blocking data in cache to minimize the memory bandwidth
ters, the wrapped blocks (mainly FMUs with wrappers) as consumption. For each problem size, we concurrently run
well as the communication channels between them are au- from 1 up to 64 threads, each thread executing one comtomatically generated by DACCOSIM by translating the plete call to the kernel on locally allocated data structures.
calculation graph defined by the user via its GUI. All com- We considered (1) two large matrix sizes: 2048  2048
munications are implemented using ZeroMQ (or ZMQ) matrices of 32 MB and 4096  4096 matrices of 128 MB,
DOI
10.3384/ecp17132673

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

675

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster

tions (a new FMU could enter its computation substep
only when a previous one finished its substep).
But performance measured when limiting the concurrency of many FMUs on a same node were disappointing:
the total computation time still increased. We have not
succeeded to improve the execution of many concurrent
FMUs per node with a basic scheduling mechanism.
Figure 5. Size up experiments on 1 Gb/s and 10 Gb/s clusters

3.2

FMU Communications

3.2.1 Main Features of Inter-FMU Communications
each matrix being larger than the entire node cache, and
(2) a smaller problem with 1024  1024 matrices of 8 MB,
allowing to store the three matrices of the problem into
one node cache. Each curve illustrates the global execution time evolution when running more concurrent computations.
Fig. 4 shows the slow down observed when increasing the number of concurrent computations: SD(n) =
t(n)/t(1). Our optimized OpenBLAS kernel exhibits
good concurrent performance, with a very limited slow
down up to the 8 physical cores, followed by a first slow
down increase up to the 16 logical cores (exploiting hyperthreading), and a linear increase when running more concurrent tasks serially processed by the node cores. Then,
we concurrently run several threads executing the same
FMU5 , modeling heat transfers and achieving significant
computations with the cvode solver6 . We can observe
in Fig. 4 that these concurrent FMU executions (1) exhibit a limited slow down, up to (nc  2) FMU computing
threads, similar to the behavior of concurrent OpenBLAS
kernels, and (2) then quickly increase their slow down beyond (nc  2) FMU computing threads per node, going
away from OpenBLAS kernel curves.
In fact some extra tasks are running in parallel of the
FMU computation threads in DACCOSIM, and it is not
surprising the slow down starts to increase a little bit before deploying one FMU per physical core. But the slow
down increase appears stronger than with OpenBLAS kernels, and is militantly in favour of running only (nc  2)
FMUs per computing node and using additive nodes. Of
course, this experimental study will need to be conducted
on different cluster nodes with different FMUs in the near
future to confirm the definition of the ideal number of
FMUs to deploy and run on a multi-core cluster node.

There is no order in the inter-FMU communications of a
time step, they can all be routed in parallel, fully exploiting the cluster interconnect bandwidth. Moreover, FMU
communications inside a computing node can be achieved
faster (no crossing of network connections no network
software layer). But data exchanged between two FMUs
are usually small (like one or a few floating point values).
Each FMU communication is sensitive to the network and
applicative latency: time to transfer a byte from one JVM
(running FMUs) on one node to another JVM on another
node, in current DACCOSIM implementation. Moreover,
an FMU graph has many connections generating communications at the end of each time step.
So, communication features of multi-simulations are
different from classic HPC application ones, which always
attempt to group data and exchange large messages not too
frequently. FMU communications are small, numerous
and frequent, however their implementation can be parallelized.
3.2.2 Sensitivity to Latency and Bandwidth

Respective weights of FMU computations and communications depend on the FMU graph and the multisimulation. We have run some size up experiments on
our multi-simulation of heat transfer inside buildings. We
have implemented larger simulations using greater number of computing nodes, replicating buildings on new
nodes. Theoretically, the execution time of the multisimulation should have remain almost constant (FMU
computation time remained constant on each node, and
communications were routed in parallel). Experimentally,
Fig. 5 shows the execution time increase on PC clusters
with 1 Gb/s and 10 Gb/s Ethernet interconnects. This time
increase is more limited on the 10 Gb/s Ethernet interconnect. These experiments of heat transfer multi-simulations
3.1.2 Unsuccessful Performance Improvement
have pointed out the importance of the communications
When the number of available computing nodes is limited, and the sensitivity to the interconnect speed.
it leads to run many FMUs on a same node, many more
than (nc  2). Then, we attempted to reduce the computa- 3.2.3 Difficulty to Fully Use Infiniband Interconnect
tion time limiting the number of FMUs simultaneously run In order to reduce cost of these intensive and short comin parallel on a same computing node. We implemented a munications, an interesting issue consists in using low lasemaphore-based synchronization-mechanism, authoriz- tency and high bandwidth interconnects of standard HPC
ing only nmax FMUs to concurrently run their computa- clusters, like some Infiniband networks. However, it requires to use some constrained middleware or communi5 FMUs were designed at EDF Lab Les Renardires using
cation libraries from HPC technologies (like MPI library),
BuildSysPro models, and generated with Dymola 2016
6 Sundials suite of nonlinear and differential/algebraic equation
with native Infiniband interface. Using modern and consolvers, of the LLNLs Center for Applied Scientific Computing
fortable middleware (like ZMQ in DACCOSIM environ676

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132673

Session 10A: FMI II

Figure 6. Relaxed synchronization of time step subparts

Figure 7. Overlapped orchestration mode

ment) leads to use Infiniband networks over TCP/IP adapwhen it has updated all its inputs, it enters its next comtors and to loose their very low latency (Secco et al., 2014).
putation substep.
We attempted to use the MPI library to implement
 If an FMU receives the command to roll back (bottom
our multi-simulation communications, but MPI has been
of Fig. 6), it restores its previous state at ti and reruns
designed for process-to-process communications and ap0
=
its computation step, but progresses from ti up to ti+1
peared not adapted to DACCOSIM thread-to-thread com0
0
ti + h , with h < h the new time step broadcasted by the
munications, where each thread manages an FMU. We
M.A.
have currently suspended this investigation, and we use
So, the only global synchronization barrier is the M.A.
Infiniband networks over TCP/IP adaptors.
decision broadcast, that all FMUs are waiting for. Oth3.2.4 Minimizing Message Sizes
ers synchronization points are relaxed ones, that stop only
Current communication mechanisms of DACCOSIM send one task (the M.A. or one FMU). Then, each task going
FMU output data as strings, and send input name strings over a relaxed synchronization point carries on with its
instead of short input identifiers (like input indexes). Fu- work independently of others tasks. Relaxed synchronizature versions of DACCOSIM will implement shorter data tion allows to increase performance, avoiding time conencoding in order to reduce message sizes and bandwidth suming synchronization barriers and avoiding to synchronize all FMUs on the current slowest ones (the ones with
consumption.
longest computations or communications at current time
3.3 Time Step Subparts Orchestration
step). Algorithms with relaxed synchronization schemes
3.3.1 Ordered Orchestration with Relaxed Synchro- are usually more complex to implement and to debug, but
ZMQ middleware has allowed an easy and efficient implenization
mentation of these communication and synchronization
Basic orchestration of a time step is illustrated on Fig. 6, mechanisms between threads across a PC cluster.
and follows a relaxed synchronization mechanism. All
FMU computations are run in parallel to progress from ti 3.3.2 Overlapping Strategy
up to ti+1 = ti + h, and as soon as an FMU has finished To still reduce the communication cost, a solution consists
its computation substep it sends its requirements to the in overlapping some of the communications with some
Master Algorithm (M.A.): to roll back and rerun with a FMU computations, and with the Master Algorithm decismaller time step (to increase accuracy), to continue with sion pending. Fig. 7 illustrates these mechanisms. When
the same time step, or to continue with a greater time step. an FMU has finished its computation substep, it sends its
Then, the M.A. processes each received requirement but requirements to the M.A. and, not waiting for M.A. deawaits all requirements (synchronization point S0 ) before cision broadcast, enters its communication substep. So,
taking a global decision, and broadcasting its decision to FMUs update their input values while the M.A. collects
all FMUs. All FMUs wait for the M.A. global decision, their requirements and broadcasts its global decision.
and as soon as an FMU receives the M.A. decision (sync.
But, depending on the pending time of the M.A decison
point S1 ), it rolls back or continues its time step.
and on the number of inter-FMU communications, each

 If an FMU receives the command to continue (top of
Fig. 6), it enters its communication substep, sending its
output results to connected FMUs and waiting for the
update of all its input values (sync. point S2 ). Finally,
DOI
10.3384/ecp17132673

FMU can cross its synchronization points S1 (M.A. decision broadcast) and S2 (all input update received) in any
order (see FMU1 and FMU2 examples on Fig. 7). So,
when both S1 and S2 synchronization points have been

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

677

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster

crossed, each FMU considers the M.A. decision:

 If the M.A. has broadcasted a command to continue,
then each FMU enters its new computation substep
(see top of Fig. 7), and has saved some execution
time achieving its inter-FMU communications while
the M.A. decision was pending.
 If the M.A. has broadcasted a command to rollback,
then each FMU waits for the end of its communications,
restores its state at the beginning of the time step, and
0 . In this case,
reruns its computation from ti up to ti+1
the overlapping mechanism has a little bit increased the
execution time, achieving unnecessary inter-FMU communications.

CS standard improvement leads to execute a maximum of
one rollback per FMU each time an unpredictable event
appears during a time step. In the end, we do not know
in advance how much the execution time will decrease but
we are sure to achieve higher accuracy while improving
the computation performance.

4
4.1

FMU Placement Strategies
Not a Dependence Graph Problem

A DACCOSIM program running a total of nF FMUs is
composed of nF FMU wrapper tasks, nF data receiver
tasks, plus a local or global control task per computing
node (implementing our hierarchical M.A., see section
2.2). Of course, a DACCOSIM program can be considered as a dependency task graph, and some strategies exist
to distribute such a graph on a PC cluster (Sadayappan and
Ercal, 1988; Kaci et al., 2016). However, a DACCOSIM
task graph has some specific task dependencies. During
one time step in ordered orchestration mode, all FMUs
execute three substeps as illustrated on Fig. 8:

From a theoretical point of view, our overlapping mechanism reduces the execution time when there are few rollbacks, or when using constant time steps. But from a
technical point of view, some threads will work to send
and receive messages while some threads will achieve the
end of long FMU computations (M.A. decision broadcast
is no longer a synchronization barrier). The communication threads could disturb the ongoing computations and  The computation substep (Fig. 8 part a): all FMU wrapslow down the multi-simulation, especially when running
per tasks run concurrently and autonomously, achievmore threads than available physical cores (see section
ing the FMU computations. There is no dependence
3.1). Nevertheless, our overlapped orchestration mode has
between these tasks during this substep. The only optiappeared efficient on our multi-simulation of heat transfer
mizations consist in load balancing the FMU computainside three floor building, run on a 6-core node cluster
tions among the computing nodes, and to set only nc 2
with a 10 Gb/s Ethernet interconnect. Section 5 will show
FMU per nodes when there are enough available comthe performance achieved on our benchmark of power grid
puting nodes, according to section 3.1.
multi-simulation.
 The control substep (Fig. 8 part b): each FMU wrapper
task sends its wish to the control task for the next op3.4 Event Handling Impact
eration (rollback or continuation, and size of the future
To increase their genericity, it seems necessary for CPSs to
time step) and waits for its global decision. There is a
handle more signal kinds especially continuous & piecetotal dependence of the control task to all the wrapper
wise differentiable signals, piecewise continuous & diftasks, followed by a total dependence of all the wrapferentiable signals and piecewise constant signals, which
per tasks to the control task, close to a synchronization
are sources of events. The current FMI-CS 2.0 rebarrier for the FMU wrapper tasks (see section 3.3).
lease (Blochwitz et al., 2011) can theoretically approach
There is no optimization to achieve when distributing
events thanks to for example a bisectional search using
the FMU graph, excepted to implement a local control
variable step size integration (Camus et al., 2016). But
task on each node to manage its FMU wrapper tasks.
only events due to piecewise constant signal changes can
be detected. And the solution involves bad performance  The communication substep (Fig. 8 part c): it is only
achieved when no rollback is ordered by the control
as it is based on rollbacks and finally some inaccuracies
task. Each FMU wrapper task sends its new outputs
appear due to the last non zero integration step size.
to connected FMU inputs, while each FMU receiving
We proposed to add new primitives in the FMI-CS stantask ensures the reception of the new input values of the
dard (Tavella et al., 2016) in order to integrate hybrid coFMU. These communication operations are not CPU
simulation in a pure FMI-CS environment. Our solution
consuming. So, we run in parallel up to 2  n f tasks on
does not require any model adaptation and allows to coueach computing node hosting n f FMUs, in order to opple physics model with continuous variability and contimize
the communications (see section 3.3). All these
trollers with discrete variability. Moreover, parallelism is
tasks
run
without any synchronization nor dependence
not reduced by our approach, as all FMUs continue to run
during
the
communication substep, and the only opticoncurrently either when processing shorter time steps,
mization
when
distributing the FMU graph consists in
or when executing rollbacks. So, event handling by the
grouping
on
the
same node the most strongly connected
FMI-CS evolution we have proposed does not require to
FMUs
(fighting
with the load balancing objective).
change our parallel and distribution strategy of FMU cosimulation graph.
In fact, we can classify our DACCOSIM task graph as a
From a computing performance point of view, this FMI- periodic task graph. Its period is equal to one time step,
678

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132673

Session 10A: FMI II

When the best distribution of a one-building problem
(using n0 nodes) was identified, we enlarged the problem with k buildings, replicating our best distribution (using k  n0 nodes). We successfully scaled up (Dad et al.,
2016): processing larger problem on larger cluster in
similar time. But this approach takes too long development times, and replicating the best elementary distribution leads to use too many nodes, some cores remaining
unused. This approach cannot be a generic solution.
4.2.2 Approach function of the User Knowledge
Figure 8. Multi-task synchronization overview (ordered mode)

and includes 2 phases (a and c) with pure concurrent task
executions, and one phase (b) which is a kind of synchronization barrier (with only the control task working). So,
we do not consider the task dependencies to distribute our
FMU graph on a PC cluster. We focus on load balancing,
on grouping the most connected FMUs, and on limiting
the number of FMU per nodes (when there are enough
available nodes).
IFP EN and INRIA succeeded to parallelize computation inside wide FMUs thanks to a fine scheduling of
basic operation executions on one multi-core node (Saidi
et al., 2016). The practical speed-up observed by our colleagues is achieved by imposing a constrained allocation
of all the operations of a same FMU to the same core.
Their approach is complementary to ours as they optimize
the co-simulation of FMUs on the different processors of
the same calculation node while we are optimizing the deployment of a calculation graph composed with lots FMUs
on a possibly wide set of multi-core nodes.

4.2

Different Contexts and Approaches

The main trouble to establish a good distribution of the
FMU graph on a PC cluster is the lack of metadata about
FMU computations in the FMI-CS standard. There is no
information about FMU computation time, or computation complexity. Dynamic load balancing is out of reach
of our current implementation, and static load balancing
of the computations on the nodes of a PC cluster remains
difficult. This section introduces the different approaches
we identified to distribute FMU graphs.
4.2.1

Previous Experimental Approach

In the beginning of 2016 we distributed on two PC clusters
a first multi-simulations of heat transfers inside buildings.
Each building was a subgraph of only 10 FMUs. We ran
a small one-building problem setting only one FMU per
node, so that FMUs could run the real simulation without disturbing each other (not sharing cache memory, nor
memory bandwidth, nor cores. . . ). We measured the computation time of each FMU (to characterize our different
FMUs), and then we established the most load balanced
FMU distributions on various number of nodes. Finally,
some complementary experiments allowed to identify the
most efficient distribution of a one-building problem on
each PC cluster.
DOI
10.3384/ecp17132673

From our point of view, distributing a totally unknown
FMU graph or a fully characterized FMU graph should
be infrequent DACCOSIM use cases. Users build cosimulations based on their expertise and have an initial
knowledge about computation loads and communication
volumes in their FMU graphs, allowing to use basic distribution mechanisms. When testing and improving their
co-simulations they accumulate knowledge on their FMU
graphs, and can use more complex heuristics. However, it
is not obvious to design an efficient heuristic.
During the development phase of a co-simulation many
FMU graphs are only run a few times and the FMU graph
distribution has to be computed quickly, without long calibration steps. But when a co-simulation design is finished
and successful, it can enter a long exploitation phase, requiring frequent runs. Then, it can be profitable to make
detailed performance measurements and to compute a fine
distribution of the FMU graph, in order to use less computing nodes and/or to decrease the co-simulation time.
Considering current and future usage of DACCOSIM at
EDF, for smart grid co-simulations, we identified 3 levels
of user knowledge, and we propose 3 associated generic
FMU distribution approaches.
a - Identifying FMU Families: when users have only
minimal technical and skill information about their cosimulations, and are able just to group the FMUs in families with close computing load.
Proposed approach: each family will form an FMU list,
and the concatenated list of all FMU families will be distributed on the computing nodes according to a roundrobin algorithm. This approach requires light knowledge
on the FMUs used, and succeeded to load balance the
FMU computations on our benchmark (see section 5).
Extreme use case: If no information is available on some
external FMUs, it is possible to group these FMUs in a
particular family to spread over the computing nodes. If
no pertinent information is available on any FMUs, it is
also possible to group all FMUs in a unique family, to
achieve a random distribution and to track a statistical load
balancing.
b - Cumulating Knowledge for Heuristics: when users
progress in their co-simulation development they improve
their knowledge about their FMUs and FMU graph. This
extra-knowledge can be exploited by more or less generic
heuristics to improve the FMU distribution. For example:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

679

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster

 running and testing different configurations of the FMU
graph allows to learn some relative computing weights
comput
comput
(ex: tFMU2
 0.5  tFMU1
),
 analyzing the FMU graph allows to detect some regular
patterns strongly connected (ex: a city area connected
on one medium voltage network of a smart grid).

I

1

3
2

5
4

19
18

20

building model
ventilation
heating system

XX

1

3
2

4

thermal

envelope
Proposed approach: design and use an heuristic (1) to opoccupancy
behavior
timize load balancing in order to reduce the global computation time, and/or (2) to group on same nodes the FMUs
Figure 9. Topology of the large scale testbed using IDEAS lib.
strongly interconnected in order to reduce the global communication time.
stead of creating a unique JVM per node managing all the
Warning: our experiments have shown the load balancing threads, can increase data locality and performance.
optimization is the most important criterion, however designing an efficient heuristic (improving performance of 5 Large Scale Experiments
the previous approach) remains difficult.
5.1 Experiment Objectives

c - Building Models of Computation and Communication Times: when an FMU graph enters an exploitation
phase, it can be profitable to establish an execution time
model of the co-simulation, to optimize its distribution and
the computing resource usage.
Proposed approach: (1) run smaller but similar cosimulations, deploying only one or very few FMUs per
node (to avoid mutual disruption between FMUs) and
measure each FMU computation time on the nodes of
the target cluster, (2) analyse the FMU graph to compute
the volume of each inter-FMU communication, and measure the experimental applicative latency and bandwidth
on the target cluster. Then, establish a computation and a
communication time model of the co-simulation, to feed a
solver looking for the best distribution of the FMU graph.

The co-simulation of a large scale District Energy System was chosen as a testbed. Co-simulation methods are
foreseen to handle several bottlenecks encountered during
CPS simulation on one single simulation tool, such as:
 Multi-Physics integration (electrical, hydraulic, thermal, etc.),
 Multiple time-scales and dynamics,
 Implementation of controllers,
 Scalability, i.e. the capability to study a growing number of buildings and the growing size of the power grid.
The numerical experiment consists in a complex multiphysical district energy system. The main purpose of
this section is thus to propose a proof of concept of cosimulation with lots of FMUs on a HPC cluster and to
highlight the advantages of such an approach for large
scale systems.

Warning: This approach requires long experimental measurements.
5.2
The IDEAS test case described in section 5, has been
distributed on different PC clusters according to the Identifying FMU families and the Cumulating knowledge for
heuristics approaches.

4.3

FMU Distribution on Virtual Nodes

Testbed Description

In this section, we propose to assess DACCOSIM Master
Algorithm efficiency by co-simulating an electrical distribution grid using a variable number of cluster nodes. The
model has been completely implemented using Modelica
and the OpenIDEAS library7 (Baetens et al., 2015). Neither the electrical grid, the heating systems nor the building envelops have been simplified.
The general structure of the use case is shown on Fig.
9. It is composed of 1000 buildings connected to low voltage (LV) feeders, each of them including a thermal envelope, ventilation and heating systems and a stochastic occupancy behavior. The buildings are dispatched on 20 low
voltage LV feeders, each modeled as one FMU, noted I to
XX on Fig. 9. These feeders are connected to a medium
voltage (MV) network that is also simulated with a single
FMU. A data-reading FMU provides real medium voltage measurements that are imposed at the MV substation
busbar. The electric grid frequency is provided to different FMUs (buildings and feeders) by 20 additional FMUs.

When the FMU graph is defined, the DACCOSIM software suite distributes the FMUs and generates Java source
files for a set of virtual nodes, and maps the virtual nodes
on the available physical computing nodes at runtime.
Then the Java source codes are compiled, a JVM is started
for each virtual node and its Java program is executed.
We defined intermediate virtual nodes in order to generate
Java source files independent of physical node names and
IP addresses, and to make the deployment more flexible on
nodes with Non Uniform Memory Architecture (NUMA).
Modern computing nodes have several processors and
memory banks interconnected across a small network. But
memory access time becomes function of the distance between the core running the code and the memory bank
7 EFRO-SALK project, with support of the European Union, the
storing the data (NUMA principle). Creating one pro- European Regional Development Fund, Flanders Innovation & Encess (one JVM, one virtual node) per NUMA subnode in- trepreneurship and the Province of Limburg
680

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132673

Session 10A: FMI II

This distributed frequency FMU implementation is meant
to reduce inter-node communications since the frequency
has to be dispatched to all the FMUs of the use case. Finally, the co-simulation holds a total of 1042 FMUs exported from Dymola 2016 FD01 in conformance with the
FMI-CS 2.0 standard. A smaller use-case with less buildings and only 442 FMUs, has also been designed to evaluate the scalability of our solution.
The test case was run on two different clusters: (1)
Sarah at CentraleSupelec Metz, composed of dual 4-cores
Intel Xeon E5-2637 v3 at 3.5 GHz (Haswell) with a 10
Gb/s Ethernet communication network, and (2) Porthos
at EDF R&D, composed of dual 14-cores Intel Xeon E52697 v3 at 2.60 GHz (Haswell) with Infiniband FDR communication network. These clusters are labeled "sar" and
"por" on performance curves of section 5.4. On both clusters, DacRun is used to deploy and run the DACCOSIM
co-simulation. DacRun is implemented in Python 2.7, is
compliant with OAR and SLURM cluster management
environments, and can also be used on standalone machines (for small experiments). It achieves Java source
files compilation, virtual/physical nodes mapping, JVMs
starting and can ensure to gather the results and logs.
Figure 10. Current from a building of the DACCOSIM co-

5.3

Numerical Results

The runs are done for a one-day simulation with oneminute constant step size. The co-simulation gives realistic results according to expert judgment. Moreover the energy consumption of the buildings follows the same trend
as the one observed on a Dymola simulation limited to one
20-building feeder. To assess the correctness of the cosimulation on cluster, we selected a single building of the
test case and simulated it with Dymola by injecting sampled voltage data obtained from the cluster co-simulation.
The power consumed by the building simulated with Dymola and the one co-simulated on cluster should be the
same as the two selected buildings have the same environment: same input voltage, same weather data and same
occupancy data. The root mean square error on the current between those two simulations is 1.16  102 A, with
current mainly in the range 1  10A. The two currents for
the one-day simulation are plotted on top of Fig. 10 with
a close-up on its bottom. The dynamic of the power consumption is well reproduced thus the cluster co-simulation
seems reliable.

5.4

Performance and Scaling

The FMUs were dispatched on the nodes following two
different approaches introduced in section 4.2: with (1)
a Cumulated knowledge for heuristic approach exploiting the problem topology with balanced load ("KHBL" on
Fig. 11), and (2) according to an Identifying FMU families
approach associated to a round-robin mechanism ("FFRR"
on Fig. 11). Experimentations were conducted on our
clusters in the ranges 32  1024 and 112  1792 cores,
with overlapped and ordered orchestration modes ("over"
and "order"), on both 442 and 1042 FMUs use-cases.
DOI
10.3384/ecp17132673

simulation and its Dymola counterpart

Scalability Achievement: time curves on Fig. 11 appear
very linear on this full logarithmic scale graphic, slope is
close to 1 on HPC Porthos cluster, and time curves of
different problem sizes are parallel. So, execution time
regularly decreases when using more cores, and similar
performance can be achieved when running larger problems on larger number of cores (from 442 to 1042 FMU
benchmark curves). Of course, when using as many cores
as FMUs the execution stops to decrease (right-hand side
of Porthos curves).
Interconnect and Communication Impact: time curve
slope is smaller on Sarah cluster and its 10 G/s Ethernet
interconnect, than on Porthos and its high performance Infiniband FDR interconnect. Communications are not negligible, and a high performance interconnect (low latency
and high bandwidth) improves the scalability.
Complex Choice of the Orchestration Mode: Overlapped mode was the fastest one on a previous use case
run on a cluster with smaller nodes (Dad et al., 2016). But
when running IDEAS use case on Sarah cluster, the overlapped mode appears slower than the ordered one, and
when run on Porthos cluster, both orchestration modes
have close performances up to allocate enough nodes to
get one core per FMU. Beyond this limit it remains free
cores on each node to manage communications, and the
execution time of the overlapped mode roughly decreases
and really becomes the smaller one. So, both orchestration modes are interesting, but strategy to foresee the right
one is still under investigation.
Difficulty to Design Efficient Heuristics: our heuristic
based on FMU graph knowledge, aiming to group connected FMUs on the same node with respect to load bal-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

681

Scaling FMI-CS Based Multi-Simulation Beyond Thousand FMUs on Infiniband Cluster

H. Elmqvist, A. Junghanns, J. Mauss, M. Monteiro, T. Neidhold, D. Neumerkel, H. Olsson, J.-V. Peetz, and S. Wolf. The
Functional Mockup Interface for Tool independent Exchange
of Simulation Models. In Proceedings of the 8th International
Modelica Conference, Dresden, Germany, March 2011.
B. Camus, V. Galtier, and M. Caujolle. Hybrid Co-Simulation
of FMUs using DEV and DESS in MECSYCO. In Proceedings of the 2016 Spring Simulation Multiconference, Symposium on Theory of Modeling and Simulation (TMS/DEVS16),
Pasadena, CA, USA, April 2016.
K. M. Chandy and J. Misra. Distributed Simulation: A Case
Study in Design and Verification of Distributed Programs.
IEEE Trans. Softw. Eng., 5(5), September 1979.

Figure 11. IDEAS benchmark with 442 FMUs run on clusters

C. Dad, S. Vialle, M. Caujolle, J.-Ph. Tavella, and M. Ianotto. Scaling of Distributed Multi-Simulations on Multi-Core
Clusters. In Proceedings of 25th International Conference
on Enabling Technologies: Infrastructure for Collaborative
Enterprises (WETICE 2016), Paris, France, June 2016.

ancing, requires in our testbed some accurate number of
nodes (5, 10 or 20 on our example) and does not achieve
better performance than round-robin distribution of FMU V. Galtier, S. Vialle, C. Dad, J.-Ph. Tavella, J.-Ph. Lam-Yee-Mui,
and G. Plessis. FMI-Based Distributed Multi-Simulation with
families. An efficient heuristic remains hard to design
DACCOSIM. In Proceedings of the 2015 Spring Simulaand our round-robin on FMU families algorithm appears
tion Multiconference, Symposium on Theory of Modeling and
a good solution
Simulation (TMS/DEVS15), USA, April 2015.

6

Conclusion and Perspectives

With DACCOSIM generating Java files for Linux and its
Python add-in DacRun easily compiling, running and collecting the results of a DACCOSIM application on clusters, we have illustrated in this paper the capability of
our FMI-CS based environment to manage very wide cosimulations. Our testbed is a realistic case study using
the OpenIDEAS library and involving the detailed modeling of 1000 buildings scattered on a distribution grid. We
have demonstrated the feasibility of scaling-up the multisimulation by pushing very far the limits of the simulation
and taking advantage of Porthos, the EDF cluster ranked
310th in the 48th edition of the TOP500 list published in
November 2016.
Work is currently being carried out to further improve
the capabilities of our co-simulation tools suite. Some
can be performed with the current FMI-CS 2.0 standard
(e.g. minimizing inter-FMU message sizes), while others would require an evolution of the standard (e.g. event
handling of accurate hybrid co-simulation).
A collection of generic heuristics for FMU graph distribution, when knowledge on co-simulation has been accumulated, is also under development, to make easier large
scale deployments of more complex co-simulations.

References
R. Baetens, R. De Coninck, F. Jorissen, D. Picard, L. Helsen,
and D. Saelens. OPENIDEAS - An Open Framework for
Integrated District Energy Simulations. In Proceedings of
Building Simulation Conference 2015 (BS 2015), Hyderabad,
India, December 2015.
T. Blochwitz, M. Otter, M. Arnold, C. Bausch, C. Clau,

682

A. Kaci, H. N. Nguyen, A. Nakib, and P. Siarry. Hybrid Heuristics for Mapping Task Problem on Large Scale Heterogeneous Platforms. In Proceedings of the 6th IEEE Workshop on Parallel Computing and Optimization (PCO 2016),
IPDPS Workshop 2016, Chicago, IL, USA, May 2016.
A. Ricci, M. Viroli, and A. Omicini. Give Agents Their Artifacts: The A&A Approach for Engineering Working Environments in MAS. In Proceedings of the 6th International
Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS07), Honolulu, HI, USA, May 2007. ACM.
P. Sadayappan and F. Ercal. Cluster-partitioning Approaches to
Mapping Parallel Programs Onto a Hypercube. In Proceedings of the 1st International Conference on Supercomputing
(ICS 1988), Athens, Greece, June 1988. Springer-Verlag.
S. E. Saidi, N. Pernet, Y. Sorel, and A. Ben Khaled. Acceleration of FMU Co-Simulation On Multi-core Architectures.
In Proceedings of 1st Japanese Modelica Conference, Tokyo,
Japan, May 2016.
A. Secco, I. Uddin, G. P. Pezzi, and M. Torquati. Message Passing on InfiniBand RDMA for Parallel Run-Time Supports.
In Proceedings of the 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing
(PDP 2014), Turin, Italy, February 2014.
J.-Ph. Tavella, M. Caujolle, S. Vialle, C. Dad, Ch. Tan,
G. Plessis, M. Schumann, A. Cuccuru, and S. Revol. Toward an Accurate and Fast Hybrid Multi-Simulation with the
FMI-CS Standard. In Proceedings of the IEEE 21st International Conference on Emerging Technologies and Factory
Automation (ETFA 2016), Berlin, Germany, September 2016.
B. P. Zeigler, T. G. Kim, and H. Praehofer. Theory of Modeling
and Simulation : Integrating Discrete Event and Continuous
Complex Dynamic Systems. Academic Press, 2000.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132673

Development of an open source multi-platform software tool for
parameter estimation studies in FMI models
Javier Bonilla1,3

Jose A. Carballo1,3

Lidia Roca1,3

Manuel Berenguel2,3

1 CIEMAT-PSA,

Centro de Investigaciones Energticas, Medioambientales y Tecnolgicas - Plataforma Solar de
Almera, Spain, {javier.bonilla,jose.carballo,lidia.roca}@psa.es
2 Department of Informatics, University of Almera, Almera, Spain, beren@ual.es
3 CIESOL, Solar Energy Research Center, Joint Institute University of Almera - CIEMAT, Almera, Spain

Abstract
This paper presents the current development of an open
source multi-platform software tool intended for estimating or optimizing parameters of Functional Mock-up Interface (FMI) compliant models. Parameter estimation
and optimization is a powerful tool in many engineering and science fields. Nevertheless, the effort and time
that must be devoted to coupling and integrating complex modeling languages and tools together with analysis and optimization methods and algorithms sometimes is
high. As a consequence of that, commonly the most convenient and easy-to-use optimization mechanisms are applied. Therefore, the focus on the development of this tool
is in facilitating such coupling while being customizable.
The main toolkit and libraries used in the development of
the tool are presented, all of them are open source. Two
application examples are also presented, one of them is
a parameter optimization study considering a steady state
model, while the other is a parameter estimation study of a
dynamic model against experimental data. Finally, current
tool limitations are presented, ongoing work and ideas for
future features are also commented.
Keywords: parameter estimation, parameter optimization,
model calibration, Functional Mock-up Interface (FMI),
open source software tool

1

Introduction

The application of optimization to complex dynamic models has become recently more usual in industry, as well as
in academia. Optimization can be online, such as optimal
control in the form of Model Predictive Control (MPC) or
offline, such as parameter estimation, state estimation or
parameter optimization.
In parameter optimization, also known as design optimization, some parameters are optimized to improve the
system dynamics or response according to some criteria. Parameter estimation, model calibration or parameter identification, comprises estimating some unknown parameters in a particular model. To that end, several simulations are performed and results are compared against
experimental data. The unknown parameters are therefore
determined by numerical optimization algorithms. This
DOI
10.3384/ecp17132683

procedure is a powerful tool in many engineering and science fields and has its origin in the least squares method
proposed by Gauss.
In order to apply optimization techniques to complex
dynamic models, a suitable modeling language, that can
deal with dynamic systems and the increasing complexity
of research and engineering needs, is advisable. Modelica
(Modelica Association, 2014b) is one of those modeling
languages, easing the model development, maintenance
and reuse thanks to the equation-based object-oriented
paradigm and other useful features. Nevertheless, there
are other commonly used modeling languages and simulation tools, being one of the most representative Matlab/Simulink (The MathWorks Inc., 2016). For this reason, the support of an independent standard devoted to
Model Exchange (ME) and co-simulation, such as FMI
(Modelica Association, 2014a), would be advisable when
considering the model interface for an optimization software tool.
Even though there are modeling languages and tools
for developing complex dynamic models, as well as a
standard format to exchange those models, and advanced
methods for optimization, sometimes the time required to
couple all these tools is high. This task involves writing
scripts for bindings and using several programming languages and tools.
With the aim of facilitating the integration of these tools
and methods, an easy-to-use open source multi-platform
software tool which performs parameter estimation studies in Functional Mock-up Units (FMUs) is currently being developed. This software tool performs parameter
estimation studies using a global-search Multi-Objective
Genetic Algorithm (MOGA). The tool also supports linear and non-linear equality and inequality constraints.
This paper is organized as follows. Section 1.1 is a brief
summary of Modelica and FMI-based tools for parameter estimation. Section 2 describes the still under development software tool and its architecture. In Section 3,
two examples are presented. Section 3.1 shows a steadystate parameter optimization study, whereas Section 3.2
presents a model calibration study against experimental
data from a Thermal Energy Storage (TES) tank. This
tank is used for research on solar thermal storage.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

683

Development of an open source multi-platform software tool for parameter estimation studies in FMI models

Project
Projectname
name
FMU
FMUfile
file

Project
Projectinfo
info
Model
Modelinfo
info

Numerical
Numericalintegrator,
integrator,
experiment
experimentand
andoutputs.
outputs.
Design
variables,
Design variables,algorithm,
algorithm,
Optimization
Optimizationinfo
info objectives and constraints.
objectives and constraints.
Simulation
Simulationinfo
info

In

pu

Optimization
Optimization Design
Designvariables
variables
results
(table,
results
(table,2D
2Dand
and3D
3Dgraphs)
graphs)
ts
tp u
Ou

ts

FMU file

QuaZIP

Save project to file

PRJ
Graphical user interface
(GUI)

Unzip file

Si
m
re ulat
su io
l ts n

n
io
at
i z ts
im u l
pt res

FMI++
Simulation library

Load project from file

st n
ue tio
eq za
R imi
t
op

O

R
sim eq
ul ues
at t
io
n

A C++ / Qt ZIP library

Request simulation

Simulation results

Dakota
Optimization library

Figure 1. Optifmus information exchange

1.1

State of the art

Most commercial Modelica tools have parameter estimation and optimization libraries for Modelica models,
i.e. Model Design Tools (Elmqvist et al., 2005; Pfeiffer,
2012) in Dymola (Dassault Systemes, 2016) and corresponding libraries in SimulationX (ESI ITI GmbH, 2016),
MapleSim (MapleSoft, 2016) and SystemModeler (Wolfram, 2016), among others. GenOpt (Wetter, 2001) is an
optimization program that can be coupled with Modelica
models compiled in Dymola. BuildingsPy (Berkeley Lab,
2016) is a Python package that can run Modelica simulations using Dymola, additional Python packages for parameter estimation can be used by means of scripting, such
as those from SciPy.org (SciPy developers, 2017). The
OpenModelica tool (OSMC, 2016) includes the OMOptim tool (Thieriot et al., 2011) for parameter estimation of
Modelica models in Windows platforms.
Modelica models can be also exported as FMUs and imported in commercial and open source numerical computational tools such as Matlab/Simulink and Scilab (Scilab
Enterprises, 2015). Parameter estimation studies can be
performed by means of scripting in these tools. JModelica.org (kesson et al., 2010) supports parameter estimation of Modelica and FMI models also by scripting. The
RaPId Parameter Identification (RaPId) toolbox (Vanfretti
et al., 2016) is a modular and extensible toolbox for parameter estimation of FMI models in Matlab/Simulink.

2

Optifmus Software Tool

The under development software tool is called
Optifmus. Although it is at an early development
stage, it is functional with respect to FMU simulations
and parameter estimation studies using a MOGA. The
tool is composed of the following main elements.
684

 Graphical User Interface (GUI). The GUI allows
the user to provide all the required information:
model information (FMU file and parameters), simulation information (numerical solver and its configuration, inputs and simulation interval), optimization
information (algorithm and its configuration, parameters, objective functions and constraints). The GUI
also shows the obtained results. Results are presented in tables, 2D and 3D graphs.
 Optimization toolkit. This toolkit collects all the information introduced in the GUI and calls the FMU
simulator to perform the needed simulation runs and
carry the optimization out using the selected algorithm. Optimization results are presented to the user
in the GUI.
 FMU simulator. The simulator performs the model
simulation according to the suplied data (model and
simulation information) and provides the results to
the GUI or to the optimization toolkit.

2.1

Software Architecture

Optifmus is being developed in C++ using open source
multi-platform libraries and tools. The following list
briefly describes the main libraries. Figure 1 shows the
information exchange between them.

 Qt toolkit (The Qt Company, 2016). It is a crossplatform application framework used for developing
application software. The Qt Core and Qt Widgets
modules are used for the GUI. The Qt Charts module
is used for 2D graphs, whereas the Qt Data Visualization module is used for 3D graphs.
 Breeze icons (KDE Community, 2016). The GUI
icons belong to this open source library.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132683

Session 10A: FMI II

 FMI++ (Widl et al., 2013). The FMI++ library is
a high-level utility package for FMI-based software
development. It provides high-level features, which
ease the handling and manipulation of FMU models: an eXtensible Markup Language (XML) parser
and numerical integration capabilities. The FMI++
library relies on the Odeint library (Ahnert and Mulansky, 2011), and optionally on SUite of Nonlinear
and DIfferential/ALgebraic Equation Solvers (SUNDIALS) (Hindmarsh et al., 2005), for the numerical
integration of FMUs.
 QuaZIP (Tachenov, 2016). It is a C++ wrapper for
accessing ZIP files. This wrapper uses the Qt toolkit
and therefore it is a multi-platform wrapper. It is used
in Optifmus to handle the extraction of FMU files.
 Dakota (Adams et al., 2016). The Dakota toolkit is
intended as a flexible, extensible interface between
simulation codes and a variety of iterative systems
analysis methods. Dakota is a powerful toolkit which
provides the following functionality: optimization,
uncertainty quantification, nonlinear least squares
methods, and sensitivity/variance analysis. Dakota
uses Sandia-developed libraries, as well as external
optimization and design of experiments libraries. For
further details consult Sandia Corporation (2016).
Dakota can be used as a standalone application or
as a C++ library.

where,
f (x) = { f1 (x)    fi (x)},
x = {x1    x j },
xl = {xl,1    xl, j },
xu = {xu,1    xu, j },
g(x) = {g1 (x)    gk (x)},
h(x) = {h1 (x)    gn (x)}.
The example considered in this section, known as Srinivas problem, can be found in the Dakota Users Manual
(Adams et al., 2016), section Additional examples  Multiobjective test problems  Multiobjective test problem 3.
The problem has two design variables, x1 and x2 with their
respective upper and lower bounds,
20 x1  20,
20 x2  20,
two objective functions, f1 and f2 , which must be minimized,
f1 (x1 , x2 ) = (x1  2)2 + (x2  1)2 + 2,
f2 (x1 , x2 ) = 9x1  (x2  1)2 ,
and two inequality constraints h1 and h2 ,
h1 (x1 , x2 ) = x12 + x22  225  0,
h2 (x1 , x2 ) = x1  3x2 + 10  0.

Additionally, reading and writing operations of input
and result files in Comma-separated Values (CSV) or trajectory mat format are performed by means of C functions The first step is to generate a FMU file of this model,
most Modelica tools support exporting Modelica models
available in the source code of the OpenModelica tool.
to FMUs. The Modelica code of this model is as follows.

3

Examples

In order to show the Optifmus capabilities and illustrate how a parameter estimation study can be performed, the following sections introduce two examples.
Section 3.1 shows a steady-state parameter optimization
study, whereas Section 3.2 shows a model calibration
study against experimental measurements from a real facility.

3.1

Parameter optimization

The general formulation for a optimization problem description is given by Equation 1. It can be formulated as
optimize (minimize or maximize) several objective functions f (x) that depend on some parameters or design variables x subject to several constraints: upper and lower
bounds for design variables, xl and xu , equality constraints, g(x) and inequality constraints, h(x).
optimize

f (x)

with respect to x  R j
subject to
xl  x  xu ,
g(x) = 0,
h(x)  0,
DOI
10.3384/ecp17132683

(1)

model mogatest3
parameter Real x1 = 0 "Parameter x1";
parameter Real x2 = 0 "Parameter x2";
output Real f1 "Function f1";
output Real f2 "Function f2";
output Real h1 "Constraint h1";
output Real h2 "Constraint h2";
equation
f1 = (x1-2)^2 + (x2-1)^2 + 2;
f2 = 9*x1 - (x2-1)^2;
h1 = x1^2 + x2^2 - 225;
h2 = x1 - 3*x2 + 10;
end mogatest3;

The next step is to create a new project in Optifmus.
Currently, two kinds of projects can be created: simulation and parameter estimation. Projects can be saved to
and loaded from files. Figure 2 shows the Optifmus
GUI for parameter estimation. The information that must
be completed is divided in groups in the GUI and it is described as follows.
1. Project information. A descriptive name can be
given to easily identify the project.
2. Model information. A FMU file must be specified. Once the file is loaded, some information is

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

685

Development of an open source multi-platform software tool for parameter estimation studies in FMI models

Table 1. Numerical integrators
Numerical integrator
Forward Euler
4th order Runge-Kutta
Adams-Bashforth-Moulton
5th order Runge-Kutta-Cash-Karp
5th order Runge-Kutta-Dormand-Prince
8th order Runge-Kutta-Fehlberg
Bulirsch-Stoer
4th Rosenbrock
Backwards Differentiation Formula (BDF)
Adams-Bashforth-Moulton

Library

Step size

Order

Odeint
Odeint
Odeint
Odeint
Odeint
Odeint
Odeint
Odeint
SUNDIALS
SUNDIALS

Constant
Constant
Constant
Controlled
Controlled
Controlled
Controlled
Controlled
Controlled
Controlled

1
4
Adjustable
5
5
8
Controlled
4
Controlled
Controlled

Figure 2. Optifmus GUI for parameter estimation.

displayed in the GUI. There are three buttons in this
group. The FMU info button shows some information about the model, see Figure 3a. The structure
button shows the model structure, see Figure 3b. The
parameters button allows the user to give values to
the model parameters, see Figure 3c. Since in our
case, both parameters x1 and x2 are going to be calibrated, there is no need to give them values.
3. Simulation information. There are also three buttons in this group: numerical integrator, experiment
and outputs. The first one allows us to select the numerical integrator, Figure 4a. The step size is only
needed if it is not controlled by the integrator. If it
is controlled, absolute and relative tolerance are used
instead. Some integrators allows the users to specify
the order whereas others have a fixed constant or a
controlled order. The FMI++ library can use the numerical integrators given in Table 1 from the Odeint
686

and SUNDIALS libraries. The numerical integrator
(BDF) and tolerances (104 ) are left by default in
our example. The experiment window permits selecting the simulation interval, start and stop times,
and matchs model inputs with data from files. Since
our model does not have inputs and it is a steadystate model, this step can be omitted and thus leaving the simulation interval by default, [0,1] seconds.
Section 3.2 shows how to use this window.
The outputs window, see Figure 4b, shows the model
outputs, furthermore allows us to specify the number of intervals, i.e. the number of points that will
be sampled for the output trajectory. The number of
points can be also set by a time step instead of by a
fixed number. Since our model is a steady-state one,
there is no need to sample more than one interval.
One interval means that values at the beginning and
end of the simulation are stored.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132683

Session 10A: FMI II

(b) Model structure

(a) FMU information

(c) Model parameters

Figure 3. Model information

(a) Numerical integrator

(b) Model outputs

Figure 4. Simulation information

4. Parameter estimation information. This GUI
group gathers all the information for the parameter
estimation study: parameters or design variables, optimization algorithm, objective functions and constraints.
 Parameters. The parameters to be calibrated can be
selected in the parameter window, see Figure 6. For
each parameter, it can be specified its initial value,
its lower and upper bounds, and if scaling is considered. If this is the case, the scaling type can be a
fixed value, logarithm scale or automatic. The two
first require a scale value. Consult Dakota documentation for further information about scaling of design
variables (Adams et al., 2016).

 Algorithm. Currently, the only Dakota algorithm
considered in the tool is the MOGA from the Sandiadeveloped JEGA library (Eddy and Lewis, 2001).
This is a multi-objective algorithm which supports
general constraints: bounded design variables, linear and nonlinear equality and inequality constraints.
DOI
10.3384/ecp17132683

The algorithm is highly configurable. Figure 5 shows
the window to configure the algorithm. The options
selected in our case are those indicated in Dakota
documentation for this example. The number of
model evaluations is set to 2000.

 Objectives. The objectives can be selected in the objectives window, see Figure 7. For each objective the
following options are available: criterion (maximize
or minimize), trajectory reduction, weight, scaling
type and value. The trajectory reduction option reduces the whole trajectory for each objective function to a single value in each simulation run. This
is required because the optimization algorithm needs
a single value per objective function and simulation
run. The following options are available: root mean
of squares, mean of absolute values, max, min or last
value. The weight value is used if the option to use
weights, and therefore transform the multi-objective
problem to a single-objective problem, is checked.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

687

Development of an open source multi-platform software tool for parameter estimation studies in FMI models

Figure 5. Optimization algorithm configuration

688

Figure 6. Selected design variables

Figure 8. Linear inequality constraints

Figure 7. Objective functions

Figure 9. Nonlinear inequality constraints

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132683

Session 10A: FMI II

-0.7

f2

-54.9

-109.1

-163.4

-217.6
11.0

63.6

116.3
f1

168.9

221.6

Figure 10. Srinivas problem - 2D graph
Figure 12. Srinivas problem - optimization results

Figure 11. Srinivas problem - 3D graph

information about the optimization results. Our optimization example took less than 5 seconds for 2000 model
evaluations in a conventional laptop (4 x Intel Core i5 2.60
GHz, 8 Gbytes of RAM). During the process, messages
and log information are shown in the GUI.
Optimization results are shown in the results window,
see Figure 12. The MOGA algorithm provides all the solutions found in or close to the Pareto front. In our case, the
MOGA algorithm found 421 solutions after 2000 model
evaluations. Design values, objective functions and constraints for each solution are shown in a table. In the result
window, any design variable, objective function or constraint can be selected to be plotted in 2D or 3D graphs.
Figure 10 shows a 2D graph of f2 with respect to f1 , which
is the Pareto front of our problem. Figure 11 shows a 3D
graph of f1 with respect to x1 and x2 .

The scaling option has the same meaning than for
design variables, but there are some limitations for
objective functions, consult Dakota documentation
for further details. In our example, for both objective functions the criterion is minimize. Since this is
a steady-state model, reductions are set to last simulation values. Scaling is not used and weight are not 3.2 Model calibration
enabled because this is a multi-objective optimiza- This section presents the calibration of a TES tank dytion problem.
namic model that it is under development. This kind of
 Constraints. The tool supports linear and nonlinear tanks is used in solar thermal power plants in order to store
equality and inequality constraints. Scaling options thermal energy and dispatch it at night or under unfavorare also available. Linear constraints with respect to able meteorological conditions. A complete description
design variables can be directly specified in the ap- of the model is out of the scope of this paper, but a brief
propriate tab in the constraint window. In our exam- summary is given in the following lines. The storage fluid
ple, the linear constraint h2 was defined in the Mod- is commonly molten salts, which can reach high temperaelica code, but this was not necessary since it can tures.
The dynamic model considers two control volumes and
be directly defined in the GUI, see Figure 8. On the
other hand, it can be also defined in the model as in dynamic mass and energy balances for molten salt and the
our example. Nonlinear constraint functions must be the inert gas in the facility, nitrogen. Tank geometry, slope
defined in the model, in our example h1 , then both or and dimensions are considered in the model. The pump
only one limit per constraint must be set in the GUI, inside the tank is also modeled, assuming a simplified geometrical form. The position of the level meter and thersee Figure 9.
mocouples in the tank are also taken into account. The
Once all previous information is defined, the optimization model considers different kinds of heat transfer processes:
process can be performed hitting the calibration button, convection, conduction and radiation between molten salt,
see Figure 2. The stop button allows us to stop the cur- gas, tank walls, roof, floor, pump, insulation and foundarent optimization process. When the calibration process tion. The variables of interest are tank level, together with
is completed, the results button will be enabled to show molten salt and gas temperatures.
DOI
10.3384/ecp17132683

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

689

Development of an open source multi-platform software tool for parameter estimation studies in FMI models

calibration time, since samples were taken each five
seconds. Model inputs and time are matched to file
data. The numerical integrator is left by default. The
number of intervals is set to 500 in the output window in order to capture several points in the output
trajectories.
4. Parameter estimation information. There are no
constraints in our example, the remaining configuration options are described as follows.

 Parameters. Insulation and foundation mean thermal conductivities (kins , k f ou ) are the design variables, guess initial values are 0.15 W/(m K) . They
are bounded in the [0, 1] interval.

Figure 13. Tank calibration experiment

Molten salt tank foundation designs are commonly outside of standards for foundations, since these standards
do not cover the temperature range were TES systems
operate. The modeled tank has several foundation layers made of concrete with steel fibers and a compacted
light expanded clay aggregate. The thermal insulation is
usually made of several layers from different materials.
The outer thermal insulation layer is frequently covered
with an aluminum jacket for weather protection. For all
these reasons, thermal conductivities in the insulation and
foundation are difficult values to estimate. In this model,
those thermal conductivities are assumed as mean constant
values and have been calibrated using the Optifmus
tool. Needed measurements are available from experimental campaigns carried out in the facility. It is located at
CIEMAT - Plataforma Solar de Almera (PSA). Therefore,
our model calibration problem can be formulated as minimizing the differences between molten salt and gas experimental and simulated temperatures by tuning the mean
insulation and foundation thermal conductivities.
The steps to perform the calibration are similar to those
in Section 3.1, for example setting the project (step 1)
and model (step 2) information. The remaining steps are
briefly summarized in what follows.
3. Simulation information. The experiment window is
used to match model inputs with experimental data
stored in files, see Figure 13. The values in the input file can be visualized thanks to a plotting tool included in Optifmus. In case the input file is oversampled, a factor can be used to reduce the number of
samples. Model inputs can be also fixed to constant
values in this window if needed. Time values can be
read from the loaded file or a number of time intervals between the start and stop times can be specified in the GUI. In our example, the simulation interval is set to [41500, 55000] seconds. The number
of samples is reduced by 1/7 in order to reduce the
690

 Algorithm. The MOGA algorithm is used with its
default values, besides the number of model evaluations (1000) and the seed (1) in order to obtain reproducible results.
 Objectives. The differences between experimental
and simulated molten salt and gas temperatures are
the two objective functions (Tms,di f f , Tgas,di f f ), they
must be minimized. The trajectory reduction was set
to root mean square values, therefore both objective
functions provide the mean temperature difference in
the trajectory. There is no need to use scaling since
both objective functions represent temperature differences. Weights are not used because we are considering a multi-objective minimization problem.
The calibration process took 21 minutes and found 157 solutions in or close to the Pareto front for 1000 model evaluations. Figure 14 shows 10 of those solutions, where the
objective functions give the mean temperature difference
between experimental data and simulation results. Figure 15 shows the Pareto front.
The first solution in Figure 14, and pointed out by the
arrow in Figure 15, was used to compare the model results
against a different set of experimental data. All figures
shown in this section were created in the Optifmus plotting tool. The system was exposed to several mass flow
rate steps in this experiment, see Figure 16. Figure 17
shows experimental and simulated tank levels. Horizontal lines point out the position in height of the thermocouples. The gas experimental temperature corresponds
to that from the highest-placed thermocouple, whereas
the molten salt temperature is obtained from the highestplaced thermocouple immersed in molten salts. Figure 18
shows the experimental and simulated molten salt temperatures. Notice that there is no experimental molten salt
temperature until the tank level reaches the first thermocouple position. This is why the experimental temperature
is set to a constant value at the beginning of the simulation.
Figure 19 shows the experimental and simulated gas temperatures. Notice that the molten salt level reaches the last
thermocouple at the end of the simulation, therefore there
are no available measurements for gas temperature.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132683

Session 10A: FMI II

Figure 16. Tank simulation - mass flow rate

Figure 14. Tank model calibration results

2.244

Figure 17. Tank simulation - levels

Tgas_diff

2.166

2.089

2.012

1.934
1.458

1.534

1.610
Tms_diff

1.686

1.762

Figure 18. Tank simulation - molten salt temperatures
Figure 15. Tank model calibration Pareto front

4

Optifmus limitations

The current main Optifmus limitations are listed here.

 The software tool has been tested only in Linux. It is
planned to be tested in Windows and Mac platforms.
 Only ME FMUs version 1.0 and 2.0 are supported.
 Only continuous real design parameters, objectives
functions and constraints are supported.
 All the MOGA options are configurable from the
GUI besides the niching type and the use of surrogate models which are not supported.

5

Ongoing work and future ideas

Ongoing work is summarized in the following list.







Optimize the code to improve speed.
Unit support when setting parameter values.
Load FMI++ logs in the Optifmus GUI.
More graphic configuration options.
Include an option to simulate the model with the parameters of the selected row in the result table.

DOI
10.3384/ecp17132683

Figure 19. Tank simulation - gas temperatures

 Dakota offers many more algorithms for parameter
estimation and optimization. One of the ongoing
tasks is to implement several of those algorithms.
As future ideas to improve the software tool, the following
will be considered and studied.

 Dakota is a powerful toolkit, other features that could
be added to the tool are: parameter studies, sensitivity analyses, design of experiments, uncertainty
quantification, and model simplification by means of
surrogate models.
 The development of an Application Programming Interface (API) independent of the GUI could be useful
for integrating FMI optimization capabilities in other

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

691

Development of an open source multi-platform software tool for parameter estimation studies in FMI models

tools. It could be applied to offline optimization, as KDE Community. Breeze icons, 2016. URL https://
github.com/KDE/breeze-icons.
well as to online optimization, for example in MPC.

 Parallelization of the software tool could drastically MapleSoft. MapleSim 2016, 2016. URL https://www.
reduce the optimization time. Dakota offers capabilimaplesoft.com/products/maplesim/.
ties for parallelization. If we consider parallelization,
as well as an API, executable programs could be gen- Modelica Association. Functional Mock-up Interface for Model
Exchange and Co-Simulation, Version 2.0, 2014a. URL
erated and executed in high-performance clusters to
https://www.fmi-standard.org/downloads.
further reduce the computational time.
Modelica Association. Modelica Specification, version 3.3 Revision 1, 2014b. URL http://www.modelica.org/
documents.

Acknowledgments

This work has been funded by the National Plan Project
DPI2014-56364-C2-1/2-R (ENERPRO-EFFERDESAL) OSMC. OpenModelica 1.9.7, 2016. URL http://www.
of the Spanish Ministry of Economy, Industry and Comopenmodelica.org/.
petitiveness and ERDF funds.

References
Brian M. Adams, Mohamed S. Ebeida, Michael S. Eldred, Gianluca Geraci, John D. Jakeman, Kathryn A. Maupin, Jason A.
Monschke, Laura P. Swiler, J. Adam Stephens, Dena M.
Vigil, and Timothy M.Wildey. Dakota, A Multilevel Parallel Object-Oriented Framework for Design Optimization, Parameter Estimation, Uncertainty Quantification, and Sensitivity Analysis: Version 6.5 Users Manual, 2016.
Karsten Ahnert and Mario Mulansky. Odeint - Solving ordinary differential equations in C++. In AIP Conference
Proceedings, volume 1389, pages 15861589, 2011. ISBN
9780735409569. doi:10.1063/1.3637934.
Johan kesson, Karl-Erik rzn, Magnus Gfvert, Tove
Bergdahl, and Hubertus Tummescheit. Modeling and Optimization with Optimica and JModelica.orgLanguages and
Tools for Solving Large-Scale Dynamic Optimization Problems. Computers and Chemical Engineering, 34(11):1737
1749, 2010.
Berkeley Lab. BuildingsPy - Modelica Buildings Library,
2016.
URL http://simulationresearch.lbl.
gov/modelica/buildingspy/.
Dassault Systemes. Dymola 2017 FD01, 2016. URL http:
//www.dymola.com.
John Eddy and Kemper Lewis. Effective Generation of Pareto
Sets Using Genetic Programming. In ASME 2001 Design
Engineering Technical Conferences and Computers and Information in Engineering Conference, number 1, pages 19,
Pittsburgh, PA, 2001.
Hilding Elmqvist, Hans Olsson, Sven Erik Mattsson, Dag
Brck, Christian Schweiger, Dieter Joos, and Martin Otter.
Optimization for Design and Parameter Estimation. In Proc.
4th International Modelica Conference, 2005.
ESI ITI GmbH. SimulationX 3.8, 2016. URL http://www.
simulationx.com/.
Alan C. Hindmarsh, Peter N. Brown, Keith E. Grant, Steven L.
Lee, Radu Serban, Dan E. Shumaker, and Carol S. Woodward. SUNDIALS: Suite of Nonlinear and Differential/Algebraic Equation Solvers. ACM Transactions on Mathematical Software, 31(3):363396, 2005. ISSN 0098-3500.
doi:10.1145/1089014.1089020.

692

Andreas Pfeiffer. Optimization Library for Interactive MultiCriteria Optimization Tasks. In Proc. 9th International Modelica Conference, pages 669680, Munich, Germany, nov
2012.
Sandia Corporation. Dakota Packages, 2016. URL https:
//dakota.sandia.gov/content/packages.
Scilab Enterprises. Scilab: Open Source software for numerical
computation, 2015. URL http://www.scilab.org/.
SciPy developers. SciPy.org - Python-based ecosystem of opensource software for mathematics, science, and engineering,
2017. URL http://scipy.org/.
Sergey A. Tachenov. QuaZIP - Qt/C++ wrapper for ZIP/UNZIP
package, 2016. URL http://quazip.sourceforge.
net/.
The MathWorks Inc. MATLAB R2016b, 2016. URL http:
//www.mathworks.es/products/matlab/.
The Qt Company. Qt - Cross-platform software development for
embedded & desktop, 2016. URL https://www.qt.io.
Hubert Thieriot, Maroun Nemer, Mohsen Torabzadeh-Tari, Peter Fritzson, Rajiv Singh, and John John Kocherry. Towards
Design Optimization with OpenModelica Emphasizing Parameter Optimization with Genetic Algorithms. In Proc. 8th
International Modelica Conference, pages 756762, 2011.
Luigi Vanfretti, Maxime Baudette, Achour Amazouz, Tetiana
Bogodorova, Tin Rabuzin, Jan Lavenius, and Francisco Jos
Gomz-Lpez. RaPId: A modular and extensible toolbox
for parameter estimation of Modelica and FMI compliant
models. SoftwareX, 5:144149, 2016. ISSN 23527110.
doi:10.1016/j.softx.2016.07.004.
Michael Wetter. GenOpt - A Generic Optimization Program.
Seventh International IBPSA Conference, (1):601608, 2001.
Edmund Widl, Wolfgang Muller, Atiyah Elsheikh, Matthias
Hortenhuber, and Peter Palensky. The FMI++ library:
A high-level utility package for FMI for model exchange.
2013 Workshop on Modeling and Simulation
of Cyber-Physical Energy Systems, MSCPES 2013, 2013.
doi:10.1109/MSCPES.2013.6623316.
Wolfram. SystemModeler 4.3, 2016. URL http://www.
wolfram.com/system-modeler/.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132683

Innovations for Future Modelica
Hilding Elmqvist1

Toivo Henningsson2

Martin Otter3

1

Mogram AB, Magle Lilla Kyrkogata 24, 223 51 Lund, Sweden, Hilding.Elmqvist@Mogram.net
2
Lund, Sweden, toivo.h.h@gmail.com
3
Institute of System Dynamics and Control, DLR, Oberpfaffenhofen, Germany, Martin.Otter@dlr.com

Abstract
This paper discusses language innovations for future
Modelica versions, on the one hand for generally applicable language elements, and on the other hand to improve modeling of multibody systems with contacts, and
media modeling. In a companion paper new algorithms
are proposed to handle much larger models than can be
treated today. All these innovations are developed and
evaluated with the experimental modeling and simulation environment Modia. Modia is based on Julia, a
powerful programming language with strong focus on
scientific computing, meta-programming and just-intime compilation that allows very fast development. The
modeling language is directly defined and implemented
with Julias meta-programming constructs and is designed tightly together with the symbolic and numeric
algorithms. This approach is very well suited for innovation and experimenting with evolutions of modeling
capabilities in Modelica.
Keywords: Modelica, Modia, Julia, modeling, simulation

1

Introduction

The objective is developing and testing innovations for
future Modelica versions with reasonable effort both
from a language point of view as well as for new symbolic and numeric algorithms that are tightly designed
together with the language elements. To achieve this
goal, an experimental modeling and simulation environment called Modia is under development. Modia uses a
Modelica-like language. It shall be both simpler and
more powerful than Modelica 3.3 (Modelica Association, 2014) and takes into account the experience gained
with Modelica in the last 20 years.
New algorithms have been already developed and
test-implemented in Modia and are described in the
companion paper (Otter and Elmqvist, 2017). For example, arrays defined in a model stay as arrays in the generated code, even if (array) equations need to be differentiated. This is a pre-requisite to handle much larger
models than what can be treated with current Modelica
tools.
In addition to equations, Modelica has a function concept for procedural programming of tasks, such as table

DOI
10.3384/ecp17132693

look-up, media calculations and control system implementations. The function part of Modelica is, however,
not rich enough. There are no advanced data structures
such as union types, no matching construct. Type inference is missing with the implication that there are presently separate blocks for adding Reals, Integers and
Complex numbers. The evolution of Modelica has
slowed down since its a too large task to make a full
algorithmic language. Instead of inventing all such features, it makes sense to use another language as a base.
Julia (Bezanson, et al., 2017) is a very promising language design effort with focus on scientific computing
and has many of the properties needed to complement
the equational style for modeling. Julia also allows definition of real equations (expression = expression). Furthermore, advanced meta-programming features are
available which are suitable for symbolic treatment of
equations before just-in-time compilation.
Julia allows developing a modeling language together
with a public reference implementation so that language
features and symbolic/numeric algorithms are designed
tightly together. Native Julia functions are used in models and equations use Julia syntax.
Examples of other research oriented language designs
for modeling are: SOL (Zimmer, 2010), Hydra (Giorgidze and Nilsson, 2009) and Modelyze (Broman and
Siek, 2012). There is also one experimental simulation
package for Julia called Sims (Short, 2012). Sims does
not make any structural and symbolic processing
though, but has event handling. It is based on ideas from
Modelyze and Hydra.
This paper introduces major language constructs of
Modia and proposes new language features for future
Modelica versions. Other aspects of Modia and its implementation are given in (Elmqvist, et al., 2016). Modia is available from https://github.com/ModiaSim.

2

Modia Language Design

2.1 Model with differential equations
Modia is a domain specific language extension of Julia
by means of structured macros, that is, the Julia parser
is used to parse Modia models.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

693

Innovations for Future Modelica

A simple first order example model is shown below:
@model FirstOrder begin
x = Variable(start=1)
T = Parameter(0.5, "Time constant")
U = 2.0
@equations begin
T*der(x) + x = u
end
end

@model is a call to the Modia macro called model. The
first part after begin is used for variable and component
declarations by means of calling constructors. The second part inside the @equations macro contains differential and algebraic equations as well as connections. #
starts a Julia comment. Semicolons can be omitted in
Julia.
The constructor Variable is used to declare x with
a start value of 1. In general it constructs instances of
ordinary variable types and arrays of those. It is a Julia
composite type which in addition to its value also allows
specifying type, min, max, variability, start value, info,
etc. The constructor Parameter is a specialization of
the Variable constructor which sets the variability to parameter, that is, a quantity that is changeable before simulation starts but constant during simulation. There is
also a special short hand notation to define parameters
by just giving a default value. This notation is used to
define the parameter u. The operator der() denotes the
time derivative of its argument.
The corresponding Modelica model is:
model FirstOrder
Real x(start=1);
parameter Real T=0.5 "Time constant";
parameter Real u = 2.0;
equation
T*der(x) + x = u;
end FirstOrder;

Modia uses the Julia way to declare variables with constructor calls. The benefit with respect to current Modelica is a simpler syntax since value, variability, info,
etc. are all given in the constructor calls. This allows to
easily extending the language with new attributes/properties in the future.

2.2 Coupled models
In order to couple models, the interfaces need to be defined. For simplicity of the language and its implementation, this is currently described as a @model (and
might be improved in the future by a dedicated @connector macro):
@model Pin begin
v = Float()
i = Float(flow=true)
end

Float is a specialization of Variable with fixed type
Float64. The flow variable, i, is marked with an attribute flow=true. Such a Pin can be used to define the
terminals p and n of an electrical resistor:

694

@model Resistor begin
p = Pin()
n = Pin()
v = Float()
i = Float()
R = Parameter(info="Resistance")
@equations begin
v = p.v - n.v # Voltage drop
0 = p.i + n.i # KCL within component
i = p.i
R*i = v # Ohms law
end
end

An electrical component library has been developed
containing also Capacitor, Inductor, VoltageSource, etc.
A low-pass filter can then be defined as a set of connected components:
@model LPfilter begin
R = Resistor(R=100)
C = Capacitor(C=0.001)
V = ConstantVoltage(V=10)
@equations begin
connect(V.p, R.p)
connect(R.n, C.p)
connect(C.n, V.n)
end
end

The function connect has the same meaning as in Modelica. Note, that no ground component is needed because
the missing ground can be automatically handled with a
new algorithm described in (Otter and Elmqvist, 2017).
Modia is used to evaluate whether this simplification is
reliable and transparent for the user. The diagram of a
corresponding Modelica model is shown in Figure 1.

Figure 1. Low pass filter (without ground object)

2.3 Inheritance
There are several electrical components that share the
property of having two Pins. Such components are
called OnePorts. Similarly to Modelica, it is possible to
describe the common properties once and inherit them.
The common properties are:
@model OnePort begin
p = Pin()
n = Pin()
v = Float()
i = Float()
@equations begin
v = p.v - n.v # Voltage drop
0 = p.i + n.i # KCL within component
i = p.i
end
end

The Resistor model can then be simplified:
@model Resistor begin

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132693

Session 10B: Modelica Language & Tools

@extends OnePort()
@inherits i, v
R = Parameter(info="Resistance")
@equations begin
R*i = v # Ohms law
end
end

The @extends macro incorporates all declarations and
all equations from OnePort. The OnePort variables
can be accessed by this.v and this.i in the equations of the Resistor. The @inherits macro enables
to directly use variables i and v.

2.4 Type and size inference
The Modelica Standard Library (Modelica Association,
2016) contains similar models operating on different
data types. One example is switches, which based on a
Boolean signal select between two Real, two Booleans,
or two Complex numbers. There is a desire in the Modelica community to unify this situation by means of type
inference.
To experiment with type and size inference, such a
feature is included in Modia: Variable constructors do
not need to specify type and size. Types and sizes can
be inferred from the environment of a model or start values provided, either initial conditions for states or approximate start values for algebraic constraints.
A generic switch that can be applied to matrices and
strings as well, can be then defined as:
@model Switch begin
sw = Boolean()
u1 = Variable()
u2 = Variable()
y = Variable()
@equations begin
y = if sw; u1 else u2 end
end
end

scalar = Var(T=Float64, size=())
array3 = Var(T=Float64, size=(3,))
matrix3x3 = Var(T=Float64, size=(3,3))

The size is given with the tuple constructor according to
the result of the Julia size function. Empty tuple, (),
means scalar. A vector size is given as a tuple with the
size. Such a tuple with one element needs a comma to
distinguish it from an expression within parenthesis.
When the size attribute is given, T denotes the array element type.
There is also a FixedSizeArrays module for Julia
(Danish, 2014) which gives faster code since stack allocation is possible and garbage collection avoided. The
corresponding Modia declarations are then:
fixedArray3 = Var(T=Vec{3,Float64})
fixedMatrix3x3 = Var(T=Mat{3,3,Float64})

SI units can be given using the Julia SIUnits module
(Fisher, 2013). It has predefined types such as: Meter,
KiloGram, Second, Ampere, Kelvin, Mole,
Candela, Radian, Steradian, Joule, Coulomb, Volt, Farad, Newton, Ohm, Siemens,
Hertz, Watt, Pascal. A Modia variable with unit
Volt is declared as:
v2 = Var(T=Volt)

There is an option in the SIUnits module to use units
with shorter names (m, kg, etc) (and * is not needed between literal and identifier), for example:
m=2.5kg
length=5m

However, this feature is not useful since unit m would
then be in the same name space as the variable m. Investigations are being made to allow a local scope for units
after literals using a syntax with [ ]:
m=2.5[kg]
length=5[m]

2.5 Variable Declarations

2.6 Type Declarations

There are, however, cases when size and type inference
based on start values is not natural, for example, when
algebraic equations form a linear system of real simultaneous equations. In such a case, the solution is independent of any start value and only size needs to be
given.
It is possible to provide type information in variable
declarations using the type parameter T in the Variable constructor or its short version Var:

To avoid repeatedly typing type and size information,
its possible to define alternative variable constructors
outside the @model macro:

v1 = Var(T=Float64)

It is unspecified if the variable v1 is a scalar or array of
Float64. It is possible to provide information that a
variable is of array type with a certain number of dimensions:

Float3(; args...) = Var(T=Float64,
size=(3,); args...)
Voltage(; args...) = Var(T=Volt;
args...)

The notation "; arg... " denotes a list of keyword
arguments which are just passed to the Variable constructor using the same notation. This means that a 3vector with start attribute and a three-phase Voltage
variable can be declared as:
v3 = Float3(start=zeros(3))
v4 = Voltage(size=(3,), start=[220.0,
220.0, 220.0]Volt)

array = Var(T=Array{Float64,1})
matrix = Var(T=Array{Float64,2})

The size can be fixed using the size attribute:

DOI
10.3384/ecp17132693

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

695

Innovations for Future Modelica

2.7 Redeclaration of submodels
With the "replaceable" language element, Modelica has
a powerful concept to exchange submodels on a lower
level. However, it is complicated to understand and difficult to implement for tools. Furthermore, it is not powerful enough for certain applications, because redeclarations cannot be controlled by variables and they must be
planned in advanced, because only models can be replaced that are marked to be replaceable.
A simpler and more powerful concept for redeclarations has been tested in Modia and follows naturally
from the constructor style of declaration using expressions, as shown in the following example:
MotorModels = [Motor100KW,
Motor200KW,
Motor250KW] # Modia models
selectedMotor = motorConfig( ) # Int
@model HybridCar begin
@extends BaseHybridCar(
motor = MotorModels[selectedMotor](),
gear = if gearOption1; Gear1(i=4)
else Gear2(i=5) end)
end

The breaking shaft can be modelled as follows using
conditional equations:
@model BreakingShaft begin
flange1 = Flange()
flange2 = Flange()
broken = Boolean()
@equations begin
if broken
flange1.tau = 0
flange2.tau = 0
else
flange1.w = flange2.w
flange1.tau + flange2.tau = 0
end
end
end

Figure 3 shows the angular speeds of the two inertias
when the shaft breaks at time = 100.

In model BaseHybridCar every submodel can be replaced without being marked. In particular new motor
and gearbox models are provided. The motor model is
selected from an array of Modia models via an integer.
The gearbox model is selected based on a logical condition. Such flexible types of redeclarations cannot be formulated in Modelica 3.3.

2.8 Multi-mode Modeling

Figure 3. Angular speeds of inertias

Several attempts have been made to generalize the semantics of Modelica to allow mode changes, for example (Mattsson, et al., 2015). However, only a limited
classes of problems could be handled. One reason is the
imposed restriction that the equations are only processed
once, code is generated and this code should hold for all
mode changes. There are academic simulation prototypes that dynamically process and switch equations
during run-time, such as (Zimmer, 2010; Hger, 2014).
The question is how to incorporate such ideas in to Modelica and Modelica tools with the goal to solve realworld industrial problems.
First investigations have been carried out in Modia to
experiment with changing model structure. Consider the
model of an electrical motor with a load in Figure 2. The
shaft between motor and load breaks at a certain time.

The set of model equations and the DAE index is changing when the shaft breaks. The Modia environment
makes new symbolic transformations and just-in-time
compilation for each mode of the system. The final results of variables before an event is used as initial conditions after the event.
Mode changes with conditional equations might introduces inconsistent initial conditions causing Dirac
impulses to occur. This more general problem is treated
in (Benveniste, et al., 2017).

2.9 Other features
Other features, such as type and size inference, time
events, synchronous controllers, state events, multi domain models are exemplified in (Elmqvist, et al., 2016).
There are also ongoing development and experimentation regarding nested simulations, etc.

3

Model Examples

3.1 Multibody modeling
Figure 2. Electrical motor, load and breaking shaft.

696

Multibody models uses vector and matrix equations. Below, a tiny multibody library is defined with similarities
to package MultiBody of the Modelica Standard Library

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132693

Session 10B: Modelica Language & Tools

(Modelica Association, 2016). First, convenient Variable constructors involving SIUnits are defined.
Position(; args...) =
Var(T=Meter; size=(), args...)
Velocity(; args...) =
Var(T=Meter/Second; size=(), args...)
Acceleration(; args...) =
Var(T=Meter/Second^2; size=(), args...)
Angle(; args...) =
Var(T=Radian; size=(), args...)
AngularVelocity(; args...) =
Var(T=Radian/Second; size=(), args...)
AngularAcceleration(; args...) =
Var(T=Radian/Second^2; size=(),
args...)
Force(; args...) =
Var(T=Newton; size=(), args...)
Torque(; args...) =
Var(T=Newton*Meter; size=(), args...)
Mass(; args...) =
Var(T=KiloGram; size=(), min=0,
args...)

Based on these scalar Variable constructors, vector and
matrix constructors can be defined.
Axis3(; args...) =
Var(T=SIPrefix; size=(3,), args...)
Position3(; args...) =
Position(size=(3,); args...)
Velocity3(; args...) =
Velocity(size=(3,); args...)
Acceleration3(; args...) =
Acceleration(size=(3,); args...)
Rotation3(; args...) =
Var(T=SIPrefix; size=(3,3),
property=rotationGroup3D, args...)
AngularVelocity3(; args...) =
AngularVelocity(size=(3,); args...)
AngularAcceleration3(; args...) =
AngularAcceleration(size=(3,); args...)
Force3(; args...) =
Force(size=(3,); args...)
Torque3(; args...) =
Torque(size=(3,); args...)
Inertia3(; args...) =
Var(T=KiloGram*Meter*Meter, size=(3,3);
property=symmetric, args...)

It should be noted that Rotation3, the type for rotation
matrices, has a special property:

etc are needed anymore. Note, these operators are awkward, difficult to understand and it is easy to make mistakes.
Other properties can be defined as well. In particular,
the Inertia3 constructor specifies the matrix to be symmetric. This can enable better user interface for setting
parameters.
The coupling semantics is defined by Frames.
@model Frame begin
r_0 = Position3()
R = Rotation3()
f = Force3(flow=true)
t = Torque3(flow=true)
end

A Prismatic joint has two Frames. Axis of translation is
given by a vector parameter n.
@model Prismatic begin
n = Axis3(value=[1,0,0],
variability=parameter)
frame_a = Frame()
frame_b = Frame()
s = Position(start=0*Meter)
v = Velocity(start=0*Meter/Second)
a = Acceleration()
f = Force()
@equations begin
v = der(s)
a = der(v)
frame_b.r_0 = frame_a.r_0 +
frame_a.R*(n*s)
frame_b.R = frame_a.R
frame_a.f = -frame_b.f
frame_a.t + frame_b.t =
cross(n*s, frame_b.f)
# d'Alemberts principle
f = -dot(n, frame_b.f)
f = 0*Newton # Not driven
end
end

A Revolute joint has similar structure.
@model Revolute begin
n = Axis3(value=[0,1,0],
variability=parameter)

property=rotationGroup3D

In particular this means that the element declared in this
way is a 3x3 rotation matrix that has 9 elements with 6
implicit constraints between them. In case kinematic
loops are present, this property of rotation matrices
would lead to redundant constraint equations that are
difficult to handle. As discussed in (Elmqvist and Mattsson, 2016), a tool can, however, automatically remove
this redundancy of a kinematic loop in a pre-processing
step, provided the rotation matrices are marked, as done
above. Compared to current Modelica, the benefit is that
no special operators Connections.branch/.root/.isRoot

frame_a = Frame()
frame_b = Frame()
phi = Angle(start=0)
w = AngularVelocity(start=0)
a = AngularAcceleration()
tau = Torque()
R_rel = Rotation3()
@equations begin
R_rel = n*n + (eye(3) - n*n)*cos(phi)
- skew(n)*sin(phi)
w = der(phi)
a = der(w)
frame_b.r_0 = frame_a.r_0

DOI
10.3384/ecp17132693

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

697

Innovations for Future Modelica

frame_b.R = R_rel*frame_a.R
frame_a.f = -R_rel'*frame_b.f
frame_a.t = - R_rel'*frame_b.t
# d'Alemberts principle
tau = -dot(n, frame_b.t)
tau = 0*Newton*Meter # Not driven
end
end

The skew function is defined as:
skew(x) = [

0 -x[3] x[2];
x[3]
0 -x[1];
-x[2] x[1]
0]

Gravity is defined by the following function:
gravityAcceleration(r) =
9.81*[0,-1,0]*Meter/Second^2

A Body has one Frame. The parameter r_CM gives the
vector from the frame to center of mass.
@model Body begin
r_CM = Position3(variability=parameter)
m = Mass(variability=parameter)
I = Inertia3(variability=parameter)
frame = Frame()
r_0 = Position3()
R = Rotation3()
v_0 = Velocity3()
a_0 = Acceleration3()
w_a = AngularVelocity3()
z_a = AngularAcceleration3()
g_0 = Acceleration3()
W = Var(T=Float64, size=(3,3))
@equations begin
r_0 = frame.r_0
R = frame.R
g_0 = gravityAcceleration(r_0 + R'*r_CM)
# Translational kinematic differential
# equations
v_0 = der(r_0)
a_0 = der(v_0)
# Rotational kinematic differential
# equations
W = der(R)*transpose(R)
w_a = [W[3,2], W[1,3], W[2,1]]
z_a = der(w_a)
# Newton/Euler equations
frame.f = m*(R*(a_0 - g_0) +
cross(z_a, r_CM) + cross(w_a,
cross(w_a, r_CM)))
frame.t = I*z_a + (cross(w_a, I*w_a) +
cross(r_CM, frame.f))
end
end

The coordinate systems must be fixed for multibody dynamics. This is done by using a World object:
@model World begin
frame = Frame()
@equations begin
frame.r_0 = zeros(3)*Meter
frame.R = eye(3,3)

698

end
end

A simple sliding mass model is shown below:
@model TranslationalBody begin
world = World()
j = Prismatic(n=[1,1,1]/sqrt(3),
v = Velocity(start=1*Meter/Second))
body = Body(r_CM=[0.5,0,0]*Meter,
m=1.0*KiloGram,
I=1e-3*eye(3)*KiloGram*Meter^2 )
@equations begin
connect(world.frame, j.frame_a)
connect(j.frame_b, body.frame)
end
end

3.2 Functions and data structures
One of the reasons for developing Modia on top of Julia
is to have direct access to Julia algorithmic features, i.e.
much more powerful functions and data structures than
available in current Modelica.
One of the limitations of current Modelica is a convenient way of handling collisions of many objects for
DEM (Discrete Element Modeling). The problem is that
there are n*(n-1)/2 potential contacts possible for n objects. The user can of course not explicitly make these
connections.
One approach is that each object registers its position.
After that, the forces between each pair of objects in
contact are calculated. Then each object retrieves the
sum of the forces acting on the object. This force is used
in the equations of motion. In (Elmqvist et al., 2015), the
information about each object and the above calculations are handled in C/C++. A problem is that there is
no convenient method in current Modelica to make sure
all objects have registered their position before forces
are extracted. An elaborate scheme involving inner/outer construct together with flow variables was
used.
An experimental feature has been included in Modia
to solve this problem. The built-in operator
allInstances(v) creates a vector of all the variables
v within all instances of the class where v is declared. It
can be seen as a specialization of the proposed Modelica
array constructor: [c.v for c in class Class], (Elmqvist,
et al., 2015b). This construct did not make it into Modelica 3.4 due to concerns about self-reference and mutual recursive loops. The allInstances operator is referring to the class where its used but has a more restricted semantics.
Consider modeling a set of spherical balls moving on
a plane. We will assume the same radius for simplicity
and a force law of a spring-damper during contact. A
Modia model is shown below.
@model Ball begin
r = Var()
v = Var()
f = Var()

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132693

Session 10B: Modelica Language & Tools

m = 1.0
@equations begin
der(r) = v
m*der(v) = f
f = getForce(r, v, allInstances(r),
allInstances(v), (r,v) -> (k*r + d*v))
end
end

The force is dependent on the position and velocity of
all Balls, that is, the allInstances operator is used on
both r and v. The force law is provided as an anonymous function: (r,v) -> (k*r + d*v).
A set of Balls can easily be modelled by just instantiation. The contact handling is automatic:
@model Balls begin
b1 = Ball(r = Var(start=[0.0,2]),
v = Var(start=[1,0]))
b2 = Ball(r = Var(start=[0.5,2]),
v = Var(start=[-1,0]))
b3 = Ball(r = Var(start=[1.0,2]),
v = Var(start=[0,0]))
end

In

this

case

with

three

balls,

the

operator

allInstances(r) expands to [b1.r, b2.r, b3.r].

The force contributions from all other balls are calculated according to the spring-damper model by function
getForce:
const k=10000
const d=100
const radius=0.05
function getForce(r, v, positions,
velocities, contactLaw)
force = zeros(2)
for i in 1:length(positions)
pos = positions[i]
vel = velocities[i]
if r != pos
delta = r - pos
deltaV = v - vel
f = if norm(delta) < 2*radius;
-contactLaw((norm(delta)2*radius)*delta/norm(delta),
deltaV) else
zeros(2) end
force += f
end
end
return force
end

The described technique opens up the possibility for further important optimizations. In order to avoid O(n2)
complexity when deciding which objects that are in contact, space partitioning by quad-trees or oct-trees can be
used, see (Elmqvist et al., 2015). This requires recursive
data structures that are available in Julia.

3.3 Media Modelling
The Modelica.Media library within the Modelica Standard Library1 provides a large set of packages and functions to compute media properties of one and two-phase
media dedicated for simulation. Although the Media library is powerful, it has conceptual limitations for the
modeling of media with multiple substances that have
multiple phases. Furthermore, the details of the library
are difficult to understand and difficult to support by
Modelica tools due to the extensive use of replaceable
packages and functions. There have been several attempts to simplify the approach and making media modeling more powerful.
Julia allows a fresh view on this difficult topic and it
seems that multiple dispatch and other Julia features allow a surprisingly simple way to model complex media:
Following the Modelica.Media library design, a medium has the following orthogonal properties:
1. Medium states that define the independent variables
of the medium. A medium may have different types
of independent variables. For example, it might
have as independent variables pressure p and temperature T or pressure p and specific enthalpy h. In
Julia they would be described as types.
2. Medium constant data that defines constants for
every instance of a specific medium. For example a
simple medium may have a constant d_const for the
mean density. In Julia constant data would be described as constants in a module.
3. Medium immutable data that defines constants specific to an instance of a specific medium that cannot
be changed once the medium is instantiated. Typically reference points such as h_offset may have a
default value, but might be changed for particular
medium instances. In Julia such data would be described as immutable types.
4. Medium functions that define properties of a medium as function of the medium constant and immutable data and the medium states. For example density(medium,state) computes the density for a
medium using the given state description.
Below is a sketch of a new Media library design:
module Media # Interface of media models
# Possible medium states
type State_pT
p::Float64
T::Float64
end
type State_ph
p::Float64
h::Float64
end
# Possible medium functions
density(medium,state)=error(..)

1

http://doc.modelica.org/om/Modelica.Media.html

DOI
10.3384/ecp17132693

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

699

Innovations for Future Modelica

specificEnthalpy(medium,state)=error(..)
setState_pT(medium,p,T)=error(..)
setState_ph(medium,p,h)=error(..)
...
end

In a generic module Media, the supported medium states
and the supported medium functions are collected. The
default implementation of the functions for every medium are error messages. However, also concrete functions could be added here that hold for every medium.
A specific medium is implemented with a Julia module, as shown here for a simple water model:
module SimpleWater
import Media
# Constants of
const cp_const
const cv_const
const d_const
const T0

medium
= 4184.0
= 4184.0
= 995.586
= 273.15

# Variables specific to an instance
immutable Medium
h_offset::Float64
Medium(;h_offset=0.0) = new(h_offset)
end
# Functions of medium
Media.density(
m::Medium,
state::Media.State_pT) = d_const
Media.specificEnthalpy(
m::Medium,
state::Media.State_pT) =
cp_const*(state.T - T0) + m.h_offset
Media.setState_pT(m::Medium, p, T) =
Media.State_pT(p,T)
Media.setState_ph(m::Medium, p, h) =
Media.State_pT(p,
T0+(h-m.h_offset)/cp_const)
...
end

In a Modia model Julia data structures and functions can
be used. As a result, it is possible to instantiate a medium
model at some place with
medium1=SimpleWater.Medium()
medium2=SimpleWater.Medium(h_offset=10.0)

and then propagate this medium through all connected
fluid component models:
@model FluidPort begin
# contains medium, p, h, ...
end
...
port = FluidPort()
...
port.medium = SimpleWater.Medium()

Inside a component model, medium properties are computed. The implementation of such a component model
neither knows which concrete medium model is used,
nor which independent states the medium has, so the

700

component model can be used for all media that provide
an implementation of the used functions:
state = setState_ph(port.medium,
port.p,
port.h)
d = density(medium,state)
h = specificEnthalpy(medium,state)

Julia selects the concrete functions to be called based on
the medium type and the state type. This is the key innovation that makes media modeling suddenly so simple: a function is (statically) selected based on the types
of several arguments.

4

Implementation

The Modia implementation is made in Julia which provides meta-programming capabilities which are suitable
for symbolic treatment of the equations.

4.1 Meta-programming in Julia
Languages such as Modelica and Modia require symbolic transformations of equations into executable code.
A mathematical expression is conveniently represented
by an AST (abstract syntax tree). The Julia language
(Bezanson, et al., 2017) allows creation of quoted expressions encapsulated as, :().
julia> equ = :(0 = x + 2y)
:(0 = x + 2y)

Such an expression is stored as an AST. The AST can
be shown by using a built-in function, dump():
julia> dump(equ)
Expr
head: Symbol =
args: Array(Any,(2,))
1: Int64 0
2: Expr
head: Symbol call
args: Array(Any,(3,))
1: Symbol +
2: Symbol x
3: Expr
head: Symbol call
args: Array(Any,(3,))
typ: Any
typ: Any
typ: Any

equ is of type Expr which has three fields: head, args
and typ. equ.head is the Symbol = representing the
equality of the two expressions of the equation. The
right hand side is the sum of two expressions: x and 2y.
The operator + is represented as a function call:
equ.args[2].head. Which function to call is defined in
equ.args[2].args[1]. The operands of the + operator are
equ.args[2].args[2] and equ.args[2].args[3].
A new AST can be built using the Expr constructor.
For example, solving an equation of the form:
0 = x + expression

can be done as follows:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132693

Session 10B: Modelica Language & Tools

julia> solved = Expr(:(=),
equ.args[2].args[2], Expr(:call, :-,
equ.args[2].args[3]))
:(x = -(2y))

It is also possible to create a quoted expression referring
to parts of equ by the use of interpolation, $( ).
julia> solved = :($(equ.args[2].args[2]) =
- $(equ.args[2].args[3]))
:(x = -(2y))

The result is presented as a quoted expression. By assigning the variable y, its possible to calculate x using
the eval function on the AST solved:
julia> y = 10
10
julia> eval(solved)
-20
julia> @show x
x = -20

4.2 Symbolic Transformations of Modia
Models
The following list shows some of the structural and symbolic transformations which are performed by the Modia
implementation:
 Instantiation
 Flattening
 Alias elimination
 Type and size inference
 Removal of singularities
 Index reduction and BLT of array equations
 Symbolic differentiation of matrix equations
 Symbolic solution of matrix equations
 Partial state selection and tearing
 Transformation to a special index one DAE
 Determining sparseness structure of Jacobian
Modia supports type and size inference, that is, the Variable constructor does not need to specify type and size.
However, Pantelides algorithm and removal of singularities require that types and sizes of variables and equations are known. Types and sizes are inferred from the
start values provided and by propagation. The left and
right hand sides of equations are evaluated with given
start values and the type and size inference of Julia is
used to determine the size and types of variables and
equations.
There are useful application models where structural
symbolic algorithms fail and may lead to strange error
messages during symbolic processing or to run-time errors. For example, if an electrical circuit is not grounded,
the potentials of the electrical Pins can float, that is, the
system equations are underdetermined. On the other
hand, the equations are overdetermined regarding currents. Such singularities needs to be removed before further structural processing. Details of such a technique is
described in the companion paper (Otter and Elmqvist,
2017).

DOI
10.3384/ecp17132693

The Pantelides algorithm and other structural index
reduction algorithms are designed for scalar variables
and equations. So Modelica tools typically symbolically
expand array equations into a set of scalar equations involving the variable elements. This is not feasible if
large array equations are used, for example, for flexible
bodies or other discretized partial differential equations.
Generalizations of BLT and Pantelides algorithms to directly handle array equations can be found in (Otter and
Elmqvist, 2017).
Pantelides algorithm determines which array equations that needs to be differentiated. Special care are
needed when performing symbolic operations on array
and matrix equations since matrix multiplication is not
commutative. Solving for unknowns are done by a set
of rewrite rules. As an example, the right division operator, /, or the left division operator, \, is used depending
on whether the unknown is on the right or left side of a
multiplication operator. Special rules can be used for rotation matrices to replace division by multiplication with
the transpose of the rotation matrix.

4.3 Numeric Solution of Modia Models
Numeric treatment and transformation of the resulting
differential algebraic array equations to index one form
is described in the companion paper (Otter and
Elmqvist, 2017).

5

Outlook

The Modia experimental language gives new possibilities for creation of new innovative language elements
and algorithms to model and simulate more complex
models than is possible in current Modelica.
The suggested innovations of the companion paper
(Otter and Elmqvist, 2017) can be directly utilized in
current Modelica tools. A change in the Modelica language is not needed for them. Part of the proposed innovations in this paper for new language elements, such as
type inference, marking of rotational matrices in combination with new algorithms, or the allInstances(..) operator, could be included in a fully backwards compatible
form in a future Modelica 3.x version.
The use of native Julia for the algorithmic part would
simplify the Modelica effort considerably since Modelica does not need to be extended with new features in
functions. This means that evolution of Modelica could
be focused on the equational modeling aspects.
Contributions to Modia for language design and for
improved symbolic and numeric algorithms are welcome.

References
Benveniste A., Caillaud B., Elmqvist H., Ghorbal K., Otter
M., and Pouzet M. (2017): Multi-Mode DAE Models Challenges, Theory and Implementation. Lecture Notes on
Computer Science, submitted for review.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

701

Innovations for Future Modelica

Bezanson J., Edelman A., Karpinski S. and Shah V.B.
(2017): Julia: A Fresh Approach to Numerical Computing.
SIAM Review, Vol. 59, No. 1, pp. 65-98.
http://julialang.org/publications/julia-fresh-approachBEKS.pdf; see also: http://julialang.org/
Broman D., Siek J. G. (2012): Modelyze: a Gradually Typed
Host Language for Embedding Equation-Based Modeling
Languages, University of California at Berkeley, No.
UCB/EECS-2012-173, www2.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-173.html.
Danish D. (2014): FixedSizeArrays, https://github.com/SimonDanisch/FixedSizeArrays.jl
Elmqvist H., Goteman A., Roxling V., Ghandriz T. (2015):
Generic Modelica Framework for MultiBody Contacts and
Discrete Element Method. Proceedings 11th International
Modelica Conference, Versailles.
http://www.ep.liu.se/ecp/118/046/ecp15118427.pdf
Elmqvist H., Olsson H., Otter M. (2015b): Constructs for
Meta Properties Modeling in Modelica. Proceedings 11th
International Modelica Conference, Versailles.
http://www.ep.liu.se/ecp/118/026/ecp15118245.pdf
Elmqvist H. and Mattsson S.E. (2016): Exploiting Model
Graph Analysis for Simplified Modeling and Improved Diagnostics. Proceedings EOOLT '16, April 18, Milano, Italy.
Elmqvist J., Henningsson T. and Otter M. (2016): System
Modeling and Programming in a Unified Environment
based on Julia. Proceedings of ISoLA 2016 Conference
Oct. 10-14, T. Margaria and B. Steffen (Eds.), Part II,
LNCS 9953, pp. 198-217.
Fisher K. (2013): SIUnits. https://github.com/Keno/SIUnits.jl
Giorgidze G., Nilsson H. (2009): Higher-Order Non-Causal
Modelling and Simulation of Structurally Dynamic Systems. In Proceedings of the 7th International Modelica
Conference, pages 208218, Como, Italy.
http://www.ep.liu.se/ecp/043/022/ecp09430137.pdf.
Hger C.: Dynamic structural analysis for DAEs. In Proceedings of the 2014 SCS Summer Simulation Multiconference, 2014.
Mattsson S.E, Otter M., and Elmqvist H. (2015): Multi-Mode
DAE Systems with Varying Index. Proceedings 11th International Modelica Conference, Versailles.
http://www.ep.liu.se/ecp/118/009/ecp1511889.pdf
Modelica Association (2014): The Modelica Language Specification, Version 3.3 Revision 1, https://www.modelica.org/documents/ModelicaSpec33Revision1.pdf
Modelica Association (2016): The Modelica Standard Library, Version 3.3.2, https://github.com/modelica/Modelica
Otter M., and Elmqvist H. (2017): Transformation of Differential Algebraic Array Equations to Index One Form.
Modelica Conference 2017, Prague, May 15-17.
Short T. (2012): Sims - A Julia package for equation-based
modeling and simulations.
https://github.com/tshort/Sims.jl.
Zimmer D. (2010): Equation-Based Modeling of Variable
Structure Systems. PhD Dissertation, ETH Zrich. http://ecollection.library.ethz.ch/eserv/eth:1512/eth-1512-02.pdf.

702

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132693

Hierarchical Semantics of Modelica
Christoph Hger1
1 Institute

of Software Engineering and Theoretical Computer Science, Technische Universitt Berlin, Germany
christoph.hoeger@tu-berlin.de

Abstract

2 Modelica Scoping and Hierarchies

We present a definition of syntax and semantics for Modelicas hierarchical lookup. By using a context-independent
encoding of the static semantics of free variables, it becomes possible to define the evaluation of references within
a calculus based on substitution. Hence, all steps of evaluation have a concrete syntactic representation. We augment
the calculus with a terminating evaluation and a semanticspreserving translation to a basic  -calculus.
Keywords: Semantics, Classes, Compilation

In its simplest form, a Modelica class serves as a container
for a sequence of declarations. These may introduce constants, parameters, unknowns or declare components that
are instances of other classes. The meaning of variables
in the right-hand sides of these declarations is somewhat
intricate as the example in Listing 1 shows.
The declaration of the constant x in class A refers to
two free variables, y and z. Class A is a child of class B,
which is in turn a child of C in the class-hierarchy. Hence it
sees all declarations1 of its parent classes. In the classical
sense, B is part of As lexical scope. Therefore, z is found
directly in the surrounding scope. Note that the definition
of constant z (the literal 21) is syntactically placed after A.
The scope of a binding is independent from the order of
declarations. Variable y is not defined inside B. The next
candidate is C, where it is defined as modelicaB.z.
Such a composite name gives access to elements downwards the hierarchy. In a first step, B is found as before
in the scope of C. The result of this search is then used to
search for z, which is defined as 21. Hence the result of
evaluating C.B.A.x should yield 42.
Although this kind of scoping might seem pretty standard, there is a subtle difficulty embedded in this seemingly
simple principle. In Modelica, there is no (syntactic) difference between looking up a class (e.g. B) and its fields (e.g.
z). What might seem like an elegant unification, turns out
to be a source of major complication in combination with
inheritance.

1 Introduction
In current Modelica, there is no way to express the definition of a variable as a purely syntactic property, independent of the context in which it might be used. Its definition
is obtained as part of the dynamic semantics of the flattening process. This effectively renders static analysis of
models and packages impossible. Furthermore, there is
no formal method to obtain its meaning from the a found
definition in the context of a simulation model, as the dynamic semantics of hierarchical elements are defined only
informally.
This paper attempts to improve this situation by the
means of a compositional core calculus of classes, MCL.
In this language, we define syntactic elements for the expression of static properties of variables in a class. The semantics of Modelica-style hierarchical classes is integrated
within the framework of the classic  -calculus. This integration is inspired by the treatment of modules by Pierce
(2005). For the evaluation, we focus solely on the problems
mentioned above. For a discussion of the relation between
model elaboration and the  -calculus, we refer to earlier
work(Hger 2016). In a final step, we present a translation
that replaces the hierarchical elements with semantically
identical non-hierarchical terms. This shows how a hierarchical model can be translated into a simpler functional
language.
The rest of this paper is organized as follows: An introduction into Modelicas scoping and hierarchical organization leads to the definition of the hierarchical core calculus
of MCL. This is followed by a graphical interpretation
of the hierarchical environment and consequently its semantics. The paper concludes with a transformation of the
hierarchical aspects to more basic elements of the language.
This transformation is shown to be faithful in the sense that
it preserves the evaluation semantics.
DOI
10.3384/ecp17132703

2.1 Inheritance and Modifications
Lexical scoping as it is used above is still a pretty straightforward matter: After all, the environment in which to look
for the definition of a variable is determined by the syntactical composition of classes. The complexity rises drastically however, once inheritance (expressed as extends
statements) comes into play:
class D
extends C.B(z=2);
constant Integer x = A.x;
end D;
class C . . . end C;

1 At

least the ones with the proper variability

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

703

Hierarchical Semantics of Modelica

Listing 1. Hierarchical Lookup
class C
constant Integer y = B.z;
class B
class A
constant Integer x = y + z;
end A;

C.B.A.x
y
B.z
z

constant Integer z = 21;
end B;
end C;

In the class D above, with C left unchanged, what is the
value of D.x? Since A is inherited in D from C.B, it is
tempting to assume the answer is, again, 42. Instead, the
returned value is 232 .
The reason for this is shown in Listing 2. In the first step,
A is found to be inherited from the base class C.B. This
lookup succeeds immediately without further involvement
of inheritance. Hence, A.x is resolved by looking for x in
B. This class contains the same definition of x as before.
Accordingly z and y need to be looked up again. Variable z
is again looked up in its immediately enclosing scope. This
time, this scope is not provided by A, but by the inheriting
class D. Therefore the resulting value is 2.
In an interesting twist, y is not subject to this modification. Since its lookup passes through C and only then
returns to the definition of z the inheritance is discarded.
The resulting value is therefore found in the lexical scope
of A, and hence yields 21. The overall evaluation yields 23.
This example demonstrates an important fact about
Modelica-classes. The site of the definition of a free variable is not a syntactic property of the class. Instead, it
depends on the context in which this class is used.

2.2 The Principle of Open Recursion
This context is the result of evaluating all relevant super
classes. Therefore, the definition of lookup has to be part
of the evaluation of classes and vice versa. In Modelica
there is no explicit ordering between declarations. Due
to the existence of inheritance and because classes are
looked up in the same way as other declarations, such an
ordering cannot be found without knowledge of the context
of the class. Both the construction of the context and the
evaluation of class references are recursively linked.
In classical object-oriented languages, this principle is
called open recursion(Aldrich and Donnelly 2004): Each
method has access to a special variable (often called this
or self). Methods are always invoked from a concrete
object (sometimes called the reciever of a message). This
object then becomes the definition of the special variable
during evaluation of the methods body (the special variable is late bound). Free variables in the method are interpreted by method invocation on the special variable. This
2 as

704

discussed in https://trac.modelica.org/Modelica/ticket/2013

principle yields an implementation of recursion, since the
method itself is an element of the receiving object. It is
open, since the method might be part of different concrete
objects (and invoke different siblings on each). Hence, it is
possible to change the behavior of all methods of an object
by exchanging only one method. The same concept can be
used to explain the lookup inside Modelicas classes, when
it is applied not only to one, but possibly many special
variables.
class D
constant Integer z = 2;
extends up(1).C.B;
constant Integer x = this.A.x;
end D;
class C
constant Integer y = this.B.z;
class B
class A
constant Integer x = up(2).y + up(1).z;
end A;
constant Integer z = 21;
end B;
end C;

In the listing above, references to the context have been
codified by two kinds of special variables: this denotes a
reference to the immediately enclosing class, while up(i)
expresses access to the i-th enclosing class (hence up(0)
is the same as this, but less readable). The benefit of such
a form lies in the fact that it eliminates any free variables
and still allows to use the class in different contexts.

3

MCL

In order to focus the discussion on the hierarchical semantics by the means of such special variables, it is useful to
define a minimal calculus and ignore the any feature of
Modelica that does not directly contribute to the discussion. To this end we define MCL, a small core calculus
that embeds hierarchical term into the classical minimal
 -calculus. Besides the more concise representation, such
a reduction allows to express the complete domain of discourse. In the following sections, all relevant elements
can be expressed in the form of expressions in the core

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132703

Session 10B: Modelica Language & Tools

Listing 2. Hierarchical Lookup with Inheritance
class D
extends C.B(z=2);
constant Integer x = A.x;
end D;
class C
constant Integer y = B.z;
class B
class A
constant Integer x = y + z;
end A;

D.x

z

A.x
y

B.z

constant Integer z = 21;
end B;
end C;

language. There is no need to resort to externally (and every element is the result of applying f to the correspondimprecisely) defined entities like tables, environments or ing element in .
universes of classes.
In order to not confuse meta-level equality (e.g. of terms)
with its object-level counterpart (e.g. in an equation), we

3.1 Notational Conventions





write a = b to indicate the former (and a 6= b for the oppoLanguages are defined in a simple BNF-form: Nontermisite).
nals (e.g. t, v are expressed with the same small italic
letters as meta-variables of the corresponding syntactic sort 3.2 Syntax
(e.g. we will use t to denote both the set of terms and a
variable from that set). Productions (e.g. t ::=  x.t | x) The syntax of MCL distinguishes between hierarchical
map a nonterminal (to the left of the ::=) to clauses con- terms h and proper terms t (Figure 1). There are five
sisting of nonterminal and terminal symbols. Clauses are variants of hierarchical terms: The special variables up(i)
separated by a | . Each clause is one possible derivation refer to the i-th enclosing class. Literal classes C are a
of the left hand side. Terminal symbols (e.g. , true, if) are list of fields F bracketed in special curly braces, {|F|}.
A class field can either contain a hierarchical class (e.g. a
written in a non-proportional font.
Partial functions are univalent relations {x 7 y}. These child class) (L = h) or a value (l = t. We presume that
L can be distinguished from each label l:
relations can be augmented using the -operator, borrowed each class-label

L  l = 0.
/ A hierarchical node v denotes a class containing
from the specification language Z:
the fields F as a hierarchical child of the enclosing class

denoted by  , written {|F in  |} (the environment is
p  q = {x 7 y | x 7 y  p and x 
/ dom(q)}  q
thus encoded as a list of nodes and each node contains its
Jt K denotes the function  applied to t. In order to own environment). Explicit Modifications {|h with F|}
enhance readability, these (recursive) functions are defined override the fields defined in the class described by hterm
using pattern matching on their arguments: Jt1 t2 K means with the fields in F.
Access to the field L of a class requires an explicit nothe application of  to one term formed by the juxtaposition
of two (possible distinct) terms (i.e. the term representing tion of the corresponding super class in a reference R:
the application of t1 to t2 ). If multiple arguments are passed h1 .super(h2 ).L. Here, h1 refers to a class extending h2
to a semantic function, they are separated by commas. which in turn describes the definition-site of the declaration
Meta variables are bound in the patterns or corresponding labeled with l. The access reads as: Get the field labeled
where-clauses. When necessary, we consider each function with L in the class h2 extended by h1 . This makes the
as overloaded on different syntactic sorts, e.g the function interface of a class immediately visible (since all inherited
 can be applied to recursive definitions F as well as the fields have to be defined locally as forward references)
and is a necessary precondition for a substitution-based
fields of a class F.
Sequences are abbreviated by an overline over the name semantics. If no super class shall be referenced directly,
of the contained meta variables, e.g. t describes a sequence both parts of a reference are equal. Since this is a common
t1 . . .tn . The empty sequence is . Non-empty sequences case, we introduce the abbreviation h.L = h.super(h).L
are written as pairs of a value and the remaining sequence, to enhance the readability.
separated by a double colon, e.g. s :: t describes the seTerms t consist of the standard elements of the  quence s,t1 , . . . ,tn . The operator  maps a semantic func- calculus extended with non-strict conditional, and an extion on a sequence, e.g. f  F yields a sequence where plicit fixed point operator fix (which ranges over multiple,
DOI
10.3384/ecp17132703

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

705

Hierarchical Semantics of Modelica

Hierarchical Terms:

Core Terms:

h

::= up(i) | C | 

R

| {|h with F|} | R
::= h.super(h).L

, 

::= {|F in  |}

C
F

::= {|F|}
::= L = h | l = t

t
r

::= x | v | t t | t  t | r | if t then t else t
::= h.super(h).l

Values:
v

::= b |  x.t | fix x in F | true | false | Z | Q

F

::= x =  y.t
Figure 1.

MCL

mutually recursive functions in F). Values v  t are the
evaluated normal forms. Builtin primitives b are booleans,
rational numbers, integers and strings. The corresponding
binary operators are summarized in .
A value field can be accessed from a class using a

notation similar to the class-selection: A reference r =
h1 .super(h2 ).l refers to the field labeled with l in class
h2 extended by h1 . Again we allow the convenient abbrevi
ation h.l = h.super(h).l
Capture-avoiding substitution of variables by a partial
function p is written as [p]t. The usual conditions for freshness of bound variables have to apply to the codomain of
the partial function. Substitutions do not pass over refer
ences, i.e. [p]r = r. We write Jt Kfv to denote the set of free
variables in a term. Variables are bound by abstraction and
the mutually recursive functions (plus their arguments) of
a fixed-point. In all other cases, the set of free variables is
the union of the free variables of all sub terms.
A context is a term with a hole into which another term
is plugged. This hole is expressed as a special variable .
By convention  is never bound in any term. Plugging a
term t into a context s is then obtained via substitution
[ 7 t]s.

basic syntax

sive operations, selection, search and evaluation. During
evaluation, a special variable i is resolved in a given environment E to the i-th entry of the environment.


JE, up(n)Keval

= E(n)

JE,CKeval

= {|C in E|}



JE, h.LKeval

= JJE, hKeval , LKselect

JE,t Keval

= ...




Composite names (e.g. up(2).z) are evaluated from left
to right by selecting the label. Evaluating a literal class
with a given environment yields a context by appending
that literal class to the current environment. We ignore the
evaluation of proper terms for now.

J , LKselect

when



= JJ 0 Kenv  {0 7  }, hKeval


J , LKsearch =  0 , h

In order to select a field from a class, its definition has to
be found in the class itself or in a super class. The resulting
term is then evaluated under a new environment (obtained
via env from  0 ). By setting the 0-th environment entry
to the receiver, the special variable this is given a new
4 The Hierarchical Environment
meaning. If the definition is found in the receiver itself, i.e.

The semantics of hierarchical terms can be seen as the re-  =
 0 , the change has no effect.
duction to a normal form of evaluated classes. We will

motivate this normal form by a somewhat informal inter , h if L = h  J Kclass



pretation of the process. For reasons that will become clear



in a moment, call an evaluated class a node (expressed by

J

,
L
K
=
 0 , h0 if  extends hS
search
the syntactic sort  ). Nodes are created as the combination




Jh, J Kenv Keval
= S
of a literal class C with an environment.




The environment inside a node has one additional entry,
JS , LKsearch
=  0 , h0
mapping 0 to the node itself. All other entries link back
to the original environment (just one level higher). In a
A definition is searched recursively: If the field is a
certain sense, this definition forms an inverted view of the literal child, its right hand side is searched. Otherwise,
syntax tree, as each node gives access to an ordered set the super classes of the context are evaluated and search
of children (which may be its parents in the syntax tree). continues there.
Environments are forests of such trees and literal classes
are node labels. (Hence the name node for the elements of 4.1 Graphical Interpretation
this structure.)
As an example, consider the classes C and D from above
Evaluation of hierarchical terms can be defined by the and the evaluation of D.x. Since all classes in that example
resolution of special variables and the three mutually recur- have a unique name, this name is used in abbreviations as
706

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132703

Session 10B: Modelica Language & Tools

a subscript, i.e. C is the obtained from evaluating class C,
With these observations it is now possible to understand
EC is its environment and CC denotes its literal class.
the evaluation of D.x. In a first step, the field is found in
To support the interpretation of class values as nodes in the node itself:
a tree, they are drawn as directed graphs. Each node can

(8)
JD , xKsearch = D , this.A.x
be interpreted as such a directed graph with edge labels
to indicate the ordering of its enclosing classes. A node
There is no field A in CD . The search continues in the
label indicates the literal class. The order of nodes in an
environment is drawn as graphs with two kinds of vertices. super class, B . Here, the field is found:
Each entry is represented by a circular node that is labeled

JD , AKsearch = JB , AKsearch
by (7)
with a natural number and has exactly one outgoing edge
(9)

to the corresponding element of the environment. The
= B ,CA
top-level environment is drawn as follows:
CA is found in the super class B . The evaluation envi
ronment
is constructed from both the super class as well as
.
0
Eroot =
(1) the extending class:
Creating new nodes from a literal classes inside an environment is achieved by adding a new node (labeled with
the literal class), replacing the special nodes with edges
from that node to their respective target and increasing their
label by one:





ES = JB Kenv  {0 7 D } =

0

1

D

C

2

1

.

1

(10)
Evaluation
of
the
literal
class
then
appends
C
to
the
A


.
D
{|CD in Eroot |} = D =
nodes
of
the
environment.
This
node
in
turn
has
its
own
(2)
environment as usual:
A node implies an environment on its immediate chil0
2
1
3
dren (function env). This environment is obtained by map1
1
ping the node itself to 0 and adding an entry for each


.
C
D
A
EAS = JAS Kenv =
outgoing edge:
1
1

2

0


JD Kenv = ED



D

=

3

1

1

.

(3)

(11)
Resolving up(2) and up(1)in EAS yields C and D ,
Classes C and B are evaluated in a similar style to D in 2: respectively. Hence, y and z can be selected:




C = {|CC in Eroot |} =



1

C

.

(4)

JEAS , up(2).yKeval = JC , yKselect by (11)


= 21



JEAS , up(1).zKeval = JD , zKselect






B = {|CB in EC |} =

B

1

C

1

(12)

by (6)

by (11)

(13)



= JED , 2Keval = 2

.

This demonstrates two important aspects: First, the mod(5) ification in C has affected the evaluation as intended. And
D
second, the inheritance is forgotten, when the lookup
Using these classes, a simple evaluation can be pro- passes the correspoding lexical scope. The evaluation of y
cessed as follows:
takes place in C without further changes. In conclusion,
the result is 23, as expected:

JC , yKselect = JEC , up(0).B.zKeval
2



(6)

= JJC , BKselect , zKselect








= JB , zKselect = JEB , 21Keval = 21

= JJD , AKselect , xKselect


= JJES ,CA Keval Kselect

Similarly, the super class of D can be evaluated:



= JEAS , up(2).y + up(1).zKeval



JED , up(1).C.BKeval = JJroot , CKselect , BKselect




= JC , BKselect = B

DOI
10.3384/ecp17132703



JD , xKselect = JED , this.A.xKeval



(7)



= JEAS , 21 + 2Keval = 23

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

by (8)
by (3)
by (9)
by CA

by (12,13)

707

Hierarchical Semantics of Modelica

OP
VAL

vv



v3 = (arithmetic)v1  v2
t1  v1
t2  v2
t1  t2  v3

A PP

I F -T RUE

I F -FALSE

t1  true
t2  v
if t1 then t2 else t3  v

t1  false
t3  v
if t1 then t2 else t3  v

F IX A PP

t1  fix x in F
t2  v2
x 7  y.t3  JFK
[JFK ]([y 7 v2 ]t3 )  v
t1 t2  v

t2  v1
t1   x.t3
[x 7 v1 ]t3  v2
t1 t2  v2

N ODE

 h 

ROOT

{|F|} h {|F in |}
M OD

HS ELECT
h

S ELECT

h

h1  1
h2  {|F in  |}
L 7 h3  JF K
J1 ,  , h3 K h 3
h1 .super(h2 ).L h 3

h

h

h1  1
h2  {|F in  |}
l 7 t  JF K
J1 ,  ,t K  v
h1 .super(h2 ).l  v

h h {|F 1 in  |}
dom(F 2 )  dom(F 1 )

JF 3 K = JF 1 K  JF 2 K

{|h with F 2 |} h {|F 3 in  |}

Figure 2. Evaluation semantics

4.2 Dynamic Semantics
Figure 2 depicts the rules of the dynamic semantics of MCL
in big-step or natural(Kahn 1987) style. A term t evaluates
to a value v, iff both are related by a reduction relation
t  v. Erroneous terms are identified by not being related
to some value. All elements of  are defined inductively
by inference rules.
In order to simplify the notation of sequential constructs,
it is useful to define a mapping between concrete syntax and
partial functions. Each sequence can be seen as a partial
function, mapping its left-hand elements to the corresponding right-hand side. This conversion is implemented with
the function .

The hierarchical semantics of MCL is embedded into the
proper evaluation (but not vice-versa). In a certain sense,
classes play the role of modules. Evaluation of a hierar
chical term h to a hierarchical class  = {|F in  |} with
parents 1 . . . n is written h h  . Rule S ELECT augments
the evaluation relation . Hierarchical nodes are already in
normal form (rule N ODE). An empty literal class evaluates
to a root node (rule ROOT).
4.2.1 Selections and Inheritance

Selecting a child class via HS ELECT or S ELECT relies on
the search of the corresponding definition. This is implemented by a partial function from labels to hierarchical
terms. Depending on the context, either a class label L

JFK
= {x1 7  y1 .t1 }  . . .  {xn 7  yn .tn } or a value label l is looked up. Notably, this definition

where
F = x1 =  y1 .t1 , . . . , xn =  yn .tn of the search operation is not recursive. It relies on the
encoding of inherited fields as references from this to the

JK
= 0/
corresponding super class.

MCL does not allow for unqualified inheritance of names:
Jl = t :: F K = JF K  {l 7 t}
Instead of a single extends statement, all inherited fields

JL = h :: F K = JF K  {L 7 h}
have to be explicitly present in the base class. The def
JFK
= { xi 7 fix F in xi | xi  dom(JFK ) } inition then forwards to the super class with the second
argument of the reference:
Rule A PP is the standard application via substitution. O P
implements binary operators on builtin primitives; it is A = this.super(up(1).Y).A;
actually a family of rules with one element for each builtin a = this.super(up(1).Z).a;
operator. Rules I F -FALSE and I F -T RUE implement nonstrict conditionals.
In the example above, class A and the value a are in
Mutually recursive functions F = xi =  yi .ti are imple- herited from classes Y and Z, which are found in the outer
mented via the explicit fixed point term fix x in F, the scope. The delegation is resolved by either HS ELECT or
special function  and rule F IX A PP. In order to evaluate S ELECT. Multiple levels of inheritance are then expressed
a recursive function, first the argument has to be evalu- by a chain of such delegations. This style decouples the set
ated. This argument is then substituted into the body of of inherited elements from the definitions in the super class
the function, followed by a substitution of the group itself, and allows for a more selective approach (e.g. it becomes
as defined by  . Due to the nature of natural semantics, possible to express the resolution of multiple inheritance
divergence cannot be distinguished from a stuck term.
of fields with the same name).
708

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132703

Session 10B: Modelica Language & Tools



J_, _,  K

= 

J ,  , {|h with F|}K

J_,  , up(n + 1)K

= n+1

J ,  , {|F|}K

= {|F in  ::  |}



J ,  , up(0)K

= 

J_, , up(n + 1)K

= up(n + 1)

where



= {|J ,  , hK with f  F|}

JL = hKK f










= l = J ,  ,t K

J ,  , h1 .super(h2 ).LK = J ,  , h1 K .super(J ,  , h2 K ).L



J ,  , xK = x

Jl = t K f



= L = J ,  , hK

J ,  , h1 .super(h2 ).l K


J ,  ,  x.t K =  x.J ,  ,t K



= J ,  , h1 K .super(J ,  , h2 K ).l



J ,  ,t1 t2 K = J ,  ,t1 K J ,  ,t2 K

...

Figure 3. The Fold Function

In order to adhere to the principle of open recursion
between fields of a class, the special variables in a found
term are resolved using the fold operators  : h  h  h
and  : h    t  t before evaluation. These mutually
recursive functions (Figure 3) take three arguments: An
evaluated class  represents the tip of the environment (i.e.
the self-instance),  is the list of hierarchical parents of the
super class containing the definition of the current term,
and the third argument is the input that is being folded. 
expects and returns an hierarchical term h while  works
on plain terms t.
In the case of plain terms, the result of folding is simple:
 is applied on the sub terms or returns its input unchanged
if the argument is primitive. Value references are processed
by folding the hierarchical sub terms with .
Folding hierarchical terms resolves the special variables
up(i) (thus implementing the environment directly via substitution): The special variable up(0) (the this-variable)
is replaced with the self -instance (the first entry of the
environment). Other special variables are looked up accordingly. If the environment is empty, the result is left
unresolved. References and modified classes are folded
by folding their corresponding sub terms. In the case of
modifications this ensures that a modified field is evaluated in the context of the modification site (and not in the
context of the modified class). Literal classes are turned
into nodes by storing the environment alongside their fields.
Contrary to modifications, their fields are not subject to
further folding. This ensures that child classes retain their
own context, when a field is selected from that child class.
Nodes are left unchanged by the fold function.

4.3 Modifications and Redeclarations
MCL supports both redeclarations and modifications. The
former are implemented via overriding of inherited methods (thus, there all fields are considered replaceable). Modifications differ from overriding in their scope  modifications live outside of the modified class. Each modified field
must exist in the modified class. It is not possible to add a
field via a modification. The modification of a class h with
a sequence of fields F results in a class containing the modified fields merged with the result of the evaluation (rule
M OD). Merging is implemented by lifting the fields into

DOI
10.3384/ecp17132703

partial functions, augmenting the original function with the
new fields and lowering the result into a sequence of fields.

5 Translation of References
The specification of Modelica require the evaluation of
names only when necessary; i.e. the lookup of classes,
functions, types and variables is always driven by the attempt to flatten a particular class. We take a slightly different stance, and demand that all references can be looked
up strictly. The goal is to replace all references (inside
a certain term) with their definitions (and transitively all
references in them). The resulting term is then free of any
hierarchical references and can be evaluated as usual. This
technique allows to consider lookup and flattening as completely separate parts of the semantics (and gives reason to
consider the former as part of the static semantics).

5.1 Evaluation of Hierarchical Terms
The definition of h is algorithmic, a naive implementation will however not always terminate due to the open
recursion. In particular, evaluating the subterms of a class
reference might require evaluation of the same class reference:
{| class A = this; x = this.A.x |}.x

In the example above, a naive interpreter will repeatedly
attempt to evaluate the class reference this.A.x. This is
not a particularity of MCL, as the following example shows:
class A
model B extends C; end B;
model C extends B; end C;
B.Foo b;
end A;

This simple model cannot be flattened (as there is no class
definition for the component b). Yet, the attempt drives the
leading free implementations OpenModelica (in version
1.11.0) and JModelica (version 1.17) into an endless loop,
eventually ended by a stack overflow. In a realistically
sized model, the user can only speculate what causes such
a crash and, should the relevant loop be optimized to a
tail-recursive implementation, might not even encounter a
crash but a frozen implementation.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

709

Hierarchical Semantics of Modelica

Thus it is necessary to restrict the computation of references in a way that guarantees termination and retains
a valid result for a meaningful subset of the terminating
nodes. It is hardly constructive to reject all recursive relations between classes, as for instance recursive functions
would fall under the same rule (functions are specialized
classes in Modelica). Instead, the restriction should only
prevent divergence during lookup. This can be achieved by
only attempting to evaluate an hierarchical reference once
for any given environment.
We assume that each literal class is labeled with a unique
identifier from a set L  N. We write F i to indicate a
class with id i. The syntactic depth of a literal class is
the number of syntactically visible enclosing classes. It
is easy to see that this number is invariant during evaluation (otherwise, special variables might be invalidated).
Each node is only valid when it has precisely the correct
amount of enclosing classes for its literal class. A node
that fulfills this requirement is called context correct. The
set of context correct nodes is not finite, though. Consider two distinct literal classes F 1 and F 2 with depths 0
and 1, then {|F 2 in {|F 1 in |}|} is context correct.
But so is {|F 2 in {|F 2 in {|F 1 in |}|}|} and so
on. Obviously, hierarchies with the repeated occurance of
the same literal class are problematic. It is thus necessary
to find a syntactic criterion to rule out such strange loops.
The directed graphs used in Section 4 can be formalized
as directed multigraphs (V, E) with vertices V  L represented by the labels of literal classes and edges as triples
of one outgoing and one incoming vertex together with a
natural number E  L  L  N. The identity of an edge is
defined by its source, its destination and its number. The
usual terms from (multi) graph theory (reachability, cycles,
etc.) apply.
Definition 1 (Graph Representation of Nodes and Environments). The directed multigraph of a node is the vertex labeled with the literal class of the node linked to the
graphs of all parents by ordered edges. The graph of an
environment (i.e. a list of nodes) is the union of the graphs
of each node (where the union of graphs is the union of
their components).


J{|F u in  |}Kgr = ({ u } V, P  E)
where

P





= { (u, pi , i) | pi = Ji KL }


(V, E) =

[

i1...| |

into a node, when the outgoing edges of a each node are
labeled consecutively with the numbers ranging from 1 to
the depth of the corresponding literal class. Such a graph is
said to be context correct. This transformation is bijective.
Definition 2 (Admissible Lookups). A node is admissible, iff its graph representation is a context correct, rooted
multigraph. An environment  is admissable, iff all contained nodes are admissable and the lookup of a label
L in an environment is admissible iff the environment is
admissible:

 admissible  J Kgr is rooted and context correct
 admissible  i  1 . . . | | i admissible
h ::   Li admissible   admissible   admissible
If all nodes are rejected that do not meet these simple
criteria, the set of admissible nodes is finite. This allows to
evaluate any hierarchical term without in a finite amount
of steps (by checking for repetitions). As a side effect,
all strange loops (i.e. classes that contain themselves) are
ruled out, but classes that merely refer to each other are
still allowed.
Lemma 1 (Finiteness of Admissible Lookups). For any
given finite labeling of literal classes, and a finite maximal depth of classes the set of admissible lookups is finite.
admissable nodes is finite.
Proof. Admissible nodes are finite due to their injective
mapping to a context correct, rooted multigraph over the
(finite) labeled vertices. Admissible (finite) environments
and lookups are products of finite sets.
Evaluation of hierarchical terms can be implemented in
a terminating, total function H. This function follows the
definition of h by construction. The sole difference lies in
the memory G, a set of admissible lookups. No lookup
is ever repeated, hence the function terminates.
= 

JG, {|h with F2 |}KH

= {|F 3 in  |}

JG, {|F|}KH



= {|F in |}




JG, hKH = {|F1 in  |}

if

dom(F 2 )  dom(F 1 )

Ji Kgr

JG, h1 .super(h2 ).LKH
The set of possible results of this transformation is finite,
if
when both the set of labels and edges are finite. Both
conditions are trivially fulfilled by graphs created from
context correct nodes, since each node is in itself a finite
structure, the syntactic depth of each node is limited by the
syntactic structure of the source program, and each source
program is labeled by a finite set of labels.
Multigraphs that do not contain any cycles and have a
distinguished root node can be unambiguously transformed JG, hKH
710



JG,  KH





JF 3 K = JF 1 K  JF 2 K

= JG0 , J1 ,  , hL K KH


JG, h1 KH = 1


JG, h2 KH = {|F in  |}

L 7 hL  JF K
h1 ::   Li admissible 
/G


G0 = G  {h1 ::   Li}


=

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

in any other case
DOI
10.3384/ecp17132703

Session 10B: Modelica Language & Tools

5.2 Lookup of References

as functions, since MCL does not allow for any other recursive definitions. This is easily achieved by wrapping them
into a thunk (a function taking an unused argument).
Function C maps each found definition to a structurally
similar term where all references are replaced with their
corresponding name. It is assumed that the lookup result is
arbitrarily ordered.

The definition of H immediately yields an algorithm for the
lookup of references, L. A lookup is successful if both the
super class and the base class can be evaluated successfully,
the resulting environment is admissable and it contains a
matching element. The result of a successful lookup maps
the environment and looked up label to the folded result
term. An error is indicated by the mark .
Definition 3 (Transformation). The transformation replaces all references with a recursive function that is ob
tained by the lookup closure of its definition. The closure
Jh1 .super(h2 ).l KL = h1 ::   li 7 J1 ,  ,t K
replaces each references with the name of its definition.

if
J0,
/ h1 KH = 1


J0,
/ h2 KH = {|F in  |}
l 7 t  JF K



=

JrKL




JR, [ 7 r]t KC = [ 7 xi 0]JR,t KC

otherwise







JRKG =







if [ 7 r]s  img(R) s.t. JrKL =


R  { JrK | [ 7 r]s  img(R) }
L

otherwise

The exhaustive search terminates, when a fixed point is
reached. This is guaranteed due to the finite set of admissible environments. G is also inflationary. This guarantees
the existence of the conditional fixed point starting from a
set R (see Pepper and Hofstedt 2006, chapter 10).
Lemma 2 (Fixed Point of G). The ascending Kleene chain
of G has a least fixed point.
Proof. The partial functions (and error marker) obtained
by G form a complete partial order (cpo) under the subset
relation, i.e. R1  R2  R1  R2 with as top element,
i.e. R  , because the set of admissible environments (the
domain of each R) is finite and adding a top element to
a cpo yields a cpo. Function G is also Scott-continuous
(the least upper bound of any chain is the set-union in the
absence of errors and the error otherwise).

5.3 Transformation



R = { L1 7 t1 , . . . , Ln 7 tn }

where

JrKL = Li 7 ti
{ x1 . . . xn } fresh in img(R)

This allows to to lookup all references in a term, including those references that occur transitively as the result of JRK
C
a successful lookup. Such an exhaustive search is achieved
by repeated applications of a one-step search function G to
an intermediate result set R:
Jt K

J KG =

if r 
/t

= t

JR,t KC



= { xi 7  y.ti | ti  img(R), y 
/ Jti Kfv }


if r 
/t

= t

J[ 7 r]sK
if



= [ 
7 (fix xr in FR ) 0]JsK


JFR K = JRKC


JRKG = R

and



R = J{ h ::   li 7 t }KGn

and



and

J[ 7 r]sK



=

JrKL = h1 ::  1  l1 i 7 t1

otherwise

5.4 Example
Our running example can be encoded in MCL as root .D.x.
For this term, the exhaustive lookup yields the result:


R={
hD :: Eroot  xi 7 JD , Eroot , this.A.xK ,
hA :: ES  xi 7 JA , ES , up(2).y + up(1).zK ,
hC :: Eroot  yi 7 JC , Eroot , this.B.zK ,
hD :: Eroot  zi 7 JD , Eroot , 2K ,
hB :: EC  zi 7 JB , Ec , 21K }
After closing this complete result, the translation yields:
(x0 in fix

A reference must be evaluated in order to look up its correx0 = y. (x1 0) ;
sponding definition. This does not introduce any errors, if
x1 = y. (x2 0) + (x3 0) ;
the underlying search result is indeed a fixed point, though
x2 = y. (x4 0) ;
(as all contained references have already been evaluated at
x3 = y. 2 ;
least one). The definition of a reference might (after sevx4 = y. 23 ;
eral steps of lookup) depend on the reference itself. This ) 0
implicit recursion has to be transformed into a proper fixed
point. In order to do so, all definitions have to be regarded This term then evaluates to 23, as expected.
DOI
10.3384/ecp17132703

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

711

Hierarchical Semantics of Modelica

5.5 Correctness
The correctness of  depends on the closure of a term by
a complete lookup result. The most important step is an
observation about a symmetry between the evaluation of a
term containing hierarchical references and that of a fixed
point constructed from the lookup result R of that term:
Both evaluations only differ in the presence or absence of
rule S ELECT, which is replaced by specific instances of
F IX A PP (with a group of recursive definitions generated
from R).
Lemma 3 (Correctness of C). The closure of a complete
lookup result is equivalent to the lookup of references.




When R is complete, i.e. JRKG = R 6= , a term t appears on the image of R, i.e. h ::   li 7 [ 7 t]s  R,
and t evaluates with n applications of rule S ELECT, i.e.
J ,  ,t K nS ELECT Then the application of R as a fixed
point evaluates to an equivalent result n applications of
rule F IX A PP to R:
[JRK C ]JR,t KC nF IX A PPR JR, vKC
Proof. By natural induction over n. The base step (n =
0) follows by a straightforward induction over , since
S ELECT is not applied in the derivation. The inductive step

also requires a nested induction over . In the case of t = r,
the completeness of R is used to apply one step of rule
F IX A PP (and thus the outer induction hypothesis).

nor redeclarations and is considerably outdated when it
comes to modern Modelica. Satabin et al. (2015) use a
style comparable to ours, but favor a global environment
(called class table) over our substitution based approach.
Interestingly, they also notice the difficulty to separate the
static semantics of a model from its dynamics, but solve
this problem by restricting their input language. In particular, no short class definitions or redeclarations are considered. It is also somewhat unclear if their approach allows
for the late binding of modifications. Despite these differences, the presented techique may solve the open question
of how to obtain the values for our special variables in the
first place.

6.2 Conclusion
The definition of Modelicas hierarchical elements by special variables allows to express their static semantics. Treating classes and their interactions like modules with open
recursion allows for a precise reasoning of the outcome of
redeclarations and modifications. Last but not least, the
difficulties that come with the uniform treatment of classes
and components are now obvious and might have an influence on the design of future versions of Modelica. The
correct translation of hierarchical references in a terminating process while maintaining the semantics of inheritance,
modifications and redeclarations is a feature that, to our
knowledge, has not been solved before. It allows a clear
separation between the static and dynamic semantics of
names in Modelica.

References

The correctness of the overall transformation is defined
as the preservation of the semantics of the transformed Aldrich, Jonathan and Kevin Donnelly (2004). Selective
open recursion: Modular reasoning about components
term: When a term evaluates and the transformation yields
and inheritance. In: SAVCBS 2004 Specification and
no error, then the transformed term yields a value that is
Verification of Component-Based Systems, p. 26.
equal to the transformation of the original result.
Theorem 4 (Correctness of ). The transformation  pre- Hger, Christoph (2016). Modeling with monads: extensible modeling semantics as syntactic sugar. In: Proserves the semantics of terms.
ceedings of the 7th International Workshop on Equation
Based
Object-Oriented Modeling Languages and Tools.
t  v  Jt K = s = s  JvK
ACM, pp. 1524.

Kgedal, David (1998). A Natural Semantics specification
Proof. By induction over t. The fundamental case is t = r.
for the equation-based modeling language Modelica.

By construction of , JrKL = h ::   li 7 J ,  , sK 
In: LiTH-IDA-Ex-98/48, Linkping University, Sweden.
R. Inversion of the evaluation yields J ,  , sK  v. The
Kahn, Gilles (1987). Natural semantics. In: Annual Symconclusion then follows via rule F IX A PP and Lemma 3.
posium on Theoretical Aspects of Computer Science.
Springer, pp. 2239.
Pepper, Peter and Petra Hofstedt (2006). Funktionale Pro6 Discussion
grammierung  Sprachdesign und Programmiertechnik.
Springer.
We have given a definition of an explicit, contextPierce,
Benjamin C., ed. (2005). Advanced Topis in Types
independent syntax and semantics for the lookup of names
and
Programming
Languages. MIT Press.
in Modelica classes. Classes (hierarchical terms) can be
Satabin,
Lucas
et
al.
(2015).
Towards a formalized Modtranslated by a terminating evaluation of all references.
elica
subset.
In:
Proceedings
of the 11th International
This translation maintains the original semantics.
Modelica Conference, Versailles, France, September 216.1 Related Work
23, 2015. 118. Linkping University Electronic Press,
pp. 637646.
The semantics of Modelica has been subject to surprisingly
little research. The work of Kgedal (1998), has a much
broader scope. It does however not discuss open recursion
712

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132703

Towards a Standard-Conform, Platform-Generic and Feature-Rich
Modelica Device Drivers Library
Bernhard Thiele1

Thomas Beutlich2

Volker Waurich3

Martin Sjlund1

Tobias Bellmann4

1 PELAB,

Linkping University, Sweden, {bernhard.thiele,martin.sjolund}@liu.se
2 ESI ITI GmbH, Germany, thomas.beutlich@esi-group.com
3 Chair of Construction Machinery, TU Dresden, Germany, volker.waurich@tu-dresden.de
4 Institute of System Dynamics and Control, DLR, Germany, tobias.bellmann@dlr.de

Abstract
There are many cases where simulation applications need
to interact with their environment. Typical examples are
Human-in-the-Loop (HITL) simulators (including flight,
driving, and marine training simulators), Hardware-inthe-Loop (HIL) simulators, but also offline process simulators which cannot operate in a completely self-contained
manner and therefore need to be coupled to external applications. Embedded control applications are another related area requiring interaction between applications and
their environment. The Modelica_DeviceDrivers library,
which had its first release as open-source library in 2012,
tries to cater to such use cases. This paper describes the
library for the first time and reports about the numerous
challenges that the project experienced to meet its goal of
supporting several platforms and tools within a standardconform, platform-generic, feature-rich, and easy-to-use
Modelica library. Furthermore, the paper gives an insight into the inner mechanics of the librarys communication and serialization functionalities, the various supported
hardware interfaces and the possibilities to generate code
for embedded systems.
Keywords: human-in-the-loop, hardware-in-the-loop,
real-time simulation, embedded control application, Modelica external C

1

Introduction

time simulation and/or model-based development of embedded control applications. Some of these environments
can be coupled with Modelica tools, by wrapping code
that is generated from Modelica tools into respective thirdparty tool-internal representations which can be connected
to hardware devices in the respective development environment. For example, such customized solutions are
available in Dymola1 via its DymolaBlock interface to the
MATLAB/Simulink2 tool chain, OpenModelica3 via customized tool chains (Worschech and Mikelsons, 2012),
or SimulationX4 via Code Export for Simulink/Simulink
Coder2 or HIL environments like dSPACE DS10065 , NI
VeriStand6 or ETAS LABCAR7 (Blochwitz and Beutlich, 2009). Furthermore, it may also be possible for
a Modelica tool to generate Functional Mock-up Units8
(FMUs) which can be imported into compatible simulator
environments (e.g., the dSPACE SCALEXIO5 HIL simulator).
Instead of embedding the (FMI-) compiled Modelica model into a simulator environment, the Modelica_DeviceDrivers (MDD) library uses a different approach. The MDD library provides access to external devices by utilizing Modelicas external function interface
for interfacing to the C API of various device drivers directly from Modelica models (see Section 2).
Historically, the origins of the MDD library can be traced back to the ExternalDevices library (Bellmann, 2009),
an internal DLR9 Modelica library developed for the interactive simulation and visualization of Modelica models. The ExternalDevices library already supported UDP
and shared memory communication as well as several

The most common usage of Modelica models is for offline simulation experiments. However, in many cases simulations need to interact with their environment or other
software components. Typical examples are Human-inthe-Loop (HITL) simulators (including flight, driving, and
1 Dassault Systmes, https://www.3ds.com
marine training simulators), Hardware-in-the-Loop (HIL)
2 The MathWorks, https://mathworks.com
simulators, but also offline process simulators which can3 Open Source Modelica Consortium (OSMC), https://www.
not operate in a completely self-contained manner and the- openmodelica.org
4 SimulationX by ESI, https://www.simulationx.com
refore need to be coupled to external applications. Furt5
hermore, Modelica can be used for developing (modeldSPACE, https://www.dspace.com
6 National Instruments, http://www.ni.com
based) control applications that also require interaction
7 ETAS, http://www.etas.com
with their environment.
8 FMI development group, https://www.fmi-standard.
There are different approaches for enabling the above- org
9 Deutsches Zentrum fr Luft- und Raumfahrt (DLR), German Aementioned applications in the context of Modelica. Several development environments offer tool chains for real- rospace Center, http://dlr.de
DOI
10.3384/ecp17132713

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

713

Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library

input devices (keyboard, 3Dconnexion SpaceMouse10 ,
and game controller). Additionally, it featured a modelintegrated real-time visualization system, the foundation
of the later DLR Visualization library (Hellerer et al.,
2014).
However, the ExternalDevices library only supported Microsoft Windows and was developed and tested
using only the Dymola tool, which caused unintentional incompatibilities with other Modelica tools. In the
further course of development, it was decided to split
the ExternalDevices library into the commercial DLR
Visualization library and an open-source cross-platform
hardware interface library, the Modelica_DeviceDrivers
library.
The library is available from its GitHub
project site at https://github.com/modelica/
Modelica_DeviceDrivers/. This paper is based on
MDD v1.5.0.

Block Layer
Blocks

ClockedBlocks

Drag & Drop blocks using
traditional when sample() then
style for calls to the Function
Layer.
- Blocks.Examples:
Executable examples

Drag & Drop blocks using the
Synchronous Language Elements
extension of Modelica 3.3 for calls
to the Function Layer.
- ClockedBlocks.Examples:
Executable examples

Function Layer

Modelica (external C) functions grouped into following packages:
- Packaging (packaging data for the communication devices)
- Communication (UDP, shared memory, etc.)
- HardwareIO (data acquisition)
- InputDevices (keyboard, joystick, etc.)
- OperatingSystem (real-time synchronization, etc)

C-Code Layer

The glue C-code interfaced by the External C-Function Layer.
Contains the operating system specic C-code. The C-code is
available within the Resource folder of this library.
Windows

Linux

Other

Figure 1. MDD layered architecture.

2

Modelica_DeviceDrivers

The MDD library allows Modelica models to access hardware devices by using the Modelica external C interface
calling the appropriate C driver functions provided by the
underlying operating system (see Section 2.1).
The library is organized in several layers as indicated
in Figure 1. It provides two high-level drag & drop block
interfaces.
1. The Blocks components are compatible to Modelica v3.2, using when sample() for periodically
calling Modelica functions from the Function Layer.

#if defined(_MSC_VER) || defined(__CYGWIN__
) || defined(__MINGW32__)
#include <windows.h>
/* Windows specific code goes here */
#elif defined(__linux__)
#include <unistd.h>
/* Linux specific code goes here */
#else
#error "Modelica_DeviceDrivers: Unsupported
compiler or platform"
#endif

2. The ClockedBlocks components use the synchronous language elements extension introduced in
Modelica v3.3 and are compatible with the Modelica_Synchronous library (Otter et al., 2012). Due
to this support, the MDD library formally depends
on the Modelica_Synchronous library, but in practice
the Modelica_Synchronous library (and tool support
for the synchronous language elements extension) is
only required for this ClockedBlocks interface.

2.2

When accessing hardware devices, a Modelica model
or application calls Modelica functions from the Function
Layer (see Figure 1). These Modelica functions provide a generic interface to the underlying C Code Layer,
which is accessed by Modelicas external function interface. The platform differentiation is handled in the C
Code Layer which uses preprocessor directives for conditional inclusion/exclusion of platform-specific code (#if,
#else, #endif, etc.) similar to the code fragment below.

2.3

Extended Tool Support

Back in 2009, the library was developed using the Dymola
tool. With MDD v1.4.0, considerable development efforts
have been spent on the Modelica compliance of the library
in order to better support SimulationX and OpenModelica.
Since OpenModelica v1.11.0 Beta 1 the MDD
SerialPackager blocks as well as the Communication
blocks are finally supported by OpenModelica. For achieving this, it was necessary to change parts of the MDD
library (under the constraint of maintaining backwards
2.1 Cross-Platform Support
compatibility), and at the same time, to extend the abiAs of MDD v1.5.0, Windows and Linux are supported as lities of respective tools (partly by providing support for
main platforms, but prototypical work also targets popular non-standard Modelica constructs). This is discussed in
more detail in Section 3.2.3.
embedded systems boards directly (see Section 4.2).

10 3Dconnexion,

714

https://3dconnexion.com

Library Structure

Figure 2 shows a screenshot of the package browser view with loaded MDD library. The first two
sub-packages Blocks and ClockedBlocks provide the
drag & drop blocks which correspond to the Block
Layer of Figure 1. The remaining sub-packages (except Utilities and EmbeddedTargets) provide the
Function Layer. Both layers use sub-packages for subdividing the provided functionality into different groups.
Package EmbeddedTargets contains highly target speci-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132713

Session 10B: Modelica Language & Tools

fic function and blocks for supporting restricted embedded
systems like the Arduino microcontroller (see Section 4).

Figure 2. MDD library structure.

Furthermore, Figure 2 gives an indication about the relation between the Block Layer and the Function Layer.
Typically, a device driver block will instantiate the corresponding external object from the Function Layer. Modelicas external objects allow external functions to access
the internal memory (created by the constructor) between calls to external functions, i.e., the device handlers are maintained in memory in order to access them
in subsequent simulation phases. Modelica also guarantees that both the constructor and destructor functions of an external object are called exactly once, enabling a reliable one-time initialization and termination of
hardware devices, usually during the initialization and termination phase of the Modelica simulation model, respectively. For example, the JoystickInput block creates an instance of the external object GameController.
The package GameController_ collects functions that
can operate on external objects of type GameController.
This package provides the function getData, which takes
a GameController object as argument and returns the values of the axes and buttons of its associated hardware device.
A good way of learning how to use the Block Layer
interface of the library is by exploring the Examples
package. Care has been taken to provide self-explanatory
usage examples for the provided device driver blocks.

2.4

Interfaces

MDD library functionality can be accessed by drag &
drop of blocks from the Blocks and ClockedBlocks subpackages, or by direct calls to the underlying functions.
An example, which directly uses the Function Layer
for accessing a game controller, is given below:
DOI
10.3384/ecp17132713

model GameControllerExample
import
Modelica_DeviceDrivers.InputDevices.*;
parameter Integer id = 0 "0 = first
attached game controller";
GameController gc = GameController(id);
discrete Real axesRaw[6];
Integer buttons[32], pOV;
equation
when sample(0, 0.1) then
(axesRaw, buttons, pOV) =
GameController_.getData(gc);
end when;
end GameControllerExample;

The code above creates an external object named gc. The
constructor for this object takes the argument id. This argument allows specifying which controller to use if several game controllers are attached to the system. The
function getData is called periodically within a whenclause. It takes the external object gc as argument and
returns vectors which contain the values read from the associated game controller. The vector is pre-dimensioned,
so that it can attune to controllers featuring as much as six
axes, 32 buttons and a POV (point of view) switch. The
actually available data depends on the connected game
controller hardware. Tests with the actual hardware are
needed for determining which vector entry corresponds to
which physical axis or button.
Figure 3 shows how game controllers can be accessed by simply dragging & dropping a JoystickInput
block into the diagram view of a Modelica tool. While
Figure 3a uses the block found in the Blocks package,
Figure 3b uses the corresponding clocked variant from
ClockedBlocks. The additional blocks periodicClock
and assignClock are from the Modelica_Synchronous library. They associate a periodic clock to the variables and
equations within the JoystickInput block. As a result,
the underlying getData function will be called whenever
the associated clock ticks (i.e., every 0.1 s in the presented
example).

(a) Using Blocks

(b) Using ClockedBlocks

Figure 3.
Accessing game controller devices by using
the JoystickInput block from the Blocks, or the
ClockedBlocks package.

The example models can be simulated, but real-time synchronization is required to slow the simulation speed

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

715

Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library

MDD v1.3 (Linux) and v1.4.0 (Windows). A client block
for TCP/IP socket communication was added in v1.4.0
(Windows) and v1.5.0 (Linux). Furthermore, support for
sending and receiving of Lightweight Communications
and Marshalling (LCM) datagrams12 was added in v1.5.0.
LCM is a set of libraries and tools for message passing and
data marshalling13 , which is particularly targeted at low2.5 Features
latency real-time applications for robotic systems (Huang
The MDD library has grown to support a respectable et al., 2010).
Basic support for the Controller Area Network bus
amount of hardware devices and associated features that
(CAN bus) is available by two different block sets. The
will be briefly presented in this section.
first is based on the CAN Layer2 API from Softing14 and
2.5.1 Input Devices
restricted to the Windows platform. The second uses the
Standard input devices such as keyboard and game con- SocketCAN interface provided by the Linux kernel.
trollers are ubiquitously available on the market, enabling
Packaging Concept Communication devices like UDP
the user to build up interactive simulations quickly. MDD
or shared memory use a common packaging concept in
provides blocks for using the generic keyboard and game
order to send or receive data. Therefore, the same packcontroller interface of Windows or Linux (see Figure 4).
ager can be used with different communication devices.
Figure 6 shows an example in which a package consisting of three variables of type Real followed by a variable of type Integer is either transmitted using shared
memory or UDP blocks. Switching between the two communication devices is achieved by simply replacing the
corresponding device block.
down, in order to synchronize the real-time inputs with
the simulation progress. The MDD library provides convenient support for (soft) real-time synchronization11 . However, a user should consider that Modelica tools might
provide better (tool-specific) options for real-time synchronization.

Figure 4. Supported input devices from the Blocks package.

In addtion, more specialized hardware like the 3Dconnexion SpaceMouse is supported for both platforms. Often,
these blocks will be used for interactive desktop simulations, but they can also become part of more involved (costefficient) HITL simulation scenarios.
2.5.2

Communication

The most comprehensive and complex part of the library
is related to implementing support for communication devices in Modelica and external C code.
Supported Devices
supported devices.

Figure 5 gives an overview over the

Figure 6. Simple switching of communication devices due to
common packaging concept in order to send or receive data.

The packages are constructed by using blocks from the
Packaging sub-package (see Figure 2). In the initial
design of MDD, it was expected that different packaging concepts would be supported which share a common connector interface. However, as of MDD v1.5.0
Figure 5. Supported communication devices from the Blocks the SerialPackager is the only available packager. It
allows periodically adding or retrieving fixed size vectors
package.
to or from a package, respectively. Figure 7 shows the
Cross-platform support for UDP and shared memory was available blocks for serializing Modelica variables of the
12 LCM project, https://lcm-proj.github.io
already available in the first released version of MDD.
13 As of MDD v1.5.0, only the communications aspect of LCM is
Support for serial port communication is available since
11 See

716

documentation to block SynchronizeRealtime.

considered.
14 Softing, http://industrial.softing.com

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132713

Session 10B: Modelica Language & Tools

predefined types Boolean, Integer, Real and String
into a package. The type Real can be packed either
as double-precision or (using a C static cast) as singleprecision floating-point number.

wever, the main use-case for the SerialPackager concept is periodically sent, structurally static data. These restrictions may be relieved in future versions of the MDD
library by providing alternative, well-established Packagers that offer support for more flexible means of packaging data, e.g., the data marshalling of the LCM library
or the efficient binary serialization format of the MessagePack library15 .
Finally, it turned out that the SerialPackager blocks
were a major hurdle for extending the number of Modelica
tools which support MDD (see Section 3.2).
2.5.3

Figure 7. SerialPackager blocks for adding variables to a
package.

At the C side, a package is a C byte array in which C variables with respectively indicated types are simply successively appended in a data-flow prescribed order. For example, in Figure 6 the resulting byte array starts with three
double values (3  8 bytes) followed by one int32 value
(4 bytes), resulting in a byte array of size 28. For the sake
of providing an illustrative example at the C language level the following C code snippet constructs a structurally
equal package named data (the example shall shed light
on the concept, it does not advocate a coding style using
magic numbers for array offsets):
double v1[3] = {1.1, 2.2, 3.3};
int v2 = 4;
unsigned char* data = (unsigned char*)
calloc(28, sizeof(unsigned char));
memcpy(&data[0], &v1[0], sizeof(v1));
memcpy(&data[24], &v2, sizeof(v2));

Figure 7 shows the blocks for adding variables to a
package, symmetrically, blocks are available for retrieving
variables from a package. Using these blocks is deemed
to be rather intuitive with the notable exception of the
packInt block. This block allows packing unsigned integer values at the bit level. The number of bits used for
encoding is set by a parameter width, therefore the maximum value of the integer signal that can be encoded is
2width  1. A parameter bitOffset allows to specify the
bit at which the encoding starts relative to the preceding
block. Since MDD v1.3 most blocks support specifying
the byte ordering (big-endian or little-endian format).
It is simple to use the SerialPackager blocks for deserializing data which has been serialized by it (see Figure 6). In practice, however, communication typically
needs to be established with a remote station that is unrelated to the Modelica model. As long as this remote
station periodically sends or receives structurally static,
fixed sized packages, it is usually quite convenient to establish a communication using the MDD blocks. If the
remote station uses a more dynamic protocol, it becomes
more difficult. In some cases using the Function Layer directly (instead of the Block Layer) can provide additional
flexibility for coping with more dynamic protocols. HoDOI
10.3384/ecp17132713

Hardware I/O

Package HardwareIO (see Figure 2) is intended for data
acquisition hardware like digital-analog converter (DAC),
analog-digital converter (ADC) and other interface hardware. As of MDD v1.5.0, it contains only one subpackage, which provides support for the Linux control and
measurement device interface Comedi. The Comedi
project develops open-source drivers, tools, and libraries
for data acquisition16 . The project provides a common interface for accessing supported data acquisition hardware
(see the website for supported hardware). The MDD library implements an interface to the Comedi user-space
library.
Figure 8 shows an example model, which uses the available blocks. Configuration of the device is performed
in the Modelica record named comedi. The record contains an external object dh of type ComediConfig which
contains the Comedi device handle and is passed through
a parameter to the other blocks (comedi.dh). Using
external objects in records is not standard-compliant to
Modelica v3.3 revision 1 (Modelica Association, 2014),
which is further discussed in Section 3.3.

Figure 8. Accessing data acquisition hardware via the Linux
control and measurement device interface Comedi.

Writing or reading raw integer values to DAC or from
ADC channels is provided by the blocks DataWrite
15 MessagePack
16 Comedi

project, https://msgpack.org
project, http://comedi.org

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

717

Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library

or DataRead, respectively. These blocks have each
annotation(__ModelicaAssociation_Impure=
true);
a variant which works with physical values, instead
of the raw integer values (PhysicalDataWrite and end getKey;
PhysicalDataRead). Blocks DIOWrite and DIORead
A Modelica tool will map this information to compilersupport digital input and output (DIO) channels.
and linker-dependent directives and thereby select the libraries that fit best for the respective platform.
2.5.4 Embedded Targets
MDD v1.5.0 introduced the new top-level package
EmbeddedTargets. The package is intended for platformspecific targets, such as microcontrollers, that cannot so
easily share code with other devices due to memory or
hardware limitations. There exists first prototypical support for the Atmel17 AVR family of microcontrollers. A
prototype application is described in Section 4.2.

3.1.1 Linking Platform-Dependent System Libraries

Having platform-specific system libraries like X11 (for Linux only) and User32 (for Windows only) in one generic
Library annotation, proofed to be a significant development difficulty. As a remedy, dummy libraries of the Linux system libraries are provided in the Windows-specific
library directories win32 and win64, and vice versa. Furthermore, the linking to system libraries on Windows was
3 Modelica Standard-Compliance
simplified by the introduction of compiler-specific pragUsing a Modelica library-based approach for accessing mas, e.g., in MDDKeyboard.h
hardware devices from a simulation started as an experiment, which relied on the Dymola tool and its support #pragma comment( lib, "User32.lib" )
for interfacing external C code. However, when trying to understood by the Visual Studio compilers only. Howeextend the number of Modelica tools supporting the MDD ver, for GCC (including the MinGW and CygWin build
library, it became apparent that quite a few constructs that environments) the issue remains unresolved18 .
were useful and appreciated by the initial authors of the
library were not supported by other tools and were partly 3.1.2 Impure Functions
problematic in respect of compliance to the Modelica stan- The above example function getKey features an addard.
ditional (vendor-neutral) annotation which declares the
On one hand, this section reports on important develop- function as impure. The intended meaning is that a
ment efforts (starting with MDD v1.4.0) that have been tool may not expect that the function returns the same
spent on the Modelica compliance of the library for better output for the same input, which is the typical case for
supporting SimulationX and OpenModelica, and on the MDD functions that read values from external devices.
other hand it addresses open issues which may be of in- Indeed, Modelica v3.3 introduced the dedicated keyword
terest for future improvements to the Modelica standard, impure to cater for such cases. However, since not all
or which may require possibly non-backwards compatible Modelica tools support this keyword, yet, the MDD lirevisions of the MDD library for achieving full Modelica brary uses the Impure annotation which is understood by
compliance.
Dymola, OpenModelica and SimulationX.

3.1

Modelicas External Function Interface

3.1.3 Modelica Standard Improvements
As the Modelica standard specification on the external Future releases of MDD may benefit from improvements
function interface improved over the years, standard- on the external function interface, which are expected in
conform libraries with external C code dependencies the (future) Modelica v3.4 standard:
could be created in a more satisfying way. For example,
Modelica v3.2 standardized the search directory structure
 Compiler-specific sub-directories for the platformfor the external C header files and libraries (Modelica Asspecific library directories, e.g., if Visual Studio 2015
sociation, 2010, p. 153). Having a standardized directory
is used as a Windows 64-bit compiler a Modelica tool
structure facilitated creating cross-platform libraries with
may first search directory win64/vs2015 for depenexternal C library dependencies. For example, the Modent libraries19 .
delica code snippet below declares an include dependency
to the header file MDDKeyboard.h and linker dependen The IncludeDirectory annotation accepts multiple
cies to the libraries X11 and User32:
directories enabling a more convenient way to spefunction getKey
cify several external C header file dependencies disinput Integer keyCode "Key code";
tributed over different include directories20 .
output Integer keyState "Key state";
external "C" MDD_keyboardGetKey(keyCode,
keyState) annotation(
Include = "#include \"MDDKeyboard.h\"",
Library = {"X11", "User32"});
17 Atmel,

718

http://atmel.com

18 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/1668
19 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/1316
20 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/2103

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132713

Session 10B: Modelica Language & Tools

However, a generalized build process18 of the external
code still misses the definition and (future) standardization
of build features such as compilation of several C source
modules, compiler flags (CFLAGS) or preprocessor defines
(CPPFLAGS)21 .

3.2

The Serial Packager

pkgOut.dummy = addInteger(pkgOut.pkg,
u, pkgIn.dummy);
end when;
pkgOut.pkg = pkgIn.pkg;
pkgOut.trigger = pkgIn.trigger;
pkgOut.backwardTrigger =
pkgIn.backwardTrigger;
pkgOut.userPkgBitSize =
pkgIn.userPkgBitSize;
end AddInteger;

The SerialPackager blocks are the core elements of
the block-based communication support provided by the
MDD library (see Section 2.5.2). They use a rather intri- The instantaneous equation invoking the addInteger
cate approach for propagating a package between con- function is activated by the event trigger which is pronected blocks.
pagated through the connected packager blocks. The
dummy variables are used to establish data-flow depen3.2.1 Connector Definition
dencies which ensure that the addValue functions of
The definition of the SerialPackager input connector is
connected blocks are invoked in the correct order. The
given below.
backwardTrigger event allows propagating a triggeconnector PackageIn "Packager input
ring event in the inverse connector direction. Its supconnector"
porting logic is omitted here for brevity. A Modelica
input SerialPackager pkg;
standard-conform alternative is provided by the variable
input Boolean trigger;
userPkgBitSize that allows propagating a user defined
input Real dummy;
package size, i.e., it is possible for a user to customize
output Boolean backwardTrigger;
the package size of the external data buffer of the commuoutput Integer userPkgBitSize;
output Integer autoPkgBitSize;
nication device block (see Section 2.5.2). However, in the
end PackageIn;
default setting the necessary package size is deduced autoThe definition of the output connector is similar, but with matically with the help of the autoPkgBitSize variable.
reversed input and output causalities. Most notably con- This approach is described in Section 3.2.4.
nector PackageIn contains an element pkg, which is an
external object of type SerialPackager. This external
object is passed between connected blocks (see Figure 6).
Within an add or get block the passed in external object is used as an argument to external functions which
first add or retrieve data from the package and then pass it
on to the next block.
Due to the design of the SerialPackager connector
sharing both input and output variables it is impossible
to have more than one connect equation per connector.
However, Modelica offers no option to tell a user already
at modeling time about this maximal allowed connector
cardinality.

3.2.3 External Object Aliasing

A problem with the Block Layer of the SerialPackager
is that the pkg objects within the connectors are not explicitly created by calling an external object constructor
function as required in Modelica v3.3 (Modelica Association, 2014, p. 165). Instead, they rely on aliasing through
(connect) equations to access an external object which has
been created at another place. In Figure 6 the pkg object
for the add blocks is created in the Packager block at
the top of the figure, while the pkg object for the get
blocks is created in the device block for reading from
shared memory (or UDP, respectively). While the concept
of external object aliases does not exist in Modelica v3.3,
3.2.2 Basic Concept
equating two external objects may be interpreted as an asThe following simplified Modelica code snippet illustrates signment to an external object, which is forbidden. The
the basic idea for adding the (Integer) value of an input authors hope that future versions of the Modelica standard
will consider use-cases that the Modelica tools Dymola,
variable u to a package:
OpenModelica and SimulationX already support22 .
block AddInteger
A Modelica standard-conform implementation that
PackageIn pkgIn "Input connector";
avoids
the aliasing is to only rely on the Function Layer
PackageOut pkgOut "Output connector";
provided
by package SerialPackager_.
IntegerInput u "Integer input connector";
equation
when initial() then
pkgIn.autoPkgBitSize =
pkgOut.autoPkgBitSize + 32 /* bit
size of int32 */;
end when;
when pkgIn.trigger then
21 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/2145

DOI
10.3384/ecp17132713

3.2.4 Automatic Buffer Size
The actual creation of the SerialPackager object is performed in the Packager block, or, respectively, in the reading device block (see above). The following simplified
code illustrates the basic concept.
22 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/1669

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

719

Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library

block Packager
PackageOut pkgOut(
pkg = SerialPackager(bufferSize),
dummy(start=0, fixed=true));
Integer bufferSize;
equation
when initial() then
bufferSize =
if pkgOut.userPkgBitSize > 0 then
pkgOut.userPkgBitSize else
pkgOut.autoPkgBitSize;
end when;
end Packager;

The difficulty here is that the bufferSize which is needed as an argument for the external object constructor
SerialPackager(bufferSize) needs to be computed
by solving the initial system of equations. This is not supported by all Modelica tools and its Modelica compliance
was discussed at the Modelica Issue Tracker with a majority opting to clarify the specification in order to forbid
it23 , but on the other hand it was also discussed how the
Modelica standard could be extended to allow it24 .
In the initial version of the MDD library the external
object was actually created within a when-clause, which
was clearly illegal in Modelica v3.3. As part of improving
the Modelica compliance of the library, the creation of the
object was moved into the component declaration.

3.3

3.4

Fixed Attribute of Strings

According to Modelica v3.3 the predefined type String
was designed without the fixed attribute (as opposed
to other predefined types Boolean or Integer). However, such a fixed attribute is particularly relevant for the
GetString block of the SerialPackager when retrieving sampled String data from a package. This issue was
resolved by (future) Modelica v3.4 such that future Modelica tools supporting Modelica v3.4 will no longer raise
a warning on the GetString block25 .

4

Applications

This section describes several applications that were implemented with the help of the MDD library.

4.1

Arduino

The Arduino26 is an open-source electronics platform that
features easy configurations to read the sensors, process
the data and send it to other devices via a serial connection.
Therefore, the Arduino can be utilized to provide sensor
data in a real-time Modelica model by means of the MDD
serial port implementation, as depicted in Figure 9. With
the help of potentiometers or other deflection sensors, customized control devices can be built.

External Objects in Records

The SocketCAN and the Comedi blocks use a Modelica
record as means for specifying general settings for a hardware device. The idea is that the settings are specified
once when creating an instance of the record and this instance is passed as parameter to blocks using this device. Figure 9. Setup to read potentiometer deflection during realFor example, the Comedi configuration record (stripped time simulation with MDD serial port model27 .
from some elements for brevity) is defined as
record ComediConfig
parameter String deviceName =
"/dev/comedi0" "Name of Comedi device";
final parameter Comedi dh =
Comedi(deviceName) "Handle to comedi
device";
end record;

As an exemplary application, self-built pedals for a driving simulator can be equipped with a sensor in order to
measure the displacement. The pedal itself is a steel sheet,
mounted on a revolute joint and a shock spring. The measured deflection is transferred via a serial connection to a
Blocks.Communication.SerialPortReceive in order
to drive a virtual vehicle. Therefore, expensive or unavailable input devices can be substituted by custom constructions. By using a Bluetooth module with Serial Port
Profile (SPP) a wireless connection between Arduino is
handled in the same way as a serial port over USB connection. No further modifications are necessary to implement a wireless control device.

where dh is an external object. It is convenient to collect configuration information in a record, since this allows passing a complete set of related configuration settings at once. The problem here is that passing an external
object as part of a record can be interpreted as the record
returning the object and assigning it to another external
object (which is forbidden in Modelica v3.3 but supported
by Dymola). However, similarly to the external object ali- 4.2 Embedded Control
asing described in Section 3.2.3 it seems highly desirable
to consider use-cases as described above in some way, in The EmbeddedTargets package (see Section 2.5.4) contains blocks and functions to directly control I/O or clocks
future versions of the Modelica standard.
23 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/1907
24 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/2037

720

25 Modelica Issue Tracker, https://trac.modelica.org/
Modelica/ticket/1797
26 Arduino, https://arduino.cc
27 Autodesk screen shots reprinted courtesy of Autodesk, Inc.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132713

Session 10B: Modelica Language & Tools

in the AVR ATmega microcontroller family28 . The advantage of including this code into the MDD library is that it
makes it simple to write a model for a microcontroller that
works the same way in any Modelica tool since all the OS
support, real-time code, etc., is abstracted away. Provided
that the Modelica tool produces minimal C-code (uses minimal features outside of standard C: for example, no linear solver included if the system has no linear systems,
no OS or I/O functions, no threading models, etc.), and the
model itself does not use C-code that the embedded target
cannot support (such as file I/O), the code generator would
work on pretty much any embedded target supporting C.
The Modelica code itself tries to avoid the Integer constants from the data sheets. Instead, enumerations such
as prescaler=1/128 or clock=2B are passed from Modelica and the C code for the AVR target depends on
function inlining in order to remove dead code. For example, the constructor for the clock takes an enumeration
that specifies the clock, which should be manipulated, and
after function inlining, the C code for other clocks is removed. The blocks in the MDD library try to take userfriendly constants such as frequency=100 Hz or period
=0.1 s for real-time synchronization; the Modelica code
then has logic to find good clock prescalers to create a matching frequency. The code does not use parameters since
they cannot be guaranteed to be evaluated in Modelica,
and the C-code depends on the C-compiler (AVR GCC)
being able to inline and eliminate dead code from C-code
such as the constructor. An example of this is the timer
external object in the microcontroller, which becomes one
or two bitset instructions when the function is called with
a constant input:
function constructor "Initialize timer"
input Types.TimerSelect timerSelect;
input Types.TimerPrescaler clockSelect;
input Boolean clearTimerOnMatch;
output Timer timer;
external "C" timer = MDD_avr_timer_init(
timerSelect, clockSelect,
clearTimerOnMatch)
annotation(Include = "#include \"
MDDAVRTimer.h\"");
end constructor;
static inline void* MDD_avr_timer_init(int
timerSelect, int clockSelect, int
clearTimerOnMatch)
{
static const uint8_t
clockSelectTable0[7] = {...},
clockSelectTable1[7] = {...},
clockSelectTable2[7] = {...};
switch (timerSelect) {
#if defined(TCCR0)
case 1: /* Timer 0 */
TCCR0 |= ...;
break;

#elif defined(TCCR0B)
case 1: /* Timer 0 */
TCCR0B |= clockSelectTable0[clockSelect
-1];
TCCR0A |= ...;
break;
#endif
case 2: /* Timer 1 */
...
case 3: /* Timer 2 */
...
default:
exit(1);
}
return (void*)timerSelect;
}

One of the AVR examples included in MDD is the single
board heating system (SBHS29 ), shown in Figure 10.

Figure 10. The single board heater system running a real-time
control algorithm using firmware based on MDD code. There is
a programmer attached to the board to upload new firmware, but
the code runs without any computer connected to the SBHS.

The SBHS consists of a heater assembly, fan, temperature sensor, AVR ATmega16 microcontroller and associated circuitry. It was developed by IIT Bombay and is used
for teaching and learning control systems (Arora et al.,
2010). The MDD SBHS example uses pulse width modulation (PWM) blocks to control the heater and fan, and an
analog-to-digital converter (ADC) block to read the temperature. It combines these elements with a PID controller
with the goal to control the fan such that the temperature
settles at a setpoint of 45 C while a constant voltage feeds
the heater assembly.

4.3

DLR Demonstrators

At the DLR Institute of System Dynamics and Control, several simulator systems utilize the MDD library for intersystem communication and querying of input devices.
The DLR Robotic Motion Simulator (Bellmann et al.,
2011) is a 7-axis driving and flight simulator based on an
industrial robot arm (see Figure 11). The main use of this
motion simulator is the evaluation of input devices such
as side-sticks, steering wheels, pedals, etc., as well as the
test and validation of control algorithms in terms of stability and real-time capability. The control architecture of
the simulator uses blocks from the MDD library in several
28 As of MDD v1.5.0, only ATmega16 and ATmega328P (=Arduino
ways:

Uno) are supported. The code can easily be extended, but requires
checking the data sheets in order to write to the correct bits.

DOI
10.3384/ecp17132713

29 SBHS,

http://sbhs.fossee.in/

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

721

Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library

Figure 12. View into the simulator cabin of the DLR motion
simulator. The instrumentation package is replaceable, so that
the simulator cabin can be easily adapted for different simulation
types, e.g., for driving or flight simulation.

Figure 11. The DLR Robotic Motion Simulator.

 Input devices such as force-feedback steering wheels
are connected via CAN bus and integrated in the software framework via the CAN blocks; the same applies for a force-feedback side-stick.
 Other, consumer based input devices such as pedals
or Airbus styled flight controls are connected via the
JoystickInput block.
 The control architecture for the robot consists of two
Modelica simulations on two different computers:
First, the real-time path planning running on a realtime Linux system controlling the movements of the
robot, and second, the control panel running on a
standard Windows system. The control panel is used
to change parameters such as washout filter modes
(the washout filter maps the movement of road vehicles / airplanes to the workspace of the simulator)
and gives an overview on the actual robots position and telemetry. All real-time critical communication (e.g., the simulated road vehicle / airplane forces
and angular velocities inputs for the real-time pathplanning, or the control panel I/O) are communicated
via the UDP blocks and the serial packaging system.

Figure 13. DLR ROBEX technology demonstrator.

Figure 13 shows the ROBEX demonstrator which was
developed as a technology demonstrator for a science
exhibition. This demonstrator allows the user to command
a rover on a scientific lunar mission. The missions goal
is to pick up a sensor package from a nearby lander and
to place it on a marked position on the lunar surface. The
user controls the rover via an Android App, which runs
on a tablet computer in front of the simulator screen. On
the screen, the visualization of the rover is displayed. The
underlying Modelica simulation performs the multi-body
simulation of the rover and utilizes the DLR Visualization
library to display the rover and the scenery. It uses the
UDP blocks to communicate with the tablet computer and
the SynchronizeRealtime block to adjust the simulation
speed.

Figure 12 shows the inside of the simulator cabin. The
instrumentation package can be adapted for different simulation types or for testing different input concepts. An
on-board computer is used to query input devices, to display information on control screens, and to project the pilots outside view visualization on the embracing concave
dome shell. These tasks are performed using Modelica
In very similar ways, the library is also used in several
models, where the SynchronizeRealtime block is used
for real-time synchronization. In addition, communication other simulator and demonstrator systems, e.g., a drilling
with the other simulation components is performed partly rig training simulator, several desktop flight simulators, or
a rover software-in-the-loop development environment.
via the UDP blocks.
722

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132713

Session 10B: Modelica Language & Tools

5

Outlook

The Modelica_DeviceDrivers library is a tried and tested
library, which can support a wide range of application scenarios. During its development, valuable experience on
interfacing Modelica with external C code has been gained. Thus, the source code can also serve as an example
for anybody who is interested in applications, which require a more complex integration of Modelica code with
external C code.
Considerable development efforts have been spent on
improving the Modelica compliance of the library. Still,
there are open issues and one may see the library as a
testbed, which stresses Modelicas external function interface to the limit. On one hand, experiences gained thereby
can provide inputs for further enhancements to the Modelica standard specification, on the other hand, further
efforts in the library development can improve the level
of standard-compliance. However, since backwards compatibility is a strong objective in the library development,
non-backwards compatible changes for the sake of better
standard-compliance will not be introduced lightly.
Naturally, there is a large pool of conceivable feature
extensions to the library, due to the myriad number of available external devices and communication protocols. A
frequent request is to extend the communication abilities
beyond the capabilities of the available SerialPackager.
There exists a huge choice of data serialization formats
that could be utilized for this purpose (e.g., LCM or MessagePack). Particularly, with regard to the Internet of
Things (IoT) technology becoming more important, improving communication capabilities is a worthy goal. Similarly, supporting embedded systems beyond the prototypical work is very attractive in that perspective.

Acknowledgements

Int. Modelica Conference, Como, Italy, September 2009.
doi:10.3384/ecp09430056.
Tobias Bellmann, Johann Heindl, Matthias Hellerer, Richard
Kuchar, Karan Sharma, and Gerd Hirzinger. The DLR
Robot Motion Simulator Part I: Design and Setup. In
2011 IEEE International Conference on Robotics and Automation (ICRA), pages 46944701. IEEE, May 2011.
doi:10.1109/ICRA.2011.5979913.
Torsten Blochwitz and Thomas Beutlich. Real-Time Simulation of Modelica-based Models. In Francesco Casella, editor,
7th Int. Modelica Conference, Como, Italy, September 2009.
doi:10.3384/ecp09430119.
Matthias Hellerer, Tobias Bellmann, and Florian Schlegel. The
DLR Visualization Library - Recent development and applications. In Hubertus Tummescheit and Karl-Erik rzn, editors, 10th Int. Modelica Conference, Lund, Sweden, March
2014. doi:10.3384/ecp14096899.
Albert S. Huang, Edwin Olson, and David C. Moore. LCM:
Lightweight Communications and Marshalling. In 2010
IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS 2010), pages 40574062, October 2010.
doi:10.1109/IROS.2010.5649358.
Modelica Association.
ModelicaA Unified ObjectOriented Language for Physical Systems Modeling
v3.2. Standard Specification, March 2010. available at
http://www.modelica.org/.
Modelica Association.
ModelicaA Unified ObjectOriented Language for Systems Modeling v3.3 Revision 1. Standard Specification, July 2014. Available at
http://www.modelica.org/.
Martin Otter, Bernhard Thiele, and Hilding Elmqvist. A
Library for Synchronous Control Systems in Modelica.
In Martin Otter and Dirk Zimmer, editors, 9th Int. Modelica Conference, Munich, Germany, September 2012.
doi:10.3384/ecp1207627.

This work has been supported by Vinnova in the ITEA3
OPENCPS projects, and in the RTISIM project. Support
Niklas Worschech and Lars Mikelsons. A Toolchain for
from the Swedish Government has been received from the
Real-Time Simulation using the OpenModelica Compiler.
ELLIIT project, as well as from the European Union in the
In Martin Otter and Dirk Zimmer, editors, 9th Int. MoH2020 INTO-CPS project. The Open Source Modelica
delica Conference, Munich, Germany, September 2012.
Consortium supports the OpenModelica development.
doi:10.3384/ecp12076839.
Finally, the authors would like to thank everybody who
has contributed to the library, either by providing feedback
and suggestions, or by direct contributions to the implementation of the library, particularly, Miguel Neves, Dominik Sommer, Rangarajan Varadan, and Dietmar Winkler.

References
Inderpreet Arora, Kannan M. Moudgalya, and Sachitanand
Malewar. A low cost, open source, single board heater system. In 4th IEEE International Conference on
E-Learning in Industrial Electronics (ICELIE), November
2010. doi:10.1109/ICELIE.2010.5669868.
Tobias Bellmann. Interactive Simulations and advanced Visualization with Modelica. In Francesco Casella, editor, 7th

DOI
10.3384/ecp17132713

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

723

724

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

modelica.university: A Platform for Interactive Modelica
Content
Michael M. Tiller1

Dietmar Winkler2

1 Xogeny,
2 University

USA, michael.tiller@xogeny.com
College of Southeast Norway, dietmar.winkler@usn.no

Abstract
The World Wide Web was conceived of as a medium for
the expression and exploration of scientific and engineering ideas. However, much of the innovation in web technologies is now focused on consumer facing applications.
Although science and engineering content is available on
the web (Wolfram Alpha, 2017), there are not that many
tools that allow engineers and scientists to create and build
scientific and engineering applications.
Fundamentally, HTML and HTTP are certainly sufficient for the creation of scientific and engineering content
just as they are for the creation of online magazines and
websites. But while a number of "content management
systems" have been created to facilitate the publication of
prose, there are very few such tools that cater to making it
easy to create scientific and engineering content.
In this paper, we will present a platform which can be
thought of as a content management system for scientific
and engineering content. We will start by describing what
we believe to be the fundamental requirements for such a
system. From there, we will discuss two different applications built on this platform. The first is an interactive
tutorial for teaching the basics of the Modelica languages
and the other is an example application that involves creating interactive content for use in an engineering course
on hydro-electric power generation. This content will be
published on the modelica.university domain and
we are already collaborating with others to contribute additional content to the site.
Keywords: Modelica, web, cloud, education, content management

1
1.1

Introduction
Background

The initial goal of this project was to recreate a previous
application entitled Tour of Modelica using a newer platform for deploying web-based engineering tools and content. The previous version of the application was written
to provide a tool free experience for learning the basics
of Modelica. Similar efforts involving the OpenModelica
tool OMNotebook have also been undertaken (Palanisamy
et al., 2016).
Because the tutorial was web-based, it could be used
as part of an interactive, introductory tutorial at events
DOI
10.3384/ecp17132725

like the North American Modelica Users Group meetings without requiring participants to install tools. Furthermore, the only prerequisite was a browser. So, the tutorial
was not just tool neutral, but OS neutral as well. During
live events, the tutorial material was used by participants
running Windows, MacOS and even iOS.
However, the tutorial was based on older infrastructure
and the decision was made to upgrade the tutorial. At the
same time, it was also decided to make the underlying platform available for others to create web-based educational
content based on Modelica. The domain name modelica.university was registered for this new site.

1.2

Requirements

The underlying platform was created to support the creation of web-based engineering analysis tools. Many
lessons from the creation of proprietary tools were factored into the design of the infrastructure that supports the
deployment of these applications. In this section, some
high level requirements for the platform (based largely on
the experience of developing earlier tools) will be enumerated.
1.2.1 Hypermedia
The success of the web is, in part, due to the ability of
hypertext to link together content from different sources.
For most users and developers of web content, this is most
typically associated with HTML (W3C, 2016).
However, it should be noted that the concept of hypertext has since been generalized to the more general term
hypermedia. The concept of hypermedia extends the
idea of describing links and relationships not just between
text and content within that text, but to data in general. In
hypermedia, a URL is used to refer to a resource. Those
resources represent data of some kind and may have potentially multiple different potential representations (e.g., an
image resource could be represented as either a JPG or a
GIF image). This modern conception of hypermedia and
the use of hypermedia as an architectural style for building
network based applications was formalized in (Fielding,
2000).
But in order to support this, formats besides HTML
are required. This is because HTML is focused on being a declarative way to represent documents (hence the
presence of elements like <img> (image), <h1> (header)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

725

modelica.university: A Platform for Interactive Modelica Content

and <p> (paragraph). But in order to generalize the
approach to data, a whole range of new formats like
HAL (Kelly, 2016), Collection+JSON (Amundsen, 2013)
and Siren (Swiber, 2016) were developed.
The most essential aspect of these formats is that they
allow generalized data (in most cases serialized as either
XML (Maler et al., 2008) or, more commonly, JSON
(ECMA International, 2011)) to express hypermedia concepts like relationships to other resources and/or actions
that can be performed on these hypermedia resources.
At the dawn of the World Wide Web, hypermedia was
recognized as an essential component for the expression
and exploration of scientific and engineering ideas. Our
experience shows that the power of applying hypermedia
concepts to science and engineering is still not fully realized and our goal was to not only include it as a requirement for managing scientific and engineering content, but
to exploit it even further than most existing platforms.

yond simple static markup requires a wider range of skills.
Unfortunately, people with those skills tend to be drawn
to more consumer oriented projects with the potential
to reach very large markets (social networking, advertising, search engines, games, etc.). As a result, the rate of
innovation and adoption in the engineering sector has traditionally been and continues to be slow.
In order to break this cycle, it is essential to develop
technologies that make it easy to turn people with specialized scientific or engineering skills into content creators.
Of course, this is nothing new. But, again, many of the development resources are focused on empowering broader
sections of society and less on science and engineering.
In reducing the learning curve for non-experts, there are
two important aspects to consider. The first is easing the
creation of content. This means being able to easily make
scientific and engineering content accessible through the
APIs, e.g., connecting the API to existing data sources or
computational capabilities. The other aspect is the visual1.2.2 API
ization of the underlying content in the web browser. For
Nearly all web applications require some kind of API to in- the purposes of this project, we require that both of these
teract with. Generally speaking, the two main functions of are facilitated to some extent.
an API are to provide information and the carry out tasks.
1.2.4 Third Party Tools
The term Command Query Responsibility Segregation
(CQRS) refers to an architectural style where these two re- While modelica.university is being hosted pubsponsibilities are clearly and cleanly delineated (Fowler, licly, the infrastructure it is build on was developed to sup2011).
port proprietary tools and applications. Many of those apAs such, it is no surprise that our API requires both plications are intended to be hosted on private networks. It
of these functions. An API is generally just the mid- is quite common that customers insist that all data remain
dle man between the client (e.g., the web application) on private networks. In those cases, it is impossible to rely
and one or more sources of information leveraged by the on third party services hosted on the public Internet (e.g.,
server (e.g., databases, file systems). The query function- Amazon EC2, Google Cloud Platform, Digital Ocean).
ality allows the web application to request information
So none of the software libraries used by the modelfrom those sources via the API. The command function- ica.university infrastructure rely on services that
ality allows the web application to request tasks to be per- are hosted exclusively on the public Internet. However
formed by the server. The main difference between the the requirement to avoid public services was relaxed for
command and query functionality is that queries are, gen- this project to make deployment easier and more cost eferally speaking, idempotent, i.e., they don not change the fective.
state of the server while the command functionality typically exists solely for the purpose of mutating the server 1.2.5 Job Processing
side state. Furthermore, querying functionality generally In our earlier discussion on APIs, we mentioned the need
relies on caching as an optimization to speed up the fetch- to perform computational tasks. But for scalability reaing of information and to ensure its freshness while com- sons, it is frequently important to delegate these compumands frequently invalidate caches as a result of mutation. tational tasks away from the API server. Without such
For our purposes, we need querying functionality to delegation, the response of the API server itself could be
provide us with text, images, models, simulation results, slowed down considerably by CPU intensive tasks running
etc.. We need the command functionality mainly to re- on the same machine. Furthermore, numerical tools are
quest computational tasks like simulations and optimiza- often written in languages like FORTRAN, C++, Python,
tions to be performed.
Julia, etc., while web servers, databases and other backend services are written in languages like Javascript, Java
1.2.3 Content Creation
and so on. To address both the scalability and interoperA significant impediment to web and cloud adoption in ability, it is often convenient to introduce message queues
the world of science and engineering is the fact that there or worker queues. These provide a way to link together
is not much overlap in technical skills between engineers various services in a scalable way while avoiding the tenand web developers. As such, engineers need to rely on dency toward monolithic architectures. The term miweb developers to help them with creation of web based croservices (Susan Fowler, 2016) refers to an architectools. Of course, HTML is relatively easy. But to move be- tural style which is very much aligned to these require726

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132725

Session 10B: Modelica Language & Tools

ments.

2

Content Management Platform

Now that we have elaborated some of the requirements
for the application, we will quickly review how we have
addressed those requirements in our implementation.

2.1

Backend

The term backend refers to aspects of the application
not handled in the web browser. This includes the web
server that serves the application, databases, authentication, memcache, etc..
2.1.1

API

We start our discussion of the backend with the API itself. For modelica.university, we leverage the
Heisman API framework. Heisman is a proprietary framework developed by Xogeny for creating hypermedia APIs.
The main feature of this framework is the ability to define
so-called resources using an intrinsically hypermediaoriented structure. Once defined, an HTTP based API can
automatically be synthesized for those resources. The emphasis on hypermedia semantics means that resources are
able to easily express not just data about themselves but
also relations to other resources as well as actions that can
be performed by resources.
The fact that an HTTP based API can be automatically
synthesized is important because it avoids having to write
a great deal of boilerplate code to handle pedantic HTTP
specific details like status codes, caching, etags, accept
header processing and so on.
We have taken an API first approach to application
development. As we will discuss shortly, once the resources are defined and the API is automatically generated,
a generic API browsing application is already available for
the API.
2.1.2

Resources

The resource oriented approach to application development means that resources need to be defined with hypermedia semantics in mind. Our definition of resources is
largely inspired by the Siren hypermedia format. Specifically, a resource is described by three distinct types of
information.
The first type of information a resource can provide is
the properties of the resource. This is the true data associated with the resource. For example, if the resource represents results from a time-domain simulation, the properties might be the values of the independent and dependent variables.
The second type of information a resource can provide about itself is metadata. The metadata for a resource includes a textual description of the resource
as well as zero or more textual classes that identify
(in some domain specific way) what the resource represents. For example, if the resource represented simulation results, the set of textual classes might include the
DOI
10.3384/ecp17132725

string simulation_result. It may also include
the name of a more specialized class, e.g., a resource
might include drive_cycle_result and simulation_result where the former is a specialized
form of the latter.
The final, and arguably most important, type of information associated with a resource is links, which convey
how one resource relates to other resources. The ability to
link to other resources is the essence of hypermedia. The
link between resources is always associated with one or
more relations. Relations, like classes, are typically domain specific names although the Internet Assigned Numbers Authority (IANA) has defined a collection of standard link relations (Internet Assigned Number Authority,
2017). For example, the item relation is used to define
the relationship between a (collection) resource and any
other resource contained in it. Similarly, the collection relation may appear on each item resource to link
back to the enclosing container resource.
2.1.3 Domain Specific Resources
The term resource is an abstraction used to refer to any
kind of data that might be accessed over a network. To
help understand what a resource is and how they relate to
our application, we will provide several concrete examples
for discussion in this section.
Static Content A very common type of resource is a
file. In fact, web servers like the Apache or NGINX web
servers treat files precisely as hypermedia resources by
providing a way to refer to those files as network addressable streams of bytes. Heisman also provides a means to
serve files as network addressable resources. However, in
our application the contents of the file are only part of the
resource. We also allow the metadata and link information
to be associated with a file. Just by associating such information with the files, it becomes possible to quickly and
easily define a rich range of structural information about
the resources associated with an application. This hypermedia oriented information can be supplied within the file
itself (by serializing it as a Siren instance) or programmatically via special handler routines registered with the server
that add hypermedia annotations to those files.
This ability to annotate files with hypermedia information means that much of the content being managed by the
content management system can be represented by files
that are statically served directly from a file system. This
capability is important because it helps us address the requirement that creation of content should be easy and intuitive for people who are not programmers or web developers. Using this functionality, much of the application can
be built simply by dragging and dropping files into directories. We will demonstrate this further in the context of
both applications discussed later. It is worth noting that
content served from the filesystem is also much easier to
version control vs. content stored in a database.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

727

modelica.university: A Platform for Interactive Modelica Content

Dynamic Content In addition to static content, most applications depend on the ability to create and manipulate
data dynamically in response to user actions. For example, each time a simulation is performed we might wish
to store those simulation results away for retrieval later.
In some cases, we might want a resource to represent a
very specific type of data (e.g., simulations performed by
a given user) with specific fields (e.g., model simulated,
user who requested the simulation, time request was made,
time required to complete the simulation). In other cases,
we might require a way to create, manipulate and query
arbitrary (schema free) data. While the former often requires specialized resources to be created, Heisman provides a standard collection resource to handle the latter.
Job Brokers The final resource type used in these applications is essential for handling requests for computational work. In both applications, the computational work
required is running simulations. Because nearly every
scientific or engineering application will require one or
more types of computationally intensive analyses, Heisman includes already implemented resources called job
brokers. These job brokers provide an API for requesting work to be done, tracking the status of that work and
reporting back the successful result or an error message.
The code is independent of the task to be performed. This
means that a job broker can be easily created and associated with one or more specific computational tasks required by the application.
The hypermedia semantics allow us to cross reference
job requests with job results. In other words, for a given
simulation result we can follow the links associated with
that result to find the original request and vice-versa. Such
cross referencing of resources can be used for traceability
and to determine provenance of data.

2.2

Communication

The capabilities described so far rely on several different communication mechanisms. In this section we will
quickly summarize each of these.
The web application running in the browser relies on
hypertext transfer protocol (HTTP) (Fielding et al., 1999)
for invoking queries and commands. These HTTP requests are received and acted upon by code on the server
that maps these requests to the underlying resources referenced in the requests.
The job broker resource uses a tool called Redis (Sanfilippo and Noordhuis, 2017) to implement message and
worker queues. It is via Redis that messages are sent between the API server and the workers that perform any
CPU intensive computations.

URL in a web browser), but the process of deploying software to these servers safely and efficiently adds a whole
new dimension to the software development process1
An important technology for the deployment of network services is called Docker. Technically, Docker is
a tool designed to make it easy to access the special Linux
process groups called containers. But this explanation
does not adequately explain Dockers role or capabilities.
Conceptually, Docker is a technology for creating extremely resource efficient virtual (Linux) machines. The
efficiency comes from Dockers use of kernel level features in Linux that isolate groups of processes while allowing them to share large amounts of read only data in
memory and/or on the file system.
The backend server for modelica.university is
a Node (Node.js Foundation, 2017) application written in
TypeScript (Microsoft, 2017). To generate a Docker image, the dockergen Node package (Tiller, 2017) is used.
The dockergen script creates a Dockerfile which
specifies how the application should be packaged for deployment to a Docker host. Once a Docker image is built,
it can be run as a container on a Docker host. Since this is
a public application, we can take advantage of commercial
Docker hosting services.
The actual application is made up of several distinct
Docker images executed using the compose functionality of Docker. In addition to the API server image, the
backend consists of several other images. One image
runs the Redis server. Another image runs a NGINX web
server to act as a reverse proxy. A third image runs the
API server. The final image executes the workers for the
computational tasks processed via the worker queue. With
Docker, it is quite simple to activate multiple containers
running the worker image. This allows us to easily scale
up the number of workers during periods of high load. Another advantage of Docker that all the machines in a cluster are securely firewalled within the same network. Only
ports that have been explicitly opened to machines within
the cluster are accessible outside the cluster.

3
3.1

Application 1: Tour of Modelica
Objective

Now that we have discussed how the underlying infrastructure is implemented, let us get into the details of the
first application. As mentioned previously, the Tour of
Modelica application is a reimplementation of an earlier
web application. The application is structured in the form
of chapters and lessons. In each lesson, the user is presented with some introductory material about a specific
aspect of the Modelica language and starting from some
2.3 Deployment
sample code is asked to carry out several modeling tasks.
After
completing the exercises, the user moves on to the
Desktop tools are typically compiled into binaries and disnext
lesson
and/or chapter.
tributed via installers. In contrast, web applications are
deployed (often, continuously) to servers where they can
1 So much so, that the term DevOps was coined to refer to the
then be accessed via a web browser. This simplifies the combined set of development and operational skill required to deploy
install process for the user (since they only have to enter a web applications.
728

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132725

Session 10B: Modelica Language & Tools

To complete each task, the user must be able to edit,
compile and simulate Modelica code. The code editing is
done in the browser, but the compilation and simulation
is requested via the API and performed by a worker that
uses OpenModelica (Open Source Modelica Consortium,
2016) to compile and simulate each model.

3.2

Content

The content for the application consists primarily of
lessons, chapters, lesson text and sample models. All of
these can be represented as static resources using the functionality previously discussed in 2.1.3.
content/
chapter1/
chapter1.json
lesson1/
lesson1.json
lesson1.html
lesson1.mo
lesson2/
...
...
chapter2/
...
training.json
Figure 1. Fragment of the files system.

A fragment of the file system content is shown in Figure 1. All content is rooted in a directory named content. The files are organized by chapters and lessons
although this is strictly a convention. Files ending in the
.json suffix are interpreted as hypermedia resource descriptions. These JSON files contain the metadata, properties and links discussed previously. Let us look at the
lesson1.json file to as an example of how one such
resource might be described:
{
"title": "Simplest Model",
"properties": {}
"class": ["lesson", "start"],
"links": [
{ "rel": ["text"],
"href": "./lesson1.html" },
{ "rel": ["source"],
"href": "./lesson1.mo" },
{ "rel": ["task"],
"href": "resource://simulate"
{ "rel": ["chapter"],
"href": "../chapter1.json" },
{ "rel": ["training"],
"href": "../../training.json"
],
"query": {
"rel": {
"training/*": { "embed": true
"chapter/*": { "embed": false

DOI
10.3384/ecp17132725

},

"source/data": { "embed": false },
"text/data": { "embed": false },
"task": { "embed": true }
}
},
}

From this description, we can see that this resource is titled Simplest Model and has no properties. Because this
resource is a lesson, we include the lesson class in its
description. It also has the start class which we can use
in our application to locate the first lesson. The links
section provides (respectively) links to the HTML markup
for the lesson text, the initial model source, the job broker
that will run the simulation, the chapter that this lesson belongs to and the training.json file which describes
all the chapters that are part of the Tour of Modelica application. The query section describes what information
about the resource should be returned from each HTTP
request2 . By default, all resources have a default query
that describes what information about that resource is to
be returned for each HTTP request. The query section
here is defining the default query. Note that clients (e.g.,
our web application) are free to specify their own query
with each request. In this way they can request more or
less information to be provided, depending on their needs.
This is a lot of information. Furthermore, nearly all of
it is essentially repeated from one lesson to the next where
only a few details are changed. Fortunately, Heisman provides a way for us to programmatically augment the contents of resources represented by files on the file system.
In this way, we are able to write code to automatically fill
in all the information based conventions like the directory
structure or the lesson name. In fact, the only thing we
cannot figure out automatically is the title. As a result, the
task of creating a new lesson resource becomes as easy as
creating a file that contains:
{
"title": "Simplest Model"
}

A similar process is used to augment information about
other types of content on the file system (e.g., chapters).
This relatively small amount of upfront work to define
specialized handlers greatly simplifies the process of content creation and making the process accessible to nonprogrammers. In addition, allowing data to describe its
relationship to other data means that that information and
logic does not need to be coded into the client. This makes
development of the client easier and more general.

3.3

Visualization

3.3.1 Generic Browser
}

},
},

There are many aspects about the operation of a web
browser that most users are not aware of. One of those
2 In our API, the primary response content type is Siren. Because
Siren allows related resources to be embedded in a response or simply
linked to, our query format must specify which approach to use for each
matching resource. Hence the embed field.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

729

modelica.university: A Platform for Interactive Modelica Content

aspects is the Accept header. This is a header included
with an HTTP request that lets the server know what types
of content it expects back. The default Accept header
for Google Chrome looks like this:
Accept: text/html,application/xhtml+xml,
application/xml;q=0.9,image/webp,*/*;q=0.8

This is essentially a list of content types the browser
understands. But it also defines the clients order of preference for the different content types. The Accept header
is useful to the server because it is possible that a given
resource could be represented in multiple formats and the
Accept header provides a clue as to which format is preferred.
The Accept header is important in API development
because it can be used to determine whether the request
that the API is handling is coming from a browser or from
Javascript code. If our server sees that the request is for
HTML, it will respond to the request by serving up a page
that loads an embedded browser application. That web
application is actually a generic graphical user interface
for Siren APIs that comes bundled with the server. We will
talk about the user interface application in greater detail
shortly.
This is part of the API first philosophy discussed earlier. As a result of following this philosophy, every API
developed in this way automatically comes with a graphical user interface. Furthermore, remember that Heisman
automatically synthesizes an HTTP API based on the resources that are registered with it. What this means, in
practice, is that once you describe your resources, you immediately and automatically get both an HTTP API and a
web application.
3.3.2

Custom Visuals

As mentioned previously, Simran is the web application
that is launched when browsing the API. Simran is a proprietary technology used by Xogeny to create web based
UIs for scientific and engineering applications.
Simran is really a browser running in a (web) browser.
Generally speaking, web browsers like Chrome or Firefox
are used for browsing HTML or other widely used content
types. If you are a scientist or engineer, the problem is that
web browsers do not understand more technical formats
(e.g., Modelica models, .mat files, FMUs).
The API browsing application compensates for this by
providing a web application that is extensible. Because
the browser application is built around the notion of hypermedia (primarily in the form of Siren representations) and
not hypertext (i.e., HTML), we can represent many different content types and the relationships between them. In
a sense, this is a lower level alternative to HTML.
That, by itself, may not sound that useful. But it becomes more useful because of the plugin system. Via the
plugin API, it is possible to extend the browsing application with any number of specialized visual components.
While the base browser application is a generic browser
730

that renders all Siren resources essentially the same, when
enhanced via plugins the browser application is able to
provide custom rendering for different content types based
on the metadata, properties or relations of the resource.
For example, using just the base browser, our Tour of
Modelica application is shown in Figure 2.
There we can see the first lesson and its related resources rendered using metadata. Furthermore, we can
click on links to follow the various resources. But each
resource will be visualized in the same generic way. However, after we provide a plugin with custom visuals for
lessons and chapters, putting the same URL in our web
browser will yield a rendering of the lesson like the one
shown in Figure 3.
The plugin system is based on React (Facebook, 2017).
Normally, each React component independently specifies
what properties it understands when instantiating a component. We turn this around a bit and standardizes these
properties to conform to a canonical representation of a
hypermedia resource. As a result, all React components
are equivalent in the sense that they are instantiated with
the same set of properties but with different values. But,
through the plugin system we have the freedom to customize which component to use for each hypermedia resource. In this way, we are essentially creating a browser
that can easily be extended to understand any kind of scientific or engineering content instead of being limited to
just those standardized in the HTML specification by the
W3C.
In the case of the Tour of Modelica site, the plugin defines custom renderers for lessons, chapters and the training overview. In addition, it leverages some standard and
easily reusable visuals provided by the built in browser for
applications and application suites.
For each application, the application developer can decide what types of content the browser should be capable
of understanding and then simply add those visuals to their
plugin. This modular approach to visualization makes it
very easy to create a custom user interface for a particular domain and/or reuse components developed for other
applications.
The authors would like to acknowledge the contribution
of the moijs project for providing syntax highlighting
and checking for the embedded Modelica editor as well as
the CodeMirror project (Haverbeke, 2017) for the editor
widget itself.
3.3.3 Mobile
Consumers of web applications and web content are increasingly consuming this content from mobile devices.
Support for phones and tablets mainly involves making
sure that layout of content makes sense for small form factor screens. In some cases, some content may be hidden
on small displays. With modelica.university we
have made every effort to support mobile devices.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132725

Session 10B: Modelica Language & Tools

Figure 2. Generic rendering of Tour resources

4

Application 2:
Power System

4.1

Hydro-Electric

Objective

The second application example is a student exercise that
is part of the Masters course Object-oriented Modelling
of Hydro Power Systems at University College of Southeast Norway. The course starts with an introduction to the
fundamentals of Modelica. Later on it moves on to model
specific parts of a hydro-electric power system.
Typical modeling problems are:

 Waterway configuration
 Water hammer investigations
 Droop control behavior of the turbine governor
Being able to solve such problems interactively using
only the browser as a tool without having to immediately
understand Modelica code improves the physical understanding of the system. Once the physical understanding
is there, creating more complex models and scenarios is
easier for the students to achieve.

4.2

Content

The contents of this application are the different main
problems and each with multiple configurations. For example, for the Waterway application different examples
with a number of interconnecting pipes are given where
the levels of the pipe ends need to be verified and checked
DOI
10.3384/ecp17132725

that they make sense. This is sometimes not as easy as
it sounds since pipes might connect to reservoir models
which have a different height reference. So the student is
given a set of parameters for the different pipe segments of
other components of the water way and has to determine
if the setup makes physical sense.
For the Water hammer problem, one can investigate the
influence of closing time of a valve depending on the pipe
diameters and flow rates. The content would also provide
certain restrictions like allowable maximum pressure in
the pipes.
The Droop control (Wikipedia, 2017) problem contains
data that describes the droop settings of one or more turbine controllers and lets one investigate the respective frequency dependent power productions.
The typical data structure of the content is shown in
Figure 4.

4.3

Visualization

The real benefit for the second application will be the visualizations of the problems and especially solutions.
The Waterway problem is much more intuitively solvable when the students is presented with a sketch of the
physical setup of the different pipe levels and other waterway components. Here the student can at once see a
possible flow in the parameter set.
For the Water hammer problem a different method of
visualization can be used. For example interactively showing unsuitable closing times by emphasising the pressure
plots of setups that violate the restrictions. As the student
changes parameters live (e.g.,via a slider), they get the plot

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

731

modelica.university: A Platform for Interactive Modelica Content

Figure 3. Custom rendering of Tour resources

results presented live based on a real simulation done in
 Modelica in Action - An interactive notebook for
the background. The executed models can be supplied as
compiling and simulating Modelica (Bonvini, 2017).
Modelica source files or FMUs.
 Modelica by Example - An interactive book about
The Droop control problem can be visualized by providModelica (Tiller, 2016).
ing interactive droop setting behaviours including limits
and again reacting on parameters that can be interactively
6 Conclusions
set.
Figure 5 shows a typical plot of the power sharing be- By leveraging the power of hypermedia and a wide array
havior of three generators with different droop settings.
of open source technologies, we were able to build the
modelica.university site and our two sample ap5 Related Efforts
plications. We gained several insights as a result of this
work.
The pace of innovation in the web development landscape
is breathtaking. It is nearly impossible to keep track of all 6.1 Middleware
the new technologies that emerge almost on a daily basis. Creating a site like this involves creation of the underlying
The authors drew inspiration from many amazing projects, content, implementation of the necessary analysis capabilincluding:
ities, an HTTP API and a domain specific web application
to support user interaction. But most of the domain spe Jupyter A tool for interactive data science and cific work here is at the edges, i.e., content creation and
scientific computing across all programming lan- visualization. Through their API synthesis and browser
guages (Project Jupyter, 2017)
architectures, the Heisman and Simran packages allow development resources to remain focused on those domain
 Nextjournal - An interactive writing and program- specific edges. This adds efficiency to the development
ming environment for every stage of research from process while providing a tremendous amount of reusabilexperimentation to publication (Nextjournal, 2017)
ity. Together, these two packages form the foundation of
Xogenys Aperion platform.
 "What Can a Technologist Do About Climate
Change? (A Personal View)" - Bret Victors 6.2 Current Status
sprawling essay on technologies that can help ad- At this point, modelica.university implements the
dress climate change (Victor, 2015).
two applications described in this paper. Our experiences
732

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132725

Session 10B: Modelica Language & Tools

content/
waterway/
waterway.json
setup1/
setup1.json
setup1.html
setup1.mo
setup2/
...
...
waterhammer/
waterhammer.json
long-ww/
long-ww.json
long-ww.html
long-ww.fmu
...
droopcontrol
...
hydro-power.json

ica.university and other proprietary projects. Now
that the basic pieces of the architecture are implemented,
there are countless optimizations we would like to make
to improve responsiveness. There are also many types of
content we would like to provide custom visualizations for
(e.g., time series data, version trees, diagram authoring).

Figure 4. Fragment of the files system.

R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter,
P. Leach, and T. Berners-Lee. Hypertext Transfer Protocol
 HTTP/1.1, 1999. URL https://tools.ietf.org/
html/rfc2616.

References
Michael Amundsen. Collection+JSON - Hypermedia Type,
2013. URL http://amundsen.com/media-types/
collection/.
Marco Bonvini. Modelica in action: compile and simulate
models, 2017. URL http://marcobonvini.com/
modelica/2017/01/02/modelica-in-action.
html.
ECMA International. Standard ECMA-262 - ECMAScript
Language Specification.
5.1 edition, June 2011.
URL
http://www.ecma-international.org/
publications/standards/Ecma-262.htm.
Facebook. React - v15.4.2, 2017. URL https://facebook.
github.io/react/.

with these applications further reinforces the importance
of the requirements outlined at this start of this paper. We
are confident that with each additional application, the Roy Thomas Fielding. Architectural Styles and the Design of
Network-based Software Architectures. PhD thesis, 2000.
platform will gain more and more capability as a browser
AAI9980887.
for scientific and engineering content.

6.3

Martin Fowler.
CQRS, 2011.
URL https:
//martinfowler.com/bliki/CQRS.html.

Future Plans

In terms of content, we hope that others will contribute
more content in diverse subject areas to help us further Marijn Haverbeke. CodeMirror, 2017. URL https://
codemirror.net/.
validate our approach, refine our requirements and, ultimately, provide meaningful educational content for sci- Internet Assigned Number Authority. About Us, 2017. URL
ence and engineering students.
http://www.iana.org/about.
As for the platform, we feel its further development
JSON Hypertext Application Language,
will be largely driven by use cases involving model- Michael Kelly.
2016.
URL https://tools.ietf.org/html/
draft-kelly-json-hal-08.

Power Sharing Versus Total Load

120

Eve Maler, Tim Bray, Jean Paoli, Franois Yergeau, and Michael
Sperberg-McQueen. Extensible markup language (XML) 1.0
(fifth edition). W3C recommendation, W3C, November 2008.
http://www.w3.org/TR/2008/REC-xml-20081126/.

Generator Power [MW]

100
80
60

Microsoft. TypeScript - Javascript that scales, 2017.
https://www.typescriptlang.org/.

40

Generator A
Generator B
Generator C
upper power limit
lower power limit

20
0
20
40

0

50

100

150
200
Total Load [MW]

250

Nextjournal.
Nextjournal,
nextjournal.com/.
300

Figure 5. Example of a droop control visualization

DOI
10.3384/ecp17132725

2017.

URL

URL https://

Node.js Foundation. About Node.js, 2017. URL https://
nodejs.org/en/about/.
Open Source Modelica Consortium. Openmodelica, December
2016. URL https://openmodelica.org/.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

733

modelica.university: A Platform for Interactive Modelica Content

A. Palanisamy, M. Sjlund, and P. Fritzson.
Generating OpenModelica Web Books Including Mathematical
Typesetting from OMNotebooks, 2016.
URL http:
//www.modprod.liu.se/filarkiv/1.672879/
OpenModelica2016-talk15-Arunkumar-GeneratingOpenModelicaWebbook.
pdf.
Project Jupyter. Project Jupyter, 2017.
jupyter.org/.

URL http://

Salvatore Sanfilippo and Pieter Noordhuis. Redis, 2017. URL
https://redis.io/.
Susan Fowler. Production-Ready Microservices: Building
Standardized Systems Across an Engineering Organization.
December 2016. URL http://shop.oreilly.com/
product/0636920053675.do.
Kevin Swiber. Siren: a hypermedia specification for representing entities, 2016. URL https://github.com/
kevinswiber/siren.
Michael M. Tiller. Modelica by Example, 2016. URL http:
//book.xogeny.com/.
Michael M. Tiller. Generate a Dockerfile for any NodeJS
application, 2017. URL https://www.npmjs.com/
package/dockergen.
Bret Victor. What Can a Technologist Do About Climate
Change? (A Personal View), 2015.
URL http://
worrydream.com/ClimateChange/.
W3C. HTML 5.1, 2016. URL https://www.w3.org/TR/
html/.
Wikipedia. Droop speed control, 2017. URL https://en.
wikipedia.org/wiki/Droop_speed_control.
Wolfram Alpha. Wolfram Alpha, 2017. URL https://www.
wolframalpha.com/web-apps/.

734

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132725

Object-oriented modelling of a flexible beam including geometric
nonlinearities
Davide Invernizzi1

Bruno Scaglioni2

Gianni Ferretti2

Paolo Albertelli3

1 Politecnico

Di Milano, Dipartimento di Scienze e Tecnologie Aerospaziali
Via La Masa 34, 20156 Milano, Italy
2 Politecnico Di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria DEIB
Via Ponzio 34/5, 20133 Milano, Italy
3 Politecnico Di Milano, Dipartimento di Meccanica, Via La Masa 1, 20156 Milano, Italy

Abstract
In this paper, an efficient approach for the modelling and
simulation of slender beams subject to heavy inertial loads
is presented. The limitations imposed by a linear formulation of elasticity are overcome by a second order expansion of the displacement field, based on a geometrical exact beam model. In light of this, the nonlinearities of the
elastic terms are shifted as inertial contributions, which
yields an expression of the equations of motion in closed
form. Thanks to the formulation in closed form, the proposed model is implemented in Modelica, with particular care to the suitability of the model with respect to the
Modelica Multibody library. After describing the model
formulation and implementation, the paper presents some
simulation results, in order to validate the model with respect to benchmarks, widely adopted in literature. In
the context of modern multi-domain modelling, the modular and object oriented approaches are the state-of-the-art
paradigms upon which complex models are built. In this
respect, multibody dynamics is frequently only one of the
domains involved, nevertheless several real-world applications can be found where multibody modelling plays a
crucial role in the design of systems, analysis and modelbased control architectures. In this framework, modelling
techniques and tools have evolved towards the insertion
of flexible bodies into the models (MSC Software Corporation, 2017; Claytex Services Ltd; Dymore Solutions,
2016; Spacar, 2016; Heckmann et al., 2006; Ferretti et al.,
2014).
Flexible multibody systems can be divided in two main
branches according to the linear or nonlinear constitutive laws employed to model flexible elements. In the
first case, the strain-displacement relationships are assumed to be linear and strain components to remain
small. Nevertheless, several occurrences can be found
where elastic bodies may undergo large overall motion
while strains are kept small. Traditionally, linear elasticity has been accounted for using the so called floating
frame of reference approach (short, FFR), which is natural way to include flexibility in the rigid multibody framework(Shabana, 1998). Indeed, the displacement field is
DOI
10.3384/ecp17132735

decomposed as the sum of an arbitrary large motion of
a suitably selected frame, superposed to an elastic displacement field which is assumed to be small with respect to the overall motion. Thus the elastic displacement
field may be computed accurately through a modal expansion, which is extremely efficient from a computational
point of view. Furthermore, component mode synthesis
techniques, like the well-known Craig-Bampton method
(Craig and Bampton, 1968), has been widely adopted in
multibody simulation tools and specifically in the context
of Modelica, both in commercial (Claytex Services Ltd;
Heckmann et al., 2006) and open-source (Ferretti et al.,
2014; Bascetta et al., 2015) libraries. By means of this
technique, complex geometry can be included in the analysis even tough an external finite element modeling tool
is required. Although the concept of floating frame is
simple, in practice there are several issues to be handled.
The selection of the floating frame is not unique and accuracy of the results is strongly affected by the choice of
the modal basis (Schwertassek et al., 1999a), (Heckmann,
2010). Furthermore, the use of linear elasticity may lead
to erroneous results when the inertial contribution of the
floating frame motion is large enough to produce high
loads in bodies with high stiffness. A well-known example is the rotating beam around a fixed axis: the coupling among the axial, flexural and torsional motion, neglected by the linearized theory, is crucial in order to correctly predict the behavior of the structure (Berzeri and
Shabana, 2002; Sharf, 1995; Lugrs et al., 2008; Absy and
Shabana, 1997). On the other hand, the flaws of this theory pushed the multibody community toward the development of new approaches, closely related to the nonlinear
finite element method (Gradin and Cardona, 2001). In
this case the domain is divided in sub-domains or finite elements which are connected at nodes to ensure elements
compatibility, the nodal displacements and rotations are
referred to a common frame, which is selected as the inertial frame. From a theoretical point of view this approach
is challenging when considering structural elements such
as beams, shells, plates and in particular when large displacements and rotations are considered. Geometrically
exact models for these elements have been developed in

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

735

Object-oriented modelling of a flexible beam including geometric nonlinearities

the last decades (Pai, 2007) and are the state-of-the-art
to deal with large displacements small strains problems.
Nonetheless special care is required for the computation
of elastic terms and for the interpolation scheme of spatial rotations in a finite elements framework (Jelenic and
Crisfield, 1998). Moreover, a large number of degrees of
freedom is required to obtain accurate solutions and the
expression of the elastic contribution is highly nonlinear
even in the case of small strains. The use of such approach
within the Modelica multibody library is difficult because
the closed form expression of the discretized equations of
motion is not manageable even for simple elements like
beams.
Within the FFR method, several approaches have been
proposed in the reference literature that overcome the
shortcomings of the standard linear approach by accounting for geometrically nonlinear effects (Wallrapp and
Wiedemann, 2003; Bremer, 2008; Banerjee, 2016). As
already mentioned, the classic linear approach may provide erroneous results due to a-priori linearization of the
kinematics and of the elastic energy, even if the strains are
small. This problem has been deeply studied (Absy and
Shabana, 1997) and different techniques have been developed to consistently linearize the equations of motion, so
that all the relevant terms are retained while keeping the
standard linear elastic terms.
In this work, a general framework to include geometrically nonlinear effects within the FFR approach is presented. The approach is based on a second order expansion of the displacement field, which can be derived from
geometrically exact models of simple structural elements.
Then, the displacement field is written in terms of a set
of generalized deformation variables for which the elastic terms are linear. Thanks to this substitution, the standard linear elastic theory can be exploited and the nonlinearities are expressed as inertial contribution, which can
be computed in closed form. Hence, the existing FFR formulation can be employed with minor changes, which is
particularly efficient when small elastic deformations are
expected: few degrees of freedom are usually required.
The proposed formulation has been applied to slender
structural elements which are usually modeled as beams.
In the standard approach, a linearized model is adopted to
describe the deformation field in the floating frame, such
as the Euler-Bernoulli or the Timoshenko beam model.
This approach greatly simplifies the computation of the
elastic terms but limits the correctness of the results by
neglecting nonlinear effects, e.g. the geometric stiffening induced by the centrifugal acceleration for fast rotating beams. Within the Modelica framework, the standard
linear approach has been implemented in (Schiavo et al.,
2006), while in (Heckmann et al., 2006) a second order apporximation of the deformation field is presented together
with a Ritz-Galerkin discretization (Ritz, 1909). With respect to (Heckmann et al., 2006), in this work the deformation field is expanded starting from a geometrically exact description of the beam kinematics ((Schwertassek and
736

Wallrapp, 1999)) and the model is discretized according
to a finite element approach. Finally, the Craig-Bampton
reduction is applied to obtain a computationally efficient
set of equations. The model is implemented in Modelica following an approach similar to (Ferretti et al., 2014)
and two validation benchmarks taken from literature are
reproduced, showing trustworthy agreement between simulation results and literature data.
The paper is organized as follows: In section 1 the modelling framework is described for the generic flexible body
and the equations of motion are formulated. Section 2
goes into details of the beams by describing the mathematical formulation pointed out in the previous section. In
section 3 the implementation and the simulation results are
described. In particular, the results are compared with two
well known literature benchmarks. Section 4 concludes
the paper.

1

Equations of motion of a flexible
boby

Within the FFR approach, the absolute position p of a
generic point of the flexible body is composed by the sum
of three contributions
p = r + u0 + u f ,

(1)

where r is the vector describing the position of the reference frame {Oi , xi , yi , zi } with respect to the inertial frame
{Ow , xw , yw , zw }, u0 is the undeformed position of the
point with respect to the local reference frame and u f is
the deformation field, as shown by Figure 1. The components of u0 resolved in {Oi , xi , yi , zi } are named material
coordinates.
In order to obtain the equations of motion, the principle
of virtual work is exploited, i.e.:
We = Wi

(2)

where We and Wi are the external and internal virtual
works. According to the FFR approach, the virtual displacement related to (1) can be computed as follows:

 p =  r +    u0 + u f +  u f
(3)
where   is the virtual rotations vector of {Oi , xi , yi , zi }
while  u f is the virtual variation of the deformation field
with respect to the local reference frame of the body.

Figure 1. Flexible body reference frames

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132735

Session 10C: Mechanical Systems Modelling

The external and internal virtual works for a generic where i j are the components of the identity tensor:
flexible body can be defined as:

1 i= j
Z
Z
i j =
.
(11)
0 i 6= j
 p  t dA (4)
W =
 p  (a + f) dV +
e

V

AN

As already mentioned in the introduction, the classic
(5) linear approach may lead to erroneous results since sevV
eral terms are a-priori neglected. Instead, a consistent ap3x3
3x3
proximation of (5) is based on the decomposition of the
where  is the density of the body, B  R and J  R
are the Jaumann strain and stress tensor respectively (see deformation gradient such that
(Pai, 2007) for more details). By using the indicial nota1
tion, the double inner tensor product ":" is defined by:
(12)
Bi j  (Fi j + Fji )  i j
2
Z

Wi

=

 B : J dV

3

3

3
(6) where Fi j = k=1 Rik Fk j and Rik is the rotation matrix describing the orientation of a suitable frame with respect to
V
i=1 j=1
the local reference frame. Under the small strains assumpMoreover, f is the body force per unit volume and t the tion, the aforementioned frame can be selected such that
surface traction per unit area, V is the volume of the body Fi j  i j , even if displacements are large (see (Bauchau
et al., 2016) for more details).
and A is the unconstrained portion of the body surface.
Within this framework, a second order approximation
It must be pointed out that the Jaumann strain tensor
3x3
is related to the deformation gradient F  R as follows of the deformation field is considered in this paper. In
particular, it is possible to operate a change of variables
(see (Hodges, 2006)):
such that elastic forces can be derived from standard linB = UI
U2 = FT  F
(7) ear theory whereas geometrical effects are computed as an
inertial contribution. In order to perform such change, the
where I is the identity tensor and U is the right stretch following assumptions are introduced:
tensor.
 the deformation field u f depends on a finite set of
It must be pointed out that the Jaumann strains are an
physical deformation functions d p = d p (u0 ), i.e.,
objective strain measure suitable for large displacementsu
f = u f (d p , u0 ). Physical deformations depend only
small strains analysis since they are co-rotated engineeron
a reduced set of material coordinates u0 , e.g., in
ing strains. As a consequence, in a linear elastic framebeam
models, the reference axis displacements and
work the reduced material stiffness matrix can be derived
the
cross-section
rotation angles are functions of the
from standard experiments (Pai, 2007). The term of We
reference
axis
coordinate
alone;
relative to inertial virtual work can be expanded by substituting (3) in (4), thus obtaining:
 the physical deformations d p can be expressed in
Z
terms of generalized deformation functions dg , i.e.,


 p   v +   v +   u0 + u f +
(8)
d p = d p (dg , u0 ), such that the deformation gradient F
V


(and thus elastic forces) are linear in dg when strains
+   (  u0 + u f ) + u f + 2  u f dV
(but not displacements) are small;

Z

Z

 B : J dV =

   Bi j Ji j dV.
V

where v and  are the body translational and angular ve the nonlinear relation u f = u f (d p (dg ), u0 ) is exlocities of the FFR.
panded up to the second order in terms of the genIn the classic linear approach, the deformation field
eralized deformations.
measured in the FFR is assumed to be infinitesimal such
that the computation of the internal virtual work can be It is worth remarking that these assumptions are not restrictive as they hold true for geometrically nonlinear
approximated with the standard linear theory:
models of beams, plates and shells. On the other hand,
Z
Z 3 3
it is not trivial to obtain the relationship among physi B : J dV     i j i j dV
(9) cal and generalized deformation variables (Schwertassek
V
V i=1 j=1
et al., 1999b).
Assuming that the generalized deformations are expanded
1
where i j = 2 (Fi j + Fji )  i j is the infinitesimal deforby means of a Ritz-Galerking approach (Ritz, 1909), i.e.,
mation tensor, and i j the conjugated stress tensor, both
resolved in the undeformed basis {Oi , xi , yi , zi }. The cordg =  (u0 ) q(t),
(13)
responding components of the deformation gradient are:
the displacement field, up to the second order, reads:
uf i
Fi j = i j +
(10)
u f = Sq + G(q)q,
(14)
 u0 j
DOI
10.3384/ecp17132735

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

737

Object-oriented modelling of a flexible beam including geometric nonlinearities

where  (u0 ) are spatial mode functions, q is a vector of
generalized coordinates and S(u0 ) is the standard matrix
of shape functions obtained with linear models. The matrix G(q) linearly depends on q and allows to account for
geometrically nonlinear terms:
 T

q G1
G(q) =  qT G2 
(15)
qT G3

where Gi = Gi (u0 ) is a symmetric matrix depending
only on the material coordinates. Adopting the approximation (14) in the definition of the internal and
external virtual works (4,5) leads to the derivation
of the equations of motion in the following form:

eCT  + 2C
eCT  + CTt q + m
e 1 = hre
e d
e Tt q + mv
m (v  g) + md
eC v
eC (v  g) + J + CTr q + J
e + 2C
e Tr q = he
e
+ md
md
g
e + (De + Dcr ) q + Kq = hef  hct
Ct (v  g) + Cgr  + Me q + Ct v
e

where the terms of the inertia and stiffness matrices include additional terms with respect to the classical linear
Newton-Euler approach(Shabana, 1998). In particular, the
generalized stiffness matrix is expressed as follows:
K = Ke + Kct + K1g + K2g + Krg

(19)

and contains additional contributions relative the motion
induced stiffness (K1g , K2g ) and the external action which
account for geometrically nonlinear effects. The motion
induced stiffness (Krg ) contribution depends on the reference frame motion and accounts for the loss of stiffness
induced by the centrifugal acceleration (Kct ). The aforementioned terms appear in the equations of motion as a
consequence of the presence of the first order term in the
virtual variation of the generalized coordinates formulation:

(16)
(17)
(18)

of the Modelica framework. The definition of the standard terms m, dC , Ct , J, Cr , De , Ke , Me , hre , he , hfe and
the computation of the corresponding invariants can be
found in (Bascetta et al., 2015).

2

Geometrically exact modeling of
slender beams

The method developed in Section 1 is applied to derive the
equations of motion of slender beams, for which the crosssection plane is assumed to remain normal to the reference
axis during the deformation. The motion of the flexible
beam can be described in terms of three reference frames
as shown in Figure 2, frame {Ow , xw , yw , zw } is the world
reference frame, while the undeformed beam geometry is
represented by frame {Or , xr , yr , zr } where b1 is the direction of the undeformed beam axis, b2 and b3 define the
cross section principal axis. Finally, frame {Od , xd , yd , zd }
 u f = S q + G(q) q
(20) describes the motion of the beam cross-section. The outof-plane displacement are assumed to be negligible.
which yields a contribution in the external virtual work
formulation
We = Wec + Wg
(21)
where the standard terms of the external virtual work are
contained in Wec and the geometric contribution is described by Wg . The complete derivation of the terms
is not reported here for the sake of brevity, it must be
however pointed out that all the terms of the geometric contribution can be computed as function of invariants. The formulation described above enhances the classic linear FFR approach through the addition of further
terms, providing a simple solution for including geometric nonlinearities in the equations of motion. This can be
considered as a relevant advantage of the proposed formulation. The nonlinearities are isolated in the inertial
terms, hence, a closed form expression for the geometrical stiffening effects is derived, which is essential for
the application of the proposed approach in the context
738

Figure 2. Beam reference frames

According to the reference frames described above, the
position of a generic point on the deformed beam, with
respect to the inertial frame, (see eq.1) is given by:
p = r + xb1 + u + R  

(22)

where u = u(x)b1 + v(x)b2 + w(x)b3 represents the vector of the cross-section translation dofs,  = yb2 + zb3

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132735

Session 10C: Mechanical Systems Modelling

and R(x) is the rigid rotation tensor of the cross-section where EA, GJ, EJyy , EJzz are the axial, torsional, and
which can be parametrized by means of Euler angles bending stiffness, respectively.
Thus, by substituting the constitutive law in the internal
( (x),  (x), (x)). The deformation field, defined as u f =
u + R   , is a nonlinear function of a set of physical dis- virtual work expression:
placements d p = (u, v, w,  ,  , ), as required by the first
assumption in Section 1.
Z `
As already mentioned, the Jaumann strain tensor B is cho( eEAe +  k1 GJk1 +  k1 GJk1 +  k2 EJyy k2
sen as the strain measure. According to the small defor0
mations assumption, B can be consistently approximated
+  k3 EJzz k3 ) dx. (26)
as:
It is clear that the above expression is linear in generalized
B11 = e + zk2  yk3
strains and has the same mathematical form of the clas2B12 = 2B21 = zk1
(23) sic linear approach. Nonetheless, it is valid also in the the
2B13 = 2B31 = yk1
case of large displacements and small strains. In order to
adopt the described approach, a suitable change of variB22 , B33 , B23 , B32 = 0
ables is introduced, such that the elastic forces are linear
where e represents the axial stretch, k1 the twisting cur- in these new variables, according to the second assumpvature and k2 , k3 the bending curvatures. These quanti- tion in Section 1.
ties are called generalized strains and are nonlinear func- The generalized strain components are written in terms
tions of the physical displacements and their derivatives, of a set of generalized deformation functions d =
g
see (Hodges, 2006) for further details. The internal virtual u(x), v(x), w(x),  (x) by defining:
work is expressed in terms of the Jaumann strains Bi j in
(23) and their work-conjugate stresses Ji j as follows:
 
 u
Z
,
k1 =
,
e=
x
x
Wi = ( B11 J11 + 2 B12 J12 + 2 B13 J13 ) dV. (24)
V
 2 w
 2 v
k2 =  2 ,
k3 = 2 .
(27)
After substituting (23), the internal virtual work can be
x
x
compactly written by introducing the generalized axial
As shown in (Schwertassek and Wallrapp, 1999), by
force F1 and moments M1 , M2 , M3 as follows
describing the physical variables in terms of generZ `
Wi =
( eF1 +  k1 M1 +  k2 M2 +  k3 M3 ) dx. (25) alized strains (27) and expanding up to the second
order the corresponding relation, one can compute
0
Assuming a linear elastic constitutive law for an isotropic the components of the deformation field u f as:
material, the generalized force and moment are related to
the corresponding strains as:

 


EA 0
0
0
e 
F1 






 



0 GJ
0
0 
k1
M1


=
0
0 EJyy
0 
k2 
M2 





 k 
 M 
0
0
0
EJ
3

zz

uf1

uf2

uf3

3

"  
 #
Z
 v
 v 2
 w 1 x
 w 2
= u  y  z

+
dx +
x
x 2 0
x
x
Z x  2


Z x 


 w  u  2 v
 w
 u  2 w
 2 v
 v
y
 2 
z
dx + 
+  2 dx  
x
 x  x2
x
 x  x2
x
x
0
0
" 
#
 
Z x
Z x
2
2
2
 u  v
 u  v
 w
1
 v
= v  z +
+
  2 dx dx  y
+  2 +
2
x x
x x
x
2
x
0
0

 
Z x
 v  w
 u    w  2 v
z
+

dx
x x
 x  x  x  x2
0
"
#
 

Z x
Z x
 u  w
 u  2 w
 2 v
1
 w 2
2
= w + y +
dx +
+  2 dx dx  z
+  +
x x
 x  x2
x
2
x
0
0
Z x 
 
 u    w  2 v
+y

dx .
 x  x  x  x2
0

DOI
10.3384/ecp17132735

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(28)

(29)

(30)

739

Object-oriented modelling of a flexible beam including geometric nonlinearities

The direction cosine matrix of the cross-section, expanded up to the second order, can be defined accordingly. A full treatise can be found in (Schwertassek et al.,
1999b).
Finally, the generalized deformations, namely: u(x), v(x),
w(x) and  (x) can be approximated as a linear combination of shape functions in terms of the generalized coordinates q by means of the classical Ritz-Galerkin method
(Ritz, 1909), in particular:

on the corresponding modal basis, which include constraint as well as normal modes. This is particularly efficient from a computational point of view since the final
model includes only a few degrees of freedom while providing satisfactory results. The deformation field (14) can
be written as:
 


 T

q G1
S1
 uf1 
uf2
=  S2  q +  qT G2  q


S3
uf3
qT G3

u = 1 q

v = 2 q

(31)

w = 3 q

 = 4 q

(32) where
 3
 2
z
x
x
S2 = 2  z4
S3 = 3 + y4

where  are rows of admissible shape functions. It is
worth to remark that the boundary conditions of the generalized displacements are the same of physical displacements. In this work, a finite element approach is used to
discretize the beam domain. After the assembly procedure, the Craig-Bampton (Craig and Bampton, 1968) reduction procedure is applied by projecting the equations

Zx

G1

1
= 
2
0


Zx

z 

0

G3

!

 2 2  1 T  2 3
+
 x2
x
 x2

!

T4



Zx

dx  y 

0

dx  T4

 2 3  1 T  2 2
T4

 x2
x
 x2


!




3
dx + T4
+
x

 2 
x

(33)

! 
!
Zx
T
T 2
2





1




 2 T  2
1
1
3
2
2
T
T


 4
dx dx  y
=
+
+ 4 4 +
x
x
x
 x2
 x2
2
x
x
0
0

! 
Zx
T
T
T 2
 2  3
 1  4  3  2
z 
+

dx
x
x
x
x
x
 x2
0

! 
x
Z
Zx
T
T 2
2









2
1
3
3
1

+ T4
dx dx +
=
+
x
x
x
 x2
 x2
0
0
!
!
Zx
T
 1  4  3 T  2 2
1
 3 T  3
+y

dx  z
+ T4 4 .
x
x
x
 x2
2
x
x
Zx

G2

 2 T  2  3 T  3
+
x
x
x
x

S 1 = 1  y



(34)

(35)

0

The terms of the direction cosines matrix are not reported dard Modelica multibody library has been developed. The
here for brevity, the procedure for the computation is sim- shape functions and the invariants which assemble the
ilar.
terms of eq.(18) are collected in a Modelica record defined as replaceable, in order to exploit the object3 Model implementation and valida- oriented approach of the language and possibly instantiate
multiple flexible beams in the same model. The aforetion
mentioned record has been calculated offline by means
of an external script written in Matlab (Mathworks, 2014)
3.1 Model implementation
starting from the geometric and material parameters of the
The implementation of the model is similar to (Ferretti beam. The symbolic computation toolbox has been used
et al., 2014), a component fully compatible with the stan- to solve eqs.(28,29,30).
740

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132735

Session 10C: Mechanical Systems Modelling

sional behaviour, due to the different relative orientation
of the load and beam.

Figure 3. Diagram level scheme of the beam in a simple model

Figure 4. User interface of the beam model

The connectors are placed at the ends of the beam and
the number is limited to two. As an example of model
usage, fig. 3 shows a simple implementation containing
the beam, while fig. 4 shows the GUI of the beam model,
where the replaceable data record can be modified.
In the rigid body components of the multibody library,
the body coordinates are used as state variables when the
component is floating, this is carried out by selecting the
component as root of one connection tree (see (The Modelica Association, 2009; Otter et al., 2003) for details).
Conversely, if the body is connected to a root, a branch
statement is declared and the kinematic is computed from
the states of the joints connecting the component to the
root tree. This mechanism is reproduced in the implementation described here, the FFR (placed in the FrameA
connector) is assigned as root of the connection tree if the
body is floating, if the body is part of a kinematic chain a
branch is declared between FrameA and FrameB. Finally, the 3D visualization of the component is provided
by means of the Advanced.Shape visualizer of the
standard multibody library.

3.2

Model validation

The model has been thoroughly validated by means of two
simulation scenarios. Initially, the well-known Princeton
beam experiment (Bauchau et al., 2016) has been reproduced in order to validate the quasi-static behaviour of the
model. The beam is subject to a lateral load in different
root orientations ranging from 0 to 90 degrees. The setup
is briefly shown in fig. 5 while the geometric and material
parameters of the beam are shown in tab. 1. This experiment is particularly effective in order to validate the static
deflection of the beam as well as the coupled bending/torDOI
10.3384/ecp17132735

Figure 5. The Princeton beam experiment, reference scheme

Length
Height
Width
Axial S
Shearing K22
Shearing K33
Torsional H11
Bending H22
Bending H33

0.508 m
3.2024x103 m
12.377x103 m
2.842x106 N
0.6401x106 N
0.9039x106 N
3.103 Nm2
36.28 Nm2
2.429 Nm2

Table 1. Princeton beam parameters

The simulations have been carried out in three different loading conditions, namely P1 = 4448N, P2 = 8896N
and P3 = 13345N and the results have been compared with
simulations performed in the software Dymore(Dymore
Solutions, 2016) where a geometrically exact beam theory
is implemented. A photogram of the animation is shown
in fig. 6, where the green arrow on the tip of the bent beam
represents the applied load. Moreover, a substrucutred instance has been tested in order to show the difference in
performance and accuracy. The beam has been divided in
5 elements (6 dofs each) placed in series by simply connecting five instances of the model. Figs. 7 and 8 show the
absolute displacement of the transverse components of the
beam with respect to the beam root orientation, while fig.
9 shows the twisting angle in the same circumstances. The
continuous lines represent the Dymore solutions while the
triangles represent the simulations performed in Dymola
(Dynasim AB). As shown in the figures, the results of the
single element model are in good accordance with the exact solution in the first loading case (blue), while five substructuring elements are sufficient to correctly reproduce
the exact solution in the other loading cases. Indeed, in the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

741

Object-oriented modelling of a flexible beam including geometric nonlinearities

second and third case, large displacements are expected
and a single element with a second order approximation
is not adequate. As expected from a theoretical point of
view, the proposed model is slightly stiffer because shear
deformations are not included. It is also worth to remark
that a null twisting angle (fig. 9) would be predicted by a
linearized beam model whilst the coupling effect between
bending and twisting is correctly captured by the present
formulation even with a single element.

Figure 8. The Princeton beam experiment, transverse tip displacement (w)

Figure 6. The Princeton beam experiment, simulation visualization

Figure 9. The Princeton beam experiment, twisting angle

In order to validate the dynamic behaviour of the model,
the classical planar spin-up manoeuver benchmark has
been considered (Berzeri and Shabana, 2002; Valembois
et al., 1997; Shi et al., 2001; Wu and Haug, 1988). A flexible beam rotates about one end with a prescribed angular
law, a diagram of the mechanism is reported in fig.10. The
law describing the time evolution of the angle  is the follwing:
i
( h2
T 2
2t
 t
+
(
)
(cos(
)

1)
, t <T
2
T
(36)
 (t) = T 2
(t  T /2),
t T

thus, the spin-up starts at t = 0 and ends at t = T , when a
constant angular velocity is reached, where it has been assumed T = 15s in the considered experiment. This benchmark is widely used in literature in order to demonstrate
the effectiveness of the substructuring technique as well
as the robustness of nonlinear formulations. The following geometrical data were assumed for the beam: length
L = 8m , cross sectional area A = 7.3  105 m2 , modulus
10
2
Figure 7. The Princeton beam experiment, transverse tip dis- of elasticity E = 1.3359  10 N/M , second moment of
9
4
placement (v)
inertia I = 8.218  10 m and density  = 2766Kg/m3 .
742

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132735

Session 10C: Mechanical Systems Modelling

The tip transverse deflection for a 20 seconds simulation
is here compared with the results obtained with a completely different approach, thoroughly described in (Boer
et al., 2011). A single element beam has been used by retaining two additional normal modes in order to increase
accuracy. Thus the number of active dofs is five, considering only the planar components of the end node deformation. Fig. 11 shows satisfactory results in terms of accordance between the two approaches. Moreover, the dy-

Model
Present formulation
SPACAR, nonlinear beam
SPACAR, superelement
Wu and Haung (Wu and Haug, 1988)

namics shown here is in good accordance with the other
results in literature (see (Boer et al., 2011; Wu and Haug,
1988)), and the maximum tip deflection is similar to other
numerical results as shown in tab. 2. The proposed formulation captures correctly the geometric stiffening effect induced by the rotation and overcomes the shortcomings of
the standard linear approach, while keeping low the computational effort.

Number of elements
1 (5 dofs)
4 (8 dofs)
4 superelements (8 dofs)
6 substructure

Max. deflection [m]
0.536
0.5388
0.5375
0.543

Table 2. Maximum tip deflection, comparison with other simulation results

phenomena. The equations of motion for a generic flexible body are developed starting from the approximation
of the Jaumann strain tensor under the small strain hypothesis. Assuming that the deformation field of the continuum model can be expanded up to the second order, a
closed form expression of the equations of motion is presented including only a few additional terms with respect
to the standard floating frame of reference approach. Subsequently, the proposed formulation is applied to slender
structures. A second order model is consistently derived
from a geometrically exact beam model. The finite element approach is adopted in order to discretize the beam,
finally the Craig-Bampton method is applied to reduce the
Figure 10. Planar spin-up, scheme of the setup
number of degrees of freedom. The theoretical model
is implemented in the Modelica framework by adopting
an efficient approach where the invariant terms are computed offline and the resulting model is fully integrated
in the Modelica multibody library. The model is finally
validated by means of comparison with well known literature benchmarks, the numerical results are compared
with simulations obtained by means of completely different approaches. The model is suitable to perform small
strains, moderate displacements analysis and can be employed in large displacements cases by means of substructuring, which is naturally managed in Modelica. The proposed model will allow to consider the realistic behaviour
of slender beams subject to high angular velocities, as well
as to correctly consider the geometrical nonlinear phenomena in slender beams. The development of this model
constitutes a step forward in the state of the art of the flexFigure 11. Planar spin-up, tip transverse deflection
ible multibody Modelica models, leading to more efficient
models for real-world applications. The beam model, as
4 Conclusion
well as the other flexible multibody models developed by
In this paper, an approximated dynamic model for flexi- the authors are freely available upon request, hence, the
ble beams is presented, including geometrically nonlinear author would encourage possible users to contact them.
DOI
10.3384/ecp17132735

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

743

Object-oriented modelling of a flexible beam including geometric nonlinearities

References
H.E. Absy and A.A. Shabana. Geometric Stiffness and Stability
of Rigid Body Modes. Journal of Sound and Vibration, 207
(4):465496, 1997.

U. Lugrs, M. A. Naya, J. A. Perz, and J. Cuadrado. Implementation and efficiency of two geometric stiffening approaches.
Multibody System Dynamics, 20:147161, 2008.
Mathworks. Matlab, 2014.

Arun K Banerjee. Flexible Multibody Dynamics: Efficient Formulations and Applications. John Wiley & Sons, 2016.

MSC Software Corporation. ADAMS/Flex users manual, 2017.

L. Bascetta, G. Ferretti, and B. Scaglioni. Closed-form Newton
Euler dynamic model of flexible manipulators. Robotica (in
press), 2015.

M. Otter, H. Elmqvist, and S.E. Mattsson. The new Modelica
multibody library. In 3rd Modelica Conference, Linkping,
Sweden, November 34, 2003.

Olivier A. Bauchau, Peter Betsch, Alberto Cardona, Johannes
Gerstmayr, Ben Jonker, Pierangelo Masarati, and Valentin
Sonneville. Validation of flexible multibody dynamics beam
formulations using benchmark problems. Multibody System
Dynamics, 37(1):2948, 2016. ISSN 1573-272X.

P Frank Pai. Highly flexible structures: modeling, computation,
and experimentation. AIAA (American Institute of Aeronautics & Ast, 2007.

M. Berzeri and A.A. Shabana. Study of the Centrifugal Stiffening Effect Using the Finite Element Absolute Nodal Coordinate Formulation. Multibody System Dynamics, 7(4):357
387, 2002.
S.E. Boer, R.G.K.M. Aarts, J.P. Meijaard, D.M. Brouwer, and
J.B. Jonker. A two-node superelement description for modelling of flexible complex-shared beam-like components. In
Multibody Dynamics 2011, ECCOMAS Thematic Conference, 2011.
Hartmut Bremer. Elastic Multibody Dynamics. Springer, 2008.
ISBN 9781402086809.
Claytex Services Ltd. FlexibleBody Library. Coventry, UK.
R. R. Craig and M. C. C. Bampton. Coupling of substructures
for dynamic analyses. AIAA Journal, 6(7):13131319, 1968.
Dymore Solutions. Dymore users manual, 2016.
Dynasim AB. Dymola. Lund, Sweden.
G. Ferretti, A. Leva, and B. Scaglioni. Object-oriented modelling of general flexible multibody systems. Mathematical
and Computer Modelling of Dynamical Systems, 20(1):122,
2014.

W. Ritz. ber eine neue Methode zur Lsung gewisser Variationsprobleme der mathematischen Physik. Journal fr die
Reine und Angewandte Mathematik, 135:161, 1909.
F. Schiavo, L. Vigan, and G. Ferretti. Object-oriented modelling of flexible beams. Multibody System Dynamics, 15(3):
263286, 2006.
R. Schwertassek and O. Wallrapp. Dynamik flexibler Mehrkrpersysteme. Vieweg, Wiesbaden, 1999.
R. Schwertassek, O. Wallrapp, and A. A. Shabana. Flexible
multibody simulation and choice of shape functions. Nonlinear Dynamics, 20:361380, 1999a.
Richard Schwertassek, Oskar Wallrapp, and Ahmed A Shabana.
Flexible multibody simulation and choice of shape functions.
Nonlinear Dynamics, 20(4):361380, 1999b.
A. A. Shabana. Dynamics of Multibody Systems. Cambridge
University Press, New York, 1998.
I. Sharf. Geometric stiffening in multibody dynamics formulations. Journal of Guidance, Control and Dynamics, 18(4):
882890, 1995.
P. Shi, J. McPhee, and G.R. Heppler. A deformation field for
EulerBernoulli beams with applications to flexible multibody dynamics. Multibody System Dynamics, 5:79104,
2001. ISSN 13845640.

M. Gradin and Alberto Cardona. Flexible Multibody Dynamics: A Finite Element Approach. Wiley, Chichester, Great
Britain, January 2001.

Spacar. users manual, 2016.

A. Heckmann. On the choice of boundary conditions for mode
shapes in flexible multibody systems. Multibody System Dynamics, 23(2):141163, 2010.

The Modelica Association. Modelica  A Unified Object
Oriented Language for Physical Systems Modeling. Language Specification Version 3.1, 2009.

A. Heckmann, M. Otter, S. Dietz, and J. D. Lpez. The DLR
FlexibleBodies library to model large motions of beams and
of flexible bodies exported from finite element programs. In
5th Modelica Conference, Vienna, Austria, September 4-5
2006.

R. E. Valembois, P. Fisette, and J. C. Samin. Comparison of
various techniques for modelling flexible beams in multibody
dynamics. Nonlinear Dynamics, 12:367397, 1997. ISSN
0924090X.

Dewey Hodges. Nonlinear Composite Beam Theory. AIAA,
2006. ISBN 1563476975.

Oskar Wallrapp and Simon Wiedemann. Comparison of results
in flexible multibody dynamics using various approaches.
Nonlinear Dynamics, 34(1-2):189, October 2003.

G. Jelenic and M. A. Crisfield. Interpolation of rotational variables in nonlinear dynamics of 3d beams. International
Journal for Numerical Methods in Engineering, 43(7):1193
1222, 1998.

S.C. Wu and E.J. Haug. Geometric nonlinear substructuring for
dynamics of flexible mechanical systems. International Journal for Numerical Methods in Engineering, 26:22112276,
1988.

744

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132735

Musculoskeletal Modeling of the Hand and Contact Object in
Modelica
Shashank Swaminathan1

Johan Andreasson2

1

2

Novi, Michigan, USA, sh.swami235@gmail.com
Modelon KK, Japan, johan.andreasson@modelon.com

Abstract
The paper's primary goal is to develop a mathematical
model that could be used towards the development and
improvement of orthotic assist gloves. The model is
constructed using component based modeling in the
object-oriented declarative language Modelica,
specifically the MultiBody Modelica library. Multiple
hand models currently do exist; however, they are
mainly causal, and require separate development and
validation of mathematical solvers before use. By using
Modelica, the model is constructed from the systems
physical equations, thereby relieving issues regarding
validity of the models computational equations; the
acausality inherent in Modelica allows for model
development that more closely mirrors relations in the
physical world. The model is scoped to be able to model
the kinematics and dynamics of the hand when grasping
a spherical object  both bone structure and muscle
geometry and actuation are simplifications based off
anatomy literature. The contact model is developed as a
separate component from the hand system. The main
design goal of the contact model is to represent the
characteristics of a relatively rigid object that still
maintains a degree of friction and pliability on the
surface layer.
The main two grasps tested in the paper are the
prehensile and precision grasps (powerful and dexterous
grasps). The muscle actuation profiles per each finger
are adjusted until the desired dynamic profile is
achieved for each type of grasp. The main data points of
interests are the joint angles and contact forces for each
finger. Further verification of the model is done using
the animation automatically generated by the tool.
Simulation testing results indicate that the model can
successfully simulate contractions at all levels of
abstraction of the hands components (basic bone-joint
components, finger components, and the overall hand
system). The results also indicate that both prehensile
and precision grasps are possible, given appropriate
muscle actuation and finger orientation parameter
values.
Keywordsmusculoskeletal model of hand; Modelica;
grasp model; orthotic gloves

DOI
10.3384/ecp17132745

1

Introduction

1.1 Relevant Background and Definitions
Patients recovering from a stroke, or those that have
Parkinsons disease, amongst many others, typically
experience muscle weakness in the upper extremities.
The use of orthotic devices in such situations is an
effective method of returning a modicum of motor
control to patients. Multiple such orthotic devices have
been developed, including, but not limited to, gloves
(Radder et al, 2015), (Adler, 2016), braces (Linn et al,
2012), and soft-muscle pneumatic tubes (Yanchev,
2015; Polygerinos, 2015). However, many of these
devices, must be specially constructed per each patient,
and requires multiple rounds of testing and data
acquisition before completion. Constructing a
mathematical model would enable a better
understanding of the orthotic device, as well as optimize
its construction. The prerequisite to developing a model
of an orthotic device, is the development of a model for
the underlying system, the hand.
Hand modeling has been typically done as a system
of rigid bodies connected through revolute joints e.g.
(Griffin et al, 2000). The papers derive the full set of
equations of motion of the hand from this physical
concept e.g. (Tarmizi, 2009).
From (Marieb, 2000), neural impulses trigger
protein-based reactions that leads to overall muscle
contraction, proportional to the neural impulse strength.
Since the purpose of this paper is not to model the neural
aspects, we will abstract this as an actuation request for
a percentage of total muscle force.
In this paper also, the hand is modeled as composed
of rigid bodies connected by revolute joints. The joints
have restrictions on the total angle of rotation, and
muscle actuation is added to the fingers appropriately.
(Hicks et al, 2015) observes that mathematical
modelers have a dual responsibility of verifying and
validating both the physical equations in the model, and
the mathematical solving components of the model. We
aim to significantly reduce this challenge by keeping the
physics of the system well-removed from the
mathematics required to solve the models. This is
achieved by using Modelica (Modelica, 2013) as the
modeling language to describe the physical equations of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

745

Musculoskeletal Modeling of the Hand and Contact Object in Modelica

the hand, and Modelica-supporting tools  specifically
Dymola
(Dymola,
2017),
OpenModelica
(OpenModelica, 2016), JModelica (JModelica, 2016),
and Wolfram SystemModeler (SystemModeler, 2015) 
to mathematically solve the model. The choice of
language was made due to Modelica's object-oriented
unique nature; the systems can be broken into
components, and each component's behavior can be
represented solely through its physical equations. The
separation of the physical and mathematical aspects of
the system, with the user only interacting with the
physical equations, and the tool handling the
mathematical portion, enables focus only on the validity
of the physical equations of the model.
The model utilizes the MultiBody library (Otter et
al.,2003), which contains many components dealing
with three-dimensional rigid bodies, further reducing
the user burden.
To check the performance, the hand model performs
prehensile (powerful) and precision (gentle) grasps
around spherical objects. The grasps are derived from
the taxonomy of grasps defined in (Cutkosky, 1990). To
investigate such motion, a model of a contact object is
also required; given the various levels of potential
abstraction available while developing the contact
object, this is addressed separately in the paper.

1.2 Objectives
The goal for the work described in this paper was to
build a prototype mathematical model of the hand, in
Modelica, that can describe the kinematic and dynamic
interaction between the bones, joints, and natural or
artificial muscles and tendons, such that it can be used
to:
1. Simulate the curling and extension motion of the
finger based on activation of the posterior muscles
and anterior muscles.
2. Simulate different types of grasping motions;
specifically simulate prehensile and precision
grasping motions around a spherical object.
3. Visualize the simulation of the finger motions
through three-dimensional animation.
4. Capture the contact forces on the fingers resulting
from muscle actuation around the spherical object.
In Section 2, the physiological considerations in
modeling the hand are discussed, including the
necessary assumptions made. In Section 3, a closer look
is taken at the hand model itself, involving both a
component-by-component inspection, as well as a
broader view at the package hierarchy. Section 4 follows
with detail on the structure of the contact model
developed in this paper. Sections 5 handles the
simulation of the models, as well as the corresponding
analysis. Section 6 provides the final remarks and closes
the paper.

746

2

Approach to the Physiology

The bones in the hand are treated as rigid bodies, and
joints are modeled as a set of revolute joints, the number
depending on the degrees of freedom in the joint's
motion.
The muscles in the hand are composed of numerous
sarcomeres (muscle fibers); these muscle fibers actuate
in unison to produce the overall muscle force. The
model of the muscle abstracts this actuation process into
one total force - the input to the muscle component is
the percent of the total muscle being actuated, and the
output is the product of the percent value and the
parameter value for the total muscle force (Marieb,
2000). This is done as sarcomeres actuate in an all-ornothing manner; hence, for the muscle to vary the force
of contraction, it must vary the total amount of
sarcomeres firing  in essence, activating a portion, or
percentage, of the total possible muscle force.
The muscle's complex structure is broken down into
multiple line segments moving between attachment
points, as an approximation to the curve, demonstrated
in Figure 1.
The attachment points function as the skin, limiting
the muscle to conform to the physiology of the hand
itself. The nature of skin as a dividing middle layer
between a bone and an object is included in the contact
model. It acts as a buffer layer between the direct contact
between the bone and object, serving to add a degree of
compliancy. The tendons are assumed to act in
conjunction with the muscles as massless bodies that
connect contracting muscles with appropriate bone
structures.

Figure 1: Finger Model Approximation schematic

3

Hand Model

3.1 Modeling Approach
The musculoskeletal aspect of the hand can be broken
down into component-based construction using bones
and muscles. The basic component considered to have
similar functional properties to the hand is called the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132745

Session 10C: Mechanical Systems Modelling

Bone-Joint-Bone component; it is constructed using two
bones, a connecting revolute joint, and actuating
muscles on both the anterior and posterior side.
BONE-JOINT-BONE COMPONENT
BONE

JOINT

BONE

Figure 2: Bone-Joint-Bone Component Structure
A finger can be considered an extension of this idea;
rather than having two bones and one joint, there are
multiple bones, and multiple joints, between joints for
normal flexing motion as well as sideways motion.
Figure 5: Schematic of a Basic Muscle-Joint
component

FINGER COMPONENT
ANTERIOR MUSCLES
BJBC

BJBC

3.3 Finger Component
BJBC

The finger is constructed by fusing two BJBCs and one
DBJBC, to make four bones (metacarpal and phalanges)
connected by three joints (metacarpophalangeal and
interphalangeal joints)  as seen in Figure 6A.

POSTERIOR MUSCLES

Figure 3: Finger component structure
The hand itself can be thought of as the joint
workings of multiple fingers in unison, connected
through a bone structure representing the wrist.

FINGER

HAND MODEL

Figure 6A: Schematic of the Finger Bone Model

WRIST

Figure 4: Hand Model Structure
The modeling approach relies on the component
breakdown detailed above. By relying on the basic
Bone-Joint-Bone component structure, the finger bones
and the overall hand are constructed. Muscle
components are added as appropriate to actuate the
joints present.

There are muscle components for both the anterior and
posterior side, connected to the bone at the attachment
points (as seen in Figure 6B).

3.2 Bone-Joint-Bone Component
This component (BJBC) represents the basic structure
of the bones and joints in the hand. The component is
constructed using two rigid bodies representing bones,
connected by a revolute joint representing a finger joint;
there are attachment points designated on the bones as
areas the muscle will actuate upon. The Double-JointBone (DBJBC) component is an extension of this idea,
with an additional degree of motion added to the joint,
to allow sideways motion.

DOI
10.3384/ecp17132745

Figure 6B: Schematic of the Finger Muscle Model

The finger model additionally contains elements that
model interface to a contact object, and is discussed in
the next section; this is shown in Figure 6C.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

747

Musculoskeletal Modeling of the Hand and Contact Object in Modelica

the muscle components, and contact object models.
There also exist examples for each type of system,
namely the basic bone-joint system, the finger-andcontact system, and the hand-and-contact system.

4

Figure 6C: Schematic of the Full Finger Model

Contact Object

The contact object is modeled essentially as a semi-rigid
sphere  a combination of nonlinear spring and damper
systems that only exerts a force on the bone when a
contact event occurs (below is a diagram of the contact
object).

3.4 Hand Component
The model is created by instantiating multiple finger
components, each at a different position and orientation
relative to the inertial frame. The non-opposable fingers
each have axes of rotation rotated slightly (about 15
degrees) relative to each other, while the opposable
fingers axis of rotation is almost opposite to the axes of
the other fingers.

Figure 9: Spherical Object Contact Model

Figure 7: The Hand Component

3.5 Package Structure
The overall PowerGrab library consists of one main
package, PowerGrabStructure (as seen in Figure 8),
and a separate package for test models, named
PowerGrabTestingRig (not shown in the figure). The
division was made so that the main models can be
assuredly independent of the testing models and other
older versions.

The object is represented as the combination of a point
defining the center of the contact object, and a connector
component between the object center and the potential
point of contact on the bone. Each connector component
details the contact dynamics between the contact object
and the specific bone segment the component is
connected to. Having separate connectors per each bone
segment allows there to be multiple contact points per
finger, one per each bone segment (for a maximum of 4
points per finger). However, as the connector follows a
straight line, the contact is restricted to occur at a single
point per each bone segment. Furthermore, as the
contact model is designed for a spherical object, later
models for other object shapes must be independently
developed.

4.1.1 Determining the point of contact

Figure 8: Package Structure

We define vector " as the direct path from the base of
the bone to the center of the contact object. Next, we
define a vector perpendicular to the bone, # , by
subtracting the projection of the vector " along the
length of the bone from " . Should the magnitude of #
fall below the radius of the object, we can then
determine that contact has occurred.
# = "  "  ()*+ ()*+ 	

The PowerGrabStructure package contains the main
components of the library, including the bone structures,

The actual implementation of this strategy in
Modelica is simplified using a relative position sensing

748

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132745

Session 10C: Mechanical Systems Modelling

component and a prismatic joint. A prismatic is attached
to the base of the bone, and is free to slide along the xaxis, as resolved in the frame of the bone. Using a
relative position sensing component between the center
of the contact object and the nonmoving base end of the
prismatic joint, resolved in the frame of the bone, the
vector for the relative position of the center of the object
is found. The component of that vector along the bone
is determined (as the x-component of the vector, as it is
resolved in the frame of the bound), and is subtracted
from the overall relative position vector. This leaves us
with the component of the vector that is perpendicular
to the bone, which is the vector desired.
If and as the finger slips along the object, both the
number and location of contact points will be updated
accordingly.
4.1.2 Determining the force of contact

As the contact object is spherical in nature; this allows
for the following abstraction: the object is a spring that
has a relaxed length of 0, with a nonlinear stiffness that
becomes nonzero only when the stretched length is
below a certain threshold (thus creating a zone of
nonzero stiffness described by a threshold radius ).
The force equation is thus as follows:
   #  # ,
|# |  
0 # =
	
0,
|# | > 
Apart from the normal contact force between the
object and the bone, an additional force representing the
effect of skin on contact is also applied. This is
considered as a "buffer layer", as the skin will meet the
contact object before the bone, thus acting as a buffering
between the two. The skin is considered to have some
pliability, and is therefore modeled as a spring
connection between the contact object and the point of
contact on the bone. Due to modeling purposes, the skin
is assumed to be layered around the contact object rather
than the bone itself, as it allows for the approximation
that the skin-caused buffering force 89::+; 1 acts
in the same manner as the normal contact force, albeit at
a larger threshold range. This extension in force and
range is reflected in the parameters  and  ,
respectively.
,
1   + 
89::+; 1
	
0,
1 >  + 
4.1.3 Determining the friction due to contact

The friction due to the contact between the bone and
contact object is represented as a damping on the sliding
motion across the surface of the contact object. The
magnitude of damping is 0  A9;:BC+ . The normal
force magnitude is equal to the magnitude of the contact
force on the bone, and the surface velocity is determined
as the magnitude of the result of subtracting the vector
DOI
10.3384/ecp17132745

component of the relative velocity between the bone and
contact object that is parallel to the radius from the
overall relative velocity vector.
;+D = ()*+  )(E+CF 	
A9;:BC+ = ;+D  ;+D 

5

#

#

#

#

Simulation

5.1 Component Testing
The purpose of the component tests is to determine if the
components performance conforms to the expected
result. To test the bone structure components, muscle
components are instantiated in the test models, to
actuate the bone structures.
5.1.1 Bone-Joint-Bone Component Test

The muscle actuation profile alternates between
actuating the anterior muscle and actuating the posterior
muscle, with small intervals of overlap. As seen in
Figure 10, the limits on rotation are -0.5 and 1.6 radians,
and the system can successfully reach those limits
following sustained muscle activation. As the desired
functionality is for the component to be able to undergo
such motion, we conclude that the Bone-Joint-Bone
Component can adequately support our needs.

Figure 10: (Unit Level) test of BJB component
5.1.2 Double-Bone-Joint-Bone Testing

Like the Bone-Joint-Bone components test, the DBJBC
component also utilizes muscle components to actuate
the bones in the system. As seen in Figure 11, we actuate
the side muscles using the same muscle activation
profile used for testing BJBC component, while keeping
the other muscles inactive. The following angular
displacement occurs in the Side Joint (note that the
limits on the angle of rotation is different between the
joints).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

749

Musculoskeletal Modeling of the Hand and Contact Object in Modelica

Figure 11: (Unit Level) test of the DBJB component:
Side joint actuation only

Of special interest is the relationship between
sideways motion and forward motion. It is reasonable to
expect that, due to coupled dynamics, forward motion
will cause motion sideways, and vice versa. In Figure
12, both the Forward Joint and the Side Joint are
actuated. For the Forward Joint, it is sequential
activation of the anterior and posterior muscles. The
Side Joint follows the same activation profile used in the
previous tests, and correspondingly experiences motion
as seen in Figure 12 (bottom graph). There are also
slight additional movements in the side joint, in
conjunction with change in direction of movement in the
forward joint, which can be attributed to the coupled
dynamics.

Figure 12: (Unit Level) test of the DBJB component,
with simultaneous side and forward actuation
Similar to the requirements for the Bone-Joint-Bone
component, the requirement for this component is to be
able to undergo such movement given appropriate
actuation, without too much deviation from smooth
motion. As such, we determine that this component is
suitable for use.
5.1.3 Finger Component Test
5.1.3.1

Finger Testing without Contact Object Results:

The finger muscles were sequentially actuated to
enable flexion and extension. The activation is done in

750

a square wave pattern, as seen in Figure 14 (bottom),
and alternates the anterior actuation with the posterior
actuation. The resulting joint angles (Figure 14 top)
indicate that the model successfully captures contracting
motion, with the finger curling when the anterior
muscles are actuated, and extending when the posterior
muscles are actuated. A screen capture of the animation
of the testing is seen in Figure 13.
These test results, in conjunction with the test results
shown in the previous section, indicate that the first goal
of the paper has been satisfied (to simulate the curling
and extending motion of the fingers through actuation
of the muscles.

Figure 13: Animation of No Contact Finger
Component Test

Figure 14: Curling and extension tests for Finger
model
5.1.3.2

Finger Testing with the Contact Object Results:

The previous test was repeated, but with the addition of
a spherical contact object placed in front of the finger.
The actuation profile is a staggered sequential activation
from the proximal phalange to the distal phalange. The
tests goal is to have the finger curl around the contact
object when the object is positioned both directly in
front of the finger, and positioned in front with a small
offset to the side. As seen in Figure 15 below, when the
object is directly in front, the finger curls around the
object without slipping to the side. (Note that the middle

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132745

Session 10C: Mechanical Systems Modelling

phalange and distal phalange contact the object at the
same time, and that the side joints angle is constant at
zero).

Figure 17: Finger contacting spherical object with
offset
Figure 15: Finger contacting spherical object headon
Figure 16 shows a screen capture of the animation of
the head-on contact with the spherical object.

Figure 18: Animation of Finger contacting spherical
object (front and side views)

The finger, during each trial, undergoes motion that
conforms to expectation on how it should behave, and
so is considered successfully tested.
A limitation observed is that the frictional force
model, along with the high stiffness associated with the
object's normal force, causes computational strain on the
numerical solver during model simulation.
Figure 16: Animation of the Finger contacting
spherical object head-on
The experiment is repeated with the object placed with a
small offset. As seen in Figures 17 and 18 below, the
finger still contacts the object, but proceeds to slide across
the surface for a short period.

DOI
10.3384/ecp17132745

5.2 Hand Grasping Tests
The two grasps tested for in simulation were the
prehensile and precision grasps. The precision grasp is
a grasping motion that relies on relatively minimal
muscle actuation to lightly hold the contact object; a
prehensile grasp is when the muscles in the hand actuate
to fully grab, and squeeze, the contact object in question
(Cutkosky et. al., 1990).
The testing of the hand model, consisting of five
finger component instantiations, is similar to the contact
object test for the individual finger component. The
muscles of the hand actuate, and cause the hand to
contract. The purpose of the test is to determine if the
hand can both perform a prehensile circular grasp
around the ball, or a precision circular grasp around the
ball. Separate actuation profiles were used for the
prehensile grasp and the precision grasp.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

751

Musculoskeletal Modeling of the Hand and Contact Object in Modelica

Correspondingly, the object was placed at two different
locations, depending on the type of grasp.
The results of the prehensile grasp (Figure 19)
indicate that the fingers make and maintain contact with
little sliding through the testing  all except the little
finger  as indicated by the minimal movement in the
side-joints angle. The contact objects small radius of
only 2.75 cm, in comparison to the fingers of average
length 15 cm with diameter 2 cm, was chosen to
demonstrate a typical hand grasp. The opposable fingers
can maintain a firm grasp on the object, like how actual
hands maintain holds on small objects. Some slipping
occurs because there is not enough friction between the
surfaces. The sliding motion could not be further
reduced by increasing the friction, as doing so caused
numerical issues; however, the slipping did not occur
indefinitely, due to the side joints resistance to motion
(as mentioned in Section 3.2.1).

well. During the entire grasp, there is minimal slipping
exhibited at all the contact points.
The hand testing, for both the prehensile and the
precision grasps, displayed both the contracting motion
and the grasping characteristics desired.

Figure 20: Precision Grasp Simulation

6

Conclusions

6.1 Results Summary
Implication with respect to Paper Goals:
The primary goals of this study were to be able to:

Figure 19: Prehensile Grasp Simulation

For the precision grasp, only the proximal phalanges
were actuated, and the object was located closer to the
distal phalanges. As seen from the results in Figure 20,
contact occurs only as the distal phalanges  the little
finger does not contact the object entirely, as it does not
reach the object. Looking at the joint angles, we see that
the proximal joints motion stops soon after the distal
phalange contacts the object. The distal phalanges start
to bend backwards upon with the object, as reasonably
expected  once the distal phalanges stop bending
backwards, the proximal phalanges motion stops as
752

1. Simulate the curling and extension motion of the
finger based on activation of the posterior muscles
and anterior muscles.
2. Simulate different types of grasping motions;
specifically - specifically simulate prehensile and
precision grasping motions around a spherical
object.
3. Visualize the simulation of the finger motions
through three-dimensional animation.
4. Capture the contact forces on the fingers resulting
from muscle actuation around the spherical object.
As seen from the results, goals 1, 2, 3 and 4 were
successfully achieved.

6.2 Development Review
The initial construction of the model was done in
Wolfram SystemModeler; the later models were
developed in Dymola, leveraging its user-friendly
refactoring and model creation capabilities. For
compilation, debugging, and simulation capability,
JModelica was used. OpenModelica was then separately
utilized for animation (with simulation). All three
services, apart from OpenModelicas lack of a

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132745

Session 10C: Mechanical Systems Modelling

CVODES solver, did not require major tool-specific
code alterations to run. This allowed for smooth
transition between tools during model development and
testing. The non-tool-specific functionality of Modelica,
and the support for Modelica from the tools
SystemModeler,
Dymola,
JModelica,
and
OpenModelica, were extremely useful for this
packages creation.

6.3 Further Work
Much of this model was based off simplifications to
get the models and simulations running  future work
should focus on refining these model assumptions.
6.3.1 Musculoskeletal Model Improvement

Models of both the bone structure and the muscle
geometry can be improved from its current state. The
bones physical parameters, including bone lengths and
finger orientations, should reflect the actual structure of
the bones. Currently, most parameters were chosen from
an average of measurements taken of a group of
volunteers; parameters not gathered from measurements
were chosen arbitrarily. Using data selected from
studies on hand dimensions and appropriately large
ranges of volunteers would improve the validity of the
resulting forces and motion involved in grasping. The
muscles are currently modeled through linear line force
segments between a limited number of attachment
points to approximate the muscles curve  this could be
expanded by better representing the multiple interacting
muscles and tendons, and their corresponding muscle
geometries. Further improvements with the muscle
actuation dynamics are also possible.
6.3.2 Contact Model Improvements

The current contact model is based around a
spherical object; this should become more generalized,
for multiple geometrical shapes and surfaces.
Furthermore, the model currently assumes that each
interacting bone will have a maximum of one tangential
contact point, and that skin acts as a mere buffer  the
models should account for the hands relative flexibility
and pliability. Lastly, the friction model is constructed
as a type of surface damping, but it would be more
appropriate to include Coulombic friction as well. As
the contact object was developed in an ad-hoc manner,
improvements can be made by integrating standard
existing contact model approaches.
6.3.3 Testing Improvements

The testing of the hand grasping motion should be
improved such that the muscle actuation profiles are not
arbitrary pulses, but an imitation of natural activation
profiles. Moreover, future work should also integrate
experimental datasets from muscular grasps to make
testing result analysis more accurate.

DOI
10.3384/ecp17132745

References
Cutkosky, M. R., & Howe, R. D. (1990). Human Grasp
Choice and Robotic Grasp Analysis. In S. T. Venkataraman
& T. Iberall (Eds.), Dextrous Robot Hands (pp. 5-31).
Springer-Verlag.
Griffin, W. B., Findley, R. P., Turner, M. L., & Cutkosky, M.
R. (2000). Calibration and Mapping of a Human Hand for
Dexterous Telemanipulation. ASME IMECE 2000
Conference Haptic Interfaces for Virtual Environments and
Teleoperator Systems Symposium. Retrieved from
http://wwwcdr.stanford.edu/DML/publications/griffin_asme00.pdf
Adler A, GM-NASA Space Robot Partnhership brings
Power Glove to Life, GM Corporate News
announcement,
2017
July
6th,
http://media.gm.com/media/us/en/gm/home.detail.html/co
ntent/Pages/news/us/en/2016/jul/0706-gm-nasa.html
Linn D. M., Ihrke A. C., Diftler M. A., Human grasp assist
device and method of use, US Patent No. 8255079 B2,
2012.
Polygerinos P, , Galloway K. C., Savage E., Herman M., O
Donnell K, and Walsh J. C., Soft Robotic Glove for Hand
Rehabilitation and Task Specific Training, 2015 IEEE
International Conference on Robotics and Automation,
May 2015, doi: 10.1109/ICRA.2015.7139597
Yanchev
T,
Power
Assist
Gloves,
https://www.youtube.com/watch?v=gzfZCTYREww 2015
van Nierop, O. A., van der Helm, A., Overbeeke, K. J., &
Djajadiningrat, T. J.P. (2007). A natural human hand
model.
The
Visual
Computer,
24(1).
http://dx.doi.org/10.1007/s00371-007-0176-x
Gustus, A., Stillfried, G., Visser, J., Jrntell, H., & van der
Smagt, P. (2012). Human hand modelling: kinematics,
dynamics, applications. Biological Cybernetics, 106(11).
http://dx.doi.org/10.1007/s00422-012-0532-4
Wan Tarmizi, W. F. B., Elamvazuthi, I., & Begam, M. (2009).
Kinematic and Dynamic Modeling of a MultiFingered robot
Hand. International Journal of Basic & Applied
Sciences, 9(10). Retrieved from http://ijens.org/index.htm
Marieb, E. N. (2000). Essentials of human anatomy and
physiology (6th ed.). San Francisco: Benjamin Cummings.
Otter, M., Elmquist H, Mattson S. E., The New Modelica
Multibody Library, Proceedings of the 3rd International
Modelica Conference, Linkopig, 2003
Tiller, M. (2014). Modelica by Example. Retrieved from
http://book.xogeny.com/
Modelica (2013) - A Unified Object-Oriented Language for
Physical Systems Modeling, Language Specification

https://modelica.org/documents/ModelicaSpec32Revisi
on2.pdf
Hicks J. L., Uchida T.K., Seth A., Rajagopal A., Delp S.L., Is
my model good enough? Best practices for verification and
validation of musculoskeletal models and simulation
environment, Journal of Bioengineering, Vol 137, Feb
2015.
Radder, B., Kottink AIR, van der Vaart N, et. al, Usercentred input for a wearable soft-robotic glove supporting
hand function in daily life, 2015 IEEE International

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

753

Musculoskeletal Modeling of the Hand and Contact Object in Modelica

Conference on Rehabilitation Robotics (ICORR),
Singapore, 2015, doi: 10.1109/ICORR.2015.7281249
Dymola (2017) Copyright  Dassault Systmes, 1992-2016
http://www.3ds.com/productsservices/catia/products/dymola/
SystemModeler (2015) Copyright  2015 Wolfram Research,
Inc. http://wolfram.com/system-modeler/
OpenModelica (2016) Copyright Open Source Modelica
Consortium (OSMC) https://www.openmodelica.org/
JModelica (2016) from http://jmodelica.org/

Authors Notes

I was first introduced to Modelica during an
internship at Xogeny in the summer of 2014, as a
freshman in high school. This led to me modeling a flat
linear motor I had previously built by hand. The linear
motor consisted of multiple solenoids sequentially
activated by an Arduino, to propel a cart down metal
tracks. It was developed in an ad hoc manner, and
adjusting the design was difficult; I felt that modeling
was a nicer way of doing these kinds of tasks.
When noticing elderly persons having trouble
opening doors and holding jars, I began thinking of ways
to devise an orthotic glove to assist them. To gain a
better understanding of the system, I decided to first
develop a mathematical model of the hand. I began
working on the PowerGrab project as a summer intern
at Modelon KK, under the supervision of Dr.
Andreasson. Since then, I have continued to work on
developing the code for the PowerGrab library, as well
as writing the corresponding paper, with the continued
guidance of Dr. Andreassons comments and feedback.
My Background:
Shashank was born in Michigan, USA, and is
currently a senior in high school. He was a summer
intern at Modelon KK and Modelon, Inc., and is
currently in the Wolfram Mentorship Program.

754

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132745

Modelica Spur Gears with Hertzian Contact Forces
Markus Dahl1
1 Wolfram

Hkan Wettergren1

Henrik Tidefelt1

MathCore, Linkping, Sweden, {markusd,hakanw,henrikt}@wolfram.com

Abstract

1.1

To be able to capture the dynamics of entire systems
is one of the strengths of the Modelica language. This
article will examine the possibility of modeling spur
gears in the Modelica environment Wolfram SystemModeler, and integrating them with other rotating
machinery elements, such as roller bearings and flexible shafts. The contact forces between spur gears are
based on the Hertzian Theory of Contact1
Keywords: Spur Gear, Hertz Contact Theory, Rotating Machinery

Several papers have been written regarding modeling gears in the Modelica language. Special attention
has been seen in the area of powertrains. One of the
original papers is (Otter et al., 2000) where the PowerTrain package was presented.
The package PowerTrains contains 1-dimensional,
rotational mechanical systems. I.e. a lot of simplifications have been made to be able to model the complete driveline. At that time it was a state of the art
approach. However, the very idealized components
in that library cannot be used for any advanced dimensioning or root cause analysis. The description
of the components are very simplified compared to
the special simulation tools that exist in each specific
machine element area.
During the years, several of the components have
been refined. One work is (van der Linden and
de Souza Silva, 2009) where a 3-dof elastic model
was used which included the elasticity of the support
bearings in the load direction, which was not possible in the standard gear model. The model was then
extended in (van der Linden, 2012) to also include a
Gear Contact Model. A later paper, (van der Linden,
2015) compared the results from a Modelica model
that investigated gear contact to tests.
A much more detailed approach was taken by
(Kosenko and Gusev, 2011) and further improved in
(Kosenko and Gusev, 2012), where the forces between
gears were modelled with high detail in a Modelica
environment.

1

Introduction

Gear contact forces can be accurately modelled by
fem programs, but usually at a high computational
cost. The focus is usually on solving the force equations statically, where some dynamics might be lost.
A common way of calculating the dynamics is to add
a so called application factor to the static solution,
approximating the dynamic result. By using a Modelica model instead, the dynamics can be included in
the model, replacing the application factor. To be
compatible with other libraries, the models here are
based on the MultiBody library from the Modelica
Standard Library. The choice of using a 3D mechanical library instead of libraries such as PlanarMechanics (Zimmer, 2012), is to be able to keep building on
these models to handle helical and other type of gears.
Another benefit of Modelica models is that they
can be used with other rotating machinery elements.
Lets say that a wind turbine gear box should be analyzed. This gear box contains inner and outer spur
gears, flexible shafts, and roller bearings. If a Modelica model is used for this purpose, we can see both
how the spur gears affect the bearings, the shafts, as
well as how the shafts and bearings affect the gears.
Therefore, the dynamics of the entire system can be
captured and analyzed.
In Section 2, the gear geometry of a spur gear will
be introduced. Following that, Section 3 will be an
introduction to the Hertzian Contact theory. Section
4 will explain how this was implemented in Modelica.
Section 5 will go through some examples where the
gears were used. Finally a discussion of the results
will follow in Section 6.
1

As found in Roarks Formulas for Stress and Strain, 2002

DOI
10.3384/ecp17132755

2

Previous work

Gear Geometry

This section describes the geometrical modeling of
two gear wheels that are in contact or in close proximity. Starting with the geometry of a single gear
wheel, we then proceed with the geometry of the interaction between two gear wheels, before going into
more advanced topics such as tip relief and the geometry involved in triggering events in a Modelica
model.

2.1

Geometry of a gear wheel

A gear is basically a toothed wheel aimed to transmit
rotation from one shaft to another. Spur gears, that is
the focus in this article, can be described as parallelaxes gears without a helical angle. The gears can be of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

755

Modelica Spur Gears with Hertzian Contact Forces

ra

b
r

r



p

c

a

Figure 1. Involute of a circle. The involute (thick line) is
traced by mapping each angle  to the point p by going the
distance r along the circle from point a to point b, and then
going the same distance back along the tangent to point p.
Note the right angle at point p. The involute obtained by
this procedure creates an involute corresponding to a rear
flank of a gear tooth. Mirroring the procedure creates a
front flank, drawn with a dotted line.


rb t

n

sb

rb

rear

k

r

ront
pf

p

Figure 3. Intersection between gear flank and a tangent
of the base circle. Also showing the derived quantity sb ,
and the additional parameter ra . Vector k points to the
point on the tooth where the involute begins. The point p
is then obtained from the rolling angle, , and rb . The front
flank is where force is transmitted when applying torque in
counter-clockwise direction, and the rear flank when applying clockwise torque.)

of the circle involute, is a fundamental property of
involute curves.
There are four geometrical parameters that need to
Parameter
Description
be specified for a spur gear in our case, listed in Taz
Number of teeth in gear
ble 1. These parameters are shown in Figure 2. From
m
Gear module
these user-specified parameters, many other quanti0 = 20
Reference profile angle
ties are derived, see Figure 3. For example, one can
x
Profile shift factor
derive the tooth base thickness, sb , and also express
a standard choice of ra , as


two types, inner gear (a ring with teeth on the inside)
sb =
+ 2x tan 0 + z inv 0 m cos 0
(1)
2
and outer gear (a wheel with teeth on the outside. For

z
clarity of presentation, only outer gears are considered
ra = m
+x+1
(2)
2
in this section.
One of the main reasons for the broad use of gears where inv 0 = tan 0  0 .
is the efficiency of the transmission, which depends
The signed rolling angle, , is related to the inner
on shape of the teeth. The most common shape of a product of the unit vectors k and t,
tooth is a circle involute. A circle involute or simply


involute, is a curve following the end point of a tan
(3)
< k, t > = cos
2
gent that is rolled up from a circle. It is defined by
the geometry in Figure 1. The right angle at point from which it can be solved reliably.
p, between the tangent of the circle and the tangent
Table 1. Gear wheel geometry parameters.

2.2

m2

0

+
m

2x

mz
2

n

ta

rb

m


z

0

2
z

Figure 2. Gear wheel geometry parameters in an outer
spur gear. The radius of the base circle, rb is easily derived
from the gear wheel parameters z, m, and 0 . The effect
of the profile shift, x, is best understood in relation to a
straight gear reference profile, but the derivation is out of
scope in the current presentation.

756

Line of contact

Contact between two gears always occur for either
front-front flank contact, or rear-rear flank contact.
For each of the two contact cases (front or rear), there
is a line of contact (LoC ), along which the contact
between the teeth will be located. The front and rear
contact cases are analogous, and to avoid going into
details about sign conventions, only the front case
will be considered from here on. Using the wheel
positions, the distance between these points, aw can
be related to the angle of LoC, w . See Figure 4.
aw =

m
cos 0
(z1 + z2 )
2
cos w

(4)

Here, the indices 1 and 2 mean gear wheel 1 and
gear wheel 2 respectively. The LoC normal (in two

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132755

Session 10C: Mechanical Systems Modelling

modules, which makes the effect on the LoC negligible. The new tooth shape with tip relief can then be
calculated by the following standard equation:

LoC
rb,2

c2

v() = q(  a )

aw
c1

w
rb,1

(8)

where q is a coefficient to ensure that the amplitude
is obtained correctly, and a is the maximum value
for the roll angle. How much of the tooth that is
removed can be specified by setting the distances c
and d, defining the tip relief amplitude and tip relief
length, respectively.

n

Figure 4. Line of contact of two gears, for contact between
front flanks on the teeth (transmitting force when either
gear is driving with positive direction of rotation). The LoC
for contact between rear flanks is obtained by reflection in
the line through the gear centers.

2.4

Tooth pair activation

A pair of teeth in contact are identified by one integer
index on each gear, i1 and i2 . Together with the rotations of the axes on which the gears are mounted, 1
and 2 , the directions k1 and k2 pointing at the starting points of the involutes on the base circles follow,
dimensions), n, can then be expressed using the angle
which in case of front flank contact are given by
w , as
!
cos 1
sb,1
2
(rb1 + rb2 )
+ i1
+ 1
(9)
k1 =
1 =
cos w =
(5)
2rb,1
z1
sin 1
||aw | |
!
q
cos

sb,2
2
2
2
sin w =  1  cos w
(6)
k2 =
2 =
+ i2
+ 1
(10)


2rb,2
z2
sin 2
aw
cos w sin w
n =
(7)
 sin w cos w ||aw | |
As was shown in Figure 3, the rolling angles follow for
any given direction of the LoC. In Figure 6, the front
where the sign of sin w reflects the choice between
flanks corresponding to indices i1 and i2 are marked
LoC for clockwise or counter-clockwise rotation.
with a thick line. As the gears rotate, the current
A point p on the flank of a tooth can now be detooth pair will become disengaged, while other pairs
scribed using w , the LoC, rb , and the center position
will become engaged. An index skip, i , is chosen by
of the gears, ci .
upward rounding of the gear contact ratio. DependIn order to determine contact forces between two
ing on the direction of rotation, the next tooth pair to
gear flanks, we define an indentation depth,  measurfollow when the current pair has become disengaged
ing the amount of intersection between the teeth. The
is selected as
depth is modeled using the points p1 and p2 , where
the gear flanks intersect with the LoC.
i01 = i1  i
(11)

Tip relief

i02 = i2  i



rb

c

k2

rb,2
2
i 2

v() c
d

+
ra,1

2
a,2

ra,2


i2

i1+2

ra

(12)

2
i 2+

To get a smooth contact force, a modification of the
tip is usually done, called a tip relief. This can be
done by removing a small portion of the tooth, as
shown in Figure 5. The LoC will be affected by this
modification, but the change is on the scale of 0.01

i1

2.3

1
rb,1

a,1

0

i12
k1

Figure 5. Gear with tip relief (exaggerated).

DOI
10.3384/ecp17132755

Figure 6. Slack variables used to control tooth pair activation for front flank contact. Here, i = 2, corresponding
to a configuration for a contact ratio between 1 and 2.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

757

Modelica Spur Gears with Hertzian Contact Forces

In Figure 6 where gear 1 rotates clockwise, the
change in i1 is with positive sign, while the change in
i2 is with negative sign. The slack angle + measures
how much the rolling angle 1 may decrease until it
is absolutely necessary to consider interaction for the
tooth pair i01 and i02 . Analogously, when gear 2 rotates
clockwise,  measures how much the rolling angle 2
may decrease until it is absolutely necessary to consider interaction for the tooth pair in the opposite
direction. The slack angles are given by
2
 a,1
z1
2
 = 2 + i
 a,2
z2
+ = 1 + i

(13)
(14)

In the Modelica model presented in Section 4, the
tooth indices are updated such that the slack angles
are positive at all times. For robust simulation, it is
desirable to update indices with some margin until
it is absolutely necessary according to the slack variables. That is, we should avoid triggering the update
at the lower bound 0. When indices are updated because one of the slacks is getting too close to zero, that
slack variable will be reset to a large value, while the
other slack variable will be signifiantly reduced. We
will trigger based on the following conditions, where
 is a positive constant which remains to be determined,


2
+ <    i
Trigger positive change in i1
z2
(15)


2
 <  +  i
Trigger negative change in i1
z1
(16)
In order to avoid endless event iteration when updating the indices, it must be ensured that triggering a change in one direction does not reduce the
other slack so much that it satisfies the condition
for re-triggering a change in the opposite direction.
By equating the margin to the lower bound of zero
slack, with the margin to re-triggering a change
 in
the opposite direction, a natural choice of  = 51
2
is obtained.

3

Hertz Contact Stress

To calculate the force between two gear teeth,
Hertzian Contact Theory has been used. At the point
of contact, the two teeth are approximated by two
cylinders with parallel axes, see Figure 7.
The indentation depth, , is related to the contact
force by
=
758

2F (1   2 )( 32 + log( 4Rb 1 ) + log( 4Rb 2 ))
LEmod

(17)

Figure 7. Contact between two cylinders with variables.

where F is the force,  is the Poisson ratio, Emod is
Youngs modulus, L is the length of the cylinder, Ri
are the radii of the cylinders, and b is the contact
width2 . The contact width is modeled by
s
32F
b=
(18)
LEred ( R11 + R12 )
Here, Ered is a combination of the two gear wheels
material parameters


1 1  12 1  22
1
=
+
(19)
Ered 2 Emod1 Emod2
From (17) and (18), the force can be calculated as a
function of the indentation depth. The geometry of
the cylinders in contact will change when moving on
the LoC. This means that the curvature radii R1 and
R2 will be changing so that one of them will start
with a small radius and increase when moving along
the LoC, and the other will start with a big radius
and decrease when moving along the LoC.
The conditions for applying a force at the appropriate time is to check if the distance between the wheel
center ci and the point pi is less than the top radius of
the gear ra,i . Additionally, we also check if  is larger
than zero, i.e.
|c1  p1 | < ra,1
|c2  p2 | < ra,2
>0

(20)
(21)
(22)

The effects of gear damping has not been included
in this model.
2
As found in Roarks Formulas for Stress and Strain, 2002,
Table 14.1.2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132755

Session 10C: Mechanical Systems Modelling

4

Modelica Model

The implementation of the spur gear model in Modelica is using the Modelica MultiBody library. This
means that there will be 3D animations for all models. For example, the contact force is visualized by
arrows between two teeth, as seen in Figure 8.
The topology of the model consists of a top layer
diagram where the layout is specified, i.e. how the
gear wheels are positioned and if a force should be
calculated between them. Figure 9 shows the Modelica diagram layer of a simple two wheel model with
contact between them.
The force between the two gear wheels is calculated inside the gearForceCalculation component.
The system of non-linear equations (17) and (18)
has multiple solutions, and the correct one is not Figure 10. Model of the component where gear forces are
calculated, containing four ContactForcePoints.

differentiable at  = 0. To handle this, the solution is approximated by a closed-form expression.
The gearForceCalculation class contains at least
four ContactForcePoint components, as seen in Figure 10. Each of these ContactForcePoints is responsible for calculating one force pair on one matching
teeth pair. Since the gear ratio should be above one,
but less than two in the case of two outer spur gears,
two force pairs are needed. Two more force pairs
(ContactForcePoint components) are needed due to
the two flanks on each tooth. If a gear ratio over 2
is possible, as in the case of a planetary gear between
the ring and a planet, more ContactForcePoints can
be added to handle this.
The contact ratio will be calculated automatically, depending on the geometry of the two gear
Figure 8. Two outer spur gears in contact, with arrows wheels in contact. This is used to assert that the
representing the contact forces acting on the gears. At this GearForceCalculation component is set up cormoment, two teeth pairs are in contact.
rectly.
Many parameters can be set by set user on the
GearForceCalculation component that will affect
the ContactForcePoints inside. The parameters are
listed in Table 2.
Table 2. GearForceCalculation parameters.

Parameter Description

Figure 9. Model of two gear wheels in contact.

DOI
10.3384/ecp17132755

m
L
zi
xi
i
Emodi
ci
di

Gear module
Contact width of wheels
Number of teeth in gear wheel i
Profile shift factor for gear wheel i
Poissons ratio for wheel i
Youngs Modulus wheel i
Tip relief amplitude for wheel i
Tip relief length for wheel i

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

759

Modelica Spur Gears with Hertzian Contact Forces

5

Example Models

Figure 9 showed a simple example with two outer
gears in contact, and no other components in the system. This can easily be expanded.

5.1

Effect of tip relief

Using the presented gear model, it is possible to compute dynamic effects in gears such as the variation in
contact stresses. Figure 11 shows the contact stress
for one tooth during a contact. In this case the gear
wheel support is fixed in all translational directions,
which means that there are no external vibrations afFigure 12. Contact pressure between two teeth with tip
fecting the result.
The contact starts with a transient, stabilizing to a relief.
lower force level, where two pairs of teeth in contact.
Then the other pair of teeth goes out of contact and
only the current tooth takes all force. After a while, a
new teeth pair will go into contact, and the force level
will drop again. Finally the current teeth pair goes
out of contact, and the force drops to zero. The reason for the transient is that all pair of teeth in contact
will have the same indentation depth, . Hence, when
a new pair of teeth goes into contact, the initial indentation depth at the tip of the incoming tooth will
be that of the one pair of teeth currently in contact.
The gears will then quickly adjust to the same total
torque of two pairs of teeth. To avoid the transient,
the tip of the involute shape is modified with a tip
relief, as was shown in Figure 5.
Figure 12 shows the much smoother contact pressure with tip relief.

5.2

Wind turbine gear box

A planetary gear box can be created by combining
inner and outer spur gears with flexible shafts. A
two-stage gear box is then connected to the planetary
gear box. A screenshot of the animation is shown in
Figure 13 and the model diagram is shown in Figure 14. This setup is capable of changing the angular
velocity from the slow rotation of the blades, around

Figure 11. Contact pressure between two teeth without
tip relief.

760

Figure 13. Animation of the wind turbine gear box model.

10 rpm, to the fast rotation of the generator, around
1500 rpm.
The contact forces are calculated at many different points in this system. In the planetary gear
there are forces between the center gear wheel (the
sun) and the three outer wheels (the planets), and
also between the three planets and the inner gear
wheel (the ring). With a possible contact ratio above
2, the GearForceCalculation components between
inner and outer gears (planet and ring) contain 6

Figure 14. A wind turbine gear box.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132755

Session 10C: Mechanical Systems Modelling

ContactForcePoints. In total, the system contains
38 ContactForcePoint components, making it possible to simulate this system with gear forces at all
points and all rotational directions. The gear can
be driven by any wheel, both clockwise and counterclockwise. In addition to this, the wheels are connected to flexible shafts that are fixed in a support.
In this setup, one could detect if there are any peaks
in forces between the gears, or if the flexible shafts
affect the gear in any significant way if the material
parameters for the beams changes. An example of
contact pressures in a steady state of the gear box
can be seen in Figure 17 on page 9.

5.3

Gear and bearings

Since rotating machinery elements affect each other
in various ways, it is important to be able to study
different elements together. An example of such and
interaction is when a system containing rotating flexible shafts with bearings, that sets the gear wheels
in motion. The bearings contain cylindrical rollers,
which have Hertzian contact forces between the inner
and outer ring of the bearing. A 3D visualization of
the setup is shown in Figure 15.
Two flexible shafts are supported by roller bearings. The bearings on the lower shaft are mounted on
flexible supports, that are fixed to the ground. The
lower shaft rotates at 600 rpm. One of the bearings
has an outer ring defect (top right bearing in figure
15). The visualization of the outer ring in this bearing
has been removed to give a better view of the rollers
inside the outer wheel. This defect will in this case

Figure 16. Acceleration in the vertical direction, with a
red highlighting at impact points, as predicted by the shock
pulse method.

cause an extra downward force to be applied at the
"12 oclock" position when a roller passes this point.
Vibration analysis of a damaged bearing is usually
a quite complicated task. A frequency spectrum will
normally not show a small bearing defect. Instead
different kinds of shock pulse methods have been developed. The signals are normally at rather high frequencies. In this example the time of impact has been
marked with red lines. As can be seen in figure 16, the
accelerations and impacts align at most points. This
analysis can also be done to investigate a damaged
gear.
The benefit of being able to do this simulation analysis is huge. Understanding where and how large a
damage is gives a better picture of what and when an
overhaul should be done, often saving a lot of money
as well as improving the overhaul. A typical example
of where this is vital is in paper machines where a
carefully planned overhaul may save millions of dollars. Another example is in cruise ship machines,
where a dry-dock needs to be available for an overhaul and passengers might need to rebook their trip
to other ships, depending on overhaul time.

Figure 15. Two shafts with bearings, connected by spur
gears.

DOI
10.3384/ecp17132755

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

761

Modelica Spur Gears with Hertzian Contact Forces

6

Conclusions

bending has been neglected in this model and
should be included in the future

With this implementation of a gear model, a high accuracy causal model of contact forces can be put in a
multi-domain simulation environment. This can then References
be used to find weak points in complex rotating machinery systems. Key points are summarized below. Ivan Kosenko and Ilya Gusev. Implementation of the

spur involute gear model on modelica. Proceedings of
the 8th International Modelica Conference, 2011. URL
https://www.modelica.org/events/modelica2011/
Proceedings/pages/papers/13_3_ID_117_a_fv.pdf.

 The physical accuracy is at the level where factors like shaft position, clearances, tip relief, misalignment and vibrations by default are taken
into account. Essentially, this approach com- Ivan Kosenko and Ilya Gusev. Revised and improved implementation of the spur involute gear dynamical model.
bines the simplicity of drag-and-drop, and multiProceedings of the 9th International Modelica Conferdomain modeling in Modelica, as in (van der Linence, 2012. doi:10.3384/ecp12076311.
den, 2012), with high accuracy calculations of
gears, as in (Kosenko and Gusev, 2012).
M. Otter, M. Dempsey, and C. Schegel.
Package
 The drag-and-drop capability of Modelica and
Wolfram SystemModeler, makes the creation of
a custom model very easy. All effort required
from a user is to parametrize the models.

PowerTrain: A Modelica library for modeling and
simulation of vehicle power trains. Modelica Workshop 2000 Proceedings, pages 2232, 2000.
URL
https://www.modelica.org/events/workshop2000/
index_html/proceedings/Otter.pdf.

 The formulation of the gear contact shown in F.L.J. van der Linden. Modelling of elastic gearboxes
using a generalized gear contact model.
Proceedthis paper is designed to be simple to expand
ings
of
the
9
International
Modelica
Conference,
2012.
into more complex contacts. In other words it
doi:10.3384/ecp12076303.
is easy to take deviations from the ideal involute
gear into account. Tip relief was used here as F.L.J. van der Linden. Modeling of geared positioning sysan example. Another effect of this is that the
tems: An object-oriented gear contact model with valigear formulation can also easily be expanded to
dation. Proceedings of the Institution of Mechanical Engineers, 2015. doi:10.1177/0954406215592056.
helical gears, bevel gears and worm gears. Effects
such as contact roughness, and manufacturing
F.L.J. van der Linden and P.H. Vazques de Souza Silva.
errors can also be included in the future.
Modelling and simulating the efficiency and elasticity of

gearboxes. Proceedings 7th Modelica Conference, 2009.
 Domain specific software, such as gear or bearing
doi:10.3384/ecp09430052.
design software, gives very accurate results for a
specific machine element, but are limited when Dirk Zimmer. A planar mechanical library for teaching
an extension outside the domain is needed. The
modelica. Proceedings of the 9th International Modelica
examples presented in this paper shows how efConference, 2012. doi:10.3384/ecp12076681.
ficient several different machine elements can be
combined, as well as coupling to other domains.
For instance, the applied torque in the models
was obtained using a pid controller.

 The wind turbine example showed how important tip relief is for avoiding excessive wear. Using a software not able to include tip relief may
lead to a bad geometrical design and high costs
in the correction process. This is particularly
true if the wear is detected after some time in
operation.
 What is missing and can be included in future
work, is testing and verification of the modeling
results as done in (van der Linden, 2015), as well
as a speed up of the simulation time. Today, the
simulation time is around real-time for simple
models (2 spur gears in contact, both connected
on flexible shafts), and slower for more complex
models, depending on speed of rotation. Tooth
762

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132755

Session 10C: Mechanical Systems Modelling

Figure 17. Contact pressure on teeth at three places in the wind turbine gear box. The first plot is showing the
pressure of one planetary wheel to the ring. The second plot shows the pressure between teeth in the first step in the
two-step gear box. Finally the third plot shows the pressure between teeth in the last step of the gear box. One can
easily see how the frequency changes from the planetary gear to the last step before the generator.

DOI
10.3384/ecp17132755

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

763

764

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Modeling of Roller Bearings
Dipl.-Ing. Tobias Weiser1

Univ.-Prof. Dr.-Ing. Burkhard Corves2

1 KUKA
2 Department

Robotics GmbH, Germany, Tobias.Weiser@kuka.com
of Mechanism Theory and Dynamics of Machines , RWTH Aachen, Germany,
corves@igm.rwth-aachen.de

Abstract

model. Effects considering the rolling elements e.g. mass
effects are neglected.

Modeling of multi-body system mechanics plays a central
role in the design of mechatronic systems. Roller bearings contribute stiffness and damping to the system dy- 2 Single-row bearings
namics of a mechatronic system. This article shows the
stiffness modeling of selected types of roller bearings. The For the modeling of roller bearings or ball bearings, the
kinematics of deformation of a roller bearing are shown. elastic forces and torques are determined for both types
Based on the principle of Hertzian contact stress the elas- using the Hertzian contact stress.
tic forces and torques are calculated. These forces are considered and implemented in the MultiBody Library.
Outer Ring
r
Keywords: Bearing Stiffness, Bearing Modelling, MultiBody Library

1

Introduction

This document discusses the modeling of stiffness for various types of rolling-contact bearings for use in the simulation of multi-body systems. In addition to this macroscopic perspective, the modeling of stiffness is used for
rotordynamics. Beyond this, research in bearing modeling
deals with the effects on structure-borne noise. The study
(Ghalamchi et al., 2013) puts forward a simple model
based on Hertzian contact stress to calculate rotordynamics for barrel roller bearings. A second application for
bearing modeling is damage diagnostics and the identification of the causes of bearing damage. In the publication
(Tadina and Boltear, 2011), the system-dynamic effects
of damage to the balls and running surfaces of ball bearings are analyzed. The inner ring, the outer ring and the
rolling elements are modeled as rigid bodies. The balls are
elastically connected to the inner ring and the outer ring.
To test design measures to improve the contact pattern
of the bearing and its rolling elements, system-dynamic
investigations are carried out. To calculate the optimal
profiles for cylindrical roller bearings, the rollers are discretized in (Qian and Jacobs, 2014) using the slice model,
and the stiffness is modeled as a Hertzian contact.
The scope of this paper is to create a model for the stiffness of selected types of single and double row roller bearings. It will be used for modeling mechanisms like a robot
arm. The target is to simulate macroscopic system dynamics of a mechanism.
Modelica provides a powerful library for simulating
multi-body systems like mechanisms - the MultiBody library. Therefore this approach extends the range of this
library. An internal bearing analysis is out of scope of this
DOI
10.3384/ecp17132765

z

R
Inner Ring
jth rolling element of the ith row

r
Outer Ring

z

Inner Ring

Figure 1. Deformations of a bearing

For simulating the stiffness of a bearing in Modelica the
forces and torques in a bearing have to be derived.
First the change in angular position of the rolling element j when rotating the bearing about the Z-axis with
the angle  is calculated using the bearing geometry of
the pitch radius of the rolling elements R and the rolling
element radius RW .

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

765

Modeling of Roller Bearings
y

y

roller).

r

Ball :

B, j
x

=


R, j

 j



 R  RW cos(0 )  , fixed outer ring
R
=

 R + RW cos(0 )  , fixed inner ring
R

(9)

Roller :

z

Figure 2. Coordinate system of a double row bearing

A j  A0 , B j > 0
0, B j  0

=

r j cos( j ) + z j sin( j ), R j > 0
(10)
0, R j  0

The load Q j on each rolling element j depends on
the type of roller bearing W and is calculated with the
Hertzian exponent n. For elliptical Hertzian contact (ball
- elastic half-space) we assume n = 3/2. For a rectangular contact (cylinder - elastic half-space) we assume
n = 10/9. Depending on the geometry and the material
properties of the roller we denote the load Q j on each
(1) rolling element j with the Hertzian stiffness constant Kn
for ball (B) and roller bearings (R):

fj )n
Q j = Kn  W (
(11)
We simplify in the next equation the angle  j of the
roller position of the jth roller according to the X-axis to
Then we yield the forces and torques on a bearing with
ej:
the angle 
e j as the angular position of each
Z rolling elements and 
e j =  j +  j

(2) rolling element (Lim and Singh, 1990a,b; Gunduz, 2012).




For every rolling element j, the axial z j and radial deej)
Fxbm
cos( j )cos(
formation r j is calculated from the translational deformaej) 
 Fybm 
 cos( j )sin(




Z
tions xm , ym , zm and the angular deformations xm , ym
sin( j )
 Fzbm 


(12)

 =  Qj 
of the bearing (Fig. 2) with the pitch radius R and the
ej) 
Mxbm  j=1  Rsin( j )sin(





bearing clearance rL .
ej)
Mybm
Rsin( j )cos(
0
Mzbm
z j
r j

ej)
= zm + R (xm sin(
e
 ym cos( j ))
ej) +
= xm cos(
e j )  rL
ym sin(

For roller bearings we obtain with  j = 0 (Lim and
Singh,
1990a) the forces and torques:
(3)
(4)

The contact angle under load  j of the rolling element j
can be calculated with the contact angle of the bearing 0 ,
the net effective radial (r ) j and axial (z ) j displacement
and the relative distance A0 between the raceway groove
curvature centers of the inner ai and outer ao bearing ring
in case of no load:
(z ) j
(r ) j

= A0 sin(0 ) + z j
= A0 cos(0 ) + r j
(z ) j
tan( j ) =
(r ) j

(5)
(6)


Fxbm
 Fybm 


Z
 Fzbm 
n

 = Kn  (R, j cos(0 ))
Mxbm 
j=1
M 
ybm
Mzbm


ej)
cos(0 )cos(
ej) 
 cos(0 )sin(


sin(
)


0

ej) 
 Rsin(0 )sin(

Rsin( )cos(
e j )
0
0


(13)

The rotation about the Z-Axis is free because the torque
(7) about the Z-axis M in equations 12 and 13 is zero.
zbm

Then we obtain the distance between the raceway 3 Double-row bearings
groove curvature centers under load A j :
Besides single-row the force and torque balances for
double-row ball and roller bearings are determined in this
q
A j = (z )2j + (r )2j
(8) section. Three possible configurations for the double row
bearings exist (Figure 3). The bearing arrangement coDepending on the type of the rolling element W , the efficent c3 considers these configurations. The calculatotal elastic deformation is W ( j ), (W = B : ball, R : tions of the radial (r )ij and axial displacement (z )ij of
766

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132765

Session 10C: Mechanical Systems Modelling


Fxbm
 Fybm 


 Fzbm 

 =
Mxbm 
M 
ybm
Mzbm


O

X

(21)

j

0

R = R sin( ij )  c1 e cos( ij )

Tandem

Figure 3. Bearing Arrangements (Matek et al., 2013) (Gunduz,
2012)



e ij )
cos( ij )cos(
 cos( ij )sin(
e ij ) 


2 Z
i


sin( j )

  Q j  R sin(e i ) 
j


i=1 j=1
 R cos(
ei ) 

(22)

For bearings with rollers as rolling elements, the angular offset ij assumed to be zero. Therefore, the following
applies:
 ij = 0
(23)

each rolling element j in row i (equations 3,4) have to
be extended by the kinematics of the double row bearThe equations for the forces Fxbm , Fybm , Fzbm and torques
ing with the row coefficent c1 , the bearing clearance rL , Mxbm , Mybm , Mzbm are thus as follows for each rolling elethe distance between the two bearing rows e, the trans- ment j in row i introducing the parameter Re for simplifilational deformations xm , ym , zm , the angular deforma- cation.
e ij
tions xm , ym of the bearing and the angular position 
of each rolling element.




e ij )
cos(0 )cos(
Fxbm
 cos(0 )sin(
e ij ) 
 Fybm 





2 Z


sin(0 )
 Fzbm 
1, for i = 1, left row
 (24)


 =   Qj  e
c1 =
(14)
i
ej) 
Rsin(
Mxbm 
1, for i = 2, right row


i=1
j=1
M 
 Rcos(
i) 
e
ybm
e

i
i
j
ej) +
(z ) j = [xm + c1 ym e] cos(
Mzbm
0
i
e j )  rL
[ym  c1 xm e] sin(
(15)
Re = Rsin(0 )  c1 ecos(0 )
(25)


e ij )  ym cos(
e ij ) (16)
(r )ij = zm + R xm sin(
Next the equations of the net effective radial (r )ij and
axial (z )ij displacement of equation 5 and 6 are extended
for the double row bearings. With the bearing arrangement
coefficent c3 (Figure 3) we calculate the net radial (r )ij
and axial (z )ij effective displacements and the loaded distance Aij between the raceway groove curvature centers of
the inner ai and outer ao bearing ring of the rolling element
j in the row i.

y
e

e=0

x

i=1

c3
(r )ij
(z )ij
Aij

i=2


[left row, right row] , arrangement

Figure 4. Conversion of a double row roller bearing to a cross


roller bearing
[1, 1] , Back-To-Back, O
=
(17)
[1,
1]
,
Face-To-Face,
X


 [1, 1] , Tandem
A cross-roller bearing is modeled as a double-row bearing
for which the distance e between both bearing rows is
= A0 cos(0 ) + ri j
(18)
e ij
zero (see Fig. 4). For each row the correct angle offset 
i
= zi j + c3 (A0 sin(0 ) + z0
)
(19) for each rolling element has to be considered.
q
= ( (z )ij )2 + ((r )ij )2
(20) 4 Implementation

In general, the following relation applies to the forces
Fxbm , Fybm , Fzbm and torques Mxbm , Mybm , Mzbm on the
double-row ball bearing. For simplification we introduce
the parameter R .
DOI
10.3384/ecp17132765

The integration is carried out in the MultiBody library.
In the preceding chapters, the relationship of the forces
and torques on a roller bearing has been described. The
motion equations and the elastic forces and torques of the
bearing are determined using Lagranges equation of the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

767

Modeling of Roller Bearings

The equations 35 and 36 show that the relationships of
second kind. Here T is the kinetic energy, Q are the generalized forces (Hardtke et al., 1997). The generalized the forces and torques can be directly incorporated into the
forces Q consist of conservative Qk and non-conservative equations of motion.
forces Qn . In this model non-conservative forces dont exThe force and torque equilibrium then is:
ist. With the vector of generalized coordinates q and the import Modelica.Mechanics.MultiBody.Frames;
potential energy U(q) we denote:
// Force and torque equilibrium
frame_a.f = -F_Bearing;


T
d T
frame_b.f = -Frames.resolve2(

= Q
(26)
Frames.relativeRotation(frame_a.R,
dt  qi
 qi
frame_b.R),
Q = Qk + Qn
(27)
frame_a.f);
Qn = 0
(28)
if fixedRotationAtFrame_a then
U(q)
(29)
Qk (q) = 
Connections.root(frame_a.R);
q
frame_a.R = Frames.nullRotation();
The vector of generalized coordinates q are the deformations on the bearing and we yield the vector of the forces
on a rolling element F(q) with the auxiliary parameters
for coding FBearing , MBearing :
q = [xm , ym , zm , xm , ym ]T
T

F(q) = [FBearing , MBearing ]

T
FBearing = Fxbm , Fybm , Fzbm

T
MBearing = Mxbm , Mybm , 0

(30)
(31)
(32)
(33)

The force and torque relationships for single-row and
double-row bearings are described in chapter 2 and chapter 3, respectively. For calculation of the potential energy
U(q), the following applies in general for the energy over
the force F(q) with the vector of generalized deformations
q and finally we yield for the conservative force Qk :

else
frame_a.t = -M_Bearing;
end if;
if fixedRotationAtFrame_b then
Connections.root(frame_b.R);
frame_b.R = Frames.nullRotation();
else
frame_b.t = -Frames.resolve2(
R_rel,frame_a.t);
end if;

The calculation of the forces Fxbm , Fybm , Fzbm and
torques Mxbm , Mybm , Mzbm on a bearing is realized in the
sub-function calculateBearingForce(). The deformations
r_rel_a, R_rel between the f rame_a and f rame_b of the
bearing block are required for calculating bearing forces
and torques. The angles xm , ym ,  are calculated as consecutive rotations out of the rotation matrix R_rel . The
vector angles represents these angular deformations.
angles = [xm , ym , ]T

(37)

r_rel_a = Frames.resolve2(frame_a.R,
frame_b.r_0 frame_a.r_0);
R_rel = Frames.relativeRotation(
frame_a.R,frame_b.R);
angles = Frames.axesRotationsAngles(R_rel,
{1,2,3},0);
/* Determine forces and torques at frame_a
and frame_b */
q = {r_rel_a[1],r_rel_a[2],r_rel_a[3],
angles[1],angles[2]};
(Fx,Fy,Fz,Mx,My) =
Functions.calculateBearingForce(
myLager,angles[3],q);

Figure 5. Input parameter mask in Dymola
f_Bearing = {Fxbm,Fybm,Fzbm};
m_Bearing = {Mxbm,Mybm,Mz};
Mz = 0;

U
 qi
U
 qi
Qk
768

=


 qi

Z
0

= F(qi )
= F(q)

q


F(qi )dqi

(34)

For the transformation of the forces and torques in the
equations of motion the Jacobi matrix J is required. This
(35) matrix describes the kinematics on the bearing and is determined by means of the deformation q. The Cartesian
(36) deformations im , i = x, y, z are modeled as sliders and the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132765

Session 10C: Mechanical Systems Modelling

(38)

5

 F(q)
q

Fxbm

100

Fybm

0

Fzbm

100

0

100

200

300

400

Angle in ()

(40)

20

(41)

The possible singularity of the Jacobi matrix for rotation
about the x and y axes by 90o is ignored since small deformations are expected.
The mass and inertia of the inner and outer ring of the
bearing are modeled with the block "Body" of the MultiBody.Parts library. Each body is attached to f rame_a and
f rame_b respectively. The dynamics of the rolling elements are neglected since only macroscopic effects of the
system dynamics will be modeled.
Deriving a stiffness matrix K(q) is not required for the
equations of motion in equation 26. If required, the stiffness matrix K(q) can be calculated by means of the partial differentiation of the force and torque vectors F(q) according to the generalized coordinates of the bearing deformation q in equation 30.
K(q) =

200

(39)

Torque in (Nm)

= ex , ey
 
Jvi
J =
Ji
(
zi
, translational motion
Ji =

zi  pi , rotational motion
(
0 , translational motion
Ji =
zi , rotational motion
zi

Bearing forces and torques
300

Force in (N)

rotations im , i = x, y are modeled as consecutive rotation
about x, y with the rotation axis vector zi using the rotation
matrices Rx , Ry (see Fig. 2).

19

Mxbm
Mybm

18
17

0

100

200

300

400

Angle in ()

Figure 6. Bearing stiffness forces, bearing angle position varying

testing of the overall system of the manipulator is necessary. Next a simple example of a pendulum is shown. A
stiff revolute joint and a bearing with its parameters in table 1 as a revolute joint are compared. The point mass is
1kg and the length of the pendulum is 1m. Figure 7 shows
the model in initial configuration. The reaction forces and
torque in figure 8. show the difference between the rigid
and the elastic suspended joint of the pendulum.

(42)

y

y

Simulation Results

x

x

The parameters from table 1 are used to simulate the stiffness forces and torques with varying preload Fxm and a
partial rotation  = 360/Z of the bearing.
1

Parameter
R
e
Z
Kn
0
rL
A0
n
z,0

Value
34.45
10
15
395000
45
0
0.52
1.5
0

Unit
mm
mm

2

Figure 7. Pendulum, 1: rigid suspension 2: elastic suspension
3

N/mm 2
mm
mm

6

Conclusion and Outlook

In this work the calculation of the stiffness forces and
torques of single- and double-row bearings are shown.
The following bearing types are considered:

mm

 Single row ball bearing

Table 1. Parameters of a double row roller bearing

 Single row roller bearing
Figure 6 shows a periodicity for the forces and torques
within a bearing rotation. For each bearing rotation, the
force and torque progression is repeated by the number of
rolling elements. To assess the effects of parameter excitations on the system dynamics of the manipulator, further
DOI
10.3384/ecp17132765

 Double row ball bearing
 Double row roller bearing
 Cross roller bearing

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

769

Modeling of Roller Bearings

Force in (N)

Bearing forces and torques
15

Fxr

10

Fyr
Fzr

5

Fxbm

0

Fybm

5

Fzbm

0

0.2

0.4

0.6

0.8

1

Time in (s)
Torque in (Nm)

1.5

Mxr

1

Myr

0.5

Mxbm

0
0.5

Mybm
0

0.2

0.4

0.6

0.8

1

Time in (s)

rolling element bearings, part i: bearing stiffness formulation.
Journal of sound and vibration, 139(2):179199, 1990a.
Teik C. Lim and Rajendra Singh. Vibration transmission through
rolling element bearings, part ii: system studies. Journal of
sound and vibration, 139(2):201225, 1990b.
Wilhelm Matek, Dieter Muhs, Herbert Wittel, and Manfred
Becker. Roloff/Matek Maschinenelemente: Normung Berechnung Gestaltung. Springer-Verlag, 2013.
Weihua Qian and Georg Jacobs. Dynamic simulation of cylindrical roller bearings. Technical report, Lehrstuhl und Institut fr Maschinenelemente und Maschinengestaltung, RWTH
Aachen, 2014.
Matej Tadina and Miha Boltear. Improved model of a ball bearing for the simulation of vibration signals due to faults during
run-up. Journal of sound and vibration, 330(17):42874301,
2011.

Figure 8. Forces and torques on the bearing and on the revolute
joint and the displacement

The stiffness forces and torques are implemented in the
MultiBody library of Modelica. A simulation shows the
influence of loads and bearing position.
ActuatedBearing

Bearing

a

ba

b

Figure 9. Bearing with 1 DOF and actuated bearing

According to equation 12 and figure 2 the bearing
model yields a free rotation about the Z-axis. For multibody systems and actuated mechanisms it will be important to consider the drivetrain. The scope of the future
work is to develop an actuated bearing similar to the actuated joint in the Modelica MultiBody library. Further
modeling and simulation of different mechanisms like a
robot arm will be performed and validated.

References
Behnam Ghalamchi, Jussi Sopanen, and Aki Mikkola. Simple
and versatile dynamic model of spherical roller bearing. International Journal of Rotating Machinery, 2013, 2013.
Aydin Gunduz. Multi-dimensional stiffness characteristics of
double row angular contact ball bearings and their role in
influencing vibration modes. PhD thesis, The Ohio State University, 2012.
Hans-Jrgen Hardtke, Bodo Heimann, and Heinz Sollmann.
Lehr-und bungsbuch Technische Mechanik Bd. II, Kinematik. Kinetik-Systemdynamik-Mechatronik, Fachbuchverlag Leipzig, 1997.
Teik C. Lim and Rajendra Singh. Vibration transmission through

770

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132765

Cabin Thermal Needs: Modeling and Assumption Analysis
Florent Brque

Maroun Nemer

MINES ParisTech, PSL Research University, Center for energy Efficiency of Systems
5 rue Lon Blum, Palaiseau, 91120, France
florent.breque@mines-paristech.fr

Abstract
Interest for cabin thermal needs has strongly increased
for the past 10 years, particularly due to heating.
Indeed, the development of electric and hybrid vehicles
stressed the need to rethink the cabin thermal design
and the HVAC, this high-consuming auxiliary, which
can dramatically decrease the vehicle electric range.
Thus, this paper presents a detailed transient and
mono-zonal model of a car cabin in order to predict the
thermal needs. The model is developed using the
MODELICA language via the DYMOLA environment.
It considers conduction, convection, radiation heat
transfers as well as the HVAC and water vapor
impacts. The different assumptions of the model are
discussed and important considerations usually not
discussed are highlighted. The thermal loads are also
analyzed. Finally, the heating and cooling thermal
needs are computed for steady state mode and for
convergence mode as well as for varying recirculation
ratios. This work is useful to better understand the
whys and wherefores related to the cabin thermal
needs.
Keywords:
thermal model, vehicle cabin, cabin
thermal needs, HVAC, heating, Air-conditioning,
electric vehicle.

1

Introduction

For the past ten years, the electric vehicle
developments and deployments have strongly
accelerated. However, one of the major concerns with
those vehicles is their low range. Hence, a lot of effort
has been made to improve the vehicle range. It
appeared that a major load for the battery is actually
the HVAC system, which can consume as much energy
as the motor in some conditions. Thus, additional
development is necessary to decrease the HVAC
energy consumption. One solution is to use a heat
pump instead of the electric heaters typically used.
The work presented in this paper is part of a project
which aims at developing a heat pump technology for
electric vehicles. The project focuses particularly on
the frosting issue with regards to the evaporator.
Another important aspect of the project is to evaluate
the gains that can be obtained from using heat pumps

DOI
10.3384/ecp17132771

and evaluate other thermal strategies. In order to do so,
a detailed thermal model of the cabin is required.
Different models have already been presented in the
literature. They are of different types.
A first category is composed of the CFD models
(Versteeg and Malalasekera, 2007). Some authors use
those models to evaluate the thermal comfort (Fujita et
al., 2001; Kataoka and Nakamura, 2001; Sevilgen and
Kilic, 2012). Others study the impact of specific
aspects such as the windows opening, the glazing
properties or the air quality (Al-Kayiem et al., 2010;
Fujita et al., 2001; Zhu et al., 2010).
On the other hand, lumped models, also called
mono-zonal model, have been developed. Here, the
cabin air is modeled by a single node and is therefore
considered homogeneous (Marcos et al., 2014;
Wischhusen, 2012). Those types of models are mainly
used to study the impact of some factors on the thermal
load (Li and Sun, 2013; Torregrosa-Jaime et al., 2015)
but can also be used for studying HVAC control
(Sanaye et al., 2012).
Finally, an intermediary approach between the two
previous exists and is called the zonal approach. It
consists in defining several air lumped nodes in a
single air volume and linking them in order to
exchange mass (Boukhris et al., 2009). The challenge
here is then to use or develop a proper flow model
between the nodes (Daoud and Galanis, 2008; Inard et
al., 1996). It can be seen as a simplified CFD approach
in some cases. For vehicle applications, this approach
is sometimes used but usually only with two nodes in
the cabin (Torregrosa-Jaime et al., 2015; Wischhusen,
2012).
Based on this review, it clearly appears that the most
relevant category of models to study the cabin thermal
needs takes the mono-zonal approach. It is therefore
the one that will be developed in this paper.
Regarding the thermal need analysis, several authors
have studied it (Iskandar, 2010; Li and Sun, 2013;
Marcos et al., 2014; Mezrhab and Bouzidi, 2006;
Torregrosa-Jaime et al., 2015). However, they focused
on air-conditioning needs (since it was the important
aspect for conventional cars) but neglect heating needs.
Furthermore, they have studied a limited number of
cases and the assumptions have not been discussed.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

771

Cabin Thermal Needs: Modeling and Assumption Analysis

Consequently, the aim of this paper is to address those
issues.
To do so, a model is developed using the
MODELICA language via the DYMOLA environment.
First, an overview of the top level model is presented
in this paper. Then the main models are presented.
Through the model descriptions, the different
assumptions of the model are discussed and important
considerations usually not discussed are pointed out.
Then, in the result section, the steady state mode is first
analyzed, followed by the convergence mode, which
correspond to the initial transient warm-up or cooldown phase. The thermal loads are analyzed for the
steady state case and, for both mode, a sensitivity
analysis is performed. Finally, cooling and heating
thermal needs are computed.

2

Mathematical model

2.1 Model overview
Figure 1 is a view of the cabin top level model in the
DYMOLA environment. It is composed of several
models. First, the cabin model itself includes the
thermal network and the cabin air node (moist air). The
HVAC model handles the recirculation air flow and the
heating/cooling of the air. It is operated by a controller
which either adjusts the thermal power to reach the
targeted cabin air temperature or imposes a constant
thermal power depending on the user choise. The
atmosphere model imposes the weather conditions.
Finally 5 records are used here as an interface for
model parameterization.

between each other and to the walls. The first
corresponds to the cabin air and the second to the
internal solid mass (seats, dash board).
Second, a fluid flow network is represented. It
represents the moist air flows. It is particularly of
interest since it computes the properties of the
recirculation air, it determines the water vapor
condensation rate in the evaporator and also computes
the water vapor mass balance in the cabin taking into
account passenger water vapor generation.
This model is described in more details in the
following sections.

2.2 Atmosphere model
Basically, the atmosphere model is quite simple. It is
here to provide 5 inputs: outside air temperature,
outside air humidity, solar direct and diffuse flux as
well as the sun direction vector. One can directly
provides this information as parameters. Instead of
giving directly the solar vector, it is also possible to
write a latitude and longitude with the date and time.
Then, using calculation from (ASHRAE, 2009), the
solar vector is computed.
It can be noted here that the atmosphere variables
are transferred to the other models via the
inner/outer method.

2.3 Wall model
The wall model presented in Figure 2 is the thermal
network between the cabin interior and the outside
environment (all thermal components are from the
MSL Thermal library).
solar fluxes
calculation
transmitted flux

Atmosphere

absorbed flux

outer inner
Cp
Cp

inner
radiation

outer
radiation

Controler

conduction
outer
convection
HVAC

inner
convection

Cabin

Figure 1. Cabin top level model in DYMOLA.

Figure 2. Wall model in DYMOLA.

Figure 3 is a schematic of the complete model. It can
be observed that the model is divided in two parts.
First, there is the thermal network. It includes the
heat transfer exchanges with the exterior. In addition,
two cabin internal nodes are defined and connected

Based on Figure 2, the thermal balance at the outer
applies as follow (by convention,
wall node
heat flow is positive when heat goes from outside
into the cabin):

772

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132771

Session 10D: HVAC Systems

Figure 3. Schematic of the model.

section 2.5. The wall thermal resistance



	

	

,



	

		

 

1

 

,





			

	 	

,
4

4



(1)



			 			

,



Similarly, the thermal balance at the inner wall node
is expressed as follow:



	

				
,

1




			


,

		



(2)
		

 

4

4



In eq. (1), the solar flux
is computed via a sub,
model described in section 2.4. In addition, the
and
are given in
convection coefficient
DOI
10.3384/ecp17132771

and the

and
are
thermal capacitances
	
	
determined by basic calculations taking into account
the multilayer structure of the wall. It is done in a
generic way such that both opaque body (with an inner
skin, a lining material and a outer skin) and glazing
surfaces can be handled by the same model.
An interesting aspect here is that the radiation heat
transfer has been considered both for inner and outer
wall surfaces. The outer surface exchanges by radiation
.
with a so called environment IR temperature
Determining this temperature is not trivial. Depending
on the surfaces, it could be equal to the outside air
temperature, but it also could be equal to the sky
temperature, which can be far lower than the outside
temperature for clear skies. In addition, during
summer, the floor sees the road which can have a very
high temperature compared to the air. In the model,
those aspects are configurable. For the clear sky
temperature, the correlation from (Swinbank, 1963) is
used.
Furthermore, in eq. (2), one can observe that the
internal radiative heat exchange is between the wall
and the internal mass (the seats, the dashboard,) via
a view factor. First, this view factor is not easy to
determine. In addition, the radiative heat exchanges
between the walls themselves are not considered.
The impact of those different assumptions are
evaluated in the results section.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

773

Cabin Thermal Needs: Modeling and Assumption Analysis

2.4 Solar fluxes computation sub-model
This sub-model included in the wall model aims at
computing the absorbed solar flux
by the wall
,
and the transmitted solar flux through the wall
(for glazing). The following equations,
,
extracted from (ASHRAE, 2009) are used.
The direct solar flux 	received by a surface with a
normal
is given by (with
the scalar product
between the solar vector and and the solar flux):

(3)

received is:
Then, the total diffuse flux
1
1
(4)



2
2
With
the horizontal diffuse flux,
the angle
between and the vertical, the albedo and
the
global flux.
Finally, the solar fluxes are given by eq. (5) and (6).
,
,





	

(5)





		

(6)

2.5 Convection sub-model
The wall model also includes a convection sub-model.
The convection in this thermal problem is quite
complicated. Indeed, the geometry is complex and
natural and forced convection can be mixed. A detailed
analysis of the convection correlations has been
conducted here.
First, it can be noted that the cabin walls are often
assumed to be flat plates. Hence, the general
correlations for flat plates (see (Bergman et al., 2011))
are often used. For instance, eq. (7) is for forced
parallel and turbulent flow and eq. (8) is for natural
convection over a vertical plate. All applicable flat
plate correlations have been implemented in the code.
In addition, for internal convection, correlations of
the form of eq. (9) (Abou Eid, 2016) and used in
building applications have also been evaluated. The
coefficients c and n are adjusted depending on the
situations (floor, ceiling, vertical walls, mixed
convection).
Finally, for external correlations around the vehicle
(car, bus or train), several authors (Fujita et al., 2001;
Kataoka and Nakamura, 2001; Li and Sun, 2013;
Mezrhab and Bouzidi, 2006; Zhang et al., 2009) use
their own specific correlation in the general form of eq.
(10) (with a, b and c constants). Most of the authors
define a minimum value which is applied for low
velocities.



Nu L  0,037  Re L

0 .8

 Pr

1/ 3



0,387  Ra

NuL   0.825 
9 / 16 8 / 27 

1

0
.
492
/
Pr







774

1/ 6
L



hconv  c  Tinwall  Taircab

n

hconv  a  b  v c

(9)
(10)

In order to give an idea on how the correlations
compare, Error! Reference source not found. plots
the computed coefficients. It appears that the general
trends are similar except for the laminar correlations
and Lis correlation. However, the coefficients can be
multiplied by 1.5 from one correlation to the other. The
impact of those correlations is evaluated in the result
section. By default, the (Fujita et al., 2001) correlation
and the eq. (9) with c=3 and n=1/3 (mixed convection)
are used.

2.6 Passenger model
As shown in Figure 3, the model takes into account the
passenger thermal loss
and the passenger water
vapor generation
. According to (ASHRAE,
2009), it is assumed that a person emits 70W of
sensible heat and 35W of latent heat. The latent heat is
converted to a mass flow rate in the model and not
added in the thermal network. Only the mass flow rate
is injected in the cabin volume and is then considered
for the mass and energy balances. The number of
passengers can be adjusted.

2.7 Cabin model
The cabin model is shown in Error! Reference
source not found.. It includes the wall and passenger
models that just have been presented. In the figure,
only one wall model appears. However, an important
feature here is that it is actually a vector of walls. Thus,
the number of walls, opaque or transparent walls, can
be varied. This allows adjusting to the exact vehicle
configuration.

Walls[n]
Cabin air
volume
passengers

(7)

Internal
mass

2

(8)
Figure 4. Cabin model in DYMOLA.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132771

Session 10D: HVAC Systems

Convectioncoefficient(W.m2.K1)

120
100
80
60
40
20
0
0

20

40

60

80

100

120

140

Vehiclespeed(km.h1)

Figure 5. Convection coefficients from the different correlations for external forced convection.

In this model, the energy balance applies for the
:
internal mass node



In addition to the energy balance, the mass balances
also apply:



	
,

,

		


With :

			 			


(12)
An assumption that can be discussed here is the
approach with the internal mass and the way the
radiation problem is treated. It follows the approach
used in (Marcos et al., 2014) where a base node is
defined. The internal mass is assumed to be a black
body and to receive all the radiation heat fluxes: the
solar transmitted flux as well as the IR flux from the
inner surface of the walls. It is useful to consider this
internal mass since it has a strong impact on transient
results. In addition, due to the complex shape of the
internal masses and their high emissivity and
absorptivity, it makes sense to assume a black body
here. Those points are discussed in the result section.
Then, the energy balance is applied to the air
volume:





			
							 				

,
,

,



			

			 			


							
With






(13)

			 			
			 		

		

the enthalpy of water vapor at 37C.

DOI
10.3384/ecp17132771

(14)

	

(11)

				 	

			 	





			

(15)


	 	
A key point here is of course the water vapor mass
balance which will determine the humidity ratio in the
cabin air and impact the HVAC either by requiring
additional fresh air to avoid mist and/or by adding a
cooling load to the evaporator.

2.8 HVAC model
The HVAC can be seen as an external component of
the cabin. Therefore, one could want to focus on the
cabin and not to consider at all the HVAC for the
determination of thermal cabin needs. However,
considering the HVAC is actually required here to
properly compute the thermal cabin needs, which
translate into the HVAC thermal loads. Indeed,
knowing the water vapor condensation rate at the
evaporator is important since it can strongly impact the
total A/C needs. Moreover, this condensation rate is
required when addressing the cabin dehumidification
needs, which also translate into cabin needs. In
addition, the thermal needs are strongly dependant on
the recirculation ratio, which is controlled by the
HVAC.
Figure 6 is a view of the HVAC model. It is
composed of a recirculation box and a cooling/heating
element. The recirculation box is made of valves (from
MSL Fluid library) whose openings are adjusted to

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

775

Cabin Thermal Needs: Modeling and Assumption Analysis

control the recirculation ratio as desired (a PI is used
here in the controller of the Figure 1). The model
handles the mixing of the fresh air with the recirculated
air via basic mass and energy balances.

At this point it can be noted that the controller of the
HVAC (see Figure 1) can adjust the evaporator
sensible cooling power and the heating power to obtain
proper cabin air temperature and humidity (and hence
to satisfy the cabin needs: (heating, cooling,
dehumidifying). It is also possible to impose both
sensible cooling power and heating power. Then, using
is computed followed by
eqs. (16) to (18), the
and
.
Here, it can be noted that the heat-pickup (or loss) in
the air distribution system (dashbord and
recircirculation channel) has been neglected.

2.9 Model parameters
The model requires a full list of parameters. There are
not presented in detail here due to conciseness
considerations. Basically, the car geometry is described
by the wall areas and orientations. In addition,
thicknesses and thermal parameters are required. For
the following results, parameters from a mid-size car
are applied (main parameters given in Table 1).

fan

Table 1. Geometry and thermal parameters.
Cooling
HX

Heating
HX

Figure 6. HVAC model in DYMOLA.

The cooling/heating element is composed of a fan, a
cooling HX and a heating HX. The fan model is the
PrescribedPump model from MSL Fluid library and
the heating HX is modeled with a DynamicPipe from
the same library. Only the cooling HX is modeled via
an ad hoc pipe which is able to handle water vapor
condensation. To do so, the sensible heat exchange
is computed as follow:

				


	



	

(16)

Then, the water vapor condensation rate
is
	; null otherwise):
given by (when



		



,

(17)

	

Parameter

Value

Glazing areas

2 m2

Opaque areas

9.9 m2

Lateral insulation thickness

75 mm

Floor insulation thickness

15 mm

Roof insulation thickness

13 mm

Internal thermal capacity

75 kJ.K-1

Total wall thermal capactity

155.4 kJ.K-1

Glazing transmittivity

0.85

Wall outer absorptivity

0.85

In addition to those parameters, when one wants to
compute the cabin thermal needs, operating condition
parameters are required. Those parameters are
presented in Table 2. As we will see, some of those
parameters strongly influence the results. They are in a
sense arbitrary and depend more on the manufacturer
philosophy (specifications), but they have to be
carefully considered by one who wants to study
thermal needs due to their strong influence.
In addition to the parameters given in Table 2, the
target cabin temperature is set to 23C. The number of
passengers is 0 for heating and 4 for AC. No sun is
considered for heating and the sun is defined by
	 and
117	 .
for A/C. The
700	 .
vehicle speed is set to 45 km/h. And the initial
condition is a cabin at 	
(all thermal nodes).

Then, it comes:

	

776

	 		



(18)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132771

Session 10D: HVAC Systems

Table 2. Operating conditions.




(C)
-20
-15
-10
-5
0
5
10
15
20
15
20
25
30
35
40
45

%



min

85
20

95

15
10

95
85
65
55
35

10

15
20



Deshum.



Stab.

Conv.



(kg.h-1)
245
236
225
210
200
185
180
187
195
187
195
248
330
378
400
408

(kg.h-1)
400
390
360
330
310
290
285
290
300
290
300
390
533
608
632
640

(kg.h-1)

(C)

Same
as

No







3
5

(no
recirc)

10
Total = 2293 W

187
195
124
88
59

min 10

Figure 7. Thermal loads (W) at 0C.

N/A

48

2.10 Model validation
The experimental validation of the model is being
carried out at the moment. Hence, the results were not
available for this paper but they will be presented in a
following paper. The first tests conducted with a crane
cabin (and not a car cabin, due to industrial partner
needs) were very encouraging since the cabin
temperature was predicted within +/-1C. The first
tests suggested that the thermal parameters need to be
filled carefully and that the analysis conducted in this
paper are valid.

3

Figure 8. Thermal loads (W) at 40C.

3.2 Sensitivities  steady state

Model results

3.1 Reference cases  steady state
To start the analysis, lets have look at the thermal
loads at 0C and 40C (the other parameters are as
given in section 2.9) in steady state.

Figure 7 presents the thermal loads at 0C. The total
heating need is 2.3 kW. It can be observed that the
fresh air is responsible for more than half of the needs.
Then, the heat transfer occurs more through glazing.
For the air-conditioning case at 40C presented in
Figure 8, the load split is more complex. The total
cooling load is 2.9 kW. 1/3 is due to the solar, 1/3 due
to fresh air and the last third due to heat exchange with
the exterior temperature through wall and due to the
passengers. Because the recirculation ratio is high, the
fresh air sensible load is low. However, the high
humidity level results in an important fresh air latent
load. It is important to take into account this load since
the A/C system will have to overcome it.

DOI
10.3384/ecp17132771

Total = 2878 W

In this section different assumptions were varied for
the two reference cases (at 0C and 40C).
First, the different correlations presented in section
2.5 were tested. Using flat plate natural convection
correlation for the internal surfaces can decrease by
10% the thermal needs. For external surfaces, the
sensitivity to the correlations is less than +/-3%.
Several cases were tested to evaluate the
dependence on radiative assumptions. The IR
environment temperatures have been assumed to be all
the sky temperature or all the outside air temperature.
A case with a road at 80C has also been considered.
The view factors between each wall and the internal
mass have been varied from default value to 1. For all
those cases, the sensitivity was less than +/-3%. A case
with no radiative heat exchange inside the cabin has
been considered. It decreased by 7% the thermal
heating need and 5% the cooling needs for the
reference case using the mixed convection correlation
for the inner convection. However, if pure natural

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

777

Cabin Thermal Needs: Modeling and Assumption Analysis

Thermal needs (W) and relative gap (%).
Text
0C
40C

Case 1

Case 2

Case 3

Case 4

2622

1638

1982

2079

14.3%

-28.6%

-13.6%

-9.3%

2786
-3.2%

4126
43.4%

3102
7.8%

2937
2.1%

3.3 Cabin needs  steady state
The thermal cabin needs in steady state conditions are
presented in Figure 9. Between 5 and 20C, the
dehumidification (cooling and heating at the same
time) is taken into account.
Based on the previous discussion, needs for varied
recirculation ratio from 0 to 100% is added to the
curves (without taking into account dehumidification
needs). It corresponds to the grey bands.
For the dehumidification zone, the required heating
is between 1 to 2 kW. Then, at -10C, it increases up to
3.6 kW. Those numbers are the same order of
magnitude as the average traction power for an urban
trip (taking into account stops), though lower. Thus, it
appears clearly here why the heating is so damageable
for electric vehicle range for a basic case using electric
heaters. The A/C needs are also high but the they
increase less with respect to the temperature above
25C because of the high recirculation ratio considered
and the A/C system has a better COP then the electric
heaters.

3.4 Reference cases  convergence
Similarly to what has been done for steady state, two
reference cases, based on operating conditions
described in section 2.9 at 0C and 40C, are analyzed.
Figure 10 is a plot of the cabin air temperature during
the warm-up. 4 kW heating is required to reach the
targeted temperature within the targeted duration. The
heating power is applied continuously during the
simulation and that is why the temperature exceeds the
target at the end of the simulation. For normal cases,
once the targeted temperature is reached within a
certain interval, a real HVAC control algorithm would
decrease the thermal power and converge
approximately towards the steady state required power
(values presented previously). Here, the controller is
not modeled in details and just a constant-power
transient is analyzed.
The results for the cool-down at 40C are presented
in Figure 11. Here, 3.5 kW were required to reach the
proper temperature within the required duration.
Cabinair
temperature(C)

Table 3. Sensitivities to operating conditions

Figure 9. Steady state thermal needs.

30
20
10
0
0

10
20
Time(min)

30

Figure 10. Warm-up transient cabin air temperature.
Cabinair
temperature(C)

convection conditions prevail, neglecting the inner
radiation decreases by 17% the heating and cooling
needs. Hence, internal radiation needs to be taken into
account.
The impacts of the conditions selected in section 2.9
have also been analyzed via the following cases:
 Case 1: 25% increase in blown air flow rate (with
same recirculation rate as default case)
 Case 2: recirculation rate at 50%
 Case 3: target cabin temperature set at 20C
 Case 4: stationary vehicle
The results are presented in Table 2. It is clear that
those operating conditions have strong impacts on the
results, far more important than the majority of
previous modeling sensitivities. Therefore, it means
that, when talking about the cabin needs, the related
considered conditions should be clearly stated,
particularly the recirculation rate considered and the
blown air flow rate.

35
25
15
0

10
20
Time(min)

30

Figure 11. Cool-down transient cabin air temperature.
778

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132771

Session 10D: HVAC Systems

A rapid change of slope can be observed on both
curves. It separates two transient phases. The first one
corresponds to the air capacity and the second one to
the wall and internal capacities. This separation is not
so obvious in practice since the HVAC power also
integrates a transient phase, which smoothes the
curves.

3.5 Sensitivities  convergence
A sensitivity analysis with regards to the thermal
capacitances has been conducted. It appears that the
internal mass has 3 times more influence than the wall
capacitances, but the dependency is not so important
since an increase by 50% of the internal mass
capacitance results in an increased less than 7.5 % of
the required power.
On the other hand, the assumption with an internal
mass separated from the air cabin by a convection
resistance has been analyzed. Integrating directly the
internal mass capacitance to the air (i.e. without
convection resistance) increases by 9% and 28%
respectively the heating needs and the cooling needs.
In addition, if the inner radiative couplings are
considered between the walls and the air (instead of
between the walls and the internal mass), the cooling
needs are increased by 15%. Of course, those two
approaches do not represent the reality, but this
analysis emphasizes the fact that the internal mass has
to be considered properly.
Furthermore, a sensitivity analysis on the conditions
given in Table 2 is conducted with the following cases:
 Case 1: targeted temperature at the end of the
convergence 2C lower than steady state.
 Case 2: required duration to reach proper cabin
temperature is 10 min instead of 15 min initially.
 Case 3: initial condition: vehicle parked under sun
(and so initial cabin temperatures higher than
outside temperature).
Results are presented in Table 3. The two first cases
have impacts around 10%. On the other hand, taking
into account a case with the cabin under sun for hot
cases increased by more than 40% the thermal needs.
Table 4. Sensitivities to operating conditions.

Thermal needs (W) and relative gap (%).
Text
Case 1
Case 2
Case 3
0C

-10.0%

12.5%

N/A

40C

-8.6%

8.6%

42.9%

3.6 Cabin needs  convergence
The thermal needs for convergence are presented in
Figure 12. In addition to the with or without
recirculation grey band, a point at 40C corresponding
to the case with a parked vehicle under the sun is added
since it increases a lot the needs.

DOI
10.3384/ecp17132771

For the convergence mode, the heating needs are
roughly twice the needs for the steady state mode. The
increase is less important for the cooling needs.
Those results suggest that, for an electric vehicle,
the usage will have a strong influence on the thermal
needs and, thus, on the vehicle range. Indeed, if the
vehicle is used only for urban trip, short distances but
lots of time at low speed or even stopped, the HVAC
consumption will be high due to convergence mode.

Figure 12. Convergence thermal needs

4

Conclusion

A transient thermal model of a vehicle cabin has
been developed. Different model assumptions have
been discussed and analyzed. The results showed that
the model is not so sensitive to some non trivial
modeling aspects such as the convective correlations.
However, it appeared that neglecting the inner
radiation or the internal thermal node can have an
important impact in some cases (up to 15 to 25%
approximately). On the other hand, it appeared that, if
one wants to determine the thermal cabin needs, the
considered arbitrary conditions actually dramatically
influence the results. In addition, it is important to
consider the dehumidification needs and the latent heat
generated in the evaporator.
The model allowed establishing the thermal needs
for the steady state case as well as for the convergence
mode. The heating needs for the convergence mode are
roughly twice the needs for the steady state mode. In
addition, the thermal needs are of the same order of
magnitude as the traction needs. The results clearly
indicate that the thermal needs are damageable for
electric vehicle range, particularly the heating, and that
the vehicle usage is determinant.
In future work, the proposed model will be
integrated in an electric vehicle model in order to study
different thermal strategies such as the use of a heat
pump, pre-conditioning and thermal storage. The
model can also be used to evaluate improved cabin
thermal design.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

779

Cabin Thermal Needs: Modeling and Assumption Analysis

Acknowledgements

env

Environment

This work received financial support from the French
National Research Agency (ANR) under the ELEC-HP
project (grant number ANR-11-VPTT-005).

evap

Evaporator

ext

Exterior

IR

Infrared

In

Inner side

HX

Heat exchanger

mix

Mixed

out

Outer side

pass

Passengers

return

Return

sat

Saturation

sol

Solar

Nomenclature
Symbol

Name [unit]

A

Area [m2]

cp

Specific heat [J.K .kg ]

F

View factor [-]

-1

-1

-1

h

Enthalpy per unit mass [J.kg ]

L

Length [m]

Llv

-1

Latent heat of vaporization [J.kg ]

m

Mass flow rate [kg.s ]

trans

Transmitted

Nu

Nusselt number [-]

w

Related to water

Pr

Prandtl number [-]

wall

At or through wall surface

Q

Heat transfer rate [W]

-1

Thermal resistance [K.W-1]

R
Ra
Re

Rayleigh number

T

Temperature [K]

t

Time [s]

u
V
v

Internal energy per mass [J.kg-1]

xi

Reynolds number [-]

Volume [m3]
Velocity [m.s-1]
Mass ratio of the species i in a
mixture [kg.kg-1]

Greek symbols



Absorptivity [-]



Relative humidity [-]



Emissivity [-]






Density [kg.m-3]
Stefans constant [-]
Recirculation [-] or transmissivity [-]

Subscripts or Superscripts
abs

Absorbed

air

Related to moist air

blown

Blown

cab

Cabin

cond

Conduction

conv

Convection

780

References
Abou Eid, R., 2016. Rapport - Passenger comfort and HVAC
thermal load in a tramway.
Al-Kayiem, H.H.., Sidik, F.B.M.., Munusammy, Y.R.. A..
L., 2010. Study on the Thermal Accumulation and
Distribution Inside a Parked Car Cabin. Am. J. Appl.
Sci. 7, 784789.
ASHRAE, 2009. ASHRAE HandbookFundamentals.
Bergman, T.L., Lavine, A.S., Incropera, F.P., Dewitt, D.P.,
2011. Fundamentals of Heat and Mass Transfer, 6th
ed. John Wiley & Sons.
Boukhris, Y., Gharbi, L., Ghrab-Morcos, N., 2009. Modeling
coupled heat transfer and air flow in a partitioned
building with a zonal model: Application to the winter
thermal comfort. Build. Simul. 2, 6774.
doi:10.1007/S12273-009-9405-8
Daoud, A., Galanis, N., 2008. Prediction of airflow patterns
in a ventilated enclosure with zonal methods. Appl.
Energy 85, 439448.
doi:10.1016/j.apenergy.2007.10.002
Fujita, A., Kanemaru, J. ichi, Nakagawa, H., Ozeki, Y.,
2001. Numerical simulation method to predict the
thermal environment inside a car cabin. JSAE Rev. 22,
3947. doi:10.1016/S0389-4304(00)00101-6
Inard, C., Bouia, H., Dalicieux, P., 1996. Prediction of air
temperature distribution in buildings with a zonal
model. Energy Build. 24, 125132. doi:10.1016/03787788(95)00969-8
Iskandar, B.S., 2010. Study on the Thermal Accumulation
and Distribution Inside a Parked Car Cabin Hussain H
. Al-Kayiem , M . Firdaus Bin M . Sidik and
Yuganthira R . A . L Munusammy Department of
Mechanical Engineering , University Technology
PETRONAS ,. Ashrae Stand. 7, 784789.
Kataoka, T., Nakamura, Y., 2001. Prediction of thermal
sensation based on simulation of temperature
distribution in a vehicle cabin 30, p, 195212.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132771

Session 10D: HVAC Systems

Li, W., Sun, J., 2013. Numerical simulation and analysis of
transport air conditioning system integrated with
passenger compartment. Appl. Therm. Eng. 50, 3745.
doi:10.1016/j.applthermaleng.2012.05.030
Marcos, D., Pino, F.J., Bordons, C., Guerra, J.J., 2014. The
development and validation of a thermal model for the
cabin of a vehicle. Appl. Therm. Eng. 66, 646656.
doi:10.1016/j.applthermaleng.2014.02.054
Mezrhab, A., Bouzidi, M., 2006. Computation of thermal
comfort inside a passenger car compartment. Appl.
Therm. Eng. 26, 16971704.
doi:10.1016/j.applthermaleng.2005.11.008
Sanaye, S., Dehghandokht, M., Fartaj, A., 2012.
Temperature control of a cabin in an automobile using
thermal modeling and fuzzy controller. Appl. Energy
97, 860868. doi:10.1016/j.apenergy.2012.02.078
Sevilgen, G., Kilic, M., 2012. Three dimensional numerical
analysis of temperature distribution in an automobile
cabin. Therm. Sci. 16, 321326.
doi:10.2298/TSCI1201321S
Swinbank, W.C., 1963. Long-wave radiation from clear
skies. Q. J. R. Meteorol. Soc. 89, 339348.
doi:10.1002/qj.49708938105
Torregrosa-Jaime, B., Bjurling, F., Corberan, J.M., Di
Sciullo, F., Paya, J., 2015. Transient thermal model of
a vehicles cabin validated under variable ambient
conditions. Appl. Therm. Eng. 75, 4553.
doi:10.1016/j.applthermaleng.2014.05.074
Versteeg, H., Malalasekera, W., 2007. An introduction to
computational fluid dynamics: The finite volume
method, PEARSON Pr. ed.
Wischhusen, S., 2012. Modelling and Calibration of a
Thermal Model for an Automotive Cabin using
HumanComfort Library. Int. Model. Conf. 253263.
doi:10.3384/ecp12076253
Zhang, H., Dai, L., Xu, G., Li, Y., Chen, W., Tao, W.Q.,
2009. Studies of air-flow and temperature fields inside
a passenger compartment for improving thermal
comfort and saving energy. Part II: Simulation results
and discussion. Appl. Therm. Eng. 29, 20282036.
doi:10.1016/j.applthermaleng.2008.10.005
Zhu, S., Demokritou, P., Spengler, J., 2010. Experimental
and numerical investigation of micro-environmental
conditions in public transportation buses. Build.
Environ. 45, 20772088.
doi:10.1016/j.buildenv.2010.03.004

DOI
10.3384/ecp17132771

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

781

782

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Simulative Comparison of Mobile Air-Conditioning Concepts for
Mechanical and Electrical Driven Systems
Arnim von Manstein 1

Dirk Limperich1

Shivakumar Banakar2

1

Daimler AG, Germany, {arnim.von_manstein, dirk.limperich}@daimler.com
Mercedes Benz R & D India Pvt. Ltd., India, Shivakumar.banakar@daimler.com

2

Abstract
Ever increasing energy demand and the stringent
emission norms have resulted in the need for developing
more efficient automotive systems. Fuel economy and
emission targets are the two important driving factors in
the development of an automobile. Efficiency of a
Mobile Air-Conditioning system (MAC) has a
considerable impact on the fuel economy of an
automobile. This study involves simulative comparison
of MAC concepts for mechanical & electrical driven
systems. System models are developed for MAC
concepts using Dymola simulation tool. Drive cycles
considered in this study correspond to the real time
driving scenarios and ambient conditions. From this
study the conclusions are drawn about the most efficient
ways to reach the thermal comfort for the passenger
cabin in an automobile.
Keywords: Energy Efficiency; MAC; HVAC; LV; HV;
MHEV; PHEV; BEV; Compressor; Dymola.

1

Introduction

MAC systems were considered to be an optional
equipment in the past for the automobiles. Nowadays
they have become an integral part of all the cars that are
produced. In the recent time momentum has gained for
the development of hybrid & electric vehicles which
means that vapor compression refrigeration systems will
become a necessity for passenger cabin cooling as well
as battery cooling. The UN estimated the sale of more
than one billion cars with MAC system in 2015 which
has resulted in 2.3 gigatons of carbon dioxide adding
into the environment (Lemke et al. 2011). In order to
reduce the world wide emission caused by automobiles
there are two ways. One is to reduce the direct emissions
of cars. For example implementing stringent emission
norms, use of alternative powertrain concepts, reducing
weight by replacing heavy cast iron components are
very simple and effective methods (Slattery et al. 2010).
The second way would be to reduce the indirect
emissions by changing for example refrigerants of the
refrigeration cycle. Especially for the second way the
European Union set in the directive 2006/40/EC the way
to reduce the Global Warming Potential (GWP) of
refrigerants. It is set that from January 2017 only
refrigerants with a GWP of lower than 150 are allowed
DOI
10.3384/ecp17132783

to be sold in Europe (Europische Union 6/14/2006). In
order to fulfill this directive there are two alternatives,
one is R1234yf (2, 3, 3, 3-Tetrafluorpropen) with a
GWP of 4 and the other is R744 (CO2) with a GWP of
1.
The refrigerant loop in a MAC system consists of an
evaporator, compressor, condenser and expansion
valve. The low temperature, low pressure vapor is
compressed by a compressor to a high temperature and
high pressure vapor. This vapor is condensed into high
pressure liquid in the condenser, by rejecting heat to a
low temperature ambient air and then passes through the
expansion valve. Here, the high pressure liquid is
throttled down to a low pressure liquid and passed on to
an evaporator, where it absorbs heat from the cabin air
and vaporizes into a low pressure vapor. Then it reaches
compressor suction line and the cycle repeats. In order
to increase the efficiency, Daimler AG, Germany,
introduced at early stages for example internal heat
exchanger (IHX). There the refrigerant is subcooled
after it exits the condenser. Therefore you can reach
lower temperatures after expansion to increase cooling
capacity on the one hand and ensure compressor safety
on the other side due to its superheating effect after the
refrigerant exits the evaporator. By ensuring superheat
at the compressor suction, we can eliminate liquid lock.
A key component of a MAC system is the
compressor. This refrigerant compressor is driven in
state of the art automobiles with a belt drive directly
from an Internal Combustion Engine (ICE). With hybrid
powertrain such as Mild Hybrid Electric Vehicle
(MHEV), Plug-in Hybrid Electric Vehicle (PHEV) and
Battery Electric Vehicle (BEV), the compressor is
driven by an electric motor via the necessary voltage
level. Especially for MHEV there are changes in the
automotive industry to reduce this voltage level limit up
to 60V. The further reduction in voltage level with
electrification of the powertrain is known and also the
new voltage level already described in detail (Coppin,
Potteau 2015).
With this electrification and with the implementation
of stringent emission norms to reduce emission of
carbon dioxide, have resulted in the tremendous changes
for MAC.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

783

Simulative Comparison of Mobile Air-Conditioning Concepts for Mechanical and Electrical Driven Systems

2

Experimental Procedure

System simulation techniques play a very important
role in the development and evaluation of various
concepts for MAC system. So far the simulation
predictions were mainly used to determine whether the
designed MAC system is able to achieve thermal
comfort for the customer at certain boundary conditions.
Going a step further the car manufacturers are
interested in studying the system behavior under real
time operating conditions of the customer. For sure
testing with prototypes is very important testing set up,
but lot of what if scenarios can be addressed through
simulation studies in the early stages of concept
development and concept evaluations.
In this study we will limit ourselves to a comparison
of MAC system driven by a mechanical compressor and
an electrical compressor. Because, already there are
large number of scientific papers that discuss the overall
efficiency of ICE and hybrid powertrain, such as
(Carpetis 2000). These concepts are evaluated using
Dymola simulation tool. In general this study will result
in an overall discussion about what is the most efficient
way to reach thermal comfort in an automotive cabin.
In our special use case we evaluate two types of
compressor that come along in automotive application:
1.
Regular mechanical compressor driven by belt
drive
2.
HV electrical compressor with a voltage level
around 400V
Fortunately, there are several reports about Worlds
climate conditions such as the FAT 224. In order to
reduce complexity we just take MAC system operation
into consideration and will provide data for the ambient
air temperature of 22C, 29C and 35C.
As mentioned, these systems are operated by
customers in different ambient and driving conditions.
Most severe conditions for MAC systems are higher
ambient temperatures at low car speed.
Daimler AG has selected one drive cycle (MBVT),
which was created using the real time data from vehicles
operating in various driving scenarios and ambient
conditions all over the world.
The MBVT is a mixed drive cycle with  50% inner
city driving,  35% interstate and  15% highway
(Autobahn) profile. Additional parameters in the drive
cycle include time/speed gradients, acceleration,
deceleration and the pitch. The stop phases are
calculated to be roughly about 4.5 mins.
The MAC system investigated in this study is based
on a series production S-Class system which is operated
in both systems with a hydrofluoroolefin refrigerant
(such as R134a/R1234yf). This set up is described in
detail in Section 3.

784

3

System Description and Simulation
Model

The vapor compression refrigeration system
components configurations that we have used for
investigation in our study corresponds to the series
production S-Class car. Table 1 describes geometrical
parameters of all components used in the system.
Table 1. Component details & geometrical parameters

Component

Description

Condenser

Cross flow,
Fin & Tube
heat
exchanger
with 2 layers

Evaporator

Air cooled,
Cross flow,
Fin & Tube
heat
exchanger

Internal
Heat
Exchanger

Expansion
Valve

Compressor
1
Compressor
2

Concentric
tube in tube
heat
exchanger
Thermal
Expansion
Valve with
superheat
feedback
Swash plate
variable
displacement
compressor
Scroll
compressor

Geometry
Height
453.10
(mm)
Width
640
(mm)
Depth
12
(mm)
HTA (m2) 2.0158
Volume
5.552E(m3)
4
Height
223
(mm)
Width
303
(mm)
Depth
50
(mm)
HTA (m2) 1.199
Volume
0.0011
(m3)
78
Length
498
(mm)
0.0837
HTA (m2)
2
Capacity
(ton)

2.0

Capacity
(cc)

170.0

Capacity
(cc)

33

Simulation models of the components of refrigerant
loop are developed using a multi-engineering dynamic
simulation tool Dymola (version 2015 FD01) and Airconditioning Library (version 1.9). The snapshot of the
system model developed in Dymola is as shown in
Figure 2. In the first step heat exchangers like
Condenser, Evaporator & IHX (Internal Heat
Exchanger) are modelled using the templates from airconditioning library and geometrical data. The
developed heat exchanger models are then calibrated
and validated using the calibration toolbox within

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132783

Session 10D: HVAC Systems

Dymola and experimental data from suppliers. The
compressor model is as described below.
Compressor Model

Inputs

Outputs

n

Isentropic Efficiency


d

mdot

Volumetric Efficiency
P

Effective Isentropic Efficiency

Figure 1. Compressor model variables

Where,
n = Compressor speed
 = Compressor pressure ratio
d = Relative displacement
mdot = Refrigerant mass flow rate through compressor
P = Compressor power consumption
Efficiencies of the compressor i.e., isentropic
efficiency, volumetric efficiency and effective
isentropic efficiency are modeled as a function of
compressor speed, relative displacement and pressure
ratio. Correlations for the compressor efficiencies are
developed using the measured data from the supplier.
Range of the compressor measurement data used for the
modelling is shown in Table 2. The standard deviations
in isentropic efficiency & volumetric efficiency models
are found to be 4.81% & 2.9% respectively. Compressor
performance parameters like mass flow rate, power
consumption and compressor discharge temperature are
computed using these efficiency values.

Figure 2. Representation of a compressor model
developed in Dymola.
Table 2. Details of the compressor measured data used
for modelling.

Parameters



n (rpm)

d

Range

2.5 to 8.4

700 to 8000

0.35 to 1.0

DOI
10.3384/ecp17132783

Figure 3. System model developed in Dymola simulation
tool.

The validated component models were then
integrated to develop the system model as shown in
Figure 2. Two variants of the system models were
developed; System A with engine driven mechanical
swashplate compressor and System B with battery
driven electric scroll compressor; keeping all other
components same. The system simulations were carried
out in the subsequent stage to evaluate and compare the
performance of these two systems.
As previously described (Dermont et al. 2016) the
main challenges in simulating the real time conditions
are the stop phases, where the mechanical swash plate
compressor, during a vehicle stand still at a traffic light,
is shut off. In order to mimic the stop phase of the
compressor in simulations, the compressor speed was
limited to 10 rpm. Because of the very low rpm of the
compressor, refrigerant mass flow in the system is of the
order of 10E-4 kg/s which results in a zero-mass flow
scenario. Flow reversal was observed in some of the
components of the system during the stop phase which
resulted in lots of numerical problems in the simulation.
Numerical problems in the simulations were caused
by the flow reversal that was observed at the outlet of
the condenser. This was found to be because of the
dynamic enthalpy value that was assigned in the flow
source charge, which is connected at the outlet of
condenser. The flow source charge is used to ensure
fixed quantity of charge inside the system. To fix these
numerical problems, the enthalpy input in the flow

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

785

Simulative Comparison of Mobile Air-Conditioning Concepts for Mechanical and Electrical Driven Systems

source charge was assigned a constant value. Simulation
cases were re-simulated again using Dymola 2017
FD01, where the handling of zero flow simulation was
found to be better. It was observed that the simulations
were faster and smoother in the new version of Dymola
as compared to the previous versions.

4

Results & Discussion

After developing the system models, simulations
were done using the MBVT drive cycle for 3 different
ambient temperatures and 2 different air mass flows
over the evaporator at each ambient temperature. The
details of the boundary conditions are as shown below
in Table 3.
Table 3. Details of the comparison study for each
temperature and air massflow rate

MBVT

T_ambient
= 22C

T_ambient
= 29C

T_ambient
= 35C

[kg/min]

[kg/min]

[kg/min]

1,5

2

2

3

4

6

Results are described in the following section.

4.1 Ambient Temperature 22C
The simulations at 22C ambient temperature and
55% relative humidity were done with an air mass flow
of 1,5 kg/min over the evaporator. At 29C ambient
(40% humidity) with a massflow of 2 kg/min and at
35C (40% humidity) with 4 kg/min. The following
simulation results are showing data of the mechanical
and electrical system in one graph for each evaluation
criterion. The relevant criteria for this paper are:
- Pressure (suction and discharge) [bar]
- Evaporator air outlet temperature [C]
- Refrigerant Massflow [kg/h]
- Cooling capacity [kW]
- Coefficient of performance (standardized) [-]
In Figure 4, we can see that the suction and discharge
pressure reach their aimed ratios for both the systems.
For the electrical system both suction & discharge
pressures run more stable, especially for the suction
pressure. This fluctuating pressure from the mechanical
system can result for example in pulsation which have a
negative impact on the acoustics of such a system.

Figure 4. Suction and discharge pressure of both system
as a function of time

There are two main aspect visualized in Figure 5. The
first one is that the massflow for mechanical system
experiences large variations. This is caused by the fact
that the compressor is being driven via the belt drive of
the ICE. Also in the simulation model, the compressor
speed was reduced to a minimum of 10 rpm at stop
phases. A complete stand still of the mechanical
compressor was not achievable with this Dymola model.
This leads us to the second main aspect of Figure 5. Due
to the reduction of compressor speed resulting in a
reduction of massflow, the air outlet temperature of the
evaporator couldnt be kept constant. For longer
periods, for example during long phases of traffic signal,
it is observed that the temperature increases
dramatically. This will result in a massive discomfort in
the passenger cabin as compared to the electrical
system. The electrical scroll compressor was operated
during all stop phases in the drive cycle that results in
maintaining the thermal comfort of the passengers.

Figure 5. Evaporator air outlet temperature and massflow
as a function of time

For the electrical system in general it is evident that
it runs more stable compared to the system with the
mechanical compressor at 22C ambient temperature.
This hypothesis is affirmed in Figure 6. The massive
variation of the cooling capacity of the mechanical
system is again linked to the stop phases. During the

786

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132783

Session 10D: HVAC Systems

stop phase it will decrease because of the reduced
compressor speed. Additionally, the temperature of the
evaporator increase, as the ambient air at 22C is blown
over it. Once the system starts again, the system tries to
reach the evaporator air set point temperature of 3C.

 =   
where,
=

_
|_   | + _

Figure 6. Cooling capacity and COPs as a function of
time

Also the variation in COP of the mechanical system
can be explained with the stop phases. There it is
important to know that mechanical compressors in
automotive application have a variable displacement
which is controlled via parameters of the refrigeration
loop. So once the car starts after a stop phase the loop
tries to reach the evaporator air set temperature. The
speed of the compressor is fixed to the given profile so
the only chance to increase the capacity is to increase
the compressor displacement. This is also shown in
Figure 4 with the graph of the massflow. There it is
noticeable how the massflow is changing due to the
changes in the displacement. Because of the design of
the variable displacement compressor it is found to be
operating in a more efficient mode at lower speed and
full displacement. After the set point is achieved the
displacement decreases and it runs afterwards in a rather
inefficient mode in comparison to the scroll compressor.
In Figure 6 the COP is standardized because at stop
phases when the mechanical compressor is shut of we
still gain the cooling capacity which is stored in the
refrigerant loop. But in the meantime you lose thermal
comfort in the vehicle cabin so it is needed to take this
also into consideration in calculation of the COP. So the
factor  is introduced for calculating COPs. Its graph is
plotted for the air outlet temperature over the evaporator
in Figure 7.

Figure 7. Correction factor () for each temperature of the
air at the evaporator outlet

4.2 Ambient Temperature 29C
The following graphs for 29C ambient are pretty
similar to those of 22C ambient. In Figure 8 we see that
both systems attaining the same high pressure level and
due to the constant speed of the electrical compressor
the suctions pressure is in stable conditions.

Figure 8. Suction and discharge pressure of both system
as a function of time

In Figure 9 the advantages of an electrical system are
evident. Constant refrigerant massflow and evaporator
air exit temperatures are observed for most part of the
system operation. Thermal comfort in the cabin is also
maintained for most part of the drive cycle.

DOI
10.3384/ecp17132783

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

787

Simulative Comparison of Mobile Air-Conditioning Concepts for Mechanical and Electrical Driven Systems

4.3 Ambient Temperature 35C

Figure 9. Evaporator air outlet temperature and massflow
as a function of time

In the end the simulations where done at an ambient
temperature of 35C. In statistics this might be the most
severe temperature for Germany for example. But in
southern parts of Europe and for example in the western
region of the United States of America these
temperatures occur more often. It is easy to detect that
now both systems operate at the upper end of their
capacities. In Figure 11 the suction pressure stays in the
same regions except during the stop phases, but the high
pressure differs a lot. This can be explained to the
different compressor types. As previously described the
mechanical compressor is a piston type and the electrical
is a scroll one.

By visual comparison the system with an electrical
compressor operates with a better COPs for most part of
the drive cycle. The large peaks for the system with
mechanical compressor are due to the stored cooling
capacity in the system. Additionally, it is observed from
Figure 8 that the high pressure for the mechanical
system decreases during the stop phases.

Figure 11. Suction and discharge pressure of both system
as a function of time

Figure 10. Cooling capacity and COP as a function of
time

Although the exciting air temperature over the
evaporator is almost kept constant for the electrical
system you can easily see by analyzing the plotted
massflow that the compressor is also varying the speed.
The massive differing shows that even if the scroll
compressor is independent of the belt drive of the ICE it
regulates dynamically for this high load case.

In order to compare both systems in terms of
efficiency we compare the classic COP without
standardization regarding cabin comfort:
 =
 =

=1  




;  =

=1  


= 1,2851  128,5%

So even under severe conditions the electrical
compressor system runs at 29C in a higher COP by
28,5% compared to the mechanical compressor system.
The work that is needed over the driving cycle for the
mechanical conferred to the electrical is higher by 57%.
Although there is just an overall advantage of 28% the
difference is with variation of the cooling capacity.

788

Figure 12. Evaporator air outlet temperature and
massflow as a function of time

As a last the COPs in Figure 13 interestingly are no
longer higher for the electrical system. This is also due

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132783

Session 10D: HVAC Systems

to the compression technique of the mechanical
compressor. Piston type compressors have an optimum
operation ratio at almost full stroke with 100%
displacement. The average displacement over this
driving cycle for the mechanical system is at 50%.

Acknowledgements
The authors would like to thank and gratefully
acknowledge the support received from RD/KIT and
RD I/CCS departments at Daimler AG & MBRDI
respectively.

Publication bibliography
Carpetis, C. (2000): Globale Umweltvorteile bei Nutzung von
Elektroantrieben mit Brennstoffzellen und/oder Batterien im
Vergleich zu Antrieben mit Verbrennungsmotor. Edited by
Deutsches Zentrum fr Luft und Raumfahrt e.V. Institut fr
Technische Thermodynamik. Stuttgart (STB-Bericht, 22),
checked on 10/12/2016.
Coppin, Oliver; Potteau, Sbastien (2015): 48-V-HybridSystemarchitektur zur Reduzierung der CO2-Emissionen. In
ATZ elektronik 10 (02).

Figure 13. Cooling capacity and COPs as a function of
time

Simulations plots are described for one evaporator
air massflow rate at each ambient temperatures. All the
plots arent added to this paper but they do show similar
behavior in general. The conclusion all in all stays the
same.

5

Conclusion

For future investigation simulation tools such as
Dymola will be mainly used for efficiency analysis and
system optimizing operations. The comparative study
outlined this strategy and justified this procedure. This
simulation will be moreover expand in an even wider
temperature range to complete the virtual behavior of an
automotive A/C-loop. Especially transient simulations
will become more and more sufficient. By simulating a
mechanical compressor at all ambient temperatures and
even an electrical at severe conditions the changes in the
massflow are tremendously. By simulating just steady
state conditions you cant visualize those changes that
are also important for NVH (Noise Vibration and
Harshness) analyses and cabin comfort for the customer.
The shut-off phases of the mechanical system are the
main issue as stated in chapter 3. For this point of view
we could show that the system driven with an electrical
scroll compressor has 20% higher COPs at 29C than a
system with a mechanical (belt driven) compressor. In
terms of increasing the system efficiency, the
hybridization of passenger cars is also a big chance for
the thermal management of the cabin and powertrain. A
validation of the simulation model is of course
applicable and will be done as a next step.

Dermont, Pieter; Limperich, Dirk; Windahl, Johan; Prlss,
Katrin; Kbler, Carsten (2016): Advances of Zero Flow
Simulation of Air Conditioning Systems using Modelica. In :
Deployment of high-fidelity vehicle models for accurate realtime simulation, 2011-02-05: Linkping University
Electronic Press (Linkping Electronic Conference
Proceedings), pp. 139144.
Europische Union (6/14/2006): Richtlinie 2006/40/EG des
Europischen Parlaments und des Rates vom 17. Mai 2006
ber Emissionen aus Klimaanlagen in Kraftfahrzeugen und
zur nderung der Richtlinie 70/156/EWG des Rates.
2006/40/EG, revised L161/12.
Lemke, Nicholas; Mildenberger, Julia; Graz, Martin (2011):
Untersttzung der Markteinfhrung von Pkw-Klimaanlagen
mit dem Kltemittel CO2 (R744). Prfstandsmessungen und
Praxistest. Im Auftrag des Umweltbundesamtes. Edited by
Umweltbundesamt. Dessau-Rolau (Texte, 64). Available
online at http://www.uba.de/uba-info-medien/4184.html,
checked on 6/25/2015.
Slattery, B. E.; Edrisy, A.; Perry, T. (2010): Investigation of
wear induced surface and subsurface deformation in a
linerless AlSi engine. In Wear 269 (3-4), pp. 298309. DOI:
10.1016/j.wear.2010.04.012.

Nomenclature
A/C

Air Conditioning

BEV

Battery Electric Vehicle

COP

Coefficient of Performance

COPs

Coefficient of Performance standardized

GWP

Global Warming Potential

ICE

Internal Combustion Engine

IHX

Internal Heat Exchanger

MAC

Mobile Air Conditioning

MBVT Special Daimler Driving Cycle
MHEV Micro Hybrid Electric Vehicle

DOI
10.3384/ecp17132783

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

789

Simulative Comparison of Mobile Air-Conditioning Concepts for Mechanical and Electrical Driven Systems

NVH

Noise Vibrations and Harshnes

PHEV Plug-In Hybrid Electric Vehicle
RPM

Rounding Per Minute

n

Compressor speed



Compressor pressure ratio

d

Relative displacement

mdot

Refrigerant mass flow rate through compressor

P

Compressor power consumption

790

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132783

Duty Cycle for Low Energy Operation of a Personal Conditioning
Device
Rohit Dhumane

Jiazhen Ling Vikrant Aute

Reinhard Radermacher

Center for Environmental Energy Engineering, University of Maryland, College Park, 4164 Glenn L. Martin Hall
Bldg., MD 20742, USA
{dhumane,jiazhen,vikrant,raderm}@umd.edu

Abstract
The Roving Comforter (RoCo) is an innovative personal
thermal management technology that provides ultimate
personal thermal comfort for individuals in inadequately
or even unconditioned environments. It is a miniature heat
pump system mounted on a robotic platform capable of
autonomously following individuals to deliver comfort by
directing hot or cold air through automatically controlled
nozzles. This allows buildings to relax their thermostats
up to 4F (2.2C), leading to energy savings anywhere between 10 to 30% depending on climatic conditions. Since
RoCo is a portable device, it needs to be operated on battery. A smaller battery pack will require frequent charging
making it inconvenient for the users, while a bigger battery
pack will add to the weight of the device leading to higher
power consumption during motion. To address this problem, a multi-physics model for the operation that incorporates thermodynamics, electricity and mechanics of RoCo
Figure 1. Current prototype of RoCo
is developed and two duty cycles analyzed. Strategies for
the operation of RoCo are provided from the observations
of results.
temperature range in either the hot or cold direction, toKeywords: Battery, Air-conditioner, Duty-cycle
tal HVAC energy is reduced at a rate of 10% per C. To
enable expansion of building set-point temperatures, it is
1 Introduction
necessary to provide supplementary Personal ConditionClimate change and global warming have been hot top- ing System (PCS) operating at significantly lower energy
ics of discussion over past few decades. The greenhouse consumption.
PCS offer dual benefits of energy saving and increased
gas emission from human activities has lead to disrupcomfort.
As a result, several PCS have been developed
tion of several natural systems leading to rising sea-levels,
and
are
summarized
in the review articles by Zhang et al.
increased ground instability in mountains and change in
(2015)
and
Vesel
and
Zeiler (2014). However, except
seasonal winds. The United Nations IPCC has identified
for
the
desk
and
ceiling
fans, they are not commercially
the building industry as the one with the most climate
available.
This
can
be
attributed
to a variety of factors
mitigation potential (Intergovernmental Panel on Climate
unique
to
the
designs
like
poor
thermal
performance, low
Change Fourth Assessment, 2007).
energy
efficiency,
high
cost
and
poor
aesthetics.
To adBuilding Heating, Ventilation and Air Conditioning
(HVAC) account for 13% of energy consumption in dress these issues and to achieve the benefits of PCS, an
the United States (United States Department of Energy, innovative robotic personal conditioning device called the
2011). Much of this energy goes into maintaining narrow Roving Comforter (RoCo) shown in Figure 1, is being deindoor temperature ranges that building operators consider veloped (Du et al., 2016).
necessary for comfort but are really not necessary for oc2 System Description
cupant comfort (Zhang et al., 2011).
Hoyt et al. (2015) demonstrated the potential of energy In technical terms, RoCo is a vapor compression system
savings from extending thermostat set-points in the build- mounted on an autonomous robotic platform and delivering. They concluded that if it were possible to relax the ing comfort by directing hot or cold air using its automatDOI
10.3384/ecp17132791

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

791

Duty Cycle for Low Energy Operation of a Personal Conditioning Device

ant control volumes. The four refrigerant circuits formed
by each of the refrigerant tube immersed in the PCM are
assumed to be symmetric. To avoid computational expense, only one of these refrigerant circuits is modeled.
Flow splitter and flow mixer components are used to accomplish this. The splitter component divides the refrigerant mass flow rate into four equal parts and the mixer
merges it back to resume the original mass flow rate for
the next component in the refrigerant circuit. The PCM
blocks interact with the refrigerant control volume using
the HeatPort interface. The refrigerant then flows through
receiver, valve and evaporator before reaching the compressor.
Component models for refrigerant tube connecting various components are also included.

Figure 2. Conceptual representation of RoCo in operation

ically controlled nozzles. It is a heat pump on wheels.
RoCo stores its condenser heat in a compact phase
change material based thermal storage which needs to be
recharged before its next cooling operation. Thus RoCo
operates in two modes and it is necessary to size the battery to deliver multiple operating cycles. Figure 2 shows
the schematic of the two alternating modes of RoCo. The
left schematic in Figure 2 shows the onboard vapor compression system using R134a as the refrigerant. The cooling operation is terminated when the PCM surrounding
the condenser is completely melted. Before the next cooling operation, there is a need to re-solidify the PCM.
This PCM recharge is achieved by a gravity assisted thermosiphon operation. Details of this recharge operation
and its modeling are discussed in Dhumane et al. (2016).
The current prototype has separate battery packs for its
robotic platform and vapor compression system. For the
new prototype, a single unified battery pack is desired. An
innovative nozzle design which permits nozzle rotation using motors in both horizontal and vertical plane is being
developed for the new prototype. To understand various
power draws for a single unified battery pack a duty cycle,
representative of a worst-case operation of the new RoCo
prototypes incorporating all the modifications is conceptualized. Simulations are carried out for the operation of various components to come up with strategies for increased
the battery operation time.

3

Component Modeling

The model for the current simulation is shown in Figure 3.
The top portion of the model contains components for
modeling the vapor compression cycle. The compressor
pumps the refrigerant in the circuit. A non-adiabatic tube
element accounts for heat losses from the refrigerant between the compressor and the condenser. The condenser
consists of inlet and outlet headers, and four refrigerant
tubes immersed in PCM (See Figure 2 to understand the
tube layout). The headers are modeled by lumped refriger792

The bottom left portion contains the battery model and a
power load component. The latter needs power draw as an input.
The components which draw current from the battery are Compressor, fan, nozzle, robotic platform and on-board electronics.
The power consumption from all of them is added and provided
as input for the power load component. It then determines the
current draw from the battery. This section discusses equations
involved in calculating the power consumption from all these
components.

3.1

Vapor Compression System Components

RoCo is a heat pump on wheels and detailed modeling for vapor
compression cycle is carried out using components from CEEE
Modelica Library (CML) (Qiao et al., 2015). Components used from the library are compressor, evaporator, pipe, receiver and fixed orifice expansion device.

3.2

Phase Change Material Heat Exchanger

The condenser consists of helical refrigerant tubes surrounded
by the phase change material (PCM). The PCM melting is a
complex phenomenon due to the fact that the solid-liquid boundary moves depending on the rate of heat transfer and hence its
position with time forms part of the solution. The rate of heat
transfer varies progressively during the melting due to varying
effects of conduction and natural convection. It decreases in at
early times, attains a minimum, then rises again to a maximum
and subsequently decreases (Sparrow et al., 1977). The helical
nature of the refrigerant tube further increases the complexity by
making the problem 3D. Due to strong non-linear nature of the
problem, a simple 2D problem of melting in a square cavity may
take several days on a personal computer (Wang et al., 2010). Finally, the two-phase refrigerant circuit exchanging heat with the
PCM adds difficulty in convergence.
The model used in the current work is a trade-off for accuracy, complexity and usability. The PCM block is taken as a
lumped control volume to eliminate the momentum equation.
Two components are used to model PCM: PCMConductor
and PCMCapacitor which are PCM analogous versions
of HeatCapacitor and ThermalConductor from the
Thermal package of Modelica Standard Library.
Temperature transforming model by Cao and Faghri (1990) is
used to model the energy equation since it also captures temperature glide over melting without much oscillatory effects. A heat
transfer coefficient vs melt fraction profile based on the various
heat transfer regimes discussed in Sparrow et al. (1977) is used
and fitted to match experimental data.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132791

Session 10D: HVAC Systems

PCM
C

pCMConductor

header

pCMCapacitor

Mixer

Splitter

compressor

valve

RPMTransfer
Evaporator

tube

2100

PT1

RPM

T=3

receiver

evaporator
cellParameters

duration=0

A
batteryStack

+

currentSensor

duration=0
duration=0

+1

mdot

+1

robotic platform

RH

load

V

voltageSensor

np

Tair

add
+1

ns

angle

P

robot

+

+1

Nozzle

+1

ground

battery

add

offset=0

coefficient_rolling_friction
fanAndElectronics
offset=0

acceleration

nozzle

offset=0

fan and onboard
electronics

offset=0

k=10

Figure 3. Schematic of System Model for RoCo.

3.2.1

PCM Capacitor

The PCM Capacitor block includes a HeatPort and models
the heat storage of PCM. The equations for temperature transforming model use scaled temperature (T  [K]) as input. It is
defined as:
T  = T  Tm

(1)

where Tm [K] is the mid-point of the temperature glide and T
[K] is the lumped PCM temperature. The specific enthalpy (h
[J kg1 ]) is calculated by:
h = c(T  + s)

where,  T [K] is the temperature range over which the PCM
melts.

l

(4)

l

The if-else loops are implemented using NoEvent operator as
shown below for the specific heat capacity block.

DOI
10.3384/ecp17132791

The melt fraction ( ) of PCM is calculated from its enthalpy
value as:
 = max(0, min(1,

(2)

The specific heat capacity (c [J kg1 K1 ]) and the source term
(s [K]) are defined as:


T  <  T
cs ,
hsl
cs +cl

(3)
c=
2 + 2 T ,  T  T   T

c ,

T > T
l

(
 T,
if T    T
s = cs
hsl

c T + c , T > T

if noEvent(T_star < -deltaT) then
c = c_s;
elseif noEvent(T_star <= deltaT) then
c = (c_s + c_l)/2 + h_sl/(2*deltaT);
else
c = c_l;
end if;

h
)
hl

(5)

where hl [J kg1 ] is the enthalpy at the point where the PCM just
turns liquid. The equation is simplified because of the fact that
the enthalpy scale is defined as zero for the point where the PCM
starts to melt. The melt fraction is made available for the PCM
capacitor block through the RealOutput interface.

3.2.2 PCM Conductor
PCM Conductor block connects the refrigerant control volume
of the condenser to the PCM Capacitor block. It extends
Modelica.Thermal.HeatTransfer.Interfaces.
Element1D block and provides for the heat flow, which is calculated using CombiTable1D fitted function for heat transfer
coefficient as a function of melt fraction. The RealInput
interface is used to obtain melt fraction input from PCM
Capacitor.
Table 1 contains the anchor points given to the CombiTable
block used as input for the normalized heat transfer coefficient

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

793

Duty Cycle for Low Energy Operation of a Personal Conditioning Device

Fa

as a function of melt fraction. The constant value used to multiply the normalized function to obtain heat transfer coefficient
(HTC) is 116 W m2 K1 . These numbers are obtained by matching the condenser pressure from simulation to the experiment
since there are no correlations to capture the behavior in literature. Pal and Joshi (2001) discusses the heat transfer variation
in the four regimes captured by Table 1. The initial heat transfer
occurs in a conduction dominated regime. Then there is a reduction in heat transfer coefficient with the appearance of small melt
layer because the velocity of the liquid PCM due to buoyancy
force is low. The melting then progresses to a convection dominated regime where the velocity of liquid PCM increases causing
a higher rate of heat transfer. Finally, the magnitude of velocity
decreases as the temperature in the molten PCM becomes more
uniform with time due to natural convection stirring, leading to
reduced buoyancy force for convection.
Table 1. Input table for PCM Conductor block.

Normalized HTC

0
0.2
0.4
0.7
1

1
0.9
1
0.9
0.8

Figure 4. Free Body Diagram for Robotic platform

Z t

(7)

I dt
0

(6)

where, Q [C] is the charge removed and C [C] is the capacity
of the cell. SOC0 [C] is the initial state of charge of the cell.

794



Q =

Battery

Q
C

Ff

The model provides inputs for modeling the capacity of the cell,
resistances and capacitances as variables using parameters for
calendaric aging and aging due to cycling. The charge removed
from the battery is calculated as shown in Equation (7).

Battery modeling is necessary to reduce the total weight and
cost, which are critical parameters in the design of RoCo. Accurate prediction of the state of charge (SOC) of the battery is essential to determine how long the battery will last with a typical
user case scenario. The battery capacity should be sufficient to
run the whole cooling operation with charging and discharging
operations without entering regions of overcharging and overdischarging for longer operation.
There are a variety of methods for mathematical modeling of the battery which vary in complexity, computational requirements and reliability of the prediction. The models based
on electrochemical principles which model first-principle phenomena require significant computational resources and detailed
datasets for input (Marco et al., 2015). Equivalent circuit models have a good trade-off between exactness, complexity and usability while still providing some insights into the battery state
(Einhorn et al., 2011b). As a result, the equivalent circuit approach is used for the current research. Modeling for the battery is carried out using the Electrical Energy Storage Library
(Einhorn et al., 2011a). The battery pack is modeled using the
model LinearDynamicImpedance from the battery stack
sub-package.
The battery model in the library involves modeling a single
cell as an effective resistance capacitor [R-C] circuit. By taking
inputs of the number of cells in series and number of cells in
parallel of the battery, the behavior of the battery can be modeled
by appropriate scaling of the cell model.
The state of charge of a cell (SOC) is calculated as:
SOC = SOC0 

Fg

Various components are available to model different types of
loads in the circuit, which determines the current I [A]. For
the present study, the component SignalPower is used. This
component takes power draw as input and creates loads on the
battery accordingly.

3.4

Platform

The power consumption from the motion of Robotic platform is estimated from first-principles based approach used by
(Gonullu, 2013). The free body diagram of the platform is
shown in Figure 4. The total force required for motion (Ft [N]) is
the sum of gravitational force acting along the incline (Fg [N]),
the drag force by the air (Fd [N]), the force to overcome friction
(Ff [N]) and the force required to produce acceleration (Fa [N]).
Ft = Fg + Fd + Ff + Fa

(8)

Since the platform operates at speeds of around 1 m s1 , the
drag force (Fd ) can be neglected. If m [kg] is the total mass of
RoCo, g [m s2 ] the acceleration due to gravity, the remaining

30
28
Voltage [V]

3.3

Melt Fraction

Fd

26
24
22
20

0

50

100
150
Time [min]
Simulation
Experiment

200

Figure 5. Comparison of simulation results to experimental for
the battery discharge test

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132791

Session 10D: HVAC Systems

forces can be calculated as:
Fg = m g sin()
Ff = fr m g cos()
Fa = m a

1

(9)
(10)
(11)

0
2
0

20

40

Finally, the net power for the motion of the platform (P [W])
is obtained as:

60
80
Time [min]

VCC

100

100
Nozzle

120

1

P = Ft v

(12)

where v [m s1 ] is the velocity of the platform.
Typical variations in the motion are changes in velocity, motion over different surfaces and on surfaces with different inclinations. A TimeTable block for each of acceleration (a
[m s2 ]), rolling friction resistance of surface ( fr ) and inclination angle of surface with horizontal () is used to capture these
variations in the motion.

3.5

Nozzle

The stationary nozzle modeled in Figure 1 can be housed with
two motors to rotate it along horizontal and vertical directions. The power consumed by the rotary nozzle is taken
as the maximum power draw of two DC motors used for its
motion. The transient power draw from the nozzle is given
by Modelica.Blocks.Sources.TimeTable block. The
nozzle is assumed to move continuously for a period of 10 seconds, for every 5-minute interval.

4

System Model

The screenshot for the system model is shown in Figure 3. The
inputs for various components are discussed in this section. The
displacement volume and RPM for the compressor are provided
from manufacturers data. The efficiency is adjusted to match
the power consumption measured from experiment (Du et al.,
2016). For pressure drop calculations, values are calculated using various correlations (McAdams et al., 1942; Friedel, 1979;
Lockhart and Martinelli, 1949; Mller-Steinhagen and Heck,
1986) and nominal values selected based on the range calculated
from them. For refrigerant heat transfer coefficient, single phase
heat transfer coefficients are evaluated using Dittus and Boelter (1985) correlation. Two phase heat transfer coefficient in
the evaporator is evaluated using Shah (1982) correlation. Condenser consists of helical coils inside the PCM. The single phase
liquid only heat transfer coefficient is calculated using Schmidt
(1967) correlation to be used as input to Shah (2016) correlation
for two phase heat transfer coefficient calculation. The air side
heat transfer coefficients are calculated using Wang et al. (2000).
The battery used in the prototype shown in Figure 1 consists
of 21 cells, consisting of 3 parallel lines of 7 cells of Samsung
ICR18650-26F in series (7s3p). Its capacity is 7.8 A h. Obtaining the input parameters for battery requires results from extensive battery testing carried out primarily to obtain parameters
for the model which were not available in open literature. To

DOI
10.3384/ecp17132791

0

20

40

60
80
Time [min]

120

0

20

40

60
80
100
120
Time [min]
Robotic Platform

1

0

Fan

The
fan
operates
continuously
during
the
operation
of
RoCo
and
can
be
modeled
by
Modelica.Blocks.Sources.Constant. The power
measured from the experiment is given as input. The power
draw from on-board electronics is also constant and is lumped
together with the fan power.

3.6

2
0

Figure 6. Typical operation of RoCo with VCC always ON

address this, the resistance and capacitance values for the model
are taken from Muenzel et al. (2015) for Sanyo UR18650FM
since it has similar cell capacity and initial internal impedance as
Samsung ICR18650-26F. These two parameters are most
important for modeling overall battery performance as can be
seen from results of Einhorn et al. (2011b). For accurate prediction of battery performance, a battery discharge test is conducted
using a constant power drawing circuit. The power draw of this
circuit is selected to be similar to that of RoCo during a steady
operation. The SOC vs OCV (Open Circuit Voltage) table is
modified in the model to match the experimental discharge profile. The comparison of voltage discharge profile of simulation
and experimental case is shown in Figure 5.
The weight of the system applied to the platform is taken to
be 30 kg. RoCo is assumed to be moving upwards a slope with
10 incline. The coefficient of rolling friction is taken to be 0.05
which applies for poor condition stone paving to represent the
worst conditions.
Two duty cycles are considered for the operation. The logic
for the operation of various power draw sources in a two hour
time duration is shown in Figure 6 and Figure 7. In the first
one, the fan and compressor continue to operate for the whole
duration (hereby referred to as Cycle 01, see Figure 6) while
in the second one, they are stopped when RoCo is in motion
(hereby referred to as Cycle 02, see Figure 7). This is done to
avoid peaks in the power draws for battery. In the simulation,
the compressor and fan are first turned off. The platform motion
is started after a delay of 1 second.

5

Results and Discussion

The model is simulated using Dymola 2017 with Radau IIa order 5 stiff solver. The tolerance selected for the solver is 1e-6.
The simulation time on a PC with 16 GB RAM, 64-bit Operating
System and 3.5 GHz is 1159 seconds.
Figure 8 and Figure 9 show comparison of the simulated results with the experimental data. It can be observed that the simulation predicts the experimental trends to a reasonable extent.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

795

Duty Cycle for Low Energy Operation of a Personal Conditioning Device

300
2

Capacity [W]

250

1

20

200
150

100
50

0

20

40

60
80
Time [min]

100
VCC

120

0
0

1

40

80
Time (min)

120

160

Expt Evaporator capacity Sim Evaporator Capacity
Expt Compressor power Sim Compressor power

2
0

0

20

40

60
80
Time [min]

100
Nozzle

120

Figure 9. Cooling capacity and power consumption of RoCo

1
120

100

0

20

40

Power [W]

0
60
80
100
120
Time [min]
Robotic Platform

Figure 7. RoCo Operation with VCC turned off during motion

80
60
40
20

0
0

Pressure [kPa]

2000

20

40

60
Time [min]

Cycle 01

1600
1200

80

100

120

Cycle 02

Figure 10. Power draw during the two operating cycles

800
400

opening and flow coefficient are adjusted using the experimental
refrigerant mass flow rate. The suction and discharge pressure
0
from simulation also need to be noted during the txv parameter
0
40
80
120
160
calibration. Since the RPM and displacement volume of comTime [min]
pressor are available from manufacturers data, the valve as the
Expt Discharge Sim Discharge Expt Suction Sim Suction
only component to significantly affect the refrigerant mass flow
rate, permitting the aforementioned adjustment. Calibration is
Figure 8. Pressures at suction and discharge of compressor
also needed for the battery, compressor power and PCM, which
is already discussed in the respective sections.

The experimental setup uses a variable expansion valve which
is modulated by an operator. The valve model used in the simulation assumes fixed opening and constant discharge coefficient.
These two effects lead to the deviations in measured pressures
and mass flow rates in the initial part of the operation. Another
factor for the deviation of discharge pressure in the initial 20
minutes (Figure 8) is from the inaccuracy of the heat transfer
coefficient.
The dynamic modeling for cycle 02 is complicated due to
cycling. So to model it, the power consumption profile of
compressor is extracted from cycle 01 results. For the portion
where RoCo is in motion, the values are set to zero in the profile. This load is now given as an input to the battery using a
Modelica.Blocks.Sources.TimeTable block.
The results of power consumption can be seen in Figure 10.
It can be observed that in cases where all the components operate power exceeds 100 W. However, by turning off the fan and
compressor when RoCo is in motion, it is possible to limit the
power draw to 70 W.
For improved results, a few parameters from the simulation
are calibrated for a better match with the experimental data (Du
et al., 2016). A fixed opening valve is used in the model. Its

796

6

Conclusions

A first principle based multi-physics model is developed to
model the behavior of a portable air conditioning device. The
model is used to capture power consumption of new version of
the device for two different operating cycles. Based on the results of power consumption, it is observed that turning off the
VCC during the motion can reduce peak load on the battery by
up to 34%.

7

Acknowledgment

This research was supported by the Advanced Research
Projects Agency - Energy (ARPA-E) with Award Number DEAR0000530. We thank the members of Center for Environmental Energy Engineering (CEEE) and team members of the Roving Comforter Project for their support.

References
Y. Cao and A. Faghri. A numerical analysis of phase-change
problems including natural convection. Journal of heat transfer, 112(3):812816, 1990. doi:10.1115/1.2910466.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132791

Session 10D: HVAC Systems

R. Dhumane, Y. Du, A. Mallow, K. Gluesenkemp, J. Ling,
V. Aute, and R. Radermacher. Transient Modeling of a
Thermosiphon based Air Conditioner with Compact Thermal
Storage: Modeling and Validation. In 16th International Refrigeration and Air Conditioning Conference, Purdue, Indiana, USA, 2016.
F. W. Dittus and L. M. K. Boelter. Heat transfer in automobile radiators of the tubular type. International Communications in Heat and Mass Transfer, 12(1):322, 1985.
doi:10.1016/0735-1933(85)90003-X.
Y. Du, J. Muehlbauer, J. Ling, V. Aute, Y. Hwang, and R. Radermacher. Rechargeable Personal Air Conditioning Device.
In ASME 2016 10th International Conference on Energy Sustainability collocated with the ASME 2016 Power Conference
and the ASME 2016 14th International Conference on Fuel
Cell Science, Engineering and Technology. American Society
of Mechanical Engineers, 2016. doi:10.1115/ES2016-59253.
M. Einhorn, F. V. Conte, C. Kral, C. Niklas, H. Popp, and
J. Fleig. A modelica library for simulation of electric
energy storages. In Proceedings of the 8th International
Modelica Conference; March 20th-22nd; Technical Univeristy; Dresden; Germany, number 63, pages 436445.
Linkping University Electronic Press, 2011a. ISBN 16503740. doi:10.3384/ecp11063436.
M. Einhorn, V. Conte, C. Kral, and J. Fleig. Comparison of
electrical battery models using a numerically optimized parameterization method. In 2011 IEEE Vehicle Power and
Propulsion Conference, pages 17. IEEE, 2011b. ISBN
1612842488. doi:10.1109/VPPC.2011.6043060.
L. Friedel. Improved friction pressure drop correlations for horizontal and vertical two-phase pipe flow. In European twophase flow group meeting, Paper E, volume 2, page 1979,
1979.
M. K. Gonullu. Development of a mobile robot to be used in mobile robot research. Masters thesis, Department of Mechanical Engineering, Middle East Technical University, 2 2013.
T. Hoyt, E. Arens, and H. Zhang. Extending air temperature setpoints: Simulated energy savings and design considerations
for new and retrofit buildings. Building and Environment, 88:
8996, 2015. doi:10.1016/j.buildenv.2014.09.010.
I. Intergovernmental Panel on Climate Change Fourth Assessment. Contribution of Working Groups I, II and III to the
Fourth Assessment Report of the Intergovernmental Panel
on Climate Change, 2007. ISSN 14764687. URL http:
//www.ipcc.ch/publications{_}and{_}data/
ar4/syr/en/spms2.html{#}footnote5.

W. H. McAdams, W. K. Woods, and L. C. Heroman. Vaporization inside horizontal tubes-II-benzene-oil mixtures. Trans.
ASME, 64(3):193200, 1942.
V. Muenzel, A. F. Hollenkamp, A. I. Bhatt, J. de Hoog,
M. Brazil, D. A. Thomas, and I. Mareels. A Comparative Testing Study of Commercial 18650-Format LithiumIon Battery Cells. Journal of The Electrochemical Society, 162(8):A1592A1600, 2015.
ISSN 0013-4651.
doi:10.1149/2.0721508jes.
H. Mller-Steinhagen and K. Heck. A simple friction pressure drop correlation for two-phase flow in pipes. Chemical Engineering and Processing: Process Intensification, 20
(6):297308, 1986. ISSN 0255-2701. doi:10.1016/02552701(86)80008-3.
D. Pal and Y. K. Joshi. Melting in a side heated tall enclosure by
a uniformly dissipating heat source. International Journal of
Heat and Mass Transfer, 44(2):375387, 2001. ISSN 00179310. doi:10.1016/S0017-9310(00)00116-2.
H. Qiao, V. Aute, and R. Radermacher. Transient modeling of
a flash tank vapor injection heat pump systempart I: model
development. International journal of refrigeration, 49:169
182, 2015. doi:10.1016/j.ijrefrig.2014.06.019.
E. F. Schmidt.
Wrmebergang und Druckverlust in
rohrschlangen. Chemie Ingenieur Technik, 39(13):781789,
1967. doi:10.1002/cite.330391302.
M. M. Shah. Chart correlation for saturated boiling heat transfer:
equations and further study. ASHRAE Trans.;(United States),
88(CONF-820112-), 1982.
M. M. Shah. Comprehensive correlations for heat transfer during condensation in conventional and mini/micro channels in
all orientations. International journal of refrigeration, 67:
2241, 2016. doi:10.1016/j.ijrefrig.2016.03.014.
E. M. Sparrow, S. V. Patankar, and S. Ramadhyani. Analysis
of melting in the presence of natural convection in the melt
region. Journal of Heat Transfer, 99(4):520526, 1977. ISSN
0022-1481. doi:10.1115/1.3450736.
United States Department of Energy. Energy Efficiency and Renewable Energy. 2011.
M. Vesel and W. Zeiler. Personalized conditioning and its
impact on thermal comfort and energy performance  A review. Renewable and Sustainable Energy Reviews, 34:401
408, 2014. doi:10.1016/j.rser.2014.03.024.

R. W. Lockhart and R. C. Martinelli. Proposed correlation of
data for isothermal two-phase, two-component flow in pipes.
Chem. Eng. Prog, 45(1):3948, 1949.

C.-C. Wang, K.-Y. Chi, and C.-J. Chang. Heat transfer and
friction characteristics of plain fin-and-tube heat exchangers, part II: Correlation. International Journal of heat and
mass transfer, 43(15):26932700, 2000. doi:10.1016/s00179310(99)00333-6.

J. Marco, N. Kumari, W. D. Widanage, and P. Jones. A cellin-the-loop approach to systems modelling and simulation of
energy storage systems. Energies, 8(8):82448262, 2015.
doi:10.1049/cp.2011.0421.

S. Wang, A. Faghri, and T. L. Bergman. A comprehensive numerical model for melting with natural convection. International Journal of heat and mass transfer, 53(9-10):1986
2000, 2010. doi:10.1016/j.ijheatmasstransfer.2009.12.057.

DOI
10.3384/ecp17132791

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

797

Duty Cycle for Low Energy Operation of a Personal Conditioning Device

H. Zhang, E. Arens, and W. Pasut.
Air temperature
thresholds for indoor comfort and perceived air quality.
Building Research & Information, 39(2):134144, 2011.
doi:10.1080/09613218.2011.552703.
H. Zhang, E. Arens, and Y. Zhai. A review of the corrective
power of personal comfort systems in non-neutral ambient
environments. Building and Environment, 91:1541, 2015.
doi:10.1016/j.buildenv.2015.03.013.

798

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132791

A Platform for the Agent-based Control of HVAC Systems
Roozbeh Sangi Felix Bnning

Johannes Ftterer Dirk Mller

Institute for Energy Efficient Buildings and Indoor Climate, E.ON Energy Research Center, RWTH Aachen
University, Germany, rsangi@eonerc.rwth-aachen.de

Abstract
Attempts to develop efficient and environmentally friendly
building energy systems have led to modern complex energy concepts for buildings, which have consequently initiated a need for new control strategies for them. Multiagent control, which is known with other names like
agent-based control, offers a promising solution to this
challenge. To the knowledge of the authors, there are 96
platforms for multi-agent systems in different programming languages available, which are mostly java-based
and mainly used in logistic applications, but there is no
platform in the modeling language Modelica, which is
widely used for simulation of dynamic systems, especially
buildings performance simulation. This lack motivated
the authors to develop a platform for agent-based control
of HAVC systems. The platform eliminates the dependency of models developed in Modelica on an extra interface, which is usually required to couple the models
to the platforms written in any programming languages
other than Modelica. This paper presents the structure
of the platform and explains how the agents communications work. The flexibility of the optimization objective
is ensured through the definition of readily interchangeable cost functions. The applicability and functionality of
the platform are proved by applying the platform in the
control of building energy systems examples.
Keywords: Agent-based control, Building energy systems,
Control, HVAC, Modelica, Multi-Agent System

1

Introduction

The amount of energy used for heating and cooling in
the building sector is about one third of the total energy
consumed in the world. The finiteness of natural energy
resources on the one hand, and the ever-increasing demand for energy in the world on the other hand, necessitate the development of systematic approaches for improving the efficiency of building energy systems as well
as minimizing the usage of primary energy resources and
the damaging impacts and harmful effects on the environment (Sangi et al., 2014). Taking into account that renewable energy sources for the building sector such as photovoltaics, heat pumps and combined-heat-and-power units
are becoming profitable, such components are installed in
private and commercial buildings with increasing quantity.
Often more than one of such components are operated in
parallel to increase cost effectiveness and the security of
DOI
10.3384/ecp17132799

supply.
Consequently, the complexity of building energy systems has severely increased in the recent past. Therewith the need for controlling concepts that can handle
such complexity has arisen. Besides concepts like ModelPredictive control and Artificial Neural Networks (Afram
and Janabi-Sharifi, 2014), the concept of agent-based
control realized through Multi-Agent Systems (MAS)
promises good results in the area of HVAC control (Huber et al., 2015).
Multi-Agent Systems were successfully applied in the
areas of logistics and telecommunication in the past
(Verein Deutscher Ingenieure, 2010). Inherently this concept is suited to solve complex control problems and is
therefore predestined for the control of complex energy
systems. For the development of such systems, tools for
multiple programming languages and programming environments are available (Allan, 2010), but not for the
object-oriented language Modelica.
Modelica is a modelling language commonly used for
the dynamic simulation of thermo-hydraulic systems. It
is receiving growing attention in the use of modeling and
simulation of building energy systems, as recent studies
indicate: In (Wetter et al., 2014) a Modelica library for the
simulation of building energy systems is introduced. (Ali
et al., 2013), (Perera et al., 2016), (Sangi et al., 2016) and
(Fuchs et al., 2016) use Modelica in order to model, simulate and investigate in building energy systems as well
as district heating systems. MAS will play an important
role in the control of future building energy systems (see
2.2). Consequently, a Modelica library for MAS will be
needed.
In the course of this work a library for the agent-based
control of building energy systems in the modeling language Modelica is developed, implemented and finally
validated in a case study. The library allows "plug-andplay" implementation of MAS into any model of a building energy system in the Modelica environment, thus allowing the investigation in agent-based building energy
system control through dynamic simulation. It depicts a
solution that through UDP/IP-communication can be run
on distributed machines, enabling the user to integrate
both software and hardware into the optimization problem. Furthermore, the cost functions can be changed without interfering with the agent system leading to a flexible
solution in which the individual user can optimize their energy system for an individual optimization goal with only

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

799

A Platform for the Agent-based Control of HVAC Systems

minor engineering effort.
In the following an overview on multi-agent system is
presented and the system structure is described. The developed library for agent-based control is also introduced
following by an example that demonstrates the application
of the library in building energy systems.

2
2.1

Overview on Multi-Agent Systems
The Concept of Agents and Multi-Agent
Systems

Agents The concept of agent-based control is a concept which allows to control complex systems by splitting
the main objective of the system into smaller objectives
which so-called agents try to obtain by interacting with
each other. Although the concept is widely spread in the
scientific area, especially in the field of computer science
and information technologies, there is no unified definition of the term agent.
After the term first appeared in the context of a dissertation in 1985, in which the term agent is connected
with the attributes of autonomy and problem-solving behaviour (Rosenschein, 1985), further attributes such as
proactivity and the ability to work towards higher goals
(Wernstedt, 2005), the ability to perceive the changes of
their surroundings and to react on them (Divenyi, 2013),
the ability of rational calculation and organization of actions to achieve higher aims as well as permanent activeness (Kirn, 2002), socialness and truthfulness (Bellifemine et al., 2007) were defined by various authors.
In VDI 2653 agents are defined as encapsulated entities, hardware or software, with specified objectives. An
agent attempts to achieve these objectives through its autonomous behaviour, in interacting with other agents and
their surrounding. In addition, several characteristics such
as autonomy, scope of action, interaction, encapsulation,
persistence, goal-orientation and reactivity are defined.
Multi-Agent Systems VDI 2653 describes Multi-Agent
Systems (MAS) as a set of agents interacting to fulfil one
or more tasks. Bellifemine describes MAS as entities that
can model complex systems and introduces the possibility of agents having common or conflicting goals. These
agents are able to interact with each other both indirectly,
by acting on the environment, or directly via communication and negotiation. Depending on their task they may
cooperate to reach a common goal or compete to achieve
their own aims. (Bellifemine et al., 2007)
An MAS can be used to control complex systems. One
advantage over a holistic control concept is the possibility
of splitting the often very complex control problem into
sub-problems and -tasks and dividing them between the
agents. This approach is beneficial for the developer as the
analysis of those sub-problems is more accessible than the
analysis of the holistic problem and thus also the implementation of the systems solving these problems. Furthermore, an agent-based approach has the advantage of being
800

more easily adjustable during the runtime of the system as
new agents can be implemented and added to the system.

2.2

Use of Multi-Agent Systems in energysystem control

MAS have received growing recognition in various fields
over the past few years. Beginning in the fields of
computer science, such as Human Computer Interaction,
where agents help the user depending on their already existing experience with the software, or Information Retrieval, where agents search the Internet for specific information for their user, now agent-based systems have
also reached the field of logistics and telecommunication
(Verein Deutscher Ingenieure, 2010). As a consequence of
growing complexity in the various fields of science, MAS
also receive growing attention in the fields of chemistry,
biology, physics, sociology and economics (Kirn, 2002).
In recent years the field of energy generation and distribution has become much more complex due to the increase of renewable energies and the concept of smartand micro-grids. MAS depict a promising technology to
control the described energy systems.
Regarding the use of MAS to control classical smartand micro-grids, i.e. systems which generate and distribute electricity, a lot of research has been conducted (for
example (Jiang, 2006), (Kok et al., 2012), (Kuznetsova
et al., 2014), (Ye et al., 2015), (Karavas et al., 2015),
(Khan et al., 2016), (Radhakrishnan and Srinivasan,
2016), (Rahman et al., 2016), (Xydas et al., 2016), (Ansari
et al., 2016)). However, also the use of MAS for complex
energy systems for the generation and distribution of heat
or cold, such as building energy systems, HVAC systems
and district heating grids, has recently gained growing attention.
In (Huberman and Clearwater, 1995) a market-based
MAS is used to distribute warm and cold air in an office
building. The system uses a double-blind auction procedure in which agents bid to buy and sell warm and cold air.
The auction is managed by a central auctioneer. Experiments with a real office building show an even temperature
distribution in the building without leading to excessive
actuator movement.
(Qiao et al., 2006) introduces an MAS which combines
the control of a building energy system with user interaction. The system is built of personal agents, local agents
and central agents. Personal agents act as teachable assistants which carry personal user information, such as preferred room temperature, humidity and the current location of the user. Local agents act as mediators, policy enforcers and information providers. The tasks of the central
agent are decision aggregation and interfacing services.
A similar system based on personal agents, local agents
and central agents is used in (Yang and Wang, 2013). Personal agents are developed to predict user preferences by
learning their behaviours. Local agents act as mediators,
information providers, decision makers and control executors while the central agent facilitates collaboration be-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132799

Session 10D: HVAC Systems

tween the local agents while regarding the overall system goal. The functionality of the system regarding effective control of the building energy system while satisfying
occupants demands is proven with simulations and case
studies.
In (Wang et al., 2011) a system using only central and
local agents is used. The central agent contains the main
intelligence of the system. It calculates set point of temperature, illumination and humidity based on user preferences and outdoor information using particle swarm optimization. The local agents use fuzzy controllers to control
the actuators in order to reach said set points.
In (Wang et al., 2012) an indoor energy and comfort
management system based on information fusion and a
multi-agent control system is proposed. A multi-agent
building control system with particle swarm optimization
is built to achieve the smart building control goal, which
is to maximize the comfort index using minimum power
consumption.
(Davidsson and Boman, 2000) uses an MAS consisting
of personal comfort agents, room agents, environmental
parameter agents and badge system agents to control temperature and illumination in a building. Following simulation results, the system is able to reduce energy use while
maintaining user satisfaction.
In (Mokhtar et al., 2013) an already existing MAS
for building heat distribution control is updated with an
ARTMAP, a type of artificial neural network with learning
capabilities. Simulation results show the proposed intelligent MAS is able to maximize the use of a ground source
heat pump effectively by profiling, predicting and coordinating its usage with other energy resources.
(Mokhtar et al., 2014) uses a similar MAS based on
ARTMAP to control a building energy system based on
learned user preferences. Simulation results show that the
system provides better energy control and thermal comfort
management than a reference rule-based MAS.
In (Hurtado et al., 2015) an agent-based approach to
optimize the interaction of smart-grids and building energy systems is developed. Particle swarm optimization
is used to maximize comfort and energy efficiency. It is
shown that the operation of the building energy system
with the MAS allows the support of the voltage control in
the smart-grid.
(van Pruissen et al., 2014) presents a solution based on
electronic market principles called HeatMatcher. HeatMatcher is a P2P system based on PowerMatcher (Kok
et al., 2012), which is a general purpose coordination
mechanism for balancing supply and demand in electricity networks. The system features trading of heat on two
different time scales depending on the inertia of the components involved in trading. The MAS is tested with a
floor heating system connected to a heat pump and a boiler
and shows more energy efficient operation than a reference centralized controller.
In (Huber et al., 2015) an MAS based on consumer
agents and supply agents is introduced. Consumer agents
DOI
10.3384/ecp17132799

recognize heating or cooling demands and request them
from supply agents. Supply agents estimate the corresponding costs. The control of the energy system is governed by negotiation between those agents. The system is
tested with a hardware-in-the-loop test bench consisting of
a central air handling unit and four rooms. Results show
basic functionality of the system.
The developed MAS within the course of this research
offers a flexible approach to the control of building-energy
systems. The MAS can, without any adaptation necessary,
be applied to any building energy system in the simulation
environment of Modelica. With only minor effort it can
also be used to control any energy systems, e.g. electrical
grids or district heating networks. Furthermore, the MAS
can also be used for real life applications beyond the scope
of simulation thanks to agent communication via UDP/IP
network protocol with only minor adaptation to the real
life building energy system necessary. Moreover, the separation of agent logic and cost functions allows changing
of the optimization goal for each individual user without
interfering with the agent system and empowers other developers to design own cost functions for their individual
optimization goal. To the best of the authors knowledge,
no other MAS offers this functionality.

3

System architecture

In the following sections the roles of different types of
agents, the system architecture, and the communication
architecture of the Modelica library will be discussed.
Producer Agent

Producer Agent

Broker

Producer Agent

Intermediate Agent

Producer Agent

Broker

Room Agent

Room Agent

Consumer Agent

Figure 1. Structure of the Multi-Agent System

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

801

A Platform for the Agent-based Control of HVAC Systems

Producer Agent
(boiler)

Producer Agent
(heat pump)

Broker
(warm cycle)

Producer Agent
(glycol cooler)

Producer Agent
(boiler)

Broker
(cold cycle)

Intermediate Agent
(heating register)

Producer Agent
(CHP unit)

Broker
(hot cycle)

Intermediate Agent
(cooling register)

Intermediate Agent
(heating exchanger)

Producer Agent
(heat pump)

Broker
(for the room)

Broker
(warm cycle)

Room Agent

Room Agent

Figure 2. Cascading of the agent system with the help of the intermediate agent

3.1

Fundamentals

The agents are designed as state machines, which is a type
of event discrete system, meaning that one agent can take
on one state and change to a different state when a transition condition becomes true. For the implementation of
the state machines, the Modelica StateGraph library (Otter
et al., 2005) was used.
The contentual agent communication is based on
the FIPA ACL Message Structure Specification (FIPA,
2002a) and FIPA Communicative Act Library Specification (FIPA, 2002b), which depict a common standard for
agent communication. Physical agent communication is
established via UDP/IP standard under the use of the Modelica DeviceDrivers library (Thiele and Bellmann, 2015).
The UDP/IP standard allows communication outside of
the simulation environment of Modelica, giving the opportunity to operate agents on different machines and potentially hardware-in-the-loop simulation. As UDP does
not guarantee message delivery, measurements to guarantee delivery are implemented on the application level.

3.2

MAS structure

Figure 1 shows the structure of the MAS. The system is a
partially centralized market-based approach in which capacity adjustments of heat and cold are traded. There are
four different types of agents in the system: room/consumer agent, producer agent, intermediate agent and broker.
Room/consumer agents represent entities in the system
which require heat or cold for their proper functioning
within a building energy system, for example rooms, storage tanks or lab equipment which requires process heat.
Their task is to estimate a need for heat or cold and to
make a corresponding request to the broker. Room agents
802

use PID controllers to calculate a capacity request from a
deviation between the current room temperature and the
set point. The set point and an allowed deviation from the
set point can be set for each individual room agent in the
system, allowing the occupants of the room to adjust the
system according to their needs. Consumer agents can use
a variety of strategies to determine the capacity request.
Producer agents represent entities in the system which
supply heat or cold, for example boilers, CHP units, heat
pumps or chillers. Their task is to sell heat or cold to the
broker and to adjust capacity when a deal was successfully
made. In order to make an offer, they use a cost-function
which matches a capacity adjustment with a corresponding price. The cost function is exchangeable, rendering the
optimization of the system performance towards different
optimization goals possible.
Intermediate agents are a hybrid of producer agents and
consumer agents. They act as a consumer in one market
and as a producer in another market. They can represent
heat exchangers in building energy systems. With the help
of the Intermediate agent, cascaded energy systems can be
controlled with the MAS system.
The broker is a purely virtual agent and is not connected
to any physical entity of the building energy system. It facilitates the trade of heat and cold by collecting requests
from room/consumer agents and asking for offers from
Producer agents. After collecting all offers, it chooses the
most cost effective supplier and requests a capacity adjustment.

3.3

Trading procedure

In the following, the working principle of the whole controlling process will be explained. The room agent notices
a temperature which is out of a certain range around the set

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132799

Session 10D: HVAC Systems

temperature and decides to take action. It sends a heating
or cooling request to the broker asking for a certain surplus
of heat or cold during a specified period of time. The broker waits for requests of other rooms for a certain time to
bundle individual requests to one big request. When a specific waiting time for more requests has expired, the broker
calls for proposals from each of the producer agents. The
producer agents check if they can supply the requested
amount of heat or cold and calculate a corresponding price
with the help of a cost function. Afterwards, all producer
agents send either an offer or a refusal to the broker. Based
on these proposals the broker chooses the best offers and
calculates a price for each request from the room agents.
This information is sent to the room agents which confirm their request. Based on these confirmed requests, the
broker then decides which offer is best-suited for the corresponding request and sends out "accept offer" or "reject
offer" messages to the producer agents. Producer agents
that received "accept offer" messages adjust their capacity
accordingly. The communication procedure between the
broker and the producer agents follows the FIPA Contract
Net Interaction Protocol specification (FIPA, 2002c).
The intermediate agent is important for the flexible use
of the agent system. It allows the cascading of the agents
and the interconnection of different heating circuits. In the
case of Figure 1, the Intermediate agent communicates as
a producer to the lower broker and as a consumer to the
upper broker. Thereby the two producers in the upper circle can be addressed although they are not part of the same
heating circuit. Two examples of the use of the intermediate agent are shown in Figure 2. On the left-hand side
of the figure an HVAC system is described in which each
room has a heating and a cooling register. The broker mediates between the room agent and the two registers. As
the registers need to be supplied with cold or heat themselves, they are each represented by an intermediate agent,
that ensures their supply by buying heat or cold from superior markets. On the right-hand side an HVAC system
is described in which each room has only one heating device and no cooling device (common European residential
building). There are, however, two temperature circuits
with different temperature levels. These circuits surround
a heat exchanger represented by an intermediate agent. In
case of capacity shortage in the warm temperature circuit,
the hot temperature circuit can act as a heat producer by
transferring heat via the heat exchanger.

3.4

the simplest form of available cost functions. The functionality of the exergy cost functions has been proven in
(Bnning, 2015).
In the case of fuel cost functions, the cost per hour of
operation of a heat/cold producing entity is calculated as
following:
p
C(cap)
=  cap
h


(1)

In which cap represents the capacity, C(cap)
denotes the
h
cost per hour as a function of the capacity, p stands for
the price of the fuel per kWh and  for a representative
efficiency factor of the device. The costs for a capacity
adjustment follows:
C C(capnew ) C(capcurrent )
=

h
h
h
p
=  (capnew  capcurrent )


(2)

With the help of the calculated C
h , producer agents determine the costs of a capacity adjustment and make an
offer to the broker.

4

Modelica HVAC Agent-based Control Library

In the previous sections the development of communication and logic concepts, agent behaviour and cost functions have been illustrated. These aspects are combined
and implemented in the Modelica programming language
resulting in the Modelica HVAC Agent Library.

Cost functions

The cost functions are used by the producer agents to calculate a corresponding price for a requested capacity adjustment. In the Modelica Library, producer agents and
cost functions are separate components, which means that
the cost functions are easily exchangeable, depending on
the optimization goal of the MAS. In the library cost functions depending on fuel cost, exergy loss and primary exergy loss are available. For demonstration purposes fuel
cost functions are used in the following as these depict
DOI
10.3384/ecp17132799

Figure 3. Structure of the HVAC Agent-based Control Library

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

803

A Platform for the Agent-based Control of HVAC Systems

Figure 3 shows the structure of the library. It features
six different agents for the creation of MAS to control
building energy systems. For the producer agents, cost
functions with different calculation methods based on fuel
costs, exergy and primary exergy are available. The fuel
cost functions are applied within this study. The other cost
functions have been defined in order to be used in an ongoing research project which aims at developing an exergybased control strategy for building energy systems. Furthermore, the library offers an example agent system with
two room agents, one broker and two producer agents,
which will be discussed in the following section. Each
model of the library is documented regarding its use and
function and has its own icon.
Besides the HVAC related agents, agents implementing
a book trading example in reference to (Caire, 2009) are
included as well as examples to demonstrate agent communication between two different machines.

5

Boiler

Room 2

Heating Rod

Case study

A scheme of the system under investigation is shown
in Figure 4. The system consists of two rooms, each
equipped with a convective radiator. The rooms are connected to weather data from the 2012 Test Reference Year.
Furthermore, the system features two heat supplies, a gas
boiler and an electric heating rod. The heating rod can be
run on electricity from the grid or on electricity provided
by an additional PV panel. The gas boiler has a maximum
capacity of 3 kW and the heating rod of 2 kW.
Both rooms are equipped with a room agent. Both heat
sources are equipped with producer agents. To complete
the MAS, a broker is used. As cost functions, the fuel
cost functions are used with parameters shown in Table 1.
Additionally, the cost function of the heating rod is connected to a sensor which measures solar radiation. When
solar radiation reaches a value of 310 mW2 , it is assumed
that sufficient electricity is provided by the PV panel and
therefore considered free of charge. Consequently the fuel
price for the heating rod becomes zero.
Table 1. Cost function parameters

boiler
heating rod (grid)
heating rod (PV)

p [ Euro
kW h ]
0.08
0.35
0.00

 []
0.80
1.00
1.00

Besides the control via the agent system, each thermal
zone is equipped with a PID controller and a valve, which
allow the control of the room temperature to a limited degree.
All physical components of the system are taken from
the AixLib library (RWTH-EBC, 2015). The simulation
is executed on Dymola 2016 (Dassault Systemes, 2016).
804

Room 1

Figure 4. Example heating system with agents

6

Results and discussion

The system was simulated for 28 days with the weather
data of the month of February of the 2012 Test Reference
Year. Figure 5 shows the behaviour of the outside air temperature during the simulated time period. It can be seen
that the temperature ranges from +15 C to -8 C. The data
therefore offers situations of both high and low heating
requirement for the simulation.
Figure 6 shows the trend of the air temperature in both
rooms. The set point for the room temperature is 20 C. It
can be seen that the temperatures are kept at a satisfactory
level between 19.5 C and 20.5 C during the vast majority
of time. Between these temperatures, the control of the
room temperature is governed by the PID controllers and
valves.
As soon as the room temperature reaches 19.5 C or
20.5 , the system leaves the control range of the PID controllers and the room agents become active. In case of
19.5 C further heat is requested by the agents, in case of
20.5 C a reduction of heat supply is requested. It can be
ascertained that the reaction time of the agent system is
sufficient as the system rarely crosses the threshold temperatures.
Figure 8 shows the capacities of the boiler and the heating rod, which are solely controlled by the MAS. It can

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132799

Session 10D: HVAC Systems

20

[C]

15

Outside

10
5

T

0
5
10
0

5

10

15

20

25

Time [d]

Figure 5. Outside air temperatures
21
Room 1

Room 2

[C]

20.5

T

room

20
19.5
19
0

5

10

15

20

25

Time [d]

Figure 6. Room temperatures

PV Active [Boolean]

1

0.5

0
4

5

6

7

Time [d]

Figure 7. Activeness of PV panel

supply is increased by the boiler as the PV is no longer
active. When the boiler reaches its maximum capacity in
the first third of day six, the heating rod is switched on,
although the PV is inactive, as the boiler is not able to supply more heat. It can further be seen that the other active
PV times, apart from the long period on days 4 and 5, are
not used to the fullest extent as no heat requests are made
Figure 9 shows a detailed segment of the heat supply during these times. Agents used to specifically survey PV
capacities between day 4 and 7. Figure 7 shows the cor- activeness could be introduced here.
responding activeness of the PV panel which determines
whether the electricity for the heating rod is considered
The functionality of the system was validated in the
free of charge. A comparison of the figures shows the simulation. However, the MAS can also be used to coneffect of the different electricity prices on the MAS be- trol real life applications because the agents communicate
haviour. When the heat supplies first become active be- to each other beyond the border of the simulation software
tween day 4 and 5, it can be seen that the heating rod is framework as they use a UDP/IP protocol to communicate
only used once the PV panel is active. In the middle of via an Ethernet network. An example for this functionday 5 the heating rod is switched off as the electricity is ality is provided in the library. It shows the user how to
not free of charge any more. Shortly afterwards, the heat run an MAS on distributed machines. Such a distributed
be seen that the capacities vary based on the current heat
demand of the system. The figure also shows that the heat
supplies are used less during the first third of the month,
when the outside air temperature is generally higher. It
can further be seen that the boiler holds the greater share
of both heat supplies as it is mostly more cost effective.

DOI
10.3384/ecp17132799

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

805

A Platform for the Agent-based Control of HVAC Systems

Capacity [kW]

3

Boiler

Heating rod

2

1

0
0

5

10

15

20

25

Time [d]

Figure 8. Heat supply capacities

Capacity [kW]

3

Boiler

Heating rod

2

1

0
4

5

6

7

Time [d]

Figure 9. Detailed heat supply capacities

MAS offers much higher reliability compared to a central
control as the system is still functional in case an individual producer or consumer agent fails. This means that
each entity in the energy system (e.g room, boiler, etc.)
is connected to one computer on which the corresponding
agent is running. Communication between agent and device needs to be developed individually as each building
energy system device has a different software interface. If
another entity is added to the system, it can be integrated
into the building energy system control with minimal effort by setting it up with its own agent and introducing
the agent to the broker. The concept is therefore highly
flexible and convenient.
The results show that the MAS is able to maintain a
system variable within margin while reducing the effort
in accordance to an optimization goal (in this case fuel
price). Although the system is developed and tested for
building energy simulation, it can be used and extended
to optimize any system in which forms of energy are distributed between components, such as chemical processes,
district heating systems and electricity smart grids. The interchangeability of the cost function supports this diverse
application as any developer can set up own cost functions
for their needed domain.

7

Conclusion

A Modelica library for the agent based control of building
energy systems was introduced. The structure of the
Multi-Agent System was explained and the roles of
different types of agents were discussed. Furthermore,
806

the trading procedures of capacity adjustments and an
example of a type of cost function were introduced. The
MAS was tested with an example of a building energy
system in the simulation environment of Dymola. The
results have shown that the system is capable of keeping
a satisfactory room temperature while selecting the heat
supply with the most cost effective way of generating
heat. The library provides a flexible MAS that can be
applied to multiple domains in the energy field due to
exchangeable cost functions and that requires minimal
implementation effort. Moreover, UDP/IP communication between agents software environment allows real
life hardware application in the form of a distributed
agent system. Future research will be dedicated to the
development of model-predictive cost functions and the
application of the MAS to smart district heating grids.

Acknowledgement
The authors gratefully acknowledge the financial
support provided by the BMWi (Federal Ministry for
Economic Affairs and Energy), Germany, promotional
references 03ET1218A.

References
Afram, A. and Janabi-Sharifi, F. (2014). Theory and applications
of hvac control systems AS a review of model predictive
control (mpc). Building and Environment, 72:343355.
Ali, M., Vukovic, V., Sahir, M. H., and Fontanella, G. (2013).
Energy analysis of chilled water system configurations using simulation-based optimization. Energy and Buildings,
59:111122.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132799

Session 10D: HVAC Systems

Allan, R. (2010). Survey of agent based modelling and simulation tools. Technical report, Science and Technology Facilities Council.
Ansari, J., Gholami, A., and Kazemi, A. (2016). Multi-agent
systems for reactive power control in smart grids. International Journal of Electrical Power & Energy Systems,
83:411425.
Bellifemine, F. L., Caire, G., and Greenwood, D. (2007). Developing Multi-Agent Systems with JADE. Wiley Series in Agent
Technology. Wiley.
Bnning, F. (2015). Development of a modelica-library for the
agent-based control of hvac systems. Bachelorthesis, RWTH
Aachen University.
Caire, G. (2009). Jade tutorial - jade programming for beginners.
TILAB.
Dassault
Systemes
(2016).
Dymola.
http://www.3ds.com/productsservices/catia/products/dymola.
Davidsson, P. and Boman, M. (2000). Saving energy and providing value added services in intelligent buildings: A mas
approach. In Agent Systems, Mobile Agents, and Applications, pages 166177. Springer.
Divenyi, D. (2013). Agent-based modeling of distributed generation in power system control. IEEE Transactions on Sustainable Energy, 4:886889.
FIPA (2002a). Fipa acl message structure specification.
FIPA (2002b). Fipa communicative act library specification.
FIPA (2002c). Fipa contract net interaction protocol specification.
Fuchs, M., Teichmann, J., Lauster, M., Remmen, P., Streblow,
R., and Mller, D. (2016). Workflow automation for combined modeling of buildings and district energy systems. Energy.
Huber, M., Brust, S., Schtz, T., Constantin, A., Streblow, R.,
and Mller, D. (2015). Purely agent based control of building
energy supply systems. In ECOS - International Conference
on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems.
Huberman, B. A. and Clearwater, S. H. (1995). A multi-agent
system for controlling building environments. In ICMAS,
pages 171176.
Hurtado, L., Nguyen, P., and Kling, W. (2015). Smart grid
and smart building inter-operation using agent-based particle swarm optimization. Sustainable Energy, Grids and Networks, 2:3240.
Jiang, Z. (2006). Agent-based control framework for distributed
energy resources microgrids. In IEEE/WIC/ACM International Conference on Intelligent Agent Technology.
Karavas, C.-S., Kyriakarakos, G., Arvanitis, K. G., and Papadakis, G. (2015). A multi-agent decentralized energy management system based on distributed intelligence for the design and control of autonomous polygeneration microgrids.
Energy Conversion and Management, 103:166179.
Khan, M. R. B., Jidin, R., and Pasupuleti, J. (2016). Multiagent based distributed control architecture for microgrid energy management and optimization. Energy Conversion and
Management, 112:288307.
Kirn, S. (2002). Kooperierende intelligente softwareagenten.

DOI
10.3384/ecp17132799

Wirtschaftsinformatik, 44(1):5363.
Kok, K., Roossien, B., MacDougall, P., van Pruissen, O.,
Venekamp, G., Kamphuis, R., Laarakkers, J., and Warmer,
C. (2012). Dynamic pricing by scalable energy management systemsATfield experiences and simulation results using powermatcher. In Power and Energy Society General
Meeting, 2012 IEEE, pages 18. IEEE.
Kuznetsova, E., Li, Y.-F., Ruiz, C., and Zio, E. (2014). An integrated framework of agent-based modelling and robust optimization for microgrid energy management. Applied Energy,
129:7088.
Mokhtar, M., Liu, X., and Howe, J. (2014). Multi-agent gaussian adaptive resonance theory map for building energy control and thermal comfort management of uclans westlakes
samuel lindow building. Energy and Buildings, 80:504516.
Mokhtar, M., Stables, M., Liu, X., and Howe, J. (2013). Intelligent multi-agent system for building heat distribution control
with combined gas boilers and ground source heat pump. Energy and Buildings, 62:615626.
Otter, M., Arzen, K., and Dressler, I. (2005). Stategraph AS a
modelica library for hierarchical state machines. In In Proceedings of the 4th International Modelica Conference, pages
569578.
Perera, D., Winkler, D., and Skeie, N.-O. (2016). Multi-floor
building heating models in matlab and modelica environments. Applied Energy, 171:4657.
Qiao, B., Liu, K., and Guy, C. (2006). A multi-agent system
for building control. In Proceedings of the IEEE/WIC/ACM
international conference on Intelligent Agent Technology,
pages 653659. IEEE Computer Society.
Radhakrishnan, B. M. and Srinivasan, D. (2016). A multi-agent
based distributed energy management scheme for smart grid
applications. Energy, 103:192204.
Rahman, M., Mahmud, M., Oo, A., Pota, H., and Hossain, M.
(2016). Agent-based reactive power management of power
distribution networks with distributed energy generation. Energy Conversion and Management, 120:120134.
Rosenschein, J. (1985). Rational Interaction: Cooperation
among Intelligent Agents. PhD thesis, Stanford University.
RWTH-EBC (2015). Aixlib - a modelica model library for
building performance simulations. https://github.com/rwthebc/aixlib.
Sangi, R., Baranski, M., Oltmanns, J., Streblow, R., and Mller,
D. (2016). Modeling and simulation of the heating circuit of a
multi-functional building. Energy and Buildings, 110:1322.
Sangi, R., Streblow, R., and Mller, D. (2014). Approaches for
a fair exergetic comparison of renewable and non-renewable
building energy systems. In The 27th international conference on efficiency, cost, optimization, simulation and environmental impact of energy systems. Turku, Finland.
Thiele, B. and Bellmann, T. (2015). Modelica DeviceDrivers.
https://github.com/modelica/Modelica_DeviceDrivers.
van Pruissen, O., van der Togt, A., and Werkman, E. (2014).
Energy efficiency comparison of a centralized and a multiagent market based heating system in a field test. Energy
Procedia, 62:170179.
Verein Deutscher Ingenieure (2010). Vdi 2653 blatt 1.
Wang, Z., Wang, L., Dounis, A. I., and Yang, R. (2012). Multi-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

807

A Platform for the Agent-based Control of HVAC Systems

agent control system with information fusion based comfort
model for smart buildings. Applied Energy, 99:247254.
Wang, Z., Yang, R., and Wang, L. (2011). Intelligent multiagent control for integrated building and micro-grid systems.
In Innovative Smart Grid Technologies (ISGT), 2011 IEEE
PES, pages 17. IEEE.
Wernstedt, F. (2005). Multi-Agent Systems for Distributed Control of District Heating Systems. PhD thesis, Blekinge Institute of Technology, Department of Systems and Software
Engineering.
Wetter, M., Zuo, W., Nouidui, T. S., and Pang, X. (2014). Modelica buildings library. Journal of Building Performance Simulation, 7(4):253270.
Xydas, E., Marmaras, C., and Cipcigan, L. M. (2016). A multiagent based scheduling algorithm for adaptive electric vehicles charging. Applied Energy, 177:354365.
Yang, R. and Wang, L. (2013). Development of multi-agent system for building energy and comfort management based on
occupant behaviors. Energy and Buildings, 56:17.
Ye, D., Zhang, M., and Sutanto, D. (2015). Decentralised dispatch of distributed energy resources in smart grids via multiagent coalition formation. Journal of Parallel and Distributed
Computing, 83:3043.

808

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132799

MoVE  A Standalone Modelica Vector Graphics Editor
Nicola Justus1
1 KITE,

Christopher Schlzel1

Andreas Dominik1

Technische Hochschule Mittelhessen, Giessen, Germany, {nicola.justus, christopher.schoelzel,
andreas.dominik}@mni.thm.de

Abstract
Modelica models can have a graphical icon defined as a
bitmap or vector graphics. Vector graphics have several
benefits, the most obvious being free scaling of images
from icon to poster size. With OpenModelica there already
exists one open source tool that can be used for editing
these vector graphics icon annotations, but it does not reach
the usability comfort of professional vector graphics editing
tools.
In this paper we present the Modelica Vector graphics Editor (MoVE), a standalone open source editor for
Modelicas vector graphics syntax that provides many convenience features inspired by the vector graphics editor
Inkscape. These features include grouping, snap to grid,
move to foreground/background, rotation handles, and
drawing perfect circles and squares as well as horizontal
and vertical lines when holding Shift.
We hope that MoVE, as a part of the Modelica Tool
Ensemble (MoTE), can enrich the open source ecosystem
of Modelica by simplifying the creation of more elaborate
vector graphics icons for Modelica models.
Keywords: JavaFX, vector graphics, open source, SVG,
Inkscape, MVC, MoTE, OpenModelica

1

Introduction

Modelica is a language for modeling complex physical
systems that also incorporates a graphical representation of
model components into the language itself. These graphical
representations come in the form of annotation statements
that can either contain a link to a bitmap image or define
an image using a vector graphics syntax (Modelica Assoc.,
2012). Vector graphics have the advantage that they are
freely scalable. This is interesting in any context where
a model might not only be displayed as a small icon on a
screen but also has to be presented to a larger audience on
a slide or a poster.
Unfortunately, creating vector graphic icons for Modelica models is not as easy as it could be. Standard vector
graphics tools such as Inkscape (Inkscape, 2016) provide a
rich set of features for precise and fast interaction, such as
grouping, rotation handles, sending elements to the front
or back, snap to grid, or drawing straight horizontal lines
and perfect circles when holding a modifier key. It would
be ideal, if we could use such a tool and save the resulting
image in Modelica notation. However, the Modelica annoations are not compatible with vector graphics formats
DOI
10.3384/ecp17132809

such as Scalable Vector Graphics (SVG) (Dahlstrm et al.,
2011), since there are both features in SVG that have no
equivalent in the Modelica syntax and vice versa.
There are many commercial tools for Modelica but
OpenModelica is the only open source choice for graphical
editing of Modelica models (Fritzson et al., 2005). This
graphical editor of OpenModelica is called OpenModelica
Connection Editor (OMEdit) (Asghar et al., 2011). It has
all features that are required to create vector graphic annotations, but does not provide the same level of userfriendliness as Inkscape or related tools. For example,
non-standard rotation angles, fill patterns and line patterns
can only be changed via a properties dialog that has to
be opened separately for each component; the order of
Elements cannot be changed (although respective entries
exist in the context menu); drawing of straight horizontal
lines and perfect circles is not supported; and when we
began this project, OpenModelica did not even support
undo-redo operations for graphical manipulations. Furthermore OMEdit generates the icon annotation as one big line
of code. This is especially uncomfortable when the source
code is managed through a version control system.
In this Paper we therefore present the Modelica Vector
graphics Editor (MoVE), a new standalone open source
Modelica vector graphic editor with a streamlined interface
similar to Inkscape. In the following, we will first give a
bit more detail of the context in which MoVE was created.
In section two, we will then present an overview of the
technologies used to create the editor followed by a discussion of the major design aspects in section three. Section
three presents the major features of MoVE and section four
explains current limitations leading to the conclusion in
section six.

1.1

Background and Related Work

Modelica Tool Ensemble
MoVE is part of the Modelica Tool Ensemble (MoTE) (Justus, Hoppe, and Schlzel, 2017). MoTE aims to provide
small user-friendly standalone appliations for editing and
simulating Modelica models. With this toolset we follow
the Unix philosophy to make each program do one thing
well (McIlroy, Pinson, and Tague, 1978). Separating the
different tasks needed for editing and simulating Modelica models leads to smaller applications that are easier to
maintain than a full-featured development environment like
OpenModelica. Additionally, users may choose to use the
tools that they like and substitute the tools they do not like

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

809

MoVE A Standalone Modelica Vector Graphics Editor

with other alternatives, leading to a more flexible ecosystem
that can accommodate different user needs. MoVE only
touches the main annotation statement of a model. To edit
other parts of the model, one can, for example, use the text
editor Atom (GitHub, 2016) which can provide type checking, auto-completion and error highlighting when coupled
with Modelica | Editor (Mo|E), another tool in the MoTE
family. Instead one could also chose to use OMEdit or
the Eclipse plugin Modelica Development Tooling (MDT)
(Pop et al., 2006).
Inkscape
The main source of inspiration for MoVE was the aforementioned vector graphics editor Inkscape (Inkscape,
2016). Inkscape is an open source application that can be
used to create professional and complicated vector graphic
images. It supports a rich set of features including alignment of elements or individual nodes, combination and
cutting of multiple paths, drawing with Bezier curves,
bold and italic text, importing shapes from a PDF-file, and
many many more. Features that are not already included
can be made available with a language-independent scripting API. These features are presented to the user mainly
through toolbars and hotkeys that make the interaction
fast and seamless. The native format of Inkscape is SVG
(Dahlstrm et al., 2011), which is an XML-based format
that can easily be interpreted by other tools.
MoVE does not nearly provide as many features as
Inkscape, but it tries to follow the same principles for usability and precision.

2

Scala

3
3.1

Parser

ModelViewController

JavaFX is built around the Model-View-Controller (MVC)
software design pattern (Reenskaug, 1979). MVC splits
the application in three parts. The first part is the model1 ,
which represents the business data. The model updates the
view if someone changes the model. The second part is
the view, which displays the data and listens on updates to
the model. The third part is the controller, which connects
a model with the respective view. The controller is also
responsible for user interactions and transforms them into
commands for the model or the view. The typical MVC
workflow is depicted in Figure 1.
Because JavaFX already provides views, which contain
the data representation for shapes, MoVE is designed with
controllers and views. There are no explicit models. They
are hidden inside of the JavaFX shapes.

Scala is a programming language for the Java Virtual Machine (JVM). This means that it is platform-independent
and that it is possible to use any Java library. Especially the
library JavaFX is useful for creating a modern Graphical
User Interfaces (GUIs). Scala merges object orientation
with functional programming, which allows to write code
faster and more flexible than in plain Java. It also brings
its own set of libraries such as a parser combinator library
(EPFL and Typesafe, Inc., 2016) that proved very useful
for this project.
3.3

2.2

Design

To load existing Modelica models we have created a simple
parser for Modelica source code. This parser is built using
the scala-parser-combinators library (EPFL and Typesafe,
Inc., 2016). This library allows combination of simple
parsers to create more complex ones. An external parser
generator is not necessary. MoVE ignores everything in
the source file, except the icon annotations of all models
defined in the file. This makes the parser (and MoVE)
mostly independent of future language modifications, thus
MoVE should work with future versions of Modelica. If the
icon annotations are modified, the parser has to be modified.
This should be a small effort. Additionally this assures that
MoVE interacts nicely with version control systems. Since
we only parse annotations, we can guarantee that we will
not change any other part of the model.
During the parsing process, the parser generates a
MoVE-specific abstract syntax tree. This tree is then transformed into shapes, that are derived from the standard
JavaFX shapes. Finally this shapes are displayed in the
user interface.

3.2

Technologies

This chapter is a short overview over the technologies that
are used for implementing MoVE. Basically MoVE is written in the programming language Scala using the graphical
user interface toolkit JavaFX.

2.1

FXML format, Oracle provides a graphical editor for building the user interface by dragging and dropping interface
components, namely the SceneBuilder. This makes GUI
design much faster and leads to a clean separation of the
layout and the actual code.

JavaFX Elements

JavaFX

To display Modelicas graphical primitives (Modelica Assoc., 2012), we have created a small set of JavaFX elements.
JavaFX is a GUI toolkit for the Java programming lanThese elements are all derived from the standard JavaFX
guage. Because it is written for Java it runs on the JVM
shape elements and add additional properties and behavand is also usable from Scala. JavaFX is the latest toolkit
ior such as fill and stroke patterns. The JavaFX shapes
for GUIs running on the JVM and incorporates many ideas
of modern GUI design. JavaFX provides a special format
1 Here, in section 3.2, the word model refers to source code of a
for describing the structure of a UI. This format is called software project that is structured with the MVC-Pattern and not to a
FXML and based on XML. To develop GUIs using the Modelica model.
810

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132809

Session 11A: Modelica Tools & GUIs

by the color pickers for the fill color and stroke color. The
color pickers are followed by a selector for the LinePattern
and FillPattern. For these last two elements, all patterns
defined in chapter 18.6 from (Modelica Assoc., 2012) can
be selected.
The left toolbar contains the tools for selecting and moving as well as drawing the icon primitives. Going top to
bottom it starts with the arrow, which is used for selecting
and moving shapes. The arrow is followed by the tools for
drawing lines, paths, rectangles, polygons and ellipses, and
for inserting images, and text.
The bottom toolbar currently only contains two items:
an indicator for the size of the draw pane and buttons for
controlling the zoom. The magnifying glass with the minus
zooms out and the magnifying glass with the plus zooms
in.

4
4.1

Features
Code Generation

MoVE provides two code generators for the icon annotation. The first generates the annotation as one big line and
writes
it into the model. This is similar to OMEdit. The
Figure 1. The Model-View-Controller (MVC) software design
second
code generator generates pretty-printed code with
pattern splits an application into three parts in order to increase
line
breaks
and indentations, which is more readable than
maintainability and extensibility (Frey, 2016).
a big line (Listing 1). This style is also better supported
by version control systems as they can recognize which
provides the basic properties for rectangles, ellipses, lines, lines or properties have changed instead of reporting only
paths, polygons, and images.
a change of the whole annotation.
Furthermore, for abstracting the common behavior of
the shapes, they are all derived from a specific trait, which Listing 1. MoVE generates a well formatted icon annotation
with line breaks and indentation.
provides the common behavior. For example, all shapes
that behave like a rectangle are derived from the trait RectangleLike. A similar trait is defined for shapes that behave model Test
annotation(
like a path.
Icon (

3.4

UI Overview

Figure 2. The user interface of MoVE is built with the JavaFXframework and consists of three main toolbars: tool selection
(left), tool properties (top) and zoom and size indicator (bottom).

The user interface contains 3 toolbars for interacting
with MoVE (Figure 2).
The top toolbar contains controls for specifying the color
of selected or newly drawn shapes. Going left to right this
toolbar starts with a selector for the stroke size, followed
DOI
10.3384/ecp17132809

coordinateSystem(
extent = {{0,0},{200,125}}
),
graphics = {
Rectangle(
origin = {34,96},
lineColor = {0,0,0},
fillColor = {128,186,36},
lineThickness = 4.0,
pattern = LinePattern.Solid,
fillPattern = FillPattern.Solid,
extent = {{-14,8}, {14,-8}}
),
Ellipse(
origin = {75,91},
lineColor = {0,0,0},
fillColor = {128,186,36},
lineThickness = 4.0,
pattern = LinePattern.Solid,
fillPattern = FillPattern.Solid,
extent = {{-13,10}, {13,-10}},
endAngle = 360
)
})
);
end Test;

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

811

MoVE A Standalone Modelica Vector Graphics Editor

4.2

Grouping

MoVE supports grouping of multiple shapes through Edit
 Group or by pressing Ctrl+G. Moving a shape which
is part of a group moves all shapes that are part of this
group (Figure 3). Ungrouping is also supported through
Edit  Ungroup or by pressing Ctrl+Shift+G. Note that
the groups are only used in MoVE and are discarded when
the model is saved, because this is not supported by the
icon annotation syntax of Modelica.

Figure 4. The context menu for a shape contains controls for
rotation and stacking order.

Figure 3. MoVE allows to group shapes together in the user
interface, so that they can be easily moved together. These groups
are lost when the annotation is saved.

4.3

Stacked Shapes

MoVE allows to move shapes into the background using
ContextMenu  In Background and to move shapes into
Figure 5. SVG image exported from MoVE displayed in Google
the foreground using ContextMenu  In Foreground (Fig- Chrome.
ure 4). This allows easy modifying of the order of stacked
shapes.
Furthermore, MoVE also handles shapes with the fill
Additionally to rotation by moving the anchors, it is
pattern FillPattern.None in an intuitive way. Shapes that possible to rotate an element using the context menu:
are behind the transparent filling can still be selected. The
 ContextMenu  Rotate 90 clockwise
transparent shape itself is only selected when the user clicks
on the visible border.
 ContextMenu  Rotate 90 counter clockwise

4.4

Export as Images

 ContextMenu  Rotate 45 clockwise
MoVE enables exporting of Modelica icons either as PNG
or as SVG (Figure 5). SVG is especially interesting because
 ContextMenu  Rotate 45 counter clockwise
SVG images can be further modified in Inkscape. This is
useful if the user likes to create a poster which contains a
4.6 Snap to Grid
graphic from a Modelica model.
MoVE operates on a customizable grid. The size of the grid
4.5 Rotation
can be modified to fit the needs of the user. Via the menu
After a double click on a shape, four red anchors appear at entry View  Enable snapping or by pressing Ctrl+A the
the corners of the shape (Figure 6). Moving the anchors snap to grid function can be toggled. If activated, elements
rotates the shape around its center. This is more intuitive will snap to the precise location of the grid lines when they
than rotating a shape by defining a specific degree value are moved close to such a line. This allows for a precise
through a separate property dialog.
alignment of individual elements.
812

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132809

Session 11A: Modelica Tools & GUIs

5
5.1

Limitations
Annotations

MoVE supports every icon annotation except properties
which are defined using a if-clause or a DynamicSelect statement, because the result of both statements is
a dynamic value, which is only defined at runtime. These
dynamic definitions do not fit into the scope of an editor
for static vector graphic images. If MoVE finds properties,
which are defined using this two statements, it warns the
user that this properties will be overwritten by a static value
after a save call (see Figure 8).

Figure 6. Arbitrary rotations can be realized in MoVE by rotation handles (red dots).

4.7

Config Files

MoVE uses simple text files as configuration files that
are placed inside of ~/.move. Application settings are
placed in the file ~/.move/move.conf and keyboard
shortcuts are read from ~/.move/shortcuts.conf.
Both files can be customized with any text editor.

4.8

Additional features

When holding down Shift while drawing a shape, it is possible to create straight horizontal or vertical lines, perfect Figure 8. A Warning is displayed when opening a Model whose
squares, and perfect circles (Figure 7).
icon annotation contains DynamicSelect and if-clause
elements in MoVE.

5.2

Line Scaling

The Modelica language specification does not define the
meaning of the thickness property of a line (Modelica
Assoc., 2012). The most intuitive definition would be to
assume that the thickness of a line is given in units of the
coordinate system of the icon. Both Dymola and OMEdit,
however, define the line thickness in terms of the coordinate
system of the users screen, so that lines scale automatically
when zoomed. At the moment, MoVE does not follow this
behavior, because it is unintuitive and cannot be reproduced
when the image is exported to SVG or Portable Network
Graphics (PNG).

5.3
Figure 7. When holding Shift, MoVE will create perfect squares
and circles and straight horizontal or vertical lines.

MoVE supports undo and redo using Edit  Undo / Edit
 Redo or through the shortcuts Ctrl+Z and Ctrl+Shift+Z.
It is also possible to copy, paste and duplicate selected
shapes. Holding down Shift and selecting a shape selects
multiple shapes.
DOI
10.3384/ecp17132809

Placing Connectors

MoVE currently does not support placing connectors in the
icon, because this would require parsing and altering connector definitions in the model. Loading and saving models
with MoVE does not affect existing connector placements.
MoVE is only a graphical editor for the main annotation
statement of Modelica models and leaves the rest of the
code untouched. Connector placement would add another
layer of complexity to the tool that goes beyond its intended
scope.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

813

MoVE A Standalone Modelica Vector Graphics Editor

We are currently working on another tool in the MoTE
International Modelica Conference. Dresden, Germany,
family named Modelica Diagram Editor (MoDE), which
pp. 739747.
will be used for the graphical composition of Modelica Dahlstrm, Erik et al. (2011). Scalable Vector Graphics
models and could also be used handle the connector place(SVG) 1.1 (Second Edition). W3C Recommendation
ment (Hoppe, 2016).
REC-SVG11-20110816. W3C. URL: https://www.
w3.org/TR/SVG/.
5.4 Inherited Annotations
EPFL and Typesafe, Inc. (2016). scala-parser-combinators.
Modelica allows inheritance of icon annotations. The inGitHub Repository. URL: https://github.com/
herited annotations are currently not displayed in MoVE.
scala/scala- parser- combinators (visited
This feature was postponed to future versions, because it
on 12/09/2016).
would require parsing of several files and inspection of Frey, Regis (2016). The model, view, and controller (MVC)
inheritance hierarchies.
pattern relative to the user. URL: https : / / en .
wikipedia.org/wiki/File:MVC- Process.
6 Conclusions
svg (visited on 12/07/2016).
Fritzson,
Peter et al. (2005). The OpenModelica ModIn this paper we presented a new graphical editor for Modeling,
Simulation,
and Development Environment. In:
elica icon annotations. In contrast to other open source
Proceedings
of
the
46th Scandinavian Conference on
alternatives, the user interface of MoVE is specifically deSimulation
and
Modeling
(SIMS). Trondheim, Norway.
signed to make editing and creating vector graphic icons
GitHub
(2016).
Atom.
URL
:
https://atom.io
(visited
for Modelica models as easy and fast as creating a vector
on
11/01/2016).
graphic image with tools such as Inkscape. MoVE builds
on the modern platform-independent framework JavaFX. Hoppe, Marcel (2016). Modelica Diagram Editor. URL:
https://github.com/THM- MoTE/MoDE (visIt has many convenience features such as grouping, snap
ited on 12/20/2016).
to grid, move to foreground/background, rotation handles,
Inkscape
(2016). Inkscape  Draw Freely. URL: https:
and drawing perfect circles and squares as well as horizon//inkscape.org
(visited on 12/09/2016).
tal and vertical lines when holding Shift. It is also designed
to work well with version control systems so that changes Justus, Nicola, Marcel Hoppe, and Christopher Schlzel
(2017). Modelica Tool Ensemble (MoTE). URL: https:
to individual elements can be captured. Except for dynamic
/ / github . com / thm - mote (visited on
elements, it supports every part of the icon definition in the
03/28/2017).
Modelica language specification.
McIlroy,
M. D., E. N. Pinson, and B. A. Tague (1978).
There are many possibilities for future improvement
Unix
Time-Sharing
System: Foreword. In: The Bell
which can be drawn from the feature set of Inkscape such
System
Technical
Journal
57.6, pp. 18991904.
as component and node alignment or the combination and
Modelica
Association
(2012).
Modelica - A Unified Objectcutting of multiple paths. Ideally, these features could be
Oriented
Language
for
Systems
Modeling. Language
brought to MoVE by a (partial) import of SVG graphics.
Specification.
Version
3.3.
This would allow to create icons in Inkscape and convert
them into Modelica code so that they are used directly in Pop, Adrian Dan Iosif et al. (2006). OpenModelica Development Environment with Eclipse Integration for BrowsModelica models. For this, one would need to define a
ing, Modeling, and Debugging. In: Proceedings of the
subset of SVG that is translatable to Modelica and some5th
International Modelica Conference. Vienna, Austria,
how restrict the user in Inkscape to only use this subset.
pp.
459465.
Futhermore, if MoVE should be able to place and display
Reenskaug,
Trygve (1979). Thing-Model-View-Editor 
connectors of the model, the parser needs to be extended
An Example from a planningsystem. technical note. Xeand additional parts of the model have to be altered.
rox PARC.
We hope that this tool can enrich the open source ecosystem of Modelica and will enable more elaborate vector
graphic icons for Modelica libraries. MoVE is part of a
larger ensemble of tools called MoTE, which also features
an integration of Modelica compiler features into a structured text editor.
The projects are open source and hosted on GitHub:
https://github.com/thm-mote/

References
Asghar, Syed Adeel et al. (2011). An Open Source Modelica Graphic Editor Integrated with Electronic Notebooks
and Interactive Simulation. In: Proceedings of the 8th

814

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132809

Mo|E  A Communication Service Between Modelica Compilers
and Text Editors
Nicola Justus1
1 KITE,

Christopher Schlzel1

Andreas Dominik1

Thomas Letschert1

Technische Hochschule Mittelhessen, Giessen, Germany, {nicola.justus, christopher.schoelzel,
andreas.dominik, thomas.letschert}@mni.thm.de

Abstract
The Modelica language is becoming increasingly popular among scientists and engineers as platform for modelling physical or biological systems. Although Modelica
is maintained as non-proprietary language by the Modelica Association, a considerable number of commercial
implementations and development environments is complemented by a surprisingly small number of open source
tools.
In this paper, we present the communication service
Mo|E that connects any text editor as front-end with a
Modelica compiler as back-end. Based on the simple
HTTP communication protocol, editor plugins for a software developers favourite text editor can be developed
easily, hence turning any editor into a lightweight Modelica development tool.
We also present a first implementation of a plugin for
the text editor Atom that exhibits features necessary for
efficient software development, such as display of compile errors, code completion, go to declaration or view of
context-sensitive documentation. In addition, Modelicaspecific checking of the number of equations in a model is
supported.
Keywords: Modelica, open source, integrated development
environment, distributed systems, structured editor, ENSIME, OpenModelica, JModelica, MoTE

1

Introduction

Modelica is a powerful object-oriented programming language that facilitates acausal description of physical systems. Although many commercial and open source tools
for developing or working with Modelica are available,
the OpenModelica suite (Fritzson et al., 2005) is the only
comprehensive set of tools for Modelica. OpenModelica
provides a standalone Modelica compiler, an Eclipse plugin
for developing Modelica inside of Eclipse (MDT), a graphical model editor for connecting components (OMEdit), and
a Modelica debugger. The primary tools for developing
Modelica are MDT and OMEdit. Both are full-fledged
integrated development environments (IDEs).
IDEs are well suited for working with big projects but
may have some disadvantages. They often are slow, difficult to use and and may be even scary for novice users. For
Modelica additional challenges arises from the differences
DOI
10.3384/ecp17132815

between Modelica compilers, such as JModelica or OpenModelica which silghtly differ in their understanding of
Modelica. In order to develop code compatible with different compilers, the IDE should be able to compile models
using different compilers.
Today, when writing source code or any other type of
structured text, it is common to use a structured editor
which is aware of the documents structure. Structured
editors are an essential part of most IDEs. Experienced developers usually prefer them to other  graphical  means
of input. A structure aware editor must be able to analyze the text given to it. Thus structure awareness means
awareness of the syntax and to some extend also of the
semantics of the texts it deals with. The structured editor
is deeply integrated with the IDE, rather than being just a
mere component.
In this paper we present Modelica | Editor (Mo|E), a development environment for Modelica, centered on editing
and checking complex models, refraining form all issues of
model execution. A structured editor is its main component
and user interface.
A key concept of Mo|E is that the user may use a text
editor of her own choice, attach it to a service process that
provides syntactic and semantic analysis and transforms
the plain text editor to a structured editor.
Thus users may edit texts using the editor they are used
to and still benefit from automatic recompilation, code
completion, semantic highlighting, go to declaration, refactoring, and so on.
A central part of our solution is a server process that
mediates between the text editor and Modelica aware analytical services. These services are provided by existing
Modelica compilers, and/or further existing or future tools
that may be plugged into this infrastructure (Figure 1). We
have enhanced one text editor to a Modelica editor, but
other text editors may be integrated with little effort. These
editors only have to provide a plugin that implements the
service API. This API provides a unique interface to different Modelica compilers and eases the communication with
compilers and related tools, protecting users from complex
and differing command-line interfaces.
The design of Mo|E was inspired by the ENSIME project
(ENSIME Contrib., 2016) with its server process that mediates between text editors and Scala compilers.
Mo|E is an environment for developing Modelica models

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

815

Mo|E A Communication Service Between Modelica Compilers and Text Editors

 Provide jump to the source of a model. This is better
known as go to declaration.

using editors that are enhanced to be Modelica aware. It
was realized as part of the first authors bachelors thesis
(Justus, 2016).

 Provide a view of the documentation of a model.

1.4

Background and Related Work

CORBA

HTTP
Mo|E-protocol

Editor

OpenModelica

Mo|E
server

JModelica

Pythonscript

Figure 1. Survey of the communication between a text editor
with a Mo|E-plugin, the Mo|E server and OpenModelica or JModelica.

1.1

Structure of the Paper

Section 2 describes which technologies and standards
where used to implement Mo|E. Section 3 describes the
protocol between client and service process, the communication with OpenModelica as well as with JModelica. Section 4 presents the key features of Modelica | Editor (Mo|E)
and their use in the text editor Atom. Finally, section 5
gives a summary and a short outlook on future extensions.

1.2

Naming

The name Modelica | Editor (Mo|E) alludes to the use of the
pipe character (|) in UNIX-like operating systems, which
establishes a pipeline between two programs. Mo|E can be
seen as such a pipeline between the Modelica compiler and
a structured editor. In contexts where special characters
like the pipe may cause problems, we chose the alternative
spelling ModelicaPipeEditor (MoPE).

OneModelica (Samlaus, 2015) is a an Eclipse-based IDE
for Modelica models tailored to the domain of fluid dynamics. It was realized using tools and techniques of Model
Driven Software Development. It may be compared to our
approach in that it restricts itself to syntax and static semantics of the language and refrains from simulation issues. It
differs considerably in its technological base, which in the
years since its development has lost a lot of its attraction
and support, not without reason as we think.
Mo|E is the first tool in a more ambitious project called
Modelica Tool Ensemble (MoTE). MoTE aims at the provision of a collection of small user-friendly standalone applications for developing and executing Modelica models,
i.e. a lightweight development environment for Modelica.
Modelica does not differ in principle from other languages when it comes to development environments. However, due to its complex static and dynamic semantics,
it poses special challenges, mainly for the support of incremental development (see e.g. (Hger, Lorenzen, and
Pepper, 2010) or (Broman, Fritzson, and Furic, 2006)).
We are well aware of these problems. Thus, at least for
the time being, MoTE and Mo|E do not include a Modelica
compiler or tools incorporating compiler features much
beyond parsing. Instead we rely on mature compilers like
OpenModelica and JModelica.

2
2.1

Technologies
Scala and Akka

Scala (EPFL, 2016) is a hybrid programming language that
combines object orientation with functional programming.
Because the Scala compiler generates bytecode for the Java
Virtual Machine (JVM), it integrates with many available
Java libraries. In addition, resulting compiled programs
are platform independent. The service process of Mo|E is
implemented in Scala.
1.3 Goals
Akka is a library for concurrent and distributed systems,
based
on the actor model that facilitates concurrency by
Our goals for Mo|E are:
providing a high level of abstraction (Allen, 2013). We use
 Provide an extendable client server application which Akka as a provider of communication services, such as an
makes it possible to develop Modelica inside existing implementation of the HTTP-protocol and for structuring
the system according the actor model.
text editors.

2.2

OMC and CORBA

 Provide a client implementation for the text editor
OpenModelica provides the Advanced Interactive OpenAtom as reference for other clients.
Modelica Compiler (OMC), a server that provides an API
 Highlight syntax and type errors, perhaps while typ- to query loaded Modelica code (Asghar et al., 2011).
The Common Object Request Broker Architecture
ing, inside the text editor.
(CORBA) is used by the OpenModelica compiler server
 Provide code completion for models, data types, and OMC as interface to other applications and other programvariables.
ming languages.
816

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132815

Session 11A: Modelica Tools & GUIs

CORBA developed by the Object Management Group relative path to a directory that is used to store compiled
(OMG) defines a standard for inter-process communication files:
modeled as interaction of distributed objects. Because POST /mope/connect
the public API of remote objects is defined in an Interface
Definition Language (IDL), processes may be implemented {
"path": <String>,
in different programming languages (OMG, 2012).
"outputDirectory": <String>

2.3

Atom and the Electron Engine

Atom (GitHub, 2016a) is a text editor created by GitHub
in the style of Sublime Text (Sublime HQ Pty Ltd, 2016).
Basic design concepts of Atom include customization and
extensibility through plugins (called packages in the context of Atom). Extending Atom is possible with JavaScript,
HTML and CSS by using the Electron Engine (GitHub,
2016c). This allows to rapidly develop extensions and to
implement communication protocols using AJAX requests.
Furthermore, Atom already includes a package for syntax
highlighting for Modelica (Chenouard et al., 2016), a simple API for completion suggestions (GitHub, 2016b) and a
plugin for clicking on text (Facebook, 2016), which is used
to implement go to declaration functionality.
We have created an Atom plugin as first reference implementation of a Mo|E client.

}

This project information is stored in the mopeproject.json file that is placed in the project directory.
If the request was successful, the server answers with
a project id. If not, the server answers with 400
BadRequest and a detailed error message.
3.1.2 Compiling Modelica source files & Modelica
script files
Compiling a Modelica source file is initiated through a
compile request. The request body contains the path to
the currently opened file. As a result of the request a model
is instantiated and type errors are retrieved:
POST /mope/project/0/compile
{ "path": <String> }

3
3.1

Design
Mo|E  Editor Protocol

Clients are connected to the service process, by means of
Hypertext Transfer Protocol (HTTP)-based communication and JavaScript Object Notation (JSON) data representation. HTTP provides status codes, Uniform Resource
Identifiers (URIs) and content negotiation (Fielding and
Reschke, 2014). JSON is a compact text format, based on
the JavaScript Object Notation (Bray, 2014).
The communication flow follows several steps: Firstly,
the client connects to the service process using a connect
request that communicates the current project. In this
context a project is a directory containing Modelica source
files.
Secondly, after initialization the service process answers
with the respective project id. The unique project id identifies the project in the client server communication.
Henceforth, the client uses this project id to request
further IDE functionality for this project from the service
process.
To finally finish a session, the client sends a disconnect
request that triggers the service process to delete all projectrelated information and cached data.
The following sections describe each supported IDE
functionality in more detail.
3.1.1

Connecting to the server

As introduced in the preceding section, each client needs
to connect initially with the server. A connect request is
initiated through a POST request containing the respective
JSON object with the project description. The JSON object
contains the full path into the project directory and the
DOI
10.3384/ecp17132815

If the request was successful, the server answers with a
JSON array containing compiler errors:
{
"type": "Error" | "Warning", //type of
message
"file": <String>, //path to the file
which contains the error
"start": { //start of error
"line": <Number>,
"column": <Number>
},
"end": { //end of error
"line": <Number>,
"column": <Number>
},
"message": <String> //compiler error
}

Compiling a Modelica script file is initiated by sending
an analogous compileScript request:
POST /mope/project/0/compileScript
{ "path": <String> }

Although the request is called compiling a Script file,
the service process actually executes the script. This action
is intended for debugging purposes of smaller scripts and
not for scripts that simulate a model, since simulating a
model is time-consuming and may freeze or possibly even
kill the service process.
3.1.3 Checking a model
To check a model for its number of equations the client
sends a checkModel request with the model path. The
server calls the OpenModelica compiler to run checkModel and answers with a string containing the results:

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

817

Mo|E A Communication Service Between Modelica Compilers and Text Editors

POST /mope/project/0/checkModel

"kind": "Type" | "Variable" | "Function"
| "Keyword" | "Package" | "Model" | "
Class" | "Property",
"name": <String>, //the completion
//OPTIONAL: list containing names of
parameters if kind=function
"parameters": [
<String>,
<String>,
...
],
//OPTIONAL: the class comment describing
the name attribute
"classComment": <String>,
//OPTIONAL: the type of name
"type": <String>

{ "path": <String> }

This functionality is only available, if the OpenModelica
compiler is used.
3.1.4

Go to declaration

To retrieve the declaration of a model, the client sends a
declaration request. This request contains the model/class name as query string1 :
GET /mope/project/0/declaration?class=[
Modelname]

The server answers with a JSON object containing the
file path and line number of the declaration:

}

{

kind defines the type of the completion (such as package,
class, function, variable, etc.). name is the suggestion for
the subexpression.
The optional return values for parameters, classCom}
ment and type report the list of argument names if the
If the project id is unknown or the query string is missing, suggestion is a function, the documentation string if the
the server will answer with a 404 NotFound error.
the suggestion is a class and the data type of the expression
(usually the data type of a variable), respectively.
3.1.5 Go to documentation
If the given project id is unknown, the server answers
A model documentation can be retrieved using a doc rewith 404 NotFound.
quest with the model name encoded as query string:
3.1.7 Display data type of a variable
"path": <String>, //absolute path to the
file
"line": <Number> //line number

GET /mope/project/0/doc?class=[Modelname]

The server embeds the documentation in a template and
returns a HTML document that can be viewed in a web
browser.
If the project id is unknown or the query string is missing,
the server answers with a 404 NotFound error.
3.1.6

Code completion

For code completion the client sends a completion request with a JSON object that describes the position of the
cursor as file (name of current file), line and column number
(position of the cursor) and word (part of the expression to
be completed):

To retrieve data type and documentation string of a variable,
the client sends a typeOf request with a body identical
to the body of the completion request. If the request
was successful, the server answers with a JSON object
containing the name, type, and documentation string of the
variable. Otherwise the server answers with 404 NotFound:
POST /mope/project/0/typeOf
{
"name": <String>, //name of property
"type": <String>, //type of property
//OPTIONAL: property comment
"comment": <String>

POST /mope/project/0/completion
}
{
"file": <String>, //absolute path to the
file
"position": { //position inside the file
"line": <Number>,
"column": <Number>,
},
"word": <String>

3.1.8 Disconnecting from the server
A session is terminated by a disconnect request, which
initiates the shutdown sequence for this project on the
server:
POST /mope/project/0/disconnect

}

The server returns 204 NoContent if the project id is
known
or 404 NotFound elsewise.
The server responds by sending an JSON array of possible completions for the expression:
3.1.9 Stopping the server
{
//type of completion; 1 of the listed
strings
1 A query string is a component of a URI, that starts with a ? (BernersLee, Fielding, and Masinter, 2005).

818

The client can stop the whole service process by sending
a stopServer request. The server answer is 202 Accepted.
POST /mope/stop-server

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132815

Session 11A: Modelica Tools & GUIs

Command

Description

The modeling and development environment OpenModelica (OSMC, 2016) consists of a Modelica compiler (omc),
a graphical connection editor (OMEdit), an Eclipse plugin
(MDT) and a Modelica debugger (Fritzson et al., 2005). As
described in Chapter 2.2 the compiler enables querying for
model information via its CORBA interface that provides
several types of information:

Mope: Disconnect

Disconnect Atom from
the service process

Mope: Compile Project

Compile the project

Mope: Run Script

Execute the Modelica
script

Mope: Check Model

Check the model for its
number of equations

 list of all models/classes by sending getClassNames,

Mope: Show Type

Display the data type of
the variable below the
cursor

Mope: Open Documentation

Open the documentation
of the type below the
cursor

 result of a model check for equations by sending
checkModel,

Mope: Open Server Log

Open the log file of the
service process

 documentation string of a model by sending getClassComment,

Mope: Open Server Config

Open the configuration
file of the service process

Mope: Stop Server

Stop the server

3.2

Communication with OpenModelica

 source file of a model by sending getSourceFile,
 documentation annotation of a model by sending
getDocumentationAnnotation,

 arguments of a function by sending getParameterNames,

Table 1. List of commands implemented in the Atom plugin.

 specialization of a class by sending getClassReobjects. The communication scheme is depicted in Figstriction.
ure 2.
An additional difficulty arises from the fact that OpenUnfortunately JModelica does not offer access to the
Modelica uses Modelica expressions as arguments for its parsed model or its abstract syntax tree. That is the reason
CORBA interface. As a result, the functions listed above why code completion is restricted to local variables and
are not implemented explicitely in the CORBA interface. go to documentation is not yet supported in the presented
Instead, OpenModelica only provides a single method in its Mo|E Atom plugin.
CORBA interface, namely sendExpression and sends
Modelica source code strings and API function calls as arguments. Therefore, we create the function calls as strings
and interpolate them into the function argument, as shown
in Listing 1.
Listing 1. API function call through OpenModelicas CORBA
interface.
val omc:OmcCommunication = ...
val fileName = "/tmp/model.mo"
val errors:String =omc.sendExpression(s"""
parseFile("$fileName")""")

3.3

Communication with JModelica

JModelica (Modelon AB, 2016) is a Modelica compiler
developed by Modelon AB (kesson et al., 2010). To allow
dynamic adjustments during execution, JModelica offers a
Python interface which enables code modification at run
time. In addition it enables compilation of Modelica code.
We are using this Python interface for compilation of the
models by delivering the Modelica source files to a custom
Python script, which calls the JModelica compiler, parses
JModelicas output and encodes the output into JSON. The
resulting JSON is printed to stdout which is afterwards
parsed by the service process and finally decoded as Scala
DOI
10.3384/ecp17132815

Figure 2. Diagram of the communication between a text editor
(client) and JModelica.

4
4.1

Features
Client commands

Table 1 gives a full list of the commands available in the
Atom plugin.

4.2

Compiler Feedback

Modelica | Editor (Mo|E) provides instant compiler feedback for syntax errors and type errors. Background compi-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

819

Mo|E A Communication Service Between Modelica Compilers and Text Editors

lation is automatically triggered when a file is saved and the
errors are highlighted in the editor with a red indicator at
the left side of the editor tab. Error messages are displayed
at the bottom of the tab (Figure 3). Alternatively automatic
compilation can be disabled and triggered manually.
As Mo|E supports JModelica and OpenModelica it is
possible to use either JModelica or OpenModelica or both
compilers for one project.

4.4

Go to Declaration

Mo|E provides go to declaration by clicking on the model/class name while holding down Ctrl. The source file
of the model/class is opened in a separate tab. Go to declaration is mostly used for discovering source code or when
editing multiple models that are linked to each other.

4.5

Documentation View

Mo|E embeds the queried documentation of a model in
a predefined template and provides the documentation as
HTML document. The implementation in the Atom plugin
opens the requested documentation in the default browser.
Furthermore it is possible to browse the models child
components using the links in the subcomponents section
of the documentation (Figure 5).

Figure 3. Compile errors are retrieved form the back-end (OpenModelica or JModelica) by the Mo|E server and highlighted in
the source code by the editor plugin.

4.3

Code Completion

Modelica | Editor (Mo|E) features enhanced code completion on keystrokes or by pressing Ctrl + Space.
Suggestions include classes, models, functions, model parameters and variables, keywords, built-in types as well as
local variables. The suggestions contain a type indicator,
documentation string and a link to the models documentation (Figure 4). The type indicator displays the type of the
suggestion (package, model, function or variable).

Figure 5. Example of a documentation display generated as
HTML page by Mo|E by embedding the retrieved documentation
string with a template page.

4.6

Type & Documentation String Display

Figure 4. Code completion allows for selecting classes, mod- Mo|E provides a command for displaying the type and
els, functions, model parameters, variables, keywords or built-in documentation string of the variable at the cursor position.
types from a list of suggestions retrieved by the Mo|E server.

Type and documentation are displayed at the bottom of the
editor tab (Figure 6).

820

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132815

Session 11A: Modelica Tools & GUIs

5

Figure 6. Data type and documentation string are displayed in
the editor window by the Atom plugin.

4.7

Execution of Modelica Scripts

If the OpenModelica compiler is used, Mo|E allows manually triggered execution of Modelica scripts and displays
error messages in the editor.

Figure 7. Compile errors of Modelica scripts are displayed in
the editor window by the Atom plugin.

4.8

Model Check

Conclusions

This paper presented a extendable client/server application for developing Modelica in enhanced text editors like
Atom. It shows how a service process is used to simplify communication with multiple Modelica Compilers
and provide IDE features to various text editors through
a simple interface. Text editors have to implement a
small number of basic HTTP calls, which should be a
minimal effort. A minimal setup with compilation and
code completion would only require four HTTP calls. Installation instructions for Mo|E can be found at https:
//github.com/THM-MoTE/mope-server.
Mo|E is a base for further extensions. E.g. we intend to
implement plugins for different editors, such as Sublime
Text (Sublime HQ Pty Ltd, 2016), Visual Studio Code
(Microsoft Corporation, 2016) or vim (Moolenaar, 2016).
Including Visual Studio Code should not be a problem
because it uses TypeScript for its plugins, which is a superset of Atoms JavaScript.
Mo|E is part of a larger ensemble of tools called MoTE
(Schlzel et al., 2016). MoTE will also include a vector graphic editor called Modelica Vector Graphics Editor (MoVE) (Justus et al., 2017) and a diagram editor called
Modelica Diagram Editor (MoDE) (Hoppe et al., n.d.). Together with Mo|E these tools provide alternative user interfaces for the interaction with existing Modelica compilers,
which allow a simpler interaction than full-fledged IDEs
like OpenModelica.
The projects are open source and hosted on GitHub:
https://github.com/thm-mote/

References

Mo|E supports checking of a model for the number of kesson, J. et al. (2010). Modeling and Optimization
with Optimica and JModelica.org  Languages and
equations (Figure 8), if the OpenModelica compiler is used.
Tools for Solving Large-Scale Dynamic Optimization
Problems. In: Computers & Chemical Engineering 34
(11), pp. 17371749.
Allen, Jamie (2013). Effective Akka. Sebastopol, USA:
OReilly Media.
Asghar, Syed Adeel et al. (2011). An Open Source Modelica Graphic Editor Integrated with Electronic Notebooks
and Interactive Simulation. In: Proceedings of the 8th
International Modelica Conference. Dresden, Germany,
pp. 739747.
Berners-Lee, T., R. Fielding, and L. Masinter (2005). Uniform Resource Identifier (URI): Generic Syntax. RFC
3986. IETF.
Bray, T. (2014). The JavaScript Object Notation (JSON)
Data Interchange Format. RFC 7159. IETF.
Broman, D., Peter Fritzson, and S. Furic (2006). Types
in the Modelica Language. In: In Proceedings of the
5th International Modelica Conference. Ed. by Ch.and
Figure 8. Result of a model check, performed by the OpenModHaumer A. Kral. Vienna, Austria: The Modelica Associelica back-end, is displayed as pop-up in the editor window by
ation, pp. 303317.
the Atom plugin.

DOI
10.3384/ecp17132815

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

821

Mo|E A Communication Service Between Modelica Compilers and Text Editors

Chenouard, Raphael et al. (2016). Modelica language
support in Atom. GitHub Repository. URL: https :
/ / github . com / modelica - tools / atom language-modelica (visited on 11/03/2016).
cole Polytechnique Fdrale de Lausanne (2016). The
Scala Programming Language. URL: http://www.
scala-lang.org/ (visited on 11/01/2016).
ENSIME Contributors (2016). ENSIME. URL: http://
ensime.github.io/ (visited on 11/01/2016).
Facebook (2016). Hyperclick. GitHub Repository. URL:
https : / / github . com / facebooknuclide /
hyperclick (visited on 11/03/2016).
Fielding, R. and J. Reschke (2014). Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing. RFC
7230. IETF.
Fritzson, Peter et al. (2005). The OpenModelica Modeling, Simulation, and Development Environment. In:
Proceedings of the 46th Scandinavian Conference on
Simulation and Modeling (SIMS). Trondheim, Norway.
GitHub (2016a). Atom. URL: https://atom.io (visited on 11/01/2016).
 (2016b). Autocomplete+ Package. GitHub Repository. URL: https : / / github . com / atom /
autocomplete-plus (visited on 11/03/2016).
 (2016c). Electron  Build cross platform desktop apps
with JavaScript, HTML, and CSS. URL: http : / /
electron.atom.io/ (visited on 09/14/2016).
Hger, Christoph, Florian Lorenzen, and Peter Pepper
(2010). Notes on the Separate Compilation of Modelica. In: 3rd International Workshop on Equation-Based
Object-Oriented Modeling Languages and Tools. Ed. by
P. Fritzon et al. Oslo, Norway: Linkping Electronic
Conference Proceedings, pp. 4353.
Hoppe, Marcel, Christopher Schlzel, and Andreas Dominik. MoDE  A Standalone Modelica Diagram Editor.
unpublished.
Justus, Nicola (2016). Design and Implementation of a
Client/Server Application for Editing Modelica Inside
Various Text Editors. BA thesis. Giessen, Germany:
Technische Hochschule Mittelhessen.
Justus, Nicola, Christopher Schlzel, and Andreas Dominik
(2017). MoVE  A Standalone Modelica Vector Graphics Editor. In: 12th International Modelica Conference.
Prague, Czech Republic. to be published.
Microsoft Corporation (2016). Visual Studio Code Code Editing. Redefined. URL: https : / / code .
visualstudio.com/ (visited on 22/12/2016).
Modelon AB (2016). JModelica.org. URL: www .
jmodelica.org (visited on 11/01/2016).
Moolenaar, Bram (2016). welcome home : vim online. URL:
http://www.vim.org/ (visited on 12/21/2016).
Object Management Group (2012). Common Object Request Broker Architecture (CORBA). Part 1: CORBA
Interfaces. OMG document formal/2012-11-12. Version 3.3.

822

Open Source Modelica Consortium (2016). OpenModelica.
URL : https://openmodelica.org (visited on
11/01/2016).
Samlaus, Roland (2015). An Integrated Development Environment with Enhanced Domain-Specific Interactive
Model Validation. PhD thesis. Linkping University,
The Institute of Technology.
Schlzel, Christopher et al. (2016). Modelica Tool Ensemble. GitHub Repository. URL: https : / / github .
com/orgs/THM-MoTE/ (visited on 12/22/2016).
Sublime HQ Pty Ltd (2016). Sublime Text: The text editor youll fall in love with. URL: https : / / www .
sublimetext.com/ (visited on 11/01/2016).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132815

Traceability Support in OpenModelica using Open Services for
Lifecycle Collaboration (OSLC)
Alachew Mengist

Adrian Pop

Adeel Asghar

Peter Fritzson

PELAB  Programming Environment Lab, Department of Computer Science, Linkping University, Sweden,
{alachew.mengist, adrian.pop, adeel.asghar, peter.fritzson}@liu.se

Abstract
A common situation in industry is that a system model
is composed of several sub-models which may have
been developed using different tools. The quality and
effectiveness of large scale system modeling heavily
depends on the underlying tools used for different
phases of the development lifecycle. Available
modeling and simulation tools support different
operations on models, such as model creation, model
simulation, FMU export, model checking, and code
generation. Seamless tracing of the requirements and
associating them with the models and the simulation
results in the context of different modeling tools is
becoming increasingly important. This can be used to
support several activities such as impact analysis,
component reuse, verification, and validation.
However, due to the lack of interoperability between
tools it is often difficult to use such tools in
combination. Recently, the OSLC specification has
emerged for integrating different lifecycle tools using
linked data. In this paper we present new work on
traceability support in OpenModelica where the
traceability information is exchanged with other
lifecycle tools through a standardized interface and
format using OSLC. In particular, OpenModelica
supports automatic recording and tracing of modeling
activities such as creation, modification, and
destruction of models, import model description XML,
export of FMUs, and creation of simulation results.
Keywords:
OpenModelica, traceability, OSLC, tool
interoperability, tool integration, model management,
Modelica

1

Introduction

Modeling and simulation tools have become
increasingly used for industrial applications. Such tools
support different activities in the modeling and
simulation lifecycle, like specifying requirements,
model creation, model simulation, Functional Mock-up
Unit (FMU) export (Blochwitz et al, 2011; FMIStandard.org, 2014), model checking, and code
generation. However, the heterogeneity and complexity
of modern industrial products often require special
purpose modeling and simulation tools for different
DOI
10.3384/ecp17132823

phases of the development life cycle. Seamless
exchange of models between different modeling tools
is needed in order to integrate all the parts of a
complex product model throughout the development
life cycle.
During the past decade, the Open Services for
Lifecycle Collaboration (OSLC) specifications (Openservices.net, 2008) have emerged for integrating
development lifecycle tools using Linked Data (Heath
and Bizer, 2011). For traceability purposes, in
particular the OSLC Change Management specification
is relevant. In earlier work (Elaasar and Neal, 2013)
OSLC has successfully been demonstrated for
integration of modeling tools in general, and
traceability in particular.
OpenModelica (Fritzson et al, 2006) is an open
source modeling, simulation, and optimization tool for
Modelica (Modelica Association, 2012; Fritzson, 2014)
language. The OpenModelica Connection Editor
OMEdit (Asghar et al, 2010) is a graphical Modelica
model editing and simulation tool. It supports model
creation, deletion, FMU export/import, textual and
graphical model editing including connections
drawing, simulation, plotting, and documentation
presentation. In the previous version of OpenModelica
(Pop et al, 2014) the compiler supports traceability in
terms of tracing generated C code back to the
originating Modelica source code, but not in the OSLC
sense, and mostly used for debugging.
In this paper we present new traceability support in
OpenModelica where the traceability information is
exchanged with other lifecycle tools through a
standardized interface and format using OSLC. In
particular, OpenModelica supports automatic recording
and tracing of modeling activities such as creation,
modification, and destruction of models, import of
model description XML, export of FMUs, and creation
of simulation results to link models from various tools.
OpenModelica supports simple queries (traces to and
traces from) to present the traceability information to
the user.
The rest of this paper is structured as follows: In
Section 2 an overview of OSLC is given. The
traceability design and architecture is presented in
Section 3. An Example of integrated tools to trace

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

823

Traceability Support in OpenModelica Using Open Services for Lifecycle Collaboration (OSLC)

artifacts created during the system development
process is presented in Section 4. Section 5 describes
the traceability and model management workflow in
OpenModelica. The prototype implementation is
described in Section 6. Conclusions and future work
are presented in Section 7.

2

Open Services for Lifecycle
Collaboration (OSLC)

Open Services for Lifecycle Collaboration (OSLC)
(Open-services.net, 2008) is an open source initiative
for creating a set of specifications that enables
integration of development life cycle tools (e.g.,
modeling
tools,
change
management
tools,
requirements management tools, quality management
tools, configuration management tools). The goal of
OSLC is to make it easier for tools to work together by
specifying a minimum amount of protocol without
standardizing the behavior of a specific tool.
The OSLC specifications use the Linked Data model
to enable integration at the data level via links between
tool artifacts defined as Resource Description
Framework (RDF) (Manola and Miller, 2004)
resources (beside other possible representations such as
XML, JavaScript Object Notation (JSON) (json.org,
2016), Atom, and Turtle). The resources are identified
by HTTP URIs. A common protocol to perform
creation (HTTP POST) and retrieval (HTTP GET),
update (HTTP PUT) and delete (HTTP DELETE)
operations on resources is also specified.

3

of activities performed within the tool and interact with
other tools.

Traceability Design and
Architecture

The traceability design and architecture is mainly being
developed in the INTO-CPS project (into-cps.au.dk,
2015) which contains a set of tasks. One of these is the
design of traceability and model management with the
following goals (Lausdahl et al, 2016):
 Checking the realization of requirements in models
 Enabling collaborative work by connecting
artifacts and knowledge from different users
 Decreasing redundancy by connecting different
tools to a single requirements source and allowing
a system-wide view that is not only limited to
single tools
The Provenance (PROV) (Moreau et al, 2013) and
OSLC standards presented in (Fitzgerald et al, 2015)
are used to support traceability activities. PROV is a
set of documents built on the notation and relation of
entities, activities, and agents.
The design and architecture of the traceabilityrelated tools has recently been developed in (Lausdahl
et al, 2016) and is shown in Figure 1. Any modeling
tool written in any programming language can use
these traceability standards to support the traceability
824

Figure 1. Schematic architecture of the traceabilityrelated tools.

As depicted in Figure 1, the architecture is divided
into three parts:
 Modeling Tools  The modeling tools send
traceability information from activities that are
performed within the tools (e.g., model creation,
modification, import model description in XML) to
the daemon.
 Daemon  The daemon provides an OSLC
interface compliant with RESTful (Richardson and
Ruby, 2007) to store the traceability information
into the database and retrieve the traceability data
from the database. It is launched and terminated by
modeling tools.
 Neo4j Graph Database  The Neo4j database
(Neo Technology, Inc, 2007) is a graph database to
store the OSLC triples that make up the traceability
data.

4

An Example of Integrated Tools for
Cyber-Physical Model Development

OpenModelica has been successfully integrated with
the INTO-CPS tool chain to trace artifacts created
during the system development process from high level
requirements to simulation results. The tools involved
are Overture (Larsen et al, 2010), 20-sim (Controllab
Products B.V, 2013), Modelio (Favre, 2005) and RTTester (Verified Systems International GmbH, 2012).
The tool chain as shown in Figure 2 is defined by the
connections between the system architecture and the
simulation via the model description XML file and the
FMU.
The SysML Connection diagram defines the
components of the system and their connections. The
internals of these block instances are created in the
various modeling tools and exported as FMUs. The
modeling tools support importing the interface
definition (ports) of the blocks in the Connection
diagram by importing a modelDescription.xml file
containing the block name and its interface definition
linked with requirements. All tools are storing
information in Git and sending information about
existing and created artifacts to the global database.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132823

Session 11A: Modelica Tools & GUIs

Figure 2. An Example of integrated tools to trace artifacts created during the system development process (Bandur et al
, 2016).

5

Traceability and Model
Management in OpenModelica

In the new work reported in this paper, OpenModelica
has been extended with support of traceability in the
OSLC sense, where traceability information is
exchanged with external tools through a standardized
interface and format. The implementation is based on
an architecture and a common interface defined in
(Lausdahl et al, 2016) for exchanging traceability
information.
The modeling activities that can be recorded
automatically and traced within OpenModelica are:
 Model description XML import (linked with
requirements)
 Model creation
 Model modification
 Model destruction
 FMU export
 Simulation result creation
The complete workflow for traceability artefacts within
OpenModelica and the different components that rely
on are shown in Figure 3.

DOI
10.3384/ecp17132823

The following summarizes the main workflow that
could be used to create and record traceability
information in OpenModelica during cyber-physical
model development process.
1. Commit model file entity to Git repository and
record the Git-hash
2. Create URIs of the activity based on the Git-hash
3. OSLC triples describing the activity are generated
using the URIs
4. OSLC triples are sent to the traceability Daemon
5. Retrieve the traceability information (traces to and
traces from)
The traceability information is represented in JSON
format. The modeling activities described by OSLC
triples represented in JSON format are sent from
OpenModelica to the daemon. These traces are then
sent through the daemon to the Neo4j database, where
they are stored. In order to view and analyze
traceability data, this is later retrieved (traces to and
traces from) from OpenModelica, through the
appropriate queries from the daemon to the database.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

825

Traceability Support in OpenModelica Using Open Services for Lifecycle Collaboration (OSLC)

Figure 3. Workflow of traceability of artifacts during the system development process in OpenModelica.

6

Prototype Implementation

extended OpenModelica to support
modelDescription.xml (See Figure 4).

importing

We have implemented a prototype to demonstrate the
idea of exchanging traceability information for
integrating lifecycle modeling tools using OSLC. The
prototype is implemented based upon the design and
architecture presented in Section 3.
As mentioned, the implementation of this prototype
is an extension of OMEdit (Asghar et al, 2010) which
is implemented in C++ using the Qt Framework (Nokia
Corporation, 2011) graphical user interface library. For
presentation reasons, we have grouped the prototype
functionality into three categories: importing model
description XML, model management with Git
integration, and traceability support using OSLC,
which are described in the following subsections.

6.1 Import Model Description in XML
As a preparation for the extension to support tracing
for importing modelDescription.xml interface files, we

826

Figure 4. A screen shot of the model description XML
import operation.

OpenModelica can import model description XML
interface files (linked with requirements) created using
other system architectural modeling tools and create

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132823

Session 11A: Modelica Tools & GUIs

Modelica models from this information. The result is a
generated file with a Modelica model stub containing
the inputs and outputs specified in the model
Description.xml file. Then the user can create a
complete model using the GUI via drag and drop in the
editor. Hence, the traceability chain within
OpenModelica traces models linked with requirements
through model description xml import, model creation,
model modification, FMU export and simulation
results.

The implemented prototype also allows to create a
local Git repository by selecting Git -> Create New
Repository from the menu bar. Since the URI, as
presented in (Fitzgerald et al, 2015) is the combination
of the Git-hash and the unique path for every file in the
project, creating a Git repository for traceability
purposes automatically adds a structure (See the left
part of Figure 5) for models, simulation results, FMUs,
and model description XML files to the Git repository.

6.2 Model Management with Git Integration

The traceability support in OpenModelica provides a
graphical user interface to interact with other lifecycle
modeling tools.
As already mentioned in Section 4, OpenModelica
supports traceability in the OSLC sense, where
traceability information is exchanged with external
tools through a standardized interface and format. The
implementation is based on the architecture and a
common interface defined in (Lausdahl et al, 2016) for
exchanging traceability information.
OpenModelica imports the modelDescription.xml
and creates a Modelica model according to the FMU
interface. The generated Modelica model is completed
with behavior for the SysML block and the final model
is exported in the FMU form. The generated FMU is
then used in a whole system simulation connected
according to the SysML connection diagram. The

One of the objectives of the traceability tooling is to
manage the development process in terms of modeling
activities within the modeling tools. In order to achieve
this objective access to the version control system is
required
in
OpenModelica.
Therefore
the
OpenModelica Connection Editor OMEdit has been
enhanced to support Git version control as shown in
Figure 5.
The OMEdit Git integration is currently in an early
stage of development but already supports some basic
functionality (See Figure 5) such as staging modified
tracing operations on files for commit, committing, and
reverting changes. It is useful to provide viewing of
status and version history which can be used for
creating the resource URIs for the modeling activities
on each new commit.

6.3 Traceability Support in OpenModelica

Figure 5. GUI of Git Integration in OpenModelica and functions available to create traceability URI.

DOI
10.3384/ecp17132823

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

827

Traceability Support in OpenModelica Using Open Services for Lifecycle Collaboration (OSLC)

FMU master simulation algorithm component performs
the simulation via the INTO-CPS App. This whole
chain is traced using OSLC.
We have designed a graphical user interface shown
in Figure 6 which allows the user to record the
traceability information and send to the Daemon
(OSLC triples in JSON format), describing the activity
using the URIs generated in the GUI shown in Figure
5. The PROV and OSLC relations that are mainly used
in this work can be found in (Fitzgerald et al, 2015).

OpenModelica to the daemon and visualized in the
Neo4j database.
Entities
(e.g.
Modelica
files,
FMUs,
modelDescription XML file) are shown in green,
actions (e.g. model creation, FMU export,
modelDescription XML import) are shown in yellow,
agents (e.g. users with the names "Alachew",
Adrian, Peter, and Adeel) are shown in blue,
and their relationships what come from what and
what used what (e.g. wasGeneratedBy,
wasDerivedFrom, usedTool) are shown with red
arrows.
In order to view and analyze traceability data, we
have also designed a graphical user interface shown in
Figure 8 which allows the user to query traceability
information (traces to and traces from) from the
daemon to the database (via HTTP GET):
 http://localhost:8080/traces/from/<URI>/json and
 http://localhost:8080/traces/to/<URI>/json

Figure 6. GUI to send traceability information to daemon.

These traces are then sent through the daemon to the
database via HTTP POST http://localhost:8080/
traces/push/json, where they are stored. Figure 7 shows
an example of traceability information sent from

Figure 7. An example of traceability information sent from OpenModelica to the daemon and visualized in the Neo4j
database.

828

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132823

Session 11A: Modelica Tools & GUIs

thanks to Kenneth Lausdahl, Peter Niermann, Jos Hll,
Carl Gamble, Oliver Mller, Etienne Brosse, Tom
Bokhove, and Luis Diogo Couto for collaboration and
valuable input to traceability related tools design.

References

Figure 8. GUI to query traceability information (traces to
and traces from) from Neo4j database.

7

Conclusions and Future Work

This paper has presented a framework for traceability
and model management in OpenModelica, and its
integration with the Git version control system.
The new version of OpenModelica supports
traceability in the OSLC sense, where traceability
information is exchanged with external tools through a
standardized interface and format. The Modeling
activities that can be recorded automatically within
OpenModelica and traced are import of model
description XML linked with requirements, creation of
models, modification of models, destruction of Models,
export of FMUs, and creation of simulation results.
A first prototype to query traceability information
(traces to and traces from models or simulation results)
from the database and display to end-users in JSON
format is also complete. As future work, we also intend
to extend the OpenModelica tool to support
visualization and presentation of the traceability data
viewed both in the form of graphs and trees.
The OpenModelica model management with Git
integration is currently in an early stage of
development but is already being able to support endusers to trace back all steps of the modeling process
and to revert each step in the development history, and
also model collaboration between end-users. Ongoing
work is focused on having fully functional Git
integration including showing two versions of the same
model in parallel.
Future work also involves computing the impact of
two different versions of the same model on simulation
results and merging the models in way that the
resulting model can be valid without modification.

Acknowledgments
This work has been supported by the European Union
in the H2020 INTO-CPS project. Support from
Vinnova in the ITEA3 OPENCPS project has been
received. The OpenModelica development is supported
by the Open Source Modelica Consortium. Special

DOI
10.3384/ecp17132823

Adeel Asghar, Sonia Tariq, Mohsen Torabzadeh-Tari, Peter
Fritzson, Adrian Pop, Martin Sjlund, Parham Vasaiely,
and Wladimir Schamai. An Open Source Modelica
Graphic Editor Integrated with Electronic Notebooks and
Interactive Simulation. In Proc. of the 8th International
Modelica Conference 2011, pp. 739747. Modelica
Association, March 2011.Linkping University, Sweden,
2010.
Victor Bandur, Peter Gorm Larsen, Kenneth Lausdahl,
Casper Thule, Anders Franz Terkelsen, Carl Gamble,
Adrian Pop, Etienne Brosse, Jrg Brauer, Florian Lapschies,
Marcel Groothuis, Christian Kleijn, and Luis Diogo Couto.
INTO-CPS Tool Chain User Manual. Technical report,
INTO-CPS Deliverable, D4.2a, December 2016.
Torsten Blochwitz et al. The Functional Mockup Interface
for Tool independent Exchange of Simulation Models. In
Proceedings of the 8th International Modelica Conference,
Dresden, Mar. 2011. doi: 10.3384/ecp11063105.
Controllab Products B.V. Modelling and simulation software
package for mechatronic systems http://www.20sim.com/,
January 2013.
Maged Elaasar and Adam Neal. Integrating Modeling Tools
in the Development Lifecycle with OSLC: A Case Study,
pages 154-169. Springer Berlin Heidelberg, Berlin,
Heidelberg, 2013.
Jean-Marie Favre. Foundations of Model (Driven) (Reverse)
Engineering: Models  Episode I: Stories of The Fidus
Papyrus and of The Solarus. In Language Engineering for
Model-Driven Software Development, March 2005.
John Fitzgerald, Carl Gamble, Richard Payne, and Ken
Pierce.Methods Progress Report 1. Technical report,
INTO-CPS Deliverable, D3.1b, December 2015.
FMI-Standard.org (2014). Functional Mock-up Interface for
ModelExchange and Co-Simulation Version 2.0.
https://www.fmi-standard.org/
(accessed:
10th
of
December 2016).
Peter Fritzson. Principles of Object Oriented Modeling and
Simulation with Modelica 3.3: A Cyber-Physical
Approach. 1250 pages. ISBN 9781-118-859124, Wiley
IEEE Press, 2014.
Peter Fritzson, Peter Aronsson, Adrian Pop, Hakan Lundvall,
Kaj Nystrm, Levon Saldamli, David Broman, Anders
Sandholm. OpenModelica  A Free Open-Source
Environment for System Modeling, Simulation, and
Teaching. Proceedings of the 2006 IEEE Conference on
Computer Aided Control System Design, Munich,
Germany, October 46, 2006.
Tom Heath and Christian Bizer (2011) Linked Data:
Evolving the Web into a Global Data Space (1st edition).
Synthesis Lectures on the Semantic Web: Theory and
Technology, 1:1, 1-136. Morgan & Claypool, 2011. doi:
10.2200/S00334ED1V01Y201102WBE001.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

829

Traceability Support in OpenModelica Using Open Services for Lifecycle Collaboration (OSLC)

into-cps.au.dk (2015). Integrated Tool Chain for Modelbased Design of Cyber-Physical Systems. http://intocps.au.dk/ (accessed: 10th of December 2016).
json.org. JavaScript Object Notation. http://www.json.org/
(accessed: 10th of December 2016).
Peter Gorm Larsen, Nick Battle, Miguel Ferreira, John
Fitzgerald, Kenneth Lausdahl, and Marcel Verhoef. The
Overture Initiative  Integrating Tools for VDM.
SIGSOFT Softw. Eng. Notes, 35(1):16, January 2010.
Kenneth Lausdahl, Peter Niermann , Jos Hll , Carl Gamble
,Oliver Mller , Etienne Brosse , Tom Bokhove , Luis
Diogo Couto , Adrian Pop , and Christian Knig. INTOCPS Traceability Design. Technical report, INTO-CPS
Deliverable, D4.2d, December 2016.
Frank Manola and Eric Miller, editors (2004). RDF Primer.
W3C Recommendation. World Wide Web Consortium.
https://www.w3.org/TR/2004/REC-rdf-primer-20040210/
(accessed: 10th of December 2016).
Modelica Association (2012). Modelica: A Unified Object
Oriented Language for Physical Systems Modeling,
Language Specification version 3.3. https://modelica.org/
(accessed: 10th of December 2016).
Luc Moreau, Paolo Missier, James Cheney and Stian
Soiland-Reyes, editors and contributors (2013): An
Overview of the PROV Family of Documents.
https://www.w3.org/TR/prov-n/ (accessed: 10th of
December 2016).
Neo Technology, Inc (2007). Neo4j Database.
https://neo4j.com/ (accessed: 10th of December 2016).
Nokia Corporation (2011). Qt Project. https://www.qt.io/
(accessed: 10th of December 2016).
Open-services.net (2008): Open Services for Lifecycle
Collaboration  Lifecycle Integration Inspired by the Web.
http://open-services.net/ (accessed: 10th of December
2016).
Adrian Pop, Martin Sjlund, Adeel Ashgar, Peter Fritzson,
and Francesco Casella. Integrated Debugging of Modelica
Models.
Modeling,
Identification
and
Control,
35(2):93{107, 2014.
Leonard Richardson and Sam Ruby. RESTful Web Services
(First ed.), O'Reilly, 2007.
Verified Systems International GmbH, Bremen, Germany.
RTTester Model-Based Test Case and Test Data Generator
 RTTMBT: User Manual, 2015. https://www.verified.de/
products/model-based-testing/, Doc. Id. Verified-INT003-2012.

830

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132823

A Simulation Environment for Efficiently Mixing Signal Blocks
and Modelica Components
Ramine Nikoukhah

Masoud Najafi

Fady Nassif

ALTAIR ENGINEERING, FRANCE, ramin@altair.com

Abstract
There exist several specialized tools that provide environments for the development and simulation of either pure
Modelica models or pure signal based models. These environments have each their own advantages and flaws.
solidThinking ActivateTM has been developed to mix
these domains and take advantage of both of these approaches to system modeling. This paper presents this
mixed Signal-Modelica environment, and in particular the
efforts and challenges faced in its development.
Keywords: Modelica tool, Signal based tool, FMI

1

Introduction

R
The Modelica
language1 and tools are successfully used
for modeling physical systems in industrial applications.
This success is primarily due to the ability of Modelica to
express mathematical equations corresponding to physical
phenomena in a natural way (Modelica Association; Peter
Fritzson).
For modeling complete systems, for example systems
including controllers, Modelica provides other features
that makes it go beyond a declarative language for expressing equations. Data types other than reals, algorithm
sections, Matlab-like matrix operations are introduced to
R
dispense of the use of other tools, in particular Matlab
R

and Simulink for handling models with control components. Yet, still in many applications, the design process
requires using Modelica to model the physical plant and
exporting the model in the Matlab/Simulink environment
for controller design. The reason for this is in part the
limitations of the Modelica language, which is not well
suited for creating block diagrams, such as the ones used
in control applications, for which specialized tools such as
Simulink, Scicos (Campbell et al., 2010), and solidThinking ActivateTM have been developed.
In an attempt to provide an environment for modeling
efficiently both blocks and physical components, in 2002
Modelica was introduced in the Scicos environment in the
framework of the publicly funded project RNTL (Rseau
National des Technologies Logicielles) Simpa (Simulation pour le Process et lAutomatique). This Scicos extension (Najafi et al., 2004, 2005a,b; Nikoukhah, 2006;
Nikoukhah and Furic, 2009) allowed Scicos users to

1 http://www.modelica.org.

DOI
10.3384/ecp17132831

mix both standard Scicos blocks and Modelica components in the same environment. A similar extension was
later introduced in Simulink with the introduction of the
SimscapeTM language (Simscape).
Scicos/Modelica environment based on the Modelicac
compiler (Furic, 2007) provides a versatile modeling environment, especially thanks to the Coselica library2 . Even
though this extension allows Scicos users to use some
Modelica components in the construction of their models,
it has many limitations. For example Modelica libraries
cannot be automatically imported and used in Scicos.
Activate is a professional simulation tool developed by
Altair Engineering based on the open source academic
simulation software Scicos. As such, it inherits many
of Scicos features including the close integration with a
matrix-based scripting and programming language. In
Activate, the HyperMath Language (HML) has replaced
Scilab3 and NSP4 . And for the Modelica extension, Scicos
Modelicac has been replaced with the MapleSimTM compiler developed by Maplesoft5 in Activate.
Activate and Scicos both use the same mechanism to
integrate Modelica: at compile time, they aggregate Modelica components and create a Modelica program which
is then processed by the Modelica compiler providing
the C code corresponding to the simulating function of a
block replacing these Modelica components in the original model6 . The Activate environment however provides
specific features that has allowed taking the Modelica integration beyond what is available today in Scicos. This
paper presents this new modeling environment.

2

Motivations

It is widely agreed upon that for many applications Modelica today does not provide a viable alternative to blockbased modeling tools such as Simulink, Scicos and Activate. The limitations imposed by the language make it
difficult to provide the types of blocks that are needed
2 http://www.kybdr.de/software.
3 http://www.scilab.org
4 https://cermics.enpc.fr/~jpc/nsp-tiddly
5 http://www.maplesoft.com
6 A noteworthy difference is that in Scicos this simulation function
represents a DAE (Differential Algebraic Equations) forcing Scicos to
use a DAE solver, whereas in Activate the simulation function is provided as a model-exchange FMU representing ODEs. This difference
however is not relevant to the presentation here.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

831

A Simulation Environment for Efficiently Mixing Signal Blocks and Modelica Components

Figure 1. Different modules in Activate and their interactions.

to model control systems. For example creating a simple multiplexer block capable of concatenating a variable
number of vectors and scalars of different data types is
complicated in Modelica. Same is true for the summation block and many other basic mathematical operations
(Elmqvist et al., 2016).
Other limitations come from the lack of a powerful supporting math environment. The computation of model parameters, post processing of the simulation results, etc.,
require access to math and engineering libraries, which
could in theory be developed or interfaced in Modelica,
but would require an enormous and lasting effort. In
short it would amount to developing alternatives to Matlab, Scilab, HML, or Nsp, including their specialized toolboxes in control, signal processing, communication, optimization, etc. Some Modelica tools already use other languages, for example Maple and Python, for such support.

implementation of Modelica is considered with Julia7 as
User Language. This undertaking is very ambitious in that
the Underlying Language is also used for defining the dynamics of blocks and components. The Activate/Modelica
environment presented here is developed with this consideration in mind and follows the spirit of Scicos but uses
HML as the Underlying Language. It does not go as far as
defining dynamics of blocks in HML (except for embedded code generation purposes (Chancelier and Nikoukhah,
2015)); but rather it makes a clear distinction between the
block/model creation and compilation, and runtime simulation. Model creation, evaluation and compilation, and
in general anything that can be done before the start and
after the end of runtime simulation are based strongly on
the User Language. On the other hand the block dynamics
need not be based on the User Language. The standard
(Signal) Activate blocks have in general their runtime simulation functions expressed in C, and the equations of Activate physical components are expressed in Modelica.
This approach allows the Activate/Modelica environment to take advantage of existing technologies: Activate (synchronous semantics, block libraries, compiler,
Simulink import (Weis, 2015) facility) and Modelica (existing Modelica compilers, in particular the MapleSim
compiler, and existing Modelica libraries such as MSL).

A reasonable solution to this problem is to base the simulation environment on a User Language, preferably a
matrix-based mathematical language such as Scilab, Matlab, Nsp, Octave, HML, or even on non-matrix based
languages such as Python and LUA. The key point is to
give users the ability to interact with the simulation model
through this language for anything from block/component
creation, model construction, parameterization, compila- 3 Activate/Modelica environment feation, code generation and simulation to data collection,
tures
post processing, optimization, and more. The Scicos environment was developed in this spirit with Scilab as User Activate is not a Modelica tool per se; it cannot be used
Language. Matlab is the User Language for Simulink and conveniently to build Modelica libraries. Its objective is to
Simscape.
propose a unique harmonious environment to allow mixing regular Activate blocks and Modelica components in a
A very interesting effort in this direction is under7 http://julialang.org.
taken in (Elmqvist et al., 2016), where a complete re832

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132831

Session 11A: Modelica Tools & GUIs

same model. The user interface and behavior of Modelica
blocks and regular Activate blocks are designed to be as
similar as possible without being too different from user
interface of other Modelica tools. The Modelica components are seen as regular Activate block in this environment.

3.1

Modularity

A key architectural element in Activate is modularity. The
diagram in Figure 1 shows different modules that constitute Activate. There are three main modules, the graphical
user interface, the interpreter language, and the Activate
engine. The graphical user interface and the interpreter
can be replaced with similar modules fairly easily. For example the HML interpreter can be replaced with another
interpreter, and alternative user graphical interfaces (for
example javascript based tools) can be considered. The
other module that can easily be replaced is the Modelica compiler. Currently the MapleSim compiler is used.
In Scicos, Modelicac was used. Other compilers may be
considered in the future.
The modularity between the engine and the graphical
user interface is enforced by the usage of file based exchanges. The model, once edited is saved in an XML format and the engine uses this file to proceed with the compilation and simulation. The modularity of the interpreter
is guaranteed through the specification of a set of APIs
for the exchange with the graphical user interface and the
engine.

3.2

Double layer implementation

In the Activate environment, a model is constructed using
blocks. The compiler however does not operate on these
blocks; it interacts with Atomic Units (AU). In many cases
a block is associated with a single AU, but not always: a
block may produce a network of AUs. The AU or AUs
produced by a block may depend on the values of the
block parameters. Specifically, the choice of the AU(s),
their parameters, and the topology of the network is specified by an HML function associated with the block based
on the values of the block parameters.
The ability to programmatically instantiate an AU or a
network of AU(s) is an elementary feature in Activate but
provides a particularly useful functionality in the context
of Modelica components, as it will be described later.
Atomic unit (AU)
An AU may be presented as a "basic" block, but this would
be misleading. An AU has ports that are connected to
links, just like a block. It has parameters, like a block, but
these parameters are not in general the block parameters.
Consider for example the Activate block that implements
a transfer function. The block parameters are the numerator and the denominator coefficients of the transfer function. The AU associated with this block operates in time
domain and implements the dynamics based on the statespace realization of the transfer function. The parameters
DOI
10.3384/ecp17132831

of the AU in this case are the A, B, C, D matrices, which
are computed by the HML function associated with the
block.
In general an AU is a computational unit providing
APIs to be used by the simulator. The APIs are C functions that are called by the simulator at different stages
of the simulation: computation of the output, of the state
derivative, of the next discrete state, etc. But the AUs can
also be Modelica components. An AU may also be virtual.
The creation of AUs from Activates blocks based on
a User Language script is a process that does not have
an equivalent in standard Modelica or in Simulink (SFunctions). This process, which provides a clear separation between the model at the graphical layer and at the
compiler layer, has been first implemented in Scicos.

3.3

Modelica components

In Activate, Modelica components are Activate blocks and
treated as such in the graphical editor. They are also
treated similarly at the evaluation phase, prior to compilation. This means that certain properties of Modelica
components that are coded as annotations are handled by
the corresponding Activate XML file and HML evaluation
script. These properties include in particular the graphical
properties and the parameter descriptions. When a Modelica library is imported into Activate, these component
annotations are used to create the Activate blocks. These
annotations are never directly used in Activate.
So, having the Modelica component as an Activate
block means that all graphical features, parameter definitions, code instantiations, ..., are done in the usual Activate
way. The use of Activate block to instantiate the Modelica components provides facilities that allows for example
the creation of components with variable number of ports
or different data types based on block parameters. The
Activate block is thus a lot more versatile than a standard
Modelica component; even the internal Modelica code of
the block/component can be customized. At the extreme
case, the Modelica code itself could become a block parameter.
On the graphical editor, the visible difference between
a regular Activate block and a Modelica Activate block is
that the latter has special (implicit) ports. No connections
can be made between these ports and other Activate port
types. Two special interface blocks are used to interface
the Modelica world with the regular Activate world. One
has an implicit input port and a regular output port and
the other, the opposite (see Figure 2). Such connections
are meaningful only if the the connection on the Modelica
side is of type Modelica Signal.

Figure 2. Special blocks for Modelica-Activate world interface

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

833

A Simulation Environment for Efficiently Mixing Signal Blocks and Modelica Components

Importing Modelica libraries
The import of a Modelica library is done by the MapleSim
compiler, which creates HML scripts, the execution of
which create the corresponding Activate library. An Activate library is a collection of XML files, HML functions,
image icons and palettes. The MapleSim compiler also
uses the definition of component icons described in Modelica language to generate image files (svg format) to
be used by Activate as block icons. Certain features such
as dynamical icons (icons changing during simulation) are
not supported.
Currently, most but not all MSL (Modelica Standard
Library) blocks are imported and integrated in Activate
palettes.

3.4

way the mechanism operates. The newly created block
has one input and two outputs, as expected.

Model compilation

Compiling a model consists of producing a structure to be
used by the simulator. This structure contains all the information needed by the simulator that can be computed
before the start of the simulation. It contains in particular
type and size information, and scheduling tables specifying the condition and the order in which AU computational
functions are to be called during simulation. The same
structure is used for code generation.
Model evaluation
The evaluation is the first phase of model compilation. In
this phase, the model parameters are evaluated and the
HML function associated with the blocks are executed
producing the network of AUs associated with the model.
Note that this network of AUs, which retains a hierarchical
structure, does not in general present a one to one correspondence with the original block diagram model.
At the end of model evaluation phase, all model and
block scripts and parameters are removed. They are used
in this phase to construct the AUs and evaluate the numerical values of their parameters. They are not available or
needed for the rest of the compilation process, which deals
exclusively with the network of AUs.
Model flattening
Model flattening is the second phase of the compilation.
The hierarchical network of AUs produced by the model
evaluation phase is converted into a flat network of computational units. All virtual AUs are removed and all Modelica AUs have been replaced with computational AUs (in
particular derived from an FMU produced by the Modelica compiler).
A simple example is provided in Figure 3. This model
contains an electrical circuit, modeled for the most part
using Modelica components. The regular Activate blocks
are the sine wave generator and the Scope. There are three
interfacing blocks connecting the Activate environment to
the Modelica environment.
The Modelica part is aggregated into a single block as
shown in Figure 4. This step is of course fully transparent
to the user and is presented here as an illustration of the
834

Figure 3. Simple Activate diagram containing Modelica components.

Figure 4. Equivalent Activate model after aggregation of Modelica components.

The Modelica code corresponding to the Modelica part
is generated automatically by Activate and sent to the
Modelica compiler for compilation. The Modelica compiler then generates a corresponding FMU, which replaces
the Modelica part as shown in Figure 5. This step is of
course again transparent to the user and is presented here
as an illustration

Figure 5. Resulting regular Activate model with no Modelica
components.

Back-end compiler
In this phase, which consists of computing the scheduling
tables for the simulator, the structure contains no trace of
the Modelica components; they have been replaced with
computational AUs in the previous phase. So the introduction of the Modelica extension does not affect this phase.

4

Modelica integration through FMI

The way Activate handles the Modelica components is by
grouping them into a single Modelica model with inputs
and outputs that are clearly specified by special interfacing blocks, as presented in the previous section. In the
Modelica code generated by the Activate compiler, the interfacing blocks (shown in Figure 2) are instantiated as
Modelica.Blocks.Interfaces.RealInput
Modelica.Blocks.Interfaces.RealOutput.

The Modelica model is then compiled by the Modelica
compiler, which in turn generates a code executable in Activate. This code is then imported in the Activate model as
an FMU to replace the Modelica part. The FMI has been

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132831

Session 11A: Modelica Tools & GUIs

chosen as the exchange format because it is a standard already supported both by Activate and MapleSim.
The FMI format is a rich interface format and quite
compatible with Activate and Modelica. There are however a few shortcomings that need to be considered. Some
challenges encountered in the usage of FMI standard in
this context is discussed in this section.

4.1

Choice of the FMI type: Model-Exchange
or Co-Simulation

The Modelica part of the Activate model is converted into
Figure 6. A simple model mixing Modelica and Activate blocks
an FMU and imported as a regular Activate block. In the
exported FMU, both Model-Exchange and CoSimulation
implementations are available. Using the model-exchange
implementation allows taking advantage of different nu- an artificial algebraic loop.
merical solvers of Activate. The co-simulation implementation is useful for complex models where different parts
of the model are needed to be simulated separately or even
in parallel. Currently only the model-exchange implementation is used in Activate.

4.2

FMI import preserving full output/input
dependency property

A challenge in importing the FMI generated from the
Modelica code (or more generally any FMI) in Activate
is the treatment of output/input dependencies. In the Activate block (or more specifically its AU) output/input
dependencies are expressed as a vector of dependencies
specifying which inputs affect any of the outputs. So the
dependency is solely a property of an input port. The reason is that an AU computes all of its outputs in the same
call, so all its dependent inputs must be up to date when
the call is made. An FMU on the other hand specifies
output/input dependencies as a matrix specifying which
output depends on which known variables including individual inputs. The FMU provides routines that allow the
computation of output ports separately and take advantage
of variable caching.
A way to deal with this situation, which is the way the
Modelica extension is implemented in Scicos, is to simply
project the matrix of dependencies into a vector. This conservative approach properly assigns dependencies in Activate but "loses" information along the way. This may lead
in particular to detection of algebraic loops by the Activate compiler that are not true algebraic loops (artificial
algebraic loops). Even though there are ways to break algebraic loops in an Activate model, it is not the best way
to deal with this situation. A very simple example that
illustrates this problem is shown in Figure 6.
After compiling the Modelica part, a model similar to
what is shown in Figure 7 is obtained in Activate. In the
generated FMU, there is a direct dependency between the
SignalCurrent input port (in) and the CurrentSensor
output signal (A). The dependency is depicted by a red
dashed line in Figure 7. If the dependency matrix is projected into a vector, both the output ports A and V are
considered depend on the input port in, which results in
DOI
10.3384/ecp17132831

Figure 7. The model in Figure 6, after converting the Modelica
part into an FMU block.

There is no solution to this problem as long as the FMU
block implements a single AU. But as it was stated previously, Activate blocks can implement a network of AUs,
the topology of which can depend on block parameters. It
turns out that the matrix output/input dependency can be
properly implemented by a properly constructed network
of AUs to implement the FMU.
In this case the block parameters are provided by the
FMU XML file. By reading and parsing the XML inside
the FMU, the block generates a network of AUs, as shown
for example in Figure 8 in the case of a 2 input 4 output
FMU block. The network contains a central AU, always
present, and an AU associated with each output port. The
input dependency associated with an output is specified
in the AU associated with that output. In this particular
example it can be seen that the first output depends on
both inputs whereas the second output has no input dependency, the third output depends only on the first input
and the last output depends on the second input.
The central AU includes the simulation APIs for state
derivative computation and discrete state updates and does
not have any input dependency. All the AUs in the network use the same internal structure, which is instantiated
by the central AU. The central AU provides a pointer to
this structure to the other AUs through its output port.
In the case of the model in Figure 6, the network of
AUs is generated as in Figure 9. By using this network
to replace the FMU block, the resulting Activate model
contains no algebraic loop.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

835

A Simulation Environment for Efficiently Mixing Signal Blocks and Modelica Components

file inside the FMU.
Another way is to add a new function to the set of FMI
APIs in order to bring back the solution on the constraint
after each completed integration step.
fmi2ApplyProjection(fmiComponent c)

This function would apply a near-minimal projection
to the continuous states in the model. This is often done via a Newton-based method, and terminates
Figure 8. Automatically generated network of AUs from FMU when it achieves the desired precision. This method can
import for an FMU with two input and four output ports.
be applied on single-step solvers where memory of the
past solution is not used. It will be necessary to call
fmi2GetContinuousStates after the projection to obtain the continuous states satisfying the solution. Having
this as a separate function allows the simulator to choose
when it is applied (e.g. at the end of an integration step,
internal to the step, after events, etc.).
A third way, which does not require adding a
new API, a projection is implicitly applied when
fmi2CompletedIntegratorStep is called by the simulator. This solution would work only with single-step
solvers. No error tolerance control can be used on the conFigure 9. The network of AUs corresponding to the example in
straints in that case.
Figure 6.

4.4
4.3

DAE support and constraints on states

The current FMI standard is powerful enough to be used
for implementing the Modelica extension in Activate for
many situations but some extensions would be particularly
useful.
Compiling complex Modelica models, in particular mechanical models, very often results in high index DAEs or
sometime ODEs and DAEs with constraints. Keeping the
constraints valid is important to avoid drift in the solution. In the current FMI specification, only ODEs are supported. Activate currently supports both DAEs, and ODEs
with constraints. But these solvers cannot be used for the
Modelica extension since the FMI does not support DAEs
and ODEs with constraints.
The DAE support is currently being considered for
FMI. ODEs with constraints, should also be considered.
If it is known that an ODE x = f (x) satisfies a constraint
C(x) = 0, information that could be available in various
scenarios, then the solver should take advantage of this
information to reduce drift in the solution. The constraint
information may be provided as a residual function returning the constraint value, i.e., C(x), or as a projection function such as J T (JJ T )1 where J = C
x .
This FMI extension can be done in several ways. One
way would be to add one of these APIs to FMI interface:
fmi2Projection(fmiComponent c, double *J)
fmi2Constraint(fmiComponent c, double *C)

Handling input derivatives

Consider the simple example shown in Figure 10. In this
model the derivative of the input is required.

Figure 10. model requiring the derivative of inputs

When the time derivative of an input is required, the
derivative can be computed numerically inside the FMU,
but this does not always work for variable-step size solvers
since the derivative value is not necessarily stable as the
integrator step-size changes. Furthermore, at initial step or
just after an event that changes the internal model configuration, no derivative can be computed. If there are constraints that depend on these derivatives, the integration
step rapidly reduces to zero, stalling the simulation. In
FMI for CoSimulation, the derivative of inputs can be provided via the API fmi2SetRealInputDerivatives,
but nothing is available for ModelExchange FMI. The
only robust alternative currently is to add an extra input
port to provide the derivative of input from the environment, if available.

4.5

Using the Jacobian of the FMU

The numerical solvers often need the Jacobian of the
If the second API is used, then the number of con- model for numerical integration. The Jacobian can eistraints should also be declared as an attribute in the XML ther be provided analytically or computed numerically. In
836

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132831

Session 11A: Modelica Tools & GUIs

complex models providing the analytical Jacobian is crucial for obtaining reliable results. The FMU block8 may
provide directional derivatives of its state derivatives and
outputs with respect to its states and inputs. These directional derivatives can be used to compute the equivalent
linear model of the block. If an FMU block with nonlinear
dynamics defined as (1) provides its directional derivatives

x = f (x, u)
(1)
y = g(x, u),

Modelica expressions, records and functions

The parameters of Modelica components present in an Activate models follow the scoping rules of Activate. So the
records and functions used in the definition of parameters
in Modelica are not always consistent with the way Activate handles parameters. This creates a complex problem
for importing Modelica components. A translator of expressions is being developed to deal with this issue. For
importing models, the records should be converted into
HML scripts to be placed in Activate diagram contexts.
The matrices (A, B,C, D) as defined in (2) can be obtained This is a complex task, in general, but solutions have been
by repeated calls to fmi2GetDirectionalDerivative found in special cases.
function in FMI.
Initial equations
A =  xf B =  uf
(2) Initial equations in Modelica are global information that
C =  gx D =  gu
are not related to a specific component. Adding such information, even in specialized Modelica tools, cannot be
easily done in the user interface and must be added textually. Since Activate does not provide a textual interface,
the addition of initial equations currently is not possible.
Various solutions are being considered but for the moment
Activate does not allow the definition of initial equations
in models. Initial equations in library components are of
 Computing a pure numerical Jacobian, i.e., ignoring course handled by the compiler as usual.
the local analytical linear system of blocks and compute the complete Jacobian of the model using the 6 Conclusion
numerical differentiation method. This method usuActivate provides a complete environment for modeling
ally works fine and it is fairly fast, but may fail for
systems with both physical components and signal based
complex stiff models.
control parts where the physical components are modeled
 Mixing numerical and analytical Jacobian. In many in Modelica. The integration of Activate and Modelica
cases, the highly nonlinear part of the Jacobian of the is done by respecting the semantics of the two languages.
model is present in matrix A of the block. The ana- But there remain issues for going towards full Modelica
lytically obtained matrix A of blocks may be used to support. This paper has presented the Modelica extension
populate the Jacobian matrix of the model, then the in Activate and the issues that remain open.
rest of the Jacobian matrix can be filled numerically.
This methods works fine, and is the default method References
in Activate.

The (A, B,C, D) matrices are equivalent linear system of
the FMU block. The numerical solver, on the other hand,
needs the complete Jacobian of the entire model which
may be composed of other FMU blocks and other regular
Activate blocks. In order to obtain the complete Jacobian
of the model, Activate offers the following solutions.

Stephen L. Campbell, Jean-Philippe Chancelier, and Ramine

Nikoukhah. Modeling and Simulation in Scilab/Scicos with
 Fully analytical method. This method which is more
ScicosLab 4.4. Springer-Verlag New York, 2010. ISBN 978complex than other two methods is useful if all
1-4419-5526-5.
blocks provide their analytical equivalent linear system matrices (A, B,C, D). Since this method does not
Jean-Philippe Chancelier and Ramine Nikoukhah. A novel code
require calling the f (x, u) and g(x, u) function in (1),
generation methodology for block diagram modeler and simit is useful when calling these functions is expensive.
ulators scicos and VSS. CoRR, abs/1510.02789, 2015. URL
http://arxiv.org/abs/1510.02789.

5

Challenges
Hilding Elmqvist, Toivo Henningsson, and Martin Otter. Sys-

Activate is not a Modelica tool and cannot provide the
tems modeling and programming in a unified environment
same Modelica functionalities as do pure Modelica tools
based on julia. In Proceedings of the ISoLA 2016 - 7TH Intersuch as Dymola or OpenModelica. Modelica is an extennational Symposium On Leveraging Applications of formal
sion for the modeling and simulation environment Actimethods, verification and validation; 2016, pages 198217,
2016.
vate. Efforts have been made to provide a user-friendly
interface both for native Activate users as well as ModelUsing modelica under scilab/sciica component users in this environment. There are cur- Sbastien Furic.
cos, 2007.
URL http://www.scicos.org/
rently a number of limitations in this extension.
8 Only

FMI-2.0 blocks provide directional derivative.

DOI
10.3384/ecp17132831

ScicosModelica/Formation/Documentation/
IntroductiontoModelica.pdf.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

837

A Simulation Environment for Efficiently Mixing Signal Blocks and Modelica Components

Peter Fritzson. Principles of Object-Oriented Modeling and
Simulation with Modelica 3.3: A Cyber-Physical Approach.
Wiley, 2014. ISBN 9781-118-859124.
Modelica Association.
The Modelica Language Specification, Version 3.3 Revision 1, 2014.
URL
https://www.modelica.org/documents/
ModelicaSpec33Revision1.pdf.
Masoud Najafi, Azzedine Azil, and Ramine Nikoukhah. Extending scicos from system to component level simulation.
In Proceedings of the ESMc2004 international Conference;,
Paris; France; October, 2004, 2004.
Masoud Najafi, Sbastien Furic, and Ramine Nikoukhah. Scicos: a general purpose modeling and simulation environment.
In Proceedings of the 4th International Modelica Conference;
Hamburg; 2005, 2005a.
Masoud Najafi, Ramine Nikoukhah, Serge Steer, and Sbastien
Furic. New features and new challenges in modeling and simulation in scicos. In Proceedings of the IEEE conference on
control application; Toronto; Canada; August, 2005, 2005b.
Ramine Nikoukhah. Challenges in integrating modelica in the
hybrid system formalism scicos. In Claude Gomez Shi Li,
Long-Hua Ma, editor, The Oxford Handbook of Innovation.
Tsinghua University Press, Beijing, 2006.
Ramine Nikoukhah and Sbastien Furic. Towards a full integration of modelica models in the scicos environment. In
Proceedings of the 7th International Modelica Conference;
Como; Italy; 20-22 September 2009, pages 641645, 2009.
Simscape. Physical systems simulation. URL https://www.
mathworks.com/products/simscape.html.
Pierre Weis. Simport: A simulink model importer for scicos.
In Proceedings of The 3rd International Workshop on Simulation at the System Level for Industrial Applications; Ecole
Normale Suprieure de Cachan, France, October, 2015.

838

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132831

Component Development for Nuclear Hybrid Energy Systems
M. Scott Greenwood1
1

Oak Ridge National Laboratory, USA, greenwoodms@ornl.gov

Abstract
A Nuclear Hybrid Energy System (NHES) uses a
nuclear reactor as the basic power generation unit. The
power generated is then used by multiple customers as
either thermal power, electrical power, or both. The
definition and architecture of an NHES can be adapted
based on the needs and opportunities of a given local
market. For example, locations in need of potable water
may be best served by coupling a desalination plant to
the NHES. Similarly, a location near an oil refinery may
have a need for emission-free hydrogen production.
Using the flexible, multi-domain capabilities of
Modelica, Argonne National Laboratory, Idaho
National Laboratory (INL), and Oak Ridge National
Laboratory (ORNL) are investigating the dynamics
(e.g.,
thermal
hydraulics
and
electrical
generation/consumption) and cost of such a hybrid
system. This paper examines ongoing NHES work
including the modeling organizational layout,
highlighting a few subsystems, describing some of the
component development and providing results from a
study of multi-dimensional conduction model
development.
Keywords: thermal hydraulic, nuclear, economics,
hybrid systems

1

Introduction

Electricity markets in the United States are undergoing
significant shifts in the traditional market structure.
Factors such as mandates for renewable energy, overall
carbon reduction, and the emergence of cheap natural
gas have strained the profitability of primary baseload
electricity suppliers, including nuclear power plants.
As the typical nuclear power generating station
traditionally has only one customerthe grid
diversification of the customer portfolio in an integrated
or hybrid manner may be advantageous. A
representative NHES is depicted in Figure 1.

Figure 1. A representative NHES demonstrating a
possible coupling scenario of both thermal and electrical
energy with additional systems (e.g., an industrial process
and energy storage system) (Bragg-Sitton et al. 2015).

A hybrid energy system approach, coupling base load
energy suppliers and energy customers (thermal and/or
electric), may be profitable and preferred in future
energy markets. Possible scenarios include producing
products that are more profitable than electricity or
mitigating the possible load-following needand
subsequent cost increasesthat significant renewable
penetration may impose on nuclear power plants. For
example, Figure 2 is a representative summary of the
Electric Power Research Institutes (EPRI) recent study
on the impact of renewable energy generation on grid
variability (EPRI, 2015). Given current economic and
political trends, future electrical grids will require
highly variable operations that impose significant
technical and economic challenges for power producers.
Introducing hybrid energy systems may help create a
path to achieving highly variable markets that are
economically sound and do not compromise grid
reliability.
This paper presents background information on the
methodology being developed to evaluate the economic
merit of an NHES, with a focus on the development of
dynamic multiphysics models in Modelica that play a
key role in the economic evaluation. Additional
information beyond the scope of this paper can be found
in ORNL, 2016a, ORNL, 2016b, and ORNL, 2017.

This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of
Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United
States Government retains a non-exclusive, paid-up, irrevocable,
world-wide license to publish or reproduce the published form of this
DOI
of theGovernment
12th International
839
manuscript,
or allow others to doProceedings
so, for United States
purposes. Modelica Conference

10.3384/ecp17132839

May 15-17, 2017, Prague, Czech Republic

Component Development for Nuclear Hybrid Energy Systems

2050

Figure 2. Prediction of electrical grid variability for regions of the United States in 2050.
The color of the cells represents the variability. Regions approaching red and blue have
demands that will be difficult and expensive for the electrical grid to meetespecially
power producers operating under traditional market paradigms (EPRI, 2015).

2

The Tightly Coupled NHES

The reference hybrid energy system is referred to as a
tightly coupled system. This coupling indicates that
both the thermal and the electrical energy from the base
load power supplier are integrated with one or more
systems (e.g., industrial plant). The Modelica-based
system under development is presented in Figure 3. The
numbers in the figure correspond to the brief
descriptions in Table 1.

Table 1. Description of the various subsystems
comprising a tightly coupled hybrid energy system.
Identifier
1
2
3
4

Component
Primary Heat
System
Energy
Manifold
Balance of
Plant
Industrial
Process

5

Energy
Storage

6

Secondary
Energy
Switchyard

7
8
9

Electrical
Grid
Control
Center

Description
Baseload heat and
power
Diverts energy to
subsystems
Primary electricity
producer
Non-electric
commodity revenue
stream
Energy buffer to
increase overall
system robustness
Energy makeup

Example
Nuclear reactor

Electrical load
distributor
Electrical customer

Electricity distribution

Hub for sub-system
controls

Control/supervisory
systems

Steam distribution
Turbine and condenser
Steam electrolysis or
desalination
Batteries and firebrick

Gas turbine make-up

Large/small markets

2.1 Economic Evaluation: Cost

Figure 3. The tightly coupled NHES under development.
The blue lines indicate fluid, the red lines indicate
electricity, and the yellow lines indicate sensor/control
signals.

The dynamic model is used to provide non-economic
figures of meritsuch as the ability to meet specified
energy demands and overall system stability and
reliabilityto supplement the economic cost
evaluation.

840

An economic evaluation of NHESs will be performed to
investigate the minimum cost a hybrid system. This
information informs decision makers on the planning
and development of business/government agendas. To
evaluate the economic cost of a given hybrid system, the
Modelica model is coupled to the Reactor Analysis and
Virtual control ENvironment (RAVEN), a multipurpose software framework developed by INL that
allows for dispatching different software functionalities,
including surrogate model generation and optimization
routines (Rabiti et al., 2012). As outlined in Figure 4,
RAVEN supplies the dynamic model demand time
histories for specific subsystems along with subsystem
capacities (e.g., industrial process production capacity).
The system control logic then operates the overall
system to meet the supplied demand. At the end of the
simulation, various figures of merit (e.g., ability to meet
demand, reliability based on operation of components)
are passed to RAVEN. RAVEN then creates simplified
surrogate models of the dynamic system and performs a
cost-based optimization. This optimization generates

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132839

Session 11B: Power Plants & Energy Systems

new capacity parameters, and the process repeats until
convergence to an optimized system is achieved. Using
a high-performance computing cluster, this process is
applied for many different cases in parallel.

3

Dynamic Subsystem Models

Each of the subsystem models is built from a template,
which allows for replaceable classes, improved
interchangeability of control system approaches, and
quick introductions of alternative subsystem models
(e.g., replacing a steam electrolysis plant with a
desalination plant). Figure 6 shows the template used
when generating new subsystems and an example use
case of the primary heat system. The subsystem models
utilize the expandable connector signal bus for all
control and sensor signals. Data records are also used to
facilitate common reference values between
subsystems, their control schemes, and the overall
system.

Figure 4. Modelica NHES dynamic model and RAVEN
cost optimization process diagram (ORNL, 2016a).

2.2 Electricity Demand Profile
The specific energy demand profiles that provide set
points to the dynamic model capture the variability of a
specific energy market. For example, in a region with
large solar power installations, the net electricity
demandconsumer demand minus renewable supply
profile would show significant reductions in demand in
the middle of the daythe period with greatest
insolation. Figure 5 demonstrates a characteristic
demand profile and the associated contributions of each
of an example set of power producers over the course of
a year. The demand profile is fed to the Modelica model
using the combiTimeTable component in the
Modelica Standard Library (MSL), which uses a relative
path to an external text file to enable operation on the
cluster.

Figure 5. A one year electrical power demand profile
characteristic taken from the north-east region of the
United States (PJM, 2016). Each color represents the
respective contribution of a subsystem energy supplier
(ORNL, 2016b).

DOI
10.3384/ecp17132839

Figure 6. Subsystem template (left) and example use of the
template (right).

3.1 Example Subsystems
In this section, the primary heat system, energy
manifold, and balance of plant are briefly presented to
better illustrate the physics-based modeling approach.
3.1.1 Primary Heat System

Figure 7 demonstrates the implementation of a primary
heat source option, whichin this caseis an integral
pressurized water nuclear reactor based on the
International Reactor Innovative and Secure (IRIS)
(Westinghouse, 2007). A few important physical
phenomena captured in the model include the two phase
dynamic interactions of the pressurizer, the generation
of steam in a helical coil steam generator, and the
behavior of a nuclear core. The nuclear core model is
shown in Figure 8, and this model integrates the coolant
flow geometry and behavior, fuel behavior, and point
kinetics neutronics behavior, with feedback from the
fuel and coolant temperature.
Models in the various subsystems use custom models,
models from the MSL, and ThermoPower models. See
Section 5 for more discussion on specific component
modeling efforts.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

841

Component Development for Nuclear Hybrid Energy Systems

Pressurizer

Steam
Generator

Nuclear Core

Figure 7. The Modelica model of the IRIS integral
pressurized water nuclear reactor being used as the primary
heat source subsystem.
Figure 9. Steam energy manifold responsible for
directing thermal energy to connected subsystem models.
3.1.3 Balance of Plant

Figure 8. Model of a nuclear sub channel incorporating the
neutronic behavior, non-uniform power generation, fuel
conduction model, and coolant sub channel flow model.

One of the connections to the energy manifold is the
balance of plant. The balance of plant is responsible for
generating the primary share of electrical energy in the
hybrid system. The current, simple model contains a
steam turbine for electrical power generation, a
condenser, and a control valve (Figure 10). The turbine
control valve is responsible for small, fast control
modulations.

3.1.2 Energy Manifold

The current distribution system under consideration is a
purely thermal (i.e., steam/water) manifold (Figure 9).
The energy manifold relies on controller logic to actuate
distribution valves to handle large and slow powerset
point changes to other subsystems, as specified by the
demand profile. This actuation diverts hot steam coming
from the primary heat system to the desired destination.
The manifold also gathers return streams and directs the
flow back the primary heat system steam generator at
the proper temperature and pressure. Mixing and
splitting volumes then add thermal mass to the system,
dampening transient behaviors.

Figure 10. Simple balance of plant model, which converts
steam thermal energy to electrical energy and returns
subcooled water back to the energy manifold.

842

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132839

Session 11B: Power Plants & Energy Systems

4

Preliminary Model Performance

A preliminary testing of the model reads the external
data that contains the time series electrical demand
profile and then feeds this data to the balance of plant
control system. The control system actuates the control
valve to match demand as much as the physical process
allows. Figure 11 demonstrates 10 hours of dynamic
turbine power operation based on a demand profile. The
power changes are accomplished via the manipulation
of actuators such as the turbine control valve position.
At approximately hour three, the power set point is
above the deliverable power. Situations like this period
of unmet demand are tracked to inform the economic
evaluation.

Figure 11. Preliminary test case demonstrating the ability
of the coupled hybrid system to track a variable electrical
demand profile by diverting flow to/from the steam
turbine. Note the unmet demand at hour three.

The current NHES model consists of 14,581 equations
and simulates a one-week period in approximately 2
hours using Dymola 2017 FD01 on a desktop computer
(16 GB ram, Intel Xeon CPU ES-1607 v3 3.10GHz).
Figure 12 presents the set point and measured electrical
production values of a week-long simulation.

ThermoPower library. However, user experience has
identified various limitations to some components.
Therefore, several components have been improved or
remade for the needs of this project. A brief discussion
of two major components are presented in this section.

5.1 MSL: Dynamic Pipe to GenericPipe
There are many positive aspects of the current version
of the MSL DynamicPipe model. For example, the
flexibility of specifying the model structure and the
ability to easily change the number of discretized
volumes, flow, and heat transfer models is incredibly
useful. However, some significant limitations were
discovered when attempting to couple the dynamic pipe
with fuel and reactor neutronics models.
One primary issue was the inability to specify
temperatures or enthalpy distribution for the start values
of each control volume. The current DynamicPipe
assumes a linear distribution between the ports. Since
the neutronics model is highly sensitive to the
temperature of the coolant and fuel, simulations often
failed during the initial transient phase due to extreme
power fluctuations in the reactor core.
To more generalize the capabilities of a pipe model,
a new GenericPipe model was created. This model is
similar in structure to the DynamicPipe model, but it
removes some of its restrictions (e.g., added control of
initialization and geometry) and works towards a more
standard, organized approach to model development.
Figure 13Figure 15 show a few parameter windows
displaying the new controls of GenericPipe along
with the modified structure for various closure models,
including heat transfer, pressure loss, and geometry.
This generic pipe can also be used to create simpler
versions with more refined parametersincluding
DynamicPipeto ease user interaction. For
comparison, a few examples provided in the MSL fluid
package (e.g., BranchingDynamicPipes) were
recreated using the GenericPipe model and then
benchmarked. Current tests using GenericPipe yield
the same solutions as the DynamicPipe model but with
computational speeds up to 30% faster.

Figure 12. Load following electrical power production
from the NHES model over a period of one week.

5

Component Development

The modeling activity uses components and connectors
from the MSL along with a few components from the

DOI
10.3384/ecp17132839

Figure 13. Structure of the generic pipe model
demonstrating the expanded flexibility of the model.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

843

Component Development for Nuclear Hybrid Energy Systems

Figure 14. General parameter tab of the generic pipe. Note the Geometry parameter allows for replaceable geometries
(e.g., straight pipe and shell and tube or plate heat exchanger).

Figure 15. Improved initialization control for the pipe model permits simple initialization schemes based on port values or
more precise schemes based on discretized volume states.

5.2 Custom: Thermal Library
The temperature response of a system is very important,
particularly in nuclear reactors. The nuclear fuel
temperature impacts not only the coolant flow behavior
but also the power of the reactor itself by altering the
behavior of the neutronics. To produce reasonably
accurate models of nuclear fuel, a generic multidimensional discretized conduction model was created.
As part of this effort, the MSL Thermal package was
completely redone to create a standalone library, which
also includes a package of thermal resistances for
steady-state evaluations, fin efficiency calculations, etc.
(Figure 16). The created models are generic and can be

incorporated into cases that require thermal inertia or
dynamics of conduction in solids. An important aspect
of the library is the limited application of parameters
to only those variables which require the variable type
(e.g., initialization variables). All other parameters are
specified as type input to ensure the user has maximum
flexibility in model development. Additional features
such as radiation models will be added to the Thermal
package in the future.
5.2.1 Multi-Dimensional Conduction Models

Given the complex nature of multi-dimensional
models, additional discussion on a conduction model is
presented. Three different approaches were evaluated in

Figure 16. Thermal library with multi-dimensional conduction models, thermal resistance models, etc.

844

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132839

Session 11B: Power Plants & Energy Systems

developing the conduction models: the classical,
modelica, and mixed approach.
The classical programming approach relied on a
replaceable solution method that defined the
connections between cells. This approach has limited
flexibility as equations (e.g., spatial differentiation of
the energy equation) are hard-coded to initial
assumptions such as geometry.
The modelica approach relied on independent, singlenode, models to specify the behavior of unit volumes
and the energy flow between cells; these models were
then connected using connect() statements. Figure 17
shows the diagram layer of this modelica method and
depicts the use of simpler models to build up more
complex models.
The mixed approach limits use of connect() and
instead applies models that are have built-in
nodalization which allows direct assignment of the
variables that must be shared between models. In other
words, the mixed method attempts to hard-code all
generally applicable features of the model and only rely
on the Modelica generated equations/connections when
necessary while avoiding the embedded assumptions of
the classical approach.

Figure 17. Diagram layer of Conduction_123D using
the modelica approach. This method creates multidimensional conduction models by using independent
models to build more complex, standardized models.

Each of the approaches have successfully modeled the
needs of the hybrid energy system (e.g., fuel element
modeling and heat exchanger walls). Figure 18 shows a
surface plot of a fuel model with a fuel, gas gap, and
cladding region created using the conduction models.
Each of the regions have temperature-dependent
properties specified by the solid media package.

DOI
10.3384/ecp17132839

Fuel

Helium
Gap

Cladding

Figure 18. Surface plot of a non-uniformly heated fuel
element (fuel, gap, and clad) with external convection
created using the discretized conduction models.

Comparisons have shown that all three approaches
produce results comparable within a small and
reasonable margin of error (fractions of a degree
Kelvin), however, the computational resources of the
three approaches vary significantly. The classical
approach passes the translation process quicklyeven
for a large number of discretizationsand then
simulates quickly. The modelica approach can complete
a simulation in similar or less time than the classical
approach; however, the time it takes for the modelica
approach to translate the model becomes more
significant as the number of nodes being used increases
(Figure 19).

Figure 19. Demonstration of the translation and simulation
times required for each of the methods of a discretized
conduction model. For a given number of nodes, the
modelica method requires far more translation time than
the classical or mixed method, whereas the simulation
times for each method remain similar.

The issue of translation time stems is primarily a result
of relying on connect(), and therefore the translator,
to generate the necessary equations for the solver.
Figure 19 demonstrates that for a fixed number of many
equations (e.g., 90,000), the classical approachas
compared to the modelica methodcan achieve a much
finer discretization scheme (6,100 vs. 1,500 nodes)
without compromising the translation time (50 s vs. 240
s). However, the mixed approach also generates ~90,000

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

845

Component Development for Nuclear Hybrid Energy Systems

equations with 1,500 nodes but passes through the
translation phase in 25 s. This demonstrates that the
method in which the equations are generated, rather than
just the number of equations, is the primary controller of
translational time. The mixed approach resolves the
translational time penalty while also preserving efficient
simulations.

model flexibility
efficiency.

while

retaining

computational

Acknowledgments
This project was funded by the US Department of
Energys Office of Nuclear Energy under the Office of
Advanced Reactor Deployment.

References

Figure 20. Demonstration of the relationship between the
number of equations generated, the discretization scheme,
and the required translation time for each of the discretized
conduction model methods. The method of equation
generation is the primary controller of translational time.

Although the modelica method adopts the best
practices of Modelica programming by not repeating
code, the ability to address the time for translation
required the use of an alternative mixed approach. The
findings of this study are important for the development
of any discretized model and will be applied to
additional physics of interest such as fluid flows and
neutron behavior.

6

Conclusion

As energy markets shift to a highly variable demand
profile, traditional base load power suppliers will be
required to modify their business models. A hybrid
energy system approach, coupling base load energy
suppliers and energy customers (thermal and/or
electric), may be profitable and preferred in future
energy markets. The detailed dynamic multi-physics
models discussed in this paper are being coupled to an
economic cost optimization study that will inform the
potential benefits and limitations of these hybrid
systems by providing critical dynamic physical data of
a potential hybrid systems operation.
As part of NHESs development, various components
models are required to capture the important physical
responses of the system. Two key models are the pipe
model and thermal conduction models. This paper
discussed adaptations and improvements to a Generic
Pipe model and the creation of a new Thermal library.
The thermal library includes multi-dimensional
conduction models. Using these conduction models, an
investigation of proper model formulation has been
performed demonstrating a methodology to maximize

846

Bragg-Sitton, S.M., R. Boardman, M. Ruth, O. Zinaman, C.
Forsberg. 2015. Rethinking the Future Grid: Integrated
Nuclear Renewable Energy Systems. Report no. NREL/CP6A20-63207.
EPRI (Electric Power Research Institute). 2015. Program on
Technology Innovation: Fossil Fleet Transition with Fuel
Changes and Large Scale Variable Renewable Integration.
Technical report no. 3002006517.
ORNL (Oak Ridge National Laboratory). 2016a. Nuclear
Hybrid Energy System FY16 Modeling Efforts at ORNL.
Report no. ORNL/TM-2016/418. Oak Ridge, TN.
ORNL (Oak Ridge National Laboratory). 2016b. Nuclear
Hybrid Energy System Initial Integrated Case Study
Development and Analysis. Report no. ORNL/TM2016/707. Oak Ridge, TN.
ORNL (Oak Ridge National Laboratory). 2017. Nuclear
Hybrid Energy System Model Stability Testing. Report no.
ORNL/TM-2017/153. Oak Ridge, TN.
PJM. 2016. Estimated Hourly Load. Accessed November 4.
http://www.pjm.com/markets-and-operations/energy/realtime/loadhryr.aspx.
Rabiti, C., A. Alfonsi, J. Cogliati, D. Mandelli, and R.
Kinoshita. 2012. Reactor Analysis and Virtual control
ENvironment (RAVEN), FY12 report. Technical report no.
INL/EXT-12-27351. Idaho Falls, ID: Idaho National
Laboratory (INL).
Westinghouse. 2007. Computer Models for IRIS Control
System Transient Analysis. Report no. STD-AR-06-04.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132839

Modeling and simulation of fixed bed regenerators for a multitower decoupled advanced solar combined cycle
Ivn Mesonero

Jess Febres

Susana Lpez

IK4-TEKNIKER, Spain, {ivan.mesonero, jesus.febres, susana.lopez}@tekniker.es

Abstract

Two dynamic models of fixed bed regenerators for
metallic and ceramic configurations have been
developed in Modelica. These models have been both
worked out within CAPTURE European project and
will serve as design tool for a fixed bed regenerative heat
exchange system. The present article describes in detail
both models and presents a case study that compares
experimental and simulation results for the testing of a
ceramic honeycomb regenerative matrix.
Keywords: fixed bed regenerator, ceramic honeycomb,
stacked wire cloths, solar Brayton cycle

1 Introduction

The recently granted EU R&D project CAPTURE
(http://www.capture-solar-energy.eu) pursues a new
concept of central receiver system based on the
Decoupled Solar Combined Cycle (DSCC) plant
concept (see Figure 1). In such a plant, a multi-tower
approach is employed with a solar Brayton cycle turbine
on the top of each tower.

operation of the receiver and the turbine through the
charging and discharging of a certain number of fixed
bed regenerators.
Two approaches have been defined and modelled for the
configuration of the fixed bed regenerator matrix
material, a metallic approach based on stacked wire
cloths, and a ceramic approach based on ceramic
honeycombs monoliths. For the analysis of both options,
one-dimension dynamic Modelica model of each
approach have been developed within CAPTURE
project and will be included in a free Modelica library.
These models had to be parametric and flexible enough
to allow the analysis of the effect of the design variables,
such as the material characteristics and the bed
geometry, in the behavior of the regenerative heat
exchange.
Besides the two presented models, Modelica models of
the receiver and the turbine shall be developed within
CAPTURE in order to completely simulate the plant
shown in Figure 2. This development will be carried out
during incoming phase of the project.

Figure 1. CAPTURE plant configuration based on DSCC
concept

In CAPTURE project, a non-pressurized volumetric
receiver will be employed to feed the solar turbine using
a fixed bed regenerative heat exchange system for
connecting both pressurized and non-pressurized air
loops (see Figure 2). The fixed bed regenerative heat
exchangers are alternatively connected to the two
different air loops through a group of two-way on-off
valves. Thus, the system allows the continuous
DOI
10.3384/ecp17132847

Figure 2. Main subsystems of a single module of
CAPTURE plant

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

847

Modeling and simulation of fixed bed regenerators for a multi-tower decoupled advanced solar combined cycle

2 Metallic regenerative bed model

A cylindrical regenerative bed has been modelled
(MetalicRegenerativeBed1D) considering the
following main assumptions:
 Regenerative beds are made by a randomly stacked
woven-screen matrix with plain square (see Figure
3).

The following equations (1, 2, 3 and 4) describe how to
calculate the porosity in each option.
 ESDU:

 = 1  0.25 




NASA:

 = 1  0.25 




Armour & Cannon:

=1





(1)





(2)

 1+
(3)

=

=

Figure 3. 3D view of three randomly stacked screens
(plain square weave)







The matrix is made of metallic materials and the
model takes into account the dependency of their
conductivity and specific heat capacity with the
temperature.
One-dimensional fluid flow is assumed, including
only as heat transfer phenomenon the heat
convection between the fluid and the matrix, i.e.
radiative heat transfer is disregarded.
One-dimensional heat conduction along the matrix
(parallel to the fluid flow) is assumed. Perfect
insulation is considered at the lateral area, thus heat
losses can only be taken into account through upper
and lower end of the matrix

2.1 Model structure

The model is mainly composed of two components that
represent the solid and the fluid phases of the
regenerative bed.
The model also includes a replaceable porosity function
for the calculation of the volumetric porosity1 of the
matrix (), which is required for further calculation in
equations (5)  (10). The following options are available
to be chosen from a drop down menu: ESDUPorosity,
NASAPorosity,
ArmourCannonPorosity
and
XuWirtzPorosity. All of them were described by (Li
& Peterson, 2006). However, some discrepancies were
found for the porosity calculation defined by Xu &
Wirtz, in consequence the original reference (Xu &
Wirtz, 2002) was chosen for this case in order to define
the necessary equations implemented in the code.



Xu & Wirtz:

=1+
=

= 123 

.

 

  

(4)
 384 

 640

Where:

is the wire diameter;
 pitch is the distance between two wires or the
aperture;

is a factor that describes how compressed
are the meshes in the matrix;

is the thickness of the mesh;

is the regenerative bed length;

is the number of layers in the matrix.
It must be noted that for the last two options the user
must provide the value of some more parameters, the
thickness of the wire mesh or the number of layers in the
matrix, as shown in Figure 4.

In here the volumetric porosity is defined as the ratio
between the void volume and the total volume of a porous
body.
1

848

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132847

Session 11B: Power Plants & Energy Systems

Figure 4. Parameter dialog for the metallic regenerator model
2.1.1 Solid phase

Solid phase component is an instance of the class
HollowCyliner that is a lumped parameter thermal
system in the radial direction (there is no radial variation
of the solid temperature). It is composed of an array of
nodes which are instances of the class
HollowCylinder_Lumped that represents one section
of the solid material along its axis. Each node consists
of two classes. One that describes the conduction along
the material, and other that represents the thermal inertia
of the material section.
In order to calculate the thermal characteristics of the
solid phase model, the material properties have to be
entered in the model. HollowCylinder class includes
a replaceable instance of a class that contains the
characteristics of the material of the regenerative bed.
This material can be selected in the Solid tab of the
main model. In addition, the regenerative bed total mass
can be entered as a parameter. If no value of the total
mass is used, it is calculated multiplying the material
density by the total volume of the solid.
If a new material is required, the material class has to be
declared as a Modelica package extended from the base
class PartialMaterial. This package must contain
the thermal and physical properties of the chosen
material. The minimal set of properties required consists
of the density, the thermal conductivity and the specific
heat capacity. All of them may be defined either as a
constant or as function of the temperature.
Since the model was meant to describe the behavior of
porous materials and more in concrete woven-screen
matrixes, this class takes into account the porosity of the
matrix and the conductivities of the solid and the fluid
in order to calculate the real thermal conductivity of the
matrix using the following equation (Martini, 2004):

DOI
10.3384/ecp17132847

1+
=



1
1+

1

 1
+ 1

(5)

Where:

is the thermal conductivity of the matrix;

is the thermal conductivity of the gas in the
matrix;

is the thermal conductivity of the matrix
material (solid).


The class defining the solid phase has an array of inputs
named thermalConductivity_medium in order to
have access to the instantaneous value of the internal
variable
of
the
fluid
phase
fluidPhase.heatTransfer.lambdas
that
is
exactly the instantaneous value of the thermal
conductivity of the gas in the different nodes along the
matrix.
2.1.2 Matrix materials

Apart from the basic partial models described in the
previous sections, four specific materials have been
added to the Materials library: DIN EN 10095, DIN
17742, DIN 17470 and DIN EN 10302. These
materials were chosen taking into account the expected
operating temperatures, their availability as meshed
material, thermal and mechanical properties, and
sintering possibility. In all cases, the specific heat
capacity and thermal conductivity are temperature
dependent values while density is assumed constant. In

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

849

Modeling and simulation of fixed bed regenerators for a multi-tower decoupled advanced solar combined cycle

addition, whether the material is sintered or not is not
taken into account in this version of the model.
However, the effect of sintering the material shall be
included in further versions as it influences the thermal
conductivity (Li & Peterson, 2006) and the mechanical
stability during the cycling regime, e.g. sintering
stabilizes an in-line stacked bed (unstable before
sintering) as a permanent link between wire meshes is
guaranteed.

=

main

differences

between

the

DynamicPipe
and
DynamicRegenerativeBedFluidPhase

following:




original
the
are the

Specific equations have been implemented under
the Detailed option of FlowModel. When the
Detailed option is selected, the relationship
between the mass flow rate and the pressure loss is
determined with experimental correlation for a flow
through an infinite randomly stacked woven-screen
matrix.
Flow friction characteristics were originally defined
by Kays & London (Kays & London, 1998). They
determined experimentally the relationship between
the friction factor and the Reynolds number for
different porosity values of the matrix. But the
equations implemented within this model
correspond to the following approximation
determined by Martini (Martini 2004):

 

< 60
60 
< 1000
1000 

(6)

Where:

is the pressure drop along the matrix;

is the fluid mass flow rate;

is the length of the matrix;

is the factor of friction for matrix;

is the area of flow;

is the density of the fluid at regenerator;

is the hydraulic diameter of the matrix;

is the Reynolds number.

2.1.3 Fluid phase

The



log
=
1.73  0.93  log
0.714  0.365  log
0.015  0.125  log

Regarding this two last properties, the available
information from datasheets was fitted to polynomial
expressions (linear or quadratic) in most cases and
logarithmic expressions in others.

Fluid phase component is an instance of the class
DynamicRegenerativeBedFluidPhase
that is
based on the DynamicPipe class from the Modelica
Standard Library (Casella, 2009) that is the model of a
straight pipe with distributed mass, energy and
momentum balances providing the complete balance
equations for one-dimensional fluid flow. It treats the
partial differential equations with the finite volume
method and a staggered grid scheme for momentum
balances.

 





A new option was added to the list of classes that
describe the convective heat transfer within this
model with equation (7). It is especially suited for
gas flow through an infinite randomly stacked
woven-screen matrix being a correlation from
Organ (Organ, 2010) of experimental data from
wire screens and crossed rods simulating wire
screens from Kays & London (Kays & London,
1998).
Main assumptions of the correlation are: perfect
stacking, i.e. screens touching is assumed, and
volumetric porosity between 0.602 and 0.832.



=

.



Where:

is the Stanton number;

is the Prandtl number;

is the Reynolds number.

(7)

Regarding the parameterization of the fluid phase
model, the hydraulic radius, , of the individual wire
screen and matrixes is determined by equations (8) and
(9) when porosity is calculated by the expression
defined by ESDU (Organ, 1997) (Kays & London,
1998):

=
=









(8)
(9)

It is worth to mention also that for both correlations
(flow friction and convective heat transfer) the Reynolds

850

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132847

Session 11B: Power Plants & Energy Systems

number in equation (10) is calculated with a velocity (vs)
that is not the real velocity of the fluid along the matrix.

=

 



=
=



(10)



Where:

is the density of the fluid at the matrix;

is the hydraulic diameter of the matrix;

is the cinematic viscosity of the fluid;

is the fluid mass flow rate;

is the free flow area of the matrix;

is the frontal area of the matrix;
  is the volumetric porosity of the matrix.

The reason for that is that the free flow area is calculated
as the product of the frontal area of the matrix and its
volumetric porosity. Usually, the volumetric porosity
and the screen porosity have different values, being the
second one bigger that the first one. Accordingly, the
computed values for the fluid velocity within the fluid
phase model will be bigger than the real ones.

3 Ceramic regenerative bed model

During the specification definition phase of CAPTURE,
the partners decided that the type of ceramic regenerator
to be modelled was to be a honeycomb with straight
channels (see Figure 5).

parallel straight channel geometry (two dimensions
honeycomb). Each channel of the regenerator is
modelled as a hollow cylinder tube, whose external wall
is assumed perfectly isolated. The radius of the fluid
channel, the internal radius , is one-half of the average
hydraulic diameter of the real fluid channels and the
outside radius is given by equation (11):

=

 



+

(11)

Where:

is the total number of gas channels;

is the hydraulic diameter of the gas channel;

is the total mass of the bed;

is the density of the bed material;

is the length of the bed.

The following considerations were taken into account
when modelling the ceramic regenerative bed:
 The fluid velocity in the tubes is determined
assuming a uniform distributed fluid flow through
all channels.
 As in the metallic bed, the ceramic regenerative bed
model is constituted by two namely solid and fluid
phases.
 Regarding the solid phase, there is no radial
variation of the temperature (lumped parameter
model in the radial direction is assumed).
Note that for simulations where cycling regimes are
required, the last assumption is expected to be valid only
when the cycle time of the system is, at least, an order
of magnitude bigger than the characteristic time for
radial heat conduction in the material (Muske 2010)
which is defined by:

=

(12)

Where:

is the characteristic time for radial heat
conduction;

is the thermal diffusivity of the bed material;

is the radius of the gas channel in the tube;

is the outside radius of the tube.

Figure 5. Cordierite honeycomb brick with high density
of straight channels.

This model (CeramicRegenerativeBed1D) is based
on the modelling approach presented by Muske et al
(Muske, 2000). Even though it was originally meant for
checkerwork regenerators, the model may be used for
other regenerators with the same type of geometry, i.e.

DOI
10.3384/ecp17132847

For the case of highly channeled honeycombs, the
reduced thickness of walls assures a good agreement
with the last assumption.

3.1 Model structure

Figure 6 shows the icon of the Modelica model of the
ceramic regenerator bed. Both heat and fluid ports are
taken directly from the Modelica Standard Library,
which means the model is compatible with any element
found in Modelica.Fluid and Modelica.Thermal.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

851

Modeling and simulation of fixed bed regenerators for a multi-tower decoupled advanced solar combined cycle
3.1.1 Solid phase

The model presented in section 2.1.1 was used to model
the solid phase of the ceramic regenerator as this model
allows the user to work with non-porous material. There
is a Boolean parameter in the Porosity tab that
disables the use of the equations mentioned in section
2.1.1., making the model suitable to represent ceramic
materials.
3.1.2 Fluid phase
Figure 6. Modelica ceramic regenerative bed model icon.

The model allows users to initialize the temperature of
the fluid and the solid elements. Initial values can be
input in the Initialization tab. If no value is passed to
the model, 24 C is used as default value for both
temperatures.
In order to define the geometry of the regenerative bed,
six parameters can be input in the General tab:
 The bed length: length in [m];
 The bed cross-section area: area_s in [m2];
 Channels cross-section area: area_c in [m2];
 Channels cross-section perimeter: perimeter_c in
[m];
 Number of channels: N_c;
 Segmentation perpendicular to heat conduction:
nNodes.

Note that the model is discretised in finite volumes
(solid and fluid volumes) and the degree of
discretisation is defined by the nNodes parameter.
As mentioned previously, the model is composed, as can
be appreciated in Figure 7, by two components that
represent the solid and the fluid phases of the
regenerative bed.

The fluid phase component is an instance of the
DynamicPipe class from the Modelica Standard
Library which is the model of a straight pipe with
distributed mass, energy and momentum balances
providing the complete balance equations for onedimensional fluid flow. It treats the partial differential
equations with the finite volume method and a staggered
grid scheme for momentum balances.
Most of the parameters that define the DynamicPipe
have been fixed and only three of them (the fluid
medium, the heat transfer model and the flow model) are
accessible from the GUI.
A new option was added to the list of classes for the heat
transfer that describes the convective heat transfer with
a correlation for rough pipes by Bhatti and Shah (Muske
2000).

4 Ceramic regenerative bed case

study

The case study proposed in this paper is centered on the
ceramic honeycomb approach for regenerative matrix.
The proposed model was verified against the
experimental results presented in a technical report
elaborated by SANDERS Associates in 1980 (Sanders,
1980). This report describes the application of the
regenerator in a solar prototype small plant as well as
the experimental set-up and test results of a ceramic
honeycomb regenerator manufactured for real
demonstration at laboratory level. Next paragraphs
describe the manufactured regenerator and the tests
performed that were be employed for the case study.

4.1 Ceramic regenerator description

Figure 7. Diagram of the ceramic regenerative bed
model.

852

The ceramic regenerator is a cylindrical matrix installed
inside an internally insulated cylindrical pressure vessel,
the complete system is called Thermal Storage Module
or TSM. Dimensions of the complete matrix are 914 mm
(36 inches) in diameter and 787mm (31 inches) in
length. Base material for the regenerator matrix are
cylindrical ceramic honeycombs logs from CORNING
with the same long as the complete matrix and a
diameter of 114 mm (4.5 inches). The shape of the logs

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132847

Session 11B: Power Plants & Energy Systems

are modified in order to get the sectors that finally
conforms the complete regenerative cylinder. Figure 8,
Figure 9 and Figure 10 clarify above description.

The Cordierite log employed for manufacturing the
TSM is a square cell based honeycomb designated by
300/12, which corresponds to 300 cpsi (cells per square
inch) and 12x10-3 inches of wall thickness. The thermal
properties of the Cordierite material in the honeycomb
are summarized in Table 1
Table 1. Thermal properties of the Cordierite material in
the honeycomb

Figure 8. Typical Cordierite honeycomb cylinder for
catalytic converters in automotive application from
CORNING

Temperature
C (F)
Specific heat
J/kg K
(BTU/lb F)
Thermal
conductivity
W/mK (BTU
in/h ft2 F)
Bulk density
g/cm3 (lb/ft3)

260
(500)

1005
(0.24)

399
(750)

1118
(0.267)

538
(1000)

1193
(0.285)

815
(1500)

1289
(0.308)

1.44 (10) constant
0.589 (36.4) constant

4.2 Test set-up and instrumentation

The test set-up is mainly composed of a ceramic
regenerator, a four-way valve, a gas burner, a
compressor, control valves and piping. The test
schematic can be seen in Figure 11.

Figure 9. Picture of the internal cross section of a ceramic
heat exchanger with the same manufacturing approach as
SANDERSs regenerator (Sheindlin, 1986)

The test set-up is equipped with sensors allowing the
analysis of the regenerator performance under different
test conditions. Principal sensors of interest for the
analysis are: air mass flow meter, air temperature
sensors, air pressure sensors and temperature sensors for
the measurement of the ceramic material in different
positions along the bed.

Figure 11. Test set-up schematic developed by
SANDERS (Sanders, 1980)

4.3 Test selection for the case study
Figure 10. Diagram of the Thermal Storage Module
developed by SANDERS (Sanders, 1980)

DOI
10.3384/ecp17132847

For the model validation two different types of tests
were chosen, a single shot test and a cycling test. Both
tests are described in the next paragraphs.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

853

Modeling and simulation of fixed bed regenerators for a multi-tower decoupled advanced solar combined cycle
4.3.1 Single shot test

This test is based on a sudden heating up (or cooling
down) of the regenerator with an air stream that flows
from top to bottom (or from bottom to top). The initial
temperature of the entire matrix is constant and
homogeneous.
The objective of the test is to analyze the thermal
performance of the bed in terms of thermocline
propagation along the matrix (transient response).
Table 2. Selected single shot test data

Air flow direction

Upward

Air temperature C (F)
Initial homogeneous temperature in
the matrix C (F)

702 (1295)

Air mass flow kg/s (lb/s)

0.19 (0.43)

146 (295)

Figure 12 shows the original graph with the
experimental results of the selected test (Sanders 1980)
and the simulation results obtained overlapped. The
simulation results were obtained with the model
described on section 3 under the general test conditions
of Table 2, but it has not been possible to accurately
reproduce the variable inlet temperature of the
experimental data. Moreover, the initial temperature of
the entire regenerative bed was assumed homogeneous
but the report points out the existence of an initial
temperature profile along the bed due to experimental
difficulties in setting up initial test conditions.
Consequently, further analysis of the system transient
shall be performed in order to understand the
quantitative deviations. Nevertheless, a good
agreement, from the qualitative point of view, has been
achieved between the experimental and the simulation
results.

4.3.2 Cycling test

This test is based on a continuous cyclic operation
(charging and discharging) of the regenerator starting
from an initial steady state (constant temperature within
the entire matrix). During the charging phase, hot air
flows at atmospheric pressure, which simulates the heat
input of the solar receiver. In the discharging phase cold
air is blown in the opposite direction to simulate the inlet
from the process return (a pressurized air would
simulate compressor outlet of an air turbine).
The objective of the test is to analyze the performance
of the bed working in cycling conditions in terms of
thermocline evolution until the system becomes stable
(cyclic state).
Table 3. Selected cycling test data

Air flow direction

Air mass flow kg/s (lb/s)
Air temperature C (F)
Air pressure

Initial homogeneous
temperature in the
matrix C (F)

Charging (Downward)
Discharging (Upward)
0.19 (0.43)
Charging 702 (1295)
Discharging 146 (295)
Atmospheric pressure
for
charging
and
discharging
146 (295)

In the same way as for the single shot test, Figure 13
shows the experimental and the simulation results for
this test. The simulation results were obtained with the
model described on section 3 under the general test
conditions of Table 3. For this test the experimental data
for the inlet temperature of the air was not available so
it was assumed constant during each phase, charge and
discharge, of the cycle.
It can be appreciated in Figure 13 the very good
agreement between the experimental and the simulation
results for this test. The results are very similar
especially in the last cycles where probably the effect of
the different initial conditions applied was disappeared.

Figure 12. Experimental (black) and simulation (blue)
results of single shot test of the ceramic regenerative bed
model.

854

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132847

Session 11B: Power Plants & Energy Systems

References

Figure 13. Experimental (black) and simulation (blue)
results of cycling test of the ceramic regenerative bed
model.

5 Conclusions

Two Modelica models have been described for the
dynamic simulation of two types of regenerative beds, a
metallic one based on stacked wire meshes, and a
ceramic one based on straight-channelled honeycomb.
These models will be used as design tool in CAPTURE
project and will support the evaluation of the
performance of fixed bed regenerative heat exchangers.
These models are part of a public deliverable of
CAPTURE project and will be included in a free
Modelica library. In addition, prototypes designed using
the presented models will be tested along 2018 in the
Plataforma Solar de Almera (PSA). This give the
chance for validating the model with real data coming
from operation of the regenerative beds.

R.B. Bird et all, "Transport phenomena", Wiley, New York,
1960
F. R. Casella et all. "Standardization of Thermo-Fluid
Modeling in Modelica.Fluid", Proceedings of 7th
International Modelica Conference, 2009, Como, Italy
S. Kakac et all, "Handbook of single-phase convective heat
transfer", Wiley, New York, 1987
W.M. Kays and A.L. London, "Compact Heat Exchangers",
Krieger Publishing Company, Malabar, Florida, 1998
C. Li and G.P. Peterson, "The effective thermal conductivity
of wire screen", International Journal of Heat and Mass
Transfer 49 (2006) 4095 -4105
W.R. Martini, "Stirling Engine Desing Manual", University
Press of the Pacific, Honolulu, Hawaii, 2004
Modelica Association, "A Unified Object-Oriented Language
for Physical System Modeling", 2012
K.R. Muske et all, "Model-based control of a thermal
regenerator. Part 1: dynamic model", Computers and
Chemical Engineering 24 (2000) 2519-2531
A. J. Organ, "The Regenerator and the Stirling Engine",
Mechanical Engineering Publications Limited, London and
Bury St Edmunds, UK, 1997
A. J. Organ, "Thermodynamics and Gas Dynamics of the
Stirling Cycle Machine", Cambridge University Press,
Cambridge, 2010
Sanders Associates Inc, Small solar electric system
components demonstration final report, JPL contract
955279, Nashua, New Hampshire, August 20, 1980
A.E. Sheindlin, High temperature equipment, Hemisphere
publishing Corp., Washington, 1986
J. Xu and R.A. Wirtz, "In-plane effective thermal conductivity
of plain-weave screen laminates", IEEE TCPT 25 (4)
(2002) 615-620

A case study has been presented where experimental
results from the testing of a ceramic honeycomb
regenerator were compared with simulation results
obtained with the model developed for this regenerator
typology. The model provides a suitable representation
of the regenerative bed behaviour and constitutes a
useful tool for the design of these components.
Finally, the authors are currently working on the
metallic bed models in order to study the effect of
different configurations of the metallic meshes to assess
the feasibility of using this type of regenerators. In
addition, the metallic bed model is being extended to
include other stacking configuration (in-line and
staggered). These results will be presented in future
publications.

Acknowledgements

The authors would like to thank the European
Commission for partial funding of this work related to
CAPTURE project (H2020 research and innovation
programme, grant agreement No 640905).
DOI
10.3384/ecp17132847

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

855

856

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Annual Performance of a Solar-Thermochemical Hydrogen
Production Plant Based on CeO2 Redox Cycle
Alberto de la Calle1
1 CSIRO

Alicia Bayon1

Energy, 10 Murray Dwyer Ct., Mayfield West, NSW 2304, Australia,

{alberto.delacallealonso,alicia.bayonsandoval}@csiro.au

Abstract
For the first time, a dynamic model of a 1-MWth thermochemical hydrogen production plant is developed and implemented for CeO2 redox cycle. The work explores how
the variables of the process like the direct normal irradiation (DNI), temperature, pressure and degree of oxidation
affect the annual production of hydrogen. The model reveals that the thermal inertia of CeO2 is significantly high
to accomplish the oxidation without refrigerate the oxidizer. The operation is optimized to obtain the maximum
amount of hydrogen in a year by only modifying the mass
flow rates at the inlet of the reactors. The flexibility and
adaptability of the model allows to test different system
configurations and optimize the hydrogen production.
Keywords: Solar fuels, Central receiver, High temperature, Dynamic modelling

1

Introduction

Solar energy is, by far, able to be massively exploited for delivering all of the world energy needs
utilizing only a few percent of the deserted areas (IRENA and IEA-ETSAP, 2013; Lewis and Nocera,
2007). Nevertheless, the storage of the thermal energy for
its use during the non-solar periods is required to couple
production/demand rate in the energy market. In this context, the conversion of the solar concentrated source into
storable and transportable fuels is a remarkable alternative
to extent the commercialization of solar power technologies.
One attractive pathway is the solar thermal production
of hydrogen. Within all possible solar driven routes, solar thermochemical H2 O splitting offers a path to produce carbon-free hydrogen. Hydrogen is an energy carrier in addition to a commodity used for the several industrial processes (Ramachandran and Menon, 1998). Nevertheless, direct thermolysis of H2 O requires temperatures
well above 2000 K to obtain significant H2 concentrations
(Fletcher, 2001). In addition, to avoid the recombination
of the product gas H2 and O2 upon cooling, they need
to be separated at the dissociation temperature, which is
technically challenging (Fletcher, 2001). In this respect,
H2 O-splitting thermochemical cycles have been investigated to reduce the process operating temperature compared to direct thermolysis. In addition, the need for
DOI
10.3384/ecp17132857

high-temperature product gas separation is eliminated, because H2 and O2 are produced in separate process steps.
Compared to multi-step cycles, two-step cycles promise
to reach higher process efficiencies due to higher operating temperatures and less irreversibilities (Abanades et al.,
2006).
Besides the environmental benefits of the thermochemical cycles, several impediments must be confronted to the
economic realization which concerns the design of reactor
to reduce the radiation and conduction losses and materials development revealing satisfactory durability, reactivity and efficiencies (DSouza, 2013; Roeb et al., 2012).
Likewise, heat and mass transfer play a crucial role in the
building components and for the technological implementation of thermochemical reactors.
Up to date, 300 redox systems have been proposed although only few tens of them have been performed experimentally mainly due to temperature and thermodynamic limitations (Muhich et al., 2015). In terms of economic assessment, a recent report has indicated that solar fuels produced with 20% efficiency are likely to be
cost competitive (Kim et al., 2012). Upon all the possible
metal oxide candidates, Ceria (CeO2 ) is the most promising material so far studied during the last 50 years because it demonstrates faster hydrogen production kinetics and high selectivity (Ackermann and Steinfeld, 2014;
Chueh et al., 2010; Furler et al., 2012; Gao et al., 2016;
Scheffe and Steinfeld, 2012). In this cycle, the nonstoichiometric ceria, with fluorite-type structure, retain the
oxygen vacancies maintaining its cyclability. The reactions involved in this process are:


CeO2  CeO2 + O2 (g)
2

(1)

CeO2 +  H2 O(g)  CeO2 +  H2 (g)

(2)

The thermal reduction (Equation 1) occurs at temperatures not lower than 1500 C accompanied by a low O2
partial pressure about 1 Pa (Chueh et al., 2010). This condition requires a large amount of inert gas flowing into the
reaction media and, consequently, an enormous economic
penalty influenced by three factors: cost of inert gas, separation of O2 produced downstream and energy losses
transferred to the gas (Furler et al., 2012). In the low temperature step, the exothermic water splitting (Equation 2)

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

857

Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox Cycle

takes place at lower temperatures commonly between 600
and 1000 C.
The thermochemical efficiency was largely explored
in previous works (Bader et al., 2013; Ermanoski, 2015;
Ermanoski et al., 2013; Bulfin et al., 2015). In this context, a maximum of 68% could be obtained if all the
CeO2 is reduced to Ce2 O3 at 2200 C with the sun as
only heat source. However, at 1500 C only 2% conversion is obtained in real conditions, lowering the efficiency up to 1.72% from solar to fuel without heat recovery (Furler et al., 2012). This value could be enhanced
to 20% if ideal heat recovery is applied (Ermanoski et al.,
2013). However, all the previous thermodynamic analysis are based on steady-state simulations with the aim of
maximizing the reactor efficiency of the process giving an
single value of DNI without considering the variability of
the solar resource, heliostat field design and receiver performance. The goal of this work is to provide insights
on the effect of the variability of the solar resource over
the annual performance emulating a solar production plant
based on a Ceria thermochemical water splitting cycle.
In the present paper, a new dynamic model of a solar
hydrogen production plant is developed for annual simulations. The model is based on an object-oriented modelling methodology following a modular and hierarchical
structure. The final model has been graphically implemented by connecting different components which encapsulate the main thermodynamic processes that take place
in the plant. Modelica and Dymola 2017 were the language and the simulation environment used in this work.

2

System description

A 1-MWth solar hydrogen plant is designed to be placed
in Geraldton (WA), Australia. Table 1 shows the system
design specifications. It consists of two rotatory reactors
(for reduction and oxidation), where a flow of particles of
CeO2 is recirculated in order to efficiently use the thermal
inertia of the reactors.
The thermal reduction (Equation 1) is endothermic and
takes place in a windowed reactor-receiver where the concentrated solar radiation directly heats the moving bed of
particles. Bader et al. (2013) suggests a concentration ratio of 3000 to get a high efficiency ratio according the following equation:
Qsol,0 = AreaC0 G0 ,

(3)

The design parameters are defined as follows:
Qsol,0 = 106 W which is the design power at the receiver, G0 = 950 W/m2 that is the DNI and C0 = 3000
which is the concentration ratio. This expression allows to
obtain the diameter of the aperture (considered circular)
of the receiver at the design point (0.67 m).
In order to get a suitable concentration ratio at the receiver aperture, a secondary concentrator is placed to increase the flux density of the radiation. A compound
parabolic concentrator (CPC) has demonstrated high performance in this kind of processes (Pitz-Paal et al., 2011).
858

Table 1. System design specification.

Solar resource
Location:
Geraldton (WA)
Longitude:
114.7
Latitude:
-28.8
Local time zone:
UCT+8
Heliostat field
Heliostat size:
2.44 x 1.84 m
Number of heliostats:
604
Mirror reflectivity:
0.95
Soiling factor:
0.95
Heliostat availability:
0.99
Solar tower
Design thermal power:
1 MW
DNI design value:
950 W
Tower height:
19.45 m
Receiver elevation:
-10
Receiver acceptance angle: 70
CPC aperture diameter:
1.16 m
Reactor aperture diameter: 0.67 m
Flux shape factor:
0.87
Solar concentration ratio:
3000

These devices, based on non-imaging optics, collect radiation entering the entrance aperture diameter (DCPC ) within
angle of CPC and direct it to the reactor aperture diameter
(Drea ) with negigible losses (OGallagher and Winston,
1983). The relationship between the aperture angle and
the concentration ratio is:
CCPC =

1
,
sin2 (CPC )

(4)

and the relationship between both (CPC and reactor) aperture diameters is:
DCPC =

Drea
.
sin(CPC )

(5)

The typical values of the heliostat field concentrating ratio
rounds 1000. In this respect, a value of 3 for the CPC concentrating ratio is required to provide the required design
parameters. According this value, the acceptance angle
(i.e. 2CPC ) is 70 and the CPC diameter 1.16 m.
SolarPILOTT M (NREL, 2016) was used to design and
optimize the heliostat field. It allows fast generation and
optimization of solar fields according a series of design
parameters. Figure 1 shows the optimized solar field layout for this study. In addition, SolarPILOTT M provides the
total optical efficiency of the solar field which includes
cosine error, reflectivity and soiling, blocking and shading, atmospheric attenuation and scattering and spillage
of a whole year as function of the zenith and azimuth solar angles (Table 2). The efficiency factor is calculated
for a specific receiver, in this case, a 1.16 m side-squared
receiver. In order to compensate the difference between

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132857

Session 11B: Power Plants & Energy Systems

Table 2. Reference solar field optical efficency as a function of Zenith and Azimuth angles.
zen \ azi
0.5
7
15
30
45
60
75
85

-150
0.42947
0.37594
0.35315
0.30117
0.25081
0.20337
0.15311
0.09236

-120 
0.42832
0.38236
0.36675
0.33196
0.30291
0.26952
0.20778
0.11869

-90
0.41992
0.39179
0.38640
0.37561
0.36867
0.34444
0.27510
0.14569

-60
0.40721
0.40135
0.40662
0.41417
0.41824
0.39892
0.33189
0.14285

-30
0.39708
0.40839
0.42085
0.43945
0.44617
0.43285
0.37052
0.15079

0
0.39435
0.41095
0.42596
0.44756
0.45552
0.44481
0.37133
0.14289

30
0.39443
0.40835
0.42087
0.43918
0.44604
0.43247
0.37056
0.15139

60
0.39397
0.40135
0.40617
0.41437
0.41737
0.39877
0.33101
0.14214

90
0.39521
0.39176
0.38656
0.37532
0.36826
0.34452
0.27444
0.14519

120
0.40576
0.38262
0.36641
0.33190
0.30301
0.26885
0.20749
0.11818

150
0.41858
0.37587
0.35311
0.30110
0.25063
0.20281
0.15253
0.09174

180
0.42729
0.37355
0.34833
0.29084
0.23260
0.16978
0.11308
0.06352

2013; Bulfin et al., 2015).

3 Object-oriented modelling
The model described in this section follows an objectoriented methodology based on equations. The main
physical and chemical phenomena were identified and encapsulated into independent and reusable modules. These
modules are connected creating hierarchical structures.
This approach allows to study different plant configuration to improve the annual performance.
The model was implemented in Modelica language
(Modelica Association, 2016) and is fully compatible with
Modelica Standard Library (MSL). Modelica Fluid and
Modelica Thermal connectors were used to define relationships between components. The thermodynamic propFigure 1. Heliostat field layout.
erties of fluids are obtained from medium models that extend from Modelica Media Interface (MMI). All the submodels are locally balanced ensuring robust modelling
both shapes, square and circle, a correction factor is ap- and debugging (Olsson et al., 2008).
plied. This shape factor, that is the fraction of the total
3.1 Subsystem modelling
concentrated power in both shapes, has a value of 0.87.
The oxygen generated during the reduction of CeO2 The system model that reproduces the plant described in
should be removed in order to get an optimum reduction 2, is presented in Figure 2. It consist on the following
performance. O2 is pushed out by a purge flow of high pu- sub-models: data source, sun, heliostat field, receiver, oxirity N2 allowing reach a very low oxygen partial pressure dizer, tank, heat exchangers, pumps and valve. This model
also includes: fluid source, fluid boundary, thermal source,
inside the reactor.
The hydrogen production is accomplished at the oxi- real expression and medium sub-models.
General assumptions are summarized as follows:
dizer and depends on the temperature, the reduction degree of the moving particles of CeO2 and the amount of
 CeO2 particle properties are assumed to be quasiwater entering the reactor. In order to obtain a high profluid.
duction of hydrogen, this plant considers CeO2 as the
limiting reagent (Equation 2). It is expected that the resi One-dimensional consideration within the direction
dence time of the CeO2 inside the oxidizer is sufficient
of heat and mass flows.
to achieve the complete oxidation. A small tank of CeO2
 Heat conduction and radiation are negligible in fluid
after the oxidizer allows a better management of the CeO2
components. Axial heat flow is also negligible in
particles in the cycle.
both fluids.
In order to achieve a higher system efficiency, several
heat recovery strategies were implemented. Two shell Lumped thermodynamic properties are assumed in
and-tubes heat exchangers placed at the input of both reacfluid components.
tors to recover the sensible heat of the gases. Furthermore,
it is assumed that steam lines are pre-heated up to 200
 Chemical reactions only take place in receiver and
C in order to prevent condensation. Finally, a solid-solid
oxidizer.
heat exchanger is placed between both reactors (receiver
Receiver and oxidizer sub-models are fully described
and oxidiser) to recover the sensible heat of CeO2 particles exiting the receiver as proposed in previous works with complete set of equations in this work. The re(Bader et al., 2013; Ermanoski, 2015; Ermanoski et al., maining models were obtained and adapted from existDOI
10.3384/ecp17132857

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

859

Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox Cycle

Figure 2. Modelica component diagram of the system model.

ing libraries. In fact, this demonstrates the high reusability, extensibility and customizability of the modelling methodology used. The models of data source, sun,
heliostat field and tank are been re-used from the opensource SolarTherm library (de la Calle et al., 2016a) with
some adaptations and extensions. This library is available
at https://github.com/solartherm/solartherm
and consists on concentrating solar thermal (CST) components that are used to perform the annual simulations and
the economic assessments of solar thermal plants. The
models of heat exchangers and pumps are utilized and
adapted from previous works of de la Calle et al. (2016b).
The models of fluid source, fluid boundary, linear pressure drop valve, thermal source and real expression are
included on the MSL and medium models extends from
MMI.
A brief description of each one of the sub-models is
provided below:

partial pressure (Ermanoski et al., 2013). In addition, the
medium includes a function for knowing the minimum required amount of water to achieve the oxidation based on
the water equilibrium and heat of reaction explicit in 
(Bulfin et al., 2015).
3.1.2 Data source
This model encapsulates the extraction of weather data. It
uses a MSLs CombiTimeTable with spline interpolation
such that derivatives are continuous. The raw file is a typical meteorological year data set in the TMY3-file format
(Wilcox and Marion, 2008). In order to be readable, the
file is modified being compatible with Modelica specifications (Modelica Association, 2016).
3.1.3 Sun

This model provides the sun position relative to
the plant location and the DNI in every time step.
Users can choose between different correlations such
as Duffie and Beckman (2013) or Blanco-Muriel et al.
3.1.1 Medium models
(2001) for calculating the declination and solar hour anTwo medium models were implemented to describe gas
gles. The time variable matches with the local time where
mixture and Ceria properties. The gas medium is
0 s is 00:00 of 1st of January in this time zone. The DNI
used in both reactors and extends from the Modelica
is provided by a RealInput connector.
Media IdealGases.Common.MixtureGasNasa. This
medium is composed of water, oxygen, hydrogen and ni- 3.1.4 Heliostat field
trogen at its gaseous state and assumes ideal gas properties This model calculates the total concentrated solar power
provided by McBride et al. (2002).
of the heliostat field (Qsol ) as:
The ceria medium model includes a function of the degree of reduction ( ) explicit in temperature and oxygen
(6)
Qsol = Nhel Ahel av op G,
860

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132857

Session 11B: Power Plants & Energy Systems

where the number of heliostats (Nhel ), the heliostat area
(Ahel ) and the heliostat availability (av ) are design parameters (Table 1). Solar angles and DNI (G) are provided
by the SolarPort connector and the total optical efficiency
(op ) is calculated using the MSLs CombiTable2D with
spline interpolation and the Table 2 as input. The start-up
and the shutdown of the plant is automatically controlled
according the minimum starting power, minimum operating power and the deploy angle, which are model parameters (Appendix I).
3.1.5 Receiver

The outer mass fraction is the same as the CV mass fraction:


mg,O2
,
(11)
XO2 = max 0,
mg
XH2 O = 1  XO2 ,

(12)

where the maximum function is used to avoid numerical problems. The oxygen generated during the reduction
is calculated as function of the oxygen molecular mass
(MO2 ) and the generated molar flow (ngen,O2 ):

mgen,O2 = MO2 ngen,O2 .
(13)
This model provides the dynamic amount of CeO2 reduced at the reactor. It is designed to perform annual simulations, therefore it is able to deal with zero-mass flow The generated molar flow depends on the degree of reducrates and zero mass. It is a lumped parameter model which tion ( ) and the inner CeO2 molar flow (nce,in ):
assumes a single control volume (CV). The main particunce,in 
lar assumptions are the following:
ngen,O2 =
.
(14)
2
 Infinite thermal conductivity inside the reactor: same
The amount of CeO2 (nce ) inside the reactor is calcutemperature at shell, CeO2 and gas.
lated by the molar balance:
 Black body receiver approach: while radiative thernnce = nce,in  nce,out ,
(15)
mal losses are considered only at the reactor aperture, convective thermal losses are considered at all where the molar flow at outlet (nce,out ) is calculated acthe external reactor surface.
cording the following when-clause:
(
 Perfect mixer approach: both inner CeO2 particles
nce,in when nce  nce,max ,
(16)
nce,out =
and gas are perfectly mixed with their respectively
0
elsewhen nce  0.
accumulated masses.
The maximum number of moles (nce,max ) is calculated ac Pressure drop is neglected inside the reactor. The
cording the maximum volume of CeO2 which is a model
same pressure is assumed in all the CV.
parameter (Appendix I).
The mass of CeO2 (mce ) is determined by its molar
 Constant inner molar flow rate of CeO2 is assumed.
mass
(Mce ) which depends on delta:
The residence time of CeO inside the reactor is con2

stant.

mce = Mcence ,

The gas mass inside of the reactor (mg ) is determined and the volume by:
by the inner gas (mg,in ), the outer gas (mg,out ) and the gas
produced during the reduction (mgen,O2 ):
mg = mg,in  mg,out + mgen,O2 .
m

Vce =

mce
.
ce

(17)

(18)

(7)

 is calculated as function of the temperature and the
partial
pressure of oxygen (pO2 ). The maximum value of
The gas pressure (p) is determined by means of the ideal

is
limited
to 0.25 which is the maximum value possigas law:
ble
to
maintain
the fluorite structure of CeO2 . The partial
pVg = mg kg T,
(8)
pressure is calculated as:
where the specific gas constant (kg ) depends on the mass
mO 2
fraction of gases. The volume of the reactor (V ) is constant
pO2 =
p.
(19)
M
O2
and filled with CeO (V ) and gas (V ):
2

ce

g

V = Vg +Vce .

The temperature of the reactor is calculated according
(9) to the global energy balance:

The oxygen mass balance is calculated according the
mass fractions:
mg,O2 = mg,in XO2 ,in  mg,out XO2 + mgen,O2 .
m
DOI
10.3384/ecp17132857

sh Qsol  Qloss = Qre + Qg + Qce ,

(20)

where the concentrated solar power (Qsol ) coming from
(10) the heliostat field is attenuated by the shape factor (sh ).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

861

Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox Cycle

The heat loss (Qloss ) is the sum of the radiative (Qloss,rd ) The outflowing mass fractions are determined by:


and convective losses (Qloss,rd ):
mg,N2
,
(30)
XN2 = min 1,

mg
4
,
(21)
Qloss,rd = Aap   T 4  Tamb


mg,H2
(22)
Qloss,cv = Are  (T  Tamb ) .
XH2 = max 0,
,
(31)
mg


mg,H2 O
The radiative losses are only applicable to the aperture
XH2 O = min 1,
,
(32)
mg
area of the reactor due to the lack of thermal insulation,
and the convective losses to the whole reactor. Emissivity
where maximum and minimum functions are used for pre( ) and heat transfer coefficient ( ) are model parameventing numerical problems.
ters and the ambient temperature (Tamb ) is an input of the
The mass flows due to the oxidation are:
model.
The receiver mass contribution into the energy balance
mgen,H2 = MH2 ngen,H2 , mcon,H2 O = MH2 O ncon,H2 O , (33)
(Qre ) is mostly due to the thermal inertia of the metal
where the molar flows depends on the degree of reduction
cover:
T,
Qre = mreC p,reT
(23) of the inflowing CeO2 :
nce,in 
ncon,H2 O =
,
(34)
where the mass (mre ) and the specific heat capacity (C p,re )
2
are model parameters. The gas contribution into the enngen,H2 = ncon,H2 O .
(35)
ergy balance is determined by:
Equations 15-18 are used in this model to calculate the
(24) CeO2 mass and volume dynamics. The temperature is calculated according to the global energy balance:
where it is assumed that the outlet temperature is the same
 Qloss,cv = Qre + Qg + Qce ,
(36)
as the temperature inside the reactor. The following equation calculates the CeO2 contribution into the energy balwhere Equations 22-24 provide the heat losses, the reance:
ceiver mass contribution and the gas contribution to the
energy balance. The CeO2 contribution is determined by:
T + mce,in (hce  hce,in )  nce,in  Qred .
Qce = mceC p,ceT
(25)
T + mce,in (hce  hce,in )  nce,in  Qox,ce .
Qce = mceC p,ceT
where it is also assumed that the outlet temperature is the
(37)
same as the temperature inside the reactor and heat of re- where heat of oxidation is assumed as Qox = Qred .
duction (Qred ) depends on  .
3.1.7 Tank
T + mg,in (hg  hg,in ) .
Qg = mgC p,gT

3.1.6 Oxidizer
This model dynamically provides the amount of hydrogen
produced. It is a lumped parameter model (1 CV) similar
to the receiver. The particular assumptions are the same
as for the receiver but in this case, due to the lack of an
aperture, only convection losses are been considered. The
main assumption is the complete oxidation of the CeO2 .
The gas mass inside of the reactor is determined by
the inflowing gas, the outflowing gas, the gas produced
(mgen,H2 ) and the consumed at the oxidation (mcon,H2 O ):
mg = mg,in  mg,out + mgen,H2  mcon,H2 O .
m

This model introduces the dynamics of a small storage element which pressure is fixed parametrically. It is a lumped
parameter model which assumes a cylinder volume and an
ideally mixed fluid. The mass balance is:
m = min  mout ,
m

(38)

and the energy balance is:
mhh = min (hin  h)  Qloss ,

(39)

where shell capacitance is neglected. The convective heat
losses to the environment are only applied to the metal
(26) surface that is in contact with the fluid.

3.1.8 Heat exchanger
The oxidizer pressure and the volume calculation are deThis quasi-steady-state heat exchanger model allows
termined by Equations 8 and 9.
The mass balances of nitrogen, hydrogen and water are to calculate sensible heat transfer between two fluids
based on the mathematical development of Spakovszky
calculated according the mass fractions:
(2008) and whose implementation was performed by
mg,N2 =mg,in XN2 ,in  mg,out XN2 ,
m
(27) de la Calle et al. (2016b). It is a lumped parameter model
which assumes that every state at the heat exchanger is lomg,H2 =mg,in XH2 ,in  mg,out XH2 + mgen,H2 ,
m
(28)
cally steady. The model is able to manage zero-mass flow
mg,H2 O =mg,in XH2 O,in  mg,out XH2 O  mcon,H2 O . (29) rates.
m
862

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132857

Session 11B: Power Plants & Energy Systems

3.1.9 Pump
This ideal pump model provides a controlled mass flow
rate between two points in the same streamline.
3.1.10 Linear valve
This model calculates the mass flow rate that crosses
through the valve opening with a linear approximation of
the pressure drop.
3.1.11 Fluid source
This model provides an input boundary condition where
the mass flow rate, the specific enthalpy and mass fraction
are defined. It is used to simulate the inflowing gas at the
reactors.
3.1.12 Fluid boundary
This model provides an output boundary condition where
the pressure, the specific enthalpy and mass fraction are
defined. It is used to simulate the environment (fluid models).
3.1.13 Thermal source

The model is a set of high-index differential and algebraic equations (DAEs) of 745 scalar variables. After the
translation, the model has 255 time-varying variables and
14 continuous-time states.
The numerical value of model parameters can be reviewed in Appendix I. The annual performance of the
plant is very sensible to the operating parameters. Few operating parameters have been optimised: CeO2 mass flow
rate, inlet receiver gas flow rate and inlet oxidizer mass
flow rate and its composition. The optimization method
was the Simplex algorithm and the objective function was
the final hydrogen production.
The annual simulation was performed using weather
data for the Geraldton location provided by AUSTELA
(2016). The CPU-time for integration was 161 s for the
whole year simulated with 9997 state events mostly related with the ACS.
The amount of hydrogen produced during the simulated
year is 46.57 t. The variation in time of this production
is depicted in Figure 3, where the different seasonal rate
(winter-summer) can be observed . The solar to hydrogen
efficiency of the plant, defined as:

This model provides a thermal boundary condition where
the temperature is defined. It is used to simulate the environment (thermal models).

=

mH2 HHV
,
Qsol

(40)

3.1.14 Real expression

4

Simulation

Dymola 2017 (Dassault Systemes, 2016) was the tool used
for the Modelica implementations and simulations. The
numerical solver used for the dynamic simulations has
been DASSL (Petzold, 1983) whose absolute and relative
tolerances were set to 104 .
DOI
10.3384/ecp17132857

Hydrogen Production
in Mass [t]

where mH2 is the annual amount of hydrogen, HHV
It is a model used to connect experimental data as inputs is the hydrogen heating value and Qsol is the annual
of the models in a graphical way.
amount of energy that reach the heliostat field, has a value
of 25.27%. This result is in line with previous works
3.2 Automatic control system
(Bader et al., 2013; Ermanoski, 2015; Ermanoski et al.,
The automatic control system (ACS) is designed to guar- 2013; Bulfin et al., 2015).
antee the stability of the plant in annual simulations. This
Figure 4 shows the simulation details of 5 days (from
system is made up by a series of on-off controllers which 28 August to 1 September). This week has one sunny day
control the circulation of the fluids inside the plant.
(240), three partially cloudy days (241, 243 and 244) and
The ACS must prevent the reverse flow of gases at one completely cloudy day (242) (Figure 4(a)). The convalves. For this reason, the valves are only opened when centrated solar power by the heliostat field is shown in
the pressure drop is higher than half of the nominal pres- Figure 4(b). The plant does not use all the available energy (Qraw ) because a minimum start-up power and minsure drop.
The gas source is opened since the heliostat field imum operating power are applied. Although 1.2 MW of
reaches the start-up power and it is closed when the he- peak power is reached 2 days, only few hour per day the
liostat field is shut down and the reactor temperatures are power is higher than 1 MW. At the day 242, the system
did not achieve the start-up power in the whole day and at
below a certain shutdown temperature.
The ceria pump starts when the heliostat field is started,
both gas valves are open and the receiver temperature is
50
higher than a minimum operating temperature. In order to
take advantage of the thermal inertia of the reactors, the
40
pump shut down when the heliostat field is shut down and
the receiver temperature is below the minimum operating
30
temperature.
20
10
0
0

50

100

150

200

250

300

350

Day

Figure 3. Annual hydrogen production.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

863

1.5

800

1.25

Heliotstat Field
Power [MW]

1000

2

DNI [W/m ]

Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox Cycle

600
400
200
0
240

Qraw

1
0.75
0.5
0.25

241

242

243

244

0
240

245

241

242

Day

243

244

(b) Heliostat field power.

2500

1.6
Trd

Tox



Pressure [bar]

2000
1500
1000
500

1.2

0.8

0.4
prd

0
240

241

242

243

244

0
240

245

241

242

Day

243

244

pox
245

Day

(c) Receiver and oxidizer temperatures.

(d) Receiver and oxidizer pressures.

0.25

0.05
Xmax

Xox

0.04

[]

0.2

0.03

H

0.1
0.05
0
240

2

2

HO

0.15

X /X

Degree of reduction ()

245

Day

(a) Direct normal radiation.

Temperature [ C]

Qsolar

0.02
0.01

241

242

243

244

245

0
240

241

Day

242

243

244

245

Day

(e) Degree of reduction.

(f) Relation between hydrogen and water mass fractions inside the
oxidizer.

Figure 4. Simulation details of 5 days.

days 243 and 244 the peak power barely reached 1 MW.
Figure 4(c) shows the CeO2 temperatures inside the receiver and the oxidizer. The operating reduction temperature is ranged between 1850  1950  C and the operating
oxidation temperature is around 1000  1100  C. When
the plant is shut down, the temperature decreased quickly
and 32 hours after is close to the ambient temperature.
The pressure inside both reactors is shown in Figure 4(d).
While the receiver works at ambient pressure, the oxidizer
nominal pressure has been set to 1.5 bar in order to assure
higher pressure than ambient when the hydrogen production is large. The degree of reduction is depicted in Figure 4(e), where peaks of 0.25 can be observed. For achieving the total oxidation of the CeO2 , a minimum amount
of water per hydrogen released is required inside the ox864

idizer (Bulfin et al., 2015). In Figure 4(f) is depicted as
xmax (the mass fraction of hydrogen into water) and it limits the amount of hydrogen produced at the oxidizer with
the water used. The figure shows that in the whole simulation, the hydrogen released (xox )is lower than the maximum amount expected at the equilibrium.

5 Conclusions
In this work, a dynamic model of a solar hydrogen plant
based on the CeO2 redox cycle has been presented. The
model has been developed with an object-oriented modelling methodology that it allows the re-used of several
work previously developed. The system is design to study
the transient behaviour of the plant in annual simulations.
It was implemented with the Modelica language and sim-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132857

Session 11B: Power Plants & Energy Systems

ulated with Dymola 2017. A basic automatic control system based on on-off controllers to guarantee the system
stability was included.
The model predictions are reasonable and some usual
simulation problems like zero-mass flows were solved
with effectiveness. The computational effort of the model
is low, therefore it can be used in optimization and control
studies.
Increasing the model accuracy should be the objective
of next works. The model reveals that thermal inertia of
the CeO2 is too much high to accomplish the oxidation
without extract heat flow from the reactor. The results suggest to review the assumptions related with heat losses and
design a cooling systems at the oxidizer. The optimization
of the plant through few operating parameters has demonstrated the flexibility of the system to be improved. Future
studies should include operating cost and advanced operating strategies.

Acknowledgement
This work was performed as part of the ASTRI, a project
supported by the Australian Government, through the
Australian Renewable Energy Agency (ARENA).

Appendix I: Model parameters
References
Stphane Abanades, Patrice Charvin, Gilles Flamant, and
Pierre Neveu. Screening of water-splitting thermochemical cycles potentially attractive for hydrogen production by
concentrated solar energy. Energy, 31:24692486, 2006.
doi:10.1016/j.energy.2005.11.002.

Heliostat field
Start-up power:
0.6 MW
Shutdown power:
0.3 MW
Deploy angle:
8
Ceria pump
Mass flow rate:
2.5 kg/s
Shutdown Temperature:
1000 C
Ceria Heat exchanger
Heat transfer coefficient:
500 W/(m2 K)
Area of exchange:
5 m2
Receiver
Reactor mass:
500 kg
Diameter:
0.67 m
Lenght:
0.34 m
Maximum CeO2 volume:
25%
Emitance:
0.88
Convective coefficient:
10 W/(m2 K)
Oxidizer
Reactor mass:
500 kg
Diameter:
0.67 m
Lenght:
0.34 m
Maximum CeO2 volume:
25%
Convective coefficient:
500 W/(m2 K)
Tank
Diameter:
0.5 m
Height:
0.5 m
Convective coefficient:
10 W/(m2 K)
N2 Source
Gas Mass flow rate:
0.25 kg/s
Shutdown temperature:
700 C

Simon Ackermann and Aldo Steinfeld. Diffusion of oxygen in Ceria at elevated temperatures and its application to
H2O/CO2 splitting thermochemical redox cycles. The Journal of Physical Chemistry Cournal of, 118, 2014.
AUSTELA.
The NREL System Advisor Model for
Australian CSP Stakeholders (SAM), 2016.
URL
http://www.austela.org.au/projects.
Roman Bader, Luke J. Venstrom, Jane H. Davidson, and Wojciech Lipinski. Thermodynamic analysis of isothermal redox
cycling of ceria for solar fuel production. Energy and Fuels,
27(9):55335544, 2013. doi:10.1021/ef400132d.
Manuel Blanco-Muriel, Diego C. Alarcn-Padilla, Teodoro
Lpez-Moratalla, and Martn Lara-Coira.
Computing
the solar vector.
Solar Energy, 70(5):431441, 2001.
doi:10.1016/S0038-092X(00)00156-0.
B. Bulfin, F. Call, M. Lange, O. Lbben, C. Sattler, R. Pitz-Paal,
and I. V. Shvets. Thermodynamics of CeO2 thermochemical
fuel production. Energy and Fuels, 29(2):10011009, 2015.
doi:10.1021/ef5019912.
William C Chueh, Christoph Falter, Mandy Abbott, Danien
Scipio, Philipp Furler, Sossina M Haile, and Aldo Steinfeld. High-flux solar-driven thermochemical dissociation of CO2 and H2O using nonstoichiometric ceria. Sci-

DOI
10.3384/ecp17132857

N2 valve
Design pressure drop:
0.05 bar
Closing pressure drop:
0.025 bar
N2 Heat exchanger
Heat transfer coefficient:
500 W/(m2 K)
Area of exchange:
5 m2
H2 O Source
Gas Mass flow rate:
0.71 kg/s
H2 O Mass fraction:
0.45
Shutdown temperature:
400 C
H2 O valve
Design pressure drop:
0.5 bar
Closing pressure drop:
0.25 bar
H2 Heat exchanger
Heat transfer coefficient:
500 W/(m2 K)
Area of exchange:
5 m2

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

865

Annual Performance of a Solar-Thermochemical Hydrogen Production Plant Based on CeO2 Redox Cycle

ence (New York, N.Y.), 330(6012):1797801, dec 2010.
doi:10.1126/science.1197834.
Dassault Systemes. Dymola 2017 - Dynamic Modeling Laboratory, 2016. URL www.3ds.com.
Alberto de la Calle, Jim Hinkley, Paul Scott, and John Pye. SolarTherm : A New Modelica Library and Simulation Platform
for Concentrating Solar Thermal Power Systems. Proc. 9th
EUROSIM Congress on Modelling and Simulation, pages 1
2, 2016a. doi:10.1109/EUROSIM.2016.162.
Alberto de la Calle, Lidia Roca, Javier Bonilla, and
Patricia Palenzuela.
Dynamic modeling and simulation of a double-effect absorption heat pump.
International Journal of Refrigeration, 72:171191, 2016b.
doi:10.1016/j.ijrefrig.2016.07.018.
Lawrence DSouza. Thermochemical hydrogen production from
water using reducible oxide materials: a critical review. Materials for Renewable and Sustainable Energy, 2(1):7, feb
2013. doi:10.1007/s40243-013-0007-0.
John A. Duffie and William A. Beckman. Solar Engineering
of Thermal Processes. Wiley, New York, USA, 4th edition,
2013. ISBN 9780470873663. doi:10.1002/9781118671603.
Ivan Ermanoski. Maximizing Efficiency in Two-step Solarthermochemical Fuel Production. Energy Procedia, 69:1731
1740, 2015. doi:10.1016/j.egypro.2015.03.141.
Ivan Ermanoski, Nathan P. Siegel, and Ellen B. Stechel. A
New Reactor Concept for Efficient Solar-Thermochemical
Fuel Production. Journal of Solar Energy Engineering, 135
(3):031002, 2013. doi:10.1115/1.4023356.
Edward A. Fletcher. Solarthermal Processing: A Review. Journal of Solar Energy Engineering, 123(May 2001):63, 2001.
doi:10.1115/1.1349552.
Philipp Furler, Jonathan R. Scheffe, and Aldo Steinfeld. Syngas production by simultaneous splitting of H2O and CO2via
ceria redox reactions in a high-temperature solar reactor. Energy & Environmental Science, 5(3):6098, 2012.
doi:10.1039/c1ee02620h.
Xiang Gao, Alejandro Vidal, Alicia Bayon, Roman Bader,
Jim Hinkley, Wojciech Lipiski, and Antonio Tricoli. Efficient ceria nanostructures for enhanced solar fuel production: Via high-temperature thermochemical redox cycles.
Journal of Materials Chemistry A, 4(24):96149624, 2016.
doi:10.1039/c6ta02187e.
IRENA and IEA-ETSAP. Technology Brief 4: Thermal Storage.
Technical Report January, 2013.
Jiyong Kim, Terry a. Johnson, James E. Miller, Ellen B.
Stechel, and Christos T. Maravelias.
Fuel production
from CO2 using solar-thermal energy: system level analysis. Energy & Environmental Science, 5(9):8417, 2012.
doi:10.1039/c2ee21798h.

Bonnie J. McBride, Michael J. Zehe, and Sanford Gordon. NASA Glenn Coefficients for Calculating Thermodynamic Properties of Individual Species. Technical Report
NASA/TP-2002-211556, National Aeronautics and Space
Administration (NASA), Cleveland OH, USA, 2002.
Modelica Association. Modelica Specification 3.3, 2016. URL
www.modelica.org/documents.
Christopher L. Muhich, Brian D. Ehrhart, Ibraheam Al-Shankiti,
Barbara J. Ward, Charles B. Musgrave, and Alan W. Weimer.
A review and perspective of efficient hydrogen generation
via solar thermal water splitting. Wiley Interdisciplinary
Reviews: Energy and Environment, pages n/an/a, 2015.
doi:10.1002/wene.174.
NREL.
The Solar Power Tower Integrated Layout
and Optimization Tool (SolarPILOT), 2016.
URL
http://www.nrel.gov/csp/solarpilot.html.
J. OGallagher and R. Winston.
Development of compound parabolic concentrators for solar energy. International Journal of Ambient Energy, 4(4):171186, oct 1983.
doi:10.1080/01430750.1983.9675885.
Hans Olsson, Martin Otter, Sven Erik Mattsson, and Hilding
Elmqvist. Balanced Models in Modelica 3.0 for Increased
Model Quality. In Proc. 6th International Modelica Conference, pages 2133, Bielefeld, Germany, 2008.
Linda R. Petzold. A description of DASSL: a Diferential/Algebraic System Solver. Scientific Computing, pages 6568,
1983.
Robert Pitz-Paal, Nicolas Bayer Botero, and Aldo Steinfeld. Heliostat field layout optimization for high-temperature solar
thermochemical processing. Solar Energy, 85(2):334343,
2011. doi:10.1016/j.solener.2010.11.018.
R. Ramachandran and R. K. Menon. An overview of industrial
uses of hydrogen. International Journal of Hydrogen Energy,
23(7):593598, 1998. doi:10.1016/S0360-3199(97)00112-2.
Martin Roeb, Martina Neises, Nathalie Monnerie, Friedemann Call, Heike Simon, Christian Sattler, Martin
Schmcker, and Robert Pitz-Paal. Materials-Related Aspects of Thermochemical Water and Carbon Dioxide Splitting: A Review. Materials, 5(12):20152054, oct 2012.
doi:10.3390/ma5112015.
Jonathan R. Scheffe and Aldo Steinfeld. Thermodynamic Analysis of Cerium-Based Oxides for Solar Thermochemical Fuel
Production. Energy & Fuels, 26(3):19281936, mar 2012.
doi:10.1021/ef201875v.
Z. S. Spakovszky. Unified Engineering: Thermodynamics and
Propulsion, 2008. URL web.mit.edu/16.unified.
S. Wilcox and W. Marion. Users manual for TMY3 data
sets. Technical Report NREL/TP-581-43156, The National
Renewable Energy Laboratory (NREL), Golden CO, USA,
2008.

Nathan S Lewis and Daniel G Nocera. Powering the planet:
Chemical challenges in solar energy utilization. PNAS, 104
(42):1572915735, 2007.

866

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132857

Applying the Power Plant Library ClaRa for Control Optimisation
Friedrich Gottelt1
1 XRG

Timm Hoppe1

Lasse Nielsen2

Simulation GmbH, Germany, {gottelt, hoppe}@xrg-simulation.de
2 TLK Thermo GmbH, Germany, l.nielsen@tlk-thermo.com

Abstract

initialisation concept, have been added and the library is
going to be enhanced to handle extra-low-loads, start-up
This paper presents the current state of the open-source and shut-down processes. To illustrate the potential of the
Modelica library ClaRa which enables the user to solve library, the challenging task of a soot blowing simulation
complex power plant simulation tasks. The library can is presented as use case in this paper.
be used to help control experts to develop and test controllers without disturbing the daily operation of the ap- 2 Overview of the Library ClaRa
plying power plant. This reduces project risks and costs
significantly. As a use case the analysis and optimisation 2.1 Scope of Library
of a Benson boiler power control is presented. The presented solution reduces the impact of soot blowing on the The library ClaRa was created to enable simulation of
large steam power plants with coal dust firing. At the
power output by 57 %.
Keywords: Power plant, Clausius-Rankine cycle, open- heating side the library comprises models for the complete
source library, control optimisation, soot blowing, simu- fuel handling process from the grinding via the fuel combustion to the flue gas cleaning. At the water steam side
lation
the library features models for the cooling of the combustion chamber to the electrification of the steam in the turbo
1 Introduction
generator.
The global energy markets are in a phase of significant
The library is intended to be the centre of a whole famchanges due to increasing power production from renew- ily of Modelica libraries in the field of electricity proable sources like solar and wind power, see (International duction and consumption. Any extension of ClaRa will
Energy Agency, 2015). These renewables are usually fluc- be handled in a separate, so-called ClaRa_AddOn. This
tuating energy inputs as they depend on local weather. In avoids the constant growing of the library, limits its scope
order to ensure a stable grid operation conventional power and reduces the effort of library maintenance since not all
suppliers have to outbalance these fluctuations. This intro- add-ons must be fully compatible to each other. Espeduces new modes of operation to new and existing power cially the last mentioned aspect eases the library develplants. The questions and challenges that arise from these opment by external developers. Two ClaRa_AddOns are
new operation modes can be solved at low costs with the currently under development in close collaboration with
help of system simulation. Therefore, it is very likely that the ClaRa developers: ClaRa_Control supplies blocks for
activities in this field will grow in both, university-based an efficient implementation of state of the art power plant
and industry research and development.
process control including the start-up and shut-down proThe most recent Modelica library in this field is the li- cessing. Transient widens the scope of ClaRa by the enbrary ClaRa which was developed from 2011 in a Ger- ergy distribution and allows for the simulation of strongly
man collaboration1 of Hamburg University of Technology, coupled electric grids, gas grids and district heating grids
TLK-Thermo GmbH and XRG Simulation GmbH. Its first as well as its economic evaluation (Andresen et al., 2015).
official release of version 1.0.0 dates from March 2015
Consequently, also the ClaRa library makes use of two
(see (Brunnemann et al., 2012; Gottelt et al., 2012) for an external libraries, namely the open source library Fluidintroduction to ClaRa and a control-related application). Dissipation (Vahlenkamp and Wischhusen, 2008, 2009)
The aim of this development was to provide a library that providing functional descriptions of pressure losses and
is both, suitable for beginning and advanced researchers in heat transfer and the free-of-charge version of the TILMethe field of simulation with Modelica. This leads to spe- dia (Schulze, 2014) providing media data for water, CO
2
cial requirements with respect to usability and flexibility and gaseous flue gas and air mixtures.
which are described in section 2. Currently the library is
under ongoing development within the follow up project 2.2 Structure of Library
Dynstart2 . New features, for example a parameter based
The structure of the library follows a functional approach
1 Funded by the German Ministry for Economic Affairs and Energy
rather than structuring according to the used media. For
under reference number FKZ 03ET2009
2 Funded by the German Ministry for Economic Affairs and Energy

DOI
10.3384/ecp17132867

under reference number FKZ 03ET7060E

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

867

Applying the Power Plant Library ClaRa for Control Optimisation

example, a steam-heated shell-and-tube heat exchanger
for the preheating of feedwater will be found in the same
package HeatExchanger as a flue gas to fresh air heat
exchanger.
Table 1 gives an overview of the top level package
structure. Herein, the UsersGuide provides a brief introduction to the library as well as developers contact
data and information on the license model and the revisions. The package Examples provides a number of introductory examples making new users familiar with the
capabilities of the library. The package Basics contains basic models and other internally used codes like
functions, records and interfaces. Most users will not get
in touch often with this package. In contrast, the package Components contains all the component models required to build up a power plant model.
Table 1. ClaRa library structure

UsersGuide

Information on basic modeliing concepts, contact and license

Examples

Introducing examples

Basics

Basic models and informatics

Components

Models for turbo machines
and
electrical
machines,
connection pipings,
heat
exchanger, mass storage and
steam separation, valves, coal
grinding, furnace, flue gas
cleaning, and sensors, i.e. "the
core of the library"

SubSystems

Conceptual package aiming at
supporting team work

Visualisation

Auxiliaries for the visualisation of results

StaticCycles

Static models for the calculation of consistent initial guess
values

The package SubSystems contains some examples for the definition of subsystems. This package
is still somewhat conceptual since it does not feature
a complete set of reasonable sub systems but rather
aims at introducing ideas for an efficient team work.
The package Visualisation provides means to visualise the results using both, Modelica-based annotations and third party post processing tools. The section
2.5 gives a brief overview of the options. Finally, the
package StaticCycles contains simplified, static and
parameter-based models of most of the power plant components. Details on this package and the idea for its application within ClaRas dynamic modelling approach are
discussed in section 2.6
868

2.3

Overview of Component Modelling

One aspect of the ClaRa modelling concept is to provide
as much physics as applicable to achieve a close to reality
model behaviour of single components as well as whole
power plant models. Different modelling approaches are
used throughout the library, for example a finite volume
approach for pipes, flow models for valves, zonal models for reservoirs and characteristic maps for compressors
and pumps while almost all components are using balance
equations.
The different models are reasonably modular in structure avoiding doubled code and providing high code transparency. Another aspect in model structuring is to gain
flexibility in the model application. The structuring is
done according to the following concepts:
Models at different levels of detail are provided as
separate classes, they can be exchanged in many cases
(e.g. via Dymolas context menu "change class...") since
they have equal interfaces. However, its internal structure
is significantly different providing a differently detailed
view into the component.
For instance, a pipe can be modelled applying an integrated, slim set of balance equations (as described in (Velut and Tummescheit, 2011)) or its balance equations can
be discretised applying a finite volume approach. The first
mentioned approach will be very efficient for the simulation of water hammer effects but loosing information
about the internal, local fluid temperature and pressure
distribution. The latter mentioned approach is very robust for reverse flow and off-design conditions and gives
detailed information about local and temporal effects like
steaming but will be less efficient for very long pipes.
Physical effects at different levels of insight are
provided to allow to apply a single class to be instantiated
in different contexts. For instance, the pressure loss of a
valve might be calculated either considering supercritical
or subcritical flow conditions. In other cases, if the valves
specific behaviour is not of particular interest it might be
sufficient to simply consider a linear hydraulic correlation.
All this is handled in different replaceable models.
Basic models are reused by instantiation to form
new component models. For instance, a shell-and-tube
heat exchanger model is a compound of the shells volume, the tubes volumes and the separating wall. ClaRa
provides basic models for these sub-compounds which
makes the models very easy to understand and to maintain
and allows users to easily create new component models.
The component list is complete for most tasks around
evaluation of the normal power plant operation of both
once-through boilers and circulation boilers. Heating can
be realised either by coal dust firing or heat recovery (other
heat sources like solar energy or biomass firing will be
subject to ClaRa_AddOns). However, future releases will
increase this content further, e.g. there will be a cooling
tower enabling studies on the performance of the cold side

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132867

Session 11B: Power Plants & Energy Systems

of the process.

2.4

Media Supported

ClaRa is shipped with a non-profit version of the TILMedia featuring four different media types3 . For pure
mediums like water/steam there are table based and spline
interpolated data available which are very encouraging
concerning simulation speed and simulation stability, see
(Schulze, 2013). The flue gas is described by a gas-vapour
mixture with eight substances similar to humid air. A mixture of real fluids for application in CO2 separation processes is supported as well as pure CO2 for ORC applications.
The calculation of substance properties within TILMedia is applied by external C code for faster simulation
speed and reusability. The robust media formulation has
also a positive effect on the initialisation of ClaRa models because media evaluation outside of the range of validity is handled by extrapolation or limitation to numerical range of validity to prevent division by zero or infinity. Significant less crashes were experienced compared to
work with other media libraries.

2.5

Visualisation and Usability

The usability is a key point to ease new users the introduction to the library. Therefore, ClaRa component models
feature well-structured parameter dialogues that make extensive use of Modelicas dialogue structuring annotations
like "tab" and "group". This helps the user to distinguish
between expert settings and fundamental, geometric settings of a component. Where applicable, descriptive figures help to understand the technical context.
Modelica libraries often provide only brief documentation thus implying that the source code is self-declarative.
Although this might be true for certain libraries available
it is often an obstacle for those who are less familiar either with commonly used modelling techniques or the programming language used. ClaRa provides a comprehensive documentation for these users aiming at deepening
the understanding of the work and improving the confidence in the library by granting a maximum of transparency. The documentation gives detailed insight into
the underlying theory and explains expert user settings and
spent validation efforts.
In order to help users to keep track of very complex
power plant process designs a number of visualisers can
be included into the models, see Figure 1. These items
help to better understand the current state of the process
by visualising important process variables (pressure, temperature, spec. enthalpy and mass flow and levels) and
highlighting critical values like negative or zero flows.

2.6

Global Initialisation

The initialisation of a large differential-algebraic system
of equations is a challenge that has been discussed in
3 There are more media available at costs for a commercial TILMedia
license

DOI
10.3384/ecp17132867

Figure 1. Screenshot of ClaRa visualisation

the Modelica community from the very beginning, e.g.
(Mattsson et al., 2002; Bachmann et al., 2006; Najafi,
2008). Since initialisation can often be a time-consuming
and frustrating task, especially for beginners, a librarys
quality can also be measured in its features that support
the user in getting robustly and reproducibly initialising
models. For ClaRas implementation five aspects are considered to ease the initialisation process: First, a new user
will expect to get some kind of guidance in the task of
initialisation, i.e. it should be clear for which variables
the user should provide estimation values and for which
not. Second, the library should support the homotopy
concept that was proved to be advantageous according to
(Casella et al., 2011). Third, the available initialisation
options shall provide a flexibility to initialise models in
arbitrary combinations. Fourth, the initialisation should
be reliable, i.e. it should not be sensitive to smaller model
changes. This point also refers to the accuracy that estimated values must have. Finally, taking the system topology into account is a valuable feature that would significantly improve the initialisation process. The last point is
not straightforward since it counteracts the modular modelling principles Modelica is based on.
If we take a look on a dynamic, 0D T-join for example. The volume normally is initialised by applying estimation values for the state variables, i.e. pressure and
specific enthalpy provided by the user as parameters. In
principle, these parameters are defined locally and they
are completely independent from its neighbouring components. However, from a technical point of view it is clear
that it would be useful to take the neighbours into account
since the mixers specific enthalpy will be the weighted
mixing enthalpy of the two inlet enthalpy flows coming
from the upstream components.
The ClaRa approach to take this kind of informa-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

869

Applying the Power Plant Library ClaRa for Control Optimisation

tion about the system topology into account is the
StaticCycle package. This package contains a set of
stationary models which can be used to create a simplih
fied, static and parameter-based mimic of the dynamic cym
cle. The result is a consistent, load depending set of parameters for mass flow, pressure and specific enthalpy or
temperature for the complete cycle. Linking the results of
this static cycle to the respective initial guess values in the
dynamic cycle allows to give flexible and consistent initial values at all dynamic components considering system
topology and the possibility to use a cascaded initialisation with values of upstream neighbouring components.
This feature allows for a very robust initialisation with automated adaptation on varying design points.
Figure 2.
Overview of the StaticCycle package features:

6
1{

m h
- 

m
h p

p

6
?p

p 6 h
m
?
m p
2{


h

StaticCycle component example cut-out. Blue
arrows indicate mass flow direction, black arrows indicate signal
flow directions

 parameter based
 signal connectors
 different input/output combinations for different assembly yield four differently coloured connectors.
Equally coloured connects match

model tube
blueConnector_inlet inlet(p=p_in); //
send pressure to upstream component
blueConnector_outlet outlet(m_flow=
m_flow, h=h_in); // send mass flow
and enthalpy to downstream component
parameter Real Delta_p_nom; // nominal
pressure loss

 connectors are error proof with respect to wrong connections (e.g. outlet-outlet connection, blue-red connection)

final parameter Real m_flow(fixed=false);
final parameter Real h_in(fixed=false);
final parameter Real p_in = p_out+
Delta_p_fric;
final parameter Real Delta_p_fric =
m_flow / m_flow_nom * Delta_p_nom; //
pressure loss calculation

 functionality for load dependent initialisation (table
based)
Figure 2 shows an exemplary cut-out of a
StaticCycle circuit with visualised signal flow
directions and corresponding parameters. Blue arrows
indicate the local flow direction. In this example the
heat exchanger calculates for the outlet at position 1 the
enthalpy according to the energy balance, passes through
the mass flow from the inlet and receives a pressure value
at the blue outlet connector. In contrast, at the red steam
inlet connector (position 2) mass flow and pressure are
defined via user input and passed over to the upstream
valve. The red inlet connector receives a value for the
enthalpy. In the red-connected steam valve a nominal
pressure drop is assigned so that the component passes
pressure and mass flow to the red outlet connector of
the T-split which itself provides a value for the enthalpy.
The green outlet connector of the T-split provides values
for mass flow, enthalpy and pressure for the top valve
component which serves as a pressure break because this
components also receives a pressure signal at its blue inlet
connector while sending parameters for mass flow and
enthalpy for the downstream component.
In the following an example of a simple tube is used
to illustrate the StaticCycles work with fixed=false
parameters to determine parameters that are passed over
from neighbouring components.
870

initial equation
outlet.p=p_out; // get pressure from
downstream neighbour
inlet.m_flow=m_flow;
inlet.h=h_in; //get the enthalpy and
mass flow from the upstream
neighbour
end tube;

As can be seen, parameters calculated or set by the component are set via the connectors modifier, e.g. inlet.p. In
contrast, parameters that are set by neighbouring components are made available by parameters that apply the fixed
= false feature. The corresponding internal values are set
in an initial equation environment, ensuring that the results
can be used as initial values for the dynamical simulation
of the main model.

3
3.1

Use Case for Control Analysis and
Improvement
Scope of Work

The idea of this generic use case is to illustrate ClaRas
capabilities to model power plants at the state of the art
including the full complexity of common condensation
power plants due to extensive feedwater preheating and

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132867

Raw
Coal

8

SH1
Cold
Water

SH3

RH1

SH2
Fresh Air

RH2

Flue Gas

Eco

1

2

7

3

HP
Turbine

4

6

IP
Turbine

4

LP
Turbine

5

Session 11B: Power Plants & Energy Systems

Figure 3. P&ID of simulation model

DOI
10.3384/ecp17132867

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

871

Applying the Power Plant Library ClaRa for Control Optimisation

exhaust gas cleaning and cooling technologies. The use
case also aims at proving Modelicas power to analyse
complex processes at a physical level and its interaction
with control structures. System simulation tools are used
to analyse and improve a power plants unit control to better handle disturbances due to soot blowing.

3.2

Model Description

The dynamic power plant model analysed in this paper is
a generic once-through steam generator and has a nominal
electrical power output of 600 MW, see Figure 3. The design life steam pressure is about 270 bar at a temperature
of 600 C. The combustion chamber has an overall height
of approx. 80 m and is heated with three coal dust-fired
burners (1) at three different burner levels. The chambers
walls are cooled with evaporating water which is superheated in three convective heating surfaces (SH1-SH3) to
the live steam conditions. The layout comprises one reheating (RH1-RH2) to 520 C at 52 bar after the high
pressure turbine stage. The model discretises the boiler
in height by using an arrangement of 14 different components including the hopper, the burners, the radiation
zone (2), the convective heat exchangers and the spray injectors (3) for steam temperature control. Each of these
models is parametrised with detailed geometry information and connected to neighbouring components according
to the piping and instrument diagram. The heat exchange
between combustion chamber and walls is implemented
with detailed correlations for radiative and/or convective
heat transfer. The flue gas is post processed with respect
to NOx , SOx and ash and is used to preheat the fresh air
carrying the coal dust from the mills. In order to reproduce the impact of soot blowing to the process at several
positions steam and cool water can be introduced to the
combustion chamber.
The steam is expanded in nine turbine stages with
bleeds for several preheaters (4). The models for condenser (5) and feed water tank (6) are taking non-ideal
phase separation into account and the resulting water levels are controlled by valves and pumps applying PI controllers.
The controlling system is build up applying the upcoming ClaRa_AddOn ClaRa_Control and based on a German guideline for unit control of conventional and nuclear
steam power plants, (VDI/VDE, 2003). This guideline,
defining a baseline for the power plant control, is the starting point for numerous implementation in German power
plants.
The purpose of the model discussed in this paper is to
analyse soot blowing of the evaporator furnace and its impact on the controlling system. The soot blowers (7,8) are
modelled as a dynamical gas volume with an additional
connector for water/steam inlet. The inflowing water is
mixed ideally with the gas mass flow and the enthalpy of
evaporation is considered by the dynamical energy balance. An effect of the soot blowing on the fouling coefficient, which is a parameter that reduces the heat transfer
872

to the heating surfaces, is not considered. An approach to
model variable fouling factors which are affected by soot
blowing is presented in (Gierow et al., 2015). This simplification is acceptable since the focus of the investigation
is on the short-term energy and mass transfer of steam and
water from the water steam cycle to the furnace and its impact on the control performance of the power plant. The
medium-term improvement of the local efficiency of the
heat transfer is of minor interest here.
The resulting power plant model consists of 9212 components with 28264 equations and 1606 differentiated
variables.

3.3

Scenario Description

Figure 4. Soot blower injection mass flows

The underlying scenario to analyse the improved control strategy comprises two soot blowing events occurring
during normal power plant operation. Heating surfaces in
coal fired power plants tend to foul due to the high ash
and slag content of the combustion air. Particles stick to
the heating surfaces and cause a rising heat transmission
resistance over operation time. Thus, the heat transfer to
the water steam cycle is reduced. Soot blowing is a measure to clean the tube bundles and evaporator walls during operation by spraying steam or water through special
lances onto the heating surfaces. This measure uses the
combined effect of a thermal shock and the kinetic energy
of the water/steam jet to reduce fouling and improve the
heat transfer.
In general, two different soot blower types can be distinguished: The soot blowers for the tube bundles are fed
with steam which is extracted ahead the intermediate pressure turbine. This rededication of steam has a direct impact on the electric power production and its control. In
contrast, the soot blowers for the evaporator walls are fed
with external water at 20 C which has a more indirect effect on the power production as the water injection cools
down the furnace and thus reduces the steam production.
In figure 4 the soot blower injection mass flows are

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132867

Session 11B: Power Plants & Energy Systems

shown. The convective blowers are active two times over
a timespan of 15 min with a mass flow of 20 kgs and 10 kgs ,
respectively while the wall blowers are active for time
spans of 5 min with a mass flow of 17 kgs .

3.4

Analysis and Improvement of the Control
Strategy

The plant is run in "steam generator control" mode and
natural sliding pressure which means that the power output controller acts on the fuel mass flow and the turbine
valve is fully opened. Therefore, deviations in fuel mass
flow or disturbances on the steam generation have direct
impact on pressure and generator output. Compensation
of the generator power output by the fuel mass flow only
takes effect with a delay.
A basic model based unit control strategy according to
the German guideline for power plant unit control VDI
3508 (VDI/VDE, 2003) is implemented. The control is
sketched in Figure 5, the basic control in black, the additions of the improved control in green. In the figure three
sub-figures may be distinguished, starting from top to bottom we find the unit feed forward control and the process
predictor in sub-figure a), the feedback controllers in subfigure b) and the process itself in sub-figure c). Furthermore, three different line types are used: solid lines for
internal control signals, dashed lines for measurement signals and dot-dashed lines for process input signals. For the
sake of simplicity only the turbo generator power output
control and the soot blowing control are sketched in the
figure.
In the following the basic control set up is explained
in detail. The turbine valve is fully opened by setting the
turbine valve opening set value yT,set to 100 %. In subfigure a) the target power output is fed into the output limiter
which applies a limiting according to static and dynamic
limits. From that value the fuel feedforward block generates a load dependent value of the firing power QF,FF .
The firing power is input to the simplified process model,
referred to as the predictor in the further course, and to the
process itself via a recalculation of the firing power into
a corresponding fuel mass flow mF . The predictor calculates a corresponding expectation value of the generator
power PG . In detail the predictor works as follows. From
 a transfer function calculates
the fuel forward signal QF,FF
the expected steam generation of the boiler m St,G . The expected steam mass flow to the turbine m T is subtracted
from that value and the result serves as input to an integrator block from which the expected live steam pressure
pLS is obtained. By multiplication with the set value of
the turbine valve opening yT,set the steam mass flow to the
turbine is calculated. The turbine is modelled with a first
order transfer function block, thus receiving the expected
power output PG .
However, the real process will be disturbed e.g. by fouling of heating surfaces which leads to a deviation between
the ideal and the real process. In subfigure b) it can be
seen that this deviation in power generation is calculated
DOI
10.3384/ecp17132867

from the difference of the expected value PG and the measured value PG . The difference is input to the feedback
controller of the power output which is a conventional PIcontroller. It corrects the feed forward value QF,FF by the
value deviation QF .
Furthermore, in subfigure b) the feedback controller of
the convective tube bundles soot blowing mass flow can be
found. From the required soot blowing mass flow mSB,set
the measured soot blowing mass flow mSB is subtracted.
The difference is input to the soot blowing mass flow controller which is a conventional PI controller.
Applying the concept of a model based unit control the
process will be controlled in open loop as long as the process reacts as predicted. Thus, the control effort of the
feedback control is significantly reduced compared to a
conventional control system in which load changes are
acting on the set value of a feedback controller. However,
a disturbance like soot blowing has to be outbalanced by
the power feedback controller. In case of the tube bundle
soot blowing, intermediate pressure steam is consumed.
Thus, the steam mass flow to the turbine is reduced and the
generated electric power drops. The power feedback controller raises the fuel mass flow to compensate the power
generation drop, but it takes effect with a delay. Poor control accuracy is the result.
To improve the behaviour of the model based unit control during soot blowing of the convective tube bundles
some additions have been made, marked green in Figure
5. The set value of the required soot blowing mass flow
mSB,set is introduced as positive disturbance signal to the
predictors expected steam mass flow to turbine m T . To
overcome the delayed reaction of the boiler on changes of
the fuel mass flow, the disturbance signal to the predictor
is activated prior to the starting time of the soot blowing
process. This is done by delaying the soot blowing set
point signal to the soot blowing mass flow controller with
a delay block. The predictor reacts on the mass flow disturbance signal and raises the expected power output. In
consequence, the feedback control outbalances the disturbance and raises the control signal. Thus, the coal mass
flow rises and at the start time of the soot blowing additional steam is produced, which then can be consumed for
the soot blowing. A drop of the produced power can be
compensated.
The presented modifications acting on the feedback
control are very efficient and easy to implement. A physical signal, the soot blowing steam mass flow, can be used
directly as a disturbance signal without complicated recalculation. It is also independent of the load point as the
signal is added to the boiler predictor of the unit control.
The predictors output is a load dependent rise of the generator power. The approach to derive an improvement of
an existing control system from a profound analysis of the
system of question rather than applying purely controltheoretical approaches has the advantage that the ideas
can be easily understood and discussed with the power
plants operating personnel. This eases the acceptance of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

873

Applying the Power Plant Library ClaRa for Control Optimisation

Target power output

b) Unit feedback control

a) Unit feed forward control

Target output limiting
1
Delay
Fuel feedforward

PREDICTOR STEAM CYCLE

Power output controller

Soot blowing
mass flow controller

Fuel mass
flow control
1

c) Process

G

Figure 5. Model-based unit control and convective sootblowing control

such optimisation projects. System simulation prior to the
In the following the simulation results are discussed.
commissioning can help to reduce technical and economic Figure 6 shows the flue gas outlet temperatures of the first
superheater bundle during the soot blowing events for both
risks.
control strategies. As can be seen, the impact of the soot
For the sake of completeness it shall be mentioned that
blowing on the flue gas temperatures is higher for the wall
an implementation of the disturbance signal in the feedforblowers compared to the convective blowers. The reason
ward control would require a load dependent recalculation
behind this is that the convective blowers are fed with hot
of the physical signal, the steam mass flow rate, to a corsteam taken from the hot reheating pipe and the wall blowresponding firing power signal.
ers are fed with cold water from an external reservoir. Due
Analogous additions also improve the control be- to the huge amounts of evaporating water the flue gas temhaviour during steam generator wall soot blowing. As cold perature is being reduced which results in less steam prowater is injected by the wall blowers the mass flow of cold duction. In comparison to the original control strategy,
injection water has to be expressed as a corresponding re- the improved one shows a significant reduction of flue gas
duction of the steam mass flow to turbine. This is done temperature oscillations during wall soot blowing.
by multiplication of the cold water mass flow with a load
Figure 7 shows the intermediate pressure turbine mass
independent factor. The result is input as a disturbance
signal to the predictor in the previously described manner. flow during the soot blowing process with and without the
874

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132867

Session 11B: Power Plants & Energy Systems

Figure 6. Impact of soot blowing on flue gas temperatures

improvement of the controller system. The steam for soot
blowing of convective heating surfaces is taken directly
from before the intermediate pressure turbine. The control
improvement raises the steam generation such that we see
less reduction of steam mass flow through the turbine. The
soot blowing induced mass flow oscillations are of lower
amplitude and the system reaches a steady state faster with
the modified control strategy especially during the soot
blowing of the furnace walls with cold water, because a
swing up of the turbine mass flow is prevented.

Figure 7. Impact of improved control on IP turbine flow during
soot blowing

In Figure 8 the generator output for both control strategies are shown. The improvement in quality of control by
the additional disturbance value is visible here too and results in lower amplitudes and a faster reaching of a stable
state. The greater impact of the wall soot blowing with
cold water in comparison to the convective soot blowing
with hot steam manifests in higher amplitudes.
In the following, simulation results of the wall soot
blowing process with cold water are discussed in detail,
DOI
10.3384/ecp17132867

Figure 8. Impact of improved control on generator output during soot blowing. The results corresponds to a reduction of primary control from 10.7 MWh to 4.6 MWh.

which is significantly improved by the alternative control
strategy. Figure 9 shows the fuel mass flows of mills and
burners, soot blowing mass flow and first superheater flue
gas outlet temperature during the period of wall soot blowing without control improvement. When the soot blowing
process is started, the flue gas temperature inside the furnace reacts with an initial drop due to the fed in cold soot
blowing water and its evaporation, which can also be seen
in the superheater outlet temperature. This results in a reduced mass flow inside the turbine forcing the power controller to increase the fuel mass flow at mill inlet. The
mass flow at burner inlet reacts time shifted due to mass
storage effects in the mill. When the increased but delayed fuel mass flow is burned, the flue gas temperature is
rising again until the first soot blowing process is immediately stopped, which causes a temperature step up above
the initial temperature. The power controller then reduces
the coal mass flows until the second soot blowing, causing
a comparable temperature characteristic which transitions
into a swinging state when the soot blowing process has
ended.
Figure 10 shows the same variables during the same
time span for the soot blowing process with the improved
control strategy. In comparison to Figure 9 it can be seen
that the power controller raises the fuel mass flow already
before the soot blowing process is started. This is caused
by the disturbance signal of the pressure steam mass flow
being activated 50 s prior to the soot blowing process. By
the time the soot blowing process starts, the increased fuel
mass flow already enters the burner levels resulting in a
shorter and not so big initial flue gas temperature drop.
In addition, the flue gas temperature only swings with a
lower amplitude compared to the case without improvement and reaches a stable state in a significantly shorter
time span which results in a higher quality of control. Because of the higher flue gas mass flows and a change of the
heat transfer coefficients due to the fed in water, the super-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

875

Applying the Power Plant Library ClaRa for Control Optimisation

Figure 9. Fuel mass flows of mills and burners, soot blowing
mass flow and superheater outlet temperature during wall soot
blowing without control improvement

Figure 11. Impact of control optimisation on generator output
during soot blowing at different loads

heater outlet temperature tunes in to a lower temperature in power output, occurring for example during soot blowing processes which are a common routine, because unduring soot blowing.
derfulfillment would be charged with penalties and overfulfillment will not be compensated. This makes a higher
quality of control beneficial. When the operators offers
positive control power during full load operation, the plant
only could be run with a certain margin to its maximum
load under consideration of load fluctuations. If the deviations in power output during soot blowing cause the
highest amplitudes in the current power plant operation
schedule it can be seen, that an improved control strategy,
like the one proposed in this paper, enables the operator
to run the plant at a higher load and making more profit
while maintaining the needed margin to maximum load
for secondary control power.

4
Figure 10. Fuel mass flows of mills and burners, soot blowing
mass flow and superheater outlet temperature during wall soot
blowing with control improvement

Figure 11 shows the impact of the alternative controller
system on generator output at different power plant loads.
In order to ensure, that the enhancement of control quality
can be achieved at varying loads and not only the one discussed previously, additional simulations have been carried out for 100% and 65% load. As can be seen, the same
improvements are obtained at all load points shown in the
diagram where the best results are obtained for nominal
load. The ClaRa library is an appropriate tool to carry out
such additional comparisons very comfortably.
Power plants which participate at the secondary control power market, must guarantee the offered power at
any time during operation. While control power is being
called, the plant operators would like to avoid fluctuations
876

Conclusion

The current state of the library ClaRa for the simulation
of power plants has been presented to be one of the most
complete and complex open source library for the simulation of Clausius Rankine cycles. Due to its deep insight at
equally high transparency it addresses both new and experienced users. The library is open to be extended in
the future, by both new component and physics models
within the ClaRa (which is work in progress by the authors) as well as in terms of new libraries, the so-called
ClaRa_AddOns. The latter mentioned path allows the
scope to be widened to new fields like biomass or solar
heated applications.
As a use case the optimisation of a power plant unit control has been outlined. The results prove the outstanding
opportunities that are introduced by system simulation allowing to understand complex processes better by evaluating unmeasurable process variables and to test innovative
control concepts without risks.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132867

Session 11B: Power Plants & Energy Systems

5

Outlook

T. Vahlenkamp and S. Wischhusen. FluidDissipation - A Centralised Library for Modelling of Heat Transfer and Pressure
Loss. In International Modelica Conference, Bielefeld, Germany, 2008.

The further development of the library will, amongst others, introduce so-called six-equation-models for extra precise calculation of two phase flow conditions in pipes.
Furthermore, all models are under permanent review with T. Vahlenkamp and S. Wischhusen. FluidDissipation for Applications - A Library for Modelling of Heat Transfer and Presrespect to zero flow and other non-design conditions. The
sure Loss in Energy Systems. In Proceedings 7th Modelica
library is planned to be extended by special header comConference, Como, Italy, September 2009.
ponents enabling stress evaluation.

References
L. Andresen, P. Dubucq, R. Peniche, G. Ackermann, A. Kather,
and G. Schmitz. Status of the transient library: Transient
simulation of coupled energy networks with high share of
renewable energy. In Proceedings of the 11th International
Modelica Conference, Versailles, France, 2015.
B. Bachmann, P. Aronsson, and P. Fritzson. Robust initialization
of differential algebraic equations. In Proceedings of the 4th
International Modelica Conference, Vienna,Austria, 2006.

VDI/VDE. VDI/VDE Guideline 3508: Unit control of thermal
power stations. Association of German Engineers (VDI) /
German Association of Electrical Engineering and Information Technology (VDE), 2003.
S. Velut and H. Tummescheit.
Implementation of a
Transmission Line Model for Fast Simulation of Fuid
Flow Dynamics.
In Christoph Clau, editor, Proceedings of the 8th International Modelica Conference;
March 20th-22nd; Technical Univeristy; Dresden; Germany, Linkping Electronic Conference Proceedings, 2011.
doi:http://dx.doi.org/10.3384/ecp11063446.

J. Brunnemann, F. Gottelt, K. Wellner A. Renz, A. Thring,
V. Roeder, C. Hasenbein, C. Schulze, G. Schmitz, and J. Eiden. Status of ClaRaCCS: Modelling and Simulation of CoalFired Power Plants with CO2 Capture. Proceedings of the
9th International Modelica Conference, Munich, Germany,
pages 609  618, 2012.
F. Casella, M. Sielemann, and L. Savoldelli. Steady-state initialization of object-oriented thermo-fluid models by homotopy
methods. In Proceedings of the Modelica Conference 2011,
Dresden, Germany, 2011.
C. Gierow, M. Hbel, J. Nocke, and E. Hassel. Mathematical
model of soot blowing influences in dynamic power plant
modelling. In Proceedings of the 11th Modelica Conference,
2015.
F. Gottelt, K. Wellner, V. Roeder, J. Brunnemann, G. Schmitz,
and A. Kather. A Unifieded Control Scheme for Coal-Fired
Power Plants with Integrated Post Combustion CO2 Capture.
In Proceedings of the In 8th IFAC Conference on Power Plant
& Power System Control, Toulouse, France, 2012.
International Energy Agency. Tracking Clean Energy Progress
2015. Technical report, 2015.
S.E. Mattsson, H Elmqvist, M. Otter, and H. Olsson. Initialization of Hybrid Differential-Algebraic Quations in Modelica
2.0. In Proceeding of the 2nd International Modelica Conference, Oberpfaffenhofen, Germany, 2002.
M. Najafi. Selection of variables in initialization of modelica
models. In Proceedings of the 2nd International Workshop on
Equation-Based Object-Oriented Languages and Tools, Paphos, Cyprus, 2008.
C. Schulze. Table based calculation of thermophysical properties for simulation of thermodynamic systems. In Proceedings of the ITI Symposium, 2013.
C. Schulze. A Contribution to Numerically Efficient Modelling
of Thermodynamic Systems. PhD thesis, Technische Universitt Brauschweig, 2014.

DOI
10.3384/ecp17132867

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

877

878

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Interactive FMU-based Visualization for an Early Design
Experience
Volker Waurich1
1 Chair

Jrgen Weber2

of Construction Machines, TU Dresden, Germany, volker.waurich@tu-dresden.de
of Fluid-Mechatronic Systems, TU Dresden, Germany, weber@ifd.tu-dresden.de

2 Chair

Abstract
User experience is an eminent part of holistic product design. Especially in the field of mobile machinery, the
drivers impression of the machine handling is crucial for
successful design. To get an early understanding of the
ergonomic aspects of a new concept of operation, functional prototypes can be applied. This paper presents the
tools to develop a functional prototype using free software
and low-cost hardware. This includes prototyping of control devices, interfaces to the Modelica-based simulation
models and a generic visualization using a game engine.
In order to speed up the process of functional prototyping,
an approach to automatically visualizing FMUs based on
a scene description file is presented. The application of interactive simulation was used to support the development
of a novel control device for excavators in a student project
at TU Dresden.
Keywords: visualization, OpenModelica, engineering education, construction machines, rapid prototyping

1

Introduction

The operation of mobile machinery, e.g. excavators,
puts ambitious requirements on the driver. Therefore,
the ergonomic aspects of the control environment are
an important selling point. The innovation of new
operating concepts should be supported by an early
design experience. In a student project at Technische
Universitt Dresden, a collaboration of students from the
fields of Technical Design, Mechanical Engineering and
Media Computer Science developed an innovative control
concept for mobile excavators. The project was initiated
by an OEM of mobile machinery. Although the actual
project results are confidential, the applied methods and
tools shall be presented and serve as a motivation for
similar projects.

Another innovation is the availability of easy-to-use,
low-cost microcontrollers. Using different sensors, e.g.
potentiometers, motion concepts of the prototypes can
be tested. Utilizing functional prototypes during an early
design phase, facilitates more profound impressions of
the product than using CAD-models or plastic prototypes. Machine tools and electronics are available in
Makerspaces and easy to apply for students. With an
easy-to-use connection to virtual environments based on
simulation models, the design process can be enhanced
further. With the help of the OpenModelica tool chain, an
FMU-visualization has been developed which allows an
automated generation of appealing 3d environments.
This paper covers the different aspects of developing
functional prototypes with a high level of automation
and tool support. For the presented use-case of the
machine control development, only freely available
software (i.e. open-source Modelica-tool OpenModelica
and the free gaming engine unity), low-price hardware
and cheap prototyping technologies that are becoming
widely accessible, are applied. This paper is meant to be a
motivation for combining physical prototyping and virtual
mockups within the training of engineers. As experience
has shown, the development of functional prototypes
creates a high level of self-motivation and perfectionism
among participants.

In chapter 2, the applied methods of physical rapid prototyping are presented. Chapter 3 discusses the means
of developing interactive Modelica models. Afterwards,
the basic idea behind a generic FMU-visualization is presented and the tools for visualizing the simulation models
are introduced in chapter 4. The presented approach is
compared to existing visualization workflows. Chapter 5
describes the manufacturing of a control device. Finally,
chapter 6 concludes the paper and gives an outlook on fuTo support the design process, a prototypic control ture work.
device was engineered to get a haptic experience. With
the help of novel rapid prototyping technologies, as 2 Physical Prototype Manufacturing
3d-printing or lasercutting, complex designs can be
2.1 Makerspaces for Higher Education
realized quickly and cheaply. Since the required machines became affordable, public workspaces, so-called In recent years, affordable technologies for rapid protomakerspaces spread out more and more. Due to that, typing have spread widely. Various libraries and higher
even with a small budget, realistic prototyping is possible. educational institutions like Saxon State and University
DOI
10.3384/ecp17132879

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

879

Interactive FMU-Based Visualization for an Early Design Experience

Library Dresden (slu) offer public access to rapid prototyping machines in so called makerspaces. Makerspaces void loop() {
are collaborative work spaces which provide rapid proto- while(millis() - lastSignal > interval)
{
typing tools and the knowledge to utilize them. Typically,
lastSignal += interval;
projects in the field of model making and electronics
value = analogRead(1);
can be realized using the facilities of a makerspace. The
buf[0] = lowByte(value);
buf[1] = highByte(value);
interest in makerspaces emerges and despite the lack
Serial.write(buf,2);
of long-term investigation, the impact on engineering
education has been promising among many universities }}
(ISA, 2016). Ongoing studies will give an overview of
how the overall impact of academic makerspaces has
3 Modelling of Interactive Simulation
to be assessed. At least with regard of the presented
Environments
student project, a high level of motivation to realize the
projects and to acquire the necessary knowledge has been
3.1 Model Interaction
observed.
In order to develop a control device for an excavator,
3D printers and foam cutters have been used to produce
haptic prototypes. The production costs are very low and
therefore are best suited to use them in student projects.
Project participants from the field of technical design developed design drafts which have been modelled in CADsoftware. The printed 3D prototypes give a spatial impression and provide enough stability to integrate joints
and sensors.

2.2

Application
controllers

of

Sensors

and

Micro-

Besides machine tools, makerspaces offer a range of electronic components and easy-to-use microcontrollers such
as Arduino (Ard). With these low-cost controllers, sensor concepts can be set up easily and data can be processed and transferred to a computer. In the presented
project, buttons, rotary and translational potentiometers
have been set up to map the functionalities of a conventional excavator control. The sensors have been attached
in the joints of 3D-printed control devices in order to access the control device condition. The Arduino reads the
sensors and transfers the signals to a computer, either via
USB-connection or with an additional Bluetooth module.
The messages can be processed by SerialPortReceive of
the Modelica_DeviceDrivers library. When using the Arduino IDE, users write C-like code, compile and transfer
it directly to the board and are able to monitor serial connection communication. There is a vast amount of documentation and tutorials available that simplifies microcontroller programming for students outside this subjects
area. The following Arduino code can be applied to transfer signal data of the Arduinos analog pin 1 via USBconnection with a sample time of 0.1 s.

The use-case of models involving external inputs during runtime became much more accessible by Modelica_DeviceDrivers library (M_DD) (Bellmann, 2009).
The library interfaces various input devices and communication protocols. Hence, Modelica models can be enhanced with direct user-inputs or connected to other processes during runtime. A realtime synchronization is provided as well. For the presented demonstrator, the serial
port implementation was utilized in order to communicate
with an Arduino microcontroller. M_DD supports packing
and unpacking of byte-messages which allows to access
data e.g. sensor signals via a serial port connection. OpenModelica supports serial communication and packaging
both in simulation mode and in FMUs. Figure 1 displays
the graphical model view of an excavator model, that is
controlled via serial communication. The message protocol is modelled with unpackInt-models, that split incoming messages into a sequence of integer variables. These
integer variables are converted to real variables and conditioned to fit the excavator interface. The excavator model
has been taken from a Modelica-library by the Chair of
Construction Machines, TU Dresden.

byte buf[2];
unsigned long lastSignal = 0;
unsigned long interval = 100; //ms
int value = 0;
void setup() {
Serial.begin(9600);
}

880

Figure 1. Model of an excavator and a serial port interface using
Modelica_DeviceDrivers library

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132879

Session 11C: Mechanical Systems, Robotics & VR

The following listing shows the parametrization of a
model to read a two-byte message sent by an Arduino,
whereas the parameters baud, sampleTime userBufferSize
and Serial_Port have to be adapted to the sending controller. The width parameter of the UnpackUnsignedInteger model has to be set to 16 bit in order to deserialize the
two byte value, sent from the microcontroller.
model arduino
Modelica_DeviceDrivers.Blocks.Communication
.SerialPortReceive
arduinoRead(
baud=Modelica_DeviceDrivers.Utilities
.Types.SerialBaudRate.B9600,
parity=0,
enableExternalTrigger=false,
startTime=0.0,
autoBufferSize=false,
userBufferSize=2,
sampleTime=0.1,
Serial_Port="COM5");
Modelica_DeviceDrivers.Blocks.Packaging
.SerialPackager.UnpackUnsignedInteger
unpackInt(
bitOffset=0,
width=16,
nu=1);
equation
connect(arduinoRead.pkgOut,
unpackInt.pkgIn);
end arduino;

3.2

Realtime Capabilities

Realtime requirements restrict the model to simulating
within a specified interval of time. Hard realtime criteria
demand a deterministic execution time whereas soft
realtime allows the simulation to exceed the time limit
occasionally. In the presented use case, soft realtime
criteria are assessed. Nevertheless, for realtime application, it is favourable to reduce the simulation time.
Modelica compilers allow different kinds of performance
optimization for simulations. The time integration method
has a big influence on the execution time, depending on
the number of iterations and step sizes. In most realtime
applications, explicit, fixed step methods are preferable.
The lack of stability and the necessity of small step sizes
lead to the development of more sophisticated methods
e.g. inline integration (Elmqvist et al., 1995). Besides
that, the evaluation of parameters is an effective option to
increase simulation speed. There are various optimization
techniques to improve calculation of algebraic loops,
e.g. structural methods like tearing (Elmqvist and Otter,
1994) or reshuffling (Waurich et al., 2014). Calculations
of jacobi matrices can perform differently dependenig
on whether numerical, symbolical or colored jacobians
are used. Automatic parallelization is also a feature to
speed up simulation. Of course, the operating system,
the hardware and the C/C++ compiler influence the
simulation time as well.

DOI
10.3384/ecp17132879

The excavator model consists of a multi body system
and some simple hydraulic components (cylinders, valves,
flow sources). In most cases, the BLT-matrix of a mechanical model is dominated by a linear system of equations. Hence, parallelization of BLT-blocks will not improve the simulation speed. The present model benefits
mostly from the evaluation of parameters. The dominating system of equations with 437 equations including 9
tearing variables is reduced to a system with 379 equations including 7 tearing variables. The amount of single
equations reduces from 1208 to 1162. This results in a
simulation speed-up of 1.33. This is sufficient to run the
simulation without exceeding the realtime limits on a Windows 7 desktop computer with i7-3930K processor. The
FMU was compiled using OpenModelica and gcc 5.3.0 as
FMU 2.0 model exchange.

4
4.1

A Generic Visualization of FMUs
The Functional Mock-Up Unit

In order to exchange simulation models and to use them
across various software, the Functional Mock-Up Interface was developed (Blochwitz et al., 2012). The Modelica language and its tools are highly involved in the development and application of FMI. The FMI-standard features two variants, i.e. model-exchange without internal
time integration and co-simulation that includes a time integration solver. The black-box models that provide the
FMI-API are called Functional Mock-Up Units and contain the functional behaviour of a simulation model that
can be accessed via interface variables. The model variables are listed in the modelDescription.xml. The
connections and relations of these model variables are hidden from the user since FMUs are compiled as a shared
library. This is very useful since it protects intellectual
property but it is cumbersome if information of the model
structure is of interest. Hence, a generic visualization of
FMUs is not possible in general.

4.2

Existing Approaches to Visualize Multibody Models

Commercial Modelica-tools offer built-in visualization
features for multibody systems based on the Modelica.Mechanics.MultiBody.Visualization.Advanced
models. Visualization comprises both subsequent and
concurrent visualization of simulation. This visualization
is possible since the tools have full access to the model
information and the variables that are used to visualize
the shapes. Another approach would be to add dedicated
animation objects to the Modelica model and let them
communicate with an external visualization software, e.g.
in the commercial DLR Visualization library (Hellerer
et al., 2014). Also the Modelica3D implementation by
Hger relied on Client/Server communication (Hoeger
et al., 2012). Yamaura et al. (Yamaura et al., 2016) described a comprehensive framework of different tools that
exchange model variables via UDP communication with

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

881

Interactive FMU-Based Visualization for an Early Design Experience

a corresponding Unity model. This approach combines
the physical model capabilities of engineering tools like
Simulink and Dymola with the highly developed gaming
engine Unity which offers much more visualization
and graphical modeling features than any simulation
software. Another promising implementation for discrete
time simulations was presented by (Bijl and Boer, 2011)
, that is designed on a database which feeds the 3D
visualization. The use of appealing 3D visualization and
the potential of 3D game engines is described as well.
An entirely different concept was presented in (Elmqvist
et al., 2015) in which even the modeling is performed
in a 3D visualization environment that provides direct
feedback on the model structure of a multibody system.
This visualization uses the web interface of the simulation
tool Dymola.
Since there was no free Modelica tool that features
visualization in an integrated manner, the open-source
Modelica Compiler OpenModelica and its graphical editor OMEdit have been enhanced to visualize results of
simulations. Therefore, the OpenModelica Compiler has
to extract all necessary information about the visualization shapes from its internal model representation. Hence,
the animation of Modelica.Mechanics.MultiBody models
can be provided without adding dedicated visualization
objects to the model.
Instead of implementing a new OpenModelica-specific
API to transfer visualization variables between simulation
and animation-software, the authors decided to choose
an already existing API, i.e. the FMI. By means of a
visualization scene description file that is generated by
the OpenModelica Compiler, the visualization software in
OMEdit can access relevant variables and maps them to
the corresponding animation shape properties. In the following chapters, the details of FMU-based visualization
are presented.

4.3

The shape parameters are either defined by an <exp>
tag which refers to a constant expression of type real or
to a <cref> tag, which stands for a reference given
by a string-type. <cref> elements have to be updated
during runtime. Shapes can be either geometric primitives or CAD-files, like .stl or .dxf that are referenced
by their absolute path names in the scene description
file. Besides the shape models, there are more visualization models that could be defined, e.g. Surface
or PipeWithScalarField, but the current implementation covers shape only. A XML Schema Definition is available at https://github.com/vwaurich/
visxml

4.4

The Visualization Architecture

No matter which frontend is used to display the 3D scene,
the mechanism to animate the shapes is identical as depicted in Figure 2. The visualization backend needs an
FMU and a corresponding scene-description file, both
generated by the OpenModelica Compiler. It has to be
ensured, that all variables which are used to visualize the
scene, are accessible in the FMU. This means that these
variables must be retrievable via fmiGetReal API. Therefore, OpenModelica changes protected variables to public
if needed.

A Specification of Visualization

As described in the previous chapter, OpenModelica
1.11 is able to create a scene description XMLfile that contains the information about the Modelica.Mechanics.MultiBody.Visualizers.Advanced.Shape
objects within a model. The shape model contains the
basic visualization information like position, orientation,
scale and color. This approach was already mentioned in
(Waurich et al., 2016) and a proof of concept implementation was presented. The scene description XML-file
simply lists all instances of the Shape model and assigns
values to their parameters. The following exemplary
snippet of a scene description XML-file contains information about the model "shape1" which is of type
"cylinder". The position vector r is defined by constant
expressions and lies in the root "{0,0,0}" whereas the
length attribute depends on the component reference
"shape1.length".
<visualization>

882

<shape>
<ident>shape1</ident>
<type>cylinder</type>
<r><exp>0.0</exp>
<exp>0.0</exp>
<exp>0.0</exp>
</r>
<length>
<cref>shape1.length</cref>
</length>
</shape>
</visualization>

Figure 2. Overview of FMU-based visualization both with unity
and OMEdit frontend.

After the selection of an FMU, the visualization backend instantiates all shapes listed in the scene description
file. These can be either geometric primitives such as
cubes or spheres, or imported CAD-files. Constant shape
properties can be set directly during initialization of
shapes. In constrast, variable properties cannot be set
before the solution of the inital system of the FMU.
Unpacking, loading, instantiation, initialization and
simulation of the FMU is performed by the FMILibary

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132879

Session 11C: Mechanical Systems, Robotics & VR

(FMI). For the Model Exchange FMUs, a simple Explicit
Euler solver with a default step size of 1ms is used. The
simulation is synchronized with realtime by the visualizer
backend itself. Hence, no synchronization on the model
side is necessary (e.g. from Modelica_DeviceDrivers
Blocks.OperatingSystem.SynchronizedRealtime).
Compared to other visualization approaches, the
generic FMU visualization has the following advantages:

 A specification of the visualization objects allows
different tools to create the same scene automatically.
Figure 3. Screenshot of the visualization perspective in OMEdit.

 No model modifications have to be applied in order
to generate a visualization. No additional dependencies have to be included. No additional equations are 4.6 Unity FMU-Visualization
added to the existing multi-body model.
The implementation in OMEdit based on OpenSceneGraph is not visually attractive and makes it very
 It is easy for simulation tools to generate scene de- cumbersome to enhance the scene with additional graphiscription files. Based on this visualization formal- cal objects. A gaming engine with graphical editor and
ism, the visualization is independent of the simula- a huge asset store like unity (Uni), would allow an easy
tion software and does not rely on vendor specific setup of appealing graphical scenes as in Figure 4. Hence,
interfaces.
the mechanism of loading an FMU and a scene description file has been implemented in a unity plugin. The
 It enables automatic integration of physical simu- user simply chooses an FMU via a dialog and the plugin
lation in graphical modelling software (as will be creates so called GameObjects for the corresponding
shapes. Besides that, an FMU-simulator GameObject
shown for the gaming engine unity).
is created, which simulates the FMU and accesses the
 The simulation and variable access is achieved via necessary variables. This comprises everything to run the
shared memory communication and therefore does scene either in the unity debugger or from a compiled
not need (but can be extended for) simulation via a unity project.
network connection.
 It is helpful to visualize third party FMUs automatically to get an understanding of their behaviour without having access to the model itself.
 It is more convenient to add and edit advanced visualization features in a proper visualization tool and
not in the simulation model by a Modelica-Editor.

4.5

OMEdit FMU-Visualization

The graphical connection editor OMEdit features basically
textual and graphical modeling views, result plotting and
algorithmic debugging. The lack of 3D animation hindered the use for mechanical applications. The novel implementation of a result-file based and FMU-based visualization helps to get a better understanding of mechanical
systems.
Figure 3 displays the visualization view of OMEdit.
The visualization is implemented using OpenSceneGraph
and features the animation of mat-result files, csv-result
files and FMUs. In each case, a scene description file is
needed, to map the model variables to the shape properties.
DOI
10.3384/ecp17132879

Figure 4. Unity scene with an FMU-based excavator model that
is controlled by an Arduino board in realtime.

Next to the shape objects and the FMU-simulator, additional GameObjects can be added in order to create an adequate environment. Accessing the FMU-inputs and FMUoutputs from the unity model is possible via interface
functions of the FMU-simulator GameObject. Hence, the
FMU-generating simulation tool is only responsible for
the physcial simulation. The graphical modelling can be
performed by a special purpose tool. The FMU-simulator

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

883

Interactive FMU-Based Visualization for an Early Design Experience

plugin supports this separation by generating the basic
mapping between simulation and visualization automatically. The unity user interface with FMU-selection dialog and loaded FMU-visualization is depicted in Figure 5.
Since the FMU has to be initialized to calculate the position, orientation and color of the bodies, all shapes are still
in the root of the coordinate system.

sistance systems are experienceable without implementing
them in fully operable systems. This simplifies the evaluation of acceptance and ergonomics. Even exceptional
control mechanisms like handheld controllers for remote
control are possible. Figure 6 shows the setup to control a
model in OMEdit via Bluetooth connection, which is handled as an ordinary serial port.

Figure 5. Unity user interface with loaded FMU. The GameObjects for the shapes and the FMU-Simulator are listed in the hierarchy view, the .dae files are copied to the resources and the
inspector view displays all variables that are updated during runtime.

When interchanging variables between the unity world
and the Modelica-based FMU, it has to be considered,
that the coordinate systems are different. Modelica uses a
right-handed system whereas unity relies on a left-handed
system. Furthermore, the y-axis should be used as
vertical since unity uses it as vertical by default (which is Figure 6. Remote control setup to control an excavator model
essential since available skyboxes display a horizon in the in OMEdit via Bluetooth connection. The control device is a
printed box with 3 rotary potentiometers.
x-z-plane).
The FMU-simulator plugin automatically converts the
position and orientation of the Modelica-variables to the
left-handed system of the unity variables and switches the
vertical axis if desired. Another issue is the lack of stlfile support in unity. It needs an stl-importer plugin or
the CAD-files have to be converted to a 3D data format
e.g. COLLADA. File conversion can be done manually or
scripted by tools like blender (Ble).

5

The Development of a Remote Control Device for an Excavator

The unity editor allows further settings for camera position (first or third person view) as well as lighting and terrain modelling. In the unity asset store, various objects to
populate the scene can be downloaded for free or charged.

6

Conclusion and Outlook

This paper comprises a workflow for developing functional prototypes that have been realized within a student
project at TU Dresden. The usage of Makerspace facilities, low-budget electronics and free software together
in an interdisciplinary design project, was a successful
experiment. The motivation of students was huge and
both the familiarisation with novel technologies as well
as its application are valuable experiences. Besides the
individual learning success, the developed prototypes
are highly praised by the project initiator, an OEM of
excavators.

The previous chapters depicted the necessary tools to set
up a functional prototype. To try out novel control concepts, physical prototypes have been equipped with sensors to measure the motion of the joints. The signals are
used to control the volume flow in and out of the cylinders.
Hence, the velocity of motion for the boom, the arm and
During the project, improvement opportunities have
the shovel are controlled. Even inverse kinematics can be
tried out if the cylinders are controlled to follow cartesian been revealed. Basically, the development of a virtual
inputs to set the position of the shovel. Furthermore, as- environment which can be controlled with external
884

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132879

Session 11C: Mechanical Systems, Robotics & VR

hardware in realtime and based on the simulation of a
Modelica model needed improvement. Hence, an automated approach to setup visualizations of FMU-based
multi-body systems was implemented. The integration via
FMUs in the game engine unity leads to satisfying results.
More importantly, the scene description of FMUs enables
new generic interfaces to visualization tools and their
features. As a future extension, Modelica models could
be extended with contact-force-interfaces or collision
interfaces that could be generated automatically in a unity
project in order to interact with unitys physics engine
and feedback the results to the simulation model. In the
field of mobile machinery, interaction to soil or particle
models in unity would be very useful as well. Since Game
Engines feature comprehensive possibilities to model
environments, experimental grounds can be set up to test
e.g. assistance and automation systems. Through the
network protocol interfaces of M_DD, even web-based
services in mobile machines can be experienceable in
early design stages.

Torsten Blochwitz, Martin Otter, Johan kesson, Martin Arnold,
Christoph Clauss, Hilding Elmqvist, Markus Friedrich, Andreas Junghanns, Jakob Mauss, Dietmar Neumerkel, Hans
Olsson, and Antoine Viel. Functional mockup interface 2.0:
The standard for tool independent exchange of simulation
models. pages 173184, 2012. doi:10.3384/ecp12076173.
Hilding Elmqvist and Martin Otter. Methods for tearing systems of equations in object oriented modeling. In In ESM 94
European Simulation Multiconference, 1994.
Hilding Elmqvist, Martin Otter, and Fransois E. Cellier. Inline integration: A new mixed symbolicnumeric approach for
solving differential-algebraic equation systems. In Proceedings of the 1995 European Simulation Multiconference, pages
2334. Society for Computer Simulation International, June
1995.
Hilding Elmqvist, Alexander D. Baldwin, and Simon Dahlberg.
3d schematics of modelica models and gamification. In Proceedings of the 11th International Modelica Conference, Versailles, France, September 21-23, 2015, number 118, pages
527536. Linkping University Electronic Press, Linkpings
universitet, 2015.

The scene description file is currently an OpenModelica specific feature. Further support of this FMU exten- Matthias Hellerer, Tobias Bellmann, and Florian Schlegel. The
dlr visualization library - recent development and applicasion would leverage the advantage of the unity-plugin and
tions. In Proceedings of the 10th International Modelica
the development of other FMU-Visualization-Add-Ons in
Conference; March 10-12; 2014; Lund; Sweden, number 96,
additional tools. A discussion about adding the scene depages 899911. Linkping University Electronic Press;
scription file as an optional extension to the FMI-Standard
Linkpings universitet, 2014. doi:10.3384/ecp14096899.
would be highly appreciated by the authors.

References
The arduino webpage. www.arduino.cc. Accessed: 201611-18.
The blender webpage. www.blender.org. Accessed: 201612-08.
The fmilibrary webpage.
www.jmodelica.org/
FMILibrary. Accessed: 2016-11-21.
The unity3d webpage. www.unity3d.com. Accessed: 201611-18.
The saxon state and university library dresden (slub) webpage.
http://www.slub-dresden.de/en/service/
workplaces-workspace/makerspace/. Accessed:
2016-12-07.
Proceedings of the 1st International Symposium on Academic Makerspaces ISAM 2016, 2016.
URL www.
project-manus.mit.edu/home/conference.
Tobias Bellmann. Interactive simulations and advanced visualization with modelica. In Proceedings 7th Modelica Conference. Linkuping University Electronic Press, 2009.
Jonatan L. Bijl and Csaba A. Boer. Advanced 3d visualization
for simulation using game technology. In Proceedings of the
Winter Simulation Conference, WSC 11, pages 28152826.
Winter Simulation Conference, 2011. URL http://dl.
acm.org/citation.cfm?id=2431518.2431853.

DOI
10.3384/ecp17132879

Christoph Hoeger, Alexandra Mehlhase, Christoph NytschGeusen, Karsten Isakovic, and Rick Kubiak. Modelica3d
- platform independent simulation visualization. In Proceedings of the 9th International MODELICA Conference;
September 3-5; 2012; Munich; Germany, number 76, pages
485494. Linkping University Electronic Press; Linkpings
universitet, 2012. doi:10.3384/ecp12076485.
Volker Waurich, Ines Gubsch, Christian Schubert, and Marcus Walther. Reshuffling: A symbolic pre-processing algorithm for improved robustness, performance and parallelization for the simulation of differential algebraic equations.
In Proceedings of the 6th International Workshop on Equation-Based Object-Oriented Modeling Languages and Tools, EOOLT 14, pages 310, New York,
NY, USA, 2014. ACM.
ISBN 978-1-4503-2953-8.
doi:10.1145/2666202.2666203. URL http://doi.acm.
org/10.1145/2666202.2666203.
Volker Waurich, Martin Groer, and Sebastian Voigt. Generische visualisierung von fmu-basierten modellen fr die interaktive simulation. In Tagungsband Workshop ASIM STS/GMMS 2016, pages 230236. ASIM STS/GMMS, 2016. ISBN
978-3-901608-48-3.
Masahiro Yamaura, Nikos Arechiga, Shinichi Shiraishi, Scott
Eisele, Joseph Hite, Sandeep Neema, Jason Scott, and
Theodore Bapty. Adas virtual prototyping using modelica
and unity co-simulation via openmeta. In The First Japanese
Modelica Conferences, May 23-24, Tokyo, Japan, number
124, pages 4349. Linkping University Electronic Press,
Linkpings universitet, 2016.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

885

886

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

Using Modelica for advanced Multi-Body modelling
in 3D graphical robotic simulators
Gianluca Bardaro1
1 Dipartimento

Luca Bascetta1

Francesco Casella1

Matteo Matteucci1

di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy,

{luca.bascetta,gianluca.bardaro,francesco.casella,matteo.matteucci}@polimi.it

Abstract
This paper describes a framework to extend the 3D robotic
simulation environment Gazebo, and similar ones, with
enhanced, tailor-made, multi-body dynamics specified in
the Modelica language. The body-to-body interaction
models are written in Modelica, but they use the sophisticated collision detection capabilities of the Gazebo engine. This contribution is a first step toward the simulation
of complex robotics systems integrating detailed physics
modelling and realistic sensors such as lidar and cameras.
A proof-of-concept implementation is described in the paper integrating Gazebo collider and the Modelica MultiBody library, and the results obtained when simulating
the interaction of an elastic sphere with a rigid plane are
shown.
Keywords: Multi-Body Dynamics, 3D Robotic Simulators,
Autonomous Robotics, Autonomous Vehicles.

1

Introduction

The popularity of research on autonomous mobile robots,
including autonomous vehicles and mobile manipulators,
has been recently increasing due to the huge number of
potential applications, ranging from self-driving cars and
robots for logistics, to planetary explorations, search and
rescue missions, surveillance, humanitarian de-mining, as
well as precision agriculture activities such as pruning
vines and fruit trees (Paden et al., 2016; Roa et al., 2015;
Ko et al., 2015; Chitta et al., 2012).
The design and development of such systems, whose main
functionalities are perception, planning, and control, is a
multidisciplinary and complex work that has to be supported by virtual prototypes, allowing for a preliminary
design and testing of the corresponding algorithms in safe
operating conditions. However, due to the huge differences among the three mentioned skills a mobile robot
should own, the virtual prototype has to satisfy various requirements. Considering, for example, the development of
perception algorithms, the most important characteristics
of the virtual prototype are a realistic description, mainly
from a geometrical and graphical point of view, of the
scene, and the availability of realistic models for the most
common commercial sensors, i.e., laser range finders and
cameras. On the other hand, testing a control algorithm,
e.g., an Advanced Driver Assistance System in a critical
DOI
10.3384/ecp17132887

situation, requires an accurate physical modelling of the
vehicle, including all (and sometimes even only) the phenomena the designer knows to be relevant in the specific
application, e.g., cornering stiffness for lateral dynamics
control.
Nowadays there are many different, open source and
commercial, modelling and simulation environments that
are suitable to model vehicles and mobile robots.
A first family is represented by 3D robot simulators, like
for example Gazebo1 , V-Rep2 , Webots3 , Morse4 , that are
widespread in the robotics community. These simulators
allow for an easy development of complex natural/artificial simulation environments, they are already equipped
with models of perception devices, and they can be easily integrated with standard robot control middlewares like
ROS5 . For these reasons, they are particularly suitable for
the development and testing of planning and perception algorithms, and for the validation of the whole control software before moving to field tests (Bardaro et al., 2014).
The physical simulation implemented in these tools is targeted at real-time execution and ease of virtual prototype
set-up; this is obtained by providing the 3D kinematic
models for rotational and translational joints to assemble robots and vehicles, and collision detection primitives
with simplified translational and rotational friction models. These building blocks are implemented with low level
C++ libraries, such as ODE (Drumwright et al., 2010) or
MuJoCo (Erez et al., 2015), and the experimenter is expected to use them in a black box fashion with little, if
any, way to alter their physical behaviour. Indeed, the differential equations characterizing the physical behaviour
of each building block are hidden in the code, often undocumented, and with no direct tool for altering their behaviour. This makes current 3D robotics physical simulation fidelity and accuracy somehow limited, and requires
the coding of external plug-ins, e.g., using C++ custom
code, every time the phenomenon we are interested in
replicating is more complex that the one which can be obtained assembling the available building blocks.
On the other side of the spectrum, a second family of sim1 http://gazebosim.org
2 http://www.coppeliarobotics.com
3 http://www.cyberbotics.com
4 http://www.openrobots.org/wiki/morse
5 http://www.ros.org

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

887

Using Modelica for advanced Multi-Body modelling in 3D graphical robotic simulators

ulators is represented by multi-body and/or multi-physics
simulators, like for example Modelica tools 6 such as SimulationX7 , whose aim is to accurately represent the dynamic behaviour of the system, and that are thus particularly suitable for accurate dynamic analysis, control system development, and validation in repeatable and safe
operating conditions (DAmelio et al., 2015). These simulators allow a general mechanism for physical systems
modelling, based on an high-level language for the definition of the differential equations describing the relevant
aspects of the simulation, but little, if any, support is available for geometrical and graphical simulation of the environment and thus for the simulation of robot sensors such
as lidar and cameras.
In this paper we present an approach, inspired by the
idea already introduced in (Bardaro et al., 2016), to extend the multi-body modelling in the 3D Gazebo simulator using Modelica and the MultiBody library (Otter et al.,
2003). This allows to introduce ad-hoc physical models
which are tailored to the specific needs of a particular
application in a convenient, declarative, equation-based
framework, leveraging on the basic infrastructure already
provided by the MultiBody library. On the other hand, we
are able to extend the level of simulation provided by the
Modelica framework by the 3D simulation capabilities of
the Gazebo simulator. In particular, this paper focuses on
adding customized body-to-body interaction models to the
standard components of the MultiBody library, combining
the advanced capabilities of collision detection provided
by the Gazebo framework with the flexibility provided by
the Modelica environment to define sophisticated, tailormade, equation-based physical models. It must be emphasised, however, that this topic is not important per se,
instead it represents a proof-of-concept of the possibility
of integrating the two simulation environments in order to
set up a new one that is able to better address graphical
and physical aspects as well. As a consequence, the contribution of this paper is not related to an innovative or
improved interaction model, but to the framework that allows to extend Modelica modelling capabilities by the 3D
Gazebo simulation.
The paper is structured as follows. Section 2 describes
the design of the modelling framework. In the following Section 3, a proof-of-concept implementation is described, and the results obtained with a simple sphere-toplane interaction simulation are presented. Section 4 concludes the paper with an outlook to further developments.

2

Design of the modelling framework

The rationale behind the design is to let Gazebo and the
Modelica tool each perform the tasks at which they excel, for which they already have good built-in support,
and which are more conveniently programmed by the enduser.
6 http://www.modelica.org
7 http://www.simulationx.com

888

Modelica will then be used for the accurate and tailormade dynamic modelling of the multi-body objects for
which the standard modelling approach of the physical engine embedded in Gazebo is not adequate. Modelica could
also be used to represent low-level sensing, actuation and
control, such as electric motors and drives, pneumatic actuation, low-pass signal filtering, etc., which are not covered by Gazebo, when their accurate modelling is essential to assess the success or failure of higher-level control
functions.
All other tasks, such as building and managing the scenes,
simulating other objects for which ad-hoc dynamic modelling is not required, simulating vision-based sensing,
and providing geometrical information about object collisions, will be managed by Gazebo.
The present paper focuses on the integration between
Gazebo and Modelica to provide accurate ad-hoc physical modelling where needed. How the resulting physical
model can then be integrated in the Gazebo environment,
together with all the other objects and functions simulated
by Gazebo, goes beyond the scope of this paper and will
be addressed in future works.
The basic framework for the modelling of multi-body
objects is provided by the Modelica MultiBody library,
which allows to build modular models of multi-body systems by the connection of link and joint models. Since the
Gazebo engine also uses corresponding primitives, automatically generating the Modelica code of the model corresponding to any Gazebo multi-body object is a straightforward task. The availability of flexible link models compatible with the MultiBody library, e.g., those described
in (Ferretti et al., 2014), allows to easily take into account
flexibility in all those cases where this is crucial to replicate the system dynamic behaviour. This is a feature that
could be very useful in the case of soft or flexible robots
and which is still not present in Gazebo.
A key ingredient of any multi-body model of robots or
autonomous vehicles is the modelling of the interaction
between different bodies, in particular the tyre-road interaction in vehicles and the interaction between hands or
grippers and objects to be manipulated for robots. For
this purpose, Gazebo provides so-called collider objects,
which take as input the position of the reference frames
of any two objects, possibly having a complex shape, and
returns information about the presence or absence of contact points, their location, the depth of penetration, and the
normal vectors to the object surface at the contact point.
Gazebo can also compute the resulting interaction forces
and torques, according to some standard embedded model;
the idea in the context of this paper is to ignore this information and use Modelica instead to compute them, according to a tailor-made equation-based physical model
that is appropriate for the specific simulation scenario.
The Modelica code of the base model for two-body interaction, PhysicalInteraction, is listed in the appendix. The model extends the PartialTwoFrames
model of the MultiBody library. It gets the position and

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132887

Session 11C: Mechanical Systems, Robotics & VR

orientation of the two potentially interacting objects from
the two frame connectors and passes them to the collisionDetectionModelica function. This in turn
converts the rotation objects into quaternions and calls the
external function collisionDetection, that passes
the two object ID strings and their position and orientation
to the Gazebo server. The collider in Gazebo responds returning the number of contact points, the arrays of contact
points on both bodies, as well as the penetration depths
and the normals to the surface for each contact point.
This data is then passed to the replaceable function
computeInteraction, which uses the kinematic information to compute the forces and torques exerted on
body a by body b. As Modelica functions cannot generate events, a conditional equation is then written in
the PhysicalInteraction model, which applies the
forces and torques computed by the external function to
the connector if the penetration depth is positive, zero otherwise. This allows to precisely compute the contact event
instant and handle the discontinuity properly, if the Modelica solver provides proper event handling. Finally, the
corresponding forces and torques applied on body b by
body a are computed by Newtons 3rd law.
In this context, the Gazebo tool only acts as a server,
providing the service of computing the kinematic information regarding the collisions between any two objects
of interest. The physical simulation is carried out by the
code generated by the Modelica tool, which is the simulation master. This means that the sequence of calls to the
Gazebo server does not correspond to a physical sequence
of points in time, but rather to the individual function calls
required by the Modelica solver, which might go backward and forward in time to compute a solution, e.g., when
locating event instants or when a time step is rejected by
an adaptive step-size solver. As the Gazebo tool is not
the master of the simulation in this context, this is not a
problem. In fact, time is not even part of the data which
is communicated to the Gazebo server from the Modelica
side.
Specific physical interaction models can then be obtained by extending the PhysicalInteraction class
and by redeclaring the computeInteraction function with the specific algorithm that computes the interaction forces and torques, based on the model of interest
for the end user. All the infrastructure provided by the
Modelica MultiBody library can be used to carry out this
task with ease, in particular the functions to resolve vectors in different reference frames and all the functions implementing vector algebra operations.

computeInteraction uses Unix IPC sockets to communicate with the Gazebo server. In the future, this mechanism will be substituted by some more efficient, sharedmemory based communication, e.g., by embedding the
Modelica model into an FMI and using external objects
to set up the communication framework.
A simple exemplary test case has been selected for the
demonstration, namely the interaction between an elastic
ball and a fixed, rigid plane. When the two bodies collide,
the force Fa applied on the sphere at the point of contact is
the sum of three components:
Fa = Fe + Fd + Ff .
The elastic force Fe is directed as the normal vector (which
points to the spheres centre) and its magnitude is computed according to (Nassauer and Kuna, 2013)

Fe = ke V d,
where ke is an elastic constant, d is the penetration depth,
and V is the volume of the spherical cap of height d


d
2
V = d r 
.
3
The damping force Fd is proportional to the normal component vn of the relative velocity between the two bodies
at the point of contact and opposed to it, thus providing
dissipation each time the sphere hits the plane.
The friction force Ff depends on the tangential component of the relative velocity vt at the point of contact, has
the opposite direction and a magnitude
Fe p

vt
;
2
vt + v2

where  is the dry friction coefficient, v is a small velocity threshold, and the fraction is approximately equal
to one for vt  v and approaches zero as vt  0. This
model is not accurate at low relative velocities, since it
leads to a slow sliding at velocities around v instead of
proper stiction. On the other hand, it has the nice property of not becoming singular at zero relative velocity and
is perfectly adequate for the purposes of this demonstration. Other more sophisticated models that include stiction, such as the one described in (Deur et al., 2004) could
be employed if needed.
As to the torques, only the friction force exerts a net
torque on the spheres frame connector, located at the centre of the sphere; the torque vector is simply  = r  Ft .
3 Proof of concept
For simplicity, the torsional torque due to rolling friction
In this section, a proof-of-concept implementation that has been neglected in this demonstrator.
demonstrates the proposed approach is presented.

3.2

3.1

Test cases and simulation results

Implementation details

The results of three sphere-to-plane interaction simulaIn order to avoid all the problems related to memory man- tions are here presented. The sphere represents a big inagement, in this implementation the external C function flated balloon, modelled as a hollow sphere of mass m = 1
DOI
10.3384/ecp17132887

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

889

Using Modelica for advanced Multi-Body modelling in 3D graphical robotic simulators

(a) Trajectory of the sphere centre in the xz-plane

Figure 1. Simulation 1  Ball height over time.

kg, radius r = 0.5 m, moments of inertia J = 23 mr2 , elastic
constant ke = 103 N/m2 and with a relatively low friction
coefficient  = 0.1. Air friction is neglected. All the simulations start with the center of the sphere at a height of
1 m above the horizontal xy-plane, the z-axis pointing upwards.
The Modelica code was compiled into executable simulation code with the OpenModelica compiler8 version
1.12.0-dev, using a Runge-Kutta fixed time step integration algorithm with a time step of 1 ms, which is short
enough to correctly handle the elastic impacts, whose typical duration is about 10 ms.
The simulation were first tested by emulating the response of the Gazebo server by a Modelica function. This
required to extend the Sphere2Plane physical interaction model, which uses the external function calling
Gazebo, and to redeclare the collisionDetectionModelica function so that it directly computes the contact point locations, depths of penetration and normal vectors, rather than calling the external function and getting
them from Gazebo. This function is implemented easily
in Modelica, as the geometry of the sphere-to-plane interaction is extremely simple. Eventually, the same simulation results were obtained when using the Gazebo server,
thus validating the entire proof-of-concept implementation. Also, the qualitative behaviour of the system in the
three simulations corresponds to what one would expect
from physical intuition.
Many different simulations were run, in order to validate each component (elastic, damping, friction) of the
interaction forces and torques separately. In this paper,
the results of three simulation experiments with realistic
choices of the interaction model parameters are reported.
In the first simulation, the plane is horizontal and the
sphere has zero initial velocity and angular velocity. As
expected, the ball falls onto the plane and bounces a few
times before getting to rest, due to the dissipative effect
of Fd . Figure 1 shows the vertical position of the sphere
centre over time.
The second simulation scenario is similar, save that the
plane is tilted by 45 along the y-axis. When the ball
hits the plane, it bounces off horizontally. Due to fric8 https://openmodelica.org

890

(b) Angular velocity of the sphere in the y-axis direction

Figure 2. Simulation 2  Ball bouncing on a tilted plane.

tion, it also gets some angular momentum on the y-axis
during the bounce, and thus starts spinning slowly. It then
bounces a few more times on the tilted plane until dissipation causes it to remain in contact with the tilted plane and
to accelerate while rolling downwards. Figure 2(a) shows
the trajectory of the spheres centre in the vertical plane,
while Figure 2(b) shows the angular momentum over time,
which increases abruptly at each bounce and finally increases with a constant slope once the sphere stops bouncing and rolls down on the plane surface always remaining
in contact.
The last simulation considers again a horizontal plane;
in this case the sphere starts with a non-zero horizontal velocity in the negative x-axis direction, spinning fast backward around the y-axis. Every time the ball bounces on
the plane, the friction force slows down the spinning a bit,
and accelerates the sphere in the positive x-axis direction,
so that eventually the ball changes its horizontal direction
and rolls back to a point on the plane below the initial position. Figure 3(a) shows the position of the spheres center
in the vertical xz-plane, while Figure 3(b) shows the angular momentum along the y-axis over time9 .

4

Conclusions

In this paper, a proof-of-concept for the integration between the Gazebo 3D robotic simulation tool and Modelica has been presented. The proposed framework al9 The

3D videos generated by Gazebo of the three simulations are
available online at this URL: https://home.deib.polimi.

it/casella/gazebo/videos.html.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132887

Session 11C: Mechanical Systems, Robotics & VR

(a) Trajectory of the sphere centre in the xz-plane

(b) Angular velocity of the sphere in the y-axis direction

Figure 3. Simulation 3  Ball starting with a non-zero horizontal
velocity in the positive x-axis direction and spinning backward
around the y-axis.

lows to extend the basic 3D multi-body engine embedded
in Gazebo, by providing equation-based customized 3D
multi-body dynamics. The extension is very convenient
and easy to implement, as it leverages on the existing sophisticated collision detection functionality of Gazebo, on
the Modelica MultiBody library, and on the possibility of
describing an ad-hoc physical behaviour in a high level,
equation-based modelling environment. It also makes it
possible to perform equation-based multi-domain physical modelling, e.g., by adding Modelica models of physical sensors, actuators and low-level controllers to the mechanical model, and in general by modelling any kind of
physical behaviour beyond that of multi-body systems.
The framework has been demonstrated with a proofof-concept implementation, using IPC sockets to enable
the communication between the Gazebo tool and Modelica automatically generated simulation code. In particular, the results of the simulations of a simple system with
an elastic ball bouncing on a rigid plane with low friction have been presented. The obtained results are very
encouraging and suggest that it might indeed be possible
to propose these Modelica extensions, implemented with
the open-source OpenModelica compiler, as the preferred
way to extend the native Gazebo simulation engine.
To reach our final aim, further developments are under investigation. First of all, we would like to validate
the concept with scenarios involving multiple object interactions; currently we already generate Modelica simulation code in the presence of multiple object, what has to
DOI
10.3384/ecp17132887

be validated is the collision between multiple objects handled by Modelica. To improve on performance and ease
of deployment, we are currently encapsulating the Modelica model in an FMU to handle the communication with
Gazebo via shared memory and external object interface.
Once the FMU will be integrated with the Gazebo plug-in
mechanism, it will be possible to integrate the FMU-based
simulation into the master simulation loop of the Gazebo
tool in a seamless way and transparently to the designer of
the simulation.
Finally, we would like to experiment with hybrid simulations with some physical behaviour simulated by the
Gazebo physics engine and some physical behaviour with
special modelling requirements simulated by the Modelica/FMU code. This set-up could be necessary to handle demanding simulation scenarios with many objects,
since we expect the Modelica-based simulation code to be
slower than the native and somewhat simplified Gazebo
simulation engine, so that using Modelica only where
needed could end up in much faster simulations.

References
G. Bardaro, D.A. Cucci, L. Bascetta, and M. Matteucci. A
simulation based architecture for the development of an autonomous All Terrain Vehicle. In SIMPAR, pages 7485,
2014.
G. Bardaro, L. Bascetta, F. Casella, and M. Matteucci. Advancement in multi-body physics modeling for 3d graphical robot
simulators. In Workshop on Modelling and Simulation for
Autonomous Systems, pages 189195, 2016.
S. Chitta, E.G. Jones, M. Ciocarlie, and K. Hsiao. Mobile manipulation in unstructured environments: Perception, planning, and execution. IEEE Robotics & Automation Magazine,
19(2):5871, 2012.
E.L. DAmelio, L. Bascetta, D.A. Cucci, M. Matteucci, and
G. Bardaro. A modelica simulator to support the development
of the control system of an autonomous all-terrain mobile
robot. In International Conference on Mathematical Modelling, pages 274279, 2015.
Joko Deur, Jahan Asgari, and Davor Hrovat. A 3D brush-type
dynamic tire friction model. Vehicle System Dynamics, 42(3):
133173, 2004. doi:10.1080/00423110412331282887.
Evan Drumwright, John Hsu, Nathan Koenig, and Dylan Shell.
Extending Open Dynamics Engine for robotics simulation. In
Proceedings of the Second International Conference on Simulation, Modeling, and Programming for Autonomous Robots,
SIMPAR10, pages 3850. Springer-Verlag, 2010.
Tom Erez, Yuval Tassa, and Emanuel Todorov. Simulation tools
for model-based robotics: Comparison of bullet, havok, mujoco, ode and physx. In Proceedings of IEEE International
Conference on Robotics and Automation (ICRA), 2015.
Gianni Ferretti, Alberto Leva, and Bruno Scaglioni.
Object-oriented modelling of general flexible multibody systems.
Mathematical and Computer Modelling of Dynamical Systems, 20(1):122, 2014.
doi:10.1080/13873954.2013.807433.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

891

Using Modelica for advanced Multi-Body modelling in 3D graphical robotic simulators

M. Ko, B.-S. Ryuh, K.C. Kim, A. Suprem, and N.P. Mahalik. Autonomous greenhouse mobile robot driving strategies from system integration perspective: Review and application. IEEE/ASME Transactions on Mechatronics, 20(4):
17051716, 2015.
Benjamin Nassauer and Meinhard Kuna. Contact forces of polyhedral particles in discrete element method. Granular Matter,
15(3):349355, 2013. doi:10.1007/s10035-013-0417-9.
M. Otter, H. Elmqvist, and S. E. Mattsson. The new Modelica
MultiBody library. In Proceedings 3rd International Modelica Conference, pages 311330, Linkping, Sweden, Nov.
34 2003.
B. Paden, M. Cap, S. Zheng Yong, D. Yershov, and E. Frazzoli. A survey of motion planning and control techniques for
self-driving urban vehicles. IEEE Transactions on Intelligent
Vehicles, 1(1):3355, 2016.
M.A. Roa, D. Berenson, and W. Huang. Mobile manipulation:
Toward smart manufacturing. IEEE Robotics & Automation
Magazine, 22(4):1415, 2015.

892

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132887

Session 11C: Mechanical Systems, Robotics & VR

A Listing of the PhysicalInteraction model
model PhysicalInteraction "Base class for all physical interaction models"
extends Modelica.Mechanics.MultiBody.Interfaces.PartialTwoFrames;
import Modelica.Mechanics.MultiBody.Frames;
parameter Integer maxContacts = 10 "Number of max contact points";
parameter String id_a = "" "Id of interacting object a";
parameter String id_b = "" "Id of interacting object b";
Real numberOfContactPoints "Number of actual contact points";
Real cp_a[maxContacts, 3] "Array of contact points on body a, resolved in frame_a";
Real cp_b[maxContacts, 3] "Array of contact points on body b, resolved in frame_b";
Real depth_a[maxContacts] "Array of penetration depths in body a";
Real depth_b[maxContacts] "Array of penetration depths in body a";
Real normals_a[maxContacts, 3] "Array of normals on body a, resolved in world frame";
Real normals_b[maxContacts, 3] "Array of normals on body b, resolved in world frame";
Real r[3] "Vector from frame_a to frame_b resolved in frame_a";
SI.Force f_a[3] "Interaction force applied on body a, resolved in frame_a";
SI.Torque t_a[3] "Interaction torque applied on body b, resolved in frame_b";
replaceable function collisionDetectionModelica
input Integer maxContacts "Maximum number of contact points";
input Real r_a[3] "Position vector of interaction frame of object a, resolved in world frame";
input Frames.Orientation R_a "Orientation of interaction frame of object a";
input String id_a "unique id for object a";
input Real r_b[3] "Position vector of interaction fram of object b, resolved in world frame";
input Frames.Orientation R_b "Orientation of interaction frame of object b";
input String id_b "unique id for object b";
output Real numberOfContactPoints "Number of actual contact points";
output Real cp_a[maxContacts, 3] "Array of contact points on body a, resolved in frame_a";
output Real cp_b[maxContacts, 3] "Array of contact points on body b, resolved in frame_b";
output Real depth_a[maxContacts] "Array of penetration depths in body a";
output Real depth_b[maxContacts] "Array of penetration depths in body a";
output Real normals_a[maxContacts, 3] "Array of normals on body a, resolved in frame_a";
output Real normals_b[maxContacts, 3] "Array of normals on body b, resolved in frame_b";
algorithm
(numberOfContactPoints, cp_a, cp_b, depth_a, depth_b, normals_a, normals_b) :=
collisionDetection(maxContacts, r_a, Frames.to_Q(R_a), id_a, r_b, Frames.to_Q(R_b), id_b);
end collisionDetectionModelica;
function collisionDetection
input Integer maxContacts "Maximum number of contact points";
input Real r_a[3] "Position vector of interaction frame of object a, resolved in world frame";
input Frames.Quaternions.Orientation Q_a "Quaternion of the orientation of interaction frame of object
a";
input String id_a "unique id for object a";
input Real r_b[3] "Position vector of interaction fram of object b, resolved in world frame";
input Frames.Quaternions.Orientation Q_b "Orientation of interaction frame of object b";
input String id_b "unique id for object b";
output Real numberOfContactPoints "Number of actual contact points";
output Real cp_a[maxContacts, 3] "Array of contact points on body a, resolved in frame_a";
output Real cp_b[maxContacts, 3] "Array of contact points on body b, resolved in frame_b";
output Real depth_a[maxContacts] "Array of penetration depths in body a";
output Real depth_b[maxContacts] "Array of penetration depths in body a";
output Real normals_a[maxContacts, 3] "Array of normals on body a, resolved in frame_a";
output Real normals_b[maxContacts, 3] "Array of normals on body b, resolved in frame_b";
external "C"
end collisionDetection;

DOI
10.3384/ecp17132887

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

893

Using Modelica for advanced Multi-Body modelling in 3D graphical robotic simulators

replaceable partial function computeInteraction "Compute interaction torques and forces on frame_a,
resolved in frame_a"
input Real numberOfContactPoints "Number of actual contact points";
input Integer maxContacts "Maximum number of contact points";
input Real r_a[3] "Position of frame_a resolved in world frame";
input Real r_b[3] "Position of frame_b resolved in world frame";
input Real v_a[3] "Velocity of frame_a resolved in world frame";
input Real v_b[3] "Velocity of frame_b resolved in world frame";
input Frames.Orientation R_a "Orientation of frame_a";
input Frames.Orientation R_b "Orientation of frame_b";
input Real cp_a[maxContacts, 3] "Array of contact points on body a, resolved in frame_a";
input Real cp_b[maxContacts, 3] "Array of contact points on body b, resolved in frame_b";
input Real depth_a[maxContacts] "Array of penetration depths in body a";
input Real depth_b[maxContacts] "Array of penetration depths in body a";
input Real normals_a[maxContacts, 3] "Array of normals on body a, resolved in frame_a";
input Real normals_b[maxContacts, 3] "Array of normals on body a, resolved in frame_a";
output SI.Force[3] f_a "Equivalent force applied to frame_a, resolved in frame_a";
output SI.Torque[3] t_a "Equivalent torque applied to frame_a, resolved in frame_a";
end computeInteraction;
equation
(numberOfContactPoints, cp_a, cp_b, depth_a, depth_b, normals_a, normals_b) =
collisionDetectionModelica(maxContacts, frame_a.r_0, frame_a.R, id_a, frame_b.r_0, frame_b.R, id_b);
assert(numberOfContactPoints <= maxContacts, "Too many contact points");
(f_a, t_a) = computeInteraction(numberOfContactPoints, maxContacts,
frame_a.r_0, frame_b.r_0, der(frame_a.r_0), der(frame_b.r_0), frame_a.R, frame_b.R,
cp_a, cp_b, depth_a, depth_b, normals_a, normals_b);
if sum(depth_a + depth_b) > 0 then
frame_a.f = f_a;
frame_a.t = t_a;
else
frame_a.f = {0, 0, 0};
frame_a.t = {0, 0, 0};
end if;
r = Frames.resolve2(frame_a.R, frame_b.r_0 - frame_a.r_0);
zeros(3) = frame_a.f + Frames.resolveRelative(frame_b.f, frame_b.R, frame_a.R);
zeros(3) = frame_a.t + Frames.resolveRelative(frame_b.t, frame_b.R, frame_a.R) - cross(r, frame_a.f);
end PhysicalInteraction;

894

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132887

A New Object-Oriented Approach for Integrating Discrete
Element Method into Modelica
Christian Richter1
1 Chair

Jrgen Weber2

Florian Ohser3

Thomas Beutlich4

of Construction Machines, TU Dresden, Germany, christian.richter1@tu-dresden.de
of Fluid-Mechatronic Systems, TU Dresden, Germany, weber@ifd.tu-dresden.de
3 ESI ITI GmbH, Germany, florian.ohser@esi-group.com
4 ESI ITI GmbH, Germany, thomas.beutlich@esi-group.com

2 Chair

Abstract
In this paper a new library for co-simulation of discrete
element method and Modelica models is presented. For
this a component-based approach is used that allows closed modeling and visualization of discrete element systems in a modelica tool. Translation into a native DEM
description language and co-simulation is done by a separate compiler and backend. Usage and functionality are
shown in a simple use case of a bucket excavator digging
a hole.
Keywords: discrete element method, co-simulation, construction machines

1

Discrete Element Method

Contact Detection
between all particles
and walls

new positions
and velocities

Introduction

Working process of construction and conveying machines
is characterized by the interaction with granular materials.
In order to allow prospective analysis of machine behavior under real operating conditions, coupled simulations
are increasingly used. In these cases, particle-mechanical
behavior is reproduced by using discrete element method
(DEM). Up to now the creation and calculation of coupled
simulations between system models and DEM is very expensive and time-consuming. This effort can be significantly reduced by using the new library presented in this
work, which uses a new component-oriented modeling approach for discrete element systems.

1.1

deformation as a consequence of collision. For that different contact-models and force-deformation laws are used.
Figure 1 shows an example of such a contact model. By
summing up all single forces and torques, the translational and angular acceleration of each particle can be obtained. The last step is solving the equations of motion. For
that the new positions and velocities are resolved by integrating translational and angular acceleration. The whole
loop is repeated for a predetermined number of iterations.

Solving the equations
of motion
for every particle

contact forces

interparticle contacts
particle-wall contacts

Application of the
force-deformation law
for every contact

Figure 1. DEM Computation Loop.

1.2

R
LIGGGHTS

One of the most used non-proprietary software applicaR
tions for discrete element simulations is LIGGGHTS
(LAMMPS improved for general granular and granular
heat transfer simulations) (Kloss and Goniva, 2011). Main
advantages of it are:

 Open source

 Large number of available contact models
The discrete element method (DEM) is a numerical method for simulating the behavior and motion of large num Extensive import and export capabilities for geomebers of discrete, interacting objects (Cundall, 1971). In
try and results
most cases, as done here, these objects are referred as
 Various implementations and methods for paralleliparticles. Basis of the method is the calculation of forzation of computation (MPI, OpenMP, CUDA)
ces acting between the particles or between a particle and
an adjacent surface. The basic calculation cycle should be Besides these points it also has some disadvantages:
explained briefly below.
 Command-oriented modeling-paradigm
After insertion every particle has an initial position and
velocity. The simulation loop starts by determining all
 Complicated syntax
particle-particle and particle-wall contacts. After that the
forces and torques acting on every particle have to be cal Elaborate parametrization
culated. These forces result on the one hand from field
 No graphical user interfaces
forces like gravity and on the other hand from the particle
DOI
10.3384/ecp17132895

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

895

A New Object-Oriented Approach for Integrating Discrete Element Method into Modelica

 No integrated visualization and post-processing capabilities

2

Object-oriented design for DEM

R

All these disadvantages will be eliminated with the solu- As already mentioned LIGGGHTS follows a commandoriented modeling-paradigm. This is typical for all DEM
tion presented here.
applications. Usually the user writes an input script con1.3 Earlier Solutions and Classification
taining the whole simulation process. The software reads
Coupled simulation of Modelica-based machine models in this script and executes all commands in sequential orand discrete element method has been a big field of rese- der.
arch in recent years. Several solutions have been develoOne of the core ideas of Modelica is to use an objectped till now. For a better understanding of the differences oriented design (OOD) for models. For transforming
R
between them, classification shown in figure 2 (Geimer LIGGGHTS
functions into an OOD first an objectet al., 2006) should be used.
oriented analysis (OOA) must be done. According to
Core idea and principle of Modelica is to use an (Coad and Yourdon, 1991) an object is defined as a real
equation-based approach for behavioral description and world entity related to the problem domain, with crisply
linkage of different models from different physical dom- defined boundaries. Objects are encapsulated with attriains. This is called a classic simulation. While this works butes and behaviour. For identifying all objects its helpful
fine for some domains, like hydraulics or mechanics, this to start writing down all functionalities that should be inwont work for discrete element systems. To ensure fast cluded in future objects. After that object classes and their
contact detection or force computation the specialization design parameters have to be defined fulfilling all these
of another simulation tool is necessary.
functionalities. One principle is that all objects should be
For coupling two different simulation tools special in- self-explaining and easy to understand for the user. The
terfaces must be developed. In 2010 we started with the following table shows a selection of defined classes and
software-framework SARTURIS providing a network ba- some of their functions.
sed coupling of both domains(Kunze et al., 2010). Another coupling technique using functional mock-up units
(FMU) was presented in 2012 (Kunze et al., 2012). Ba- Table 1. Selection of DEM object-classes and related functiosed on the functional mock-up interface, a FMU describes nalities.
a non-proprietary data format containing encapsulated siObject
Functionalities
mulation models (Blochwitz et al., 2012). FMUs can be
exported and imported by many simulation tools and used
SimulationBox
set timestep size
for simulation coupling. Referring to figure 2 both soset contact model
lutions are co-simulations. The biggest drawback is that
set boundaries of spatial domain
distributed modeling, as well as coupling of different inget total particle count/mass
put and output values, is very time-consuming and errorSingleParticle
generate a single particle
prone.
set diameter
The solution presented in this paper allows a closed modefine material settings
deling and an automatic coupling of DEM and Modelica.
ParticleSet
load saved particle configurations
A similar approach was used in (Elmqvist et al., 2015).
ParticleSource
generate a particle stream
Additionally, the new library uses a component-based moParticleSink
remove particles
deling paradigm for discrete element models.
set particle rate / mass rate

Number of
ModelingTools

>1

=1

Closed
Simulation

Merging systems
of equations of
separately modeled
subsystems

Distributed
Simulation

RigidBody
RegionSensor

Co-Simulation

"Classic"
Simulation

Modelseparation
for Simulation

=1

>1

Distributed
Modeling

Closed
Modeling

Number of
Integrators

Figure 2. Classification of coupled simulations.

896

define material settings
set position and velocity
get forces on body
get particle count/mass in region

As you can see not all of these objects are real world entities, so it would be better to speak of a component-oriented
than of an object-oriented design. In order to keep the terminology as simple as possible it was decided to continue
speaking of an object-oriented approach.
After classes, functions and parameters are defined they
can be implemented in Modelica. Figure 3 shows the
structure of the new library and design of the single object models.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132895

Session 11C: Mechanical Systems, Robotics & VR

Frontend

Material
Database

Backend

<<component>>

<<component>>

Client 1

Server

<<component>>

<<component>>

Client 2

Slave/Compiler

<<component>>

liggghtslib.dll

<<library>>

Client N

Figure 4. System architecture

3.2

Communication

For communication and data exchange between front- and
back-end C-functions accessed by external objects are
used. Every object has a TcpClient, which is responsible
for connecting to the server as well as sending and receiving data. All data is stored in DataPackages acting like a
send and receive buffer.
TcpClient client = TcpClient();
DataPackage outPkg = DataPackage();
DataPackage inPkg = DataPackage();

R
Figure 3. DEM Library in SimulationX
.

3
3.1

Simulation coupling
System architecture

Above library allows the closed modeling of machine and
process models. In order to perform a distributed simulation, models have to be subsequently separated again. For
a better understanding on how this is done figure 4 shows
the system architecture of all simulation components. This
structure is divided into front- and back-end.
The front-end essentially consists of the library and a
material database, which will be explained more in detail
in section 4.2. Each library object contains an internal network client, which is capable to connect and communicate
via TCP/IP to a server.
The server is the root node of back-end-structure. It receives the messages coming from the components and forwards them to a special DEM-Slave with an attached compiler. The compiler is collects information about all elements in the model and translates them into LIGGGHTS
command sequences.
LIGGGHTS itself is not used as an executable but as a
shared library with a custom API. Data exchange is much
more simplified this way. Furthermore we modified some
basic LIGGGHTS function, e.g. for moving meshes, particles sources and sinks during simulation runtime.
DOI
10.3384/ecp17132895

During initialization all clients are connecting to the server. After connection has successful established initial
data is exchanged. This may be for example some positional or geometric information.
parameter Boolean isConnected = false;
parameter Boolean isInitialized = false;
parameter String address = "localhost";
parameter Integer port = 1234;
initial algorithm
if isInitialized == false then
isConnected := connectToHost(
client, address, port);
end if;
setData(outPkg, {/*integer values*/},
{/*real values*/},
{/*string values*/});
if isConnected then
sendPackage(client, outPkg);
recvPackage(client, inPkg);
end if;
isInitialized:=true;

After initialization the main loop starts. Communication
between front- and back-end occurs at discrete equidistant
time values. For this we use a sample-function. At every
communication event current model values are pushed to
the server. After sending all output data the model waits
for the data coming fom the server. At the end of the simulation loop some final data is transferred to the server.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

897

A New Object-Oriented Approach for Integrating Discrete Element Method into Modelica

parameter Real tc(quantity="Basics.Time",
displayUnit="s") = 0.0001;
Boolean commTrigger(start=false,fixed=true)
= sample(0, tc);

other. This function was not provided in the original work
package. It has been implemented since it means a considerable added value for the user and thus for the marketing
of the final product. The interpolation of a stone by a Multisphere object is shown in figure 5.

algorithm
if isConnected then
when commTrigger then
// set current data to outPkg
// send and receive packages
// extract data from inPkg
elsewhen terminal() then
// send final information
end when;
end if;

4
4.1

Pre-processing

5

Basic simulation settings

All basic simulation and communication settings are defined in the SimulationBox. Similar to the World component in Modelica.Mechanics.MultiBody package every
DEM model must contain one SimulationBox. This is ensured by an outer construct in the code.
outer DEM.Basics.SimulationBox simBox;

This way all objects have access to basic parameters like
host address and port.
equation
address = simBox.address;
port = simBox.port;

In order to keep computation costs low its necessary to
define boundaries for the DEM space. These boundaries
can be fixed (particles will be removed if they leave the
spatial domain) or dynamic growing.

4.2

Material definitions

The parameterization of the material properties of DEM
models is very complicated and presents a problem that
has not been completely solved. In order to increase the
operating convenience of the library, a material database
has been created, which contains parameter sets for the
most realistic description of different granular materials.
The valid parameter sets were determined by comparing
laboratory measurements and simulation. Various calibration tests were used. Among other things, the shear force,
the angle of inclination as well as the transit time of different granular substances were investigated. The selection
of the materials to be examined followed the possible future application areas of the total solution. Sand and gravel
(construction machinery), hard coal, brown coal, iron ore
and potash (mining and conveyor technology) as well as
corn and wheat (agricultural machinery and food technology) were investigated.
For the representation of large rocks or boulders a
function was implemented, which allows the use of Multisphere materials. In this case, a composite of several spheres is formed, which are inseparably connected to each
898

Figure 5. Multisphere approximation of a stone

5.1

Post-processing
Visualization

Besides representing time-dependent state values in diagrams, 3D visualization is an important part of modern
post processing. For this the ModelicaServices package
comes with some models for animation and visualization
of certain predefined shapes such as cylinders, boxes or
imported STL- and DXF-geometries. The implementation of this package can vary from one Modelica tool to
another.
These capabilities are very limited to basic shapes and
not sufficient for the visualization of large particle systems. Though there is an animation body for spheres, its
not very advising to use it, because for n particles it would
be necessary to create n animation submodels. This would
increase the number of internal equations and downgrade
performance.
In our implementation we created a new animation
body called DEMPoints. We propose to extend ModelicaServices with such a model.
For large-scale systems up to one million particles 3D
representation itself takes a lot of computation costs. For
that reason its possible to switch between the options
splats, diamonds or spheres, which supply different levels
of details and performance.

5.2

Sensors

In discrete element simulations its often necessary to measure particle specific values. For that we enhanced regular LIGGGHTS capabilities by some special sensor functions. Different shaped RegionSensors can be used to evaluate the number and mass of particles in a specific volumetric region. Sensor position and size can change during
simulation runtime. Its also possible to attach sensors to
rigid bodies. One use case would be the measurement of
bucket filling level during the digging process of an excavator.
To check if a particle is inside a specific region we use
a very simple and efficient algorithm. Consider theres a
cuboid region sensor with the position vector xS , orientation matrix RS and dimensions lx, ly and lz. Now we want

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132895

Session 11C: Mechanical Systems, Robotics & VR

to find out if a particle P is inside the sensor region. First
thing we have to do is calculating the absolute difference
vector of the particles global position xP and the position
of the sensor xS (eq. 1). After that we transform this absolute difference vector into the relative coordinates of the
sensor (eq. 2).
xPSabs = xP  xS
xPSrel = RS  xPSabs

(1)
(2)

To determine if the particle is inside or not we have to
check the following logic equation.
insidecuboid =|xPSrel ,x | < 0.5  lx 
|xPSrel ,y | < 0.5  ly 
|xPSrel ,z | < 0.5  lz

Figure 6. Excavator simulation

(3)

For spherical region sensors equation 2 can be omitted.
Checking is done as shown in equation 4 where r is the
radius of the sphere.
insidesphere =|xPSabs ,x | < r 
|xPSabs ,y | < r 
|xPSabs ,z | < r

(4)

Just mention that theres a second sort of sensors called
FlowSensors. They are used for measuring the number
and mass of particles passing two dimensional surfaces.
Computation algorithm for these kind of sensors is basically the same like for contact detection und shouldnt be
explained here.

6

which the truck was being loaded with during the simulation. For the ParticleSource it is also possible to chose
a predefined material of the database. Additionally, the
feature is demonstrated that accelerated, rotating and automatically increasing simulation rooms are supported during co-simulation. With the RegionSensors the number of
particles and the mass of the load can be evaluated which
interacts with the CADParts. The ground is a Plane for
the DEM simulation without any feedback to the system
simulation.

Use cases

6.1 Bucket Excavator
As first use case a bucket excavator digging a hole should
be simulated. The excavator itself was modeled as multibody system, which can easily be extended by hydraulic
or electric components. For all parts which should interact
with the granular material  in this case just the bucket 
the new library component CADPart was used. As next
step as pit of size 6.0 x 2.0 x 1.0 meters was generated
by using the PitGenerator element. The new library has a
direct interface to a database containing predefined materials, as described in section 4.2. So, the material chosen
for the pit was gravel. Figure 6 shows the 3D view of a
running simulation. As you can see particles are visualiR
zed directly in SimulationX
.

6.2

Loaded Truck

The in figure 7 shown model of the truck allows to determine the hydraulic forces in the main cylinder of the truck
during the loading and unloading of bulk material by taking the elastic suspension into account. It is also possible to determine the influence of the moving bulk material
of the drivability during different maneuvers and demonstrates additional features and the capabilities of the developed library. In the background is a ParticleSource,
DOI
10.3384/ecp17132895

Figure 7. Loaded truck simulation

7

Conclusion and Outlook

In this work, a new concept was presented allowing the
closed modelling of machine models and discrete element
systems in one simulation tool. For that the commandoriented modeling technique many DEM applications
work with was transferred into an object-oriented design
approach. This approach allows to perform DEM simulations for inexperienced users who are not familiar with
the DEM. But even for very experienced users, the new
library will make it much easier to build up DEM models,
run coupled simulations and analyze and document the results.
R
By supporting additional LIGGGHTS
features and
additional wizards the modeling could be simplified, the
possibilities expanded and the usebility of DEM models
improved.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

899

A New Object-Oriented Approach for Integrating Discrete Element Method into Modelica

R
Additional LIGGGHTS
features could be the brea- Gnther Kunze, Andre Katterfeld, Christian Richter, Hendrik
Otto, and Christian Schubert. Plattform- und Sofwareunabking and bonding of material. This field of DEM sihngige Simulation der Erdstoff-Maschine Interaktion. In 5.
mulation and the determination of the appropriate mateFachtagung
Baumaschinentechnik, Dresden, Germany, Seprial parameters is currently the content of some researchtember 2012.
projects. But the results of that projects are far away to
be used in coupled simulation. Additional wizards could
be developed for example to allow the user to vary material parameters, create their own materials, or generate
a multisphere body. Furthermore, the analysis possibiliR
ties of the LIGGGHTS
results in SimulationX could be
expanded further in order to increase the added value of
the coupled simulation. For this and for all other enhancements, we are looking forward to the feedback of future
users and interested parties.

Acknowledgements
This work is part of the project DEM-4-X funded by
the BMWi (Federal Ministry for Economic Affairs and
Energy, Project No.: 2055606KM4). The authors are deeply grateful for the financial support.

References
Torsten Blochwitz, Martin Otter, Johan kesson, Martin Arnold, Christoph Clau, Hilding Elmqvist, Markus Friedrich,
Andreas Junghanns, Jakob Mau, Dietmar Neumerkel, Hans
Olsson, and Antoine Viel. Functional Mockup Interface 2.0:
The Standard for Tool independent Exchange of Simulation
Models. In Martin Otter and Dirk Zimmer, editors, Proceedings of the 9th International Modelica Conference, Munich,
Germany, September 2012. doi:10.3384/ecp12076173.
Peter Coad and Edward Yourdon.
1991.

Object oriented analysis.

Peter A. Cundall. A computer model for simulating progressive, large-scale movements in blocky rock systems. In Proc.
Symp. Int. Rock Mech., volume 2, Nancy, 1971.
Hilding Elmqvist, Axel Goteman, Vilhelm Roxling, and Toheed
Ghandriz. Generic Modelica Framework for MultiBody Contacts and Discrete Element Method. In Peter Fritzson and
Hilding Elmqvist, editors, Proceedings of the 11th International Modelica Conference, Versailles, France, September
2015. doi:10.3384/ecp15118427.
Marcus Geimer, Thomas Krger, and Peter Linsel. CoSimulation, gekoppelte Simulation oder Simulationskopplung? Ein Versuch der Begriffsvereinheitlichung. O+P
Zeitschrift fr Fluidtechnik - Aktorik, Steuerelektronik und
Sensorik, 50(11-12):572576, 2006.
Christoph Kloss and Christoph Goniva. Open Source Discrete Element Simulations of Granular Materials Based on
Lammps, volume 2, pages 781788. John Wiley & Sons,
Inc., Hoboken, NJ, USA, 2011. ISBN 9781118062142.
doi:10.1002/9781118062142.ch94.
Gnther Kunze, Andre Katterfeld, and Tina Grning. Simulation maschineller Erdbauprozesse. In 15. Fachtagung Schttgutfrdertechnik, Munich, Germany, October 2010.

900

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132895

Modeling and Simulation of Wheel Driving Systems based on
Terramechanics for Planetary Explanation Rover using Modelica
Hiroki Yoshikawa1
1 Mechanical

Takatsugu Oda1

Kenichiro Nonaka1

Kazuma Sekiguchi1

Systems Engineering, Tokyo City University, Japan, {g1681237, g1591201, knonaka,
ksekiguc}@tcu.ac.jp

Abstract
Planetary exploration rovers have to accomplish various
missions on uneven and loose terrain. In recent years,
systems of rovers adopting terramechanics which determine the force and moment characteristics of the wheel
on loose soil is studied. In this study, using Modelica language, we construct a wheel model based on terramechanics, and we identify the wheel characteristics as a linear
for a control. We conduct a numerical simulation of the
rover using a controller including the identified longitudinal force model. It is shown that when the rover follows a
straight line on a plane, the longitudinal force model identified using known soil parameters has sufficient accuracy
on the wheel response based on terramechanics and could
be used as a control model. Keywords: terramechanics,
modeling, identification, space robots, control system

1

Introduction

In recent years, research and development of planetary exploration rovers in various configurations have been carried out to investigate the planets. Planetary exploration
rovers have to achieve a stable traveling on uncertain and
severe terrain. The planet surface is covered with fine deposits, called regolith, and uneven terrain such as craters
and rocks. Various planetary exploration rovers have been
developed which is equipped with, for example, wheel
mechanisms with suspensions to adapt to the planetary
surface, crawler mechanisms to enhance the drawbar pull
or leg mechanisms to climb over steps (Seeni et al., 2008).
Also, NASA is planning to operate a hybrid rover "ATHLETE" which is equipped with wheel and leg mechanisms.
When rovers move on planetary surface, it is important to take into account of terramechanics which governs a relation between soft soil and the driving system
of rovers. In order to analyze the effect of the soil, a semiempirical model proposed by Bekker using the experimental results and a model using Discrete Element Method
(DEM) without dependence on wheel parameters are studied (Nakashima et al., 2010). Combining DEM with Finite
Element Method (FEM), the simulation using Soil Contact
Model (SCM) of Multi-Body System (MBS) which analyzes the more detailed soil movement is proposed (Krenn
and Gibbesch, 2011). The deformation of soil and the opDOI
10.3384/ecp17132901

timal wheel shape are analyzed through these simulations
to consider efficient travel on loose soil. However, it is not
suitable for the motion analysis of the rover, since it takes
large calculation time with FEM and DEM which handle
huge complicated elements in order to ensure reasonable
accuracy (Taheri et al., 2015).
As for the studies about the control based on terramechanics, designing path (Ding et al., 2014) and analysis
of traveling performance while ascending (Ishigami et al.,
2007) is conducted. A slip ratio control of the wheels on
loose soil using sliding mode control for the rover model
considering terramecahnics is proposed (Gu et al., 2007).
In addition, another slip ratio control of the wheels using
PID control to adapt the parameters of terrain surface is
studied (Iagnemma and Dubowsky, 2004).
While it is desirable to conduct experiments in space
environments to verify these models, computer simulations are preferred considering huge cost. However, it
is difficult to compensate for the differences of planetary
environments like gravitational field and so on (Pulecchi
and Lovera, 2006). To conduct a simulation with minimized the error between the simulation model and the actual equipment is minimized, it is extremely effective for
comprehensive analysis through the more detailed rover
model and contact model of loose soil. The simulations
using Modelica language and modeling tool of physical
domains attract a lot of attention. We do not need to care
about causality to create the wheel model based on terramechanics such as slip ratio, sideslip angle and velocity
of wheel, since Modelica is an equation based language.
These features enable us to combine the wheel and rover
model effectively.
In previous our study, we conduct simulations considering the space environment using the fundamental control system and the robot model designed by Modelica.
In this study, using Modelica language we design a rover
model equipped with the terramechanics model to conduct a simulation with more detail model. We identify
the identified model which expresses the relationship between input torque and longitudinal force based on the
simulation results of the terramechanics model. Becasue the terramechanics model is too complex to use in
a controller, we design the motion controller using the
identified model. We evaluate the effectiveness of identified model through numerical simulations. Therefore,

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

901

Modeling and Simulation of Wheel Driving Systems based on Terramechanics for Planetary Explanation
Rover using Modelica

z

z



y

r

x

W

vx

Limb 3

f

r

x


m

h

Limb 2

 x ( )

h

Limb 1

Limb 4

 ( )
Limb 5

Limb 6

Figure 1. Leg-wheel mobile robot model with six joints of each
limb.

Figure 2. Normal stress and shear stress distribution concept of
terramechanics while rolling (Ishigami et al., 2007).

 Lateral and vertical dynamics of wheels are not considered.

the identified model approximates the characteristics of
the terramechanics model.
Figure 2 depicts the geometry of the wheel model based
on these assumptions; the empirical equation is described
2 Modeling controlled object
in the following section.

2.1

Leg-wheel mobile robot model

2.2.2 Entry and exit angle of wheel

Figure 1 depicts a rover model of the controlled object
(Yoshikawa et al., 2016). We use a lunar exploration
rover "ATHLETE" developed by NASA/JPL as a reference model (Wilcox et al., 2007). This rover is equipped
with six limbs with six joints while wheels achieve a high
movement performance and accommodate a wide range of
tasks using the redundancy. We create this rover model by
using Modelica language to control the degree of freedom
of the leg-wheel mechanisms with similar movements of
ATHLETE. The coordinate system of the rover is attached
at the center of the body. The limb has a number to be
distinguished from the others in this coordinate system, as
depicted in Figure 1.

The forces generated from the wheel are calculated by
integrating a stress distribution developed between the
wheel and terrain surface. Entry angle f and exit angle
r are introduced in order to decide the dynamic contact
area of the wheel. The entry angle and exit angle are defined as follows:

2.2

2.2.3 Specific wheel angle m

2.2.1

Wheel model based on terramechanics
Assumptions of the wheel model

We introduce terramechanics to the wheel model of the
controlled objects. We make reference to semi-empirical
model (Ishigami et al., 2007) (Wong, 2001) to the wheel
model based on terramechanics. Figure 2 depicts the rigid
wheel rolling on loose soil. The assumptions of the wheel
model are as follows:

h
f = cos1 (1  ),
r

h
r = cos1 (1 
),
r

(1)
(2)

where h is the sinkage of wheel and  is the volume ratio
of soil.
The normal stress distribution  (the blue curve in Figure 2) arises in the normal direction of the wheel while
rolling. This normal stress distribution is approximated
by the parabolic curve. The maximum stress angle m is
an angle at which the value of normal stress is maximum
as follows:

m = (a0 + a1  )f ,

(3)

 The contact surface between wheels and the ground where a , a is a constant value and  is slip ratio. Slip
0 1
is flat.
ratio is represented by using a translational velocity of the
wheel vx and angular velocity of the wheel  :
 Radius r and width b of wheel have enough rigidity.
 (
)
r   vx


 Wheel rotation does not affect a frontal soil.
(r > vx )

r )
(
=
(4)
r   vx


 The frontal soil is constricted and released at the rear
(r < vx ).

vx
of the wheel.
902

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132901

2.2.4

Longitudinal force Fx [N]

Session 11C: Mechanical Systems, Robotics & VR

Normal stress distribution model based on
bekkers equation

The normal stress distribution model  ( ) based on soil
pressure equation proposed by Bekker is divided into two
areas: the front parts of the specific wheel angle f ( )
(m   < f ) and the rear parts r ( ) (r <   m ). The
normal stress distribution model of the wheel is defined as
follows:
)
(
n kc
f ( ) = r
+ k [(cos   cos f )]n ,
(5)
b
)
(
kc
r ( ) = rn
+ k
b
[
]n
  r
cos{f 
(6)
(f  m )}  cos f ,
m  r

500
400
300
200
100
0
0
100
200

0.1

0.2
0.3
Slip ratio  []
300
500
400
600

0.4

0.5

700
800

Figure 3. Relationship between slipratio and longitudinal force
with respect to load of the wheel.

2.2.7 Longitudinal characteristics

Figure 3 shows longitudinal force Fx with respect to the
slip ratio of the wheel when the load of it increases every
where kc is pressure-sinkage module depending on the vis- force 100 N within 100 N  800 N. As the slip ratio incosity, k is pressure-sinkage module depending on the creases, the longitudinal force is saturated as Figure 3 infriction and n is the sinkage exponent depending on sink- dicates. In addition, as indicated in Figure 3, for the same
age of soil.
slip ratio, the longitudinal force generated by the wheel
depends on the load. It indicates that the increasing ratio
2.2.5 Shear stress model of wheel
of Fx decreases as the load grows.
Shear stress model is defined as follows:

 = max (1  e j/k ),
max = c +  tan  ,

(7) 3
(8) 3.1

where c is the cohesion stress of the soil,  is the internal
friction angle of the soil, j is the soil deformation and k
is the shear deformation modules. The shear stress of x
direction x is obtained by assigning  to Eq. (8):

x = (c +  ( ) tan  )(1  e jx ( )/kx ),

(9)

where kx is the shear deformation modules of x direction
and jx is the soil deformation of x direction as follows:
jx ( ) = r[f    (1   )(sin f  sin  )].
2.2.6

(10)

Vertical and longitudinal force of wheel

The vertical force Fz which is equal to the load of the
wheel is calculated by the summation of the normal and
shear stress of z direction as follows:
Fz = rb

 f
r

{x ( ) sin  +  ( ) cos  } d .

(11)

The normal and shear stress of the wheel can be calculated
using the each contact angle f and r determined by the
sinkage of the wheel h. Then, the longitudinal force is
calculated by the summation of normal and shear stress of
x direction as follows:
Fx = rb

 f
r

{x ( ) cos    ( ) sin  } d .

(12)

The rolling resistance torque Tx is calculated using the
shear stress as follows:
Tx = r2 b
DOI
10.3384/ecp17132901

 f
r

x ( ) d .

(13)

Identification of the wheel model
Identified model

In this section, to design a rover controller in which the
identified model is additionally used, we identify the longitudinal force of the terramechanics model. We approximate the longitudinal force generated at the wheel by a
linear first-order system. A step wheel torque is imposed
on the wheel, then the wheel response data on the longitudinal force and the slip ratio is sampled. The identified
longitudinal force model is depicted in Figure 4. The identified model is separated into two blocks: one for calculating the slip ratio by the wheel torque and the other for
calculating the longitudinal force by the slip ratio. This
separation helps to capture the feature of the physical relationship.
In the wheel model based on terramechanics, the wheel
sinkage which depends on load is decided by the optimization. In order to identify the longitudinal force corresponding to the load change, we represent the parameters of the first order system using a look up table (LUT).
Using the LUT in the identified model, we can consider
the generated force due to influences of soil deformation
caused by load change. Firstly, the gain KLUT and the time
constant TLUT are decided using the LUT. The reference
values of the LUT are the wheel load W and wheel torque
Tw . Secondly, the relationship between slip ratio  and
longitudinal force Fx with respect to load change is depicted in Figure 5. Each point in this Figure represents the
reference results of the terramechanics model. To express
these relationships in an equation, we approximate it as
follows:
Fx (W,  ) = a(W ) + b(W ),

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

(14)
903

Modeling and Simulation of Wheel Driving Systems based on Terramechanics for Planetary Explanation
Rover using Modelica

Load W

Load W

Torque Tw

K LUT (Tw , W ) / Tw
TLUT (Tw , W ) s + 1

Longitudinal
force Fx

Slip ratio 

a (W ) + b(W )

Figure 4. Identification model from wheel torque to longitudinal force of wheel.

Load

275 N

575 N

875 N

Precision

82.1%

96.8%

96.2%

50
Longitudinal force Fx [N]

Table 1. Precision of identified model to responce of wheel
baced on terramechanics in the load 275, 575, 875 N.

30
20
10
0
0.05 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45

where a(W ) and b(W ) are the coefficient derived from
the quadratic expressions with respect to load change, as
shown in Figure 6 and Figure 7, respectively.

3.2

40

100
200

300
400

Slip ratio  []
500
600

700
800

Verification of identification model
Figure 5. Reference results of the terramechanics model of

Coefficient a []

It is noted that the idetified model using LUT is an ap- slip ratio and longitudinal force obtained by step input of wheel
proximation which essentially includes interpolation error. torque and linear approximation of them.
Figure 8 indicates the longitudinal force obtained by the
wheel based on terramechanics and the identified model
3000
of it in the load W = 575 N which is the interporated re2500
gion. A precision of identified model is calculated using
2000
the following equation:
1500
1000



500
N
k=1 [y(k)  y(k)]2
0


Fit = 1  
 100,
(15)
500
N
2
k=1 [y(k)  y]
0
200
400
600
800
1000
Vertical load W [N]

where y(k) is the output of identified model, y(k) is the
output obtained by the controlled object, y(k) is the average of it and N is the number of data. In the case that
the load is not the reference results of the teramechanics
model, for example W = 275, 575, 875 N, the precision for
the step response of the wheel torque is shown in Table 1.
As a result, all of the precision is over 82%. If you need
to increase the precision, the degree of the approximate
expression will be changed more high degree. Therefore,
the identified model sufficiently approximates the longitudinal force of the wheel even when the LUT refers to the
interpolated load.

4

Simulation

Figure 6. Coefficient a of polynominal.

controller system: the identified model in section 3 is used
as the control model to calculate a wheel torque from a
velocity controller. Then, the torques are imposed on the
rover model (plant model in section2). The system calculates the wheel torque by feedback control so that the rover
achieves the target velocity. In vehicle motion controller,
we regard the rover as a mass point model for calculating the rover force on the CoG. To achieve the designed
motion, it is assumed that each wheel generate the same
longitudinal force as follows:

In this section, to evaluate the accuracy of the identified
Fx, all /6 = fw, i ,
(16)
model for the rover, we design the controller system using
the identified model, and confirm the response through the where Fx, all is whole longitudinal force of the rover, fw, i
is longitudinal force of each wheel and subscript i = 1  6
numerical simulation.
indicates the limbs number. Each wheel torque Tw, i is
4.1 Controller design
calculated using the inverse identified longitudinal force
To verify whether the rover model with terramechan- model. Then, to realize the inverse model which is the
ics wheel model could be controlled using the identified linear first order system, we add the second order filter in
model through the numerical simulation, we construct the front of it so that the model become the strictly proper
904

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132901

Session 11C: Mechanical Systems, Robotics & VR

Load W
Target position xt,Body
Target velocity vt,Body
+

Longitudinal
force Fx ,all

Vehicle
motion
controller



Inverse
identification
model

Torque Tw,i

Rover
model

Position xBody
Velocity vBody

Coefficient b []

Figure 9. Controller system.
Table 2. Parameter of rover, wheel and soil.

50
45
40
35
30
25
20
15
10
5
0
0

200

400

600

800

1000

Vertical load W [N]

Longitudinal force Fx [N]

Figure 7. Coefficient b of polynominal.
50
40
30
20
10
0
10
20
30
40

identification model
terramechanics
0

1

2

3

4

5

6

7

model. Using the inverse model, we verify the simple
characteristics of the identified model when the model is
applyed to the rover model. The filter is defined as follows:
(17)

where n is natural angular frequency and set to be
342 rad/s. The calculated wheel torque is imposed on each
wheel of the rover model which indicates the right block
depicted in Figure 9.

Simulation conditions

To verify the response of the wheel model, we conduct
a simulation that the rover tracks the target velocity on a
plane while keeping the initial posture of the rover. The
reference path is the straight line including an accelerattion areas. In this simulation, we assume that the lunar
surface is covered with regolith uniformly. The parameter of rover mass, target value, soil and wheel shape are
indicated in Table 2 (Ishigami et al., 2007).
DOI
10.3384/ecp17132901

Unit

Rover mass M
Target position xt,Body
Target velocity vt,Body
Wheel radius r
Wheel tread b
Cohension stress c
a0
a1
Pressure-sinkage module kc
Pressure-sinkage module k
Soil deformation module kx
Sinkage exponent n
Friction angle 
Wheel sinkage ratio 

1570
1.0time
1.0
0.355
0.175
0.80
0.4
0.15
1.37103
8.14  105
0.036
1.0
37.2
0.90

kg
m
m/s
m
m
kPa
N/mn+1
N/mn+2
m
deg
-

4.3

Figure 8. Example of comparisom foward identified model with
terramechanics wheel model (W = 575 N).

4.2

Value

8

Time [s]

n2
,
s2 + 2n s + n 2

Parameter

Results and discussions

The simulation results using the identified model are
shown in Figure 10. Since the rover moves on a straight
line and arranges a symmetric leg position in this simulation condition, we plot the results of the Limb1  3. Figure 10 (a) through (h) depict the wheel torque, the wheel
resistance torque, the vertical force of each wheel, each
wheel sinkage, the slip ratio of each wheel, the longitudinal force of each wheel, the velocity of the rover and the
desired longitudinal force, respectively.
As shown in Figure 10 (a), the identified model calculates the wheel torque considering the influence of resistance torque, so that the rover enable the wheel to drive
smoothly. It is because the controller implicitly considers
the effect of resistance which is depicted in Figure 10 (b).
The inertia force due to the acceleration influences that
the load distribution of the wheel biases backward of the
rover. As a result, Figure 10 (c) indicates that, during
the acceleration, the vertical force of the Limb 3 increases
while that of the Limb 1 decreases. The load change affects the change of the wheel sinkage h as depicted in Figure 10 (d). The wheel sinkage h is adapted to the vertical
force, so that the physical adequacy of the wheel model
based on terramechanics can be confirmed. The wheel
torque is calculated using the identified model, so that

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

905

Modeling and Simulation of Wheel Driving Systems based on Terramechanics for Planetary Explanation
Rover using Modelica
Table 3. RMS error of longitudinal force.

RMS error

Limb 1

Limb 2

Limb 3

0.7 N

0.4 N

0.5 N

6

Acknowledgments

The authors gratefully acknowledge the support of Grant
in Aid for Scientific Research (C) No.15K06155 of Japan.

References
the wheel arises the different slip ratio, as shown in Figure 10 (e). Accordingly, the longitudinal force of the each
wheel is generated uniformly as depicted in Figure 10 (f)
even when the load of the each wheel is different. Figure 10 (g) indicates that the rover accelerates until the
translational velocity reaches 1.0 m/s. Figure 10 (h) depicts the actual and desired longitudinal force of limb 1
as a representative example. Table 3 shows the RMS error between the actual and desired longitudinal force in
limb 1  3. This difference in the longitudinal force is
caused by the approximation error of the identified model.
The precision of the identified model tends to lower as the
load decreases, as shown in Table 1. Thus, since the load
of Limb 1 decreases during the acceleration, the RMS error becomes the largest. The maximum longitudinal force
reaches about 30 N. Nevertheless, all RMS error is below
1.0 N. Although the actual longitudinal force is not equal
to the desired, the influence is adequately suppressed by
the feedback control.

Liang Ding, Hai-bo Gao, Zong-quan Deng, Zhijun Li, Ke-rui
Xia, and Guang-ren Duan. Path-following control of wheeled
planetary exploration robots moving on deformable rough
terrain. The Scientific World Journal, 2014, 2014.
Kanfeng Gu, Yingzi Wei, Hongguang Wang, and Mingyang
Zhao. Dynamic modeling and sliding mode driving control
for lunar rover slip. In Integration Technology, 2007. ICIT07.
IEEE International Conference on, pages 3641. IEEE, 2007.
Karl Iagnemma and Steven Dubowsky. Traction control of
wheeled robotic vehicles in rough terrain with application to
planetary rovers. The international Journal of robotics research, 23(10-11):10291040, 2004.
Genya Ishigami, Akiko Miwa, Keiji Nagatani, and Kazuya
Yoshida. Terramechanics-based model for steering maneuver of planetary exploration rovers on loose soil. Journal of
Field robotics, 24(3):233250, 2007.
Rainer Krenn and Andreas Gibbesch. Soft soil contact modeling technique for multi-body system simulation. In Trends in
computational contact mechanics, pages 135155. Springer,
2011.

Each wheel can generate the desired longitudinal force
due to calculating the wheel torque corresponding to load H Nakashima, H Fujii, A Oida, M Momozu, H Kanamori,
change. Moreover, through the use of the identified model,
S Aoki, T Yokoyama, H Shimizu, J Miyasaka, and K Ohdoi.
Discrete element method analysis of single wheel perforthe wheel torque considering the influence of loose soil
mance for a small lunar rover on sloped terrain. Journal of
can be obtained without the optimal calculation for a deTerramechanics, 47(5):307321, 2010.
cision of the wheel sinkage. Therefore, it is shown that
the identified longitudinal force model based on the more Tiziano Pulecchi and Marco Lovera. A modelica library for
detailed model has the high accuracy when the model is
space flight dynamics. In In Proceedings of the 5th Interapplied to the rover controller.
national Modelica Conference. Citeseer, 2006.

5

Conclusions

In this paper, we construct the wheel model based on terramechanics derived from semi-empirical model by using
Modelica language. In order to consider the longitudinal
force of the constructed wheel model, we approximate it
by the linear first order system. Designing the controller
using the identified model, we investigate the influence on
driving systems of the rover moving on loose soil. The
simulation results indicate that the identified model can
adapt the influence of load change and consider the soil
deformation, so that the identified model has a high accuracy. With reference to the model used in the control,
it is important to simplify the structure and identify the
characteristic. Consequently, the use of the identified longitudinal force model contributes to a control design for
the rover.
As for the problems to be solved from now on, to enhance the mobility on loose soil, the lateral force of the
wheel should be identified to design a controller.
906

Aravind Seeni, Bernd Schafer, Bernhard Rebele, and Nikolai
Tolyarenko. Robot mobility concepts for extraterrestrial surface exploration. In Aerospace Conference, 2008 IEEE, pages
114. IEEE, 2008.
Sh Taheri, C Sandu, S Taheri, E Pinto, and D Gorsich. A technical survey on terramechanics models for tireterrain interaction used in modeling and simulation of wheeled vehicles.
Journal of Terramechanics, 57:122, 2015.
Brian H. Wilcox, Todd Litwin, Jeff Biesiadecki, Jaret Matthews,
Matt Heverly, Jack Morrison, Julie Townsend, Norman Ahmad, Allen Sirota, and Brian Cooper. ATHLETE: A cargo
handling and manipulation robot for the moon. Journal of
Field Robotics, 27(5):421434, 2007.
Jo Yung Wong. Theory of ground vehicles. John Wiley & Sons,
2001.
Hiroki Yoshikawa, Takatsugu Oda, Kenichiro Nonaka, and
Kazuma Sekiguchi. Modeling and simulation for leg-wheel
mobile robots using modelica. In The First Japanese Modelica Conferences, May 23-24, Tokyo, Japan, number 124,
pages 5560. Linkping University Electronic Press, 2016.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132901

Session 11C: Mechanical Systems, Robotics & VR

40

30

Limb 1
Limb 2
Limb 3

0.06
0.05

Slip ratio  []

Input torque Tw [Nm]

0.07

Limb 1
Limb 2
Limb 3

35

25
20
15
10

0.04
0.03
0.02
0.01

5

0

0

0.01

5

0.02
10

20

30

40

50

60

70

80

10

20

30

40

Time [s]

60

70

80

25

70

80

(e) Slip ratio of each wheel.

50

Limb 1
Limb 2
Limb 3

20

Longitudinal force Fx [N]

Rotation resistant torque Tx [Nm]

(a) Wheel torque of each wheel.

15
10
5
0

Limb 1
Limb 2
Limb 3

40
30
20
10
0
10

10

20

30

40

50

60

70

80

10

20

30

Time [s]

40

50

60

Time [s]

(b) Rolling resistance torque of each wheel.

550

(f) Longitudinal force of each wheel.

1.2

Limb 1
Limb 2
Limb 3

500

1
0.8

vbody [m/s]

Vertical force Fz [N]

50

Time [s]

450
400

0.6
0.4
0.2

350
0
300

0.2
10

20

30

40

50

60

70

80

10

20

30

Time [s]

50

60

70

80

Time [s]

(c) Vertical force of each wheel.

0.02

(g) Velocity of rover model.

50

Limb 1
Limb 2
Limb 3

Longitudinal force Fx [N]

Sinkage of wheels h [m]

40

0.018

0.016

0.014

0.012

Limb 1
Fall/6

40
30
20
10
0
10

10

20

30

40

50

60

Time [s]

(d) Sinkage of each wheel.

70

80

10

20

30

40

50

60

70

80

Time [s]

(h) Actual and desired longitudinal force of limb 1.

Figure 10. Rover driving simulation using longitudinal force model considring terramechanics for driving force distribution.

DOI
10.3384/ecp17132901

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

907

908

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132

The Jet Propulsion Library: Modeling and simulation of aircraft
engines
Michael Sielemann1

Anand Pitchaikani2

Nithish Selvan2

Majed Sammak3

1 Modelon
2 Modelon

Deutschland GmbH, Germany, michael.sielemann@modelon.com
Engineering Pvt. Ltd., India, {anand.pitchaikani,nithish.selvan}@modelon.com
3 Modelon AB, Sweden, majed.sammak@modelon.com

Abstract
The Jet Propulsion Library is a new Modelica library that
provides a foundation for modeling and simulation of jet
engines, and the model-based design of integrated aircraft
systems. It provides a fully rigorous foundation for sizing
and performance computations, and provides a number of
advantages over existing domain-specific solutions due to
the use of the Modelica language. This paper provides an
introduction and overview of the library and describes an
application in the design of a turbo fan engine.
Keywords: Turbo fan, turbo jet, turbo prop, turbo
shaft, performance, model-based design, sizing, secondary power

1

Introduction

The prime mover of an aircraft, the jet engine, is one of
the most important subsystem of an aircraft. Jet engines
provide primary power (thrust) and secondary power (to
drive flight control, air conditioning, cabin lighting and
so on) to the aircraft. Recently, the improvements in the
performance and efficiency of jet engines deliver a very
large share in the overall platform improvements (for both
commercial and military aircraft where for instance super
cruise requirements were met). They therefore strongly
affect aircraft value and, in case of commercial aircraft,
eventually airline competitive edge. The latter is not only
driven by costs, but even more so by environmental regulations.
However, these power plant improvements become increasingly difficult to achieve when focusing on the engine in isolation. The reason is that the local improvement
potential has largely been leveraged in previous incremental design improvements, and only changes on global aircraft level remain to substantially improve the total aircraft package. For this reason aeronautical systems such
as aircraft and their subsystems are becoming more and
more integrated. This integration takes place along a
number of trends. We mention two of these. The first
one is the electrification of secondary power on-board aircraft (Provost, 2002). This trend is also called the More
Electric Aircraft and has shaped industry road maps since
more than two decades. Historically, three different types
of secondary power were equal, namely, electric power,
DOI
10.3384/ecp17132909

hydraulic power, and pneumatic power. With the More
Electric Aircraft this is changing in favor of electric
power. The main reason lies in the anticipated development potential of power electronics, which is all but exhausted (like that of pneumatic and hydraulic power).
The second trend is more recent and is the electrification of primary power. This is getting increasing interest
due to intrinsic limitations in turbofan technology (Kyprianidis et al., 2014) (be it geared or ungeared). Following (Winter, 2013), the overall efficiency of a propulsion
system can be considered to be proportional to the product of thermal and propulsive efficiency. To achieve thermal efficiency improvements, the Overall Pressure Ratio
(OPR) and the Turbine Entry Temperatures (TET) of the
cycles are being increased in an incremental way since the
last few decades and are approaching peak values (approximately 1900-2000K TET and around 45-50 cycle OPR).
Material limits, turbine cooling, emissions, and losses in
the last stage of the high pressure compressor may now
impose fundamental limits to the thermal efficiency. Improvements in propulsive efficiency are well achievable
via reduction in fan pressure ratio and increases in bypass ratio. However, these improvements are deteriorated by losses through lowered transmission efficiency,
increased nacelle weight and higher drag due to larger
frontal area (Larsson et al., 2011). When these limits indeed turn out to become fundamental ones, different and
more integrated concepts will become of interest. For instance electric ones where power is stored in one way or
another on-board and possibly converted to electric power
by gas turbines or fuel cells and used to drive distributed
propulsion devices. Such aircraft with partially or fully
electrified primary power systems are called hybrid or
fully electric aircraft.
It is critical that the methods and tools supporting the
design of such systems keep pace with the increasing integration on the product side. Only with efficient and
robust prediction capabilities it becomes possible to establish model-based design for such solutions introducing
new technologies, and cover all relevant what if scenarios.
It is therefore evident that if future propulsion systems
and technology are to achieve the environmental challenges and performance targets set, rigorous mathematical

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

909

The Jet Propulsion Library: Modeling and simulation of aircraft engines

analysis of the component physics as well as integrated
subsystem physics is important. There exists a critical requirement to develop and adapt models at an appropriate
level of fidelity to specific components. One of the key requirement is also to have a generic framework where the
user will be able to choose components and characteristics
of his choice before integration of the subsystem.
Given the importance of propulsion system simulation
as an academic and industrial engineering discipline, the
literature on the state of the art is too extensive to be
reviewed here. We therefore focus on selected references and tools. First, Gasturb (Kurzke, 1995) is a userfriendly and powerful domain-specific system simulation
software for gas turbines. It is mature and provides extensive functionality, but also restricted to the scope defined by the authors. The model equations as implemented
in the software can hardly be accessed and adapted by
the user. Integration with other simulation and design
models is possible but mostly requires process integration and design optimization (PIDO) solutions1 . EnVironmental Assessment (EVA) (Kyprianidis et al., 2008) is
an example of a domain-specific simulation software with
widened scope (engine system simulation and some aspects of aircraft sizing). Similar to Gasturb it is restricted
to the application scope envisioned by its original programmers however. Numerical Propulsion System Simulation (NPSS) (Nichols and Chamis, 1991; Lytle, 1999;
Jones, 2007, 2010) covers more than system simulation, as
it also works as integration hub between system and field
simulation. It can also be labeled as a domain-specific
software but it relies on an object-oriented (yet causal)
custom language in which component models are written. Model equations as implemented can be accessed and
adapted by the user. Integration can also be established
via PIDO solutions, but alternatively non-propulsion subsystems can be modeled in the native NPSS language and
be integrated in a computationally more efficient and robust manner than via PIDO solutions. PRopulsion Object Oriented SImulation Software (PROOSIS) (Alexiou
and Mathioudakis, 2005; Bala et al., 2007) is a similar
system simulation software. It provides the same benefits in terms of access and customization (albeit using an
acausal language), and also allows integration using nonPIDO approaches. A number of modeling libraries for
non-propulsion sub-systems have been mentioned informally but not documented in the literature (according to
the knowledge of the authors). In any case, a main limitation of this platform is the use of an in-house modeling
language, which is not widely adopted or openly standardized via a non-profit organization.
While connecting a wide array of tools for multidisciplinary design optimization of aircraft and sub1 Process Integration and Design Optimization software typically
contains numerous CAD/CAE integration adapters that allow the user
to link different computation software in a GUI. They often also provide convergence, optimization, and surrogate modeling functionality,
which allows to automate analysis and design processes.

910

systems is feasible, integrating in a less fragile way based
on open standards such as Modelica and FMI would increase flexibility and allowed to substantially increase
manageable problem size due to higher computational efficiency. Other proposed interfacing standards such as
ARP 4868 (SAE, 2001) are domain specific and work well
for model-based efforts in their respective disciplines but
not to couple analyses for unconventional designs. However, up to now nobody has proposed a plausible modeling library in Modelica for jet engines. Such a library
could eventually be integrated one into a framework for
modeling and simulation of aircraft and their components.
This enabled time and resource efficient implementation
of model-based design processes via reuse of such model
assets; a key enabler for model-based design. Additionally, this improved consistency of results.
The objectives of this paper are
1. To suggest a library for modeling and simulation of
aircraft jet engines and their sub-systems in Modelica for a broad range of applications ranging from
engine and sub-system conceptual design to detailed
analysis and design involving transient and real-time
simulation2 .
2. To substantiate why the library can plausibly be applied to industrial-scale problems involving complex models and sophisticated analyses
3. To apply the framework to an engineering problem,
namely, the computation of the full range of cycle
performance.
4. To provide an outlook on how a Modelica implementation for modeling and simulation of aircraft
jet propulsion provides additional value over existing
discipline-specific tools in the design and analysis of
unconventional systems.

2

Jet Propulsion Library: Overview
and implementation

The Jet Propulsion Library is a modeling framework for
gas turbines and jet propulsion of commercial and military
aircraft. The comprehensive set of components enables
cycle performance analysis and optimization of all types
of aerospace gas turbines. On-design and off-design performance can be studied as well as steady-state and transient behavior based on a single model.
The physics of jet engines are governed by the balance equations of thermo-fluid dynamics, the conservation
equations of mass, energy and momentum. Thus, some
2 We restrict the scope however to only cover system simulation,
i.e., all processes governed by ordinary differential equations (ODE) or
differential-algebraic equations (DAE). Processes governed by partial
differential equations are beyond the scope of the library, unless their
partial derivatives have been suitably discretized to match the formal
framework of an ODE or DAE (e.g., one-dimensional discretization of
the balance equations of thermo-fluid dynamics).

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Session 11D: Aerospace

of the underlying principles have been documented elsewhere (Elmqvist et al., 2003; Casella et al., 2006; Franke
et al., 2009a,b). These will not be repeated here. However, given the flow velocities in such engines some assumptions commonly made in the mentioned articles are
not appropriate; for instance the assumption that the flow
velocity is small and that differences between static and
total quantities can be neglected. The following presentation describes some of the differences to the established
approaches, and gives a small example of the sophistication in its implementation to address the previously mentioned challenges.

2.1

Why Modelica

At a first glance, domain specific simulation solutions including sophisticated graphical user interfaces are very appealing. We believe however that the use of the generic
modeling language Modelica provides advantages that
may outweigh the benefits of the former.
First, this is due to the tool support to manage product
and model complexity. This relies on the object-oriented
nature of Modelica, and allows the tool to conveniently
filter what implementations fit in a placeholder on a given
model template. Manually choosing from a large library
can be surprisingly difficult as industrial size problems are
tackled. With Modelica, models can be built rapidly based
on pre-configured templates. Additionally, a model architecture can be used once implemented across the system
engineering V-cycle even as the user zooms into detailed
modeling involving dynamic and real-time analyses. This
facilitates creating and maintaining a holistic view even on
challenging systems.
Second, given the declarative and symbolic problem
description encoded in the Modelica language, a model
compiler can transform the model description (equation
system) into the form most suitable for a given analysis. This is based on automatic symbolic transformations,
and allows executing the same model as dynamic simulation, steady-state simulation, optimization, real-time simulation and so on.
Additionally (and this has already been indicated
above), using Modelica it is more straight forward to cover
all domains based on first principles. After all, Modelica
is one of the native languages of the aircraft sub-system
industry. A large community/eco-system exists based on
the Modelica language with many commercial and open
source model libraries.
Furthermore, interactions become more productive.
Based on the open standards, any given model can be
made available on multiple tools. This enables modelbased collaborations, independently whether based on
Modelica or FMI.
Finally, this approach provides full access to the models. After all, while complete documentation of black box
component models is great for many cases, reading the
actual model code including the exact equations used for
simulation in the engineering language Modelica enables
DOI
10.3384/ecp17132909

deeper understanding and customization.

2.2

Thermodynamic properties

In the following sections, the distinction between socalled static and total quantities is very important. A static
pressure ps for instance is the actual pressure in the usual
sense, which is associated not with fluid motion but with
its state. Total and dynamic pressure in turn are closely
related to fluid flow, and are a measure of flow velocity. For incompressible fluids, Bernoullis equation states
pt = ps + pd = ps + 1/2v2 . Here, pd = 1/2v2 is called
the dynamic pressure, and pt total pressure. Total quantities are sometimes also called stagnation quantities as they
correspond to the value of the static or thermodynamic
quantities if the fluid flow was brought to rest (zero velocity) in a reversible way (isentropically). As we are dealing with compressible fluids in the context of this paper,
Bernoullis equation does not hold. Instead, a compressible formulation has to be used. The details are described
in the following sections.
The thermodynamic state is always defined by the static
properties such as static temperature and pressure. These
are the actual temperatures and pressure observed in the
real world. In gas turbine performance computations it is
however a tremendous simplification to express the component level equations mostly in total or stagnation quantities (Walsh and Fletcher, 2004). Like this, the exact flow
cross section areas and velocities are not necessarily required. There are however also component models, in
which the static quantities have to be computed such as
mixers and nozzles (Walsh and Fletcher, 2004). In many
cases the static quantities are also of interest and are therefore computed in the output section (using Modelica
parlance).
In any case, the scope of the thermodynamic property
computations in the Jet Propulsion Library therefore has
to cover both static and total quantities. Additionally, to
ensure accurate predictions, this has to be done in what is
called the fully rigorous way (Kurzke, 2007). From text
books, one is tempted use the following equation to relate
the total temperature Tt and pressure pt
Tt = Ts

pt
ps

1


(1)

Or, likewise

 
pt
  1 2 1
= 1+
M
ps
2

(2)

However, the isentropic exponent  is not constant
across larger temperature or pressure ranges. Therefore,
equations (1) and (2) are strictly speaking not applicable.
Following (Kurzke, 2007; Sethi, 2008), a fully rigorous
approach based on the so-called entropy function  can
be used instead.
 (T ) =

Z T
c p dT
Tre f

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

R T

(3)
911

The Jet Propulsion Library: Modeling and simulation of aircraft engines

Then, the change of the entropy function in an isentropic
process is equal to the logarithm of the pressure ratio,
 
p2
2  1 = ln
(4)
p1
Based on this approach, we can compute the complete
set of the following six static quantities from any two of
them plus the complete set of total quantities,

 Mass flow rate w
 Cross section area Ae

replaceable partial function setTotal_pthtX
"Return total state as function of pt, ht
and composition X"
input AbsolutePressure pt
"Total pressure";
input SpecificEnthalpy ht
"Total specific enthalpy";
input MassFraction X[nS]
"Mass fractions";
output TotalState total
"Total state record";
end setTotal_pthtX;

Based on a given total thermodynamic state record any
total quantity can be computed, for instance total temperature

 Static pressure ps
 Static temperature Ts

TtIn = Medium.totalTemperature(
inlet_total);

 Mach Number M
 Flow velocity v
Then, instead of using (2), we can compute the static
pressure (and the complete set of static quantities) from
the Mach Number as follows (Sethi, 2008) (note that this
procedure requires the solution of implicit equation systems and additionally the mass flow rate as input). First,
we compute the static temperature Ts from the following
implicit equation.
p
2ht  hs (Ts )
(5)
M= p
s (Ts ) RTs
Then, the static pressure can be computed explicitly in a
fully rigorous way via the following equation
ps =
exp



pt

t  (Ts )
R

(6)

As written above, the complete set of six static quantities can be computed from any two of them (and the
total quantities). Based on which set of two static quantities is given, between zero and two numerical solutions
to implicit equations such as (5) are required to compute
the full set of static quantities. Therefore, the thermodynamic properties involving rigorous computations of total
and static quantities are somewhat different to the state of
the art in Modelica (see references above), where the need
for solution of implicit equation systems is considered a
rare case, which can often be avoided by suitable model
reformulations.
To provide convenient access to the computation of total and static thermodynamic properties we have therefore decided to use a package structure similar to Modelica.Media (Elmqvist et al., 2003) but tailored to the application specifics. First, we apply the concept of the thermodynamic state record to both total quantities (which,
following the introduction to this section, are required in
all component models) and static quantities.
A typical function to compute a total thermodynamic
state record has the following interface.
912

Additionally, a static thermodynamic state record can
be computed from a given total state record and any two
quantities related to the static quantities (w, Ae, ps , Ts ,
M, v as defined above). The rigorous procedure described
with (5) and (6) is for instance implement in such a function conforming to the following interface
replaceable partial function setStatic_Mnw
"Return static state as function of total
state, Mach Number Mn and mass flow
w"
input TotalState total
"Total state record";
input Real Mn
"Mach Number";
input MassFlowRate w
"Mass flow rate";
input Types.FlowRegime regime
= Types.FlowRegime.Subsonic
"Flow velocity regime";
output StaticState static
"Static state record";
end setStatic_Mnw;

Enumeration FlowRegime is optionally used to constrain the solution interval to sub-sonic, sonic, or supersonic results.
Based on this code structuring concept fully rigorous thermodynamic properties are implemented in the Jet
Propulsion Library. See figure 1 for an overview. The underlying model for the entropy function and other related
quantities can be exchanged to allow different representations and fidelity levels. The first one implemented in
Jet Propulsion Library utilizes the polynomial approach
of (Walsh and Fletcher, 2004) and does not capture dissociation effects.

2.3

Connector definition

For the fluid connectors in the Jet Propulsion Library
we adapt the concept of stream connectors as proposed
in (Franke et al., 2009a,b). As defined there, the static
pressure and the static specific enthalpy are used as key
connector variables. Given the introduction to section 2.2
we instead opt for using the corresponding total quantities

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Session 11D: Aerospace

nectors are used (fuel flow supply, shaft interfaces etc.).

2.4

Figure 1. Thermodynamic property functions: Static and total
state records plus functions acting on total state records to the
left and function acting on static state records to the right

on the connectors. Otherwise, the connector is identical
to the well-established and widely adopted fluid connectors. The fluid connector carries flow and thermodynamic
state information such as pressure, mass flow rate, specific
enthalpy, and composition.
connector FluidPort "Fluid connector"
replaceable package Medium =
GasWithCombustionProducts
annotation(choicesAllMatching=true);
AbsolutePressure p
"Total pressure";
flow MassFlowRate m_flow
"Mass flow rate into the
component";
stream SpecificEnthalpy h_outflow
"Total specific enthalpy of exiting
fluid";
stream MassFraction X_outflow[Medium.nS]
"Mass fractions of exiting fluid";
stream ExtraProperty C_outflow[Medium.nC]
"Properties c_i/m in the connection
point";
end FluidPort;

Note how the Modelica naming convention is used for
the variables on the fluid connector.
Unfortunately the connector is still not directly compatible with libraries using the standard fluid connector (e.g.,
from Modelica.Fluid) due to the use of a different package structure for the computation of the thermodynamic
properties. Therefore, a simple adapter component was
required if connections were to be made to the high speed
gas flow path models; for all other interfaces standard conDOI
10.3384/ecp17132909

Simulation modes: On-design, off-design,
transient

Since the beginnings, jet engine performance computations have always considered two main computation problems, design point performance computation (also called
on-design performance computations) on one hand and
off-design performance computations on the other (Walsh
and Fletcher, 2004).
For the design point performance computation, one set
of operating conditions has to be imposed. Then, the component performance levels and sizes are selected. Additionally, top level requirements are implemented (e.g.,
based on cruise at altitude on an ISA day). The design
point performance computation then allows to compute
important cycle parameters, and to define a specific design. This includes a possibly abstract or estimated engine
geometry, based on the fidelity of the analysis. Technically, the output of such a design point performance computation are however scaling parameters on component
level.
Given a specific engine design (figuratively in terms of
an estimated or abstract geometry, or, more technically, in
terms of a complete set of component scaling parameters
for a given engine topology), the off-design performance
computation then allows to estimate the performance at
other key operating conditions (different altitude, Mach
Number, day type and so on). Here geometry is fixed
and operating conditions are changing. While the literature typically describes off-design performance computation as steady-state analysis, this may as well involve
transient simulation.
In order to provide complete functionality in relation to
the established methods, these two kinds of computations
were also implemented in the Jet Propulsion Library. They
can be selected as simulation modes.
A closer look at the literature (e.g., (Walsh and Fletcher,
2004)) reveals that the notion of on-design computations
is not directly compatible with the rules of balanced modeling in Modelica (Olsson et al., 2008). Typically, the bypass ratio or flow split is imposed on a three-way junction
or splitter model. Following the rules of balanced modeling, such a component may however only impose both
downstream pressures or impose one downstream pressure and the bypass ratio or a flow rate. In on-design
computations it is however required for the scaling procedure to impose both downstream pressures and the bypass
ratio. Off-design computations in turn are basically the
computations classically done in the Modelica language.
Therefore, the corresponding simulation problems (be it in
steady-state or transient mode) are fully compatible with
the concept of balanced modeling.
As the constraints of balanced modeling are imposed
for very good reasons (for instance, to improve debugging messages and ensure plug and play compatibility
when selecting specific implementations during system ar-

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

913

The Jet Propulsion Library: Modeling and simulation of aircraft engines

chitecting for a given placeholder) it was not an option on
the design of the Jet Propulsion Library to rely on locally
unbalanced models. Instead, it was decided to restrict the
use of on-design computations to initial time and initial
equations. Like this, initial equations are used to compute corresponding values of the component parameters
that have a fixed attribute equal to false. Based on this decision both on-design computations and off-design computations are in scope of the Library, and its component
and system models always remain balanced.

2.5

Component models

With the exception in the connector definition described Figure 2. Single component experiment with two boundary conin section 2.3, the Jet Propulsion Library fully follows the ditions (the vectorized bleed port at the top is unconnected and
has length zero)
variable naming convention suggested in ARP5571 (SAE,
2005).
design and off-design have the corresponding letter written in opaque font on the boundary condition, quantities
The types of boundary condition models in the Jet Propulthat are either imposed for on-design or imposed for offsion Library are similar to those in other thermo-fluid
design have their corresponding letter written in slightly
dynamics libraries. Most fundamentally, we distinguish
transparent font.
boundary conditions imposing a given mass flow rate,
and boundary conditions imposing pressure (obviously all 2.5.2 Compressor
boundary conditions also impose quantities transported by The compressor model is one of the component models
convection). These two kinds of boundary conditions are that contains the scaling factors mentioned in section 2.4.
also required for modeling and simulation of jet engines. For the compressor on-design performance computation,
However, the prescribed variables may now change from the user typically prescribes isentropic efficiency des and
on-design to off-design computations. To provide full pressure ratio des at the design point. The corrected mass
flexibility to the user, four different flags are exposed on a flow rate wc,des is not imposed directly as a parameter on
boundary condition. These allow to switch on and off the the compressor model but on the system model as a whole,
prescription of pressure and mass flow rate for on-design and then computed from boundary conditions or inlet as
and off-design models respectively. To improve ease-of- well as design bypass ratio BPRdes (the same holds for the
use, these four flags are only exposed to the user in the corrected speed Nc ).
category of advanced component parameters; normally (in
The overall compressor performance in terms of isensimple boundary condition parameterization mode), the tropic efficiency  (or specific work) and pressure ratio
user only decides whether the boundary condition is nom-  is encoded in performance maps (Walsh and Fletcher,
inally a source or a sink.
2004). Based on a particular point in the performance map
that is marked as the design point, four scaling parameters
 A nominal source prescribes both pressure and flow
are then computed as described by (Jones, 2007).
rate for on-design computations, and pressure for offdesign computations, and
 Is. efficiency scaling factor s,des =  des
2.5.1

Boundary conditions

des,unscaled

 A nominal sink prescribes neither pressure nor flow
rate in on-design computation, and pressure in offdesign computation.
Figure 2 shows a simple model diagram with such
boundary condition instances. Color-coding is used to illustrate whether a component includes over-constrained
initial equations (nominal source with green outline) or
under-constrained initial equations (nominal sink with
blue outline). As long as the number of blue components
is equal to the number of green components the system
model will be well-posed (actually, any system is wellposed by construction, the color-coding still helps users to
double-check their model build-up). The color-coding is
also used on other components such as the splitter mentioned in section 2.4 already. Quantities imposed for on914

 Pressure ratio scaling factor s,des =

des 1
unscaled 1

 Corrected flow scaling factor swc ,des =

wc,des
wc,unscaled

 Corrected speed scaling factor sNc ,des =

Nc,des
Nc,unscaled

Here, quantities with index unscaled indicate the value
in the original, unscaled performance map. Based on this
procedure, one compressor map with its design point can
be scaled to represent another compressor (as described by
the target design point as prescribed by the user). As long
as the design points are close enough, the scaling gives a
reasonable approximation of the compressor behavior.
As indicated above, the compressor model requires that
the off-design performance is captured in the format of

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Session 11D: Aerospace

a performance map. The format of this performance
map has to be easy to handle in an computing environment (Walsh and Fletcher, 2004), and avoid vertical or
horizontal lines in the table look-up (Jones, 2007). For
this reason we use beta or R-line maps3 . The method described by (Jones, 2007) in more detail. Basically, the
performance maps relates the important thermodynamic
variables like corrected mass flow rate, pressure ratio, corrected speed and the efficiency of the compressor. A compressor performance map using R-lines is shown in figure 3. R-lines are family of curves that are parallel to the
surge line and evenly spaced among each other. The Rlines ensure unique result in the regions of low corrected
air flow where pressure ratio is almost a constant and regions of constant air flow towards the highest air flow region for a given speed line (avoiding table look-up along
vertical or horizonal tangents).

and be supplied for turbine film cooling or for so-called
customer purposes. A bleed mass flow rate through the
bleed ports can be specified via constant or variable bleed
mass flow fractions in the model. In order to capture the
stage at which the bleed air is extracted, parameter corresponding to the relative bleed enthalphy and the pressure
as a fraction of inlet and outlet conditions are used.
2.5.3 Turbine
The turbines models are built very similar to the compressor models based on the off-design turbine performance
map and a set of scaling factors. For the on-design performance computation, the user typically prescribes isentropic efficiency des and (uncorrected) shaft speed N at
the design point. The pressure ratio des , the corrected
mass flow rate wc,des are again computed from boundary
conditions and the system model (the pressure ratios at the
design point are for instance solved for such that the power
balances per shaft are fulfilled).
The turbine performance map used is as shown in figure 4. Given pressure ratio and speed, corrected flow and
isentropic efficiency can be uniquely determined in a turbine map. This eliminates the need for R-lines as discussed in the compressor section. The format is again
based on (Walsh and Fletcher, 2004; Jones, 2007). The
four scaling parameters then computed from the performance map design point and the jet engine design point
are similar to the ones used for the compressor and described in section 2.5.2.

Figure 3. R-line based compressor map with speed lines (solid),
r-lines (solid), and efficiency contours (dashed)

Other methods to capture the compressor performance
characteristics are described in the literature. One example is the Map Fitting Tool (MFT) method (Sethi et al.,
2013). While Jet Propulsion Library currently only implements the R-line or beta line methodology, the objectoriented structure allows for the convenient addition of
such additional map format in the future.
Once the key component performance variables were
read from the performance map, the component computations continue as known from other thermo-fluid dynamics
libraries.
The compressor model also has a mechanical connector through which it can receive shaft power (for instance
from the respective turbine models).
The compressor model (like all components in the Jet
Propulsion Library) support the modeling of secondary air
systems. For instance, bleed can be extracted from this
compressor model, routed through an arbitrary network,

Figure 4. Turbine map with speed lines (solid) and efficiency
contours (dashed)

Again, once the key performance variables were read
from the map, the component computations basically
continue as known from other thermo-fluid dynamics libraries. This means for instance that the turbine model
also has a mechanical port through which expansion
power is supplied to the compressor through shafts. As
indicated before, the turbine model optionally provides
3 The notion of using an auxiliary coordinate has at least two different
bleed ports which can receive secondary cooling air from
names; beta lines (Walsh and Fletcher, 2004), and R-lines (Jones, 2007). compressor stages or other sources. The resulting power
DOI
10.3384/ecp17132909

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

915

The Jet Propulsion Library: Modeling and simulation of aircraft engines

from the bleed air flows can be accounted for considering flexible and efficient manner. An unmixed turbo fan for
the tip velocity of the turbine blades.
instance consists of the inlet section, fan and compressors, the combustor, the turbines, and the primary and sec2.5.4 Inlet
ondary nozzles. An exemplary break-down for such a two
A critical part of the inlet models are parametric predic- spool unmixed turbo fan thus is
tions of the ram pressure recovery ram and the spillage,
bleed, and bypass drag (expressed via the corresponding
 Inlet section
drag coefficient Cd,install ). These effects can be modeled
 Inlet
using the correlations suggested by Kowalski (Kowalski
and Atkins, 1979). These are available in two different
 Inlet frame duct
flavors; a long (and more accurate) form of computation
 Inlet engine duct
involving 14 tables, and a short form involving 2 com Fan and compressor
pressed tables. The dimensional drag force due to capturing air Dram is eventually computed from
 Fan
Dram = w  v
(7)
 Splitter
 Low pressure compressor
where the ram pressure recovery ram indirectly influences
 High pressure compressor
mass flow rate. The drag force due to installation Dinstall
 Fan duct
is
2
Dinstall = 1/2v Cd,install
(8)
 Combustor
The given references contains more details about the implementation.
 Diffuser duct
 Burner
2.5.5 Nozzle
The ideal gross thrust Fg,ideal of a nozzle can readily be
computed from the following equation

Fg,ideal = w  v + ps,exit  ps,amb Aeexit
(9)

 Turbine

Here, ps,exit and ps,amb are the static pressures at the nozzle
exit section and the ambient respectively. Again, the cruicial question for sound model-based design application is
how much of the ideal results are achievable. This can be
expressed via a number of correlations. One of the quantities to use for this purpose is the nozzle exit gross thrust
coefficient CFg . This coefficient is also used by Kowalski (Kowalski and Atkins, 1979). Beyond CFg correlations
to approximate gross thrust Fg , this methodology also estimates the aftbody drag coefficient Cd,ab . The former for
instance is computed based on pressure ratio and area ratio. Two variations for an axisymmetric nozzle as well as
2-D nozzle exists. Eventually, the actual gross thrust can
be computed
Fg = CFg Fg,ideal
(10)

 Primary and secondary nozzle sections

The nozzle model in the library contains replaceable models to compute the contributions individually. This completes the short overview of exemplary component models.

2.6

Interface and template structure

Based on these component models, different cycles can be
built up using an interface and template model structure.
Different kinds of cycles such turbo fan, turbo jet, geared
turbo fan, turbo prop or turbo shaft have been disassembled virtually into reusable sub-system and sub-assembly
models. Based on the object-oriented interface and template structure they can be plugged together in a highly
916

 High pressure turbine
 Low pressure turbine

 Exhaust frame duct and exhaust tailpipe duct,
or bypass exhaust frame duct
 Nozzle
Different to the state of the art described in section 1,
this approach uses hierarchy and object-orientation to
manage variants and system complexity. Previous art lays
all element out on a flat level. With this approach, we
can conveniently exchange inlet section models from regular inlets to inlets with inlet particle separator, based on
available map data one can conveniently switch between
average and split fan models (averaging the core and bypass fan flow, or modeling them via separate fan models
using different maps), number of spools, as well as detailed section models for compressor and turbine sections
(stage representation, inclusion or removal of case strut
ducts, inlet guide vane ducts, transition ducts, exit guide
vane ducts and so on).
An example breakdown of a turbo fan engine is illustrated graphically in figure 5. This figure shows the actual
view presented to the user in the graphical user interface of
a Modelica Integrated Development Environment (IDE).
Each type of component in the break-down above is
represented through a class hierarchy of interfaces, templates, and implementations. The implementations use the
atomic components described in section 2.5.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Session 11D: Aerospace

Table 3. Low pressure compressor design point parameters.

Parameter

Value

Efficiency
Pressure ratio

86.575 %
2.25

Table 4. High pressure compressor design point parameters.

Parameter

Value

Efficiency
Pressure ratio

86.2469 %
5.679 05

Figure 5. Top-level turbofan model breakdown shown on the
top, compressor break-down on the lower left, high pressure
compression section break-down on the lower right

3

Application example and results

A complete jet engine model was built using the Jet
Propulsion Library of the Pratt & Whitney JT9D. It was
created by configuring the two spool unmixed turbo fan
template model. Each component starting from inlets,
fans, compressors, turbines etc. is redeclared with parameterized models. The respective performance maps are
adapted from the open source distribution of the Toolbox
for the Modeling and Analysis of Thermodynamic Systems (T-MATS) as described by (Chapman et al., 2014).
Table 1 provides key cycle parameters at the design
point. These parameters are approximate but consistent
with the given source.
Table 1. Cycle design point parameters.

Parameter

Value

Design point
Day conditions
Inlet flow
Bypass ratio
Turbine inlet temperature
Net thrust

Sea level static
ISA+15 C
698 kg s1
5.2751
1260 C
223 kN

Figure 6. JT9D fan compressor map

Figures 6, 7, and 8 show the compressor performance
maps. Following the principles described in section 2.5.2,
these maps are scaled based on the component design
point data given in tables 2, 3, and 4.
Table 2. Fan design point parameters.

Parameter

Value

Efficiency
Pressure ratio

90.38 %
1.603 06

DOI
10.3384/ecp17132909

Figure 7. JT9D low pressure compressor map

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

917

The Jet Propulsion Library: Modeling and simulation of aircraft engines

Figures 9 and 10 in turn show the turbine performance
maps. These maps are scaled based on the component design point data given in tables 5 and 6.
Table 5. High pressure turbine design point parameters.

Parameter

Value

Efficiency
Shaft speed

91.445 %
8000 / min

Table 6. Low pressure turbine design point parameters.

Parameter

Value

Efficiency
Shaft speed

92.88 %
3750 / min

In the following, exemplary simulation results are provided. For this purpose, two boundary conditions are imposed on this model, the aircraft Mach number and the
fuel flow rate. The design point simulation runs for a
sea-level static case. Basic sanity check results show a
reasonably good match of the sea level static thrust and
specific fuel consumption produced by the engine model
with published data (Saarlas, 2007). Then, the boundary
condition parameters are varied for off-design simulation.
The model was simulated to conduct a full factorial experiment for inputs of inlet Mach numbers (0.5, 0.7 and 0.9)
and fuel flow that varied 50% from the nominal value in
steps of 5%. The results of this full factorial experiment is
summarized in the two figures below.
Figure 11 plots the relationship between the low pressure spool speed NL and thrust for different Mach numbers. The thrust is divided by  = pt /pt,re f , the normalized inlet total pressure. The low pressure spool speed is
divided by the square root of  = Tt /Tt,re f , the normalized
inlet total temperature. These corrections are routinely
done to normalize the data (Walsh and Fletcher, 2004).
Higher Mach Numbers show lower corrected thrust due to
the inlet ram drag.
The corrected thrust specific fuel consumption trends
are shown in figure 12. Both plots are qualitatively very
similar to the charts given in the relevant literature such
as (Walsh and Fletcher, 2004; Saarlas, 2007). Illustrative
results of the transient simulation mode will be given in a
separate reference.

4

Figure 9. JT9D high pressure turbine map

Conclusions

The Jet Propulsion Library provides a foundation for modeling and simulation of jet engines, and the model-based
design of integrated aircraft system designs. It contains
fully models for sizing and performance computations,
and has a number of advantages over existing domainspecific solutions due to the use of the Modelica language.
918

Figure 8. JT9D high pressure compressor map

Figure 10. JT9D low pressure turbine map

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Session 11D: Aerospace

5

Acknowledgements

We acknowledge the contributions of Shashank Swaminathan who contributed to the interface and template structure described in section 2.6 as summer intern at Modelon,
Inc in 2016.

References
A Alexiou and K Mathioudakis. Development of gas turbine performance models using a generic simulation tool. In ASME
Turbo Expo 2005: Power for Land, Sea, and Air, pages 185
194. American Society of Mechanical Engineers, 2005.
Arjun Bala, Vishal Sethi, E Lo Gatto, Vassilios Pachidis, and
Pericles Pilidis. ProosisUa collaborative venture for gas turbine performance simulation using an object oriented programming schema. In International Symposium on Air
Breathing Engines, 2007.

Figure 11. JT9D corrected thrust vs. corrected low pressure
spool speed

F. Casella, M. Otter, K. Proelss, C. Richter, and H. Tummescheit.
The modelica fluid and media library for modeling of incompressible and compressible thermo-fluid pipe networks. In
Proceedings of the Fifth International Modelica Conference,
pages 631640, 2006.
Jeffryes W Chapman, Thomas M Lavelle, Ryan May, Jonathan S
Litt, and Ten-Huei Guo. Propulsion system simulation using the toolbox for the modeling and analysis of thermodynamic systems (t mats). In 50th AIAA/ASME/SAE/ASEE Joint
Propulsion Conference, 2014.
Hilding Elmqvist, Hubertus Tummescheit, and Martin Otter.
Object-oriented modeling of thermo-fluid systems. In Peter
Fritzson, editor, Proceedings of the Third International Modelica Conference, pages 269286, Linkping, Sweden, 2003.
Rdiger Franke, Francesco Casella, Martin Otter, Michael
Sielemann, Sven-Erik Mattson, Hans Olsson, and Hilding
Elmqvist. Stream connectorsan extension of Modelica for
device-oriented modeling of convective transport phenomena. In Francesco Casella, editor, Proceedings of the seventh
International Modelica conference, pages 108121, Como,
September 2009a.
Rdiger Franke, Francesco Casella, Michael Sielemann, Katrin Proelss, Martin Otter, and Michael Wetter. Standardization of thermo-fluid modeling in Modelica.Fluid. In
Francesco Casella, editor, Proceedings of the seventh International Modelica conference, pages 122131, Como, September 2009b.
Scott M Jones. An introduction to thermodynamic performance
analysis of aircraft gas turbine engine cycles using the numerical propulsion system simulation code. Technical Report
TM2007-214690, NASA, March 2007.

Figure 12. JT9D corrected thrust specific fuel consumption vs.
corrected thrust

Scott M Jones. Steady-state modeling of gas turbine engines
using the numerical propulsion system simulation code. In
ASME Turbo Expo 2010: Power for Land, Sea, and Air,
pages 89116. American Society of Mechanical Engineers,
June 2010.
Edward J. Kowalski and Robert A. Atkins, Jr. A computer code
for estimating installed performance of aircraft gas turbine

DOI
10.3384/ecp17132909

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

919

The Jet Propulsion Library: Modeling and simulation of aircraft engines

engines. Technical report, National Aeronautics and Space
Administration, 1979.
Joachim Kurzke. Advanced user-friendly gas turbine performance calculations on a personal computer. In ASME 1995
International Gas Turbine and Aeroengine Congress and Exposition. American Society of Mechanical Engineers, June
1995.
Joachim Kurzke. About simplifications in gas turbine performance calculations. In Proceedings of the ASME Turbo Expo,
volume 3, pages 1417, May 2007.
Konstantinos G Kyprianidis, Ramon F Colmenares Quintero,
Daniele S Pascovici, Stephen OT Ogaji, Pericles Pilidis, and
Anestis I Kalfas. Eva: A tool for environmental assessment of
novel propulsion cycles. In ASME Turbo Expo 2008: Power
for Land, Sea, and Air, pages 547556. American Society of
Mechanical Engineers, 2008.

Vishal Sethi. Advanced performance simulation of gas turbine
components and fluid thermodynamic properties. PhD thesis,
Cranfield University, April 2008.
Vishal Sethi, Georgios Doulgeris, Pericles Pilidis, Alex Nind,
Marc Doussinault, Pedro Cobas, and Almudena Rueda. The
map fitting tool methodology: Gas turbine compressor offdesign performance modeling. In Journal of Turbomachinery. American Society of Mechanical Engineers, September
2013.
Philip P Walsh and Paul Fletcher. Gas turbine performance.
John Wiley & Sons, 2004.
Michael Winter. A view into the next generation of commercial
aviation (2025 timeframe). In AIAA Aerospace Today and
Tomorrow, 2013.

Konstantinos G Kyprianidis, Andrew M Rolt, and Tomas Grnstedt. Multidisciplinary analysis of a geared fan intercooled
core aero-engine. Journal of Engineering for Gas Turbines
and Power, 136(1):011203, 2014.
Linda Larsson, Tomas Grnstedt, and Konstantinos G Kyprianidis. Conceptual design and mission analysis for a geared turbofan and an open rotor configuration. In ASME 2011 Turbo
Expo: Turbine Technical Conference and Exposition, pages
359370. American Society of Mechanical Engineers, 2011.
John K Lytle. The numerical propulsion system simulation: A
multidisciplinary design system for aerospace vehicles. In International Symposium on Air Breathing Engines, September
1999.
Lester Nichols and Christos Chamis. Numerical propulsion
system simulation-an interdisciplinary approach. In Conference on Advanced Space Exploration Initiative Technologies,
September 1991.
Hans Olsson, Martin Otter, Sven Erik Mattsson, and Hilding
Elmqvist. Balanced models in modelica 3.0 for increased
model quality. In Proceedings of the 6th International Modelica Conference, 2008.
Michael John Provost. The more electric aero-engine: a general
overview from an engine manufacturer. In Power Electronics, Machines and Drives, 2002. International Conference on,
number 487, pages 246251. IEEE, 2002.
Maido Saarlas. Aircraft performance. John Wiley & Sons, 2007.
S-15 Gas Turbine Perf Simulation Nomenclature and Interfaces
Committee of SAE. Application programming interface requirements for the presentation of gas turbine engine performance on digital computers (ARP4868). Technical report,
Society of Automotive Engineers, 2001.
S-15 Gas Turbine Perf Simulation Nomenclature and Interfaces
Committee of SAE. Gas turbine engine performance presentation and nomenclature for digital computers using objectoriented programming (ARP5571). Technical report, Society
of Automotive Engineers, 2005.

920

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132909

Virtual flight testing of a controller for gust load alleviation using
FMI for cosimulation
Reiko Mller1

Institute of System Dynamics and Control, Oberpfaffenhofen, Germany, reiko.mueller@dlr.de
2 DLR, Institute of Aeroelasticity, Gttingen, Germany, markus.ritter@dlr.de

During aircraft design and certification, one of the most
vital development tasks is the calculation of loads and
stresses, subsequent structural sizing and iterative mutual
adaptation with respect to the aircrafts systems. In an effort to build up a so called virtual flight testing capability in the DLR-wide project Digital-X (2012 - 2016), a
simulation of a flexible aircraft model coupled with CFD
based aerodynamics and a flight control system with included Gust Load Alleviation (GLA) was developed and
subjected to a certification relevant gust encounter scenario. Due to the diversity of modeling and simulation
tools present in the DLR, the Functional Mockup Interface (FMI) 2.0 model interfacing standard has been successfully employed to cosimulate the control system inside the enclosing simulation framework. Keywords: Virtual flight testing, Gust load alleviation, Flight control,
FMI, Cosimulation

ics are calculated from the conservation laws of mass,
momentum, and energy. These have no closed form analytical solution and can only be solved by employing
numerical methods from Computational Fluid Dynamics
(CFD). The Python - based software framework FlowSimulator (Meinel and Einarsson, 2010) and CFD solver TAU
(Schwamborn et al., 2006) were developed and utilized in
the Digital-X project for multidisciplinary simulation of
transport aircraft with aerodynamics calculated by CFD
(Kroll et al., 2016). A Modelica - based flight control system with added gust load alleviation functionality had to
be integrated in the FlowSimulator setup to conduct the
virtual flight tests by means of cosimulation using the FMI
2.0 - standard (Mod, 2014). The principal layout of this
approach is shown in figure 1. It benefits from the ad~pext
~ucontrol

1

Introduction

DOI
10.3384/ecp17132921

Aircraft
model
R ti+1

An aircrafts flight envelope expresses the admissible region of flight depending on the current state (e.g. variables
like angle of attack, Mach number and altitude), with upon
exceeding, the aircraft will no longer be flyable (high/low
speed stalling, buffeting). In analogy to this, the loads
envelope specifies the corresponding limits which the aircraft structure can handle. With the advent of electronic
flight control systems, an appropriate means for regulating loads automatically was found and is used to limit the
maximum design loads to increase flight safety, as well
as the ones due to maneuvering or environmental disturbances like gusts. The benefits are manifold, as for example structural stress and fatigue is reduced on the airframe,
passenger comfort is increased and overall aircraft performance can be improved by structural design optimization.
In the following contribution, a novel application for
loads analysis is introduced, combining hitherto disconnected simulation steps and forming a high - fidelity "virtual flight testing" - capability. In detail, an aircraft is
discretized as Finite Element Method (FEM) - model,
with the elements elastic motion solved by methods from
Computational Structural Mechanics (CSM). The forces
and moments acting on the airframe due to aerodynam-

FMI

~ureference

ti

~ufeedback

dt

Flight
control

fmi2Get

Abstract

fmi2Set

1 DLR,

Markus Ritter2

fmi2DoStep

Figure 1. Integration loop of the controller using FMI for cosimulation to conduct virtual flight tests. ~ureference contains controller reference values e.g. from a Flight Management System
(FMS). As well, the aircraft model can depend on external parameters and inputs ~pext that are not part of the cosimulation
loop.

vantages of FMI, that are the time-savings due to omission of user-driven API development, interoperability for
various tools and efficient simulation and event/error handling. Due to the large amount of simulations necessary
for design and tuning of the controller to a specific test
case, a second model based on a faster executing approximative method was established using the loads analysis
software Varloads (Hofstee et al., 2003). The application
scenario is an encounter of a frontal vertical gust, with the
control objective of reducing the vertical accelerations and
loads on the structure.
The paper is structured as follows: In section 2, the governing equations of motion and the elastic deformation of
the aircraft are discussed. The two aerodynamic models
necessary for the controller synthesis as well as the high

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

921

Virtual flight testing of a controller for gust load alleviation using FMI for cosimulation

fidelity simulation are derived in 2.1. The controller is
laid out in section 3, including the design in Modelica and
the gust load alleviation functionality in sections 3.1 and
3.3, along with the integration in the cosimulation setup in
section 3.4. Section 4 discusses the application to the gust
encounter scenario, while conclusions and an outlook for
future work are given in the final section 5.

2

Aircraft modeling

The motion of an aircraft through the air can be described
in different levels of detail. The simplest notion is of
a point on which the aircraft mass is concentrated, that
translates due to external forces and the weight, given by
the dynamic equilibrium of forces (dAlembert principle).
When taking into account distributed masses and the rotational movement of the aircraft, one arrives at the rigidbody equations of motion, yielding six degrees of freedom. These are defined in aircraft mean body axes with
respect to a ground-fixed inertial Cartesian coordinate system on a local tangent plane (flat earth assumption) with
uniform gravity, also known as the Newton-Euler equations (1):
#

"
~ b  ~Vb
Mbb ~Vb + 
T ~ ext
Pg
(1)
= TTrb gr

~b +
~ b  (Ibb 
~ b)
Ibb 
with
Mbb
Ibb
~Vb = [u v w]T
~ b = [p q r]T

Trb

Mass matrix
Inertia tensor
Body-fixed velocity vector
Rotational velocity vector w.r.t. body
fixed system
Transformation of Center of Gravity
(CG) to grid reference point

In (Waszak and Schmidt, 1988) the equations of motion
of the elastic aircraft are derived using the mean axis conditions. These are fulfilled easily by using mode shapes
(eigenvectors) of an unconstrained (free-free) structural
model and ensure that the rigid body equations (1), and
the linear elastic equations of structural mechanics in a
modally reduced form (2), are inertially decoupled.

Figure 2. Digital-X XRF-1 CFD computation mesh with control
surfaces and exemplary deflection of the horizontal tail plane
control surface of 5 degrees on top. A blending technique was
used to obtain a smooth transition at the boundaries of the elevators, which are the only control surfaces used during the gust
encounter cosimulation.

both the large nonlinear motions of a maneuver, and the
small linear perturbation introduced by the flexible structure, be taken into account.

2.1

Aerodynamic models

The aerodynamic forces included in ~Pgext are derived
from the conservation laws for mass, momentum and energy. While the continuity equation depicts the mass flow
through a control volume in the airflow, the Navier-Stokes
equations describe the equilibrium of forces, taking into
account viscosity, volume forces (e.g. due to gravity) and
T
T
the momentum flow through the volume. Compressibil

g f Mgg g f ~u f + g f Bgg g f ~u f
ity of the flow field requires the introduction of the en(2)
+gTf Kgg g f ~u f = gTf ~Pgext
ergy equations, formulating the equilibrium between energy flow through the volume, energy produced due to the
with
forces and moments, external energy contributions and ingr Modal matrix rigid body modes
ner and kinetic energy of the medium.
g f Modal matrix of flexible modes
~Pgext Vector of external forces to structural grid points
In combination, these form an equation system to calculate the forces / the pressure distribution on the aircrafts
Mgg Physical mass matrix
surface, for which however no closed form analytical soluBgg Damping matrix
tion exists. Numerical methods to solve this kind of probKgg Stiffness matrix
lems are grouped under the term of Computational Fluid
~u f
Generalized coordinates of elastic modes
Dynamics (CFD), with DLRs TAU code being a compreHence equations (1) and (2) are only coupled by means hensive software environment for this task and therefore
of the external forces ~Pgext , which in the end allows that an obvious choice as CFD - solver for the FlowSimulator
922

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132921

Session 11D: Aerospace

framework (see description of the simulation setup in 3.4).
Due to the nature of turbulent flow, changes can happen on
a very small scale, which is why the computational grid for
numerically solving the Navier-Stokes equations also may
need a very fine resolution locally, to include all turbulent
phenomena. As can be seen in figure 2, a higher grid density has been applied especially at geometry changes or
regions of expected turbulence.
The complex grids in turn cause a large increase in computation time for calculation of the aerodynamic forces
and moments, while during controller and aircraft design,
quite often thousands of simulation runs are performed,
e.g. to iteratively tune controller gains or to investigate aircraft response to stresses dependent on multidimensional
parameter spaces. Due to their high demand on computational power, the Navier-Stokes equations are generally
not viable for these kind of tasks and have to be simplified. A first step is to solve only for the unknowns that
are most relevant to those applications, e.g. the pressure
distribution on the objects surface.

thenbe linearized
around ~v, with the disturbance veloci
ties u0 , v0 , w0

Figure 3. Aircraft aerodynamic model composed of lift surfaces, for use in the Vortex Lattice Method (VLM) or Doublet
Lattice Method (DLM), generated by VarLoads. Blue panels
belong to the aircraft body, purple ones to the control surfaces.

3

In the beginning of the 20th century, Prandtl found that
for flows at higher Reynolds numbers Re > 105 , the effect
of viscosity is approximatively limited to a thin boundary layer encompassing the objects body. Consequently,
the flow beyond the boundary layer can be considered as
inviscid and importantly, the pressure gradient through it
normal to the surface as zero (  pz  0). In order to obtain the pressure distribution on the objects surface, it is
therefore sufficient to calculate it in the inviscid flow just
outside of the boundary layer using the inviscid NavierStokes or Euler equations. The assumption of isentropic
(no energy contribution/drain) and irrotational flow allows
to define a velocity potential function
i

 h
~v = grad  = u, v, w = x , y , z
(3)
which is inserted into the Euler equations. These can
DOI
10.3384/ecp17132921


   0 
u + x
u
u


~v =  0  +  v0  =  y 

0
w0

(4)

z

to arrive at the unsteady Prandtl-Glauert equation:
1  2
 2   2   2  2U  2 
+
+


=0
 x2
 y2
 z2
a2  xt a2 t 2
(5)
When neglecting the time-dependent terms, the linear second order Laplace equation for the Vortex Lattice Method
(VLM) (Hedman, 1966) is obtained:
(1  Ma2 )

(1  Ma2 )

 2  2  2
+ 2 + 2 = 0.
 x2
y
z

(6)

This method calculates a matrix of Aerodynamic Influence Coefficients (AIC) based on (6) to model lift distributed on an approximation of the aircraft consisting of
several lift surfaces as shown in figure 3. The unsteady
counterpart (in the frequency domain) for solving (5) is the
Doublet Lattice Method (DLM). External aerodynamic
and propulsive forces are added to the inertial forces by
means of the Force Summation method to calculate resultant forces and moments on the aircraft. The loads analysis software VarLoads, which was jointly developed by
Airbus and DLR (Hofstee et al., 2003), implements all of
these modeling and simulation paradigms and was used
to prepare the model with simplified aerodynamics for the
controller synthesis.

Controller design and integration

The Flight Control System (FCS) or short "controller",
follows the classical cascaded design layout that is well
studied in both theory and practice (see e.g. (Brockhaus
et al., 2011)). This layout is based upon the fact that the
aircrafts equations of motion can be separated into parts
that play a role on different timescales (timescale separation principle). For example, the body-fixed rotational
rates [p q r]B as fast states are directly linked to the deflection of the control surfaces and resulting moments. On the
other hand, states referring to orientation and even more
position have a slower progression. This allows to dissect the flight control system into smaller parts, as shown
in figure 4: The inner loop or Stability and Control Augmentation (SCA) - block can be designed to stabilize the
aircraft and to dampen the dynamic aircraft modes (e.g.
phugoid, dutch roll - modes). The autopilot in turn generates a reference orientation for the modified plant of
the aircraft stabilized by the inner loop. It is designed to
achieve a high tracking precision for the desired trajectory
variables. The additional Gust Load Alleviation (GLA) is

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

923

Virtual flight testing of a controller for gust load alleviation using FMI for cosimulation

arranged at the level of the SCA, since it is assumed here
that the gusts cannot be sensed ahead of the aircraft (e.g.
by LIDAR like in Hecker and Hahn (2007)) and necessitate fast reactions of the controller / the control surfaces.
FMS

ref , ref , href ,
ref , . . .

Autopilot

c , c , c ,
Vc , . . .

SCA +
GLA

A , E , R ,
T ,  , gear

6-DoF
rigid body

Figure 4. Structure of an electronic flight control system, consisting of the FMS and the FCS with autopilot and inner loop
SCA. The framed blocks are the considered parts in this work.

As the scenario only considers a frontal vertical gust encounter, the GLA operates on the longitudinal dynamics,
and can symmetrically deflect ailerons and elevators to attenuate the gust. Discrimination between inner and outer
ailerons and elevators as well as distributed spoilers are
incorporated in the GLA - layout, but only uniform and
symmetric deflections of likewise A and E act as inputs.
No actuator dynamics are modeled, due to their absence in
the aircraft model of the cosimulation. Acceleration measurements are available at the Center of Gravity (CG) and
form the single feedback variable:
nz,m =

VK 
Lift
=
+ cos()
Weight g  cos()

the FCS and the GLA respectively. The FCS consists of
four channels for the four individual control effectors of
the airplane (throttle, elevator, aileron and rudder). The
autopilot modes are set to speed -, altitude - and course
- hold, while the commanded sideslip angle c is zero.
The inner loop receives orientation commands from the
autopilot and calculates corresponding rates and control
surface deflections. Each of the channels includes a set of
several cascaded linear controllers. To ensure robustness
over the flight envelope, multiple gust - and load - cases,
a robust controller synthesis process would normally be
appropriate. However, since only one gust encounter case
is considered in this study, a simple tuning of the controller
gains has been performed to minimize the effect on the
wing root bending moment (see section 3.3).

(7)

with load factor nz,m , kinematic velocity VK , trajectory
pitch angle  and roll angle . The load factor is fed
into the parameterized GLA filter structure which generates control surface deflection commands, for the elevator
Eg with a filter structure containing e.g. a tunable timeconstant. These are then super-positioned to the comFigure 5. Modelica model of the longitudinal controller with
mands of the flight controller:
gust load alleviation.
i = ic + ig ,

i  [A, E].

(8)

Hence the autopilot and inner loop also contribute to the 3.2 Initialization of the FMU
load alleviation due to the gust, by acting to hold altitude
Each of the four channels inner loops mentioned in the
and speed.
last section contain either integrator or derivative blocks
with internal states that have to be initialized correctly to
3.1 Controller model in Modelica
avoid transient oscillations in the beginning of the simuThe resulting Flight Control System (FCS) was imple- lation. Furthermore the cosimulation must be compatible
mented in Modelica using Dymola 2016, and is shown in with both aircraft models and their respective trim algofigure 5. The Modelica Standard - and LinearSystems - rithms. The given variables of the initialization process are
libraries provide all of the needed models, with which a the reference inputs ~ureference and feedback inputs ~ufeedback
flight control library had been established. It consists of from the aircraft, while the unknowns are the FMU outmodules arranged in longitudinal, lateral, inner and outer puts ~ucontrol (see figure 1). Hence a two-step initialization
loop controllers and is also prepared for use in conjunc- of the closed-loop simulation setup is performed:
tion with DLRs FlightDynamics library (Looye, 2008).
 At first, the aircraft is trimmed separately for steady
The Dymola simulation tool makes use of the object orihorizontal flight at a given speed and altitude (see taented features of Modelica, allowing easy testing and inble 1 for a set of characteristic state values), without
terchange of different modules and furthermore offers an
the controller. This yields values for e.g.  and 
implementation of the FMI standard.
and also for elevator deflection E and throttle T 1 .
In the diagram view depicted in figure 5, the middle
1 The initial values of the lateral effectors  and  are zero.
left and the lower center grey rectangular blocks represent
R
A
924

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132921

Session 11D: Aerospace

 In the second step, the Functional Mockup Unit
(FMU) outputs need to be set to the aircraft control
input values (~ucontrol ) obtained in step 1. Yet due
to FMI design, which prevents variables with output causality from the assignment of any value, additional trim parameters have to be defined.

3.3

Synthesis of the GLA controller

The controller and GLA gains were adapted to the gust encounter scenario using the fast executing simplified model
of section 2. The single objective of this process was the
minimization of the bending moment around the aircrafts
longitudinal x - axis (see figure 2) at the wing root station,
Mx . In contrast to the high-fidelity simulation, both the
Table 1. Trim values for aircraft model used for controller syn- elevators and the ailerons were actuated by the GLA. Figure 7 compares three gust encounters, one open loop, one
thesis
with flight controller only, and one combined with additional GLA. The undisturbed case is added for reference
Property
Unit
Value
and shows the bending moment at the trim condition.
Mach number
0.83
The control objective is to reduce the initial maximum
Altitude
ft
35000
amplitudes of Mx . This is satisfied by the FCS and the
Reference velocity
m/s
246.1
GLA as expected, with the most notable difference in
Aircraft mass
kg
198540 the second peak at t  0.7 s. Due to several filter time
Angle of attack
4.55
constants, the GLA does not act against the first falling
Gust gradient H
m
85.9
peak, which is why the controller - and GLA - variants
Gust velocity in z - direction
m/s 4.296 reduce the moment about the same amount. At the second rising gust peak, the GLA is able to reduce the moment around 45 %, however the GLA inputs generate an
increased preceding moment. Using this highest GLA q
q
q



k
+
+
+
G
k
+


peak, the reduction over the open loop case is still as large
,V

as 39 % with the steady trim moment value as baseline.
k
I
c

c

RC



c

p

i

q

106

Figure 6. Inner loop pitch channel, with pitch angle , pitch
rate q and GRC as transfer function containing the correction for
turning flight (increase in pitch due to rotated lift vector).

No gust
Open loop
Controller
Controller + GLA

6.5

This second step is further explained using the example of
the inner loop pitch channel shown in figure 6: With given
E,trim and trim , the single degree of freedom is the initial
state value of the integrator. The trim pitch angle is added
to the autopilot command
c = AP + trim ,

Mx [Nm]

6
5.5
5
4.5

(9)

0

1

2

where AP is zero here due to initial h = hc . Likewise
the elevator command consists of
E = qc + E,trim + E,GLA .

(10)

With the constraint of steady state integrator initialization
(xint = 0), and similar provisions for the velocity channel,
the initial equation of the controller model has to be specified as shown in listing 1. By calling the initialize()
- method of the FMU, the controller can then match the
preceding aircraft trim.
Listing 1. Initial equation of the controller model
i n i t i a l equation
c o n t r o l l e r L o n g i t u d i n a l . y [ 1 ] = trim_de_T ;
c o n t r o l l e r L o n g i t u d i n a l . y [ 2 ] = trim_de_E ;

DOI
10.3384/ecp17132921

3
t[s]

4

5

6

Figure 7. Wing-root bending moment for uncontrolled and two
controlled gust encounter simulations.

3.4

Integration in simulation environment

The FlowSimulator framework allows to specify, integrate
and simulate all sub-models necessary for the controlled
coupled CSM - CFD application. A special FlowSimulator - plugin called FSDynafly has been developed at DLRs
Institute of Aeroelasticity to model the process chain for
the controlled cosimulation, see figure 8.
After initialization, the governing equations of motion
of the free-flying elastic aircraft (equations (1) and (2))
are solved by FSDynafly for the current time step. Their
outputs and the command references are passed on to the

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

925

Virtual flight testing of a controller for gust load alleviation using FMI for cosimulation

FMU
Solve coupled
6-DoF and
structural
EOM
x = f (x, x)

Controller:
Calculate
thrust and
control surface
actuation

TAU: Motion module update

ua = H us

CFD mesh
deformation

TAU:
Calculate
aerodynamic
forces

fs = HT fa

Figure 8. Time domain solution process of FSDynafly_6DOF
including the flight controller.

FMU to form the control error. The deflection commands
calculated by the FMU are mapped onto the structural grid
at the respective control surface positions, yielding modal
deformations us . An unstructured mesh has been built for
the Digital-X XRF-1 configuration using the meshing software CENTAUR, with the control surfaces being cut into
the CAD geometry based on locations provided by Airbus. Each control surface thus has a separate boundary
marker in order to be deflected properly in the unsteady
gust encounter simulation. As the structural grid does not
coincide with the aerodynamic one, the deformations are
multiplied with the splining matrix H, which is built from
Radial Basis Functions (RBFs). It is then morphed according to the deformations ua using the submodule FSDeformation, as is shown in figure 2 with the example of
the Horizontal Tail Plane (HTP) - deflection. In parallel,
another submodule of the CFD solver TAU calculates an
update of the aircraft motion, followed by the actual call
of TAU to solve for the new aerodynamic forces fa of the
next time step. To solve the equations of motion, these are
transformed back into forces fs relating to the structural
grid by multiplication with HT .
The controller interfaces to FSDynafly through the
Functional Mockup Interface (FMI), in the working principle shown in figure 1. The FMI for cosimulation
methodology was adopted, since deployment as model exchange - type FMU would have been far more complicated
(e.g for integration and event handling). The complete
controller model shown in figure 5 is exported together
with the Sundials CVode ODE - solver compiled in a FMI
- compliant library (64-bit .so for UNIX - type target simulation environment). As the application and interfacing
layer of FSDynafly is written in Python, the DLR - developed Python FMI - API of PySimulator (Pfeiffer et al.,
2012) is used to address the FMU. Finally, a fixed-time
step master algorithm enables communication between the
two cosimulated models, a Python code representation is
given in listing 2.

# Trim t h e a i r c r a f t
[ x_tr , u_tr , dx_tr ] = a i r c r a f t . trim (
x0 , u0 , dx0 ,
ix , iu , idx0 )
# S e t t h e t r i m p a r a m e t e r s i n t h e FMU . . .
# . . . to achieve u equal to u_tr
fmu_setReal_inValueAndReference (
fcs , pars_trim ,
[ " trim_de_T " , " trim_de_E " ,
" trim_de_A " , " trim_de_R " ] , u _ t r )
# I n i t i a l i z e t h e FMU
fcs . i n i t i a l i z e ( )
# I n t e g r a t i o n loop
while aircraftODE . s u c c e s s f u l ( )
and s t a t u s == 0
and t <= s t o p T i m e :
# Set u to u_tr for the f i r s t . . .
# . . . timestep
i f t == t 0 :
u_in = u_tr
else :
u_in = u
# E v a l u a t e a i r c r a f t r i g h t hand s i d e . . .
# . . . and r e t r i e v e f e e d b a c k
der_x , out = a i r c r a f t O D E . f (
t , aircraftODE . y , u_in )
# Set controller reference inputs
fmu_setReal_inValueAndReference (
f c s , u _ r e f , [ " h " , "V" ] , u _ r e f . v a l )
# Set c o n t r o l l e r feedback inputs
fmu_setReal_inValueAndReference (
fcs , u_feedback ,
u _ f e e d b a c k . varNames , o u t )
# I n t e g r a t e one s t e p f o r FMU
s t a t u s = f c s . d o _ s t e p ( t , dt , True )
# R e t r i e v e c o n t r o l l e r commands
u = fmu_getReal_fromValueAndReference (
f c s , y _ o u t , y _ o u t . varNames )
# S e t a i r c r a f t model i n p u t s
aircraftODE . set_f_params ( u )
# I n t e g r a t e one s t e p f o r a i r c r a f t
aircraftODE . i n t e g r a t e ( t + dt )
# Increment the master time
t = t + dt
# End o f i n t e g r a t i o n

4

Vertical gust encounter simulation

As mentioned before, the only scenario covered in this
contribution is an encounter of a discrete vertical gust with
the assumption that all points in planes normal to the aircrafts velocity are affected (as defined in (Joint Aviation
Authorities, 1994)). The vertical velocity profile is shaped
according to equation (11)



U
V
ds
Listing 2. Master algorithm for the cosimulation of aircraft with
wwind =
1  cos
 t ,
(11)
2
H
the controller in Python (only the most relevant commands are
displayed).
# Load t h e FMU
f c s = FMUInterface . FMUInterface (
" C o n t r o l l e r _ G L A . fmu " )
fcs . fmiInstantiate ( )

926

and therefore denoted as "One-minus-cosine" - gust. The
parameters of this function are the design gust velocity
Uds , the gust gradient H, which is the distance parallel
to the aircrafts flight path for the gust to reach its peak
velocity, and V  t as the distance traveled into the gust.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132921

Session 11D: Aerospace

Cosim
Ctrl

0
0.5

3

1

2

12

w [m/s]

wwind [m/s]

4

q [ /s]

0.5

5

1

GLA off

GLA on

14

0
0

0.2

0.4

0.6
t [s]

0.8

1

q [ /s2 ]

2

The gust parameters are slightly differing between the
high fidelity cosimulation and controller simulation as
shown in figure 9, similarly the angle of attack and HTP
trim values, see table 2. Furthermore, in the high fidelity
simulation results presented in the following, only the control surfaces of the horizontal tail plane were used as primary control surfaces to reduce the loads acting on the airframe. This was partly due to project time constraints and
availability of other control surface geometries like spoilers and ailerons. The gains in overall load reduction can
therefore not be compared between the high- and lower fidelity models as of now, yet this was not the goal of this
specific application anyway.

w [m/s2 ]

Figure 9. One minus cosine gust definitions used for the complete cosimulation and for the controller synthesis.

0
2
4
2
0
2
0

2

4

6
t [s]

8

10

12

Figure 10. Selected states of the aircraft as function of time,
showing a reduction of accelerations due to the gust load alleviation.

HTP [ ]

distinctive lateral motions are excited during the gust encounter. Small but negligible lateral motions occur due to
non-negative values for Ixy , and Iyz of the tensor of inertia
of the aircraft. These entries can be attributed to the fact
Table 2. Trim values for high fidelity simulation, only values that the mass model is not purely symmetric. The output
differing from those in table 1 are listed.
of the controller in terms of the time dependent rotation of
the horizontal tail planes control surface is shown in figProperty
Unit Value
ure 11. The maximum deflection of the HTP is about 1.3 .
This value is comparatively low, but the gust disturbance

Angle of attack
3.39
velocity is small as well.

HTP trim angle
2.58
Gust gradient
m
125
Gust velocity in z - direction
m/s
5
Communication time stepsize
s
0.01
1
Two gust encounter simulations are presented in the following, one without gust attenuation, and another one with
0.5
the flight controller in the loop. The results are shown
in figure 10 in terms of selected states measured in the
0
body fixed coordinate system with the pitch rate q, its time
dq
derivative dt , the velocity in the z - direction w and the acceleration in the z - direction dw
dt .
0
5
10
15
As can be seen from the time function of the states plott [s]
ted, the actuation of the controller markedly reduces the
accelerations of the airframes center of gravity, thereby Figure 11. Controller output in terms of the rotation of the HTP
reducing structural loads as well. A reduction of the heave control surface.
accelerations of more than 20% is achieved. This simulation is a purely symmetric maneuver, meaning that no
DOI
10.3384/ecp17132921

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

927

Virtual flight testing of a controller for gust load alleviation using FMI for cosimulation

5

Conclusion and outlook

In this contribution, a new methodology for loads analysis
and virtual flight testing of flight controllers is presented.
Usually disconnected simulation steps are combined into
a single process chain, including elastic structural aircraft
modeling, full Navier-Stokes aerodynamics and a flight
control system with gust load alleviation.
A flight controller with outer and inner loop, as well as
gust load alleviation system was set up in Modelica using
Dymola. It was tuned for a gust encounter scenario using a
Vortex Lattice Method (VLM) based aerodynamic model,
allowing the required large number of simulations during
controller synthesis. A final reduction of up to 45% in the
wing root bending moment was found there.
A setup for the cosimulation was developed in Python,
including a fixed-step master algorithm connecting the
simulation framework FSDynafly with the controller. By
employing the FMI standard to interface the controller,
dedicated API development for the dissimilar aircraft
models could be omitted. Furthermore the functionalities
of FMI for cosimulation allowed an easy setup and efficient operation of the controlled high fidelity simulation.
Reductions in the vertical and the pitch accelerations of up
to 20 % were achieved, also consequentially leading to a
reduction in the structural loads.
After successfully completing this first proof of concept, future work will be directed towards functionality
in larger simulation studies with multi-parameter or even
multi-model test cases and different scenarios (e.g. maneuver loads, flight performance analysis). Ensuring the
robustness of the controller for the entire flight envelope
will be an important prerequisite for these applications,
and could be achieved by employing methods from robust
control design (e.g. H or robust LPV control).
An immediate next step will be the addition of new control surfaces (ailerons and possibly spoilers) to the CFD
mesh, since currently the only means of controlling the
aircraft and the loads is the horizontal tail plane. Based on
the results of the simplified aerodynamics simulation, it is
expected that loads on the main wing can be further reduced by this approach. As well, it should be worthwhile
to incorporate additional design criteria in the controller
synthesis process. By treating it as a multi-objective optimization problem, the investigation of trade offs between
e.g. load reduction, passenger comfort and flying qualities
is made possible.

6

Acknowledgments

This work was prepared during the course of DLR project
Digital-X. The authors would like to express their thanks
to the following colleagues for their support and input:
Martin Leitner, Hans-Dieter Joos, Andreas Pfeiffer and
Thiemo Kier.
928

References
Rudolf Brockhaus, Wolfgang Alles, and Robert Luckner.
Flugregelung. Springer, 2011. ISBN 9783642014437.
URL
http://books.google.de/books?id=
2IKXH3skXBwC.
Simon Hecker and Klaus-Uwe Hahn. Advanced gust load alleviation system for large flexible aircraft. In Proceeding 1st
CEAS Konferenz, 2007.
Sven G Hedman. Vortex lattice method for calculation of quasi
steady state loadings on thin elastic wings in subsonic flow.
Technical report, DTIC Document, 1966.
Jeroen Hofstee, Thiemo Kier, Chiara Cerulli, and Gertjan
Looye. A variable, fully flexible dynamic response tool for
special investigations (VarLoads). In 2003 CEAS/AIAA/NVvL
International Forum on Aeroelasticity and Structural Dynamics, 2003.
Joint Aviation Authorities. Joint aviation requirements. JAR25. Large aeroplanes. Civil Aviation Authority Printing &
Publication Services, Greville House, 37, 1994.
Norbert Kroll, Mohammad Abu-Zurayk, Diliana Dimitrov,
T Franz, Tanja Fhrer, Thomas Gerhold, Stefan Grtz, Ralf
Heinrich, Caslav Ilic, Jonas Jepsen, et al. DLR project
Digital-X: towards virtual aircraft design and flight testing
based on high-fidelity methods. CEAS Aeronautical Journal,
7(1):327, 2016.
Gertjan Looye. The new DLR flight dynamics library. In Proceedings of the 6th International Modelica Conference, volume 1, pages 193202, 2008.
Michael Meinel and Gunnar O Einarsson. The FlowSimulator
framework for massively parallel CFD applications. PARA
2010, 2010.
Functional Mock-up Interface for Model Exchange and CoSimulation, Version 2.0. Modelica Association, July 2014.
Andreas Pfeiffer, Matthias Hellerer, Stefan Hartweg, Martin Otter, and Matthias Reiner. PySimulator-A Simulation and
Analysis Environment in Python with Plugin Infrastructure.
In Proceedings of the 9th International MODELICA Conference; September 3-5; 2012; Munich; Germany, pages 523
536. Linkping University Electronic Press, 2012. 76.
Dieter Schwamborn, Thomas Gerhold, and Ralf Heinrich. The
DLR TAU-Code: recent applications in research and industry. In ECCOMAS CFD 2006: Proceedings of the European
Conference on Computational Fluid Dynamics, Egmond aan
Zee, The Netherlands, September 5-8, 2006. Delft University of Technology; European Community on Computational
Methods in Applied Sciences (ECCOMAS), 2006.
Martin R Waszak and David K Schmidt. Flight dynamics of
aeroelastic vehicles. Journal of Aircraft, 25(6):563571,
1988.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132921

The DLR Environment Library
for Multi-Disciplinary Aerospace Applications
Lle Evrim Briese1
1 Institute

Andreas Klckner1

Matthias Reiner1

of System Dynamics and Control, DLR German Aerospace Center, Oberpfaffenhofen, Germany,

Lale.Briese@dlr.de  Andreas.Kloeckner@dlr.de  Matthias.Reiner@dlr.de

Abstract
Environment models are vital elements for any type of
vehicle dynamics simulations, such as aircraft or satellites. Recently, applications have been developed, where
these previously unrelated regimes of operation need to
be integrated, for example in end-to-end simulations of
launch vehicles. This paper therefore introduces the new
DLR Environment Library, which implements common
models of planets, geospheres, currents, kinematics, and
physical effects for such applications. It provides a set of
environment models with minimal dependencies, complete compatibility to the Modelica Standard Library, and
convenient drag & drop usage. The DLR Environment
Library is expected to immensely aid developing endto-end simulation models integrating components from
DLRs SpaceSystems and FlightDynamics Libraries. In
particular, it will importantly decrease modeling errors
due to its consistent environment models.
Keywords: environment modeling, gravitational models,
planet models, atmosphere models, kinematic state models, space mission simulation, multi-disciplinary modeling

1

Introduction

Modeling of environmental effects is highly relevant for
vehicle simulations, such as aircraft (Klckner et al., 2013;
Looye, 2008), satellite (Reiner and Bals, 2014; Pulecchi
et al., 2006), or launch vehicle simulations (Acquatella,
2016). While these domains have mostly been treated
as independent in the past, latest developments point towards even more integrated simulation needs. For instance, reusable launchers will require accurate modeling
of aircraft-like and satellite-like flight phases. Especially,
combined multi-disciplinary simulations, including several vehicle types like launch vehicles and satellites with
corresponding environmental conditions as well as ground
stations, are of great interest within end-to-end space mission simulations.
For several years, the Institute of System Dynamics
and Control at the DLR German Aerospace Center has
been developing Modelica-based libraries for the modeling and simulation of flight vehicles (DLR FlightDynamics Library) and satellites (DLR SpaceSystems Library) as
shown in Figure 1. These libraries can operate either inDOI
10.3384/ecp17132929

DLR Space
Systems Library

DLR Flight
Dynamics Library

DLR Environment Library
DLR FlexibleBodies Library
DLR Visualization Library
Figure 1. An overview of the interaction of application-based
libraries with the new DLR Environment Library.

dependently from each other or in combination with other
libraries. For example, the DLR FlexibleBodies Library is
used for modeling flexible structures and the DLR Visualization Library is used for visualizing multibody systems.
Although these libraries share one common need for the
modeling of environmental effects, there have been different application- and library-specific environment models for each library. Certainly, not every application requires the same level of detail or the same type of environment models for the specific design regime. For example,
a satellite system in Low Earth Orbit (LEO) can neglect
gravitational effects of another planet and a flight vehicle
with a cruise flight altitude of 40.000ft is hardly influenced
by the solar radiation pressure, unlike spacecraft in a deep
space environment.
In general, most environment models are stored inside
subpackages of application libraries, providing just the
minimal amount of data needed for the realistic simulation
of the desired application. For this purpose, most environment models take into account gravitational acceleration,
atmospheric parameters, and specific influences which are
relevant for use cases as presented for example in Reiner
and Bals (2014), Looye (2008) or Pulecchi et al. (2006).
The advantages of application- and library-dependent environment models are clearly the reduction of the level of
detail and the simplification of complex environmental effects. This leads to a smaller amount of available models
for individual purposes and consequently to less required
maintenance.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

929

The DLR Environment Library for Multi-Disciplinary Aerospace Applications

Figure 2. Visualization of Envisat in an orbit simulation using the DLR Environment Library.

A major disadvantage of this strategy arises when multiple application-based libraries must be used for one comprehensive problem. The combination of several multidisciplinary libraries can then lead to redundancies or
discrepancies in the overall environmental formulation.
This is especially the case if two or more application libraries are combined for the end-to-end simulation of e.g.
reusable launch vehicles. For example, depending on the
specific application, coordinate systems or rotation sequences can be defined differently and therefore can lead
to often unmanageable errors. Also, different gravitational
models can result in mismatched data of the Inertial Measurement Unit (IMU) of each system, finally increasing
the overall error between vehicles in a multi-disciplinary
simulation.
To prevent these problems, it has been decided to build
a common library, based on knowledge of environmental
effects inside application libraries. The overall goal of the
library is to provide a modular, non-redundant and userfriendly formulation of environmental effects. It has to be
compatible with the Modelica Standard Library (MSL) as
well as the application libraries developed at the Institute
of System Dynamics and Control.
Within this paper, the new Environment Library is presented. In Section 2, an overview of the library is given,
including its purpose, its main characteristics, its basic
structure as well as the verification of its compatibility
with the MSL. Based on this section, some selected features of the library are further introduced in Section 3. The
functionality of the models is demonstrated within Section 3 with specific examples provided by the application
libraries mentioned before. The main advantages of the
proposed library are summarized in Section 4.
930

2

Overview of the Library

For multi-disciplinary end-to-end simulations regarding
all kinds of vehicles (from Earth-based flight and launch
vehicles to spacecraft in deep space environment), specific but consistent environmental conditions have to be
considered. The library is developed to fulfill these multidisciplinary requirements and is therefore based on environment models from two application-related Modelicabased libraries developed by the Institute of System Dynamics and Control:

 DLR SpaceSystems Library (SSL)
(Reiner and Bals, 2014), and
 DLR FlightDynamics Library (FDL)
(Looye, 2008; Klckner et al., 2014a)
The library in its current version is fully tested within
the simulation environment Dymola 2017. Although it is
designed as a stand-alone library, it is based on the Modelica Standard Library (3.2.2) and builds on the DLR Visualization Library (1.4) for optional visualization as presented in Figure 2 for an orbit simulation of the environmental satellite Envisat. The DLR Visualization Library is
not required for the functionality of the provided environment models, but it enables drag & drop visualization of
all parts of the simulation. With the visual effects, a better understanding of the overall model behaviour can be
provided, especially when flight dynamics are considered.
The main characteristics of this library regarding its basic structure and the implementation of the provided models were determined by considering the following goals.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132929

Session 11D: Aerospace

 Modularity
Models inside the library shall be able to work independently. A limited amount of interdependent models is considered acceptable.

 Generality
The library shall be seen as a common ground for
multiple disciplines. It shall therefore provide models which can adapt to requirements of multiple disciplines without affecting unrelated disciplines.

1

Main Subpackages

 Adaptivity
The library shall be able to grow and has to allow individual modification. The library shall adapt easily
to changes in other used libraries (e.g. MSL).

2
3
4
5
6

 Reusability
Models provided by the library shall be usable in different domains, at the best as drag & drop models.

Figure 3. An overview of the top-level library structure.

 User-friendliness
The library and its models shall be designed without
the need of intensive maintenance or without excessive user interaction or configuration.

MultiBody.World (MSL)

 Simplicity
The amount of configurable parameters shall be reduced as much as possible and conditional changes
of the model behaviour shall be implemented in separate models instead of using enumerated types.

2.1

Basic Structure of the Library

MSL Compatiblity

MultiBodyWorld (copy)

extends
Base Classes
PartialWorld

PartialGeospheres

PartialCurrents

extends
Drag & Drop Models

An overview of the top-level structure of the Environment
Planet 1
Geosphere 1
Current 1
Library is shown in Figure 3. The library provides a docuPlanet 2
Geosphere 2
Current 2
..
..
..
mentation with information about the library itself includ.
.
.
ing contact information, references, release notes and a
tutorial for beginners. Additionally, examples to demonstrate the functionality of the provided models are imple- Figure 4. An overview of the object-oriented library structure.
mented. Environment models are stored in the main subpackages. Further dependencies between the main sub- environmental effects, offer a better understanding of the
packages are kept minimal in order to achieve maximum overall model behaviour. A brief summary of these submodularity.
packages is given below:
The main subpackages for the modeling of planets,
geospheres and currents are created based on an object Planets 1
oriented structure as shown in Figure 4. All main subpackThis subpackage contains generic MSL-based planet
ages contain the package BaseClasses in which partial
models, providing relevant planet frames, the global
models for each discipline are implemented. These parsimulation time, the time-dependent rotation angle
tial models provide specific functions to be accessed from
of rotating planets, the planet constellation inside
anywhere within the simulation model corresponding to
the solar system as well as the advanced replaceable
the inner and outer concept in Modelica. From these
gravityAcceleration function.
partial models, drag & drop models in the top-level of
 Geospheres 2
each subpackage are extended. This planet-independent
Models which represent general geospheres (e.g. atlibrary structure enables a highly modular, user-friendly,
mosphere) are included inside this package, providobject-oriented and consistent modeling of environmening inner models with replaceable functions similar
tal conditions. These advantages are vitally important for
to the gravityAcceleration function to calculate
multi-disciplinary simulations regarding multiple vehicles
specific geospheric parameters as well as the mean
in different environments. Especially, many separate modcurrent of the geosphere.
els instead of one general model containing all possible
DOI
10.3384/ecp17132929

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

931

The DLR Environment Library for Multi-Disciplinary Aerospace Applications

 Current 3
Inside this package, components for modeling of additional currents like user-defined wind are stored,
which are designed as drag & drop models to induce
currents (or wind effects in terms of the atmosphere)
to a connected body frame.

Drag &
Drop Models

 Kinematics 4
The package Kinematics contains several functions
to describe kinematic relationships and coordinate
transformations as well as models for automatic state
selection for MSL-based bodies.
 Physical Effects 5
Inside the package PhysicalEffects specific models representing certain physical effects are implemented which provide for example forces due to the
solar radiation pressure or information about the geomagnetic field.
 VisualEffects 6
Several models to visualize the Earth, the Moon
and the Sun are implemented inside this package.
They are based on components in the DLR Visualization Library. With the visualization software
SimVis (Bellmann, 2009) and the provided highresolution visualization data of the Earth, the simulation results for a certain problem can be shown in a
realistic and easily recognizable way (see Figure 2).
Subpackage-specific functions are implemented inside
the Functions packages, whereas components which
are not intended for further usage are stored inside the
Internal packages. Using common base classes for all
drag & drop models, two possible modeling approaches
can be followed by the user (van der Linden et al., 2014).
First, the partial models from the BaseClasses packages can be placed inside generic simulation models such
that they can be replaced dynamically for each application
model. Second, the drag & drop models from the top level
can be used as fully functional and stand-alone components of application models.
The Utilities package provides environment related
constants, enumeration types, icons as well as general
functions. Inside the subpackage User, individual user options can be stored as additional constants. Especially for
large files that cannot be saved inside the Resources folder,
like the visualization data of the Earth, a modifiable path
name to the source directory can be supplied and managed
by each user individually.

3

Selected Features of the Library

Within this section, some of the main subpackages and
features of the Environment Library are emphasized. Selected use cases are provided in thematically related subsections to demonstrate the functionality of the presented
models as well as the wide range of available model variants inside the library.
932

Figure 5. An overview of the subpackage Planets.

3.1

The Planets subpackage

The Planets subpackage as shown in Figure 5 provides
planet models, which are compatible to the standard multibody world component of the MSL (Otter et al., 2003).
This facilitates the switching to enhanced world models
in application libraries without changing the application
library structure or code.
The model MultiBodyWorld with the replaceable
function gravityAcceleration is a modified copy of
the original world component with two important changes.
On the one hand, the parameters have been rearranged
in additional tabs without changing their content. This
is done in order to provide a better overview of the parameters inside the world component and to enhance the
user-friendliness of the overall model with a thematically
structured graphical user interface. On the other hand,
the equations to define the position and orientation of the
frame frame_b in the original world component are no
longer defined as equations. Instead, they are integrated
as variable declarations to the definition of the frame itself such that these values can be changed while using an
extends statement. With this new modeling approach for
an extended world model and its modified frame definition, moving planets within the solar system can be integrated into the simulation taking into account their influences on each other.
From this modified world component a partial model
PartialWorld for planetary objects is extended introducing an additional frame and two internal functions to resolve any vector from the inertial frame frame_b to this
new moving reference frame. Because the world component is defined as an inner model, it is possible to call
the two internal functions inside the PartialWorld from
anywhere inside the simulation model under the condition
that an outer command referencing the world component
is used. Although this modeling strategy is applicable to
any rotating planetary object, the implementation of the
Earth will be explained further in this section.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132929

The Earth component is extended from the partial
model PartialWorld. The frame frame_b is defined as
an inertial frame (Earth Centered Inertial, ECI), whereas
the new additional frame represents the Earth Centered
Earth Fixed (ECEF) coordinate system with an attitude
depending on the simulation time and the Earths angular velocity. Additionally, the parameter gravityType is
redefined with Earth-specific gravity types and the function gravityAcceleration is redeclared with the corresponding functions to calculate the gravity acceleration
vector of the Earth.
With this modeling concept, components from the MSL
can be used with the new world definition. This can be
demonstrated with the example Double Pendulum placed
on the Earths surface. The original world component
inside the MSL and the modified MultiBodyWorld are
based on the same gravity model and therefore provide the
same results as presented in Figure 6. Additionally, the
resulting acceleration of the component boxBody2 using
a more advanced gravitational model based on the Earth
is presented. It is shown, that the behaviour of the Double Pendulum changes significantly over time depending
on the chosen gravitational model, demonstrating the consequences of using different gravitational models within
end-to-end simulations.
Some planet-specific features implemented inside the
extended planet models are further introduced using the
Earth component as an example.
Absolute Simulation Time
The new world component adds an absolute simulation
time julianDate, which is initialized with parameters
provided by the user either in Julian date format or in
years, months, days and hours with minutes and seconds
as fractions.

Gravity Acceleration,y [m/s2]

Session 11D: Aerospace

MultiBody.World (MSL)
MultiBodyWorld (Environment)
Earth with EGM96 (Environment)

100
75
50
25
0
25
50
0

1

2

3

4

5

6

7

8

Time [s]
Figure 6. Compatibility of the planet models with the MSL.

dard world component. The basic gravity types from the
original world component are still available to maintain
the compatibility to the MSL. Additionally, more precise
gravity models like the EGM96 (Lemoine et al., 1998) and
the Vinti Order 6 (Bate et al., 1971) gravity models can be
chosen for the calculation of the gravity acceleration vector gE  R3 of the Earth. The EGM96 model uses terms
up to the second degree of the zonal harmonic coefficients
of the gravitational potential as discussed in Reiner and
Bals (2014). Those are only dependent on the symmetrical
mass distribution along the z-axis of the Earth. The Vinti
Order 6 potential function takes into account the perturbation accelerations due to the Earths nonsphericity based
on Bate et al. (1971).
If needed, the gravity acceleration from the Moon and
the Sun can be considered inside the precise gravity models. Therefore, the current positions of the Moon rM and
the Sun rS with respect to the Earth are calculated analytically with low precision formulae for planetary positions (van Flandern and Pulkkinen, 1979). As an alternative, they can also be obtained from the DE405 ephemeris
files (Standish, 1998). Relying on the current Julian date
as an input parameter, the DE405 ephemeris coefficients
are extracted from an external C-code to calculate the positions of the Moon and the Sun.
The total gravity acceleration vector g0 is finally calculated as the sum of the gravity acceleration from the Earth
gE , the Moon gM and the Sun gS . The gravity acceleration vectors gM and gS are calculated according to the
Equation (1) depending on the position rM,S  R3 and the
gravitational constant GM,S of the Moon or the Sun.


rM,S 
rM,S  rE
(1)
gM,S = GM,S 
3  

rM,S  rE 
rM,S 3

Rotation of the Earth
The Earths rotation angle at a certain time is determined
as a function of the absolute simulation time as proposed
inside the Naval Observatory Vector Astrometry Software
(NOVAS) (Bangert et al., 2011). The transformation
matrix from the ECI frame to the rotating ECEF frame
can either be defined as a simplified rotation between
these frames using only the rotation angle (ERA) around
the Earths rotation axis (z-axis) with respect to the ECI
frame, or it can be calculated considering the nutation
and precession depending on the Julian date as well as
the difference in seconds between Universal Time and
Universal Coordinated Time (Bangert et al., 2011). The
leap seconds are automatically computed based on tabular
The absolute gravity acceleration for different gravity
data (Astronomical Almanac, 2010), but can also be models is shown in Figure 7 for the given latitude of the
provided by the user as input values.
International Space Station (ISS). The position of the ISS
is calculated from orbital elements provided by NORAD
Two-Line Element sets (TLE) (NASA, 2011) for a given
Gravity Acceleration
To calculate the gravity acceleration vector g0  R3 with point in time as implemented inside the SSL. The modrespect to the inertial frame, the Earth model provides a els provide very similar results, except for the expected
gravityAcceleration function comparable to the stan- disturbances.
DOI
10.3384/ecp17132929

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

933

Latitude [deg]

The DLR Environment Library for Multi-Disciplinary Aerospace Applications

60
40
20
0
20
40
60

0

1000

2000

3000

4000

5000

Gravity Acceleration [m/s2]

Time [s]
8.70
8.65
Point Gravity
EGM96
Vinti

8.60
8.55

0

1000

2000

3000

4000

5000

Time [s]
Figure 7. Comparison between different gravity models (ISS).

3.2

The Geospheres subpackage

The subpackage Geospheres is implemented to provide
specific types of geosphere models, like atmosphere models which can be used in combination with flight or launch
vehicles, respectively.
All main geosphere models are extended from the partial model PartialGeosphere. This model contains two
replaceable functions, which can be called from anywhere
inside a simulation model. Both functions require the position of an object with respect to the rotating reference
frame. The outputs of the function baseProperties are
the absolute pressure, temperature, density and speed of
sound, corresponding to the BaseProperties implementation inside the MSL package Media. The output of the
second replaceable function meanCurrent is the velocity
of the geosphere-specific current.
Similar to the implementation of planets, the user can
choose between two modeling concepts using either the
PartialGeosphere or the stand-alone geosphere models
from the top-level of this subpackage. The replaceable
functions baseProperties and meanCurrent can be redeclared with advanced functions for each specific geosphere model.
In terms of atmosphere models, geodetic parameters
such as latitude, longitude and altitude have to be calculated from the given input position. For this purpose, consistent kinematic functions inside the Kinematics package are used (see Section 3.5) approximating the shape of
the planet according to the World Geodetic System 84
(WGS84) (NIMA, 2000). Optionally, the user can decide
if the geoid undulation between the calculated altitude and
the Mean Sea Level shall be taken into account. For this
reason, the geoid information based on the EGM96 model
is computed with an external C-code (Lemoine et al.,
1998).
934

In the Environment Library, different geosphere models
for the Earths atmosphere are implemented. For example,
a constant atmosphere with user-provided parameters or a
user-defined atmosphere with input values based on tabular data can be chosen. For the latter option, the tabular
data is interpolated using the altitude of the object. Other
geosphere components use standard atmosphere models as
explained in the following list:

 StandardAtmosphere (ISA)
Within this component, two atmosphere models covering several regimes are implemented. The Two
Zones Model by Schnzer (1969) can be chosen especially for flight vehicles with an altitude up to
40.000ft. The Three Zones Model (NASA, 2015) can
be used if atmospheric conditions between the troposphere and the upper stratosphere are needed. This
model is based on atmospheric measurements with
separate curve fits for the troposphere, the lower and
the upper stratosphere.
 StandardAtmosphere76
This component is based on the U.S. Standard Atmosphere model from 1976 where the atmospheric
parameters can be determined for altitudes from -5
km up to 1000 km. For altitudes above 50 km, the
data for this atmosphere model is based on rocket
and satellite measurements (NASA, 1976).
 NRLMSISEAtmosphere
The NRL-MSISE-00 model is a highly accurate empirical model developed by the U.S. Naval Research
Laboratory (NRL) (Picone et al., 2001). It is primiraly used by spacecraft due to its accuracy in altitudes above 100 km and its range from the ground to
the exosphere. The density and temperature at a certain position are computed using the NRL-MSISE00 database with an external C-code. As inputs, the
Julian date provided by the world component as well
as the geodetic parameters latitude, longitude and altitude are required.
For all atmosphere models, the mean current is based on
a logarithmic approach to determine the velocity vector in
the Earths boundary layer with respect to the ground. In
Figure 8, a comparison between the provided atmosphere
models is shown for the ascent phase of a generic launch
vehicle depending on its current altitude. All atmosphere
models provide similar results for the atmospheric density but significantly different results for example for the
temperature corresponding to the approximation methods
used inside particular atmosphere models. Especially in
multi-disciplinary simulations, one common atmosphere
model instead of many application-specific atmosphere
models for several vehicles can therefore reduce errors in
the overall model behaviour.

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132929

40
20
0
20
40
60
80

0

10

20

30

40

Density [kg/m3]

Altitude [km]
1.2
1.0
0.8
0.6
0.4
0.2
0.0

ISA (Two Zones)
ISA (Three Zones)
U.S. 1976
NRL-MSISE-00

0

10

20

0

10

20

30

40

30

40

Mach [-]

Figure 8. Comparison between different atmosphere models.

The Currents subpackage

Currents are used as a supplement to geosphere models as
presented in Section 3.2. While geosphere models provide
mean currents for any location with their internal function
meanCurrent, a current model provides simplified models of local flow velocities such as turbulence or gusts.
Each submodel (e.g. aircraft or spacecraft) can have its
own local current model. All currents retrieve the mean
current from the geosphere and add local effects to it.
A simple example is the continuous Dryden turbulence
model (MIL-STD-1797A, 1990), which adds a low-passfiltered white noise to the mean current (The MathWorks,
2016). Such an approach is illustrated in Figure 9 for a
user-defined wind profile, where the filtered noise is added
to the mean current from the geosphere model. This approach makes it possible to also cover distributed flow effects, such as wake vortices or delayed turbulence.
Like for the geosphere models, the user has the option
to also use local wind or gust effects based on tabular data,
which interpolates the velocity components according to
the position of the object connected to the currents frame.

3.4

The PhysicalEffects subpackage

The subpackage PhysicalEffects provides stand-alone
drag & drop models to automatically induce forces and
torques due to physical effects on the attached frames. In
contrast to the previous subpackages, these models are not
based on a common partial model. However, all models
fulfill the same goals as defined in Section 2 for instance
in terms of modularity, simplicity and user-friendliness.
Selected features of this subpackage are described below.
DOI
10.3384/ecp17132929

turbulent
non-turbulent

20
10
0
10
20

0

20

40

60

80

100

120

Figure 9. Application of a turbulent current on a wind profile.

Altitude [km]

3.3

30

Altitude [km]

Altitude [km]
5
4
3
2
1
0

Global Wind Velocity [m/s]

Temperature [C]

Session 11D: Aerospace

Gravity Gradient Torque
The gravity gradient torque is modeled as a torque a that
acts on a connected frame with the position r0,a and the
rotational transformation matrix Ta . The torque is caused
by the allocation of the mass with respect to its center and
depends on the inertia tensor IB  R3x3 (Larson and Wertz,
1999). In Equation (2), the gravity acceleration vector
g0  R3 is a function of the position r0,a and the Julian
date tJ which is retrieved for the position of the connected
frame directly from the world component.
!
!
r0,a
3

 
(2)
a = Ta g0 (r0,a ,tJ ) 
r0,a   IB Ta r0,a 
Solar Radiation Pressure
The effect of the solar radiation pressure is modeled as a
force fsp that acts on the connected frame. Shadows of the
Moon and the Sun are considered with the shadow factor
sp  [0, 1] using a cylindrical shadow model. The equations are implemented as proposed in Montenbruck and
Gill (2000). Required parameters are the effective area
Asp of the solar radiation pressure and its normal vector
nsp as well as the coefficient of reflectivity of the material
sp  [0, 1] (total absorption to total reflection) as shown in
Equations (3) to (5). The distance between the Sun and the
frame is defined as dsp  R3 . The solar radiation pressure
p is assumed to be constant for spacecraft near Earth.
nsp

csp, = 
nsp 
"

d
 sp
dsp 

dsp

csp,R = (1  sp ) 
dsp  + 2 sp csp,

(3)
n
 sp
nsp 

AU 2
fsp = sp p Asp csp, csp,R  2
dsp 

#
(4)
(5)

Geomagnetic Field
The geomagnetic field can be computed for a connected
frame by the GeoMagneticField component, using the
US/UK World Magnetic Model (WMM) from 2010 or
2015 (Maus et al., 2010). The model provides a magnetic
field vector Bm  R3 that depends on the latitude, longitude and altitude of the component as well as the current

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

935

The DLR Environment Library for Multi-Disciplinary Aerospace Applications

Julian date provided by the world model. The output
vector is calculated in the local North-East-Down (NED)
frame which can be transformed to any other coordinate
system like ECI or ECEF with the provided functions
inside the package Kinematics (see Section 3.5). The
resulting geomagnetic field can be used for example in
simulations with magnetic actuators or Inertial Navigation Systems (INS).
Atmospheric Drag for Spacecraft
The atmospheric drag is caused by friction with the remainder of the atmosphere depending on the altitude. Like
the solar radiation pressure, the atmospheric drag is modeled as a force and torque element acting on the attached
frame which should be located at the center of mass of
the object. The density  of the atmosphere is provided
by the NRL-MSISE-00 model due to its accuracy in near
Earth orbit. The drag force fad and torque ad can be computed using Equations (6) and (7) where vrel is the relative
velocity of the object with respect to the rotating Earth.
fad = 0.5 cd Aad  kvrel k vrel


vrel
2
 Ta dcp
ad = 0.5 cd Aad  kvrel k
kvrel k

(6)

Figure 10. An overview of the package Kinematics.
ECEFz
North
East
Down
lat
lon
ECIx

ERA
ECEFx

ECEFy
ECIy

Figure 11. An overview of some basic coordinate systems.

(7) a better overview for the user. Common functions can reduce errors due to different implementations of coordinate
Required parameters are the drag coefficient cd , the effec- systems within application-based libraries.
tive area Aad and the vector from the center of pressure to
In addition to computing the states in a required notathe center of mass dcp , resolved in the attached frame.
tion, the library provides models to define the very same
notations as actual continuous time states of a MultiBody
3.5 The Kinematics subpackage
model by simply dragging the component into a model and
The Environment library includes a comprehensive toolset connecting it to a frame connector. This is accomplished
for coordinate transformations and kinematics simulation. by first, defining the desired states with stateSelect=
These can be used for MultiBody models to flexibly
StateSelect.always, second, transforming the desired
states into standard MultiBody notation, and finally, set compute kinematic states in different notations,
ting the frame variables to the result. As for the transformation functions, there are components to set position,
 define different notations of continuous states, and
velocity and attitude states independently from each other.
Finally, constraint models are provided, which interface
 constrain the kinematics to lower-order models.
seamlessly with the standard MultiBody models. This inIn order to compute kinematic states of a MultiBody cludes a generalization of the quasi-steady flight kinematmodel, functions are provided which transform the stan- ics inside the FDL to general MultiBody models. Theredard state set of a MultiBody frame (i.e. position r_0, at- fore, any six degrees of freedom (DOF) model can be
titude R.T, and rotational velocity R.w) to a broad variety transformed effectively into a three DOF model removing
of different notations. The structure of the provided mod- the rotational states. The transformation is accomplished
els and functions reflects this distinction in separate col- by explicitly setting R.w={0,0,0} and creating new unlections of conversion functions. Since many notations, known variables for the orientation Q. The model thus insuch as WGS84 positions or an aircrafts attitude, are terrupts the usual flow of calculation (conceptually a dougiven relative to the planets reference system, a further ble integration from torques to rates and attitude) as shown
discrimination is made between conversions in the inertial in Equations (8) to (10).
and the world reference system (see Figures 10 and 11).
der(R.w):=f(t)
 0:=f(t),
(8)
The conversion functions are used by the provided sender(Q):=f(R.w)
 no kinematics,
(9)
sor models, which retrieve the states of a frame. The implemented functions to calculate the kinematic relationt:=f(Q,R.w)
 Q:=f(t).
(10)
ships are also generalized such that they can be used to
compute the required parameters given in any other geodeBy rooting frame_a.R in the model, the kinematics
tic system instead of the WGS84. The simplified and equations in the MultiBody components are disabled and
user-friendly structure of the kinematic functions provides by setting R.w={0,0,0}, the dynamics equations implic936

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132929

Session 11D: Aerospace

Acknowledgements
We would like to thank Dr. Gertjan Looye (DLR German Aerospace Center) for his contributions to former
implementations of environment models inside the DLR
FlightDynamics Library.

References
P. Acquatella. Launch Vehicle Multibody Dynamics Modeling
Framework for Preliminary Design Studies. 6th International
Conference on Astrodynamics Tools and Techniques (ICAAT),
2016.
Figure 12. An overview of the structure of a simulation model
using the presented environment and kinematics models.

Astronomical Almanac. The Astronomical Almanac for the Year
2011. United Kingdom Hydrographic Office, 2010. ISBN:
978-07-0774-103-1.

itly force the torques to be zero. In order to achieve a J. Bangert, W. Puatua, G. Kaplan, J. Bartlett, W. Harris, A. Fredwell-defined model, external torque equations are required
ericks, and A. Monet. Users Guide to NOVAS Version C3.1.
to compute the unknown attitude variables Q.
Technical report, U.S. Naval Observatory, 2011.
As for the usage of the models provided by the subpackage Kinematics, the structure of a simulation model for R. Bate, D. Mller, and J. White. Fundamentals of Astrodynamics. Dover Publications, Inc., 1971. ISBN: 0-486-60061-0.
a generic vehicle is shown representatively in Figure 12 in
combination with the previously presented models within
T. Bellmann. Interactive Simulations and advanced Visuthe DLR Environment Library.

4

alization with Modelica. In Proceedings of the 7th International Modelica Conference, pages 541550, 2009.
doi:10.3384/ecp09430056.

Conclusion

The DLR Environment Library is a Modelica-based library for modeling environmental effects for application- A. Klckner, M. Leitner, D. Schlabe, and G. Looye. Integrated
Modelling of an Unmanned High-Altitude Solar-Powered
specific libraries. Over the past years, environment modAircraft for Control Law Design Analysis. In Advances in
els, optionally including planet definitions or atmospheric
Aerospace Guidance Navigation and Control - Selected Paparameters, have been developed independently and in a
pers of the Second CEAS Specialist Conference on Guidance,
smaller scale within each application library. These sepaNavigation and Control, pages 535548. Springer Berlin Heirate developments have induced problems due to redundelberg, 2013. ISBN 978-3-642-38252-9.
dant declarations, mismatched level of detail, accuracy
and precision within multi-disciplinary projects. With the A. Klckner, G. Looye, R. Mller, R. Kuchar, F. Re, and
DLR Environment Library, these problems are solved, as
M. Leitner. Object-Oriented Aircraft Modeling with the DLR
FlightDynamics library. In 9th AIRTEC 2014 International
introduced in previous sections.
Congress, 2014a.
Especially, the new library and modeling concept based
on an object-oriented library structure provides several adA. Klckner, F. L. J. van der Linden, and D. Zimmer. Noise Genvantages as listed below:

 modular, reusable and comprehensible structure,
 easily adaptable to new requirements & applications,
 consistent definition of environmental conditions,
 simple, user-friendly and understandable models,
 reduced maintenance demands.

eration for Continuous System Simulation. In Proceedings of
the 10th International Modelica Conference, pages 837846,
2014b. ISBN: 978-91-7519-380-9.

A. Klckner, A. Knoblach, and A. Heckmann. How to Shape
Noise Spectra for Continuous System Simulation. In Proceedings of the 11th International Modelica Conference,
pages 411418, 2015. ISBN: 978-91-7685-955-1.
W. J. Larson and J. R. Wertz. Space Mission Analysis and Design, volume 3. Microcosm Press and Kluwer Academic Publishers, 1999. ISBN: 1-881883-10-8.

Although the development of general terrain, weather
and aerodynamic models is in progress, these packages F. G. Lemoine, S. C. Kenyon, J. K. Factor, and R. G. Trimhave been excluded from the content of this paper, since
mer et al. The Development of the Joint NASA GSFC and
the models are not yet fully implemented and tested inside
National Imagery and Mapping Agency NIMA Geopotential
the Environment Library. The implementation of all planModel EGM96. Technical report, National Aeronautics and
ets within the solar system is also planned for the future.
Space Administration (NASA), 1998.
DOI
10.3384/ecp17132929

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

937

The DLR Environment Library for Multi-Disciplinary Aerospace Applications

G. Looye. The New DLR Flight Dynamics Library. In Proceedings of the 6th International Modelica Conference, volume 1,
pages 193202, 2008.

T. C. van Flandern and K. F. Pulkkinen. Low-Precision Formulae for Planetary Positions. The Astrophysical Journal Supplement Series, 41:391411, 1979.

S. Maus, S. Macmillan, S. McLean, B. Hamilton, A. Thomson,
M. Nair, and C. Rollins. The US/UK World Magnetic Model
for 2010-2015. Technical report, National Oceanic and Atmospheric Administration (NOAA), 2010.
MIL-STD-1797A. Flying Qualities of Piloted Aircraft. U.S.
Department of Defense, 1990. Military Standard.
O. Montenbruck and E. Gill. Satellite Orbits - Models, Methods
and Applications. Springer Verlag, Heidelberg, 2000. ISBN:
978-3-642-63547-2.
NASA. U.S. Standard Atmosphere, 1976. Technical report, National Aeronautics and Space Administration, 1976.
NASA. Definition of Two-line Element Set Coordinate System,
2011. National Aeronautics and Space Administration,
http://spaceflight.nasa.gov/realdata/
sightings/SSapplications/Post/JavaSSOP/
SSOP_Help/tle_def.html.
NASA. Earth Atmosphere Model, 2015. National Aeronautics
and Space Administration, https://www.grc.nasa.
gov/WWW/K-12/airplane/atmosmet.html.
NIMA. World Geodetic System 1984 - Its Definition and Relationships with Local Geodetic Systems. Technical report,
National Imagery and Mapping Agency, 2000.
M. Otter, H. Elmqvist, and S. Mattsson. The New Modelica
MultiBody Library. In Proceedings of the 3rd International
Modelica Conference, pages 311330, 2003.
J. M. Picone, A. E. Hedin, and A. C. Aikin D. P. Drob.
NRLMSISE-00 empirical model of the atmosphere: Statistical comparisons and scientific issues. Journal of Geophysical
Research, 107, 2001. doi:10.1029/2002JA009430.
T. Pulecchi, F. Casella, and M. Lovera. A Modelica Library for
Space Flight Dynamics. In Proceedings of the 5th International Modelica Conference, pages 107116, 2006.
M. J. Reiner and J. Bals. Nonlinear inverse models for the control of satellites with flexible structures. In Proceedings of
the 10th International Modelica Conference, pages 577587,
2014. doi:10.3384/ECP14096577.
G. Schnzer. Einfhrung in die Flugphysik. Institut fr
Flugfhrung, TU Braunschweig, 1969. Lecture notes.
E. M. Standish. JPL Planetary and Lunar Ephemerides, DE405
/ LE405. Technical report, Jet Propulsion Laboratory, 1998.
The MathWorks. Dryden Wind Turbulence Model, 2016.
http://de.mathworks.com/help/aeroblks/
drydenwindturbulencemodelcontinuous.html.
F. L. J. van der Linden, C. Schlegel, M. Christmann, G. Regula,
C. I. Hill, P. Giangrande, J.-C. Mar, and I. Egaa. Implementation of a Modelica Library for Simulation of Electromechanical Actuators for Aircraft and Helicopters. In Proceedings of the 10th International Modelica Conference, pages
757766, 2014. doi:10.3384/ECP14096757.

938

Proceedings of the 12th International Modelica Conference
May 15-17, 2017, Prague, Czech Republic

DOI
10.3384/ecp17132929

